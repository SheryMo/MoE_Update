nohup: ignoring input
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:0'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}
网络架构：{'231': ['146', '190', '19', '25', '22', '121', '127', '239', '137', '47', '105', '41', '30', '199', '183', '39', '176', '115', '64', '209', '134', '14', '70', '159', '222', '196', '123', '108', '178', '197', '117'], '239': ['176', '105', '137', '196', '199', '25', '47', '41', '108', '231', '178', '30', '19', '222', '117', '197', '159', '39', '22', '134', '121', '115', '14', '146', '209', '183', '190', '123', '127', '64', '70'], '39': ['178', '196', '47', '190', '108', '121', '146', '176', '134', '22', '30', '117', '159', '19', '231', '115', '105', '41', '183', '123', '239', '137', '127', '25', '199', '197', '222', '70', '14', '64', '209'], '64': ['190', '178', '115', '41', '30', '239', '105', '137', '199', '19', '108', '146', '127', '123', '121', '47', '159', '14', '70', '183', '39', '22', '231', '197', '25', '176', '222', '117', '134', '209', '196'], '159': ['231', '47', '121', '25', '222', '14', '209', '146', '70', '41', '183', '176', '190', '199', '39', '105', '115', '127', '196', '22', '178', '64', '108', '30', '19', '239', '134', '117', '197', '137', '123'], '134': ['108', '22', '159', '137', '178', '25', '190', '117', '146', '19', '39', '121', '123', '196', '222', '209', '115', '70', '47', '41', '127', '199', '176', '14', '183', '231', '239', '105', '197', '64', '30'], '47': ['190', '117', '183', '159', '231', '25', '196', '105', '108', '222', '41', '123', '30', '64', '176', '127', '121', '22', '39', '134', '197', '209', '70', '146', '19', '239', '178', '115', '137', '199', '14'], '25': ['137', '196', '146', '183', '190', '64', '199', '123', '41', '22', '178', '105', '117', '222', '134', '209', '197', '239', '121', '19', '30', '115', '231', '159', '70', '14', '127', '47', '39', '108', '176'], '178': ['70', '239', '199', '159', '146', '19', '176', '105', '25', '115', '22', '14', '209', '183', '134', '196', '197', '41', '123', '121', '64', '190', '30', '108', '47', '39', '222', '117', '231', '127', '137'], '117': ['22', '105', '231', '134', '14', '19', '115', '127', '137', '39', '70', '197', '178', '176', '64', '222', '146', '30', '199', '190', '121', '209', '196', '159', '108', '123', '25', '47', '41', '239', '183'], '137': ['123', '64', '117', '222', '199', '70', '209', '115', '239', '231', '30', '108', '190', '121', '197', '183', '146', '127', '14', '105', '19', '178', '196', '159', '47', '39', '134', '22', '41', '25', '176'], '19': ['108', '137', '231', '183', '64', '30', '196', '123', '178', '222', '25', '47', '239', '121', '159', '134', '39', '146', '115', '127', '105', '176', '199', '14', '209', '197', '41', '190', '22', '70', '117'], '41': ['146', '19', '197', '47', '30', '231', '22', '64', '222', '178', '209', '121', '190', '25', '137', '159', '183', '105', '14', '115', '117', '134', '108', '199', '123', '196', '239', '127', '39', '70', '176'], '14': ['105', '39', '22', '197', '64', '134', '199', '159', '196', '70', '183', '146', '115', '137', '30', '178', '190', '209', '25', '41', '239', '231', '121', '222', '47', '127', '108', '117', '123', '176', '19'], '190': ['19', '121', '64', '108', '117', '159', '70', '22', '30', '199', '105', '178', '115', '39', '239', '197', '222', '231', '134', '14', '41', '25', '183', '137', '127', '146', '209', '123', '47', '196', '176'], '121': ['231', '115', '25', '14', '22', '176', '196', '178', '146', '239', '108', '41', '127', '64', '19', '190', '70', '159', '183', '47', '137', '209', '30', '105', '39', '134', '197', '222', '117', '123', '199'], '115': ['176', '222', '199', '196', '108', '137', '64', '105', '183', '239', '231', '47', '39', '19', '190', '127', '134', '209', '123', '41', '197', '22', '178', '121', '159', '30', '117', '146', '25', '14', '70'], '183': ['222', '14', '30', '159', '178', '123', '137', '105', '47', '22', '25', '39', '115', '19', '41', '70', '190', '108', '176', '134', '239', '231', '146', '209', '64', '196', '197', '127', '121', '117', '199'], '70': ['117', '127', '231', '196', '137', '121', '146', '239', '39', '30', '159', '190', '105', '14', '178', '108', '41', '134', '19', '22', '64', '47', '176', '199', '183', '123', '209', '197', '115', '25', '222'], '196': ['105', '25', '39', '123', '239', '70', '176', '134', '127', '117', '190', '137', '178', '197', '222', '115', '64', '231', '159', '47', '146', '19', '121', '14', '22', '199', '183', '41', '108', '209', '30'], '22': ['127', '41', '190', '178', '176', '231', '14', '115', '30', '209', '239', '134', '121', '19', '70', '196', '137', '105', '197', '123', '159', '146', '108', '183', '64', '39', '47', '199', '25', '117', '222'], '123': ['178', '209', '25', '117', '231', '22', '239', '199', '183', '47', '127', '115', '146', '105', '222', '176', '14', '64', '41', '134', '108', '190', '30', '39', '121', '70', '137', '197', '19', '196', '159'], '105': ['183', '14', '127', '231', '137', '19', '30', '108', '178', '196', '209', '117', '159', '25', '47', '134', '22', '123', '197', '39', '146', '199', '222', '190', '239', '41', '176', '70', '115', '121', '64'], '30': ['108', '176', '231', '22', '222', '183', '105', '70', '239', '137', '209', '190', '39', '117', '121', '197', '25', '47', '115', '159', '123', '41', '196', '178', '19', '127', '14', '64', '134', '146', '199'], '199': ['121', '197', '47', '25', '14', '196', '137', '70', '64', '127', '108', '209', '159', '190', '39', '134', '176', '117', '30', '183', '22', '123', '231', '115', '222', '146', '105', '239', '178', '41', '19'], '127': ['47', '231', '137', '105', '239', '196', '123', '19', '183', '70', '117', '39', '30', '108', '121', '199', '115', '41', '25', '14', '197', '159', '222', '64', '176', '146', '178', '190', '22', '209', '134'], '108': ['115', '159', '39', '197', '183', '105', '14', '70', '239', '196', '209', '121', '22', '146', '64', '30', '19', '134', '127', '137', '222', '176', '117', '190', '47', '178', '231', '123', '25', '199', '41'], '197': ['183', '108', '39', '14', '19', '127', '159', '117', '123', '47', '134', '222', '231', '190', '121', '209', '146', '115', '239', '41', '178', '64', '22', '199', '176', '196', '25', '30', '70', '137', '105'], '146': ['121', '22', '115', '197', '127', '183', '47', '199', '209', '222', '176', '70', '64', '196', '134', '39', '231', '117', '19', '159', '41', '178', '239', '123', '105', '108', '190', '25', '30', '14', '137'], '209': ['197', '134', '41', '190', '105', '178', '121', '19', '127', '22', '25', '146', '199', '183', '30', '231', '176', '137', '159', '115', '239', '64', '39', '70', '14', '117', '196', '108', '222', '47', '123'], '176': ['239', '19', '209', '199', '197', '121', '22', '30', '190', '231', '137', '134', '183', '41', '222', '47', '123', '178', '25', '127', '70', '108', '105', '196', '39', '159', '14', '115', '117', '64', '146'], '222': ['47', '25', '117', '121', '70', '14', '39', '22', '115', '127', '108', '176', '19', '137', '199', '196', '146', '159', '105', '64', '190', '41', '239', '123', '134', '30', '197', '209', '231', '178', '183']}
231
cuda:0
wsc
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:58<00:58, 58.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 34.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 38.03s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wsc] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wsc] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/super_glue/super_glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue/revision/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue/revision/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue/tree/3de24cf8022e94f4ee4b9d55a6f539891524d646?recursive=False&expand=False HTTP/1.1" 307 138
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue/tree/3de24cf8022e94f4ee4b9d55a6f539891524d646?recursive=False&expand=False HTTP/1.1" 200 501
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue/tree/3de24cf8022e94f4ee4b9d55a6f539891524d646/axb?recursive=False&expand=False HTTP/1.1" 307 142
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue/tree/3de24cf8022e94f4ee4b9d55a6f539891524d646/axb?recursive=False&expand=False HTTP/1.1" 200 232
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue/revision/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue/revision/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 241
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue/tree/3de24cf8022e94f4ee4b9d55a6f539891524d646/wsc.fixed?recursive=False&expand=False HTTP/1.1" 307 148
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue/tree/3de24cf8022e94f4ee4b9d55a6f539891524d646/wsc.fixed?recursive=False&expand=False HTTP/1.1" 200 356
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 241
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 241
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 241
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 241
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 241
DEBUG:filelock:Attempting to acquire lock 140438519450560 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_wsc.fixed_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 140438519450560 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_wsc.fixed_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wsc.fixed/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 140438519450560 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_wsc.fixed_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 140438519450560 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_wsc.fixed_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Attempting to acquire lock 140437046813344 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wsc.fixed/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 140437046813344 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wsc.fixed/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wsc.fixed/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 140437046813344 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wsc.fixed/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 140437046813344 released on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wsc.fixed/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wsc from None to 0
INFO:lm_eval.api.task:Building contexts for wsc on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 44591.79it/s]
DEBUG:lm_eval.evaluator:Task: wsc; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:03<11:00,  3.32s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:04<03:47,  1.15s/it]Running loglikelihood requests:   4%|▎         | 7/200 [00:04<01:37,  1.98it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:05<01:30,  2.12it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:06<01:24,  2.23it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:07<01:20,  2.31it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:08<01:18,  2.37it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:08<01:16,  2.38it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:09<01:14,  2.43it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:10<01:12,  2.48it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:11<01:10,  2.51it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:12<01:09,  2.51it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:12<01:09,  2.51it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:13<01:08,  2.50it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:14<01:07,  2.49it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:15<01:06,  2.50it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:16<01:05,  2.53it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:16<01:03,  2.56it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:17<01:02,  2.58it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:18<01:01,  2.58it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:19<01:00,  2.60it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:19<00:58,  2.63it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:20<00:57,  2.65it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:21<00:56,  2.67it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:22<00:55,  2.69it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:22<00:54,  2.70it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:23<00:53,  2.71it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:24<00:58,  2.45it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:25<00:55,  2.53it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:26<00:55,  2.53it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:26<00:52,  2.60it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:27<00:50,  2.66it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:28<00:50,  2.64it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:28<00:49,  2.67it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:29<00:48,  2.69it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:30<00:46,  2.70it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:31<00:46,  2.71it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:31<00:45,  2.73it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:32<00:44,  2.73it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:33<00:43,  2.73it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:34<00:42,  2.76it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:34<00:41,  2.79it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:35<00:40,  2.82it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:36<00:39,  2.83it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:36<00:38,  2.82it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:37<00:37,  2.85it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:38<00:36,  2.88it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:38<00:35,  2.92it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:39<00:34,  2.97it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:40<00:33,  2.99it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:40<00:32,  3.01it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:41<00:31,  3.03it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:42<00:30,  3.04it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:42<00:29,  3.05it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:43<00:29,  3.06it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:44<00:28,  3.10it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:44<00:20,  4.07it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:45<00:16,  4.77it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:45<00:17,  4.32it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:46<00:18,  4.00it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [00:47<00:19,  3.79it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [00:47<00:19,  3.64it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [00:48<00:19,  3.54it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [00:48<00:19,  3.48it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [00:49<00:18,  3.44it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [00:50<00:18,  3.42it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [00:50<00:17,  3.41it/s]Running loglikelihood requests:  70%|███████   | 141/200 [00:51<00:17,  3.40it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [00:51<00:16,  3.40it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [00:52<00:16,  3.41it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [00:53<00:15,  3.42it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [00:53<00:14,  3.43it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [00:54<00:14,  3.44it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [00:54<00:13,  3.45it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [00:55<00:12,  3.47it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [00:55<00:12,  3.47it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [00:56<00:11,  3.48it/s]Running loglikelihood requests:  80%|████████  | 161/200 [00:57<00:11,  3.49it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [00:57<00:10,  3.49it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [00:58<00:10,  3.50it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [00:58<00:09,  3.50it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [00:59<00:08,  3.51it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [00:59<00:08,  3.51it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [01:00<00:07,  3.48it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [01:01<00:07,  3.51it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [01:01<00:06,  3.54it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [01:02<00:05,  3.57it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [01:02<00:05,  3.60it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [01:03<00:04,  3.63it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [01:03<00:04,  3.65it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [01:04<00:03,  3.66it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [01:04<00:02,  3.68it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [01:05<00:02,  3.70it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [01:05<00:01,  3.71it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:06<00:01,  3.73it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:07<00:00,  3.75it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:07<00:00,  3.77it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:07<00:00,  2.96it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:1'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:1'}
full model:
{'wsc': {'alias': 'wsc', 'acc,none': 0.39, 'acc_stderr,none': 0.04902071300001973}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8279363410631274
0.19299873358047231
0.24697427628971416
0.9498246079459217
0.9208790959024347
0.5433529265767616
0.7541489406957872
0.8642404861438043
0.9451768410410958
0.6364904470004392
0.8605038470072015
0.8806563523485148
0.7320941418431636
0.7167995199876819
0.9558598958577776
0.7974395317006763
0.8001507378395173
0.8689133172877098
0.6142386786363212
0.6039861720637983
0.8068446902119512
0.6154342295548068
0.8415314242927469
0.42042589459680124
0.7443787948515065
0.7081725962998161
0.7223774755032815
0.9338202429729527
0.7700364698774241
0.8279363410631274
0.19299873358047231
0.24697427628971416
0.9498246079459217
0.9208790959024347
0.5433529265767616
0.7541489406957872
0.8642404861438043
0.9451768410410958
0.6364904470004392
0.8605038470072015
0.8806563523485148
0.7320941418431636
0.7167995199876819
0.9558598958577776
0.7974395317006763
0.8001507378395173
0.8689133172877098
0.6142386786363212
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[6, 7, 2, 4, 5, 1, 3, 0]
tensor([6, 7, 2, 4, 5, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[1, 7, 3, 6, 2, 5, 4, 0]
tensor([1, 7, 3, 6, 2, 5, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[1, 5, 6, 3, 7, 4, 2, 0]
tensor([1, 5, 6, 3, 7, 4, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[1, 5, 3, 6, 7, 4, 2, 0]
tensor([1, 5, 3, 6, 7, 4, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 7, 5, 6, 1, 2, 3, 0]
tensor([4, 7, 5, 6, 1, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 7, 1, 5, 6, 3, 2, 0]
tensor([4, 7, 1, 5, 6, 3, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1.0, 1, 1.0, 0, 1.0]
tensor([0, 1, 1, 1, 1, 1, 0, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
done!
Normal merging for layer 2
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 3 to 4
done!
Normal merging for layer 5
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
tensor([2])
tensor(2)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
done!
Normal merging for layer 6
tensor([7])
tensor(7)
tensor([4])
tensor(4)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
done!
Normal merging for layer 7
tensor([7])
tensor(7)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([1])
tensor(1)
done!
Cross-layer merge completed for layers 8 to 28
done!
Normal merging for layer 29
tensor([0, 6])
tensor(0)
tensor([1, 2, 3, 4, 5, 7])
tensor(1)
done!
Cross-layer merge completed for layers 30 to 31
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 32 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.3238 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 31 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

239
cuda:1
mastermind_35_easy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:56<00:56, 56.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:14<00:00, 33.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:14<00:00, 37.43s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_35_mcq_random HTTP/1.1" 200 772
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/flair/mastermind_35_mcq_random/flair/mastermind_35_mcq_random.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_35_mcq_random HTTP/1.1" 200 780
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/flair/mastermind_35_mcq_random/resolve/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_35_mcq_random/revision/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 780
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_35_mcq_random/tree/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1?recursive=False&expand=False HTTP/1.1" 200 290
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_35_mcq_random/tree/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1/data?recursive=False&expand=False HTTP/1.1" 200 359
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_35_mcq_random/revision/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 780
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/flair/mastermind_35_mcq_random/resolve/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:filelock:Attempting to acquire lock 140438522280032 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_35_mcq_random_default_0.0.0_15dd5105771e9c8d2d3ea71c8d44fffda374a7a1.lock
DEBUG:filelock:Lock 140438522280032 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_35_mcq_random_default_0.0.0_15dd5105771e9c8d2d3ea71c8d44fffda374a7a1.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1/dataset_info.json
DEBUG:filelock:Attempting to release lock 140438522280032 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_35_mcq_random_default_0.0.0_15dd5105771e9c8d2d3ea71c8d44fffda374a7a1.lock
DEBUG:filelock:Lock 140438522280032 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_35_mcq_random_default_0.0.0_15dd5105771e9c8d2d3ea71c8d44fffda374a7a1.lock
DEBUG:filelock:Attempting to acquire lock 140438522280032 on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1_builder.lock
DEBUG:filelock:Lock 140438522280032 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1/dataset_info.json
DEBUG:filelock:Attempting to release lock 140438522280032 on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1_builder.lock
DEBUG:filelock:Lock 140438522280032 released on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mastermind_35_easy from None to 0
INFO:lm_eval.api.task:Building contexts for mastermind_35_easy on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1517.90it/s]
DEBUG:lm_eval.evaluator:Task: mastermind_35_easy; number of requests on this rank: 400
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/400 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/400 [00:02<15:04,  2.27s/it]Running loglikelihood requests:   0%|          | 2/400 [00:03<11:16,  1.70s/it]Running loglikelihood requests:   1%|          | 3/400 [00:04<09:47,  1.48s/it]Running loglikelihood requests:   1%|          | 4/400 [00:05<09:03,  1.37s/it]Running loglikelihood requests:   1%|▏         | 5/400 [00:07<08:38,  1.31s/it]Running loglikelihood requests:   2%|▏         | 6/400 [00:08<08:31,  1.30s/it]Running loglikelihood requests:   2%|▏         | 7/400 [00:09<08:19,  1.27s/it]Running loglikelihood requests:   2%|▏         | 8/400 [00:10<08:09,  1.25s/it]Running loglikelihood requests:   2%|▏         | 9/400 [00:12<08:02,  1.23s/it]Running loglikelihood requests:   2%|▎         | 10/400 [00:13<07:56,  1.22s/it]Running loglikelihood requests:   3%|▎         | 11/400 [00:14<07:52,  1.21s/it]Running loglikelihood requests:   3%|▎         | 12/400 [00:15<07:48,  1.21s/it]Running loglikelihood requests:   3%|▎         | 13/400 [00:16<07:45,  1.20s/it]Running loglikelihood requests:   4%|▎         | 14/400 [00:18<07:43,  1.20s/it]Running loglikelihood requests:   4%|▍         | 15/400 [00:19<07:44,  1.21s/it]Running loglikelihood requests:   4%|▍         | 16/400 [00:20<07:41,  1.20s/it]Running loglikelihood requests:   4%|▍         | 17/400 [00:21<07:33,  1.18s/it]Running loglikelihood requests:   4%|▍         | 18/400 [00:22<07:28,  1.17s/it]Running loglikelihood requests:   5%|▍         | 19/400 [00:23<07:25,  1.17s/it]Running loglikelihood requests:   5%|▌         | 20/400 [00:25<07:21,  1.16s/it]Running loglikelihood requests:   5%|▌         | 21/400 [00:26<07:18,  1.16s/it]Running loglikelihood requests:   6%|▌         | 23/400 [00:27<05:34,  1.13it/s]Running loglikelihood requests:   6%|▌         | 24/400 [00:28<05:56,  1.05it/s]Running loglikelihood requests:   6%|▋         | 25/400 [00:29<06:14,  1.00it/s]Running loglikelihood requests:   6%|▋         | 26/400 [00:30<06:26,  1.03s/it]Running loglikelihood requests:   7%|▋         | 27/400 [00:31<06:35,  1.06s/it]Running loglikelihood requests:   7%|▋         | 28/400 [00:33<06:42,  1.08s/it]Running loglikelihood requests:   7%|▋         | 29/400 [00:34<06:46,  1.10s/it]Running loglikelihood requests:   8%|▊         | 30/400 [00:35<06:49,  1.11s/it]Running loglikelihood requests:   8%|▊         | 31/400 [00:36<06:50,  1.11s/it]Running loglikelihood requests:   8%|▊         | 32/400 [00:37<06:51,  1.12s/it]Running loglikelihood requests:   8%|▊         | 33/400 [00:38<06:51,  1.12s/it]Running loglikelihood requests:   8%|▊         | 34/400 [00:39<06:51,  1.12s/it]Running loglikelihood requests:   9%|▉         | 35/400 [00:40<06:51,  1.13s/it]Running loglikelihood requests:   9%|▉         | 36/400 [00:42<06:50,  1.13s/it]Running loglikelihood requests:   9%|▉         | 37/400 [00:43<06:49,  1.13s/it]Running loglikelihood requests:  10%|▉         | 38/400 [00:44<06:48,  1.13s/it]Running loglikelihood requests:  10%|▉         | 39/400 [00:45<06:49,  1.13s/it]Running loglikelihood requests:  10%|█         | 40/400 [00:46<06:47,  1.13s/it]Running loglikelihood requests:  10%|█         | 41/400 [00:47<06:46,  1.13s/it]Running loglikelihood requests:  10%|█         | 42/400 [00:48<06:44,  1.13s/it]Running loglikelihood requests:  11%|█         | 43/400 [00:49<06:43,  1.13s/it]Running loglikelihood requests:  11%|█         | 44/400 [00:51<06:42,  1.13s/it]Running loglikelihood requests:  11%|█▏        | 45/400 [00:52<06:40,  1.13s/it]Running loglikelihood requests:  12%|█▏        | 46/400 [00:53<06:39,  1.13s/it]Running loglikelihood requests:  12%|█▏        | 47/400 [00:54<06:38,  1.13s/it]Running loglikelihood requests:  12%|█▏        | 48/400 [00:55<06:36,  1.13s/it]Running loglikelihood requests:  12%|█▏        | 49/400 [00:56<06:35,  1.13s/it]Running loglikelihood requests:  12%|█▎        | 50/400 [00:57<06:34,  1.13s/it]Running loglikelihood requests:  13%|█▎        | 51/400 [00:59<06:33,  1.13s/it]Running loglikelihood requests:  13%|█▎        | 52/400 [01:00<06:32,  1.13s/it]Running loglikelihood requests:  13%|█▎        | 53/400 [01:01<06:31,  1.13s/it]Running loglikelihood requests:  14%|█▎        | 54/400 [01:02<06:30,  1.13s/it]Running loglikelihood requests:  14%|█▍        | 55/400 [01:03<06:28,  1.13s/it]Running loglikelihood requests:  14%|█▍        | 56/400 [01:04<06:27,  1.13s/it]Running loglikelihood requests:  14%|█▍        | 57/400 [01:05<06:39,  1.17s/it]Running loglikelihood requests:  14%|█▍        | 58/400 [01:07<06:46,  1.19s/it]Running loglikelihood requests:  15%|█▍        | 59/400 [01:08<06:51,  1.21s/it]Running loglikelihood requests:  15%|█▌        | 60/400 [01:09<06:53,  1.22s/it]Running loglikelihood requests:  15%|█▌        | 61/400 [01:10<06:55,  1.23s/it]Running loglikelihood requests:  16%|█▌        | 62/400 [01:12<06:46,  1.20s/it]Running loglikelihood requests:  16%|█▌        | 63/400 [01:13<06:37,  1.18s/it]Running loglikelihood requests:  16%|█▌        | 64/400 [01:14<06:30,  1.16s/it]Running loglikelihood requests:  16%|█▋        | 65/400 [01:15<06:25,  1.15s/it]Running loglikelihood requests:  16%|█▋        | 66/400 [01:16<06:21,  1.14s/it]Running loglikelihood requests:  17%|█▋        | 67/400 [01:17<06:17,  1.13s/it]Running loglikelihood requests:  17%|█▋        | 68/400 [01:18<06:14,  1.13s/it]Running loglikelihood requests:  17%|█▋        | 69/400 [01:19<06:12,  1.12s/it]Running loglikelihood requests:  18%|█▊        | 70/400 [01:20<06:10,  1.12s/it]Running loglikelihood requests:  18%|█▊        | 71/400 [01:22<06:08,  1.12s/it]Running loglikelihood requests:  18%|█▊        | 72/400 [01:23<06:06,  1.12s/it]Running loglikelihood requests:  18%|█▊        | 73/400 [01:24<06:19,  1.16s/it]Running loglikelihood requests:  18%|█▊        | 74/400 [01:25<06:15,  1.15s/it]Running loglikelihood requests:  19%|█▉        | 75/400 [01:26<06:12,  1.15s/it]Running loglikelihood requests:  19%|█▉        | 76/400 [01:27<06:09,  1.14s/it]Running loglikelihood requests:  19%|█▉        | 77/400 [01:28<06:06,  1.14s/it]Running loglikelihood requests:  20%|█▉        | 78/400 [01:30<06:04,  1.13s/it]Running loglikelihood requests:  20%|█▉        | 79/400 [01:31<06:02,  1.13s/it]Running loglikelihood requests:  20%|██        | 80/400 [01:32<06:01,  1.13s/it]Running loglikelihood requests:  20%|██        | 81/400 [01:33<05:59,  1.13s/it]Running loglikelihood requests:  20%|██        | 82/400 [01:34<05:58,  1.13s/it]Running loglikelihood requests:  21%|██        | 83/400 [01:35<05:57,  1.13s/it]Running loglikelihood requests:  21%|██        | 84/400 [01:36<05:57,  1.13s/it]Running loglikelihood requests:  21%|██▏       | 85/400 [01:37<05:55,  1.13s/it]Running loglikelihood requests:  22%|██▏       | 86/400 [01:39<05:56,  1.13s/it]Running loglikelihood requests:  22%|██▏       | 87/400 [01:40<05:54,  1.13s/it]Running loglikelihood requests:  22%|██▏       | 88/400 [01:41<05:52,  1.13s/it]Running loglikelihood requests:  22%|██▏       | 89/400 [01:42<05:51,  1.13s/it]Running loglikelihood requests:  22%|██▎       | 90/400 [01:43<05:49,  1.13s/it]Running loglikelihood requests:  23%|██▎       | 91/400 [01:44<05:48,  1.13s/it]Running loglikelihood requests:  23%|██▎       | 92/400 [01:45<05:48,  1.13s/it]Running loglikelihood requests:  23%|██▎       | 93/400 [01:47<05:54,  1.15s/it]Running loglikelihood requests:  24%|██▎       | 94/400 [01:48<05:51,  1.15s/it]Running loglikelihood requests:  24%|██▍       | 95/400 [01:49<05:47,  1.14s/it]Running loglikelihood requests:  24%|██▍       | 96/400 [01:50<05:45,  1.14s/it]Running loglikelihood requests:  24%|██▍       | 97/400 [01:51<05:42,  1.13s/it]Running loglikelihood requests:  24%|██▍       | 98/400 [01:52<05:40,  1.13s/it]Running loglikelihood requests:  25%|██▍       | 99/400 [01:53<05:39,  1.13s/it]Running loglikelihood requests:  25%|██▌       | 100/400 [01:55<05:39,  1.13s/it]Running loglikelihood requests:  25%|██▌       | 101/400 [01:56<05:38,  1.13s/it]Running loglikelihood requests:  26%|██▌       | 102/400 [01:57<05:36,  1.13s/it]Running loglikelihood requests:  26%|██▌       | 103/400 [01:58<05:34,  1.13s/it]Running loglikelihood requests:  26%|██▌       | 104/400 [01:59<05:33,  1.13s/it]Running loglikelihood requests:  26%|██▋       | 105/400 [02:00<05:31,  1.12s/it]Running loglikelihood requests:  26%|██▋       | 106/400 [02:01<05:29,  1.12s/it]Running loglikelihood requests:  27%|██▋       | 107/400 [02:02<05:34,  1.14s/it]Running loglikelihood requests:  27%|██▋       | 108/400 [02:04<05:41,  1.17s/it]Running loglikelihood requests:  27%|██▋       | 109/400 [02:05<05:45,  1.19s/it]Running loglikelihood requests:  28%|██▊       | 110/400 [02:06<05:41,  1.18s/it]Running loglikelihood requests:  28%|██▊       | 112/400 [02:07<04:17,  1.12it/s]Running loglikelihood requests:  28%|██▊       | 113/400 [02:08<04:31,  1.06it/s]Running loglikelihood requests:  28%|██▊       | 114/400 [02:09<04:42,  1.01it/s]Running loglikelihood requests:  29%|██▉       | 115/400 [02:10<04:50,  1.02s/it]Running loglikelihood requests:  29%|██▉       | 116/400 [02:12<04:55,  1.04s/it]Running loglikelihood requests:  29%|██▉       | 117/400 [02:13<05:05,  1.08s/it]Running loglikelihood requests:  30%|██▉       | 118/400 [02:14<05:06,  1.09s/it]Running loglikelihood requests:  30%|██▉       | 119/400 [02:15<05:05,  1.09s/it]Running loglikelihood requests:  30%|███       | 120/400 [02:16<05:05,  1.09s/it]Running loglikelihood requests:  30%|███       | 121/400 [02:17<05:05,  1.09s/it]Running loglikelihood requests:  30%|███       | 122/400 [02:18<05:04,  1.09s/it]Running loglikelihood requests:  31%|███       | 123/400 [02:19<05:03,  1.10s/it]Running loglikelihood requests:  31%|███       | 124/400 [02:20<05:02,  1.10s/it]Running loglikelihood requests:  31%|███▏      | 125/400 [02:22<05:01,  1.10s/it]Running loglikelihood requests:  32%|███▏      | 126/400 [02:23<05:00,  1.10s/it]Running loglikelihood requests:  32%|███▏      | 127/400 [02:24<04:59,  1.10s/it]Running loglikelihood requests:  32%|███▏      | 128/400 [02:25<04:58,  1.10s/it]Running loglikelihood requests:  32%|███▏      | 129/400 [02:26<04:57,  1.10s/it]Running loglikelihood requests:  32%|███▎      | 130/400 [02:27<04:55,  1.10s/it]Running loglikelihood requests:  33%|███▎      | 131/400 [02:28<04:54,  1.09s/it]Running loglikelihood requests:  33%|███▎      | 132/400 [02:29<04:53,  1.09s/it]Running loglikelihood requests:  33%|███▎      | 133/400 [02:30<04:52,  1.09s/it]Running loglikelihood requests:  34%|███▎      | 134/400 [02:31<04:50,  1.09s/it]Running loglikelihood requests:  34%|███▍      | 135/400 [02:32<04:49,  1.09s/it]Running loglikelihood requests:  34%|███▍      | 136/400 [02:34<04:48,  1.09s/it]Running loglikelihood requests:  34%|███▍      | 137/400 [02:35<04:46,  1.09s/it]Running loglikelihood requests:  34%|███▍      | 138/400 [02:36<04:45,  1.09s/it]Running loglikelihood requests:  35%|███▍      | 139/400 [02:37<04:44,  1.09s/it]Running loglikelihood requests:  35%|███▌      | 140/400 [02:38<04:43,  1.09s/it]Running loglikelihood requests:  35%|███▌      | 141/400 [02:39<04:42,  1.09s/it]Running loglikelihood requests:  36%|███▌      | 142/400 [02:40<04:44,  1.10s/it]Running loglikelihood requests:  36%|███▌      | 143/400 [02:41<04:43,  1.10s/it]Running loglikelihood requests:  36%|███▌      | 144/400 [02:42<04:42,  1.10s/it]Running loglikelihood requests:  36%|███▋      | 145/400 [02:43<04:40,  1.10s/it]Running loglikelihood requests:  36%|███▋      | 146/400 [02:45<04:39,  1.10s/it]Running loglikelihood requests:  37%|███▋      | 147/400 [02:46<04:38,  1.10s/it]Running loglikelihood requests:  37%|███▋      | 148/400 [02:47<04:37,  1.10s/it]Running loglikelihood requests:  37%|███▋      | 149/400 [02:48<04:35,  1.10s/it]Running loglikelihood requests:  38%|███▊      | 150/400 [02:49<04:34,  1.10s/it]Running loglikelihood requests:  38%|███▊      | 151/400 [02:50<04:33,  1.10s/it]Running loglikelihood requests:  38%|███▊      | 152/400 [02:51<04:32,  1.10s/it]Running loglikelihood requests:  38%|███▊      | 153/400 [02:52<04:31,  1.10s/it]Running loglikelihood requests:  38%|███▊      | 154/400 [02:53<04:37,  1.13s/it]Running loglikelihood requests:  39%|███▉      | 155/400 [02:55<04:39,  1.14s/it]Running loglikelihood requests:  39%|███▉      | 156/400 [02:56<04:34,  1.13s/it]Running loglikelihood requests:  39%|███▉      | 157/400 [02:57<04:31,  1.12s/it]Running loglikelihood requests:  40%|███▉      | 158/400 [02:58<04:29,  1.11s/it]Running loglikelihood requests:  40%|███▉      | 159/400 [02:59<04:27,  1.11s/it]Running loglikelihood requests:  40%|████      | 160/400 [03:00<04:24,  1.10s/it]Running loglikelihood requests:  40%|████      | 161/400 [03:01<04:22,  1.10s/it]Running loglikelihood requests:  40%|████      | 162/400 [03:02<04:21,  1.10s/it]Running loglikelihood requests:  41%|████      | 163/400 [03:03<04:20,  1.10s/it]Running loglikelihood requests:  41%|████      | 164/400 [03:04<04:18,  1.10s/it]Running loglikelihood requests:  41%|████▏     | 165/400 [03:06<04:17,  1.09s/it]Running loglikelihood requests:  42%|████▏     | 166/400 [03:07<04:16,  1.09s/it]Running loglikelihood requests:  42%|████▏     | 167/400 [03:08<04:14,  1.09s/it]Running loglikelihood requests:  42%|████▏     | 168/400 [03:09<04:13,  1.09s/it]Running loglikelihood requests:  42%|████▏     | 169/400 [03:10<04:12,  1.09s/it]Running loglikelihood requests:  42%|████▎     | 170/400 [03:11<04:10,  1.09s/it]Running loglikelihood requests:  43%|████▎     | 171/400 [03:12<04:09,  1.09s/it]Running loglikelihood requests:  43%|████▎     | 172/400 [03:13<04:08,  1.09s/it]Running loglikelihood requests:  43%|████▎     | 173/400 [03:14<04:07,  1.09s/it]Running loglikelihood requests:  44%|████▎     | 174/400 [03:15<04:06,  1.09s/it]Running loglikelihood requests:  44%|████▍     | 175/400 [03:16<04:05,  1.09s/it]Running loglikelihood requests:  44%|████▍     | 177/400 [03:18<03:06,  1.19it/s]Running loglikelihood requests:  44%|████▍     | 178/400 [03:19<03:19,  1.11it/s]Running loglikelihood requests:  45%|████▍     | 179/400 [03:20<03:29,  1.05it/s]Running loglikelihood requests:  45%|████▌     | 180/400 [03:21<03:36,  1.01it/s]Running loglikelihood requests:  45%|████▌     | 181/400 [03:22<03:42,  1.01s/it]Running loglikelihood requests:  46%|████▌     | 182/400 [03:23<03:45,  1.04s/it]Running loglikelihood requests:  46%|████▌     | 183/400 [03:24<03:48,  1.05s/it]Running loglikelihood requests:  46%|████▌     | 184/400 [03:25<03:49,  1.06s/it]Running loglikelihood requests:  46%|████▋     | 185/400 [03:26<03:49,  1.07s/it]Running loglikelihood requests:  46%|████▋     | 186/400 [03:27<03:50,  1.08s/it]Running loglikelihood requests:  47%|████▋     | 187/400 [03:28<03:49,  1.08s/it]Running loglikelihood requests:  47%|████▋     | 188/400 [03:30<03:49,  1.08s/it]Running loglikelihood requests:  47%|████▋     | 189/400 [03:31<03:48,  1.08s/it]Running loglikelihood requests:  48%|████▊     | 190/400 [03:32<03:47,  1.08s/it]Running loglikelihood requests:  48%|████▊     | 191/400 [03:33<03:46,  1.08s/it]Running loglikelihood requests:  48%|████▊     | 192/400 [03:34<03:45,  1.08s/it]Running loglikelihood requests:  48%|████▊     | 193/400 [03:35<03:44,  1.09s/it]Running loglikelihood requests:  48%|████▊     | 194/400 [03:36<03:43,  1.09s/it]Running loglikelihood requests:  49%|████▉     | 195/400 [03:37<03:42,  1.08s/it]Running loglikelihood requests:  49%|████▉     | 196/400 [03:38<03:41,  1.08s/it]Running loglikelihood requests:  49%|████▉     | 197/400 [03:39<03:40,  1.08s/it]Running loglikelihood requests:  50%|████▉     | 198/400 [03:40<03:38,  1.08s/it]Running loglikelihood requests:  50%|████▉     | 199/400 [03:41<03:38,  1.09s/it]Running loglikelihood requests:  50%|█████     | 200/400 [03:43<03:37,  1.09s/it]Running loglikelihood requests:  50%|█████     | 201/400 [03:44<03:35,  1.08s/it]Running loglikelihood requests:  50%|█████     | 202/400 [03:45<03:34,  1.08s/it]Running loglikelihood requests:  51%|█████     | 203/400 [03:46<03:33,  1.08s/it]Running loglikelihood requests:  51%|█████▏    | 205/400 [03:47<02:42,  1.20it/s]Running loglikelihood requests:  52%|█████▏    | 206/400 [03:48<02:53,  1.12it/s]Running loglikelihood requests:  52%|█████▏    | 207/400 [03:49<03:05,  1.04it/s]Running loglikelihood requests:  52%|█████▏    | 208/400 [03:50<03:11,  1.00it/s]Running loglikelihood requests:  52%|█████▏    | 209/400 [03:51<03:14,  1.02s/it]Running loglikelihood requests:  52%|█████▎    | 210/400 [03:52<03:16,  1.04s/it]Running loglikelihood requests:  53%|█████▎    | 211/400 [03:53<03:18,  1.05s/it]Running loglikelihood requests:  53%|█████▎    | 212/400 [03:55<03:19,  1.06s/it]Running loglikelihood requests:  53%|█████▎    | 213/400 [03:56<03:19,  1.07s/it]Running loglikelihood requests:  54%|█████▎    | 214/400 [03:57<03:18,  1.07s/it]Running loglikelihood requests:  54%|█████▍    | 215/400 [03:58<03:22,  1.09s/it]Running loglikelihood requests:  54%|█████▍    | 216/400 [03:59<03:21,  1.10s/it]Running loglikelihood requests:  54%|█████▍    | 217/400 [04:00<03:19,  1.09s/it]Running loglikelihood requests:  55%|█████▍    | 218/400 [04:01<03:17,  1.08s/it]Running loglikelihood requests:  55%|█████▍    | 219/400 [04:02<03:15,  1.08s/it]Running loglikelihood requests:  55%|█████▌    | 220/400 [04:03<03:13,  1.08s/it]Running loglikelihood requests:  55%|█████▌    | 221/400 [04:04<03:12,  1.08s/it]Running loglikelihood requests:  56%|█████▌    | 222/400 [04:05<03:10,  1.07s/it]Running loglikelihood requests:  56%|█████▌    | 223/400 [04:06<03:09,  1.07s/it]Running loglikelihood requests:  56%|█████▌    | 224/400 [04:07<03:08,  1.07s/it]Running loglikelihood requests:  56%|█████▋    | 225/400 [04:09<03:07,  1.07s/it]Running loglikelihood requests:  56%|█████▋    | 226/400 [04:10<03:06,  1.07s/it]Running loglikelihood requests:  57%|█████▋    | 227/400 [04:11<03:05,  1.07s/it]Running loglikelihood requests:  57%|█████▋    | 228/400 [04:12<03:03,  1.07s/it]Running loglikelihood requests:  57%|█████▋    | 229/400 [04:13<03:04,  1.08s/it]Running loglikelihood requests:  57%|█████▊    | 230/400 [04:14<03:02,  1.07s/it]Running loglikelihood requests:  58%|█████▊    | 231/400 [04:15<03:05,  1.10s/it]Running loglikelihood requests:  58%|█████▊    | 232/400 [04:16<03:03,  1.09s/it]Running loglikelihood requests:  58%|█████▊    | 233/400 [04:17<03:01,  1.09s/it]Running loglikelihood requests:  58%|█████▊    | 234/400 [04:18<02:59,  1.08s/it]Running loglikelihood requests:  59%|█████▉    | 235/400 [04:19<02:57,  1.08s/it]Running loglikelihood requests:  59%|█████▉    | 236/400 [04:20<02:56,  1.07s/it]Running loglikelihood requests:  59%|█████▉    | 237/400 [04:21<02:54,  1.07s/it]Running loglikelihood requests:  60%|█████▉    | 238/400 [04:23<02:53,  1.07s/it]Running loglikelihood requests:  60%|█████▉    | 239/400 [04:24<02:52,  1.07s/it]Running loglikelihood requests:  60%|██████    | 241/400 [04:25<02:10,  1.22it/s]Running loglikelihood requests:  60%|██████    | 242/400 [04:26<02:19,  1.13it/s]Running loglikelihood requests:  61%|██████    | 243/400 [04:27<02:26,  1.07it/s]Running loglikelihood requests:  61%|██████    | 244/400 [04:28<02:36,  1.00s/it]Running loglikelihood requests:  61%|██████▏   | 245/400 [04:29<02:44,  1.06s/it]Running loglikelihood requests:  62%|██████▏   | 246/400 [04:30<02:46,  1.08s/it]Running loglikelihood requests:  62%|██████▏   | 247/400 [04:31<02:44,  1.07s/it]Running loglikelihood requests:  62%|██████▏   | 248/400 [04:32<02:42,  1.07s/it]Running loglikelihood requests:  62%|██████▏   | 249/400 [04:34<02:40,  1.07s/it]Running loglikelihood requests:  62%|██████▎   | 250/400 [04:35<02:39,  1.06s/it]Running loglikelihood requests:  63%|██████▎   | 251/400 [04:36<02:38,  1.06s/it]Running loglikelihood requests:  63%|██████▎   | 252/400 [04:37<02:36,  1.06s/it]Running loglikelihood requests:  63%|██████▎   | 253/400 [04:38<02:35,  1.06s/it]Running loglikelihood requests:  64%|██████▍   | 255/400 [04:39<01:58,  1.23it/s]Running loglikelihood requests:  64%|██████▍   | 256/400 [04:40<02:06,  1.14it/s]Running loglikelihood requests:  64%|██████▍   | 257/400 [04:41<02:11,  1.08it/s]Running loglikelihood requests:  64%|██████▍   | 258/400 [04:42<02:16,  1.04it/s]Running loglikelihood requests:  65%|██████▍   | 259/400 [04:43<02:18,  1.02it/s]Running loglikelihood requests:  65%|██████▌   | 260/400 [04:44<02:20,  1.00s/it]Running loglikelihood requests:  65%|██████▌   | 261/400 [04:45<02:21,  1.02s/it]Running loglikelihood requests:  66%|██████▌   | 262/400 [04:46<02:22,  1.03s/it]Running loglikelihood requests:  66%|██████▌   | 263/400 [04:47<02:23,  1.04s/it]Running loglikelihood requests:  66%|██████▌   | 264/400 [04:48<02:22,  1.05s/it]Running loglikelihood requests:  66%|██████▋   | 265/400 [04:49<02:23,  1.06s/it]Running loglikelihood requests:  66%|██████▋   | 266/400 [04:51<02:22,  1.06s/it]Running loglikelihood requests:  67%|██████▋   | 267/400 [04:52<02:20,  1.06s/it]Running loglikelihood requests:  67%|██████▋   | 268/400 [04:53<02:19,  1.06s/it]Running loglikelihood requests:  68%|██████▊   | 270/400 [04:54<01:45,  1.23it/s]Running loglikelihood requests:  68%|██████▊   | 271/400 [04:55<01:51,  1.15it/s]Running loglikelihood requests:  68%|██████▊   | 272/400 [04:56<01:56,  1.09it/s]Running loglikelihood requests:  68%|██████▊   | 273/400 [04:57<02:00,  1.05it/s]Running loglikelihood requests:  68%|██████▊   | 274/400 [04:58<02:02,  1.03it/s]Running loglikelihood requests:  69%|██████▉   | 275/400 [04:59<02:06,  1.01s/it]Running loglikelihood requests:  69%|██████▉   | 276/400 [05:00<02:06,  1.02s/it]Running loglikelihood requests:  69%|██████▉   | 277/400 [05:01<02:07,  1.03s/it]Running loglikelihood requests:  70%|██████▉   | 278/400 [05:02<02:06,  1.04s/it]Running loglikelihood requests:  70%|██████▉   | 279/400 [05:03<02:06,  1.04s/it]Running loglikelihood requests:  70%|███████   | 280/400 [05:04<02:06,  1.05s/it]Running loglikelihood requests:  70%|███████   | 281/400 [05:05<02:05,  1.05s/it]Running loglikelihood requests:  70%|███████   | 282/400 [05:06<02:04,  1.05s/it]Running loglikelihood requests:  71%|███████   | 283/400 [05:07<02:03,  1.05s/it]Running loglikelihood requests:  71%|███████   | 284/400 [05:08<02:02,  1.05s/it]Running loglikelihood requests:  71%|███████▏  | 285/400 [05:09<02:01,  1.05s/it]Running loglikelihood requests:  72%|███████▏  | 286/400 [05:11<01:59,  1.05s/it]Running loglikelihood requests:  72%|███████▏  | 287/400 [05:12<01:59,  1.05s/it]Running loglikelihood requests:  72%|███████▏  | 288/400 [05:13<01:57,  1.05s/it]Running loglikelihood requests:  72%|███████▏  | 289/400 [05:14<01:56,  1.05s/it]Running loglikelihood requests:  72%|███████▎  | 290/400 [05:15<01:55,  1.05s/it]Running loglikelihood requests:  73%|███████▎  | 291/400 [05:16<01:54,  1.05s/it]Running loglikelihood requests:  73%|███████▎  | 292/400 [05:17<01:53,  1.05s/it]Running loglikelihood requests:  73%|███████▎  | 293/400 [05:18<01:52,  1.05s/it]Running loglikelihood requests:  74%|███████▎  | 294/400 [05:19<01:51,  1.05s/it]Running loglikelihood requests:  74%|███████▍  | 295/400 [05:20<01:50,  1.05s/it]Running loglikelihood requests:  74%|███████▍  | 296/400 [05:21<01:49,  1.05s/it]Running loglikelihood requests:  74%|███████▍  | 297/400 [05:22<01:48,  1.05s/it]Running loglikelihood requests:  74%|███████▍  | 298/400 [05:23<01:46,  1.05s/it]Running loglikelihood requests:  75%|███████▍  | 299/400 [05:24<01:45,  1.05s/it]Running loglikelihood requests:  75%|███████▌  | 300/400 [05:25<01:46,  1.06s/it]Running loglikelihood requests:  75%|███████▌  | 301/400 [05:26<01:44,  1.06s/it]Running loglikelihood requests:  76%|███████▌  | 302/400 [05:27<01:43,  1.05s/it]Running loglikelihood requests:  76%|███████▌  | 304/400 [05:28<01:18,  1.22it/s]Running loglikelihood requests:  76%|███████▋  | 305/400 [05:30<01:25,  1.11it/s]Running loglikelihood requests:  76%|███████▋  | 306/400 [05:31<01:30,  1.03it/s]Running loglikelihood requests:  77%|███████▋  | 307/400 [05:32<01:34,  1.02s/it]Running loglikelihood requests:  77%|███████▋  | 308/400 [05:33<01:35,  1.04s/it]Running loglikelihood requests:  77%|███████▋  | 309/400 [05:34<01:34,  1.04s/it]Running loglikelihood requests:  78%|███████▊  | 310/400 [05:35<01:33,  1.04s/it]Running loglikelihood requests:  78%|███████▊  | 311/400 [05:36<01:32,  1.04s/it]Running loglikelihood requests:  78%|███████▊  | 312/400 [05:37<01:30,  1.03s/it]Running loglikelihood requests:  78%|███████▊  | 313/400 [05:38<01:29,  1.03s/it]Running loglikelihood requests:  78%|███████▊  | 314/400 [05:39<01:28,  1.03s/it]Running loglikelihood requests:  79%|███████▉  | 315/400 [05:40<01:27,  1.03s/it]Running loglikelihood requests:  79%|███████▉  | 316/400 [05:41<01:26,  1.02s/it]Running loglikelihood requests:  79%|███████▉  | 317/400 [05:42<01:24,  1.02s/it]Running loglikelihood requests:  80%|███████▉  | 318/400 [05:43<01:23,  1.02s/it]Running loglikelihood requests:  80%|███████▉  | 319/400 [05:44<01:22,  1.02s/it]Running loglikelihood requests:  80%|████████  | 320/400 [05:45<01:21,  1.02s/it]Running loglikelihood requests:  80%|████████  | 321/400 [05:46<01:20,  1.02s/it]Running loglikelihood requests:  80%|████████  | 322/400 [05:47<01:19,  1.02s/it]Running loglikelihood requests:  81%|████████  | 323/400 [05:48<01:18,  1.02s/it]Running loglikelihood requests:  81%|████████  | 324/400 [05:49<01:17,  1.02s/it]Running loglikelihood requests:  81%|████████▏ | 325/400 [05:50<01:16,  1.03s/it]Running loglikelihood requests:  82%|████████▏ | 326/400 [05:51<01:15,  1.02s/it]Running loglikelihood requests:  82%|████████▏ | 327/400 [05:52<01:14,  1.02s/it]Running loglikelihood requests:  82%|████████▏ | 328/400 [05:53<01:13,  1.02s/it]Running loglikelihood requests:  82%|████████▎ | 330/400 [05:54<00:54,  1.28it/s]Running loglikelihood requests:  83%|████████▎ | 331/400 [05:55<00:57,  1.19it/s]Running loglikelihood requests:  83%|████████▎ | 332/400 [05:56<00:59,  1.13it/s]Running loglikelihood requests:  83%|████████▎ | 333/400 [05:58<01:01,  1.09it/s]Running loglikelihood requests:  84%|████████▎ | 334/400 [05:59<01:02,  1.06it/s]Running loglikelihood requests:  84%|████████▍ | 335/400 [06:00<01:02,  1.04it/s]Running loglikelihood requests:  84%|████████▍ | 336/400 [06:01<01:02,  1.03it/s]Running loglikelihood requests:  84%|████████▍ | 337/400 [06:02<01:01,  1.02it/s]Running loglikelihood requests:  84%|████████▍ | 338/400 [06:03<01:01,  1.01it/s]Running loglikelihood requests:  85%|████████▍ | 339/400 [06:04<01:00,  1.01it/s]Running loglikelihood requests:  85%|████████▌ | 340/400 [06:05<00:59,  1.00it/s]Running loglikelihood requests:  85%|████████▌ | 341/400 [06:06<00:58,  1.00it/s]Running loglikelihood requests:  86%|████████▌ | 342/400 [06:07<00:58,  1.00s/it]Running loglikelihood requests:  86%|████████▌ | 343/400 [06:08<00:57,  1.00s/it]Running loglikelihood requests:  86%|████████▌ | 344/400 [06:09<00:56,  1.00s/it]Running loglikelihood requests:  86%|████████▋ | 345/400 [06:10<00:55,  1.00s/it]Running loglikelihood requests:  86%|████████▋ | 346/400 [06:11<00:54,  1.00s/it]Running loglikelihood requests:  87%|████████▋ | 347/400 [06:12<00:53,  1.00s/it]Running loglikelihood requests:  87%|████████▋ | 348/400 [06:13<00:53,  1.03s/it]Running loglikelihood requests:  87%|████████▋ | 349/400 [06:14<00:51,  1.02s/it]Running loglikelihood requests:  88%|████████▊ | 350/400 [06:15<00:50,  1.01s/it]Running loglikelihood requests:  88%|████████▊ | 351/400 [06:16<00:49,  1.00s/it]Running loglikelihood requests:  88%|████████▊ | 352/400 [06:17<00:47,  1.00it/s]Running loglikelihood requests:  88%|████████▊ | 353/400 [06:18<00:46,  1.01it/s]Running loglikelihood requests:  88%|████████▊ | 354/400 [06:19<00:45,  1.01it/s]Running loglikelihood requests:  89%|████████▉ | 355/400 [06:20<00:44,  1.01it/s]Running loglikelihood requests:  89%|████████▉ | 356/400 [06:21<00:43,  1.00it/s]Running loglikelihood requests:  89%|████████▉ | 357/400 [06:22<00:42,  1.00it/s]Running loglikelihood requests:  90%|████████▉ | 358/400 [06:23<00:41,  1.00it/s]Running loglikelihood requests:  90%|████████▉ | 359/400 [06:24<00:40,  1.00it/s]Running loglikelihood requests:  90%|█████████ | 360/400 [06:25<00:39,  1.01it/s]Running loglikelihood requests:  90%|█████████ | 361/400 [06:26<00:38,  1.01it/s]Running loglikelihood requests:  90%|█████████ | 362/400 [06:27<00:37,  1.01it/s]Running loglikelihood requests:  91%|█████████ | 363/400 [06:27<00:36,  1.01it/s]Running loglikelihood requests:  91%|█████████ | 364/400 [06:28<00:35,  1.01it/s]Running loglikelihood requests:  91%|█████████▏| 365/400 [06:29<00:34,  1.01it/s]Running loglikelihood requests:  92%|█████████▏| 366/400 [06:30<00:33,  1.02it/s]Running loglikelihood requests:  92%|█████████▏| 367/400 [06:31<00:32,  1.02it/s]Running loglikelihood requests:  92%|█████████▏| 368/400 [06:32<00:31,  1.02it/s]Running loglikelihood requests:  92%|█████████▏| 369/400 [06:33<00:30,  1.02it/s]Running loglikelihood requests:  92%|█████████▎| 370/400 [06:34<00:29,  1.02it/s]Running loglikelihood requests:  93%|█████████▎| 371/400 [06:35<00:28,  1.02it/s]Running loglikelihood requests:  93%|█████████▎| 372/400 [06:36<00:27,  1.02it/s]Running loglikelihood requests:  93%|█████████▎| 373/400 [06:37<00:26,  1.02it/s]Running loglikelihood requests:  94%|█████████▎| 374/400 [06:38<00:26,  1.01s/it]Running loglikelihood requests:  94%|█████████▍| 375/400 [06:39<00:25,  1.01s/it]Running loglikelihood requests:  94%|█████████▍| 376/400 [06:40<00:23,  1.00it/s]Running loglikelihood requests:  94%|█████████▍| 377/400 [06:41<00:22,  1.01it/s]Running loglikelihood requests:  94%|█████████▍| 378/400 [06:42<00:22,  1.01s/it]Running loglikelihood requests:  95%|█████████▍| 379/400 [06:43<00:21,  1.00s/it]Running loglikelihood requests:  95%|█████████▌| 380/400 [06:44<00:19,  1.01it/s]Running loglikelihood requests:  95%|█████████▌| 381/400 [06:45<00:18,  1.03it/s]Running loglikelihood requests:  96%|█████████▌| 382/400 [06:46<00:17,  1.03it/s]Running loglikelihood requests:  96%|█████████▌| 383/400 [06:47<00:16,  1.04it/s]Running loglikelihood requests:  96%|█████████▌| 384/400 [06:48<00:15,  1.05it/s]Running loglikelihood requests:  96%|█████████▋| 385/400 [06:49<00:14,  1.05it/s]Running loglikelihood requests:  96%|█████████▋| 386/400 [06:50<00:13,  1.06it/s]Running loglikelihood requests:  97%|█████████▋| 387/400 [06:51<00:12,  1.06it/s]Running loglikelihood requests:  97%|█████████▋| 388/400 [06:52<00:11,  1.06it/s]Running loglikelihood requests:  97%|█████████▋| 389/400 [06:53<00:10,  1.06it/s]Running loglikelihood requests:  98%|█████████▊| 390/400 [06:54<00:09,  1.06it/s]Running loglikelihood requests:  98%|█████████▊| 391/400 [06:55<00:08,  1.06it/s]Running loglikelihood requests:  98%|█████████▊| 392/400 [06:56<00:07,  1.06it/s]Running loglikelihood requests:  98%|█████████▊| 393/400 [06:57<00:06,  1.06it/s]Running loglikelihood requests:  98%|█████████▊| 394/400 [06:58<00:05,  1.07it/s]Running loglikelihood requests:  99%|█████████▉| 395/400 [06:58<00:04,  1.07it/s]Running loglikelihood requests:  99%|█████████▉| 396/400 [06:59<00:03,  1.07it/s]Running loglikelihood requests:  99%|█████████▉| 397/400 [07:00<00:02,  1.08it/s]Running loglikelihood requests: 100%|█████████▉| 398/400 [07:01<00:01,  1.08it/s]Running loglikelihood requests: 100%|█████████▉| 399/400 [07:02<00:00,  1.09it/s]Running loglikelihood requests: 100%|██████████| 400/400 [07:03<00:00,  1.09it/s]Running loglikelihood requests: 100%|██████████| 400/400 [07:03<00:00,  1.06s/it]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:2'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:2'}
full model:
{'mastermind_35_easy': {'alias': 'mastermind_35_easy', 'acc,none': 0.51, 'acc_stderr,none': 0.05024183937956913}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9685093904417202
0.9837389482734848
0.9887891422859466
0.9728424941793791
0.9273096247071001
0.9956884174036557
0.9936991917224709
0.990637728847171
0.984416562505352
0.9357041463019401
0.957486187236088
0.9794440444506461
0.9854000882321717
0.989321120949945
0.9948124947717892
0.9950699411775289
0.9589145403056732
0.9488498047330014
0.979093344902028
0.9861615563222426
0.9944647439314634
0.9974738465425171
0.9932459641322177
0.9612113452387381
0.9566187588663586
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[5, 1, 0, 3, 7, 6, 2, 4]
tensor([5, 1, 0, 3, 7, 6, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 0, 3, 7, 5, 2, 4]
tensor([6, 1, 0, 3, 7, 5, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 1, 0, 3, 7, 6, 2, 4]
tensor([5, 1, 0, 3, 7, 6, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 0, 3, 7, 5, 2, 4]
tensor([6, 1, 0, 3, 7, 5, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 1, 0, 3, 7, 6, 2, 4]
tensor([5, 1, 0, 3, 7, 6, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 0, 3, 7, 5, 2, 4]
tensor([6, 1, 0, 3, 7, 5, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Normal merging for layer 2
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Normal merging for layer 3
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Normal merging for layer 4
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Normal merging for layer 5
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 6 to 31
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 31 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.0718 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 30 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

39
cuda:2
eq_bench
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:57<00:57, 57.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:14<00:00, 33.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:14<00:00, 37.12s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:eq_bench: No `until` specified in `generation_kwargs`! Defaulting to the fewshot_delimiter='\n\n'
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/pbevan11/EQ-Bench HTTP/1.1" 200 787
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/pbevan11/EQ-Bench/pbevan11/EQ-Bench.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/pbevan11/EQ-Bench HTTP/1.1" 200 796
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/pbevan11/EQ-Bench/resolve/9ce8e5ffc1a36be5f946b37610ec8c516871f0d3/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/pbevan11/EQ-Bench/revision/9ce8e5ffc1a36be5f946b37610ec8c516871f0d3 HTTP/1.1" 200 796
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/pbevan11/EQ-Bench/tree/9ce8e5ffc1a36be5f946b37610ec8c516871f0d3?recursive=False&expand=False HTTP/1.1" 200 301
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/pbevan11/EQ-Bench/tree/9ce8e5ffc1a36be5f946b37610ec8c516871f0d3/data?recursive=False&expand=False HTTP/1.1" 404 79
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/pbevan11/EQ-Bench/tree/9ce8e5ffc1a36be5f946b37610ec8c516871f0d3/data?recursive=False&expand=False HTTP/1.1" 404 79
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/pbevan11/EQ-Bench/revision/9ce8e5ffc1a36be5f946b37610ec8c516871f0d3 HTTP/1.1" 200 796
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/pbevan11/EQ-Bench/resolve/9ce8e5ffc1a36be5f946b37610ec8c516871f0d3/dataset_infos.json HTTP/1.1" 404 0
DEBUG:filelock:Attempting to acquire lock 140438522071088 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_pbevan11___eq-bench_default_0.0.0_9ce8e5ffc1a36be5f946b37610ec8c516871f0d3.lock
DEBUG:filelock:Lock 140438522071088 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_pbevan11___eq-bench_default_0.0.0_9ce8e5ffc1a36be5f946b37610ec8c516871f0d3.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/pbevan11___eq-bench/default/0.0.0/9ce8e5ffc1a36be5f946b37610ec8c516871f0d3/dataset_info.json
DEBUG:filelock:Attempting to release lock 140438522071088 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_pbevan11___eq-bench_default_0.0.0_9ce8e5ffc1a36be5f946b37610ec8c516871f0d3.lock
DEBUG:filelock:Lock 140438522071088 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_pbevan11___eq-bench_default_0.0.0_9ce8e5ffc1a36be5f946b37610ec8c516871f0d3.lock
DEBUG:filelock:Attempting to acquire lock 140430940472240 on /public/home/zouyifei001/.cache/huggingface/datasets/pbevan11___eq-bench/default/0.0.0/9ce8e5ffc1a36be5f946b37610ec8c516871f0d3_builder.lock
DEBUG:filelock:Lock 140430940472240 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/pbevan11___eq-bench/default/0.0.0/9ce8e5ffc1a36be5f946b37610ec8c516871f0d3_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/pbevan11___eq-bench/default/0.0.0/9ce8e5ffc1a36be5f946b37610ec8c516871f0d3/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430940472240 on /public/home/zouyifei001/.cache/huggingface/datasets/pbevan11___eq-bench/default/0.0.0/9ce8e5ffc1a36be5f946b37610ec8c516871f0d3_builder.lock
DEBUG:filelock:Lock 140430940472240 released on /public/home/zouyifei001/.cache/huggingface/datasets/pbevan11___eq-bench/default/0.0.0/9ce8e5ffc1a36be5f946b37610ec8c516871f0d3_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
INFO:lm_eval.evaluator:eq_bench: Using gen_kwargs: {'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 80, 'until': ['\n\n']}
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of eq_bench from None to 0
INFO:lm_eval.api.task:Building contexts for eq_bench on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 57401.18it/s]
DEBUG:lm_eval.evaluator:Task: eq_bench; number of requests on this rank: 100
INFO:lm_eval.evaluator:Running generate_until requests
Running generate_until requests:   0%|          | 0/100 [00:00<?, ?it/s]Running generate_until requests:   1%|          | 1/100 [00:08<14:12,  8.61s/it]Running generate_until requests:   2%|▏         | 2/100 [00:15<12:25,  7.61s/it]Running generate_until requests:   3%|▎         | 3/100 [00:22<11:36,  7.18s/it]Running generate_until requests:   4%|▍         | 4/100 [00:29<11:17,  7.06s/it]Running generate_until requests:   5%|▌         | 5/100 [00:35<11:01,  6.97s/it]Running generate_until requests:   6%|▌         | 6/100 [00:42<10:44,  6.86s/it]Running generate_until requests:   7%|▋         | 7/100 [00:48<10:21,  6.68s/it]Running generate_until requests:   8%|▊         | 8/100 [00:55<10:03,  6.56s/it]Running generate_until requests:   9%|▉         | 9/100 [01:02<10:10,  6.71s/it]Running generate_until requests:  10%|█         | 10/100 [01:08<09:51,  6.58s/it]Running generate_until requests:  11%|█         | 11/100 [01:14<09:39,  6.51s/it]Running generate_until requests:  12%|█▏        | 12/100 [01:22<09:55,  6.77s/it]Running generate_until requests:  13%|█▎        | 13/100 [01:28<09:45,  6.73s/it]Running generate_until requests:  14%|█▍        | 14/100 [01:35<09:32,  6.66s/it]Running generate_until requests:  15%|█▌        | 15/100 [01:41<09:24,  6.65s/it]Running generate_until requests:  16%|█▌        | 16/100 [01:48<09:07,  6.52s/it]Running generate_until requests:  17%|█▋        | 17/100 [01:54<08:54,  6.44s/it]Running generate_until requests:  18%|█▊        | 18/100 [02:00<08:38,  6.32s/it]Running generate_until requests:  19%|█▉        | 19/100 [02:07<08:44,  6.48s/it]Running generate_until requests:  20%|██        | 20/100 [02:13<08:33,  6.41s/it]Running generate_until requests:  21%|██        | 21/100 [02:19<08:24,  6.39s/it]Running generate_until requests:  22%|██▏       | 22/100 [02:26<08:16,  6.36s/it]Running generate_until requests:  23%|██▎       | 23/100 [02:32<08:07,  6.33s/it]Running generate_until requests:  24%|██▍       | 24/100 [02:38<08:00,  6.32s/it]Running generate_until requests:  25%|██▌       | 25/100 [02:45<08:03,  6.45s/it]Running generate_until requests:  26%|██▌       | 26/100 [02:51<07:47,  6.32s/it]Running generate_until requests:  27%|██▋       | 27/100 [02:57<07:33,  6.21s/it]Running generate_until requests:  28%|██▊       | 28/100 [03:03<07:29,  6.24s/it]Running generate_until requests:  29%|██▉       | 29/100 [03:09<07:22,  6.23s/it]Running generate_until requests:  30%|███       | 30/100 [03:16<07:14,  6.21s/it]Running generate_until requests:  31%|███       | 31/100 [03:22<07:02,  6.12s/it]Running generate_until requests:  32%|███▏      | 32/100 [03:28<07:07,  6.29s/it]Running generate_until requests:  33%|███▎      | 33/100 [03:34<06:54,  6.19s/it]Running generate_until requests:  34%|███▍      | 34/100 [03:40<06:44,  6.13s/it]Running generate_until requests:  35%|███▌      | 35/100 [03:46<06:35,  6.08s/it]Running generate_until requests:  36%|███▌      | 36/100 [03:52<06:21,  5.97s/it]Running generate_until requests:  37%|███▋      | 37/100 [03:58<06:18,  6.00s/it]Running generate_until requests:  38%|███▊      | 38/100 [04:04<06:06,  5.92s/it]Running generate_until requests:  39%|███▉      | 39/100 [04:10<06:01,  5.92s/it]Running generate_until requests:  40%|████      | 40/100 [04:16<05:58,  5.97s/it]Running generate_until requests:  41%|████      | 41/100 [04:23<06:10,  6.27s/it]Running generate_until requests:  42%|████▏     | 42/100 [04:29<06:09,  6.37s/it]Running generate_until requests:  43%|████▎     | 43/100 [04:35<05:53,  6.20s/it]Running generate_until requests:  44%|████▍     | 44/100 [04:41<05:38,  6.04s/it]Running generate_until requests:  45%|████▌     | 45/100 [04:46<05:25,  5.92s/it]Running generate_until requests:  46%|████▌     | 46/100 [04:53<05:28,  6.09s/it]Running generate_until requests:  47%|████▋     | 47/100 [04:59<05:27,  6.19s/it]Running generate_until requests:  48%|████▊     | 48/100 [05:05<05:14,  6.05s/it]Running generate_until requests:  49%|████▉     | 49/100 [05:11<05:04,  5.96s/it]Running generate_until requests:  50%|█████     | 50/100 [05:17<04:58,  5.97s/it]Running generate_until requests:  51%|█████     | 51/100 [05:22<04:47,  5.86s/it]Running generate_until requests:  52%|█████▏    | 52/100 [05:28<04:41,  5.87s/it]Running generate_until requests:  53%|█████▎    | 53/100 [05:34<04:33,  5.83s/it]Running generate_until requests:  54%|█████▍    | 54/100 [05:40<04:26,  5.80s/it]Running generate_until requests:  55%|█████▌    | 55/100 [05:45<04:14,  5.66s/it]Running generate_until requests:  56%|█████▌    | 56/100 [05:50<04:05,  5.59s/it]Running generate_until requests:  57%|█████▋    | 57/100 [05:56<04:03,  5.66s/it]Running generate_until requests:  58%|█████▊    | 58/100 [06:02<03:56,  5.63s/it]Running generate_until requests:  59%|█████▉    | 59/100 [06:07<03:50,  5.62s/it]Running generate_until requests:  60%|██████    | 60/100 [06:13<03:44,  5.62s/it]Running generate_until requests:  61%|██████    | 61/100 [06:19<03:41,  5.69s/it]Running generate_until requests:  62%|██████▏   | 62/100 [06:25<03:38,  5.76s/it]Running generate_until requests:  63%|██████▎   | 63/100 [06:30<03:28,  5.64s/it]Running generate_until requests:  64%|██████▍   | 64/100 [06:36<03:22,  5.62s/it]Running generate_until requests:  65%|██████▌   | 65/100 [06:41<03:17,  5.64s/it]Running generate_until requests:  66%|██████▌   | 66/100 [06:44<02:35,  4.58s/it]Running generate_until requests:  67%|██████▋   | 67/100 [06:49<02:39,  4.84s/it]Running generate_until requests:  68%|██████▊   | 68/100 [06:55<02:44,  5.14s/it]Running generate_until requests:  69%|██████▉   | 69/100 [07:00<02:43,  5.27s/it]Running generate_until requests:  70%|███████   | 70/100 [07:06<02:39,  5.30s/it]Running generate_until requests:  71%|███████   | 71/100 [07:08<02:05,  4.31s/it]Running generate_until requests:  72%|███████▏  | 72/100 [07:14<02:13,  4.79s/it]Running generate_until requests:  73%|███████▎  | 73/100 [07:16<01:47,  3.99s/it]Running generate_until requests:  74%|███████▍  | 74/100 [07:21<01:53,  4.37s/it]Running generate_until requests:  75%|███████▌  | 75/100 [07:26<01:54,  4.58s/it]Running generate_until requests:  76%|███████▌  | 76/100 [07:31<01:54,  4.76s/it]Running generate_until requests:  77%|███████▋  | 77/100 [07:37<01:53,  4.92s/it]Running generate_until requests:  78%|███████▊  | 78/100 [07:42<01:52,  5.10s/it]Running generate_until requests:  79%|███████▉  | 79/100 [07:48<01:51,  5.29s/it]Running generate_until requests:  80%|████████  | 80/100 [07:53<01:46,  5.33s/it]Running generate_until requests:  81%|████████  | 81/100 [07:58<01:40,  5.30s/it]Running generate_until requests:  82%|████████▏ | 82/100 [08:04<01:36,  5.38s/it]Running generate_until requests:  83%|████████▎ | 83/100 [08:09<01:30,  5.35s/it]Running generate_until requests:  84%|████████▍ | 84/100 [08:15<01:25,  5.32s/it]Running generate_until requests:  85%|████████▌ | 85/100 [08:20<01:20,  5.35s/it]Running generate_until requests:  86%|████████▌ | 86/100 [08:25<01:14,  5.31s/it]Running generate_until requests:  87%|████████▋ | 87/100 [08:27<00:55,  4.26s/it]Running generate_until requests:  88%|████████▊ | 88/100 [08:33<00:55,  4.64s/it]Running generate_until requests:  89%|████████▉ | 89/100 [08:38<00:55,  5.01s/it]Running generate_until requests:  90%|█████████ | 90/100 [08:44<00:52,  5.22s/it]Running generate_until requests:  91%|█████████ | 91/100 [08:49<00:47,  5.22s/it]Running generate_until requests:  92%|█████████▏| 92/100 [08:55<00:42,  5.25s/it]Running generate_until requests:  93%|█████████▎| 93/100 [09:00<00:36,  5.19s/it]Running generate_until requests:  94%|█████████▍| 94/100 [09:05<00:31,  5.21s/it]Running generate_until requests:  95%|█████████▌| 95/100 [09:10<00:25,  5.14s/it]Running generate_until requests:  96%|█████████▌| 96/100 [09:12<00:16,  4.15s/it]Running generate_until requests:  97%|█████████▋| 97/100 [09:14<00:10,  3.41s/it]Running generate_until requests:  98%|█████████▊| 98/100 [09:19<00:07,  3.89s/it]Running generate_until requests:  99%|█████████▉| 99/100 [09:24<00:04,  4.24s/it]Running generate_until requests: 100%|██████████| 100/100 [09:29<00:00,  4.53s/it]Running generate_until requests: 100%|██████████| 100/100 [09:29<00:00,  5.69s/it]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:3'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:3'}
full model:
{'eq_bench': {'alias': 'eq_bench', 'eqbench,none': -9.075457665929516, 'eqbench_stderr,none': 3.722206958756126, 'percent_parseable,none': 94.0, 'percent_parseable_stderr,none': 2.3868325657594203}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.6639018561214101
0.48429197946127234
0.9515491395508957
0.5799692129526803
0.8892832964569847
0.5583880670373075
0.6815933931575056
0.8296184325732159
0.8572432652494972
0.7515568516065031
0.7498285715344476
0.6640770908835784
0.7344737024966144
0.8863376660708159
0.7840365418395101
0.7895254515113318
0.915557892351788
0.8364869594903738
0.8262221986876632
0.8424210311799578
0.9059689119946415
0.938938460185247
0.9139805997979817
0.8791150946846779
0.9604433557463424
0.36429086085480555
0.6224935475213342
0.9367462541020114
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[2, 3, 7, 0, 6, 1, 5, 4]
tensor([2, 3, 7, 0, 6, 1, 5, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 5, 2, 1, 6, 0, 3, 7]
tensor([4, 5, 2, 1, 6, 0, 3, 7], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 3, 4, 0, 7, 1, 2, 6]
tensor([5, 3, 4, 0, 7, 1, 2, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 6, 4, 0, 3, 1, 2, 7]
tensor([5, 6, 4, 0, 3, 1, 2, 7], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 3, 0, 1, 2, 2, 3]
tensor([0, 1, 3, 0, 1, 2, 2, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[2, 3, 0, 0, 1, 1, 2, 3]
tensor([2, 3, 0, 0, 1, 1, 2, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[2, 0, 1, 0, 3, 1, 2, 3]
tensor([2, 0, 1, 0, 3, 1, 2, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[2, 0, 1, 0, 2, 1, 3, 3]
tensor([2, 0, 1, 0, 2, 1, 3, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 0, 1.0, 1, 1.0, 1.0]
tensor([0, 1, 1, 0, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 0, 1.0, 1, 1.0, 1.0]
tensor([0, 1, 1, 0, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[0, 1, 1.0, 0, 1.0, 1, 1.0, 1.0]
tensor([0, 1, 1, 0, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
Normal merging for layer 1
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
tensor([7])
tensor(7)
done!
Normal merging for layer 2
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([7])
tensor(7)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 3 to 4
done!
Normal merging for layer 5
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([1])
tensor(1)
tensor([7])
tensor(7)
done!
Cross-layer merge completed for layers 6 to 15
done!
Normal merging for layer 16
tensor([0, 3])
tensor(0)
tensor([1, 4])
tensor(1)
tensor([5, 6])
tensor(5)
tensor([2, 7])
tensor(2)
done!
Cross-layer merge completed for layers 17 to 18
done!
Normal merging for layer 19
tensor([2, 3])
tensor(2)
tensor([4, 5])
tensor(4)
tensor([0, 6])
tensor(0)
tensor([1, 7])
tensor(1)
done!
Normal merging for layer 20
tensor([1, 3])
tensor(1)
tensor([2, 5])
tensor(2)
tensor([0, 6])
tensor(0)
tensor([4, 7])
tensor(4)
done!
Normal merging for layer 21
tensor([1, 3])
tensor(1)
tensor([2, 5])
tensor(2)
tensor([0, 4])
tensor(0)
tensor([6, 7])
tensor(6)
done!
Cross-layer merge completed for layers 22 to 24
done!
Normal merging for layer 25
tensor([0, 3])
tensor(0)
tensor([1, 2, 4, 5, 6, 7])
tensor(1)
done!
Cross-layer merge completed for layers 26 to 29
done!
Normal merging for layer 30
tensor([0, 3])
tensor(0)
tensor([1, 2, 4, 5, 6, 7])
tensor(1)
done!
Normal merging for layer 31
tensor([0, 3])
tensor(0)
tensor([1, 2, 4, 5, 6, 7])
tensor(1)
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 30 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.7017 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 29 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

64
cuda:3
sciq
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:58<00:58, 58.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:14<00:00, 33.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:14<00:00, 37.14s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq HTTP/1.1" 200 1237
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/sciq/sciq.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq HTTP/1.1" 200 1237
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/allenai/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq/revision/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 111
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq/revision/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 1237
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq/tree/2c94ad3e1aafab77146f384e23536f97a4849815?recursive=False&expand=False HTTP/1.1" 307 136
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq/tree/2c94ad3e1aafab77146f384e23536f97a4849815?recursive=False&expand=False HTTP/1.1" 200 291
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq/tree/2c94ad3e1aafab77146f384e23536f97a4849815/data?recursive=False&expand=False HTTP/1.1" 307 141
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq/tree/2c94ad3e1aafab77146f384e23536f97a4849815/data?recursive=False&expand=False HTTP/1.1" 200 358
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq/revision/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 111
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq/revision/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 1237
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/allenai/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:filelock:Attempting to acquire lock 140430938719440 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:filelock:Lock 140430938719440 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430938719440 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:filelock:Lock 140430938719440 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:filelock:Attempting to acquire lock 140430938732448 on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:filelock:Lock 140430938732448 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430938732448 on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:filelock:Lock 140430938732448 released on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of sciq from None to 0
INFO:lm_eval.api.task:Building contexts for sciq on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1030.58it/s]
DEBUG:lm_eval.evaluator:Task: sciq; number of requests on this rank: 400
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/400 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/400 [00:04<28:50,  4.34s/it]Running loglikelihood requests:   0%|          | 2/400 [00:07<25:27,  3.84s/it]Running loglikelihood requests:   1%|          | 3/400 [00:11<24:30,  3.70s/it]Running loglikelihood requests:   1%|          | 4/400 [00:14<23:28,  3.56s/it]Running loglikelihood requests:   1%|▏         | 5/400 [00:17<22:26,  3.41s/it]Running loglikelihood requests:   2%|▏         | 6/400 [00:20<21:47,  3.32s/it]Running loglikelihood requests:   2%|▏         | 7/400 [00:24<22:23,  3.42s/it]Running loglikelihood requests:   2%|▏         | 8/400 [00:28<22:38,  3.47s/it]Running loglikelihood requests:   2%|▏         | 9/400 [00:31<21:19,  3.27s/it]Running loglikelihood requests:   2%|▎         | 10/400 [00:33<20:24,  3.14s/it]Running loglikelihood requests:   3%|▎         | 11/400 [00:36<19:44,  3.05s/it]Running loglikelihood requests:   3%|▎         | 12/400 [00:39<19:15,  2.98s/it]Running loglikelihood requests:   3%|▎         | 13/400 [00:42<18:28,  2.87s/it]Running loglikelihood requests:   4%|▎         | 14/400 [00:44<18:01,  2.80s/it]Running loglikelihood requests:   4%|▍         | 15/400 [00:47<18:12,  2.84s/it]Running loglikelihood requests:   4%|▍         | 16/400 [00:50<17:41,  2.76s/it]Running loglikelihood requests:   4%|▍         | 17/400 [00:52<17:09,  2.69s/it]Running loglikelihood requests:   4%|▍         | 18/400 [00:55<16:43,  2.63s/it]Running loglikelihood requests:   5%|▍         | 19/400 [00:57<16:22,  2.58s/it]Running loglikelihood requests:   5%|▌         | 20/400 [01:00<16:04,  2.54s/it]Running loglikelihood requests:   5%|▌         | 21/400 [01:02<15:49,  2.51s/it]Running loglikelihood requests:   6%|▌         | 22/400 [01:05<15:38,  2.48s/it]Running loglikelihood requests:   6%|▌         | 23/400 [01:07<15:29,  2.46s/it]Running loglikelihood requests:   6%|▌         | 24/400 [01:09<15:22,  2.45s/it]Running loglikelihood requests:   6%|▋         | 25/400 [01:12<15:01,  2.40s/it]Running loglikelihood requests:   6%|▋         | 26/400 [01:14<14:44,  2.36s/it]Running loglikelihood requests:   7%|▋         | 27/400 [01:16<14:33,  2.34s/it]Running loglikelihood requests:   7%|▋         | 28/400 [01:19<14:19,  2.31s/it]Running loglikelihood requests:   7%|▋         | 29/400 [01:21<13:47,  2.23s/it]Running loglikelihood requests:   8%|▊         | 30/400 [01:23<13:28,  2.19s/it]Running loglikelihood requests:   8%|▊         | 31/400 [01:25<13:10,  2.14s/it]Running loglikelihood requests:   8%|▊         | 32/400 [01:27<12:55,  2.11s/it]Running loglikelihood requests:   8%|▊         | 33/400 [01:29<12:32,  2.05s/it]Running loglikelihood requests:   8%|▊         | 34/400 [01:31<12:14,  2.01s/it]Running loglikelihood requests:   9%|▉         | 35/400 [01:32<12:01,  1.98s/it]Running loglikelihood requests:   9%|▉         | 36/400 [01:34<11:51,  1.96s/it]Running loglikelihood requests:   9%|▉         | 37/400 [01:36<11:44,  1.94s/it]Running loglikelihood requests:  10%|▉         | 38/400 [01:38<11:39,  1.93s/it]Running loglikelihood requests:  10%|█         | 40/400 [01:40<08:54,  1.48s/it]Running loglikelihood requests:  10%|█         | 41/400 [01:42<09:18,  1.56s/it]Running loglikelihood requests:  10%|█         | 42/400 [01:44<09:37,  1.61s/it]Running loglikelihood requests:  11%|█         | 43/400 [01:45<09:50,  1.66s/it]Running loglikelihood requests:  11%|█         | 44/400 [01:47<09:59,  1.68s/it]Running loglikelihood requests:  11%|█▏        | 45/400 [01:49<09:58,  1.69s/it]Running loglikelihood requests:  12%|█▏        | 46/400 [01:51<09:58,  1.69s/it]Running loglikelihood requests:  12%|█▏        | 47/400 [01:52<09:56,  1.69s/it]Running loglikelihood requests:  12%|█▏        | 48/400 [01:54<09:54,  1.69s/it]Running loglikelihood requests:  12%|█▏        | 49/400 [01:56<09:53,  1.69s/it]Running loglikelihood requests:  12%|█▎        | 50/400 [01:57<09:49,  1.68s/it]Running loglikelihood requests:  13%|█▎        | 51/400 [01:59<09:45,  1.68s/it]Running loglikelihood requests:  13%|█▎        | 52/400 [02:01<09:42,  1.67s/it]Running loglikelihood requests:  13%|█▎        | 53/400 [02:02<09:22,  1.62s/it]Running loglikelihood requests:  14%|█▎        | 54/400 [02:04<09:07,  1.58s/it]Running loglikelihood requests:  14%|█▍        | 55/400 [02:05<08:56,  1.55s/it]Running loglikelihood requests:  14%|█▍        | 57/400 [02:07<06:40,  1.17s/it]Running loglikelihood requests:  14%|█▍        | 58/400 [02:08<07:01,  1.23s/it]Running loglikelihood requests:  15%|█▍        | 59/400 [02:09<07:17,  1.28s/it]Running loglikelihood requests:  16%|█▌        | 62/400 [02:11<04:49,  1.17it/s]Running loglikelihood requests:  16%|█▌        | 63/400 [02:12<05:26,  1.03it/s]Running loglikelihood requests:  16%|█▌        | 64/400 [02:14<06:00,  1.07s/it]Running loglikelihood requests:  16%|█▋        | 65/400 [02:15<06:23,  1.15s/it]Running loglikelihood requests:  16%|█▋        | 66/400 [02:16<06:42,  1.20s/it]Running loglikelihood requests:  17%|█▋        | 67/400 [02:18<06:55,  1.25s/it]Running loglikelihood requests:  17%|█▋        | 68/400 [02:19<07:06,  1.28s/it]Running loglikelihood requests:  17%|█▋        | 69/400 [02:20<07:10,  1.30s/it]Running loglikelihood requests:  18%|█▊        | 70/400 [02:22<07:13,  1.32s/it]Running loglikelihood requests:  18%|█▊        | 71/400 [02:23<07:15,  1.32s/it]Running loglikelihood requests:  18%|█▊        | 72/400 [02:25<07:16,  1.33s/it]Running loglikelihood requests:  18%|█▊        | 73/400 [02:26<07:15,  1.33s/it]Running loglikelihood requests:  18%|█▊        | 74/400 [02:27<07:14,  1.33s/it]Running loglikelihood requests:  19%|█▉        | 77/400 [02:29<04:28,  1.20it/s]Running loglikelihood requests:  20%|█▉        | 78/400 [02:30<04:59,  1.08it/s]Running loglikelihood requests:  20%|█▉        | 79/400 [02:31<05:25,  1.01s/it]Running loglikelihood requests:  20%|██        | 81/400 [02:32<04:30,  1.18it/s]Running loglikelihood requests:  20%|██        | 82/400 [02:33<04:52,  1.09it/s]Running loglikelihood requests:  21%|██        | 83/400 [02:35<05:11,  1.02it/s]Running loglikelihood requests:  21%|██        | 84/400 [02:36<05:25,  1.03s/it]Running loglikelihood requests:  21%|██▏       | 85/400 [02:37<05:38,  1.07s/it]Running loglikelihood requests:  22%|██▏       | 86/400 [02:38<05:48,  1.11s/it]Running loglikelihood requests:  22%|██▏       | 89/400 [02:39<03:47,  1.37it/s]Running loglikelihood requests:  22%|██▎       | 90/400 [02:41<04:22,  1.18it/s]Running loglikelihood requests:  23%|██▎       | 91/400 [02:42<04:47,  1.07it/s]Running loglikelihood requests:  23%|██▎       | 92/400 [02:43<05:03,  1.02it/s]Running loglikelihood requests:  23%|██▎       | 93/400 [02:44<05:15,  1.03s/it]Running loglikelihood requests:  24%|██▍       | 97/400 [02:45<02:56,  1.71it/s]Running loglikelihood requests:  24%|██▍       | 98/400 [02:47<03:25,  1.47it/s]Running loglikelihood requests:  25%|██▍       | 99/400 [02:48<03:54,  1.29it/s]Running loglikelihood requests:  25%|██▌       | 100/400 [02:49<04:30,  1.11it/s]Running loglikelihood requests:  25%|██▌       | 101/400 [02:50<04:55,  1.01it/s]Running loglikelihood requests:  26%|██▌       | 102/400 [02:52<05:15,  1.06s/it]Running loglikelihood requests:  26%|██▌       | 103/400 [02:53<05:29,  1.11s/it]Running loglikelihood requests:  26%|██▌       | 104/400 [02:54<05:45,  1.17s/it]Running loglikelihood requests:  26%|██▋       | 105/400 [02:55<05:50,  1.19s/it]Running loglikelihood requests:  26%|██▋       | 106/400 [02:57<05:54,  1.20s/it]Running loglikelihood requests:  27%|██▋       | 107/400 [02:58<05:55,  1.21s/it]Running loglikelihood requests:  27%|██▋       | 108/400 [02:59<05:58,  1.23s/it]Running loglikelihood requests:  27%|██▋       | 109/400 [03:00<06:01,  1.24s/it]Running loglikelihood requests:  28%|██▊       | 110/400 [03:02<05:57,  1.23s/it]Running loglikelihood requests:  28%|██▊       | 111/400 [03:03<05:53,  1.22s/it]Running loglikelihood requests:  28%|██▊       | 112/400 [03:04<05:47,  1.21s/it]Running loglikelihood requests:  28%|██▊       | 113/400 [03:05<05:41,  1.19s/it]Running loglikelihood requests:  28%|██▊       | 114/400 [03:06<05:37,  1.18s/it]Running loglikelihood requests:  29%|██▉       | 115/400 [03:07<05:35,  1.18s/it]Running loglikelihood requests:  29%|██▉       | 116/400 [03:09<05:29,  1.16s/it]Running loglikelihood requests:  29%|██▉       | 117/400 [03:10<05:23,  1.14s/it]Running loglikelihood requests:  30%|██▉       | 118/400 [03:11<05:18,  1.13s/it]Running loglikelihood requests:  30%|██▉       | 119/400 [03:12<05:14,  1.12s/it]Running loglikelihood requests:  30%|███       | 120/400 [03:13<05:10,  1.11s/it]Running loglikelihood requests:  30%|███       | 121/400 [03:14<05:07,  1.10s/it]Running loglikelihood requests:  30%|███       | 122/400 [03:15<05:05,  1.10s/it]Running loglikelihood requests:  31%|███       | 123/400 [03:16<05:03,  1.10s/it]Running loglikelihood requests:  31%|███       | 124/400 [03:17<05:04,  1.10s/it]Running loglikelihood requests:  31%|███▏      | 125/400 [03:18<05:00,  1.09s/it]Running loglikelihood requests:  32%|███▏      | 126/400 [03:19<04:57,  1.09s/it]Running loglikelihood requests:  32%|███▏      | 127/400 [03:21<04:58,  1.09s/it]Running loglikelihood requests:  32%|███▏      | 128/400 [03:22<04:52,  1.07s/it]Running loglikelihood requests:  32%|███▏      | 129/400 [03:23<04:56,  1.10s/it]Running loglikelihood requests:  32%|███▎      | 130/400 [03:24<04:58,  1.11s/it]Running loglikelihood requests:  33%|███▎      | 131/400 [03:25<04:59,  1.11s/it]Running loglikelihood requests:  34%|███▎      | 134/400 [03:26<03:05,  1.44it/s]Running loglikelihood requests:  34%|███▍      | 135/400 [03:27<03:27,  1.27it/s]Running loglikelihood requests:  34%|███▍      | 136/400 [03:28<03:47,  1.16it/s]Running loglikelihood requests:  34%|███▍      | 137/400 [03:29<04:03,  1.08it/s]Running loglikelihood requests:  34%|███▍      | 138/400 [03:31<04:15,  1.03it/s]Running loglikelihood requests:  35%|███▍      | 139/400 [03:32<04:23,  1.01s/it]Running loglikelihood requests:  36%|███▌      | 142/400 [03:33<02:51,  1.51it/s]Running loglikelihood requests:  36%|███▌      | 143/400 [03:34<03:13,  1.33it/s]Running loglikelihood requests:  36%|███▌      | 144/400 [03:35<03:33,  1.20it/s]Running loglikelihood requests:  36%|███▋      | 145/400 [03:36<03:46,  1.13it/s]Running loglikelihood requests:  36%|███▋      | 146/400 [03:37<03:51,  1.10it/s]Running loglikelihood requests:  37%|███▋      | 147/400 [03:38<03:55,  1.08it/s]Running loglikelihood requests:  37%|███▋      | 148/400 [03:39<03:57,  1.06it/s]Running loglikelihood requests:  37%|███▋      | 149/400 [03:40<03:59,  1.05it/s]Running loglikelihood requests:  38%|███▊      | 150/400 [03:41<03:59,  1.04it/s]Running loglikelihood requests:  38%|███▊      | 151/400 [03:42<03:59,  1.04it/s]Running loglikelihood requests:  38%|███▊      | 152/400 [03:43<03:58,  1.04it/s]Running loglikelihood requests:  38%|███▊      | 153/400 [03:44<03:57,  1.04it/s]Running loglikelihood requests:  38%|███▊      | 154/400 [03:45<04:04,  1.00it/s]Running loglikelihood requests:  39%|███▉      | 155/400 [03:46<04:10,  1.02s/it]Running loglikelihood requests:  39%|███▉      | 156/400 [03:47<04:05,  1.01s/it]Running loglikelihood requests:  39%|███▉      | 157/400 [03:48<04:01,  1.01it/s]Running loglikelihood requests:  40%|███▉      | 158/400 [03:49<03:58,  1.02it/s]Running loglikelihood requests:  40%|███▉      | 159/400 [03:50<03:55,  1.02it/s]Running loglikelihood requests:  40%|████      | 160/400 [03:51<04:02,  1.01s/it]Running loglikelihood requests:  40%|████      | 161/400 [03:52<03:57,  1.01it/s]Running loglikelihood requests:  40%|████      | 162/400 [03:53<03:53,  1.02it/s]Running loglikelihood requests:  41%|████      | 163/400 [03:54<03:51,  1.03it/s]Running loglikelihood requests:  41%|████      | 164/400 [03:55<03:48,  1.03it/s]Running loglikelihood requests:  41%|████▏     | 165/400 [03:56<03:45,  1.04it/s]Running loglikelihood requests:  42%|████▏     | 166/400 [03:57<03:43,  1.05it/s]Running loglikelihood requests:  42%|████▏     | 167/400 [03:58<03:44,  1.04it/s]Running loglikelihood requests:  42%|████▏     | 168/400 [03:59<03:43,  1.04it/s]Running loglikelihood requests:  42%|████▏     | 169/400 [04:00<03:41,  1.04it/s]Running loglikelihood requests:  42%|████▎     | 170/400 [04:00<03:38,  1.05it/s]Running loglikelihood requests:  43%|████▎     | 172/400 [04:01<02:45,  1.38it/s]Running loglikelihood requests:  43%|████▎     | 173/400 [04:02<02:56,  1.29it/s]Running loglikelihood requests:  44%|████▎     | 174/400 [04:03<03:04,  1.23it/s]Running loglikelihood requests:  44%|████▍     | 177/400 [04:04<02:00,  1.84it/s]Running loglikelihood requests:  44%|████▍     | 178/400 [04:05<02:16,  1.63it/s]Running loglikelihood requests:  45%|████▍     | 179/400 [04:06<02:29,  1.48it/s]Running loglikelihood requests:  45%|████▌     | 180/400 [04:07<02:40,  1.37it/s]Running loglikelihood requests:  45%|████▌     | 181/400 [04:08<02:48,  1.30it/s]Running loglikelihood requests:  46%|████▌     | 182/400 [04:09<02:53,  1.26it/s]Running loglikelihood requests:  46%|████▌     | 183/400 [04:09<02:57,  1.22it/s]Running loglikelihood requests:  46%|████▌     | 184/400 [04:10<03:00,  1.20it/s]Running loglikelihood requests:  46%|████▋     | 185/400 [04:11<03:02,  1.18it/s]Running loglikelihood requests:  46%|████▋     | 186/400 [04:12<03:02,  1.17it/s]Running loglikelihood requests:  47%|████▋     | 187/400 [04:13<03:03,  1.16it/s]Running loglikelihood requests:  47%|████▋     | 188/400 [04:14<03:03,  1.16it/s]Running loglikelihood requests:  47%|████▋     | 189/400 [04:15<03:03,  1.15it/s]Running loglikelihood requests:  48%|████▊     | 190/400 [04:16<03:01,  1.16it/s]Running loglikelihood requests:  48%|████▊     | 191/400 [04:16<03:00,  1.16it/s]Running loglikelihood requests:  48%|████▊     | 192/400 [04:17<02:58,  1.17it/s]Running loglikelihood requests:  48%|████▊     | 193/400 [04:18<02:56,  1.17it/s]Running loglikelihood requests:  48%|████▊     | 194/400 [04:19<02:54,  1.18it/s]Running loglikelihood requests:  49%|████▉     | 195/400 [04:20<02:53,  1.18it/s]Running loglikelihood requests:  49%|████▉     | 196/400 [04:21<02:51,  1.19it/s]Running loglikelihood requests:  49%|████▉     | 197/400 [04:21<02:50,  1.19it/s]Running loglikelihood requests:  50%|████▉     | 198/400 [04:22<02:48,  1.20it/s]Running loglikelihood requests:  50%|████▉     | 199/400 [04:23<02:47,  1.20it/s]Running loglikelihood requests:  50%|█████     | 200/400 [04:24<02:45,  1.21it/s]Running loglikelihood requests:  50%|█████     | 201/400 [04:25<02:44,  1.21it/s]Running loglikelihood requests:  50%|█████     | 202/400 [04:26<02:43,  1.21it/s]Running loglikelihood requests:  51%|█████     | 203/400 [04:26<02:42,  1.21it/s]Running loglikelihood requests:  51%|█████     | 204/400 [04:27<02:41,  1.22it/s]Running loglikelihood requests:  51%|█████▏    | 205/400 [04:28<02:40,  1.22it/s]Running loglikelihood requests:  52%|█████▏    | 206/400 [04:29<02:39,  1.22it/s]Running loglikelihood requests:  52%|█████▏    | 207/400 [04:30<02:38,  1.22it/s]Running loglikelihood requests:  52%|█████▏    | 208/400 [04:31<02:37,  1.22it/s]Running loglikelihood requests:  52%|█████▏    | 209/400 [04:31<02:36,  1.22it/s]Running loglikelihood requests:  53%|█████▎    | 212/400 [04:32<01:37,  1.93it/s]Running loglikelihood requests:  53%|█████▎    | 213/400 [04:33<01:47,  1.74it/s]Running loglikelihood requests:  54%|█████▎    | 214/400 [04:34<01:56,  1.59it/s]Running loglikelihood requests:  54%|█████▍    | 215/400 [04:35<02:03,  1.49it/s]Running loglikelihood requests:  54%|█████▍    | 216/400 [04:35<02:09,  1.43it/s]Running loglikelihood requests:  54%|█████▍    | 217/400 [04:36<02:13,  1.38it/s]Running loglikelihood requests:  55%|█████▍    | 218/400 [04:37<02:15,  1.34it/s]Running loglikelihood requests:  55%|█████▍    | 219/400 [04:38<02:17,  1.31it/s]Running loglikelihood requests:  55%|█████▌    | 220/400 [04:39<02:18,  1.30it/s]Running loglikelihood requests:  55%|█████▌    | 221/400 [04:39<02:19,  1.29it/s]Running loglikelihood requests:  56%|█████▌    | 222/400 [04:40<02:18,  1.28it/s]Running loglikelihood requests:  56%|█████▌    | 223/400 [04:41<02:18,  1.28it/s]Running loglikelihood requests:  56%|█████▌    | 224/400 [04:42<02:17,  1.28it/s]Running loglikelihood requests:  56%|█████▋    | 225/400 [04:42<02:16,  1.28it/s]Running loglikelihood requests:  56%|█████▋    | 226/400 [04:43<02:15,  1.28it/s]Running loglikelihood requests:  57%|█████▋    | 227/400 [04:44<02:14,  1.28it/s]Running loglikelihood requests:  57%|█████▋    | 228/400 [04:45<02:14,  1.28it/s]Running loglikelihood requests:  57%|█████▋    | 229/400 [04:46<02:13,  1.28it/s]Running loglikelihood requests:  57%|█████▊    | 230/400 [04:46<02:12,  1.28it/s]Running loglikelihood requests:  58%|█████▊    | 231/400 [04:47<02:12,  1.28it/s]Running loglikelihood requests:  58%|█████▊    | 232/400 [04:48<02:11,  1.28it/s]Running loglikelihood requests:  58%|█████▊    | 233/400 [04:49<02:10,  1.28it/s]Running loglikelihood requests:  58%|█████▊    | 234/400 [04:49<02:09,  1.29it/s]Running loglikelihood requests:  59%|█████▉    | 235/400 [04:50<02:07,  1.29it/s]Running loglikelihood requests:  59%|█████▉    | 236/400 [04:51<02:06,  1.29it/s]Running loglikelihood requests:  59%|█████▉    | 237/400 [04:52<02:06,  1.29it/s]Running loglikelihood requests:  60%|██████    | 240/400 [04:53<01:17,  2.07it/s]Running loglikelihood requests:  60%|██████    | 241/400 [04:53<01:25,  1.85it/s]Running loglikelihood requests:  60%|██████    | 242/400 [04:54<01:33,  1.70it/s]Running loglikelihood requests:  61%|██████    | 243/400 [04:55<01:38,  1.59it/s]Running loglikelihood requests:  61%|██████    | 244/400 [04:56<01:43,  1.51it/s]Running loglikelihood requests:  61%|██████▏   | 245/400 [04:56<01:47,  1.45it/s]Running loglikelihood requests:  62%|██████▏   | 246/400 [04:57<01:48,  1.42it/s]Running loglikelihood requests:  62%|██████▏   | 247/400 [04:58<01:49,  1.40it/s]Running loglikelihood requests:  62%|██████▏   | 248/400 [04:59<01:49,  1.38it/s]Running loglikelihood requests:  62%|██████▏   | 249/400 [04:59<01:50,  1.37it/s]Running loglikelihood requests:  62%|██████▎   | 250/400 [05:00<01:49,  1.36it/s]Running loglikelihood requests:  63%|██████▎   | 251/400 [05:01<01:49,  1.36it/s]Running loglikelihood requests:  63%|██████▎   | 252/400 [05:02<01:49,  1.36it/s]Running loglikelihood requests:  63%|██████▎   | 253/400 [05:02<01:48,  1.36it/s]Running loglikelihood requests:  64%|██████▎   | 254/400 [05:03<01:47,  1.36it/s]Running loglikelihood requests:  64%|██████▍   | 255/400 [05:04<01:46,  1.36it/s]Running loglikelihood requests:  64%|██████▍   | 256/400 [05:04<01:45,  1.36it/s]Running loglikelihood requests:  64%|██████▍   | 257/400 [05:05<01:44,  1.36it/s]Running loglikelihood requests:  64%|██████▍   | 258/400 [05:06<01:44,  1.36it/s]Running loglikelihood requests:  65%|██████▍   | 259/400 [05:07<01:43,  1.37it/s]Running loglikelihood requests:  65%|██████▌   | 260/400 [05:07<01:42,  1.37it/s]Running loglikelihood requests:  65%|██████▌   | 261/400 [05:08<01:39,  1.40it/s]Running loglikelihood requests:  66%|██████▌   | 262/400 [05:09<01:37,  1.41it/s]Running loglikelihood requests:  66%|██████▌   | 263/400 [05:09<01:35,  1.43it/s]Running loglikelihood requests:  66%|██████▌   | 264/400 [05:10<01:34,  1.44it/s]Running loglikelihood requests:  66%|██████▋   | 265/400 [05:11<01:32,  1.46it/s]Running loglikelihood requests:  66%|██████▋   | 266/400 [05:11<01:30,  1.48it/s]Running loglikelihood requests:  67%|██████▋   | 267/400 [05:12<01:28,  1.50it/s]Running loglikelihood requests:  67%|██████▋   | 268/400 [05:13<01:26,  1.52it/s]Running loglikelihood requests:  67%|██████▋   | 269/400 [05:13<01:25,  1.54it/s]Running loglikelihood requests:  68%|██████▊   | 270/400 [05:14<01:23,  1.56it/s]Running loglikelihood requests:  68%|██████▊   | 271/400 [05:15<01:22,  1.57it/s]Running loglikelihood requests:  68%|██████▊   | 272/400 [05:15<01:20,  1.58it/s]Running loglikelihood requests:  68%|██████▊   | 273/400 [05:16<01:19,  1.61it/s]Running loglikelihood requests:  68%|██████▊   | 274/400 [05:16<01:17,  1.63it/s]Running loglikelihood requests:  69%|██████▉   | 275/400 [05:17<01:15,  1.65it/s]Running loglikelihood requests:  69%|██████▉   | 276/400 [05:18<01:14,  1.66it/s]Running loglikelihood requests:  69%|██████▉   | 277/400 [05:18<01:13,  1.68it/s]Running loglikelihood requests:  70%|██████▉   | 278/400 [05:19<01:12,  1.69it/s]Running loglikelihood requests:  70%|██████▉   | 279/400 [05:19<01:11,  1.70it/s]Running loglikelihood requests:  70%|███████   | 280/400 [05:20<01:10,  1.70it/s]Running loglikelihood requests:  70%|███████   | 281/400 [05:21<01:09,  1.71it/s]Running loglikelihood requests:  70%|███████   | 282/400 [05:21<01:08,  1.72it/s]Running loglikelihood requests:  71%|███████   | 283/400 [05:22<01:07,  1.73it/s]Running loglikelihood requests:  71%|███████   | 284/400 [05:22<01:07,  1.73it/s]Running loglikelihood requests:  71%|███████▏  | 285/400 [05:23<01:06,  1.73it/s]Running loglikelihood requests:  72%|███████▏  | 286/400 [05:23<01:05,  1.74it/s]Running loglikelihood requests:  72%|███████▏  | 287/400 [05:24<01:04,  1.75it/s]Running loglikelihood requests:  72%|███████▏  | 288/400 [05:25<01:04,  1.75it/s]Running loglikelihood requests:  72%|███████▏  | 289/400 [05:25<01:03,  1.75it/s]Running loglikelihood requests:  72%|███████▎  | 290/400 [05:26<01:02,  1.75it/s]Running loglikelihood requests:  73%|███████▎  | 291/400 [05:26<01:02,  1.75it/s]Running loglikelihood requests:  73%|███████▎  | 292/400 [05:27<01:01,  1.75it/s]Running loglikelihood requests:  73%|███████▎  | 293/400 [05:27<01:00,  1.76it/s]Running loglikelihood requests:  74%|███████▎  | 294/400 [05:28<01:00,  1.76it/s]Running loglikelihood requests:  74%|███████▍  | 295/400 [05:29<00:59,  1.75it/s]Running loglikelihood requests:  74%|███████▍  | 296/400 [05:29<00:59,  1.75it/s]Running loglikelihood requests:  74%|███████▍  | 297/400 [05:30<00:58,  1.75it/s]Running loglikelihood requests:  74%|███████▍  | 298/400 [05:30<00:57,  1.76it/s]Running loglikelihood requests:  75%|███████▍  | 299/400 [05:31<00:57,  1.77it/s]Running loglikelihood requests:  75%|███████▌  | 300/400 [05:31<00:56,  1.77it/s]Running loglikelihood requests:  75%|███████▌  | 301/400 [05:32<00:55,  1.77it/s]Running loglikelihood requests:  76%|███████▌  | 302/400 [05:32<00:55,  1.78it/s]Running loglikelihood requests:  76%|███████▌  | 303/400 [05:33<00:54,  1.78it/s]Running loglikelihood requests:  76%|███████▌  | 304/400 [05:34<00:53,  1.79it/s]Running loglikelihood requests:  76%|███████▋  | 305/400 [05:34<00:53,  1.79it/s]Running loglikelihood requests:  76%|███████▋  | 306/400 [05:35<00:52,  1.79it/s]Running loglikelihood requests:  77%|███████▋  | 307/400 [05:35<00:51,  1.80it/s]Running loglikelihood requests:  78%|███████▊  | 310/400 [05:36<00:31,  2.88it/s]Running loglikelihood requests:  78%|███████▊  | 311/400 [05:36<00:34,  2.56it/s]Running loglikelihood requests:  78%|███████▊  | 312/400 [05:37<00:37,  2.33it/s]Running loglikelihood requests:  78%|███████▊  | 313/400 [05:37<00:39,  2.18it/s]Running loglikelihood requests:  78%|███████▊  | 314/400 [05:38<00:41,  2.07it/s]Running loglikelihood requests:  79%|███████▉  | 315/400 [05:39<00:42,  1.99it/s]Running loglikelihood requests:  79%|███████▉  | 316/400 [05:39<00:43,  1.94it/s]Running loglikelihood requests:  79%|███████▉  | 317/400 [05:40<00:43,  1.91it/s]Running loglikelihood requests:  80%|███████▉  | 318/400 [05:40<00:43,  1.89it/s]Running loglikelihood requests:  80%|███████▉  | 319/400 [05:41<00:42,  1.89it/s]Running loglikelihood requests:  80%|████████  | 321/400 [05:41<00:32,  2.45it/s]Running loglikelihood requests:  80%|████████  | 322/400 [05:42<00:34,  2.29it/s]Running loglikelihood requests:  81%|████████  | 323/400 [05:42<00:35,  2.17it/s]Running loglikelihood requests:  81%|████████  | 324/400 [05:43<00:36,  2.09it/s]Running loglikelihood requests:  81%|████████▏ | 325/400 [05:43<00:37,  2.03it/s]Running loglikelihood requests:  82%|████████▏ | 326/400 [05:44<00:37,  1.99it/s]Running loglikelihood requests:  82%|████████▏ | 327/400 [05:44<00:36,  1.97it/s]Running loglikelihood requests:  82%|████████▏ | 328/400 [05:45<00:36,  1.96it/s]Running loglikelihood requests:  82%|████████▏ | 329/400 [05:45<00:36,  1.96it/s]Running loglikelihood requests:  82%|████████▎ | 330/400 [05:46<00:35,  1.95it/s]Running loglikelihood requests:  83%|████████▎ | 331/400 [05:46<00:35,  1.95it/s]Running loglikelihood requests:  83%|████████▎ | 332/400 [05:47<00:35,  1.94it/s]Running loglikelihood requests:  83%|████████▎ | 333/400 [05:47<00:34,  1.96it/s]Running loglikelihood requests:  84%|████████▎ | 334/400 [05:48<00:33,  1.97it/s]Running loglikelihood requests:  84%|████████▍ | 335/400 [05:48<00:32,  1.99it/s]Running loglikelihood requests:  84%|████████▍ | 336/400 [05:49<00:32,  1.99it/s]Running loglikelihood requests:  84%|████████▍ | 337/400 [05:49<00:31,  2.00it/s]Running loglikelihood requests:  84%|████████▍ | 338/400 [05:50<00:30,  2.00it/s]Running loglikelihood requests:  85%|████████▍ | 339/400 [05:50<00:30,  2.01it/s]Running loglikelihood requests:  85%|████████▌ | 340/400 [05:51<00:29,  2.01it/s]Running loglikelihood requests:  85%|████████▌ | 341/400 [05:51<00:29,  2.01it/s]Running loglikelihood requests:  86%|████████▌ | 342/400 [05:52<00:28,  2.02it/s]Running loglikelihood requests:  86%|████████▌ | 343/400 [05:52<00:28,  2.02it/s]Running loglikelihood requests:  86%|████████▌ | 344/400 [05:53<00:27,  2.02it/s]Running loglikelihood requests:  86%|████████▋ | 345/400 [05:53<00:27,  2.03it/s]Running loglikelihood requests:  86%|████████▋ | 346/400 [05:54<00:26,  2.03it/s]Running loglikelihood requests:  87%|████████▋ | 347/400 [05:54<00:25,  2.04it/s]Running loglikelihood requests:  87%|████████▋ | 348/400 [05:55<00:25,  2.04it/s]Running loglikelihood requests:  87%|████████▋ | 349/400 [05:55<00:24,  2.04it/s]Running loglikelihood requests:  88%|████████▊ | 350/400 [05:56<00:24,  2.04it/s]Running loglikelihood requests:  88%|████████▊ | 351/400 [05:56<00:24,  2.04it/s]Running loglikelihood requests:  88%|████████▊ | 352/400 [05:57<00:23,  2.04it/s]Running loglikelihood requests:  88%|████████▊ | 353/400 [05:57<00:22,  2.05it/s]Running loglikelihood requests:  88%|████████▊ | 354/400 [05:58<00:22,  2.05it/s]Running loglikelihood requests:  89%|████████▉ | 355/400 [05:58<00:21,  2.06it/s]Running loglikelihood requests:  89%|████████▉ | 356/400 [05:59<00:21,  2.07it/s]Running loglikelihood requests:  89%|████████▉ | 357/400 [05:59<00:20,  2.07it/s]Running loglikelihood requests:  90%|████████▉ | 358/400 [06:00<00:20,  2.07it/s]Running loglikelihood requests:  90%|████████▉ | 359/400 [06:00<00:19,  2.08it/s]Running loglikelihood requests:  90%|█████████ | 360/400 [06:01<00:19,  2.08it/s]Running loglikelihood requests:  90%|█████████ | 361/400 [06:01<00:18,  2.08it/s]Running loglikelihood requests:  90%|█████████ | 362/400 [06:02<00:18,  2.08it/s]Running loglikelihood requests:  91%|█████████ | 363/400 [06:02<00:17,  2.09it/s]Running loglikelihood requests:  91%|█████████ | 364/400 [06:03<00:17,  2.10it/s]Running loglikelihood requests:  91%|█████████▏| 365/400 [06:03<00:16,  2.10it/s]Running loglikelihood requests:  92%|█████████▏| 366/400 [06:04<00:16,  2.10it/s]Running loglikelihood requests:  92%|█████████▏| 368/400 [06:04<00:11,  2.73it/s]Running loglikelihood requests:  92%|█████████▏| 369/400 [06:05<00:12,  2.53it/s]Running loglikelihood requests:  92%|█████████▎| 370/400 [06:05<00:12,  2.40it/s]Running loglikelihood requests:  93%|█████████▎| 371/400 [06:05<00:12,  2.32it/s]Running loglikelihood requests:  93%|█████████▎| 373/400 [06:06<00:09,  2.89it/s]Running loglikelihood requests:  94%|█████████▎| 374/400 [06:06<00:09,  2.65it/s]Running loglikelihood requests:  94%|█████████▍| 375/400 [06:07<00:10,  2.50it/s]Running loglikelihood requests:  94%|█████████▍| 376/400 [06:07<00:10,  2.39it/s]Running loglikelihood requests:  94%|█████████▍| 377/400 [06:08<00:09,  2.32it/s]Running loglikelihood requests:  94%|█████████▍| 378/400 [06:08<00:09,  2.28it/s]Running loglikelihood requests:  95%|█████████▍| 379/400 [06:09<00:09,  2.26it/s]Running loglikelihood requests:  95%|█████████▌| 380/400 [06:09<00:08,  2.24it/s]Running loglikelihood requests:  95%|█████████▌| 381/400 [06:10<00:08,  2.22it/s]Running loglikelihood requests:  96%|█████████▌| 382/400 [06:10<00:08,  2.22it/s]Running loglikelihood requests:  96%|█████████▌| 383/400 [06:11<00:07,  2.22it/s]Running loglikelihood requests:  96%|█████████▌| 384/400 [06:11<00:07,  2.22it/s]Running loglikelihood requests:  96%|█████████▋| 385/400 [06:11<00:06,  2.22it/s]Running loglikelihood requests:  96%|█████████▋| 386/400 [06:12<00:06,  2.23it/s]Running loglikelihood requests:  97%|█████████▋| 387/400 [06:12<00:05,  2.23it/s]Running loglikelihood requests:  97%|█████████▋| 388/400 [06:13<00:05,  2.24it/s]Running loglikelihood requests:  97%|█████████▋| 389/400 [06:13<00:04,  2.24it/s]Running loglikelihood requests:  98%|█████████▊| 390/400 [06:14<00:04,  2.25it/s]Running loglikelihood requests:  98%|█████████▊| 391/400 [06:14<00:04,  2.25it/s]Running loglikelihood requests:  98%|█████████▊| 392/400 [06:15<00:03,  2.26it/s]Running loglikelihood requests:  98%|█████████▊| 393/400 [06:15<00:03,  2.26it/s]Running loglikelihood requests:  98%|█████████▊| 394/400 [06:15<00:02,  2.27it/s]Running loglikelihood requests:  99%|█████████▉| 395/400 [06:16<00:02,  2.27it/s]Running loglikelihood requests:  99%|█████████▉| 396/400 [06:16<00:01,  2.27it/s]Running loglikelihood requests:  99%|█████████▉| 397/400 [06:17<00:01,  2.28it/s]Running loglikelihood requests: 100%|█████████▉| 398/400 [06:17<00:00,  2.29it/s]Running loglikelihood requests: 100%|█████████▉| 399/400 [06:18<00:00,  2.29it/s]Running loglikelihood requests: 100%|██████████| 400/400 [06:18<00:00,  2.30it/s]Running loglikelihood requests: 100%|██████████| 400/400 [06:18<00:00,  1.06it/s]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:4'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:4'}
full model:
{'sciq': {'alias': 'sciq', 'acc,none': 0.94, 'acc_stderr,none': 0.023868325657594204, 'acc_norm,none': 0.91, 'acc_norm_stderr,none': 0.028762349126466136}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.969062788859705
0.9024924890572922
0.7706109127217512
0.8221264026535647
0.9190490061886575
0.9866654579796295
0.6586322754204971
0.7962110384246164
0.8195614021629236
0.7124178311176441
0.787697814339696
0.7034455022322618
0.8136386046534271
0.8174990104652458
0.6784276389594894
0.8698440245672888
0.8886492811850213
0.6541737276411673
0.6560861559753316
0.8139845219953913
0.6714741870309046
0.6164364868717988
0.8331581872497299
0.9065420049234512
0.9246185715568276
0.7477515960551026
0.574165362968651
0.8586446364199891
0.8889771415746612
Total groups 70 exceeded the threshold, stopping comparison.
The group tensor is
[7, 3, 4, 2, 6, 1, 5, 0]
tensor([7, 3, 4, 2, 6, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 2, 5, 3, 4, 0, 7, 1]
tensor([6, 2, 5, 3, 4, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 3, 6, 2, 7, 1, 4, 0]
tensor([5, 3, 6, 2, 7, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 4, 2, 1, 3, 5, 1]
tensor([0, 0, 4, 2, 1, 3, 5, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 2, 3, 4, 5, 0, 1, 1]
tensor([0, 2, 3, 4, 5, 0, 1, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 1, 0, 2, 2, 3, 1]
tensor([0, 3, 1, 0, 2, 2, 3, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 3, 1, 1, 2, 2, 3, 0]
tensor([0, 3, 1, 1, 2, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 1, 1.0, 1.0, 1.0, 1.0, 1]
tensor([0, 0, 1, 1, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 2 to 4
done!
Normal merging for layer 5
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 6 to 9
done!
Normal merging for layer 10
tensor([0, 1])
tensor(0)
tensor([4, 7])
tensor(4)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 11 to 12
done!
Normal merging for layer 13
tensor([0, 5])
tensor(0)
tensor([6, 7])
tensor(6)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 14 to 19
done!
Normal merging for layer 20
tensor([0, 3])
tensor(0)
tensor([2, 7])
tensor(2)
tensor([4, 5])
tensor(4)
tensor([1, 6])
tensor(1)
done!
Normal merging for layer 21
tensor([0, 7])
tensor(0)
tensor([2, 3])
tensor(2)
tensor([4, 5])
tensor(4)
tensor([1, 6])
tensor(1)
done!
Cross-layer merge completed for layers 22 to 23
done!
Normal merging for layer 24
tensor([0, 1])
tensor(0)
tensor([2, 3, 4, 5, 6, 7])
tensor(2)
done!
Cross-layer merge completed for layers 25 to 31
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 29 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.2608 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 28 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

159
cuda:4
mnli
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:54<00:54, 54.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:10<00:00, 31.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:10<00:00, 35.15s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: mnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: mnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/revision/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 111
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/revision/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c?recursive=False&expand=False HTTP/1.1" 307 136
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c?recursive=False&expand=False HTTP/1.1" 200 530
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/ax?recursive=False&expand=False HTTP/1.1" 307 139
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/ax?recursive=False&expand=False HTTP/1.1" 200 231
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/revision/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 111
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/revision/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/mnli?recursive=False&expand=False HTTP/1.1" 307 141
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/mnli?recursive=False&expand=False HTTP/1.1" 200 512
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140437582880000 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_mnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140437582880000 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_mnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/mnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140437582880000 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_mnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140437582880000 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_mnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140438521831040 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/mnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140438521831040 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/mnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/mnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140438521831040 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/mnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140438521831040 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/mnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mnli from None to 0
INFO:lm_eval.api.task:Building contexts for mnli on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 116443.75it/s]
DEBUG:lm_eval.evaluator:Task: mnli; number of requests on this rank: 300
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/300 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/300 [00:02<10:53,  2.19s/it]Running loglikelihood requests:   1%|          | 2/300 [00:03<08:01,  1.62s/it]Running loglikelihood requests:   1%|▏         | 4/300 [00:04<04:24,  1.12it/s]Running loglikelihood requests:   2%|▏         | 5/300 [00:05<04:27,  1.10it/s]Running loglikelihood requests:   2%|▏         | 7/300 [00:06<03:22,  1.45it/s]Running loglikelihood requests:   3%|▎         | 8/300 [00:07<03:35,  1.36it/s]Running loglikelihood requests:   3%|▎         | 10/300 [00:07<02:53,  1.67it/s]Running loglikelihood requests:   4%|▎         | 11/300 [00:08<03:07,  1.54it/s]Running loglikelihood requests:   4%|▍         | 13/300 [00:09<02:37,  1.82it/s]Running loglikelihood requests:   5%|▍         | 14/300 [00:10<02:52,  1.66it/s]Running loglikelihood requests:   5%|▌         | 16/300 [00:10<02:25,  1.95it/s]Running loglikelihood requests:   6%|▌         | 17/300 [00:11<02:39,  1.77it/s]Running loglikelihood requests:   6%|▌         | 18/300 [00:12<02:50,  1.65it/s]Running loglikelihood requests:   7%|▋         | 20/300 [00:13<02:22,  1.96it/s]Running loglikelihood requests:   7%|▋         | 21/300 [00:13<02:36,  1.79it/s]Running loglikelihood requests:   8%|▊         | 23/300 [00:14<02:14,  2.06it/s]Running loglikelihood requests:   8%|▊         | 25/300 [00:15<02:01,  2.27it/s]Running loglikelihood requests:   9%|▊         | 26/300 [00:16<02:16,  2.01it/s]Running loglikelihood requests:   9%|▉         | 28/300 [00:16<02:01,  2.24it/s]Running loglikelihood requests:  10%|▉         | 29/300 [00:17<02:15,  2.00it/s]Running loglikelihood requests:  10%|█         | 30/300 [00:18<02:28,  1.82it/s]Running loglikelihood requests:  10%|█         | 31/300 [00:18<02:38,  1.70it/s]Running loglikelihood requests:  11%|█         | 32/300 [00:19<02:46,  1.61it/s]Running loglikelihood requests:  11%|█▏        | 34/300 [00:20<02:14,  1.98it/s]Running loglikelihood requests:  12%|█▏        | 36/300 [00:21<01:58,  2.22it/s]Running loglikelihood requests:  13%|█▎        | 38/300 [00:21<01:49,  2.40it/s]Running loglikelihood requests:  13%|█▎        | 40/300 [00:22<01:41,  2.55it/s]Running loglikelihood requests:  14%|█▎        | 41/300 [00:23<01:56,  2.23it/s]Running loglikelihood requests:  14%|█▍        | 42/300 [00:23<02:08,  2.00it/s]Running loglikelihood requests:  14%|█▍        | 43/300 [00:24<02:18,  1.85it/s]Running loglikelihood requests:  15%|█▌        | 45/300 [00:25<01:57,  2.17it/s]Running loglikelihood requests:  16%|█▌        | 47/300 [00:25<01:45,  2.40it/s]Running loglikelihood requests:  16%|█▌        | 48/300 [00:26<01:58,  2.12it/s]Running loglikelihood requests:  17%|█▋        | 50/300 [00:27<01:45,  2.38it/s]Running loglikelihood requests:  17%|█▋        | 52/300 [00:27<01:36,  2.56it/s]Running loglikelihood requests:  18%|█▊        | 53/300 [00:28<01:49,  2.25it/s]Running loglikelihood requests:  18%|█▊        | 54/300 [00:29<02:01,  2.03it/s]Running loglikelihood requests:  18%|█▊        | 55/300 [00:29<02:10,  1.87it/s]Running loglikelihood requests:  19%|█▉        | 57/300 [00:30<01:49,  2.21it/s]Running loglikelihood requests:  20%|█▉        | 59/300 [00:31<01:38,  2.46it/s]Running loglikelihood requests:  20%|██        | 61/300 [00:31<01:30,  2.63it/s]Running loglikelihood requests:  21%|██        | 62/300 [00:32<01:43,  2.29it/s]Running loglikelihood requests:  21%|██▏       | 64/300 [00:33<01:33,  2.52it/s]Running loglikelihood requests:  22%|██▏       | 65/300 [00:33<01:45,  2.23it/s]Running loglikelihood requests:  22%|██▏       | 66/300 [00:34<01:55,  2.02it/s]Running loglikelihood requests:  22%|██▏       | 67/300 [00:35<02:03,  1.88it/s]Running loglikelihood requests:  23%|██▎       | 69/300 [00:35<01:42,  2.25it/s]Running loglikelihood requests:  24%|██▎       | 71/300 [00:36<01:31,  2.51it/s]Running loglikelihood requests:  24%|██▍       | 72/300 [00:37<01:42,  2.22it/s]Running loglikelihood requests:  24%|██▍       | 73/300 [00:37<01:52,  2.03it/s]Running loglikelihood requests:  25%|██▌       | 75/300 [00:38<01:35,  2.36it/s]Running loglikelihood requests:  26%|██▌       | 77/300 [00:38<01:26,  2.59it/s]Running loglikelihood requests:  26%|██▋       | 79/300 [00:39<01:20,  2.75it/s]Running loglikelihood requests:  27%|██▋       | 80/300 [00:40<01:31,  2.41it/s]Running loglikelihood requests:  27%|██▋       | 81/300 [00:40<01:41,  2.16it/s]Running loglikelihood requests:  27%|██▋       | 82/300 [00:41<01:49,  1.98it/s]Running loglikelihood requests:  28%|██▊       | 83/300 [00:42<01:56,  1.87it/s]Running loglikelihood requests:  28%|██▊       | 85/300 [00:42<01:35,  2.26it/s]Running loglikelihood requests:  29%|██▊       | 86/300 [00:43<01:43,  2.06it/s]Running loglikelihood requests:  29%|██▉       | 88/300 [00:44<01:30,  2.35it/s]Running loglikelihood requests:  30%|██▉       | 89/300 [00:44<01:40,  2.10it/s]Running loglikelihood requests:  30%|███       | 91/300 [00:45<01:27,  2.39it/s]Running loglikelihood requests:  31%|███       | 93/300 [00:46<01:19,  2.60it/s]Running loglikelihood requests:  32%|███▏      | 95/300 [00:46<01:14,  2.77it/s]Running loglikelihood requests:  32%|███▏      | 96/300 [00:47<01:24,  2.42it/s]Running loglikelihood requests:  33%|███▎      | 98/300 [00:47<01:16,  2.65it/s]Running loglikelihood requests:  33%|███▎      | 99/300 [00:48<01:25,  2.34it/s]Running loglikelihood requests:  34%|███▎      | 101/300 [00:49<01:16,  2.60it/s]Running loglikelihood requests:  34%|███▍      | 102/300 [00:49<01:26,  2.30it/s]Running loglikelihood requests:  34%|███▍      | 103/300 [00:50<01:34,  2.09it/s]Running loglikelihood requests:  35%|███▍      | 104/300 [00:51<01:43,  1.89it/s]Running loglikelihood requests:  35%|███▌      | 105/300 [00:51<01:47,  1.81it/s]Running loglikelihood requests:  36%|███▌      | 107/300 [00:52<01:26,  2.23it/s]Running loglikelihood requests:  36%|███▌      | 108/300 [00:52<01:33,  2.05it/s]Running loglikelihood requests:  36%|███▋      | 109/300 [00:53<01:39,  1.93it/s]Running loglikelihood requests:  37%|███▋      | 111/300 [00:54<01:21,  2.32it/s]Running loglikelihood requests:  38%|███▊      | 113/300 [00:54<01:12,  2.59it/s]Running loglikelihood requests:  38%|███▊      | 115/300 [00:55<01:06,  2.79it/s]Running loglikelihood requests:  39%|███▉      | 117/300 [00:56<01:02,  2.93it/s]Running loglikelihood requests:  40%|███▉      | 119/300 [00:56<00:59,  3.03it/s]Running loglikelihood requests:  40%|████      | 121/300 [00:57<00:57,  3.10it/s]Running loglikelihood requests:  41%|████      | 122/300 [00:57<01:06,  2.67it/s]Running loglikelihood requests:  41%|████▏     | 124/300 [00:58<01:01,  2.86it/s]Running loglikelihood requests:  42%|████▏     | 125/300 [00:59<01:09,  2.51it/s]Running loglikelihood requests:  42%|████▏     | 126/300 [00:59<01:17,  2.25it/s]Running loglikelihood requests:  42%|████▏     | 127/300 [01:00<01:23,  2.08it/s]Running loglikelihood requests:  43%|████▎     | 129/300 [01:00<01:09,  2.46it/s]Running loglikelihood requests:  44%|████▎     | 131/300 [01:01<01:02,  2.72it/s]Running loglikelihood requests:  44%|████▍     | 133/300 [01:02<00:57,  2.93it/s]Running loglikelihood requests:  45%|████▍     | 134/300 [01:02<01:04,  2.57it/s]Running loglikelihood requests:  45%|████▌     | 135/300 [01:03<01:11,  2.32it/s]Running loglikelihood requests:  45%|████▌     | 136/300 [01:03<01:16,  2.14it/s]Running loglikelihood requests:  46%|████▌     | 137/300 [01:04<01:21,  2.01it/s]Running loglikelihood requests:  46%|████▌     | 138/300 [01:04<01:24,  1.93it/s]Running loglikelihood requests:  47%|████▋     | 140/300 [01:05<01:07,  2.38it/s]Running loglikelihood requests:  47%|████▋     | 142/300 [01:06<00:58,  2.71it/s]Running loglikelihood requests:  48%|████▊     | 143/300 [01:06<01:05,  2.41it/s]Running loglikelihood requests:  48%|████▊     | 145/300 [01:07<00:56,  2.73it/s]Running loglikelihood requests:  49%|████▊     | 146/300 [01:07<01:03,  2.43it/s]Running loglikelihood requests:  49%|████▉     | 147/300 [01:08<01:08,  2.22it/s]Running loglikelihood requests:  49%|████▉     | 148/300 [01:09<01:14,  2.04it/s]Running loglikelihood requests:  50%|█████     | 150/300 [01:09<01:02,  2.42it/s]Running loglikelihood requests:  51%|█████     | 152/300 [01:10<00:54,  2.73it/s]Running loglikelihood requests:  51%|█████▏    | 154/300 [01:10<00:49,  2.95it/s]Running loglikelihood requests:  52%|█████▏    | 155/300 [01:11<00:56,  2.59it/s]Running loglikelihood requests:  52%|█████▏    | 157/300 [01:11<00:50,  2.85it/s]Running loglikelihood requests:  53%|█████▎    | 159/300 [01:12<00:46,  3.04it/s]Running loglikelihood requests:  54%|█████▎    | 161/300 [01:13<00:43,  3.18it/s]Running loglikelihood requests:  54%|█████▍    | 162/300 [01:13<00:50,  2.75it/s]Running loglikelihood requests:  55%|█████▍    | 164/300 [01:14<00:45,  2.98it/s]Running loglikelihood requests:  55%|█████▌    | 165/300 [01:14<00:51,  2.62it/s]Running loglikelihood requests:  56%|█████▌    | 167/300 [01:15<00:46,  2.89it/s]Running loglikelihood requests:  56%|█████▋    | 169/300 [01:15<00:42,  3.08it/s]Running loglikelihood requests:  57%|█████▋    | 170/300 [01:16<00:48,  2.69it/s]Running loglikelihood requests:  57%|█████▋    | 171/300 [01:17<00:53,  2.42it/s]Running loglikelihood requests:  57%|█████▋    | 172/300 [01:17<00:57,  2.23it/s]Running loglikelihood requests:  58%|█████▊    | 173/300 [01:18<01:00,  2.09it/s]Running loglikelihood requests:  58%|█████▊    | 175/300 [01:18<00:49,  2.53it/s]Running loglikelihood requests:  59%|█████▉    | 177/300 [01:19<00:43,  2.85it/s]Running loglikelihood requests:  60%|█████▉    | 179/300 [01:19<00:39,  3.07it/s]Running loglikelihood requests:  60%|██████    | 180/300 [01:20<00:44,  2.69it/s]Running loglikelihood requests:  60%|██████    | 181/300 [01:20<00:49,  2.42it/s]Running loglikelihood requests:  61%|██████    | 183/300 [01:21<00:42,  2.77it/s]Running loglikelihood requests:  62%|██████▏   | 185/300 [01:22<00:37,  3.03it/s]Running loglikelihood requests:  62%|██████▏   | 186/300 [01:22<00:42,  2.66it/s]Running loglikelihood requests:  63%|██████▎   | 188/300 [01:23<00:37,  2.96it/s]Running loglikelihood requests:  63%|██████▎   | 190/300 [01:23<00:34,  3.16it/s]Running loglikelihood requests:  64%|██████▎   | 191/300 [01:24<00:39,  2.76it/s]Running loglikelihood requests:  64%|██████▍   | 192/300 [01:24<00:43,  2.49it/s]Running loglikelihood requests:  65%|██████▍   | 194/300 [01:25<00:37,  2.85it/s]Running loglikelihood requests:  65%|██████▌   | 195/300 [01:25<00:41,  2.55it/s]Running loglikelihood requests:  65%|██████▌   | 196/300 [01:26<00:44,  2.33it/s]Running loglikelihood requests:  66%|██████▌   | 198/300 [01:26<00:37,  2.74it/s]Running loglikelihood requests:  66%|██████▋   | 199/300 [01:27<00:40,  2.48it/s]Running loglikelihood requests:  67%|██████▋   | 200/300 [01:28<00:43,  2.29it/s]Running loglikelihood requests:  67%|██████▋   | 201/300 [01:28<00:45,  2.16it/s]Running loglikelihood requests:  68%|██████▊   | 203/300 [01:29<00:37,  2.62it/s]Running loglikelihood requests:  68%|██████▊   | 205/300 [01:29<00:32,  2.95it/s]Running loglikelihood requests:  69%|██████▊   | 206/300 [01:30<00:35,  2.63it/s]Running loglikelihood requests:  69%|██████▉   | 208/300 [01:30<00:31,  2.96it/s]Running loglikelihood requests:  70%|███████   | 210/300 [01:31<00:28,  3.19it/s]Running loglikelihood requests:  71%|███████   | 212/300 [01:31<00:26,  3.36it/s]Running loglikelihood requests:  71%|███████   | 213/300 [01:32<00:29,  2.93it/s]Running loglikelihood requests:  72%|███████▏  | 215/300 [01:32<00:26,  3.18it/s]Running loglikelihood requests:  72%|███████▏  | 216/300 [01:33<00:30,  2.79it/s]Running loglikelihood requests:  72%|███████▏  | 217/300 [01:33<00:32,  2.52it/s]Running loglikelihood requests:  73%|███████▎  | 219/300 [01:34<00:27,  2.90it/s]Running loglikelihood requests:  74%|███████▎  | 221/300 [01:35<00:24,  3.18it/s]Running loglikelihood requests:  74%|███████▍  | 222/300 [01:35<00:27,  2.79it/s]Running loglikelihood requests:  75%|███████▍  | 224/300 [01:36<00:24,  3.10it/s]Running loglikelihood requests:  75%|███████▌  | 225/300 [01:36<00:27,  2.75it/s]Running loglikelihood requests:  76%|███████▌  | 227/300 [01:37<00:23,  3.07it/s]Running loglikelihood requests:  76%|███████▌  | 228/300 [01:37<00:26,  2.73it/s]Running loglikelihood requests:  76%|███████▋  | 229/300 [01:38<00:28,  2.49it/s]Running loglikelihood requests:  77%|███████▋  | 231/300 [01:38<00:23,  2.90it/s]Running loglikelihood requests:  77%|███████▋  | 232/300 [01:39<00:25,  2.62it/s]Running loglikelihood requests:  78%|███████▊  | 233/300 [01:39<00:27,  2.41it/s]Running loglikelihood requests:  78%|███████▊  | 234/300 [01:40<00:29,  2.28it/s]Running loglikelihood requests:  78%|███████▊  | 235/300 [01:40<00:30,  2.17it/s]Running loglikelihood requests:  79%|███████▊  | 236/300 [01:41<00:30,  2.10it/s]Running loglikelihood requests:  79%|███████▉  | 237/300 [01:41<00:30,  2.05it/s]Running loglikelihood requests:  79%|███████▉  | 238/300 [01:42<00:30,  2.02it/s]Running loglikelihood requests:  80%|████████  | 240/300 [01:42<00:23,  2.58it/s]Running loglikelihood requests:  81%|████████  | 242/300 [01:43<00:19,  2.98it/s]Running loglikelihood requests:  81%|████████▏ | 244/300 [01:43<00:17,  3.26it/s]Running loglikelihood requests:  82%|████████▏ | 246/300 [01:44<00:15,  3.45it/s]Running loglikelihood requests:  83%|████████▎ | 248/300 [01:44<00:14,  3.59it/s]Running loglikelihood requests:  83%|████████▎ | 250/300 [01:45<00:13,  3.69it/s]Running loglikelihood requests:  84%|████████▍ | 252/300 [01:45<00:12,  3.75it/s]Running loglikelihood requests:  85%|████████▍ | 254/300 [01:46<00:12,  3.81it/s]Running loglikelihood requests:  85%|████████▌ | 256/300 [01:46<00:11,  3.85it/s]Running loglikelihood requests:  86%|████████▌ | 257/300 [01:47<00:13,  3.30it/s]Running loglikelihood requests:  86%|████████▌ | 258/300 [01:47<00:14,  2.91it/s]Running loglikelihood requests:  87%|████████▋ | 260/300 [01:48<00:12,  3.24it/s]Running loglikelihood requests:  87%|████████▋ | 261/300 [01:48<00:13,  2.87it/s]Running loglikelihood requests:  88%|████████▊ | 263/300 [01:49<00:11,  3.15it/s]Running loglikelihood requests:  88%|████████▊ | 264/300 [01:49<00:12,  2.79it/s]Running loglikelihood requests:  88%|████████▊ | 265/300 [01:50<00:13,  2.54it/s]Running loglikelihood requests:  89%|████████▊ | 266/300 [01:50<00:14,  2.36it/s]Running loglikelihood requests:  89%|████████▉ | 268/300 [01:51<00:11,  2.86it/s]Running loglikelihood requests:  90%|█████████ | 270/300 [01:51<00:09,  3.22it/s]Running loglikelihood requests:  91%|█████████ | 272/300 [01:52<00:08,  3.42it/s]Running loglikelihood requests:  91%|█████████▏| 274/300 [01:52<00:07,  3.58it/s]Running loglikelihood requests:  92%|█████████▏| 275/300 [01:53<00:07,  3.16it/s]Running loglikelihood requests:  92%|█████████▏| 277/300 [01:53<00:06,  3.48it/s]Running loglikelihood requests:  93%|█████████▎| 278/300 [01:54<00:07,  3.07it/s]Running loglikelihood requests:  93%|█████████▎| 279/300 [01:54<00:07,  2.80it/s]Running loglikelihood requests:  94%|█████████▎| 281/300 [01:55<00:05,  3.23it/s]Running loglikelihood requests:  94%|█████████▍| 282/300 [01:55<00:06,  2.90it/s]Running loglikelihood requests:  94%|█████████▍| 283/300 [01:56<00:06,  2.68it/s]Running loglikelihood requests:  95%|█████████▍| 284/300 [01:56<00:06,  2.51it/s]Running loglikelihood requests:  95%|█████████▌| 286/300 [01:57<00:04,  3.04it/s]Running loglikelihood requests:  96%|█████████▌| 288/300 [01:57<00:03,  3.42it/s]Running loglikelihood requests:  97%|█████████▋| 290/300 [01:58<00:02,  3.70it/s]Running loglikelihood requests:  97%|█████████▋| 292/300 [01:58<00:02,  3.82it/s]Running loglikelihood requests:  98%|█████████▊| 293/300 [01:59<00:02,  3.31it/s]Running loglikelihood requests:  98%|█████████▊| 294/300 [01:59<00:02,  2.94it/s]Running loglikelihood requests:  99%|█████████▊| 296/300 [01:59<00:01,  3.37it/s]Running loglikelihood requests:  99%|█████████▉| 298/300 [02:00<00:00,  3.72it/s]Running loglikelihood requests: 100%|█████████▉| 299/300 [02:00<00:00,  3.31it/s]Running loglikelihood requests: 100%|██████████| 300/300 [02:00<00:00,  2.48it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:5'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:5'}
full model:
{'mnli': {'alias': 'mnli', 'acc,none': 0.4, 'acc_stderr,none': 0.0492365963917331}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8171409999433525
0.8739893758684915
0.8333413990263023
0.8782828649633461
0.7602933913725962
0.7047335470608914
0.9813668198386444
0.7850949920891616
0.748983595161589
0.6557873189175887
0.7043210867322975
0.9420132312730142
0.9548348739467002
0.8459964595909506
0.6932219150662173
0.8804855383939617
0.868566987197908
0.8437399449827557
0.9153450822718411
0.8433082326287293
0.910397090611448
0.7626694638419581
0.752151649412453
0.8346986395359313
0.9530736745854924
0.8635918585764104
0.8647192950921815
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[4, 5, 6, 1, 7, 2, 3, 0]
tensor([4, 5, 6, 1, 7, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 4, 6, 2, 5, 1, 3, 0]
tensor([7, 4, 6, 2, 5, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 2, 7, 3, 5, 1, 4, 0]
tensor([6, 2, 7, 3, 5, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 2, 5, 4, 6, 1, 3, 0]
tensor([7, 2, 5, 4, 6, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 5, 3, 1, 2, 4, 0]
tensor([0, 1, 5, 3, 1, 2, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 1, 1, 2, 2, 3, 0]
tensor([0, 3, 1, 1, 2, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 2, 3, 1, 2, 0, 3, 1]
tensor([0, 2, 3, 1, 2, 0, 3, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 3, 1, 2, 2, 1, 3, 0]
tensor([0, 3, 1, 2, 2, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1.0, 1.0, 0, 1.0, 1]
tensor([0, 1, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
done!
Normal merging for layer 2
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 4 to 8
done!
Normal merging for layer 9
tensor([0, 7])
tensor(0)
tensor([1, 4])
tensor(1)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([2])
tensor(2)
done!
Cross-layer merge completed for layers 10 to 20
done!
Normal merging for layer 21
tensor([0, 7])
tensor(0)
tensor([2, 3])
tensor(2)
tensor([4, 5])
tensor(4)
tensor([1, 6])
tensor(1)
done!
Normal merging for layer 22
tensor([0, 5])
tensor(0)
tensor([3, 7])
tensor(3)
tensor([1, 4])
tensor(1)
tensor([2, 6])
tensor(2)
done!
Normal merging for layer 23
tensor([0, 7])
tensor(0)
tensor([2, 5])
tensor(2)
tensor([3, 4])
tensor(3)
tensor([1, 6])
tensor(1)
done!
Cross-layer merge completed for layers 24 to 25
done!
Normal merging for layer 26
tensor([0, 5])
tensor(0)
tensor([1, 2, 3, 4, 6, 7])
tensor(1)
done!
Cross-layer merge completed for layers 27 to 31
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 28 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.5127 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 27 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

134
cuda:5
sciq
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:55<00:55, 55.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:15<00:00, 34.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:15<00:00, 37.51s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq HTTP/1.1" 200 1237
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/sciq/sciq.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq HTTP/1.1" 200 1237
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/allenai/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/allenai/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:filelock:Attempting to acquire lock 140438522144160 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:filelock:Lock 140438522144160 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_info.json
DEBUG:filelock:Attempting to release lock 140438522144160 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:filelock:Lock 140438522144160 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:filelock:Attempting to acquire lock 140437047615104 on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:filelock:Lock 140437047615104 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_info.json
DEBUG:filelock:Attempting to release lock 140437047615104 on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:filelock:Lock 140437047615104 released on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of sciq from None to 0
INFO:lm_eval.api.task:Building contexts for sciq on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1028.21it/s]
DEBUG:lm_eval.evaluator:Task: sciq; number of requests on this rank: 400
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/400 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/400 [00:04<26:56,  4.05s/it]Running loglikelihood requests:   0%|          | 2/400 [00:07<24:59,  3.77s/it]Running loglikelihood requests:   1%|          | 3/400 [00:10<23:44,  3.59s/it]Running loglikelihood requests:   1%|          | 4/400 [00:14<23:27,  3.55s/it]Running loglikelihood requests:   1%|▏         | 5/400 [00:17<22:34,  3.43s/it]Running loglikelihood requests:   2%|▏         | 6/400 [00:20<21:51,  3.33s/it]Running loglikelihood requests:   2%|▏         | 7/400 [00:23<21:23,  3.27s/it]Running loglikelihood requests:   2%|▏         | 8/400 [00:27<20:56,  3.20s/it]Running loglikelihood requests:   2%|▏         | 9/400 [00:29<20:12,  3.10s/it]Running loglikelihood requests:   2%|▎         | 10/400 [00:32<19:33,  3.01s/it]Running loglikelihood requests:   3%|▎         | 11/400 [00:35<19:04,  2.94s/it]Running loglikelihood requests:   3%|▎         | 12/400 [00:38<19:06,  2.96s/it]Running loglikelihood requests:   3%|▎         | 13/400 [00:41<18:21,  2.85s/it]Running loglikelihood requests:   4%|▎         | 14/400 [00:43<17:52,  2.78s/it]Running loglikelihood requests:   4%|▍         | 15/400 [00:46<17:20,  2.70s/it]Running loglikelihood requests:   4%|▍         | 16/400 [00:48<16:56,  2.65s/it]Running loglikelihood requests:   4%|▍         | 17/400 [00:51<16:30,  2.59s/it]Running loglikelihood requests:   4%|▍         | 18/400 [00:53<16:10,  2.54s/it]Running loglikelihood requests:   5%|▍         | 19/400 [00:56<15:56,  2.51s/it]Running loglikelihood requests:   5%|▌         | 20/400 [00:58<15:46,  2.49s/it]Running loglikelihood requests:   5%|▌         | 21/400 [01:01<16:02,  2.54s/it]Running loglikelihood requests:   6%|▌         | 22/400 [01:03<16:10,  2.57s/it]Running loglikelihood requests:   6%|▌         | 23/400 [01:06<16:25,  2.61s/it]Running loglikelihood requests:   6%|▌         | 24/400 [01:08<16:02,  2.56s/it]Running loglikelihood requests:   6%|▋         | 25/400 [01:11<15:28,  2.48s/it]Running loglikelihood requests:   6%|▋         | 26/400 [01:13<15:04,  2.42s/it]Running loglikelihood requests:   7%|▋         | 27/400 [01:16<15:31,  2.50s/it]Running loglikelihood requests:   7%|▋         | 28/400 [01:18<15:04,  2.43s/it]Running loglikelihood requests:   7%|▋         | 29/400 [01:20<14:22,  2.32s/it]Running loglikelihood requests:   8%|▊         | 30/400 [01:22<13:51,  2.25s/it]Running loglikelihood requests:   8%|▊         | 31/400 [01:24<13:29,  2.19s/it]Running loglikelihood requests:   8%|▊         | 32/400 [01:26<13:16,  2.16s/it]Running loglikelihood requests:   8%|▊         | 33/400 [01:28<12:49,  2.10s/it]Running loglikelihood requests:   8%|▊         | 34/400 [01:30<12:29,  2.05s/it]Running loglikelihood requests:   9%|▉         | 35/400 [01:32<12:41,  2.09s/it]Running loglikelihood requests:   9%|▉         | 36/400 [01:34<12:40,  2.09s/it]Running loglikelihood requests:   9%|▉         | 37/400 [01:36<12:25,  2.05s/it]Running loglikelihood requests:  10%|▉         | 38/400 [01:38<12:13,  2.03s/it]Running loglikelihood requests:  10%|█         | 40/400 [01:40<09:18,  1.55s/it]Running loglikelihood requests:  10%|█         | 41/400 [01:42<09:39,  1.61s/it]Running loglikelihood requests:  10%|█         | 42/400 [01:44<09:55,  1.66s/it]Running loglikelihood requests:  11%|█         | 43/400 [01:46<10:08,  1.70s/it]Running loglikelihood requests:  11%|█         | 44/400 [01:48<10:16,  1.73s/it]Running loglikelihood requests:  11%|█▏        | 45/400 [01:49<10:15,  1.73s/it]Running loglikelihood requests:  12%|█▏        | 46/400 [01:51<10:13,  1.73s/it]Running loglikelihood requests:  12%|█▏        | 47/400 [01:53<10:10,  1.73s/it]Running loglikelihood requests:  12%|█▏        | 48/400 [01:55<10:07,  1.73s/it]Running loglikelihood requests:  12%|█▏        | 49/400 [01:56<10:04,  1.72s/it]Running loglikelihood requests:  12%|█▎        | 50/400 [01:58<10:01,  1.72s/it]Running loglikelihood requests:  13%|█▎        | 51/400 [02:00<09:59,  1.72s/it]Running loglikelihood requests:  13%|█▎        | 52/400 [02:01<09:57,  1.72s/it]Running loglikelihood requests:  13%|█▎        | 53/400 [02:03<09:37,  1.66s/it]Running loglikelihood requests:  14%|█▎        | 54/400 [02:04<09:22,  1.63s/it]Running loglikelihood requests:  14%|█▍        | 55/400 [02:06<09:11,  1.60s/it]Running loglikelihood requests:  14%|█▍        | 57/400 [02:07<06:52,  1.20s/it]Running loglikelihood requests:  14%|█▍        | 58/400 [02:09<07:14,  1.27s/it]Running loglikelihood requests:  15%|█▍        | 59/400 [02:10<07:30,  1.32s/it]Running loglikelihood requests:  16%|█▌        | 62/400 [02:12<04:58,  1.13it/s]Running loglikelihood requests:  16%|█▌        | 63/400 [02:13<05:37,  1.00s/it]Running loglikelihood requests:  16%|█▌        | 64/400 [02:15<06:11,  1.11s/it]Running loglikelihood requests:  16%|█▋        | 65/400 [02:16<06:35,  1.18s/it]Running loglikelihood requests:  16%|█▋        | 66/400 [02:18<07:05,  1.27s/it]Running loglikelihood requests:  17%|█▋        | 67/400 [02:19<07:42,  1.39s/it]Running loglikelihood requests:  17%|█▋        | 68/400 [02:21<07:49,  1.41s/it]Running loglikelihood requests:  17%|█▋        | 69/400 [02:22<07:45,  1.41s/it]Running loglikelihood requests:  18%|█▊        | 70/400 [02:24<07:44,  1.41s/it]Running loglikelihood requests:  18%|█▊        | 71/400 [02:25<07:42,  1.40s/it]Running loglikelihood requests:  18%|█▊        | 72/400 [02:27<07:38,  1.40s/it]Running loglikelihood requests:  18%|█▊        | 73/400 [02:28<07:33,  1.39s/it]Running loglikelihood requests:  18%|█▊        | 74/400 [02:29<07:30,  1.38s/it]Running loglikelihood requests:  19%|█▉        | 77/400 [02:31<04:36,  1.17it/s]Running loglikelihood requests:  20%|█▉        | 78/400 [02:32<05:06,  1.05it/s]Running loglikelihood requests:  20%|█▉        | 79/400 [02:33<05:32,  1.04s/it]Running loglikelihood requests:  20%|██        | 81/400 [02:34<04:36,  1.16it/s]Running loglikelihood requests:  20%|██        | 82/400 [02:36<04:58,  1.06it/s]Running loglikelihood requests:  21%|██        | 83/400 [02:37<05:17,  1.00s/it]Running loglikelihood requests:  21%|██        | 84/400 [02:38<05:43,  1.09s/it]Running loglikelihood requests:  21%|██▏       | 85/400 [02:39<05:51,  1.12s/it]Running loglikelihood requests:  22%|██▏       | 86/400 [02:41<05:55,  1.13s/it]Running loglikelihood requests:  22%|██▏       | 89/400 [02:42<03:47,  1.37it/s]Running loglikelihood requests:  22%|██▎       | 90/400 [02:43<04:15,  1.22it/s]Running loglikelihood requests:  23%|██▎       | 91/400 [02:44<04:38,  1.11it/s]Running loglikelihood requests:  23%|██▎       | 92/400 [02:45<04:57,  1.03it/s]Running loglikelihood requests:  23%|██▎       | 93/400 [02:46<05:13,  1.02s/it]Running loglikelihood requests:  24%|██▍       | 97/400 [02:48<03:12,  1.57it/s]Running loglikelihood requests:  24%|██▍       | 98/400 [02:49<03:40,  1.37it/s]Running loglikelihood requests:  25%|██▍       | 99/400 [02:50<04:05,  1.23it/s]Running loglikelihood requests:  25%|██▌       | 100/400 [02:51<04:26,  1.12it/s]Running loglikelihood requests:  25%|██▌       | 101/400 [02:53<04:44,  1.05it/s]Running loglikelihood requests:  26%|██▌       | 102/400 [02:54<04:57,  1.00it/s]Running loglikelihood requests:  26%|██▌       | 103/400 [02:55<05:08,  1.04s/it]Running loglikelihood requests:  26%|██▌       | 104/400 [02:56<05:15,  1.07s/it]Running loglikelihood requests:  26%|██▋       | 105/400 [02:57<05:20,  1.08s/it]Running loglikelihood requests:  26%|██▋       | 106/400 [02:58<05:22,  1.10s/it]Running loglikelihood requests:  27%|██▋       | 107/400 [02:59<05:23,  1.10s/it]Running loglikelihood requests:  27%|██▋       | 108/400 [03:00<05:24,  1.11s/it]Running loglikelihood requests:  27%|██▋       | 109/400 [03:02<05:23,  1.11s/it]Running loglikelihood requests:  28%|██▊       | 110/400 [03:03<05:25,  1.12s/it]Running loglikelihood requests:  28%|██▊       | 111/400 [03:04<05:22,  1.12s/it]Running loglikelihood requests:  28%|██▊       | 112/400 [03:05<05:20,  1.11s/it]Running loglikelihood requests:  28%|██▊       | 113/400 [03:06<05:17,  1.11s/it]Running loglikelihood requests:  28%|██▊       | 114/400 [03:07<05:14,  1.10s/it]Running loglikelihood requests:  29%|██▉       | 115/400 [03:08<05:19,  1.12s/it]Running loglikelihood requests:  29%|██▉       | 116/400 [03:09<05:15,  1.11s/it]Running loglikelihood requests:  29%|██▉       | 117/400 [03:10<05:10,  1.10s/it]Running loglikelihood requests:  30%|██▉       | 118/400 [03:11<05:06,  1.09s/it]Running loglikelihood requests:  30%|██▉       | 119/400 [03:13<05:02,  1.08s/it]Running loglikelihood requests:  30%|███       | 120/400 [03:14<04:59,  1.07s/it]Running loglikelihood requests:  30%|███       | 121/400 [03:15<04:58,  1.07s/it]Running loglikelihood requests:  30%|███       | 122/400 [03:16<04:55,  1.06s/it]Running loglikelihood requests:  31%|███       | 123/400 [03:17<04:54,  1.06s/it]Running loglikelihood requests:  31%|███       | 124/400 [03:18<04:52,  1.06s/it]Running loglikelihood requests:  31%|███▏      | 125/400 [03:19<04:49,  1.05s/it]Running loglikelihood requests:  32%|███▏      | 126/400 [03:20<04:47,  1.05s/it]Running loglikelihood requests:  32%|███▏      | 127/400 [03:21<04:44,  1.04s/it]Running loglikelihood requests:  32%|███▏      | 128/400 [03:22<04:42,  1.04s/it]Running loglikelihood requests:  32%|███▏      | 129/400 [03:23<04:40,  1.03s/it]Running loglikelihood requests:  32%|███▎      | 130/400 [03:24<04:38,  1.03s/it]Running loglikelihood requests:  33%|███▎      | 131/400 [03:25<04:36,  1.03s/it]Running loglikelihood requests:  34%|███▎      | 134/400 [03:26<02:50,  1.56it/s]Running loglikelihood requests:  34%|███▍      | 135/400 [03:27<03:10,  1.39it/s]Running loglikelihood requests:  34%|███▍      | 136/400 [03:28<03:27,  1.27it/s]Running loglikelihood requests:  34%|███▍      | 137/400 [03:29<03:41,  1.19it/s]Running loglikelihood requests:  34%|███▍      | 138/400 [03:30<03:52,  1.13it/s]Running loglikelihood requests:  35%|███▍      | 139/400 [03:31<04:00,  1.09it/s]Running loglikelihood requests:  36%|███▌      | 142/400 [03:32<02:36,  1.65it/s]Running loglikelihood requests:  36%|███▌      | 143/400 [03:33<02:56,  1.45it/s]Running loglikelihood requests:  36%|███▌      | 144/400 [03:34<03:14,  1.32it/s]Running loglikelihood requests:  36%|███▋      | 145/400 [03:35<03:28,  1.22it/s]Running loglikelihood requests:  36%|███▋      | 146/400 [03:36<03:40,  1.15it/s]Running loglikelihood requests:  37%|███▋      | 147/400 [03:37<03:48,  1.11it/s]Running loglikelihood requests:  37%|███▋      | 148/400 [03:38<03:54,  1.08it/s]Running loglikelihood requests:  37%|███▋      | 149/400 [03:39<03:58,  1.05it/s]Running loglikelihood requests:  38%|███▊      | 150/400 [03:40<03:59,  1.04it/s]Running loglikelihood requests:  38%|███▊      | 151/400 [03:41<04:00,  1.03it/s]Running loglikelihood requests:  38%|███▊      | 152/400 [03:42<04:01,  1.03it/s]Running loglikelihood requests:  38%|███▊      | 153/400 [03:43<04:04,  1.01it/s]Running loglikelihood requests:  38%|███▊      | 154/400 [03:44<04:06,  1.00s/it]Running loglikelihood requests:  39%|███▉      | 155/400 [03:45<04:06,  1.01s/it]Running loglikelihood requests:  39%|███▉      | 156/400 [03:46<04:06,  1.01s/it]Running loglikelihood requests:  39%|███▉      | 157/400 [03:47<04:06,  1.01s/it]Running loglikelihood requests:  40%|███▉      | 158/400 [03:48<04:05,  1.01s/it]Running loglikelihood requests:  40%|███▉      | 159/400 [03:49<04:04,  1.02s/it]Running loglikelihood requests:  40%|████      | 160/400 [03:50<04:04,  1.02s/it]Running loglikelihood requests:  40%|████      | 161/400 [03:51<04:03,  1.02s/it]Running loglikelihood requests:  40%|████      | 162/400 [03:52<04:01,  1.02s/it]Running loglikelihood requests:  41%|████      | 163/400 [03:53<03:59,  1.01s/it]Running loglikelihood requests:  41%|████      | 164/400 [03:54<03:56,  1.00s/it]Running loglikelihood requests:  41%|████▏     | 165/400 [03:55<03:51,  1.01it/s]Running loglikelihood requests:  42%|████▏     | 166/400 [03:56<03:48,  1.02it/s]Running loglikelihood requests:  42%|████▏     | 167/400 [03:57<03:46,  1.03it/s]Running loglikelihood requests:  42%|████▏     | 168/400 [03:58<03:44,  1.03it/s]Running loglikelihood requests:  42%|████▏     | 169/400 [03:59<03:42,  1.04it/s]Running loglikelihood requests:  42%|████▎     | 170/400 [04:00<03:40,  1.04it/s]Running loglikelihood requests:  43%|████▎     | 172/400 [04:01<02:47,  1.36it/s]Running loglikelihood requests:  43%|████▎     | 173/400 [04:02<02:57,  1.28it/s]Running loglikelihood requests:  44%|████▎     | 174/400 [04:03<03:03,  1.23it/s]Running loglikelihood requests:  44%|████▍     | 177/400 [04:04<02:00,  1.85it/s]Running loglikelihood requests:  44%|████▍     | 178/400 [04:05<02:16,  1.62it/s]Running loglikelihood requests:  45%|████▍     | 179/400 [04:05<02:30,  1.47it/s]Running loglikelihood requests:  45%|████▌     | 180/400 [04:06<02:41,  1.36it/s]Running loglikelihood requests:  45%|████▌     | 181/400 [04:07<02:49,  1.29it/s]Running loglikelihood requests:  46%|████▌     | 182/400 [04:08<02:55,  1.24it/s]Running loglikelihood requests:  46%|████▌     | 183/400 [04:09<03:00,  1.20it/s]Running loglikelihood requests:  46%|████▌     | 184/400 [04:10<03:02,  1.18it/s]Running loglikelihood requests:  46%|████▋     | 185/400 [04:11<03:04,  1.17it/s]Running loglikelihood requests:  46%|████▋     | 186/400 [04:12<03:05,  1.16it/s]Running loglikelihood requests:  47%|████▋     | 187/400 [04:13<03:07,  1.14it/s]Running loglikelihood requests:  47%|████▋     | 188/400 [04:14<03:06,  1.14it/s]Running loglikelihood requests:  47%|████▋     | 189/400 [04:14<03:06,  1.13it/s]Running loglikelihood requests:  48%|████▊     | 190/400 [04:15<03:04,  1.14it/s]Running loglikelihood requests:  48%|████▊     | 191/400 [04:16<03:03,  1.14it/s]Running loglikelihood requests:  48%|████▊     | 192/400 [04:17<03:01,  1.15it/s]Running loglikelihood requests:  48%|████▊     | 193/400 [04:18<02:59,  1.15it/s]Running loglikelihood requests:  48%|████▊     | 194/400 [04:19<02:57,  1.16it/s]Running loglikelihood requests:  49%|████▉     | 195/400 [04:20<02:57,  1.15it/s]Running loglikelihood requests:  49%|████▉     | 196/400 [04:20<02:55,  1.16it/s]Running loglikelihood requests:  49%|████▉     | 197/400 [04:21<02:53,  1.17it/s]Running loglikelihood requests:  50%|████▉     | 198/400 [04:22<02:51,  1.18it/s]Running loglikelihood requests:  50%|████▉     | 199/400 [04:23<02:50,  1.18it/s]Running loglikelihood requests:  50%|█████     | 200/400 [04:24<02:48,  1.19it/s]Running loglikelihood requests:  50%|█████     | 201/400 [04:25<02:47,  1.19it/s]Running loglikelihood requests:  50%|█████     | 202/400 [04:25<02:46,  1.19it/s]Running loglikelihood requests:  51%|█████     | 203/400 [04:26<02:45,  1.19it/s]Running loglikelihood requests:  51%|█████     | 204/400 [04:27<02:44,  1.19it/s]Running loglikelihood requests:  51%|█████▏    | 205/400 [04:28<02:44,  1.18it/s]Running loglikelihood requests:  52%|█████▏    | 206/400 [04:29<02:44,  1.18it/s]Running loglikelihood requests:  52%|█████▏    | 207/400 [04:30<02:46,  1.16it/s]Running loglikelihood requests:  52%|█████▏    | 208/400 [04:31<02:49,  1.13it/s]Running loglikelihood requests:  52%|█████▏    | 209/400 [04:32<02:46,  1.14it/s]Running loglikelihood requests:  53%|█████▎    | 212/400 [04:32<01:41,  1.85it/s]Running loglikelihood requests:  53%|█████▎    | 213/400 [04:33<01:52,  1.67it/s]Running loglikelihood requests:  54%|█████▎    | 214/400 [04:34<02:01,  1.53it/s]Running loglikelihood requests:  54%|█████▍    | 215/400 [04:35<02:08,  1.44it/s]Running loglikelihood requests:  54%|█████▍    | 216/400 [04:36<02:13,  1.37it/s]Running loglikelihood requests:  54%|█████▍    | 217/400 [04:37<02:19,  1.31it/s]Running loglikelihood requests:  55%|█████▍    | 218/400 [04:37<02:21,  1.29it/s]Running loglikelihood requests:  55%|█████▍    | 219/400 [04:38<02:23,  1.26it/s]Running loglikelihood requests:  55%|█████▌    | 220/400 [04:39<02:23,  1.25it/s]Running loglikelihood requests:  55%|█████▌    | 221/400 [04:40<02:23,  1.25it/s]Running loglikelihood requests:  56%|█████▌    | 222/400 [04:41<02:22,  1.25it/s]Running loglikelihood requests:  56%|█████▌    | 223/400 [04:41<02:21,  1.25it/s]Running loglikelihood requests:  56%|█████▌    | 224/400 [04:42<02:20,  1.25it/s]Running loglikelihood requests:  56%|█████▋    | 225/400 [04:43<02:24,  1.21it/s]Running loglikelihood requests:  56%|█████▋    | 226/400 [04:44<02:23,  1.22it/s]Running loglikelihood requests:  57%|█████▋    | 227/400 [04:45<02:20,  1.23it/s]Running loglikelihood requests:  57%|█████▋    | 228/400 [04:45<02:18,  1.24it/s]Running loglikelihood requests:  57%|█████▋    | 229/400 [04:46<02:16,  1.25it/s]Running loglikelihood requests:  57%|█████▊    | 230/400 [04:47<02:15,  1.25it/s]Running loglikelihood requests:  58%|█████▊    | 231/400 [04:48<02:14,  1.26it/s]Running loglikelihood requests:  58%|█████▊    | 232/400 [04:49<02:13,  1.26it/s]Running loglikelihood requests:  58%|█████▊    | 233/400 [04:49<02:12,  1.26it/s]Running loglikelihood requests:  58%|█████▊    | 234/400 [04:50<02:11,  1.27it/s]Running loglikelihood requests:  59%|█████▉    | 235/400 [04:51<02:09,  1.27it/s]Running loglikelihood requests:  59%|█████▉    | 236/400 [04:52<02:08,  1.27it/s]Running loglikelihood requests:  59%|█████▉    | 237/400 [04:53<02:07,  1.28it/s]Running loglikelihood requests:  60%|██████    | 240/400 [04:53<01:19,  2.02it/s]Running loglikelihood requests:  60%|██████    | 241/400 [04:54<01:28,  1.79it/s]Running loglikelihood requests:  60%|██████    | 242/400 [04:55<01:36,  1.64it/s]Running loglikelihood requests:  61%|██████    | 243/400 [04:56<01:42,  1.53it/s]Running loglikelihood requests:  61%|██████    | 244/400 [04:56<01:47,  1.46it/s]Running loglikelihood requests:  61%|██████▏   | 245/400 [04:57<01:50,  1.41it/s]Running loglikelihood requests:  62%|██████▏   | 246/400 [04:58<01:52,  1.37it/s]Running loglikelihood requests:  62%|██████▏   | 247/400 [04:59<01:53,  1.35it/s]Running loglikelihood requests:  62%|██████▏   | 248/400 [05:00<01:54,  1.33it/s]Running loglikelihood requests:  62%|██████▏   | 249/400 [05:00<01:54,  1.32it/s]Running loglikelihood requests:  62%|██████▎   | 250/400 [05:01<01:54,  1.31it/s]Running loglikelihood requests:  63%|██████▎   | 251/400 [05:02<01:53,  1.31it/s]Running loglikelihood requests:  63%|██████▎   | 252/400 [05:03<01:52,  1.31it/s]Running loglikelihood requests:  63%|██████▎   | 253/400 [05:03<01:52,  1.31it/s]Running loglikelihood requests:  64%|██████▎   | 254/400 [05:04<01:52,  1.30it/s]Running loglikelihood requests:  64%|██████▍   | 255/400 [05:05<01:51,  1.30it/s]Running loglikelihood requests:  64%|██████▍   | 256/400 [05:06<01:50,  1.30it/s]Running loglikelihood requests:  64%|██████▍   | 257/400 [05:07<01:50,  1.30it/s]Running loglikelihood requests:  64%|██████▍   | 258/400 [05:07<01:48,  1.31it/s]Running loglikelihood requests:  65%|██████▍   | 259/400 [05:08<01:46,  1.32it/s]Running loglikelihood requests:  65%|██████▌   | 260/400 [05:09<01:45,  1.33it/s]Running loglikelihood requests:  65%|██████▌   | 261/400 [05:09<01:43,  1.34it/s]Running loglikelihood requests:  66%|██████▌   | 262/400 [05:10<01:41,  1.36it/s]Running loglikelihood requests:  66%|██████▌   | 263/400 [05:11<01:40,  1.36it/s]Running loglikelihood requests:  66%|██████▌   | 264/400 [05:12<01:37,  1.39it/s]Running loglikelihood requests:  66%|██████▋   | 265/400 [05:12<01:34,  1.43it/s]Running loglikelihood requests:  66%|██████▋   | 266/400 [05:13<01:31,  1.46it/s]Running loglikelihood requests:  67%|██████▋   | 267/400 [05:14<01:29,  1.48it/s]Running loglikelihood requests:  67%|██████▋   | 268/400 [05:14<01:28,  1.50it/s]Running loglikelihood requests:  67%|██████▋   | 269/400 [05:15<01:27,  1.49it/s]Running loglikelihood requests:  68%|██████▊   | 270/400 [05:16<01:30,  1.44it/s]Running loglikelihood requests:  68%|██████▊   | 271/400 [05:16<01:28,  1.46it/s]Running loglikelihood requests:  68%|██████▊   | 272/400 [05:17<01:25,  1.49it/s]Running loglikelihood requests:  68%|██████▊   | 273/400 [05:18<01:23,  1.53it/s]Running loglikelihood requests:  68%|██████▊   | 274/400 [05:18<01:20,  1.57it/s]Running loglikelihood requests:  69%|██████▉   | 275/400 [05:19<01:18,  1.59it/s]Running loglikelihood requests:  69%|██████▉   | 276/400 [05:19<01:16,  1.62it/s]Running loglikelihood requests:  69%|██████▉   | 277/400 [05:20<01:15,  1.63it/s]Running loglikelihood requests:  70%|██████▉   | 278/400 [05:21<01:14,  1.65it/s]Running loglikelihood requests:  70%|██████▉   | 279/400 [05:21<01:13,  1.66it/s]Running loglikelihood requests:  70%|███████   | 280/400 [05:22<01:12,  1.66it/s]Running loglikelihood requests:  70%|███████   | 281/400 [05:22<01:11,  1.67it/s]Running loglikelihood requests:  70%|███████   | 282/400 [05:23<01:10,  1.68it/s]Running loglikelihood requests:  71%|███████   | 283/400 [05:23<01:09,  1.69it/s]Running loglikelihood requests:  71%|███████   | 284/400 [05:24<01:08,  1.69it/s]Running loglikelihood requests:  71%|███████▏  | 285/400 [05:25<01:07,  1.70it/s]Running loglikelihood requests:  72%|███████▏  | 286/400 [05:25<01:06,  1.71it/s]Running loglikelihood requests:  72%|███████▏  | 287/400 [05:26<01:05,  1.71it/s]Running loglikelihood requests:  72%|███████▏  | 288/400 [05:26<01:05,  1.72it/s]Running loglikelihood requests:  72%|███████▏  | 289/400 [05:27<01:04,  1.72it/s]Running loglikelihood requests:  72%|███████▎  | 290/400 [05:28<01:04,  1.71it/s]Running loglikelihood requests:  73%|███████▎  | 291/400 [05:28<01:03,  1.72it/s]Running loglikelihood requests:  73%|███████▎  | 292/400 [05:29<01:02,  1.72it/s]Running loglikelihood requests:  73%|███████▎  | 293/400 [05:29<01:02,  1.72it/s]Running loglikelihood requests:  74%|███████▎  | 294/400 [05:30<01:01,  1.73it/s]Running loglikelihood requests:  74%|███████▍  | 295/400 [05:30<01:00,  1.73it/s]Running loglikelihood requests:  74%|███████▍  | 296/400 [05:31<00:59,  1.74it/s]Running loglikelihood requests:  74%|███████▍  | 297/400 [05:32<00:59,  1.74it/s]Running loglikelihood requests:  74%|███████▍  | 298/400 [05:32<00:58,  1.75it/s]Running loglikelihood requests:  75%|███████▍  | 299/400 [05:33<00:57,  1.75it/s]Running loglikelihood requests:  75%|███████▌  | 300/400 [05:33<00:57,  1.75it/s]Running loglikelihood requests:  75%|███████▌  | 301/400 [05:34<00:56,  1.75it/s]Running loglikelihood requests:  76%|███████▌  | 302/400 [05:34<00:56,  1.72it/s]Running loglikelihood requests:  76%|███████▌  | 303/400 [05:35<00:55,  1.73it/s]Running loglikelihood requests:  76%|███████▌  | 304/400 [05:36<00:55,  1.72it/s]Running loglikelihood requests:  76%|███████▋  | 305/400 [05:36<00:54,  1.73it/s]Running loglikelihood requests:  76%|███████▋  | 306/400 [05:37<00:54,  1.74it/s]Running loglikelihood requests:  77%|███████▋  | 307/400 [05:37<00:53,  1.74it/s]Running loglikelihood requests:  78%|███████▊  | 310/400 [05:38<00:32,  2.79it/s]Running loglikelihood requests:  78%|███████▊  | 311/400 [05:39<00:35,  2.49it/s]Running loglikelihood requests:  78%|███████▊  | 312/400 [05:39<00:38,  2.27it/s]Running loglikelihood requests:  78%|███████▊  | 313/400 [05:40<00:41,  2.12it/s]Running loglikelihood requests:  78%|███████▊  | 314/400 [05:40<00:42,  2.01it/s]Running loglikelihood requests:  79%|███████▉  | 315/400 [05:41<00:43,  1.94it/s]Running loglikelihood requests:  79%|███████▉  | 316/400 [05:41<00:44,  1.90it/s]Running loglikelihood requests:  79%|███████▉  | 317/400 [05:42<00:44,  1.87it/s]Running loglikelihood requests:  80%|███████▉  | 318/400 [05:42<00:44,  1.85it/s]Running loglikelihood requests:  80%|███████▉  | 319/400 [05:43<00:43,  1.85it/s]Running loglikelihood requests:  80%|████████  | 321/400 [05:44<00:33,  2.39it/s]Running loglikelihood requests:  80%|████████  | 322/400 [05:44<00:34,  2.23it/s]Running loglikelihood requests:  81%|████████  | 323/400 [05:45<00:36,  2.12it/s]Running loglikelihood requests:  81%|████████  | 324/400 [05:45<00:37,  2.05it/s]Running loglikelihood requests:  81%|████████▏ | 325/400 [05:46<00:37,  1.99it/s]Running loglikelihood requests:  82%|████████▏ | 326/400 [05:46<00:37,  1.96it/s]Running loglikelihood requests:  82%|████████▏ | 327/400 [05:47<00:37,  1.94it/s]Running loglikelihood requests:  82%|████████▏ | 328/400 [05:47<00:37,  1.93it/s]Running loglikelihood requests:  82%|████████▏ | 329/400 [05:48<00:37,  1.92it/s]Running loglikelihood requests:  82%|████████▎ | 330/400 [05:48<00:37,  1.89it/s]Running loglikelihood requests:  83%|████████▎ | 331/400 [05:49<00:36,  1.89it/s]Running loglikelihood requests:  83%|████████▎ | 332/400 [05:49<00:36,  1.87it/s]Running loglikelihood requests:  83%|████████▎ | 333/400 [05:50<00:35,  1.89it/s]Running loglikelihood requests:  84%|████████▎ | 334/400 [05:50<00:34,  1.92it/s]Running loglikelihood requests:  84%|████████▍ | 335/400 [05:51<00:33,  1.93it/s]Running loglikelihood requests:  84%|████████▍ | 336/400 [05:51<00:33,  1.91it/s]Running loglikelihood requests:  84%|████████▍ | 337/400 [05:52<00:32,  1.92it/s]Running loglikelihood requests:  84%|████████▍ | 338/400 [05:52<00:31,  1.94it/s]Running loglikelihood requests:  85%|████████▍ | 339/400 [05:53<00:31,  1.95it/s]Running loglikelihood requests:  85%|████████▌ | 340/400 [05:54<00:30,  1.96it/s]Running loglikelihood requests:  85%|████████▌ | 341/400 [05:54<00:30,  1.96it/s]Running loglikelihood requests:  86%|████████▌ | 342/400 [05:55<00:29,  1.96it/s]Running loglikelihood requests:  86%|████████▌ | 343/400 [05:55<00:28,  1.97it/s]Running loglikelihood requests:  86%|████████▌ | 344/400 [05:56<00:28,  1.97it/s]Running loglikelihood requests:  86%|████████▋ | 345/400 [05:56<00:27,  1.99it/s]Running loglikelihood requests:  86%|████████▋ | 346/400 [05:57<00:27,  1.96it/s]Running loglikelihood requests:  87%|████████▋ | 347/400 [05:57<00:26,  1.97it/s]Running loglikelihood requests:  87%|████████▋ | 348/400 [05:58<00:26,  1.97it/s]Running loglikelihood requests:  87%|████████▋ | 349/400 [05:58<00:25,  1.98it/s]Running loglikelihood requests:  88%|████████▊ | 350/400 [05:59<00:25,  1.97it/s]Running loglikelihood requests:  88%|████████▊ | 351/400 [05:59<00:25,  1.95it/s]Running loglikelihood requests:  88%|████████▊ | 352/400 [06:00<00:24,  1.97it/s]Running loglikelihood requests:  88%|████████▊ | 353/400 [06:00<00:23,  1.98it/s]Running loglikelihood requests:  88%|████████▊ | 354/400 [06:01<00:23,  1.99it/s]Running loglikelihood requests:  89%|████████▉ | 355/400 [06:01<00:22,  2.00it/s]Running loglikelihood requests:  89%|████████▉ | 356/400 [06:02<00:21,  2.01it/s]Running loglikelihood requests:  89%|████████▉ | 357/400 [06:02<00:21,  2.02it/s]Running loglikelihood requests:  90%|████████▉ | 358/400 [06:03<00:20,  2.00it/s]Running loglikelihood requests:  90%|████████▉ | 359/400 [06:03<00:20,  2.02it/s]Running loglikelihood requests:  90%|█████████ | 360/400 [06:04<00:19,  2.02it/s]Running loglikelihood requests:  90%|█████████ | 361/400 [06:04<00:19,  2.03it/s]Running loglikelihood requests:  90%|█████████ | 362/400 [06:05<00:18,  2.04it/s]Running loglikelihood requests:  91%|█████████ | 363/400 [06:05<00:18,  2.04it/s]Running loglikelihood requests:  91%|█████████ | 364/400 [06:05<00:17,  2.05it/s]Running loglikelihood requests:  91%|█████████▏| 365/400 [06:06<00:17,  2.06it/s]Running loglikelihood requests:  92%|█████████▏| 366/400 [06:06<00:16,  2.06it/s]Running loglikelihood requests:  92%|█████████▏| 368/400 [06:07<00:11,  2.68it/s]Running loglikelihood requests:  92%|█████████▏| 369/400 [06:07<00:12,  2.49it/s]Running loglikelihood requests:  92%|█████████▎| 370/400 [06:08<00:12,  2.37it/s]Running loglikelihood requests:  93%|█████████▎| 371/400 [06:08<00:12,  2.28it/s]Running loglikelihood requests:  93%|█████████▎| 373/400 [06:09<00:09,  2.83it/s]Running loglikelihood requests:  94%|█████████▎| 374/400 [06:09<00:09,  2.61it/s]Running loglikelihood requests:  94%|█████████▍| 375/400 [06:10<00:10,  2.45it/s]Running loglikelihood requests:  94%|█████████▍| 376/400 [06:10<00:10,  2.35it/s]Running loglikelihood requests:  94%|█████████▍| 377/400 [06:11<00:10,  2.28it/s]Running loglikelihood requests:  94%|█████████▍| 378/400 [06:11<00:09,  2.24it/s]Running loglikelihood requests:  95%|█████████▍| 379/400 [06:12<00:09,  2.22it/s]Running loglikelihood requests:  95%|█████████▌| 380/400 [06:12<00:09,  2.19it/s]Running loglikelihood requests:  95%|█████████▌| 381/400 [06:13<00:08,  2.18it/s]Running loglikelihood requests:  96%|█████████▌| 382/400 [06:13<00:08,  2.17it/s]Running loglikelihood requests:  96%|█████████▌| 383/400 [06:14<00:07,  2.17it/s]Running loglikelihood requests:  96%|█████████▌| 384/400 [06:14<00:07,  2.17it/s]Running loglikelihood requests:  96%|█████████▋| 385/400 [06:14<00:06,  2.17it/s]Running loglikelihood requests:  96%|█████████▋| 386/400 [06:15<00:06,  2.18it/s]Running loglikelihood requests:  97%|█████████▋| 387/400 [06:15<00:05,  2.19it/s]Running loglikelihood requests:  97%|█████████▋| 388/400 [06:16<00:05,  2.20it/s]Running loglikelihood requests:  97%|█████████▋| 389/400 [06:16<00:04,  2.21it/s]Running loglikelihood requests:  98%|█████████▊| 390/400 [06:17<00:04,  2.21it/s]Running loglikelihood requests:  98%|█████████▊| 391/400 [06:17<00:04,  2.21it/s]Running loglikelihood requests:  98%|█████████▊| 392/400 [06:18<00:03,  2.22it/s]Running loglikelihood requests:  98%|█████████▊| 393/400 [06:18<00:03,  2.22it/s]Running loglikelihood requests:  98%|█████████▊| 394/400 [06:19<00:02,  2.23it/s]Running loglikelihood requests:  99%|█████████▉| 395/400 [06:19<00:02,  2.23it/s]Running loglikelihood requests:  99%|█████████▉| 396/400 [06:19<00:01,  2.23it/s]Running loglikelihood requests:  99%|█████████▉| 397/400 [06:20<00:01,  2.24it/s]Running loglikelihood requests: 100%|█████████▉| 398/400 [06:20<00:00,  2.25it/s]Running loglikelihood requests: 100%|█████████▉| 399/400 [06:21<00:00,  2.25it/s]Running loglikelihood requests: 100%|██████████| 400/400 [06:21<00:00,  2.26it/s]Running loglikelihood requests: 100%|██████████| 400/400 [06:21<00:00,  1.05it/s]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:6'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:6'}
full model:
{'sciq': {'alias': 'sciq', 'acc,none': 0.94, 'acc_stderr,none': 0.023868325657594204, 'acc_norm,none': 0.91, 'acc_norm_stderr,none': 0.028762349126466136}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.969062788859705
0.9024924890572922
0.7706109127217512
0.8221264026535647
0.9190490061886575
0.9866654579796295
0.6586322754204971
0.7962110384246164
0.8195614021629236
0.7124178311176441
0.787697814339696
0.7034455022322618
0.8136386046534271
0.8174990104652458
0.6784276389594894
0.8698440245672888
0.8886492811850213
0.6541737276411673
0.6560861559753316
0.8139845219953913
0.6714741870309046
0.6164364868717988
0.8331581872497299
0.9065420049234512
0.9246185715568276
0.7477515960551026
0.574165362968651
0.8586446364199891
0.8889771415746612
Total groups 70 exceeded the threshold, stopping comparison.
The group tensor is
[7, 3, 4, 2, 6, 1, 5, 0]
tensor([7, 3, 4, 2, 6, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 2, 5, 3, 4, 0, 7, 1]
tensor([6, 2, 5, 3, 4, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 3, 6, 2, 7, 1, 4, 0]
tensor([5, 3, 6, 2, 7, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 4, 2, 1, 3, 5, 1]
tensor([0, 0, 4, 2, 1, 3, 5, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 2, 3, 4, 5, 0, 1, 1]
tensor([0, 2, 3, 4, 5, 0, 1, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 1, 0, 2, 2, 3, 1]
tensor([0, 3, 1, 0, 2, 2, 3, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 3, 1, 1, 2, 2, 3, 0]
tensor([0, 3, 1, 1, 2, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 1, 1.0, 1.0, 1.0, 1.0, 1]
tensor([0, 0, 1, 1, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 2 to 4
done!
Normal merging for layer 5
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 6 to 9
done!
Normal merging for layer 10
tensor([0, 1])
tensor(0)
tensor([4, 7])
tensor(4)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 11 to 12
done!
Normal merging for layer 13
tensor([0, 5])
tensor(0)
tensor([6, 7])
tensor(6)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 14 to 19
done!
Normal merging for layer 20
tensor([0, 3])
tensor(0)
tensor([2, 7])
tensor(2)
tensor([4, 5])
tensor(4)
tensor([1, 6])
tensor(1)
done!
Normal merging for layer 21
tensor([0, 7])
tensor(0)
tensor([2, 3])
tensor(2)
tensor([4, 5])
tensor(4)
tensor([1, 6])
tensor(1)
done!
Cross-layer merge completed for layers 22 to 23
done!
Normal merging for layer 24
tensor([0, 1])
tensor(0)
tensor([2, 3, 4, 5, 6, 7])
tensor(2)
done!
Cross-layer merge completed for layers 25 to 31
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 27 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.2608 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 26 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

47
cuda:6
rte
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:55<00:55, 55.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:12<00:00, 33.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:12<00:00, 36.42s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: rte] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: rte] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/rte?recursive=False&expand=False HTTP/1.1" 307 140
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/rte?recursive=False&expand=False HTTP/1.1" 200 354
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:filelock:Attempting to acquire lock 140438522207056 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140438522207056 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140438522207056 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140438522207056 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140430435588800 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140430435588800 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430435588800 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140430435588800 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of rte from None to 0
INFO:lm_eval.api.task:Building contexts for rte on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 2603.07it/s]
DEBUG:lm_eval.evaluator:Task: rte; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:02<07:19,  2.21s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:03<03:46,  1.15s/it]Running loglikelihood requests:   2%|▎         | 5/200 [00:05<02:53,  1.12it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:06<02:29,  1.29it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:07<02:19,  1.37it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:08<02:10,  1.45it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:10<02:03,  1.52it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:11<01:58,  1.56it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:12<01:53,  1.61it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:13<01:50,  1.64it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:14<01:46,  1.68it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:15<01:43,  1.71it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:16<01:40,  1.74it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:17<01:37,  1.78it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:19<01:35,  1.80it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:20<01:31,  1.84it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:21<01:29,  1.86it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:22<01:26,  1.90it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:23<01:24,  1.92it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:24<01:22,  1.95it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:25<01:19,  1.99it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:26<01:17,  2.02it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:26<01:15,  2.06it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:27<01:12,  2.11it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:28<01:10,  2.15it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:29<01:07,  2.21it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:30<01:04,  2.27it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:31<01:02,  2.33it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:32<00:59,  2.39it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:32<00:57,  2.43it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:33<00:56,  2.47it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:34<00:54,  2.50it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:35<00:53,  2.52it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:35<00:52,  2.52it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:36<00:51,  2.54it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:37<00:50,  2.56it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:38<00:49,  2.59it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:38<00:47,  2.62it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:39<00:46,  2.66it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:40<00:45,  2.68it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:41<00:43,  2.71it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:41<00:43,  2.70it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:42<00:42,  2.72it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:43<00:41,  2.74it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:44<00:39,  2.78it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:44<00:39,  2.77it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:45<00:38,  2.80it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:46<00:37,  2.82it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:46<00:36,  2.84it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:47<00:35,  2.86it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:48<00:34,  2.88it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:48<00:33,  2.90it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:49<00:32,  2.92it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:50<00:31,  2.94it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:50<00:30,  2.94it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:51<00:30,  2.96it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:52<00:29,  2.98it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:52<00:28,  2.98it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:53<00:27,  2.99it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:54<00:27,  3.00it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:54<00:26,  3.00it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:55<00:25,  3.01it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:56<00:24,  3.02it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [00:56<00:24,  3.03it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [00:57<00:23,  3.03it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [00:58<00:22,  3.04it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [00:58<00:21,  3.06it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [00:59<00:20,  3.10it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [01:00<00:20,  3.12it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [01:00<00:19,  3.13it/s]Running loglikelihood requests:  70%|███████   | 141/200 [01:01<00:18,  3.14it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [01:01<00:18,  3.16it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [01:02<00:17,  3.17it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [01:03<00:16,  3.18it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [01:03<00:15,  3.20it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [01:04<00:15,  3.21it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [01:05<00:14,  3.21it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [01:05<00:13,  3.22it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [01:06<00:13,  3.24it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [01:06<00:12,  3.26it/s]Running loglikelihood requests:  80%|████████  | 161/200 [01:07<00:11,  3.28it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [01:08<00:11,  3.29it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [01:08<00:10,  3.30it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [01:09<00:09,  3.32it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [01:09<00:09,  3.34it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [01:10<00:08,  3.36it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [01:11<00:08,  3.37it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [01:11<00:07,  3.39it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [01:12<00:06,  3.41it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [01:12<00:06,  3.37it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [01:13<00:05,  3.38it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [01:14<00:05,  3.39it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [01:14<00:04,  3.39it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [01:15<00:03,  3.41it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [01:15<00:03,  3.37it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [01:16<00:02,  3.37it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [01:16<00:02,  3.40it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:17<00:01,  3.42it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:18<00:00,  3.54it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:18<00:00,  3.59it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:18<00:00,  2.54it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:7'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:7'}
full model:
{'rte': {'alias': 'rte', 'acc,none': 0.5, 'acc_stderr,none': 0.050251890762960605}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.34161229456626735
0.905233410256777
0.5205040718697735
0.4121994254524892
0.7398116665887099
0.6225415196831932
0.7923970242263771
0.7353888240887675
0.6535613357308766
0.7757058271862038
0.734046359122903
0.4471799126982846
0.773619360921301
0.7955347039939479
0.8672068064531693
0.8652880343596522
0.3302235467760883
0.6789268064017625
0.6072221471952108
0.9194446824778495
0.4812004589187253
0.5728915095234594
0.1682455054057436
0.93212414632396
0.9148362604533635
0.8268537756297094
0.7592245907029287
0.7256008379011685
0.7109756105942956
0.34161229456626735
0.905233410256777
0.5205040718697735
0.4121994254524892
0.7398116665887099
0.6225415196831932
0.7923970242263771
0.7353888240887675
0.6535613357308766
0.7757058271862038
0.734046359122903
0.4471799126982846
0.773619360921301
0.7955347039939479
0.8672068064531693
0.8652880343596522
0.3302235467760883
0.6789268064017625
0.6072221471952108
0.9194446824778495
0.4812004589187253
Total groups 73 exceeded the threshold, stopping comparison.
The group tensor is
[5, 2, 7, 1, 6, 4, 3, 0]
tensor([5, 2, 7, 1, 6, 4, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 6, 0, 7, 3, 4, 1]
tensor([5, 2, 6, 0, 7, 3, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 7, 2, 5, 4, 3, 0]
tensor([6, 1, 7, 2, 5, 4, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 7, 2, 4, 1, 5, 0]
tensor([6, 3, 7, 2, 4, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 5, 6, 2, 3, 1, 4, 0]
tensor([7, 5, 6, 2, 3, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 2, 5, 4, 1, 0, 1, 3]
tensor([0, 2, 5, 4, 1, 0, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1.0, 1.0, 0, 1.0, 1]
tensor([0, 1, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
Normal merging for layer 1
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Normal merging for layer 2
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 4
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 5 to 8
done!
Normal merging for layer 9
tensor([0, 5])
tensor(0)
tensor([4, 6])
tensor(4)
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
done!
Cross-layer merge completed for layers 10 to 30
done!
Normal merging for layer 31
tensor([0, 5])
tensor(0)
tensor([1, 2, 3, 4, 6, 7])
tensor(1)
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 26 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.1348 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 25 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

25
cuda:7
fda
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:54<00:54, 54.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:10<00:00, 31.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:10<00:00, 35.35s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:None: No `generation_kwargs` specified in task config, defaulting to {'until': ['\n\n'], 'do_sample': False, 'temperature': 0}
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/hazyresearch/based-fda HTTP/1.1" 200 1035
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/hazyresearch/based-fda/hazyresearch/based-fda.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/hazyresearch/based-fda HTTP/1.1" 200 1043
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/hazyresearch/based-fda/resolve/42569d301e12fbcf8d5a69e04e892aa013e20314/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/hazyresearch/based-fda/revision/42569d301e12fbcf8d5a69e04e892aa013e20314 HTTP/1.1" 200 1043
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/hazyresearch/based-fda/tree/42569d301e12fbcf8d5a69e04e892aa013e20314?recursive=False&expand=False HTTP/1.1" 200 291
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/hazyresearch/based-fda/paths-info/42569d301e12fbcf8d5a69e04e892aa013e20314 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/hazyresearch/based-fda/tree/42569d301e12fbcf8d5a69e04e892aa013e20314/data?recursive=False&expand=False HTTP/1.1" 200 484
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/hazyresearch/based-fda/paths-info/42569d301e12fbcf8d5a69e04e892aa013e20314 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/hazyresearch/based-fda/revision/42569d301e12fbcf8d5a69e04e892aa013e20314 HTTP/1.1" 200 1043
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/hazyresearch/based-fda/resolve/42569d301e12fbcf8d5a69e04e892aa013e20314/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/hazyresearch/based-fda/paths-info/42569d301e12fbcf8d5a69e04e892aa013e20314 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/hazyresearch/based-fda/paths-info/42569d301e12fbcf8d5a69e04e892aa013e20314 HTTP/1.1" 200 218
DEBUG:filelock:Attempting to acquire lock 140430940687104 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_hazyresearch___based-fda_default_0.0.0_42569d301e12fbcf8d5a69e04e892aa013e20314.lock
DEBUG:filelock:Lock 140430940687104 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_hazyresearch___based-fda_default_0.0.0_42569d301e12fbcf8d5a69e04e892aa013e20314.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/hazyresearch___based-fda/default/0.0.0/42569d301e12fbcf8d5a69e04e892aa013e20314/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430940687104 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_hazyresearch___based-fda_default_0.0.0_42569d301e12fbcf8d5a69e04e892aa013e20314.lock
DEBUG:filelock:Lock 140430940687104 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_hazyresearch___based-fda_default_0.0.0_42569d301e12fbcf8d5a69e04e892aa013e20314.lock
DEBUG:filelock:Attempting to acquire lock 140430940686768 on /public/home/zouyifei001/.cache/huggingface/datasets/hazyresearch___based-fda/default/0.0.0/42569d301e12fbcf8d5a69e04e892aa013e20314_builder.lock
DEBUG:filelock:Lock 140430940686768 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/hazyresearch___based-fda/default/0.0.0/42569d301e12fbcf8d5a69e04e892aa013e20314_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/hazyresearch___based-fda/default/0.0.0/42569d301e12fbcf8d5a69e04e892aa013e20314/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430940686768 on /public/home/zouyifei001/.cache/huggingface/datasets/hazyresearch___based-fda/default/0.0.0/42569d301e12fbcf8d5a69e04e892aa013e20314_builder.lock
DEBUG:filelock:Lock 140430940686768 released on /public/home/zouyifei001/.cache/huggingface/datasets/hazyresearch___based-fda/default/0.0.0/42569d301e12fbcf8d5a69e04e892aa013e20314_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
INFO:lm_eval.evaluator:fda: Using gen_kwargs: {'until': ['\n\n'], 'do_sample': False, 'temperature': 0}
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of fda from None to 0
INFO:lm_eval.api.task:Building contexts for fda on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 247305.66it/s]
DEBUG:lm_eval.evaluator:Task: fda; number of requests on this rank: 100
INFO:lm_eval.evaluator:Running generate_until requests
Running generate_until requests:   0%|          | 0/100 [00:00<?, ?it/s]Running generate_until requests:   1%|          | 1/100 [00:18<31:17, 18.97s/it]Running generate_until requests:   2%|▏         | 2/100 [00:31<24:56, 15.27s/it]Running generate_until requests:   3%|▎         | 3/100 [00:43<22:31, 13.93s/it]Running generate_until requests:   4%|▍         | 4/100 [01:01<24:24, 15.25s/it]Running generate_until requests:   5%|▌         | 5/100 [01:16<24:15, 15.32s/it]Running generate_until requests:   6%|▌         | 6/100 [01:30<23:12, 14.81s/it]Running generate_until requests:   7%|▋         | 7/100 [01:48<24:22, 15.73s/it]Running generate_until requests:   8%|▊         | 8/100 [02:05<24:56, 16.27s/it]Running generate_until requests:   9%|▉         | 9/100 [02:18<22:53, 15.10s/it]Running generate_until requests:  10%|█         | 10/100 [02:29<21:09, 14.10s/it]Running generate_until requests:  11%|█         | 11/100 [02:41<19:56, 13.45s/it]Running generate_until requests:  12%|█▏        | 12/100 [03:00<21:51, 14.91s/it]Running generate_until requests:  13%|█▎        | 13/100 [03:11<20:13, 13.95s/it]Running generate_until requests:  14%|█▍        | 14/100 [03:30<21:51, 15.25s/it]Running generate_until requests:  15%|█▌        | 15/100 [03:41<20:07, 14.21s/it]Running generate_until requests:  16%|█▌        | 16/100 [03:54<19:11, 13.71s/it]Running generate_until requests:  17%|█▋        | 17/100 [04:06<18:13, 13.17s/it]Running generate_until requests:  18%|█▊        | 18/100 [04:24<19:48, 14.49s/it]Running generate_until requests:  19%|█▉        | 19/100 [04:35<18:24, 13.64s/it]Running generate_until requests:  20%|██        | 20/100 [04:53<20:00, 15.01s/it]Running generate_until requests:  21%|██        | 21/100 [05:11<20:38, 15.68s/it]Running generate_until requests:  22%|██▏       | 22/100 [05:25<19:41, 15.15s/it]Running generate_until requests:  23%|██▎       | 23/100 [05:42<20:24, 15.91s/it]Running generate_until requests:  24%|██▍       | 24/100 [05:55<18:50, 14.88s/it]Running generate_until requests:  25%|██▌       | 25/100 [06:12<19:27, 15.57s/it]Running generate_until requests:  26%|██▌       | 26/100 [06:29<19:45, 16.02s/it]Running generate_until requests:  27%|██▋       | 27/100 [06:47<20:14, 16.64s/it]Running generate_until requests:  28%|██▊       | 28/100 [07:00<18:33, 15.47s/it]Running generate_until requests:  29%|██▉       | 29/100 [07:17<18:54, 15.98s/it]Running generate_until requests:  30%|███       | 30/100 [07:31<17:54, 15.35s/it]Running generate_until requests:  31%|███       | 31/100 [07:48<18:19, 15.93s/it]Running generate_until requests:  32%|███▏      | 32/100 [08:01<17:02, 15.04s/it]Running generate_until requests:  33%|███▎      | 33/100 [08:20<18:13, 16.32s/it]Running generate_until requests:  34%|███▍      | 34/100 [08:38<18:21, 16.69s/it]Running generate_until requests:  35%|███▌      | 35/100 [08:51<16:53, 15.59s/it]Running generate_until requests:  36%|███▌      | 36/100 [09:03<15:34, 14.60s/it]Running generate_until requests:  37%|███▋      | 37/100 [09:15<14:27, 13.77s/it]Running generate_until requests:  38%|███▊      | 38/100 [09:29<14:10, 13.71s/it]Running generate_until requests:  39%|███▉      | 39/100 [09:46<15:09, 14.92s/it]Running generate_until requests:  40%|████      | 40/100 [09:59<14:15, 14.25s/it]Running generate_until requests:  41%|████      | 41/100 [10:17<14:59, 15.25s/it]Running generate_until requests:  42%|████▏     | 42/100 [10:28<13:44, 14.21s/it]Running generate_until requests:  43%|████▎     | 43/100 [10:41<12:57, 13.65s/it]Running generate_until requests:  44%|████▍     | 44/100 [10:54<12:42, 13.62s/it]Running generate_until requests:  45%|████▌     | 45/100 [11:06<11:59, 13.08s/it]Running generate_until requests:  46%|████▌     | 46/100 [11:24<13:03, 14.50s/it]Running generate_until requests:  47%|████▋     | 47/100 [11:41<13:32, 15.34s/it]Running generate_until requests:  48%|████▊     | 48/100 [11:54<12:44, 14.70s/it]Running generate_until requests:  49%|████▉     | 49/100 [12:06<11:45, 13.84s/it]Running generate_until requests:  50%|█████     | 50/100 [12:20<11:26, 13.72s/it]Running generate_until requests:  51%|█████     | 51/100 [12:32<10:46, 13.20s/it]Running generate_until requests:  52%|█████▏    | 52/100 [12:48<11:25, 14.27s/it]Running generate_until requests:  53%|█████▎    | 53/100 [13:01<10:44, 13.71s/it]Running generate_until requests:  54%|█████▍    | 54/100 [13:13<10:02, 13.09s/it]Running generate_until requests:  55%|█████▌    | 55/100 [13:30<10:44, 14.31s/it]Running generate_until requests:  56%|█████▌    | 56/100 [13:41<09:55, 13.54s/it]Running generate_until requests:  57%|█████▋    | 57/100 [13:58<10:18, 14.38s/it]Running generate_until requests:  58%|█████▊    | 58/100 [14:12<10:01, 14.32s/it]Running generate_until requests:  59%|█████▉    | 59/100 [14:29<10:21, 15.15s/it]Running generate_until requests:  60%|██████    | 60/100 [14:47<10:44, 16.10s/it]Running generate_until requests:  61%|██████    | 61/100 [15:04<10:30, 16.17s/it]Running generate_until requests:  62%|██████▏   | 62/100 [15:16<09:34, 15.12s/it]Running generate_until requests:  63%|██████▎   | 63/100 [15:28<08:43, 14.16s/it]Running generate_until requests:  64%|██████▍   | 64/100 [15:40<08:03, 13.43s/it]Running generate_until requests:  65%|██████▌   | 65/100 [15:58<08:34, 14.70s/it]Running generate_until requests:  66%|██████▌   | 66/100 [16:16<09:00, 15.90s/it]Running generate_until requests:  67%|██████▋   | 67/100 [16:35<09:14, 16.80s/it]Running generate_until requests:  68%|██████▊   | 68/100 [16:53<09:06, 17.07s/it]Running generate_until requests:  69%|██████▉   | 69/100 [17:11<08:55, 17.28s/it]Running generate_until requests:  70%|███████   | 70/100 [17:25<08:13, 16.44s/it]Running generate_until requests:  71%|███████   | 71/100 [17:44<08:13, 17.01s/it]Running generate_until requests:  72%|███████▏  | 72/100 [18:01<08:01, 17.21s/it]Running generate_until requests:  73%|███████▎  | 73/100 [18:13<07:00, 15.57s/it]Running generate_until requests:  74%|███████▍  | 74/100 [18:31<07:01, 16.20s/it]Running generate_until requests:  75%|███████▌  | 75/100 [18:43<06:14, 14.98s/it]Running generate_until requests:  76%|███████▌  | 76/100 [18:56<05:43, 14.32s/it]Running generate_until requests:  77%|███████▋  | 77/100 [19:07<05:12, 13.58s/it]Running generate_until requests:  78%|███████▊  | 78/100 [19:19<04:42, 12.85s/it]Running generate_until requests:  79%|███████▉  | 79/100 [19:36<04:57, 14.14s/it]Running generate_until requests:  80%|████████  | 80/100 [19:50<04:43, 14.17s/it]Running generate_until requests:  81%|████████  | 81/100 [20:12<05:16, 16.66s/it]Running generate_until requests:  82%|████████▏ | 82/100 [20:31<05:11, 17.29s/it]Running generate_until requests:  83%|████████▎ | 83/100 [20:45<04:35, 16.22s/it]Running generate_until requests:  84%|████████▍ | 84/100 [20:59<04:07, 15.44s/it]Running generate_until requests:  85%|████████▌ | 85/100 [21:12<03:41, 14.79s/it]Running generate_until requests:  86%|████████▌ | 86/100 [21:29<03:37, 15.54s/it]Running generate_until requests:  87%|████████▋ | 87/100 [21:43<03:14, 14.95s/it]Running generate_until requests:  88%|████████▊ | 88/100 [21:56<02:54, 14.57s/it]Running generate_until requests:  89%|████████▉ | 89/100 [22:16<02:56, 16.08s/it]Running generate_until requests:  90%|█████████ | 90/100 [22:27<02:26, 14.67s/it]Running generate_until requests:  91%|█████████ | 91/100 [22:36<01:56, 12.90s/it]Running generate_until requests:  92%|█████████▏| 92/100 [22:44<01:32, 11.51s/it]Running generate_until requests:  93%|█████████▎| 93/100 [22:56<01:19, 11.40s/it]Running generate_until requests:  94%|█████████▍| 94/100 [23:03<01:02, 10.36s/it]Running generate_until requests:  95%|█████████▌| 95/100 [23:10<00:45,  9.15s/it]Running generate_until requests:  96%|█████████▌| 96/100 [23:21<00:38,  9.70s/it]Running generate_until requests:  97%|█████████▋| 97/100 [23:25<00:24,  8.15s/it]Running generate_until requests:  98%|█████████▊| 98/100 [23:34<00:16,  8.38s/it]Running generate_until requests:  99%|█████████▉| 99/100 [23:43<00:08,  8.46s/it]Running generate_until requests: 100%|██████████| 100/100 [23:47<00:00,  7.18s/it]Running generate_until requests: 100%|██████████| 100/100 [23:47<00:00, 14.28s/it]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:0'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}
full model:
{'fda': {'alias': 'fda', 'contains,none': np.float64(0.87), 'contains_stderr,none': 'N/A'}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.21659225770002863
0.3676799923890141
0.7718276709674655
0.684178265870135
0.5285482451872934
0.273816514287302
0.7566340923804737
0.4195302615712732
0.7048918175177445
0.8024335694665047
0.2596571673087474
0.2906758673048459
0.6559956854150746
0.2288937672529506
0.2941846927212091
0.14545644431597915
0.27237013713290037
0.1954083722558289
0.191889756656264
0.3231769309584375
0.763391177198558
0.7591908569872912
0.47699609290977873
0.24147181909203896
0.6276241833035655
0.5039903698909594
0.506775271104323
0.17806387173399968
0.3609346134453604
0.21659225770002863
0.3676799923890141
0.7718276709674655
0.684178265870135
0.5285482451872934
0.273816514287302
0.7566340923804737
0.4195302615712732
0.7048918175177445
0.8024335694665047
0.2596571673087474
0.2906758673048459
0.6559956854150746
0.2288937672529506
0.2941846927212091
0.14545644431597915
0.27237013713290037
0.1954083722558289
0.191889756656264
0.3231769309584375
0.763391177198558
0.7591908569872912
0.47699609290977873
0.24147181909203896
0.6276241833035655
0.5039903698909594
0.506775271104323
0.17806387173399968
0.3609346134453604
0.21659225770002863
0.3676799923890141
0.7718276709674655
0.684178265870135
0.5285482451872934
0.273816514287302
0.7566340923804737
0.4195302615712732
0.7048918175177445
0.8024335694665047
0.2596571673087474
0.2906758673048459
0.6559956854150746
0.2288937672529506
0.2941846927212091
0.14545644431597915
0.27237013713290037
Total groups 70 exceeded the threshold, stopping comparison.
The group tensor is
[6, 2, 7, 0, 5, 1, 4, 3]
tensor([6, 2, 7, 0, 5, 1, 4, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 0, 1, 5, 2, 7, 6, 3]
tensor([4, 0, 1, 5, 2, 7, 6, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[1, 0, 4, 2, 6, 3, 7, 5]
tensor([1, 0, 4, 2, 6, 3, 7, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 0, 6, 3, 5, 1, 4, 2]
tensor([7, 0, 6, 3, 5, 1, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 0, 2, 5, 1, 1, 4]
tensor([0, 3, 0, 2, 5, 1, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 3, 1, 4, 1, 5, 2, 0]
tensor([0, 3, 1, 4, 1, 5, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
done!
Normal merging for layer 2
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([2])
tensor(2)
tensor([7])
tensor(7)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
done!
Normal merging for layer 3
tensor([1])
tensor(1)
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 4 to 11
done!
Normal merging for layer 12
tensor([0, 2])
tensor(0)
tensor([5, 6])
tensor(5)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([4])
tensor(4)
done!
Normal merging for layer 13
tensor([0, 7])
tensor(0)
tensor([2, 4])
tensor(2)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
done!
Cross-layer merge completed for layers 14 to 31
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 25 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 11.8828 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 24 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

178
cuda:0
wnli
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:59<00:59, 59.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:19<00:00, 36.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:19<00:00, 39.70s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/wnli?recursive=False&expand=False HTTP/1.1" 307 141
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/wnli?recursive=False&expand=False HTTP/1.1" 200 352
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140438521820368 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140438521820368 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140438521820368 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140438521820368 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140437582883744 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140437582883744 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140437582883744 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140437582883744 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2641.11it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:01<03:47,  1.61s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:02<01:37,  1.42it/s]Running loglikelihood requests:   4%|▎         | 5/142 [00:03<01:13,  1.86it/s]Running loglikelihood requests:   5%|▍         | 7/142 [00:03<01:03,  2.12it/s]Running loglikelihood requests:   6%|▋         | 9/142 [00:04<00:57,  2.31it/s]Running loglikelihood requests:   8%|▊         | 11/142 [00:05<00:53,  2.45it/s]Running loglikelihood requests:   9%|▉         | 13/142 [00:06<00:50,  2.56it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:06<00:47,  2.68it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:07<00:45,  2.76it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:08<00:43,  2.81it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:08<00:41,  2.88it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:09<00:40,  2.96it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:10<00:38,  3.02it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:10<00:37,  3.07it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:11<00:36,  3.11it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:11<00:35,  3.11it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:12<00:34,  3.18it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:13<00:33,  3.24it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:13<00:32,  3.27it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:14<00:31,  3.31it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:14<00:30,  3.33it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:15<00:29,  3.36it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:16<00:28,  3.40it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:16<00:28,  3.39it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:17<00:27,  3.42it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:17<00:26,  3.46it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:18<00:25,  3.51it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:18<00:24,  3.56it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:19<00:23,  3.60it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:19<00:22,  3.63it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:20<00:22,  3.64it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:21<00:21,  3.66it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:21<00:20,  3.67it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:22<00:20,  3.68it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:22<00:19,  3.70it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:23<00:19,  3.71it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:23<00:18,  3.73it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [00:24<00:17,  3.74it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [00:24<00:17,  3.75it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [00:25<00:16,  3.77it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [00:25<00:16,  3.78it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [00:26<00:15,  3.79it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [00:26<00:15,  3.79it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [00:27<00:14,  3.81it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [00:27<00:13,  3.82it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [00:28<00:13,  3.82it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [00:28<00:12,  3.83it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [00:29<00:12,  3.83it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [00:29<00:11,  3.84it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [00:30<00:11,  3.85it/s]Running loglikelihood requests:  71%|███████   | 101/142 [00:31<00:10,  3.86it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [00:31<00:10,  3.87it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [00:32<00:09,  3.89it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [00:32<00:08,  3.91it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [00:33<00:08,  3.92it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [00:33<00:07,  3.94it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [00:34<00:07,  3.95it/s]Running loglikelihood requests:  81%|████████  | 115/142 [00:34<00:06,  3.96it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [00:35<00:06,  3.96it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [00:35<00:05,  3.98it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [00:36<00:05,  3.98it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [00:36<00:04,  3.99it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [00:37<00:04,  4.01it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [00:37<00:03,  4.02it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [00:38<00:03,  3.93it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [00:38<00:02,  3.96it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [00:39<00:02,  4.00it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [00:39<00:01,  4.04it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [00:40<00:01,  4.08it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [00:40<00:00,  4.11it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [00:40<00:00,  4.16it/s]Running loglikelihood requests: 100%|██████████| 142/142 [00:40<00:00,  3.46it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:1'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:1'}
full model:
{'wnli': {'alias': 'wnli', 'acc,none': 0.5352112676056338, 'acc_stderr,none': 0.0596130578497224}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.31190044950254875
0.7306280553786256
0.6985925052465822
0.5843516732063875
0.8124235844589114
0.820438203921003
0.6253838264581936
0.7600037006947045
0.8225872978677496
0.708398461303215
0.8646089269479391
0.8239362351853257
0.7608099850331435
0.6657423857513638
0.7943257460202938
0.7511476003698512
0.9073696655228775
0.8741838353767599
0.7945799099309127
0.9323691001541556
0.865243808509542
0.8176606226311932
0.6785099625983169
0.9579534328203848
0.788928884938056
0.9833718962298513
0.5933012307657521
0.7829988799240639
0.7823073743206628
0.31190044950254875
0.7306280553786256
0.6985925052465822
0.5843516732063875
0.8124235844589114
0.820438203921003
0.6253838264581936
0.7600037006947045
0.8225872978677496
0.708398461303215
0.8646089269479391
0.8239362351853257
0.7608099850331435
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[7, 4, 5, 1, 6, 3, 2, 0]
tensor([7, 4, 5, 1, 6, 3, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 2, 4, 5, 6, 1, 0, 3]
tensor([7, 2, 4, 5, 6, 1, 0, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 7, 5, 4, 1, 2, 0]
tensor([6, 3, 7, 5, 4, 1, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 3, 6, 4, 7, 1, 2, 0]
tensor([5, 3, 6, 4, 7, 1, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 3, 6, 5, 7, 2, 1, 0]
tensor([4, 3, 6, 5, 7, 2, 1, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1, 2, 3, 2, 3, 0]
tensor([0, 1, 1, 2, 3, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 1, 2, 2, 3, 0, 3, 1]
tensor([0, 1, 2, 2, 3, 0, 3, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 1, 1, 1.0, 1.0, 1.0, 1.0]
tensor([0, 0, 1, 1, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
Normal merging for layer 1
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
done!
Normal merging for layer 2
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
tensor([3])
tensor(3)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Normal merging for layer 4
tensor([7])
tensor(7)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 5 to 15
done!
Normal merging for layer 16
tensor([0, 7])
tensor(0)
tensor([1, 2])
tensor(1)
tensor([3, 5])
tensor(3)
tensor([4, 6])
tensor(4)
done!
Normal merging for layer 17
tensor([0, 5])
tensor(0)
tensor([1, 7])
tensor(1)
tensor([2, 3])
tensor(2)
tensor([4, 6])
tensor(4)
done!
Cross-layer merge completed for layers 18 to 30
done!
Normal merging for layer 31
tensor([0, 1])
tensor(0)
tensor([2, 3, 4, 5, 6, 7])
tensor(2)
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 24 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.2608 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 23 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

117
cuda:1
coqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:54<00:54, 54.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 32.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 35.98s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa HTTP/1.1" 200 857
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/EleutherAI/coqa/EleutherAI/coqa.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa HTTP/1.1" 200 857
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/coqa/resolve/82e11af842af6c1396f5e9a5c7de260107c50cf1/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa/revision/82e11af842af6c1396f5e9a5c7de260107c50cf1 HTTP/1.1" 200 857
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa/tree/82e11af842af6c1396f5e9a5c7de260107c50cf1?recursive=False&expand=False HTTP/1.1" 200 489
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa/tree/82e11af842af6c1396f5e9a5c7de260107c50cf1/data?recursive=False&expand=False HTTP/1.1" 404 79
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa/tree/82e11af842af6c1396f5e9a5c7de260107c50cf1/data?recursive=False&expand=False HTTP/1.1" 404 79
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa/revision/82e11af842af6c1396f5e9a5c7de260107c50cf1 HTTP/1.1" 200 857
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/coqa/resolve/82e11af842af6c1396f5e9a5c7de260107c50cf1/dataset_infos.json HTTP/1.1" 200 0
DEBUG:filelock:Attempting to acquire lock 140431342050704 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___coqa_default_0.0.0_82e11af842af6c1396f5e9a5c7de260107c50cf1.lock
DEBUG:filelock:Lock 140431342050704 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___coqa_default_0.0.0_82e11af842af6c1396f5e9a5c7de260107c50cf1.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1/dataset_info.json
DEBUG:filelock:Attempting to release lock 140431342050704 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___coqa_default_0.0.0_82e11af842af6c1396f5e9a5c7de260107c50cf1.lock
DEBUG:filelock:Lock 140431342050704 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___coqa_default_0.0.0_82e11af842af6c1396f5e9a5c7de260107c50cf1.lock
DEBUG:filelock:Attempting to acquire lock 140431074580656 on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1_builder.lock
DEBUG:filelock:Lock 140431074580656 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1/dataset_info.json
DEBUG:filelock:Attempting to release lock 140431074580656 on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1_builder.lock
DEBUG:filelock:Lock 140431074580656 released on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
DEBUG:lm_eval.api.task:doc_to_target returned a list. Assuming multiple targets.
INFO:lm_eval.evaluator:coqa: Using gen_kwargs: {'until': ['\nQ:']}
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of coqa from None to 0
INFO:lm_eval.api.task:Building contexts for coqa on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 74485.95it/s]
DEBUG:lm_eval.evaluator:Task: coqa; number of requests on this rank: 100
INFO:lm_eval.evaluator:Running generate_until requests
Running generate_until requests:   0%|          | 0/100 [00:00<?, ?it/s]Running generate_until requests:   1%|          | 1/100 [00:06<09:58,  6.04s/it]Running generate_until requests:   2%|▏         | 2/100 [00:11<09:09,  5.61s/it]Running generate_until requests:   3%|▎         | 3/100 [00:17<09:32,  5.90s/it]Running generate_until requests:   4%|▍         | 4/100 [00:22<08:53,  5.56s/it]Running generate_until requests:   5%|▌         | 5/100 [00:27<08:40,  5.48s/it]Running generate_until requests:   6%|▌         | 6/100 [00:32<08:17,  5.30s/it]Running generate_until requests:   7%|▋         | 7/100 [00:38<08:30,  5.49s/it]Running generate_until requests:   8%|▊         | 8/100 [00:43<08:07,  5.30s/it]Running generate_until requests:   9%|▉         | 9/100 [00:48<08:00,  5.29s/it]Running generate_until requests:  10%|█         | 10/100 [00:54<08:07,  5.42s/it]Running generate_until requests:  11%|█         | 11/100 [01:00<08:00,  5.39s/it]Running generate_until requests:  12%|█▏        | 12/100 [01:06<08:21,  5.70s/it]Running generate_until requests:  13%|█▎        | 13/100 [01:11<07:47,  5.38s/it]Running generate_until requests:  14%|█▍        | 14/100 [01:15<07:22,  5.15s/it]Running generate_until requests:  15%|█▌        | 15/100 [01:20<07:10,  5.07s/it]Running generate_until requests:  16%|█▌        | 16/100 [01:25<06:53,  4.92s/it]Running generate_until requests:  17%|█▋        | 17/100 [01:29<06:42,  4.85s/it]Running generate_until requests:  18%|█▊        | 18/100 [01:34<06:26,  4.72s/it]Running generate_until requests:  19%|█▉        | 19/100 [01:38<06:21,  4.70s/it]Running generate_until requests:  20%|██        | 20/100 [01:43<06:11,  4.64s/it]Running generate_until requests:  21%|██        | 21/100 [01:48<06:07,  4.65s/it]Running generate_until requests:  22%|██▏       | 22/100 [01:52<06:00,  4.62s/it]Running generate_until requests:  23%|██▎       | 23/100 [01:58<06:17,  4.91s/it]Running generate_until requests:  24%|██▍       | 24/100 [02:03<06:25,  5.07s/it]Running generate_until requests:  25%|██▌       | 25/100 [02:08<06:07,  4.90s/it]Running generate_until requests:  26%|██▌       | 26/100 [02:12<06:01,  4.88s/it]Running generate_until requests:  27%|██▋       | 27/100 [02:17<05:55,  4.87s/it]Running generate_until requests:  28%|██▊       | 28/100 [02:22<05:47,  4.83s/it]Running generate_until requests:  29%|██▉       | 29/100 [02:27<05:40,  4.79s/it]Running generate_until requests:  30%|███       | 30/100 [02:32<05:36,  4.80s/it]Running generate_until requests:  31%|███       | 31/100 [02:36<05:20,  4.64s/it]Running generate_until requests:  32%|███▏      | 32/100 [02:41<05:20,  4.71s/it]Running generate_until requests:  33%|███▎      | 33/100 [02:45<05:15,  4.71s/it]Running generate_until requests:  34%|███▍      | 34/100 [02:50<05:07,  4.67s/it]Running generate_until requests:  35%|███▌      | 35/100 [02:54<04:54,  4.52s/it]Running generate_until requests:  36%|███▌      | 36/100 [03:00<05:13,  4.90s/it]Running generate_until requests:  37%|███▋      | 37/100 [03:04<04:54,  4.67s/it]Running generate_until requests:  38%|███▊      | 38/100 [03:08<04:39,  4.51s/it]Running generate_until requests:  39%|███▉      | 39/100 [03:13<04:32,  4.47s/it]Running generate_until requests:  40%|████      | 40/100 [03:17<04:22,  4.37s/it]Running generate_until requests:  41%|████      | 41/100 [03:21<04:18,  4.38s/it]Running generate_until requests:  42%|████▏     | 42/100 [03:27<04:34,  4.73s/it]Running generate_until requests:  43%|████▎     | 43/100 [03:31<04:23,  4.61s/it]Running generate_until requests:  44%|████▍     | 44/100 [03:36<04:18,  4.61s/it]Running generate_until requests:  45%|████▌     | 45/100 [03:40<04:11,  4.57s/it]Running generate_until requests:  46%|████▌     | 46/100 [03:44<03:58,  4.42s/it]Running generate_until requests:  47%|████▋     | 47/100 [03:48<03:48,  4.30s/it]Running generate_until requests:  48%|████▊     | 48/100 [03:53<03:47,  4.38s/it]Running generate_until requests:  49%|████▉     | 49/100 [03:58<03:53,  4.58s/it]Running generate_until requests:  50%|█████     | 50/100 [04:02<03:40,  4.40s/it]Running generate_until requests:  51%|█████     | 51/100 [04:07<03:45,  4.60s/it]Running generate_until requests:  52%|█████▏    | 52/100 [04:11<03:31,  4.40s/it]Running generate_until requests:  53%|█████▎    | 53/100 [04:15<03:29,  4.47s/it]Running generate_until requests:  54%|█████▍    | 54/100 [04:19<03:17,  4.30s/it]Running generate_until requests:  55%|█████▌    | 55/100 [04:24<03:14,  4.31s/it]Running generate_until requests:  56%|█████▌    | 56/100 [04:28<03:15,  4.43s/it]Running generate_until requests:  57%|█████▋    | 57/100 [04:33<03:10,  4.44s/it]Running generate_until requests:  58%|█████▊    | 58/100 [04:37<03:00,  4.30s/it]Running generate_until requests:  59%|█████▉    | 59/100 [04:42<03:08,  4.59s/it]Running generate_until requests:  60%|██████    | 60/100 [04:46<02:55,  4.38s/it]Running generate_until requests:  61%|██████    | 61/100 [04:51<02:57,  4.55s/it]Running generate_until requests:  62%|██████▏   | 62/100 [04:56<02:57,  4.66s/it]Running generate_until requests:  63%|██████▎   | 63/100 [05:00<02:43,  4.41s/it]Running generate_until requests:  64%|██████▍   | 64/100 [05:03<02:32,  4.23s/it]Running generate_until requests:  65%|██████▌   | 65/100 [05:07<02:23,  4.09s/it]Running generate_until requests:  66%|██████▌   | 66/100 [05:11<02:15,  3.99s/it]Running generate_until requests:  67%|██████▋   | 67/100 [05:15<02:09,  3.92s/it]Running generate_until requests:  68%|██████▊   | 68/100 [05:19<02:09,  4.05s/it]Running generate_until requests:  69%|██████▉   | 69/100 [05:25<02:21,  4.56s/it]Running generate_until requests:  70%|███████   | 70/100 [05:29<02:13,  4.45s/it]Running generate_until requests:  71%|███████   | 71/100 [05:38<02:44,  5.66s/it]Running generate_until requests:  72%|███████▏  | 72/100 [05:41<02:21,  5.05s/it]Running generate_until requests:  73%|███████▎  | 73/100 [05:45<02:05,  4.66s/it]Running generate_until requests:  74%|███████▍  | 74/100 [05:49<01:56,  4.48s/it]Running generate_until requests:  75%|███████▌  | 75/100 [05:53<01:45,  4.24s/it]Running generate_until requests:  76%|███████▌  | 76/100 [05:56<01:36,  4.03s/it]Running generate_until requests:  77%|███████▋  | 77/100 [06:01<01:38,  4.26s/it]Running generate_until requests:  78%|███████▊  | 78/100 [06:05<01:30,  4.13s/it]Running generate_until requests:  79%|███████▉  | 79/100 [06:08<01:22,  3.94s/it]Running generate_until requests:  80%|████████  | 80/100 [06:12<01:19,  3.96s/it]Running generate_until requests:  81%|████████  | 81/100 [06:18<01:26,  4.54s/it]Running generate_until requests:  82%|████████▏ | 82/100 [06:22<01:15,  4.22s/it]Running generate_until requests:  83%|████████▎ | 83/100 [06:26<01:09,  4.11s/it]Running generate_until requests:  84%|████████▍ | 84/100 [06:29<01:02,  3.92s/it]Running generate_until requests:  85%|████████▌ | 85/100 [06:32<00:56,  3.76s/it]Running generate_until requests:  86%|████████▌ | 86/100 [06:36<00:52,  3.72s/it]Running generate_until requests:  87%|████████▋ | 87/100 [06:41<00:51,  3.98s/it]Running generate_until requests:  88%|████████▊ | 88/100 [06:44<00:46,  3.89s/it]Running generate_until requests:  89%|████████▉ | 89/100 [06:47<00:40,  3.67s/it]Running generate_until requests:  90%|█████████ | 90/100 [06:50<00:34,  3.48s/it]Running generate_until requests:  91%|█████████ | 91/100 [06:53<00:29,  3.30s/it]Running generate_until requests:  92%|█████████▏| 92/100 [06:56<00:25,  3.19s/it]Running generate_until requests:  93%|█████████▎| 93/100 [06:59<00:22,  3.15s/it]Running generate_until requests:  94%|█████████▍| 94/100 [07:02<00:18,  3.14s/it]Running generate_until requests:  95%|█████████▌| 95/100 [07:06<00:15,  3.20s/it]Running generate_until requests:  96%|█████████▌| 96/100 [07:09<00:12,  3.19s/it]Running generate_until requests:  97%|█████████▋| 97/100 [07:12<00:09,  3.02s/it]Running generate_until requests:  98%|█████████▊| 98/100 [07:14<00:05,  2.89s/it]Running generate_until requests:  99%|█████████▉| 99/100 [07:17<00:02,  2.87s/it]Running generate_until requests: 100%|██████████| 100/100 [07:20<00:00,  2.87s/it]Running generate_until requests: 100%|██████████| 100/100 [07:20<00:00,  4.40s/it]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:2'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:2'}
full model:
{'coqa': {'alias': 'coqa', 'em,none': 0.595, 'em_stderr,none': 0.044774970461162564, 'f1,none': 0.7211574141733987, 'f1_stderr,none': 0.037128235455690536}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.6057853926542468
0.4195568875297668
0.5244744113321889
0.5202703028806769
0.6150870974034927
0.5299634576457063
0.9336763524510373
0.23649940737178063
0.388911200696845
0.6478041116722705
0.5517233675449297
0.6723258763091353
0.7175526480521238
0.8411089149883405
0.7404554224148189
0.26376935916880817
0.9373006475493478
0.5360566853939598
0.38729358133282565
0.4541602442018795
0.8623573205888978
0.7318340566806717
0.6643209906079897
0.8122565195147101
0.4707270481319977
0.9785001455445378
0.17075087907531752
0.489625917805058
0.7595051272431785
0.6057853926542468
0.4195568875297668
0.5244744113321889
0.5202703028806769
0.6150870974034927
0.5299634576457063
0.9336763524510373
0.23649940737178063
0.388911200696845
0.6478041116722705
0.5517233675449297
0.6723258763091353
0.7175526480521238
0.8411089149883405
0.7404554224148189
0.26376935916880817
0.9373006475493478
0.5360566853939598
0.38729358133282565
0.4541602442018795
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[5, 4, 3, 2, 0, 1, 7, 6]
tensor([5, 4, 3, 2, 0, 1, 7, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 3, 4, 0, 2, 1, 7, 6]
tensor([5, 3, 4, 0, 2, 1, 7, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 1, 7, 0, 6, 2, 3, 4]
tensor([5, 1, 7, 0, 6, 2, 3, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 3, 6, 0, 5, 2, 4, 1]
tensor([7, 3, 6, 0, 5, 2, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 5, 7, 2, 4, 0, 3, 1]
tensor([6, 5, 7, 2, 4, 0, 3, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 5, 0, 0, 1, 2, 1, 3]
tensor([4, 5, 0, 0, 1, 2, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1, 2, 2, 0, 3, 3]
tensor([0, 1, 1, 2, 2, 0, 3, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([7])
tensor(7)
tensor([6])
tensor(6)
done!
Normal merging for layer 2
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
done!
Normal merging for layer 4
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Cross-layer merge completed for layers 5 to 8
done!
Normal merging for layer 9
tensor([2, 3])
tensor(2)
tensor([4, 6])
tensor(4)
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([1])
tensor(1)
done!
Cross-layer merge completed for layers 10 to 22
done!
Normal merging for layer 23
tensor([0, 5])
tensor(0)
tensor([1, 2])
tensor(1)
tensor([3, 4])
tensor(3)
tensor([6, 7])
tensor(6)
done!
Cross-layer merge completed for layers 24 to 31
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 23 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.3238 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 22 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

137
cuda:2
rte
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:56<00:56, 56.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:12<00:00, 32.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:12<00:00, 36.46s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: rte] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: rte] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:filelock:Attempting to acquire lock 140438522133872 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140438522133872 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140438522133872 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140438522133872 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140430435586592 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140430435586592 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430435586592 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140430435586592 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of rte from None to 0
INFO:lm_eval.api.task:Building contexts for rte on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 2576.97it/s]
DEBUG:lm_eval.evaluator:Task: rte; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:02<07:04,  2.13s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:03<03:36,  1.10s/it]Running loglikelihood requests:   2%|▎         | 5/200 [00:04<02:49,  1.15it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:06<02:27,  1.31it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:07<02:15,  1.41it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:08<02:06,  1.49it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:09<02:01,  1.54it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:10<01:56,  1.59it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:12<01:52,  1.62it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:13<01:49,  1.65it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:14<01:45,  1.69it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:15<01:42,  1.72it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:16<01:40,  1.75it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:17<01:36,  1.78it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:18<01:34,  1.82it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:19<01:31,  1.84it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:20<01:29,  1.86it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:21<01:27,  1.88it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:22<01:26,  1.88it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:24<01:24,  1.90it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:25<01:22,  1.92it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:26<01:20,  1.95it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:26<01:18,  1.99it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:27<01:15,  2.03it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:28<01:12,  2.07it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:29<01:11,  2.10it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:30<01:07,  2.17it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:31<01:04,  2.23it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:32<01:02,  2.29it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:33<01:00,  2.34it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:33<00:58,  2.38it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:34<00:56,  2.41it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:35<00:55,  2.44it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:36<00:53,  2.46it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:37<00:52,  2.49it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:37<00:51,  2.51it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:38<00:50,  2.53it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:39<00:48,  2.55it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:40<00:47,  2.58it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:40<00:46,  2.61it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:41<00:45,  2.61it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:42<00:44,  2.63it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:43<00:43,  2.66it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:43<00:42,  2.68it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:44<00:41,  2.70it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:45<00:39,  2.73it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:46<00:38,  2.75it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:46<00:37,  2.77it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:47<00:36,  2.79it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:48<00:36,  2.80it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:48<00:35,  2.82it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:49<00:34,  2.83it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:50<00:33,  2.84it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:50<00:32,  2.86it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:51<00:31,  2.87it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:52<00:30,  2.89it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:52<00:30,  2.90it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:53<00:29,  2.90it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:54<00:28,  2.90it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:55<00:27,  2.91it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:55<00:27,  2.91it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:56<00:26,  2.93it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:57<00:25,  2.94it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [00:57<00:24,  2.95it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [00:58<00:24,  2.95it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [00:59<00:23,  2.96it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [00:59<00:22,  2.97it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [01:00<00:21,  3.00it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [01:01<00:21,  3.00it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [01:01<00:20,  2.99it/s]Running loglikelihood requests:  70%|███████   | 141/200 [01:02<00:19,  3.01it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [01:03<00:18,  3.03it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [01:03<00:18,  3.04it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [01:04<00:17,  3.05it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [01:05<00:16,  3.07it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [01:05<00:16,  3.02it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [01:06<00:15,  3.04it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [01:06<00:14,  3.04it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [01:07<00:14,  3.03it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [01:08<00:13,  3.08it/s]Running loglikelihood requests:  80%|████████  | 161/200 [01:08<00:12,  3.12it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [01:09<00:11,  3.14it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [01:10<00:11,  3.15it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [01:10<00:10,  3.18it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [01:11<00:09,  3.20it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [01:11<00:08,  3.24it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [01:12<00:08,  3.26it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [01:13<00:07,  3.28it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [01:13<00:06,  3.29it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [01:14<00:06,  3.30it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [01:15<00:05,  3.31it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [01:15<00:05,  3.33it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [01:16<00:04,  3.34it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [01:16<00:03,  3.35it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [01:17<00:03,  3.37it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [01:17<00:02,  3.38it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [01:18<00:02,  3.40it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:19<00:01,  3.42it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:19<00:00,  3.49it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:20<00:00,  3.56it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:20<00:00,  2.49it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:3'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:3'}
full model:
{'rte': {'alias': 'rte', 'acc,none': 0.5, 'acc_stderr,none': 0.050251890762960605}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.34161229456626735
0.905233410256777
0.5205040718697735
0.4121994254524892
0.7398116665887099
0.6225415196831932
0.7923970242263771
0.7353888240887675
0.6535613357308766
0.7757058271862038
0.734046359122903
0.4471799126982846
0.773619360921301
0.7955347039939479
0.8672068064531693
0.8652880343596522
0.3302235467760883
0.6789268064017625
0.6072221471952108
0.9194446824778495
0.4812004589187253
0.5728915095234594
0.1682455054057436
0.93212414632396
0.9148362604533635
0.8268537756297094
0.7592245907029287
0.7256008379011685
0.7109756105942956
0.34161229456626735
0.905233410256777
0.5205040718697735
0.4121994254524892
0.7398116665887099
0.6225415196831932
0.7923970242263771
0.7353888240887675
0.6535613357308766
0.7757058271862038
0.734046359122903
0.4471799126982846
0.773619360921301
0.7955347039939479
0.8672068064531693
0.8652880343596522
0.3302235467760883
0.6789268064017625
0.6072221471952108
0.9194446824778495
0.4812004589187253
Total groups 73 exceeded the threshold, stopping comparison.
The group tensor is
[5, 2, 7, 1, 6, 4, 3, 0]
tensor([5, 2, 7, 1, 6, 4, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 6, 0, 7, 3, 4, 1]
tensor([5, 2, 6, 0, 7, 3, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 7, 2, 5, 4, 3, 0]
tensor([6, 1, 7, 2, 5, 4, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 7, 2, 4, 1, 5, 0]
tensor([6, 3, 7, 2, 4, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 5, 6, 2, 3, 1, 4, 0]
tensor([7, 5, 6, 2, 3, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 2, 5, 4, 1, 0, 1, 3]
tensor([0, 2, 5, 4, 1, 0, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1.0, 1.0, 0, 1.0, 1]
tensor([0, 1, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
Normal merging for layer 1
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Normal merging for layer 2
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 4
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 5 to 8
done!
Normal merging for layer 9
tensor([0, 5])
tensor(0)
tensor([4, 6])
tensor(4)
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
done!
Cross-layer merge completed for layers 10 to 30
done!
Normal merging for layer 31
tensor([0, 5])
tensor(0)
tensor([1, 2, 3, 4, 6, 7])
tensor(1)
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 22 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.1348 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 21 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

19
cuda:3
sciq
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:54<00:54, 54.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 32.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 35.97s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq HTTP/1.1" 200 1237
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/sciq/sciq.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq HTTP/1.1" 200 1237
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/allenai/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/allenai/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:filelock:Attempting to acquire lock 140437043155584 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:filelock:Lock 140437043155584 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_info.json
DEBUG:filelock:Attempting to release lock 140437043155584 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:filelock:Lock 140437043155584 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:filelock:Attempting to acquire lock 140437580010112 on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:filelock:Lock 140437580010112 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_info.json
DEBUG:filelock:Attempting to release lock 140437580010112 on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:filelock:Lock 140437580010112 released on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of sciq from None to 0
INFO:lm_eval.api.task:Building contexts for sciq on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1037.21it/s]
DEBUG:lm_eval.evaluator:Task: sciq; number of requests on this rank: 400
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/400 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/400 [00:04<28:02,  4.22s/it]Running loglikelihood requests:   0%|          | 2/400 [00:07<25:24,  3.83s/it]Running loglikelihood requests:   1%|          | 3/400 [00:11<24:34,  3.72s/it]Running loglikelihood requests:   1%|          | 4/400 [00:14<23:50,  3.61s/it]Running loglikelihood requests:   1%|▏         | 5/400 [00:18<23:13,  3.53s/it]Running loglikelihood requests:   2%|▏         | 6/400 [00:21<22:44,  3.46s/it]Running loglikelihood requests:   2%|▏         | 7/400 [00:24<22:23,  3.42s/it]Running loglikelihood requests:   2%|▏         | 8/400 [00:28<22:11,  3.40s/it]Running loglikelihood requests:   2%|▏         | 9/400 [00:31<21:18,  3.27s/it]Running loglikelihood requests:   2%|▎         | 10/400 [00:34<20:42,  3.19s/it]Running loglikelihood requests:   3%|▎         | 11/400 [00:37<20:16,  3.13s/it]Running loglikelihood requests:   3%|▎         | 12/400 [00:40<19:57,  3.09s/it]Running loglikelihood requests:   3%|▎         | 13/400 [00:42<19:15,  2.99s/it]Running loglikelihood requests:   4%|▎         | 14/400 [00:45<18:48,  2.92s/it]Running loglikelihood requests:   4%|▍         | 15/400 [00:48<18:21,  2.86s/it]Running loglikelihood requests:   4%|▍         | 16/400 [00:51<18:02,  2.82s/it]Running loglikelihood requests:   4%|▍         | 17/400 [00:53<17:38,  2.76s/it]Running loglikelihood requests:   4%|▍         | 18/400 [00:56<17:20,  2.72s/it]Running loglikelihood requests:   5%|▍         | 19/400 [00:59<17:07,  2.70s/it]Running loglikelihood requests:   5%|▌         | 20/400 [01:01<17:01,  2.69s/it]Running loglikelihood requests:   5%|▌         | 21/400 [01:04<16:50,  2.67s/it]Running loglikelihood requests:   6%|▌         | 22/400 [01:06<16:42,  2.65s/it]Running loglikelihood requests:   6%|▌         | 23/400 [01:09<16:32,  2.63s/it]Running loglikelihood requests:   6%|▌         | 24/400 [01:12<16:20,  2.61s/it]Running loglikelihood requests:   6%|▋         | 25/400 [01:14<16:00,  2.56s/it]Running loglikelihood requests:   6%|▋         | 26/400 [01:16<15:45,  2.53s/it]Running loglikelihood requests:   7%|▋         | 27/400 [01:19<15:34,  2.50s/it]Running loglikelihood requests:   7%|▋         | 28/400 [01:21<15:24,  2.49s/it]Running loglikelihood requests:   7%|▋         | 29/400 [01:24<14:53,  2.41s/it]Running loglikelihood requests:   8%|▊         | 30/400 [01:26<14:31,  2.36s/it]Running loglikelihood requests:   8%|▊         | 31/400 [01:28<14:14,  2.32s/it]Running loglikelihood requests:   8%|▊         | 32/400 [01:30<14:00,  2.28s/it]Running loglikelihood requests:   8%|▊         | 33/400 [01:32<13:34,  2.22s/it]Running loglikelihood requests:   8%|▊         | 34/400 [01:34<13:10,  2.16s/it]Running loglikelihood requests:   9%|▉         | 35/400 [01:36<12:52,  2.12s/it]Running loglikelihood requests:   9%|▉         | 36/400 [01:38<12:40,  2.09s/it]Running loglikelihood requests:   9%|▉         | 37/400 [01:40<12:31,  2.07s/it]Running loglikelihood requests:  10%|▉         | 38/400 [01:42<12:25,  2.06s/it]Running loglikelihood requests:  10%|█         | 40/400 [01:45<09:27,  1.58s/it]Running loglikelihood requests:  10%|█         | 41/400 [01:46<09:52,  1.65s/it]Running loglikelihood requests:  10%|█         | 42/400 [01:48<10:12,  1.71s/it]Running loglikelihood requests:  11%|█         | 43/400 [01:50<10:29,  1.76s/it]Running loglikelihood requests:  11%|█         | 44/400 [01:52<10:39,  1.80s/it]Running loglikelihood requests:  11%|█▏        | 45/400 [01:54<10:39,  1.80s/it]Running loglikelihood requests:  12%|█▏        | 46/400 [01:56<10:38,  1.80s/it]Running loglikelihood requests:  12%|█▏        | 47/400 [01:57<10:38,  1.81s/it]Running loglikelihood requests:  12%|█▏        | 48/400 [01:59<10:34,  1.80s/it]Running loglikelihood requests:  12%|█▏        | 49/400 [02:01<10:29,  1.79s/it]Running loglikelihood requests:  12%|█▎        | 50/400 [02:03<10:24,  1.79s/it]Running loglikelihood requests:  13%|█▎        | 51/400 [02:05<10:21,  1.78s/it]Running loglikelihood requests:  13%|█▎        | 52/400 [02:06<10:18,  1.78s/it]Running loglikelihood requests:  13%|█▎        | 53/400 [02:08<09:57,  1.72s/it]Running loglikelihood requests:  14%|█▎        | 54/400 [02:10<09:42,  1.68s/it]Running loglikelihood requests:  14%|█▍        | 55/400 [02:11<09:34,  1.67s/it]Running loglikelihood requests:  14%|█▍        | 57/400 [02:13<07:09,  1.25s/it]Running loglikelihood requests:  14%|█▍        | 58/400 [02:14<07:30,  1.32s/it]Running loglikelihood requests:  15%|█▍        | 59/400 [02:16<07:46,  1.37s/it]Running loglikelihood requests:  16%|█▌        | 62/400 [02:17<05:08,  1.10it/s]Running loglikelihood requests:  16%|█▌        | 63/400 [02:19<05:49,  1.04s/it]Running loglikelihood requests:  16%|█▌        | 64/400 [02:20<06:26,  1.15s/it]Running loglikelihood requests:  16%|█▋        | 65/400 [02:22<06:50,  1.23s/it]Running loglikelihood requests:  16%|█▋        | 66/400 [02:23<07:09,  1.29s/it]Running loglikelihood requests:  17%|█▋        | 67/400 [02:25<07:23,  1.33s/it]Running loglikelihood requests:  17%|█▋        | 68/400 [02:26<07:33,  1.37s/it]Running loglikelihood requests:  17%|█▋        | 69/400 [02:28<07:38,  1.39s/it]Running loglikelihood requests:  18%|█▊        | 70/400 [02:29<07:41,  1.40s/it]Running loglikelihood requests:  18%|█▊        | 71/400 [02:30<07:43,  1.41s/it]Running loglikelihood requests:  18%|█▊        | 72/400 [02:32<07:46,  1.42s/it]Running loglikelihood requests:  18%|█▊        | 73/400 [02:33<07:44,  1.42s/it]Running loglikelihood requests:  18%|█▊        | 74/400 [02:35<07:42,  1.42s/it]Running loglikelihood requests:  19%|█▉        | 77/400 [02:36<04:45,  1.13it/s]Running loglikelihood requests:  20%|█▉        | 78/400 [02:37<05:17,  1.01it/s]Running loglikelihood requests:  20%|█▉        | 79/400 [02:39<05:44,  1.07s/it]Running loglikelihood requests:  20%|██        | 81/400 [02:40<04:47,  1.11it/s]Running loglikelihood requests:  20%|██        | 82/400 [02:41<05:11,  1.02it/s]Running loglikelihood requests:  21%|██        | 83/400 [02:43<05:31,  1.05s/it]Running loglikelihood requests:  21%|██        | 84/400 [02:44<05:49,  1.11s/it]Running loglikelihood requests:  21%|██▏       | 85/400 [02:45<05:59,  1.14s/it]Running loglikelihood requests:  22%|██▏       | 86/400 [02:46<06:06,  1.17s/it]Running loglikelihood requests:  22%|██▏       | 89/400 [02:48<03:55,  1.32it/s]Running loglikelihood requests:  22%|██▎       | 90/400 [02:49<04:24,  1.17it/s]Running loglikelihood requests:  23%|██▎       | 91/400 [02:50<04:49,  1.07it/s]Running loglikelihood requests:  23%|██▎       | 92/400 [02:51<05:10,  1.01s/it]Running loglikelihood requests:  23%|██▎       | 93/400 [02:53<05:26,  1.06s/it]Running loglikelihood requests:  24%|██▍       | 97/400 [02:54<03:04,  1.64it/s]Running loglikelihood requests:  24%|██▍       | 98/400 [02:55<03:35,  1.40it/s]Running loglikelihood requests:  25%|██▍       | 99/400 [02:56<04:04,  1.23it/s]Running loglikelihood requests:  25%|██▌       | 100/400 [02:57<04:29,  1.11it/s]Running loglikelihood requests:  25%|██▌       | 101/400 [02:59<04:50,  1.03it/s]Running loglikelihood requests:  26%|██▌       | 102/400 [03:00<05:06,  1.03s/it]Running loglikelihood requests:  26%|██▌       | 103/400 [03:01<05:19,  1.08s/it]Running loglikelihood requests:  26%|██▌       | 104/400 [03:02<05:28,  1.11s/it]Running loglikelihood requests:  26%|██▋       | 105/400 [03:03<05:35,  1.14s/it]Running loglikelihood requests:  26%|██▋       | 106/400 [03:05<05:37,  1.15s/it]Running loglikelihood requests:  27%|██▋       | 107/400 [03:06<05:41,  1.16s/it]Running loglikelihood requests:  27%|██▋       | 108/400 [03:07<05:43,  1.18s/it]Running loglikelihood requests:  27%|██▋       | 109/400 [03:08<05:42,  1.18s/it]Running loglikelihood requests:  28%|██▊       | 110/400 [03:09<05:41,  1.18s/it]Running loglikelihood requests:  28%|██▊       | 111/400 [03:10<05:40,  1.18s/it]Running loglikelihood requests:  28%|██▊       | 112/400 [03:12<05:39,  1.18s/it]Running loglikelihood requests:  28%|██▊       | 113/400 [03:13<05:37,  1.17s/it]Running loglikelihood requests:  28%|██▊       | 114/400 [03:14<05:35,  1.17s/it]Running loglikelihood requests:  29%|██▉       | 115/400 [03:15<05:33,  1.17s/it]Running loglikelihood requests:  29%|██▉       | 116/400 [03:16<05:30,  1.16s/it]Running loglikelihood requests:  29%|██▉       | 117/400 [03:17<05:26,  1.15s/it]Running loglikelihood requests:  30%|██▉       | 118/400 [03:19<05:23,  1.15s/it]Running loglikelihood requests:  30%|██▉       | 119/400 [03:20<05:20,  1.14s/it]Running loglikelihood requests:  30%|███       | 120/400 [03:21<05:18,  1.14s/it]Running loglikelihood requests:  30%|███       | 121/400 [03:22<05:17,  1.14s/it]Running loglikelihood requests:  30%|███       | 122/400 [03:23<05:15,  1.13s/it]Running loglikelihood requests:  31%|███       | 123/400 [03:24<05:13,  1.13s/it]Running loglikelihood requests:  31%|███       | 124/400 [03:25<05:11,  1.13s/it]Running loglikelihood requests:  31%|███▏      | 125/400 [03:26<05:08,  1.12s/it]Running loglikelihood requests:  32%|███▏      | 126/400 [03:28<05:05,  1.11s/it]Running loglikelihood requests:  32%|███▏      | 127/400 [03:29<05:02,  1.11s/it]Running loglikelihood requests:  32%|███▏      | 128/400 [03:30<05:00,  1.11s/it]Running loglikelihood requests:  32%|███▏      | 129/400 [03:31<04:58,  1.10s/it]Running loglikelihood requests:  32%|███▎      | 130/400 [03:32<04:56,  1.10s/it]Running loglikelihood requests:  33%|███▎      | 131/400 [03:33<04:55,  1.10s/it]Running loglikelihood requests:  34%|███▎      | 134/400 [03:34<03:01,  1.46it/s]Running loglikelihood requests:  34%|███▍      | 135/400 [03:35<03:23,  1.30it/s]Running loglikelihood requests:  34%|███▍      | 136/400 [03:36<03:41,  1.19it/s]Running loglikelihood requests:  34%|███▍      | 137/400 [03:37<03:55,  1.12it/s]Running loglikelihood requests:  34%|███▍      | 138/400 [03:38<04:06,  1.06it/s]Running loglikelihood requests:  35%|███▍      | 139/400 [03:39<04:15,  1.02it/s]Running loglikelihood requests:  36%|███▌      | 142/400 [03:41<02:46,  1.55it/s]Running loglikelihood requests:  36%|███▌      | 143/400 [03:42<03:07,  1.37it/s]Running loglikelihood requests:  36%|███▌      | 144/400 [03:43<03:26,  1.24it/s]Running loglikelihood requests:  36%|███▋      | 145/400 [03:44<03:42,  1.15it/s]Running loglikelihood requests:  36%|███▋      | 146/400 [03:45<03:54,  1.08it/s]Running loglikelihood requests:  37%|███▋      | 147/400 [03:46<04:03,  1.04it/s]Running loglikelihood requests:  37%|███▋      | 148/400 [03:47<04:08,  1.01it/s]Running loglikelihood requests:  37%|███▋      | 149/400 [03:48<04:12,  1.01s/it]Running loglikelihood requests:  38%|███▊      | 150/400 [03:49<04:14,  1.02s/it]Running loglikelihood requests:  38%|███▊      | 151/400 [03:50<04:15,  1.03s/it]Running loglikelihood requests:  38%|███▊      | 152/400 [03:51<04:15,  1.03s/it]Running loglikelihood requests:  38%|███▊      | 153/400 [03:52<04:15,  1.04s/it]Running loglikelihood requests:  38%|███▊      | 154/400 [03:53<04:15,  1.04s/it]Running loglikelihood requests:  39%|███▉      | 155/400 [03:54<04:14,  1.04s/it]Running loglikelihood requests:  39%|███▉      | 156/400 [03:55<04:13,  1.04s/it]Running loglikelihood requests:  39%|███▉      | 157/400 [03:56<04:12,  1.04s/it]Running loglikelihood requests:  40%|███▉      | 158/400 [03:57<04:11,  1.04s/it]Running loglikelihood requests:  40%|███▉      | 159/400 [03:58<04:09,  1.04s/it]Running loglikelihood requests:  40%|████      | 160/400 [03:59<04:08,  1.04s/it]Running loglikelihood requests:  40%|████      | 161/400 [04:01<04:09,  1.04s/it]Running loglikelihood requests:  40%|████      | 162/400 [04:02<04:07,  1.04s/it]Running loglikelihood requests:  41%|████      | 163/400 [04:03<04:04,  1.03s/it]Running loglikelihood requests:  41%|████      | 164/400 [04:04<04:01,  1.02s/it]Running loglikelihood requests:  41%|████▏     | 165/400 [04:05<03:58,  1.01s/it]Running loglikelihood requests:  42%|████▏     | 166/400 [04:06<03:55,  1.01s/it]Running loglikelihood requests:  42%|████▏     | 167/400 [04:07<03:53,  1.00s/it]Running loglikelihood requests:  42%|████▏     | 168/400 [04:08<03:52,  1.00s/it]Running loglikelihood requests:  42%|████▏     | 169/400 [04:09<03:52,  1.00s/it]Running loglikelihood requests:  42%|████▎     | 170/400 [04:10<03:49,  1.00it/s]Running loglikelihood requests:  43%|████▎     | 172/400 [04:11<02:53,  1.32it/s]Running loglikelihood requests:  43%|████▎     | 173/400 [04:11<03:03,  1.24it/s]Running loglikelihood requests:  44%|████▎     | 174/400 [04:12<03:10,  1.19it/s]Running loglikelihood requests:  44%|████▍     | 177/400 [04:13<02:05,  1.77it/s]Running loglikelihood requests:  44%|████▍     | 178/400 [04:14<02:23,  1.55it/s]Running loglikelihood requests:  45%|████▍     | 179/400 [04:15<02:37,  1.41it/s]Running loglikelihood requests:  45%|████▌     | 180/400 [04:16<02:48,  1.30it/s]Running loglikelihood requests:  45%|████▌     | 181/400 [04:17<02:57,  1.24it/s]Running loglikelihood requests:  46%|████▌     | 182/400 [04:18<03:03,  1.19it/s]Running loglikelihood requests:  46%|████▌     | 183/400 [04:19<03:06,  1.16it/s]Running loglikelihood requests:  46%|████▌     | 184/400 [04:20<03:09,  1.14it/s]Running loglikelihood requests:  46%|████▋     | 185/400 [04:21<03:11,  1.12it/s]Running loglikelihood requests:  46%|████▋     | 186/400 [04:22<03:11,  1.11it/s]Running loglikelihood requests:  47%|████▋     | 187/400 [04:23<03:12,  1.11it/s]Running loglikelihood requests:  47%|████▋     | 188/400 [04:24<03:14,  1.09it/s]Running loglikelihood requests:  47%|████▋     | 189/400 [04:25<03:14,  1.09it/s]Running loglikelihood requests:  48%|████▊     | 190/400 [04:25<03:12,  1.09it/s]Running loglikelihood requests:  48%|████▊     | 191/400 [04:26<03:09,  1.10it/s]Running loglikelihood requests:  48%|████▊     | 192/400 [04:27<03:07,  1.11it/s]Running loglikelihood requests:  48%|████▊     | 193/400 [04:28<03:05,  1.12it/s]Running loglikelihood requests:  48%|████▊     | 194/400 [04:29<03:03,  1.12it/s]Running loglikelihood requests:  49%|████▉     | 195/400 [04:30<03:01,  1.13it/s]Running loglikelihood requests:  49%|████▉     | 196/400 [04:31<02:59,  1.13it/s]Running loglikelihood requests:  49%|████▉     | 197/400 [04:32<02:57,  1.14it/s]Running loglikelihood requests:  50%|████▉     | 198/400 [04:32<02:56,  1.15it/s]Running loglikelihood requests:  50%|████▉     | 199/400 [04:33<02:54,  1.15it/s]Running loglikelihood requests:  50%|█████     | 200/400 [04:34<02:53,  1.15it/s]Running loglikelihood requests:  50%|█████     | 201/400 [04:35<02:51,  1.16it/s]Running loglikelihood requests:  50%|█████     | 202/400 [04:36<02:50,  1.16it/s]Running loglikelihood requests:  51%|█████     | 203/400 [04:37<02:49,  1.16it/s]Running loglikelihood requests:  51%|█████     | 204/400 [04:38<02:47,  1.17it/s]Running loglikelihood requests:  51%|█████▏    | 205/400 [04:38<02:46,  1.17it/s]Running loglikelihood requests:  52%|█████▏    | 206/400 [04:39<02:45,  1.17it/s]Running loglikelihood requests:  52%|█████▏    | 207/400 [04:40<02:45,  1.17it/s]Running loglikelihood requests:  52%|█████▏    | 208/400 [04:41<02:46,  1.16it/s]Running loglikelihood requests:  52%|█████▏    | 209/400 [04:42<02:46,  1.15it/s]Running loglikelihood requests:  53%|█████▎    | 212/400 [04:43<01:42,  1.83it/s]Running loglikelihood requests:  53%|█████▎    | 213/400 [04:44<01:54,  1.63it/s]Running loglikelihood requests:  54%|█████▎    | 214/400 [04:45<02:04,  1.49it/s]Running loglikelihood requests:  54%|█████▍    | 215/400 [04:45<02:13,  1.39it/s]Running loglikelihood requests:  54%|█████▍    | 216/400 [04:46<02:22,  1.29it/s]Running loglikelihood requests:  54%|█████▍    | 217/400 [04:47<02:26,  1.25it/s]Running loglikelihood requests:  55%|█████▍    | 218/400 [04:48<02:29,  1.22it/s]Running loglikelihood requests:  55%|█████▍    | 219/400 [04:49<02:30,  1.20it/s]Running loglikelihood requests:  55%|█████▌    | 220/400 [04:50<02:30,  1.19it/s]Running loglikelihood requests:  55%|█████▌    | 221/400 [04:51<02:30,  1.19it/s]Running loglikelihood requests:  56%|█████▌    | 222/400 [04:51<02:29,  1.19it/s]Running loglikelihood requests:  56%|█████▌    | 223/400 [04:52<02:28,  1.19it/s]Running loglikelihood requests:  56%|█████▌    | 224/400 [04:53<02:28,  1.19it/s]Running loglikelihood requests:  56%|█████▋    | 225/400 [04:54<02:27,  1.19it/s]Running loglikelihood requests:  56%|█████▋    | 226/400 [04:55<02:26,  1.19it/s]Running loglikelihood requests:  57%|█████▋    | 227/400 [04:56<02:25,  1.19it/s]Running loglikelihood requests:  57%|█████▋    | 228/400 [04:56<02:24,  1.19it/s]Running loglikelihood requests:  57%|█████▋    | 229/400 [04:57<02:23,  1.19it/s]Running loglikelihood requests:  57%|█████▊    | 230/400 [04:58<02:22,  1.19it/s]Running loglikelihood requests:  58%|█████▊    | 231/400 [04:59<02:22,  1.19it/s]Running loglikelihood requests:  58%|█████▊    | 232/400 [05:00<02:21,  1.19it/s]Running loglikelihood requests:  58%|█████▊    | 233/400 [05:01<02:20,  1.19it/s]Running loglikelihood requests:  58%|█████▊    | 234/400 [05:02<02:18,  1.20it/s]Running loglikelihood requests:  59%|█████▉    | 235/400 [05:02<02:17,  1.20it/s]Running loglikelihood requests:  59%|█████▉    | 236/400 [05:03<02:16,  1.20it/s]Running loglikelihood requests:  59%|█████▉    | 237/400 [05:04<02:15,  1.20it/s]Running loglikelihood requests:  60%|██████    | 240/400 [05:05<01:23,  1.92it/s]Running loglikelihood requests:  60%|██████    | 241/400 [05:06<01:32,  1.72it/s]Running loglikelihood requests:  60%|██████    | 242/400 [05:06<01:40,  1.58it/s]Running loglikelihood requests:  61%|██████    | 243/400 [05:07<01:46,  1.48it/s]Running loglikelihood requests:  61%|██████    | 244/400 [05:08<01:50,  1.41it/s]Running loglikelihood requests:  61%|██████▏   | 245/400 [05:09<01:54,  1.36it/s]Running loglikelihood requests:  62%|██████▏   | 246/400 [05:10<01:55,  1.33it/s]Running loglikelihood requests:  62%|██████▏   | 247/400 [05:10<01:57,  1.31it/s]Running loglikelihood requests:  62%|██████▏   | 248/400 [05:11<01:57,  1.29it/s]Running loglikelihood requests:  62%|██████▏   | 249/400 [05:12<01:58,  1.28it/s]Running loglikelihood requests:  62%|██████▎   | 250/400 [05:13<01:57,  1.27it/s]Running loglikelihood requests:  63%|██████▎   | 251/400 [05:14<01:57,  1.27it/s]Running loglikelihood requests:  63%|██████▎   | 252/400 [05:14<01:56,  1.27it/s]Running loglikelihood requests:  63%|██████▎   | 253/400 [05:15<01:55,  1.27it/s]Running loglikelihood requests:  64%|██████▎   | 254/400 [05:16<01:54,  1.27it/s]Running loglikelihood requests:  64%|██████▍   | 255/400 [05:17<01:54,  1.27it/s]Running loglikelihood requests:  64%|██████▍   | 256/400 [05:18<01:53,  1.27it/s]Running loglikelihood requests:  64%|██████▍   | 257/400 [05:18<01:52,  1.27it/s]Running loglikelihood requests:  64%|██████▍   | 258/400 [05:19<01:51,  1.27it/s]Running loglikelihood requests:  65%|██████▍   | 259/400 [05:20<01:50,  1.28it/s]Running loglikelihood requests:  65%|██████▌   | 260/400 [05:21<01:49,  1.28it/s]Running loglikelihood requests:  65%|██████▌   | 261/400 [05:21<01:46,  1.30it/s]Running loglikelihood requests:  66%|██████▌   | 262/400 [05:22<01:44,  1.32it/s]Running loglikelihood requests:  66%|██████▌   | 263/400 [05:23<01:42,  1.34it/s]Running loglikelihood requests:  66%|██████▌   | 264/400 [05:24<01:41,  1.35it/s]Running loglikelihood requests:  66%|██████▋   | 265/400 [05:24<01:37,  1.38it/s]Running loglikelihood requests:  66%|██████▋   | 266/400 [05:25<01:35,  1.40it/s]Running loglikelihood requests:  67%|██████▋   | 267/400 [05:26<01:33,  1.42it/s]Running loglikelihood requests:  67%|██████▋   | 268/400 [05:26<01:32,  1.43it/s]Running loglikelihood requests:  67%|██████▋   | 269/400 [05:27<01:30,  1.45it/s]Running loglikelihood requests:  68%|██████▊   | 270/400 [05:28<01:28,  1.46it/s]Running loglikelihood requests:  68%|██████▊   | 271/400 [05:28<01:27,  1.48it/s]Running loglikelihood requests:  68%|██████▊   | 272/400 [05:29<01:26,  1.49it/s]Running loglikelihood requests:  68%|██████▊   | 273/400 [05:30<01:23,  1.51it/s]Running loglikelihood requests:  68%|██████▊   | 274/400 [05:30<01:21,  1.54it/s]Running loglikelihood requests:  69%|██████▉   | 275/400 [05:31<01:20,  1.56it/s]Running loglikelihood requests:  69%|██████▉   | 276/400 [05:32<01:18,  1.57it/s]Running loglikelihood requests:  69%|██████▉   | 277/400 [05:32<01:17,  1.58it/s]Running loglikelihood requests:  70%|██████▉   | 278/400 [05:33<01:16,  1.60it/s]Running loglikelihood requests:  70%|██████▉   | 279/400 [05:33<01:15,  1.60it/s]Running loglikelihood requests:  70%|███████   | 280/400 [05:34<01:14,  1.61it/s]Running loglikelihood requests:  70%|███████   | 281/400 [05:35<01:13,  1.62it/s]Running loglikelihood requests:  70%|███████   | 282/400 [05:35<01:12,  1.63it/s]Running loglikelihood requests:  71%|███████   | 283/400 [05:36<01:11,  1.63it/s]Running loglikelihood requests:  71%|███████   | 284/400 [05:36<01:10,  1.63it/s]Running loglikelihood requests:  71%|███████▏  | 285/400 [05:37<01:10,  1.64it/s]Running loglikelihood requests:  72%|███████▏  | 286/400 [05:38<01:09,  1.64it/s]Running loglikelihood requests:  72%|███████▏  | 287/400 [05:38<01:08,  1.64it/s]Running loglikelihood requests:  72%|███████▏  | 288/400 [05:39<01:08,  1.64it/s]Running loglikelihood requests:  72%|███████▏  | 289/400 [05:39<01:07,  1.64it/s]Running loglikelihood requests:  72%|███████▎  | 290/400 [05:40<01:06,  1.64it/s]Running loglikelihood requests:  73%|███████▎  | 291/400 [05:41<01:06,  1.64it/s]Running loglikelihood requests:  73%|███████▎  | 292/400 [05:41<01:05,  1.65it/s]Running loglikelihood requests:  73%|███████▎  | 293/400 [05:42<01:04,  1.66it/s]Running loglikelihood requests:  74%|███████▎  | 294/400 [05:43<01:03,  1.66it/s]Running loglikelihood requests:  74%|███████▍  | 295/400 [05:43<01:02,  1.68it/s]Running loglikelihood requests:  74%|███████▍  | 296/400 [05:44<01:01,  1.70it/s]Running loglikelihood requests:  74%|███████▍  | 297/400 [05:44<01:00,  1.72it/s]Running loglikelihood requests:  74%|███████▍  | 298/400 [05:45<00:59,  1.73it/s]Running loglikelihood requests:  75%|███████▍  | 299/400 [05:45<00:58,  1.73it/s]Running loglikelihood requests:  75%|███████▌  | 300/400 [05:46<00:57,  1.74it/s]Running loglikelihood requests:  75%|███████▌  | 301/400 [05:47<00:56,  1.74it/s]Running loglikelihood requests:  76%|███████▌  | 302/400 [05:47<00:57,  1.72it/s]Running loglikelihood requests:  76%|███████▌  | 303/400 [05:48<00:56,  1.72it/s]Running loglikelihood requests:  76%|███████▌  | 304/400 [05:48<00:55,  1.72it/s]Running loglikelihood requests:  76%|███████▋  | 305/400 [05:49<00:55,  1.73it/s]Running loglikelihood requests:  76%|███████▋  | 306/400 [05:49<00:54,  1.73it/s]Running loglikelihood requests:  77%|███████▋  | 307/400 [05:50<00:53,  1.72it/s]Running loglikelihood requests:  78%|███████▊  | 310/400 [05:51<00:32,  2.77it/s]Running loglikelihood requests:  78%|███████▊  | 311/400 [05:51<00:36,  2.46it/s]Running loglikelihood requests:  78%|███████▊  | 312/400 [05:52<00:40,  2.19it/s]Running loglikelihood requests:  78%|███████▊  | 313/400 [05:52<00:42,  2.05it/s]Running loglikelihood requests:  78%|███████▊  | 314/400 [05:53<00:43,  1.96it/s]Running loglikelihood requests:  79%|███████▉  | 315/400 [05:54<00:44,  1.89it/s]Running loglikelihood requests:  79%|███████▉  | 316/400 [05:54<00:45,  1.86it/s]Running loglikelihood requests:  79%|███████▉  | 317/400 [05:55<00:45,  1.84it/s]Running loglikelihood requests:  80%|███████▉  | 318/400 [05:55<00:45,  1.82it/s]Running loglikelihood requests:  80%|███████▉  | 319/400 [05:56<00:44,  1.82it/s]Running loglikelihood requests:  80%|████████  | 321/400 [05:56<00:33,  2.37it/s]Running loglikelihood requests:  80%|████████  | 322/400 [05:57<00:35,  2.21it/s]Running loglikelihood requests:  81%|████████  | 323/400 [05:57<00:36,  2.10it/s]Running loglikelihood requests:  81%|████████  | 324/400 [05:58<00:37,  2.02it/s]Running loglikelihood requests:  81%|████████▏ | 325/400 [05:58<00:38,  1.96it/s]Running loglikelihood requests:  82%|████████▏ | 326/400 [05:59<00:38,  1.93it/s]Running loglikelihood requests:  82%|████████▏ | 327/400 [06:00<00:38,  1.92it/s]Running loglikelihood requests:  82%|████████▏ | 328/400 [06:00<00:37,  1.90it/s]Running loglikelihood requests:  82%|████████▏ | 329/400 [06:01<00:37,  1.89it/s]Running loglikelihood requests:  82%|████████▎ | 330/400 [06:01<00:37,  1.89it/s]Running loglikelihood requests:  83%|████████▎ | 331/400 [06:02<00:36,  1.89it/s]Running loglikelihood requests:  83%|████████▎ | 332/400 [06:02<00:36,  1.88it/s]Running loglikelihood requests:  83%|████████▎ | 333/400 [06:03<00:35,  1.90it/s]Running loglikelihood requests:  84%|████████▎ | 334/400 [06:03<00:35,  1.88it/s]Running loglikelihood requests:  84%|████████▍ | 335/400 [06:04<00:34,  1.90it/s]Running loglikelihood requests:  84%|████████▍ | 336/400 [06:04<00:33,  1.92it/s]Running loglikelihood requests:  84%|████████▍ | 337/400 [06:05<00:32,  1.93it/s]Running loglikelihood requests:  84%|████████▍ | 338/400 [06:05<00:31,  1.95it/s]Running loglikelihood requests:  85%|████████▍ | 339/400 [06:06<00:31,  1.95it/s]Running loglikelihood requests:  85%|████████▌ | 340/400 [06:06<00:30,  1.96it/s]Running loglikelihood requests:  85%|████████▌ | 341/400 [06:07<00:30,  1.97it/s]Running loglikelihood requests:  86%|████████▌ | 342/400 [06:07<00:29,  1.97it/s]Running loglikelihood requests:  86%|████████▌ | 343/400 [06:08<00:28,  1.97it/s]Running loglikelihood requests:  86%|████████▌ | 344/400 [06:08<00:28,  1.97it/s]Running loglikelihood requests:  86%|████████▋ | 345/400 [06:09<00:27,  1.98it/s]Running loglikelihood requests:  86%|████████▋ | 346/400 [06:09<00:27,  1.98it/s]Running loglikelihood requests:  87%|████████▋ | 347/400 [06:10<00:27,  1.96it/s]Running loglikelihood requests:  87%|████████▋ | 348/400 [06:10<00:26,  1.96it/s]Running loglikelihood requests:  87%|████████▋ | 349/400 [06:11<00:25,  1.97it/s]Running loglikelihood requests:  88%|████████▊ | 350/400 [06:11<00:25,  1.97it/s]Running loglikelihood requests:  88%|████████▊ | 351/400 [06:12<00:24,  1.97it/s]Running loglikelihood requests:  88%|████████▊ | 352/400 [06:12<00:24,  1.97it/s]Running loglikelihood requests:  88%|████████▊ | 353/400 [06:13<00:24,  1.95it/s]Running loglikelihood requests:  88%|████████▊ | 354/400 [06:13<00:23,  1.96it/s]Running loglikelihood requests:  89%|████████▉ | 355/400 [06:14<00:22,  1.97it/s]Running loglikelihood requests:  89%|████████▉ | 356/400 [06:14<00:22,  1.98it/s]Running loglikelihood requests:  89%|████████▉ | 357/400 [06:15<00:21,  1.97it/s]Running loglikelihood requests:  90%|████████▉ | 358/400 [06:15<00:21,  1.98it/s]Running loglikelihood requests:  90%|████████▉ | 359/400 [06:16<00:20,  1.99it/s]Running loglikelihood requests:  90%|█████████ | 360/400 [06:16<00:20,  1.99it/s]Running loglikelihood requests:  90%|█████████ | 361/400 [06:17<00:19,  1.96it/s]Running loglikelihood requests:  90%|█████████ | 362/400 [06:17<00:19,  1.97it/s]Running loglikelihood requests:  91%|█████████ | 363/400 [06:18<00:18,  1.98it/s]Running loglikelihood requests:  91%|█████████ | 364/400 [06:18<00:18,  1.99it/s]Running loglikelihood requests:  91%|█████████▏| 365/400 [06:19<00:17,  2.00it/s]Running loglikelihood requests:  92%|█████████▏| 366/400 [06:19<00:16,  2.01it/s]Running loglikelihood requests:  92%|█████████▏| 368/400 [06:20<00:12,  2.61it/s]Running loglikelihood requests:  92%|█████████▏| 369/400 [06:20<00:12,  2.44it/s]Running loglikelihood requests:  92%|█████████▎| 370/400 [06:21<00:12,  2.31it/s]Running loglikelihood requests:  93%|█████████▎| 371/400 [06:21<00:13,  2.22it/s]Running loglikelihood requests:  93%|█████████▎| 373/400 [06:22<00:09,  2.76it/s]Running loglikelihood requests:  94%|█████████▎| 374/400 [06:22<00:10,  2.54it/s]Running loglikelihood requests:  94%|█████████▍| 375/400 [06:23<00:10,  2.36it/s]Running loglikelihood requests:  94%|█████████▍| 376/400 [06:23<00:10,  2.28it/s]Running loglikelihood requests:  94%|█████████▍| 377/400 [06:24<00:10,  2.23it/s]Running loglikelihood requests:  94%|█████████▍| 378/400 [06:24<00:09,  2.20it/s]Running loglikelihood requests:  95%|█████████▍| 379/400 [06:25<00:09,  2.18it/s]Running loglikelihood requests:  95%|█████████▌| 380/400 [06:25<00:09,  2.17it/s]Running loglikelihood requests:  95%|█████████▌| 381/400 [06:26<00:08,  2.16it/s]Running loglikelihood requests:  96%|█████████▌| 382/400 [06:26<00:08,  2.16it/s]Running loglikelihood requests:  96%|█████████▌| 383/400 [06:27<00:07,  2.17it/s]Running loglikelihood requests:  96%|█████████▌| 384/400 [06:27<00:07,  2.14it/s]Running loglikelihood requests:  96%|█████████▋| 385/400 [06:28<00:07,  2.14it/s]Running loglikelihood requests:  96%|█████████▋| 386/400 [06:28<00:06,  2.14it/s]Running loglikelihood requests:  97%|█████████▋| 387/400 [06:29<00:06,  2.15it/s]Running loglikelihood requests:  97%|█████████▋| 388/400 [06:29<00:05,  2.15it/s]Running loglikelihood requests:  97%|█████████▋| 389/400 [06:29<00:05,  2.15it/s]Running loglikelihood requests:  98%|█████████▊| 390/400 [06:30<00:04,  2.16it/s]Running loglikelihood requests:  98%|█████████▊| 391/400 [06:30<00:04,  2.16it/s]Running loglikelihood requests:  98%|█████████▊| 392/400 [06:31<00:03,  2.17it/s]Running loglikelihood requests:  98%|█████████▊| 393/400 [06:31<00:03,  2.18it/s]Running loglikelihood requests:  98%|█████████▊| 394/400 [06:32<00:02,  2.18it/s]Running loglikelihood requests:  99%|█████████▉| 395/400 [06:32<00:02,  2.19it/s]Running loglikelihood requests:  99%|█████████▉| 396/400 [06:33<00:01,  2.19it/s]Running loglikelihood requests:  99%|█████████▉| 397/400 [06:33<00:01,  2.20it/s]Running loglikelihood requests: 100%|█████████▉| 398/400 [06:34<00:00,  2.20it/s]Running loglikelihood requests: 100%|█████████▉| 399/400 [06:34<00:00,  2.21it/s]Running loglikelihood requests: 100%|██████████| 400/400 [06:34<00:00,  2.22it/s]Running loglikelihood requests: 100%|██████████| 400/400 [06:34<00:00,  1.01it/s]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:4'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:4'}
full model:
{'sciq': {'alias': 'sciq', 'acc,none': 0.94, 'acc_stderr,none': 0.023868325657594204, 'acc_norm,none': 0.91, 'acc_norm_stderr,none': 0.028762349126466136}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.969062788859705
0.9024924890572922
0.7706109127217512
0.8221264026535647
0.9190490061886575
0.9866654579796295
0.6586322754204971
0.7962110384246164
0.8195614021629236
0.7124178311176441
0.787697814339696
0.7034455022322618
0.8136386046534271
0.8174990104652458
0.6784276389594894
0.8698440245672888
0.8886492811850213
0.6541737276411673
0.6560861559753316
0.8139845219953913
0.6714741870309046
0.6164364868717988
0.8331581872497299
0.9065420049234512
0.9246185715568276
0.7477515960551026
0.574165362968651
0.8586446364199891
0.8889771415746612
Total groups 70 exceeded the threshold, stopping comparison.
The group tensor is
[7, 3, 4, 2, 6, 1, 5, 0]
tensor([7, 3, 4, 2, 6, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 2, 5, 3, 4, 0, 7, 1]
tensor([6, 2, 5, 3, 4, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 3, 6, 2, 7, 1, 4, 0]
tensor([5, 3, 6, 2, 7, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 4, 2, 1, 3, 5, 1]
tensor([0, 0, 4, 2, 1, 3, 5, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 2, 3, 4, 5, 0, 1, 1]
tensor([0, 2, 3, 4, 5, 0, 1, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 1, 0, 2, 2, 3, 1]
tensor([0, 3, 1, 0, 2, 2, 3, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 3, 1, 1, 2, 2, 3, 0]
tensor([0, 3, 1, 1, 2, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 1, 1.0, 1.0, 1.0, 1.0, 1]
tensor([0, 0, 1, 1, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 2 to 4
done!
Normal merging for layer 5
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 6 to 9
done!
Normal merging for layer 10
tensor([0, 1])
tensor(0)
tensor([4, 7])
tensor(4)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 11 to 12
done!
Normal merging for layer 13
tensor([0, 5])
tensor(0)
tensor([6, 7])
tensor(6)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 14 to 19
done!
Normal merging for layer 20
tensor([0, 3])
tensor(0)
tensor([2, 7])
tensor(2)
tensor([4, 5])
tensor(4)
tensor([1, 6])
tensor(1)
done!
Normal merging for layer 21
tensor([0, 7])
tensor(0)
tensor([2, 3])
tensor(2)
tensor([4, 5])
tensor(4)
tensor([1, 6])
tensor(1)
done!
Cross-layer merge completed for layers 22 to 23
done!
Normal merging for layer 24
tensor([0, 1])
tensor(0)
tensor([2, 3, 4, 5, 6, 7])
tensor(2)
done!
Cross-layer merge completed for layers 25 to 31
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 21 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.2608 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 20 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

41
cuda:4
cola
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:56<00:56, 56.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:13<00:00, 33.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:13<00:00, 36.98s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: cola] metric mcc is defined, but aggregation is not. using default aggregation=matthews_corrcoef
WARNING:lm_eval.api.task:[Task: cola] metric mcc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cola?recursive=False&expand=False HTTP/1.1" 307 141
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cola?recursive=False&expand=False HTTP/1.1" 200 358
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140437047312208 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_cola_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140437047312208 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_cola_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140437047312208 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_cola_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140437047312208 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_cola_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140431342056320 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140431342056320 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140431342056320 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140431342056320 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of cola from None to 0
INFO:lm_eval.api.task:Building contexts for cola on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 3229.47it/s]
DEBUG:lm_eval.evaluator:Task: cola; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:01<03:51,  1.17s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:01<01:37,  2.02it/s]Running loglikelihood requests:   2%|▎         | 5/200 [00:02<01:12,  2.68it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:02<01:02,  3.07it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:03<00:56,  3.35it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:03<00:53,  3.54it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:04<00:50,  3.68it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:04<00:49,  3.77it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:05<00:47,  3.84it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:05<00:46,  3.90it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:06<00:45,  3.93it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:06<00:44,  3.96it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:07<00:43,  3.98it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:07<00:43,  4.01it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:08<00:42,  4.03it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:08<00:41,  4.05it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:09<00:41,  4.06it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:09<00:40,  4.08it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:10<00:39,  4.09it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:10<00:39,  4.11it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:11<00:38,  4.10it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:11<00:38,  4.09it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:12<00:37,  4.12it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:12<00:36,  4.14it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:13<00:36,  4.15it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:13<00:36,  4.06it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:14<00:35,  4.09it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:14<00:35,  4.12it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:15<00:34,  4.12it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:15<00:34,  4.13it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:15<00:33,  4.16it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:16<00:32,  4.19it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:16<00:32,  4.21it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:17<00:31,  4.22it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:17<00:30,  4.25it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:18<00:30,  4.26it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:18<00:29,  4.27it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:19<00:29,  4.28it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:19<00:28,  4.29it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:20<00:28,  4.29it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:20<00:27,  4.29it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:21<00:27,  4.29it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:21<00:26,  4.30it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:22<00:26,  4.32it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:22<00:25,  4.33it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:22<00:25,  4.34it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:23<00:24,  4.33it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:23<00:24,  4.34it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:24<00:23,  4.35it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:24<00:23,  4.36it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:25<00:22,  4.37it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:25<00:22,  4.38it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:26<00:21,  4.38it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:26<00:21,  4.38it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:27<00:20,  4.37it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:27<00:20,  4.37it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:27<00:20,  4.31it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:28<00:19,  4.32it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:28<00:19,  4.33it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:29<00:18,  4.35it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:29<00:18,  4.36it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:30<00:17,  4.36it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:30<00:17,  4.36it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [00:31<00:16,  4.37it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [00:31<00:16,  4.37it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [00:32<00:15,  4.40it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [00:32<00:15,  4.41it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [00:33<00:14,  4.41it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [00:33<00:14,  4.41it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [00:33<00:13,  4.41it/s]Running loglikelihood requests:  70%|███████   | 141/200 [00:34<00:13,  4.43it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [00:34<00:12,  4.44it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [00:35<00:12,  4.45it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [00:35<00:12,  4.40it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [00:36<00:11,  4.43it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [00:36<00:11,  4.45it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [00:37<00:10,  4.46it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [00:37<00:10,  4.46it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [00:37<00:09,  4.48it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [00:38<00:09,  4.51it/s]Running loglikelihood requests:  80%|████████  | 161/200 [00:38<00:08,  4.52it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [00:39<00:08,  4.53it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [00:39<00:07,  4.54it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [00:40<00:07,  4.54it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [00:40<00:06,  4.54it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [00:41<00:06,  4.37it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [00:41<00:06,  4.41it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [00:41<00:05,  4.47it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [00:42<00:05,  4.52it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [00:42<00:04,  4.55it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [00:43<00:04,  4.56it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [00:43<00:03,  4.59it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [00:44<00:03,  4.58it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [00:44<00:02,  4.60it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [00:45<00:02,  4.54it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [00:45<00:01,  4.59it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [00:45<00:01,  4.60it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [00:46<00:01,  4.63it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [00:46<00:00,  4.65it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [00:47<00:00,  4.68it/s]Running loglikelihood requests: 100%|██████████| 200/200 [00:47<00:00,  4.24it/s]
bootstrapping for stddev (sequential): matthews_corrcoef
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<01:34,  1.04it/s]  2%|▏         | 2/100 [00:01<01:31,  1.07it/s]  3%|▎         | 3/100 [00:02<01:30,  1.08it/s]  4%|▍         | 4/100 [00:03<01:29,  1.08it/s]  5%|▌         | 5/100 [00:04<01:28,  1.08it/s]  6%|▌         | 6/100 [00:05<01:26,  1.08it/s]  7%|▋         | 7/100 [00:06<01:25,  1.08it/s]  8%|▊         | 8/100 [00:07<01:24,  1.08it/s]  9%|▉         | 9/100 [00:08<01:24,  1.08it/s] 10%|█         | 10/100 [00:09<01:23,  1.08it/s] 11%|█         | 11/100 [00:10<01:22,  1.08it/s] 12%|█▏        | 12/100 [00:11<01:21,  1.08it/s] 13%|█▎        | 13/100 [00:12<01:20,  1.08it/s] 14%|█▍        | 14/100 [00:12<01:19,  1.08it/s] 15%|█▌        | 15/100 [00:13<01:18,  1.08it/s] 16%|█▌        | 16/100 [00:14<01:17,  1.08it/s] 17%|█▋        | 17/100 [00:15<01:16,  1.08it/s] 18%|█▊        | 18/100 [00:16<01:15,  1.08it/s] 19%|█▉        | 19/100 [00:17<01:14,  1.08it/s] 20%|██        | 20/100 [00:18<01:14,  1.07it/s] 21%|██        | 21/100 [00:19<01:13,  1.08it/s] 22%|██▏       | 22/100 [00:20<01:12,  1.08it/s] 23%|██▎       | 23/100 [00:21<01:11,  1.08it/s] 24%|██▍       | 24/100 [00:22<01:10,  1.08it/s] 25%|██▌       | 25/100 [00:23<01:09,  1.09it/s] 26%|██▌       | 26/100 [00:24<01:08,  1.08it/s] 27%|██▋       | 27/100 [00:25<01:08,  1.07it/s] 28%|██▊       | 28/100 [00:25<01:07,  1.07it/s] 29%|██▉       | 29/100 [00:26<01:05,  1.08it/s] 30%|███       | 30/100 [00:27<01:04,  1.08it/s] 31%|███       | 31/100 [00:28<01:04,  1.07it/s] 32%|███▏      | 32/100 [00:29<01:03,  1.07it/s] 33%|███▎      | 33/100 [00:30<01:02,  1.08it/s] 34%|███▍      | 34/100 [00:31<01:01,  1.08it/s] 35%|███▌      | 35/100 [00:32<01:00,  1.08it/s] 36%|███▌      | 36/100 [00:33<00:59,  1.08it/s] 37%|███▋      | 37/100 [00:34<00:58,  1.08it/s] 38%|███▊      | 38/100 [00:35<00:57,  1.08it/s] 39%|███▉      | 39/100 [00:36<00:56,  1.08it/s] 40%|████      | 40/100 [00:37<00:55,  1.08it/s] 41%|████      | 41/100 [00:37<00:54,  1.08it/s] 42%|████▏     | 42/100 [00:38<00:53,  1.08it/s] 43%|████▎     | 43/100 [00:39<00:52,  1.08it/s] 44%|████▍     | 44/100 [00:40<00:51,  1.08it/s] 45%|████▌     | 45/100 [00:41<00:50,  1.08it/s] 46%|████▌     | 46/100 [00:42<00:49,  1.08it/s] 47%|████▋     | 47/100 [00:43<00:49,  1.08it/s] 48%|████▊     | 48/100 [00:44<00:48,  1.08it/s] 49%|████▉     | 49/100 [00:45<00:47,  1.08it/s] 50%|█████     | 50/100 [00:46<00:46,  1.08it/s] 51%|█████     | 51/100 [00:47<00:45,  1.08it/s] 52%|█████▏    | 52/100 [00:48<00:44,  1.07it/s] 53%|█████▎    | 53/100 [00:49<00:43,  1.07it/s] 54%|█████▍    | 54/100 [00:50<00:43,  1.07it/s] 55%|█████▌    | 55/100 [00:51<00:41,  1.07it/s] 56%|█████▌    | 56/100 [00:51<00:40,  1.08it/s] 57%|█████▋    | 57/100 [00:52<00:39,  1.08it/s] 58%|█████▊    | 58/100 [00:53<00:39,  1.07it/s] 59%|█████▉    | 59/100 [00:54<00:38,  1.08it/s] 60%|██████    | 60/100 [00:55<00:37,  1.08it/s] 61%|██████    | 61/100 [00:56<00:36,  1.07it/s] 62%|██████▏   | 62/100 [00:57<00:35,  1.07it/s] 63%|██████▎   | 63/100 [00:58<00:34,  1.08it/s] 64%|██████▍   | 64/100 [00:59<00:33,  1.08it/s] 65%|██████▌   | 65/100 [01:00<00:32,  1.08it/s] 66%|██████▌   | 66/100 [01:01<00:31,  1.08it/s] 67%|██████▋   | 67/100 [01:02<00:30,  1.08it/s] 68%|██████▊   | 68/100 [01:03<00:29,  1.08it/s] 69%|██████▉   | 69/100 [01:04<00:28,  1.08it/s] 70%|███████   | 70/100 [01:04<00:27,  1.08it/s] 71%|███████   | 71/100 [01:05<00:26,  1.08it/s] 72%|███████▏  | 72/100 [01:06<00:25,  1.08it/s] 73%|███████▎  | 73/100 [01:07<00:25,  1.07it/s] 74%|███████▍  | 74/100 [01:08<00:24,  1.07it/s] 75%|███████▌  | 75/100 [01:09<00:23,  1.08it/s] 76%|███████▌  | 76/100 [01:10<00:22,  1.08it/s] 77%|███████▋  | 77/100 [01:11<00:21,  1.08it/s] 78%|███████▊  | 78/100 [01:12<00:20,  1.08it/s] 79%|███████▉  | 79/100 [01:13<00:19,  1.08it/s] 80%|████████  | 80/100 [01:14<00:18,  1.08it/s] 81%|████████  | 81/100 [01:15<00:17,  1.08it/s] 82%|████████▏ | 82/100 [01:16<00:16,  1.08it/s] 83%|████████▎ | 83/100 [01:16<00:15,  1.08it/s] 84%|████████▍ | 84/100 [01:17<00:14,  1.08it/s] 85%|████████▌ | 85/100 [01:18<00:13,  1.08it/s] 86%|████████▌ | 86/100 [01:19<00:12,  1.08it/s] 87%|████████▋ | 87/100 [01:20<00:11,  1.08it/s] 88%|████████▊ | 88/100 [01:21<00:11,  1.09it/s] 89%|████████▉ | 89/100 [01:22<00:10,  1.09it/s] 90%|█████████ | 90/100 [01:23<00:09,  1.09it/s] 91%|█████████ | 91/100 [01:24<00:08,  1.08it/s] 92%|█████████▏| 92/100 [01:25<00:07,  1.08it/s] 93%|█████████▎| 93/100 [01:26<00:06,  1.09it/s] 94%|█████████▍| 94/100 [01:27<00:05,  1.09it/s] 95%|█████████▌| 95/100 [01:28<00:04,  1.09it/s] 96%|█████████▌| 96/100 [01:28<00:03,  1.08it/s] 97%|█████████▋| 97/100 [01:29<00:02,  1.09it/s] 98%|█████████▊| 98/100 [01:30<00:01,  1.09it/s] 99%|█████████▉| 99/100 [01:31<00:00,  1.09it/s]100%|██████████| 100/100 [01:32<00:00,  1.09it/s]100%|██████████| 100/100 [01:32<00:00,  1.08it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:5'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:5'}
full model:
{'cola': {'alias': 'cola', 'mcc,none': np.float64(-0.0234083603222329), 'mcc_stderr,none': 0.10027612985654218}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9827615088085355
0.9302188892609604
0.7011961870018854
0.5626926521241726
0.8487059565524276
0.8497526414658526
0.9054485200458864
0.7394951536076
0.6615723249956142
0.3790091735780837
0.7669438266452424
0.6500882643740805
0.6039759750877352
0.8611545876684488
0.9595791152744535
0.7624866897939796
0.8585278638499474
0.9654871578633694
0.8537985077125277
0.9276026122967783
0.938072418626947
0.8815459403167786
0.6241194219560614
0.901256729143793
0.7007049393842223
0.6541093728101413
0.9141945519271818
0.7667764647672246
0.8091089193013563
Total groups 69 exceeded the threshold, stopping comparison.
The group tensor is
[3, 2, 6, 7, 5, 1, 4, 0]
tensor([3, 2, 6, 7, 5, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 3, 6, 7, 5, 1, 4, 0]
tensor([2, 3, 6, 7, 5, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 3, 5, 7, 6, 1, 2, 0]
tensor([4, 3, 5, 7, 6, 1, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[2, 3, 0, 1, 2, 1, 3, 0]
tensor([2, 3, 0, 1, 2, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[1, 0, 1, 2, 3, 2, 3, 0]
tensor([1, 0, 1, 2, 3, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 2, 1, 2, 3, 1, 3, 0]
tensor([0, 2, 1, 2, 3, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[1, 0, 0, 1, 2, 3, 3, 2]
tensor([1, 0, 0, 1, 2, 3, 3, 2], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[3, 1, 0, 1, 2, 2, 3, 0]
tensor([3, 1, 0, 1, 2, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1.0, 1.0, 1, 1.0, 0]
tensor([0, 1, 1, 1, 1, 1, 1, 0], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
done!
Cross-layer merge completed for layers 2 to 5
done!
Normal merging for layer 6
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
tensor([3])
tensor(3)
done!
Cross-layer merge completed for layers 7 to 18
done!
Normal merging for layer 19
tensor([2, 7])
tensor(2)
tensor([3, 5])
tensor(3)
tensor([0, 4])
tensor(0)
tensor([1, 6])
tensor(1)
done!
Normal merging for layer 20
tensor([1, 7])
tensor(1)
tensor([0, 2])
tensor(0)
tensor([3, 5])
tensor(3)
tensor([4, 6])
tensor(4)
done!
Normal merging for layer 21
tensor([0, 7])
tensor(0)
tensor([2, 5])
tensor(2)
tensor([1, 3])
tensor(1)
tensor([4, 6])
tensor(4)
done!
Normal merging for layer 22
tensor([1, 2])
tensor(1)
tensor([0, 3])
tensor(0)
tensor([4, 7])
tensor(4)
tensor([5, 6])
tensor(5)
done!
Normal merging for layer 23
tensor([2, 7])
tensor(2)
tensor([1, 3])
tensor(1)
tensor([4, 5])
tensor(4)
tensor([0, 6])
tensor(0)
done!
Cross-layer merge completed for layers 24 to 27
done!
Normal merging for layer 28
tensor([0, 7])
tensor(0)
tensor([1, 2, 3, 4, 5, 6])
tensor(1)
done!
Cross-layer merge completed for layers 29 to 31
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 20 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.1348 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 19 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

14
cuda:5
rte
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:56<00:56, 56.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:12<00:00, 32.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:12<00:00, 36.30s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: rte] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: rte] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:filelock:Attempting to acquire lock 140437046303472 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140437046303472 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140437046303472 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140437046303472 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140431341461168 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140431341461168 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140431341461168 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140431341461168 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of rte from None to 0
INFO:lm_eval.api.task:Building contexts for rte on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 2609.55it/s]
DEBUG:lm_eval.evaluator:Task: rte; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:02<06:59,  2.11s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:03<03:33,  1.09s/it]Running loglikelihood requests:   2%|▎         | 5/200 [00:04<02:46,  1.17it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:06<02:24,  1.33it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:07<02:12,  1.44it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:08<02:04,  1.52it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:09<02:00,  1.55it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:10<01:58,  1.57it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:12<01:54,  1.60it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:13<01:51,  1.62it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:14<01:47,  1.66it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:15<01:44,  1.69it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:16<01:42,  1.72it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:17<01:38,  1.75it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:18<01:36,  1.78it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:19<01:33,  1.82it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:20<01:30,  1.84it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:22<01:28,  1.87it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:23<01:26,  1.88it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:24<01:24,  1.91it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:25<01:21,  1.94it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:26<01:19,  1.98it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:26<01:16,  2.03it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:27<01:14,  2.07it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:28<01:11,  2.11it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:29<01:08,  2.16it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:30<01:06,  2.22it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:31<01:03,  2.27it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:32<01:01,  2.32it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:32<00:59,  2.37it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:33<00:57,  2.40it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:34<00:56,  2.44it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:35<00:54,  2.46it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:36<00:53,  2.48it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:36<00:52,  2.51it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:37<00:50,  2.53it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:38<00:50,  2.52it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:39<00:49,  2.55it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:40<00:48,  2.54it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:40<00:46,  2.59it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:41<00:45,  2.62it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:42<00:44,  2.65it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:43<00:43,  2.65it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:43<00:42,  2.68it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:44<00:40,  2.72it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:45<00:39,  2.75it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:45<00:38,  2.77it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:46<00:37,  2.79it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:47<00:36,  2.81it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:47<00:35,  2.82it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:48<00:34,  2.84it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:49<00:34,  2.85it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:50<00:33,  2.87it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:50<00:32,  2.89it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:51<00:31,  2.91it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:52<00:30,  2.93it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:52<00:29,  2.94it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:53<00:28,  2.94it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:54<00:28,  2.95it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:54<00:27,  2.95it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:55<00:26,  2.96it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:56<00:26,  2.94it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:56<00:25,  2.92it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [00:57<00:25,  2.90it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [00:58<00:24,  2.93it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [00:58<00:23,  2.97it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [00:59<00:22,  3.00it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [01:00<00:21,  3.04it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [01:00<00:20,  3.07it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [01:01<00:19,  3.09it/s]Running loglikelihood requests:  70%|███████   | 141/200 [01:02<00:18,  3.11it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [01:02<00:19,  2.96it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [01:03<00:18,  3.02it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [01:04<00:17,  3.07it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [01:04<00:16,  3.11it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [01:05<00:15,  3.14it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [01:05<00:14,  3.16it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [01:06<00:14,  3.18it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [01:07<00:13,  3.19it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [01:07<00:12,  3.22it/s]Running loglikelihood requests:  80%|████████  | 161/200 [01:08<00:12,  3.25it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [01:08<00:11,  3.27it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [01:09<00:10,  3.28it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [01:10<00:09,  3.30it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [01:10<00:09,  3.32it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [01:11<00:08,  3.35it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [01:11<00:08,  3.37it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [01:12<00:07,  3.38it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [01:13<00:06,  3.40it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [01:13<00:06,  3.37it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [01:14<00:05,  3.39it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [01:14<00:04,  3.40it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [01:15<00:04,  3.42it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [01:16<00:03,  3.43it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [01:16<00:03,  3.45it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [01:17<00:02,  3.47it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [01:17<00:02,  3.48it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:18<00:01,  3.46it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:18<00:00,  3.54it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:19<00:00,  3.61it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:19<00:00,  2.52it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:6'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:6'}
full model:
{'rte': {'alias': 'rte', 'acc,none': 0.5, 'acc_stderr,none': 0.050251890762960605}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.34161229456626735
0.905233410256777
0.5205040718697735
0.4121994254524892
0.7398116665887099
0.6225415196831932
0.7923970242263771
0.7353888240887675
0.6535613357308766
0.7757058271862038
0.734046359122903
0.4471799126982846
0.773619360921301
0.7955347039939479
0.8672068064531693
0.8652880343596522
0.3302235467760883
0.6789268064017625
0.6072221471952108
0.9194446824778495
0.4812004589187253
0.5728915095234594
0.1682455054057436
0.93212414632396
0.9148362604533635
0.8268537756297094
0.7592245907029287
0.7256008379011685
0.7109756105942956
0.34161229456626735
0.905233410256777
0.5205040718697735
0.4121994254524892
0.7398116665887099
0.6225415196831932
0.7923970242263771
0.7353888240887675
0.6535613357308766
0.7757058271862038
0.734046359122903
0.4471799126982846
0.773619360921301
0.7955347039939479
0.8672068064531693
0.8652880343596522
0.3302235467760883
0.6789268064017625
0.6072221471952108
0.9194446824778495
0.4812004589187253
Total groups 73 exceeded the threshold, stopping comparison.
The group tensor is
[5, 2, 7, 1, 6, 4, 3, 0]
tensor([5, 2, 7, 1, 6, 4, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 6, 0, 7, 3, 4, 1]
tensor([5, 2, 6, 0, 7, 3, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 7, 2, 5, 4, 3, 0]
tensor([6, 1, 7, 2, 5, 4, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 7, 2, 4, 1, 5, 0]
tensor([6, 3, 7, 2, 4, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 5, 6, 2, 3, 1, 4, 0]
tensor([7, 5, 6, 2, 3, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 2, 5, 4, 1, 0, 1, 3]
tensor([0, 2, 5, 4, 1, 0, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1.0, 1.0, 0, 1.0, 1]
tensor([0, 1, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
Normal merging for layer 1
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Normal merging for layer 2
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 4
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 5 to 8
done!
Normal merging for layer 9
tensor([0, 5])
tensor(0)
tensor([4, 6])
tensor(4)
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
done!
Cross-layer merge completed for layers 10 to 30
done!
Normal merging for layer 31
tensor([0, 5])
tensor(0)
tensor([1, 2, 3, 4, 6, 7])
tensor(1)
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 19 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.1348 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 18 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

190
cuda:6
wnli
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:58<00:58, 58.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:15<00:00, 34.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:15<00:00, 37.91s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140437046298288 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140437046298288 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140437046298288 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140437046298288 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140448011883280 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140448011883280 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140448011883280 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140448011883280 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2573.59it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:01<03:41,  1.57s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:02<01:37,  1.42it/s]Running loglikelihood requests:   4%|▎         | 5/142 [00:03<01:14,  1.83it/s]Running loglikelihood requests:   5%|▍         | 7/142 [00:03<01:05,  2.08it/s]Running loglikelihood requests:   6%|▋         | 9/142 [00:04<00:59,  2.25it/s]Running loglikelihood requests:   8%|▊         | 11/142 [00:05<00:54,  2.39it/s]Running loglikelihood requests:   9%|▉         | 13/142 [00:06<00:51,  2.49it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:06<00:48,  2.60it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:07<00:46,  2.69it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:08<00:43,  2.80it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:08<00:42,  2.87it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:09<00:40,  2.96it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:10<00:38,  3.03it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:10<00:37,  3.09it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:11<00:36,  3.13it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:11<00:35,  3.17it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:12<00:34,  3.19it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:13<00:33,  3.21it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:13<00:32,  3.22it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:14<00:31,  3.24it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:15<00:31,  3.25it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:15<00:30,  3.24it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:16<00:29,  3.30it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:16<00:28,  3.33it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:17<00:28,  3.32it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:18<00:26,  3.39it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:18<00:25,  3.45it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:19<00:24,  3.49it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:19<00:24,  3.50it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:20<00:23,  3.52it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:20<00:22,  3.55it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:21<00:22,  3.55it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:21<00:21,  3.57it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:22<00:20,  3.59it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:23<00:20,  3.56it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:23<00:19,  3.58it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:24<00:19,  3.54it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [00:24<00:19,  3.53it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [00:25<00:18,  3.56it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [00:25<00:17,  3.62it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [00:26<00:16,  3.64it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [00:26<00:16,  3.67it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [00:27<00:15,  3.68it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [00:27<00:14,  3.71it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [00:28<00:14,  3.73it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [00:29<00:13,  3.74it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [00:29<00:13,  3.76it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [00:30<00:12,  3.77it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [00:30<00:12,  3.72it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [00:31<00:11,  3.72it/s]Running loglikelihood requests:  71%|███████   | 101/142 [00:31<00:11,  3.72it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [00:32<00:10,  3.73it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [00:32<00:09,  3.75it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [00:33<00:09,  3.77it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [00:33<00:08,  3.77it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [00:34<00:08,  3.73it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [00:34<00:07,  3.79it/s]Running loglikelihood requests:  81%|████████  | 115/142 [00:35<00:07,  3.82it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [00:35<00:06,  3.85it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [00:36<00:05,  3.88it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [00:36<00:05,  3.90it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [00:37<00:04,  3.92it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [00:37<00:04,  3.91it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [00:38<00:03,  3.89it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [00:38<00:03,  3.91it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [00:39<00:02,  3.94it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [00:39<00:02,  3.98it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [00:40<00:01,  4.02it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [00:40<00:01,  4.06it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [00:41<00:00,  4.09it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [00:41<00:00,  4.14it/s]Running loglikelihood requests: 100%|██████████| 142/142 [00:41<00:00,  3.39it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:7'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:7'}
full model:
{'wnli': {'alias': 'wnli', 'acc,none': 0.5352112676056338, 'acc_stderr,none': 0.0596130578497224}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.31190044950254875
0.7306280553786256
0.6985925052465822
0.5843516732063875
0.8124235844589114
0.820438203921003
0.6253838264581936
0.7600037006947045
0.8225872978677496
0.708398461303215
0.8646089269479391
0.8239362351853257
0.7608099850331435
0.6657423857513638
0.7943257460202938
0.7511476003698512
0.9073696655228775
0.8741838353767599
0.7945799099309127
0.9323691001541556
0.865243808509542
0.8176606226311932
0.6785099625983169
0.9579534328203848
0.788928884938056
0.9833718962298513
0.5933012307657521
0.7829988799240639
0.7823073743206628
0.31190044950254875
0.7306280553786256
0.6985925052465822
0.5843516732063875
0.8124235844589114
0.820438203921003
0.6253838264581936
0.7600037006947045
0.8225872978677496
0.708398461303215
0.8646089269479391
0.8239362351853257
0.7608099850331435
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[7, 4, 5, 1, 6, 3, 2, 0]
tensor([7, 4, 5, 1, 6, 3, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 2, 4, 5, 6, 1, 0, 3]
tensor([7, 2, 4, 5, 6, 1, 0, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 7, 5, 4, 1, 2, 0]
tensor([6, 3, 7, 5, 4, 1, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 3, 6, 4, 7, 1, 2, 0]
tensor([5, 3, 6, 4, 7, 1, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 3, 6, 5, 7, 2, 1, 0]
tensor([4, 3, 6, 5, 7, 2, 1, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1, 2, 3, 2, 3, 0]
tensor([0, 1, 1, 2, 3, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 1, 2, 2, 3, 0, 3, 1]
tensor([0, 1, 2, 2, 3, 0, 3, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 1, 1, 1.0, 1.0, 1.0, 1.0]
tensor([0, 0, 1, 1, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
Normal merging for layer 1
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
done!
Normal merging for layer 2
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
tensor([3])
tensor(3)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Normal merging for layer 4
tensor([7])
tensor(7)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 5 to 15
done!
Normal merging for layer 16
tensor([0, 7])
tensor(0)
tensor([1, 2])
tensor(1)
tensor([3, 5])
tensor(3)
tensor([4, 6])
tensor(4)
done!
Normal merging for layer 17
tensor([0, 5])
tensor(0)
tensor([1, 7])
tensor(1)
tensor([2, 3])
tensor(2)
tensor([4, 6])
tensor(4)
done!
Cross-layer merge completed for layers 18 to 30
done!
Normal merging for layer 31
tensor([0, 1])
tensor(0)
tensor([2, 3, 4, 5, 6, 7])
tensor(2)
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 18 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.2608 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 17 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

121
cuda:7
sciq
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:56<00:56, 56.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:14<00:00, 33.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:14<00:00, 37.09s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq HTTP/1.1" 200 1237
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/sciq/sciq.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq HTTP/1.1" 200 1237
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/allenai/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/allenai/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:filelock:Attempting to acquire lock 140430675221808 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:filelock:Lock 140430675221808 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430675221808 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:filelock:Lock 140430675221808 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:filelock:Attempting to acquire lock 140438523072336 on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:filelock:Lock 140438523072336 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_info.json
DEBUG:filelock:Attempting to release lock 140438523072336 on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:filelock:Lock 140438523072336 released on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of sciq from None to 0
INFO:lm_eval.api.task:Building contexts for sciq on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1031.78it/s]
DEBUG:lm_eval.evaluator:Task: sciq; number of requests on this rank: 400
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/400 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/400 [00:04<28:37,  4.30s/it]Running loglikelihood requests:   0%|          | 2/400 [00:07<25:19,  3.82s/it]Running loglikelihood requests:   1%|          | 3/400 [00:11<24:34,  3.71s/it]Running loglikelihood requests:   1%|          | 4/400 [00:15<24:20,  3.69s/it]Running loglikelihood requests:   1%|▏         | 5/400 [00:18<23:28,  3.57s/it]Running loglikelihood requests:   2%|▏         | 6/400 [00:21<22:45,  3.47s/it]Running loglikelihood requests:   2%|▏         | 7/400 [00:24<22:21,  3.41s/it]Running loglikelihood requests:   2%|▏         | 8/400 [00:28<22:10,  3.39s/it]Running loglikelihood requests:   2%|▏         | 9/400 [00:31<21:15,  3.26s/it]Running loglikelihood requests:   2%|▎         | 10/400 [00:34<20:43,  3.19s/it]Running loglikelihood requests:   3%|▎         | 11/400 [00:37<20:08,  3.11s/it]Running loglikelihood requests:   3%|▎         | 12/400 [00:40<19:41,  3.05s/it]Running loglikelihood requests:   3%|▎         | 13/400 [00:42<19:09,  2.97s/it]Running loglikelihood requests:   4%|▎         | 14/400 [00:45<18:45,  2.92s/it]Running loglikelihood requests:   4%|▍         | 15/400 [00:48<18:11,  2.83s/it]Running loglikelihood requests:   4%|▍         | 16/400 [00:51<17:47,  2.78s/it]Running loglikelihood requests:   4%|▍         | 17/400 [00:53<17:21,  2.72s/it]Running loglikelihood requests:   4%|▍         | 18/400 [00:56<17:00,  2.67s/it]Running loglikelihood requests:   5%|▍         | 19/400 [00:58<17:02,  2.68s/it]Running loglikelihood requests:   5%|▌         | 20/400 [01:01<17:05,  2.70s/it]Running loglikelihood requests:   5%|▌         | 21/400 [01:04<17:14,  2.73s/it]Running loglikelihood requests:   6%|▌         | 22/400 [01:07<17:14,  2.74s/it]Running loglikelihood requests:   6%|▌         | 23/400 [01:09<17:06,  2.72s/it]Running loglikelihood requests:   6%|▌         | 24/400 [01:12<17:05,  2.73s/it]Running loglikelihood requests:   6%|▋         | 25/400 [01:14<16:28,  2.64s/it]Running loglikelihood requests:   6%|▋         | 26/400 [01:17<15:57,  2.56s/it]Running loglikelihood requests:   7%|▋         | 27/400 [01:19<15:32,  2.50s/it]Running loglikelihood requests:   7%|▋         | 28/400 [01:22<15:17,  2.47s/it]Running loglikelihood requests:   7%|▋         | 29/400 [01:24<14:42,  2.38s/it]Running loglikelihood requests:   8%|▊         | 30/400 [01:26<14:30,  2.35s/it]Running loglikelihood requests:   8%|▊         | 31/400 [01:28<14:05,  2.29s/it]Running loglikelihood requests:   8%|▊         | 32/400 [01:30<13:48,  2.25s/it]Running loglikelihood requests:   8%|▊         | 33/400 [01:32<13:26,  2.20s/it]Running loglikelihood requests:   8%|▊         | 34/400 [01:35<13:25,  2.20s/it]Running loglikelihood requests:   9%|▉         | 35/400 [01:37<13:22,  2.20s/it]Running loglikelihood requests:   9%|▉         | 36/400 [01:39<13:06,  2.16s/it]Running loglikelihood requests:   9%|▉         | 37/400 [01:41<12:55,  2.14s/it]Running loglikelihood requests:  10%|▉         | 38/400 [01:43<12:59,  2.15s/it]Running loglikelihood requests:  10%|█         | 40/400 [01:45<09:46,  1.63s/it]Running loglikelihood requests:  10%|█         | 41/400 [01:47<10:07,  1.69s/it]Running loglikelihood requests:  10%|█         | 42/400 [01:49<10:22,  1.74s/it]Running loglikelihood requests:  11%|█         | 43/400 [01:51<10:34,  1.78s/it]Running loglikelihood requests:  11%|█         | 44/400 [01:53<10:49,  1.82s/it]Running loglikelihood requests:  11%|█▏        | 45/400 [01:55<10:44,  1.81s/it]Running loglikelihood requests:  12%|█▏        | 46/400 [01:56<10:40,  1.81s/it]Running loglikelihood requests:  12%|█▏        | 47/400 [01:58<10:43,  1.82s/it]Running loglikelihood requests:  12%|█▏        | 48/400 [02:00<10:40,  1.82s/it]Running loglikelihood requests:  12%|█▏        | 49/400 [02:02<10:32,  1.80s/it]Running loglikelihood requests:  12%|█▎        | 50/400 [02:04<10:31,  1.80s/it]Running loglikelihood requests:  13%|█▎        | 51/400 [02:05<10:27,  1.80s/it]Running loglikelihood requests:  13%|█▎        | 52/400 [02:07<10:25,  1.80s/it]Running loglikelihood requests:  13%|█▎        | 53/400 [02:09<10:01,  1.73s/it]Running loglikelihood requests:  14%|█▎        | 54/400 [02:11<09:54,  1.72s/it]Running loglikelihood requests:  14%|█▍        | 55/400 [02:12<09:42,  1.69s/it]Running loglikelihood requests:  14%|█▍        | 57/400 [02:14<07:20,  1.28s/it]Running loglikelihood requests:  14%|█▍        | 58/400 [02:15<07:50,  1.37s/it]Running loglikelihood requests:  15%|█▍        | 59/400 [02:17<07:58,  1.40s/it]Running loglikelihood requests:  16%|█▌        | 62/400 [02:19<05:21,  1.05it/s]Running loglikelihood requests:  16%|█▌        | 63/400 [02:20<06:02,  1.08s/it]Running loglikelihood requests:  16%|█▌        | 64/400 [02:22<06:34,  1.17s/it]Running loglikelihood requests:  16%|█▋        | 65/400 [02:23<06:53,  1.24s/it]Running loglikelihood requests:  16%|█▋        | 66/400 [02:25<07:12,  1.29s/it]Running loglikelihood requests:  17%|█▋        | 67/400 [02:26<07:23,  1.33s/it]Running loglikelihood requests:  17%|█▋        | 68/400 [02:27<07:30,  1.36s/it]Running loglikelihood requests:  17%|█▋        | 69/400 [02:29<07:40,  1.39s/it]Running loglikelihood requests:  18%|█▊        | 70/400 [02:30<07:40,  1.40s/it]Running loglikelihood requests:  18%|█▊        | 71/400 [02:32<07:39,  1.40s/it]Running loglikelihood requests:  18%|█▊        | 72/400 [02:33<07:53,  1.44s/it]Running loglikelihood requests:  18%|█▊        | 73/400 [02:35<07:57,  1.46s/it]Running loglikelihood requests:  18%|█▊        | 74/400 [02:36<07:58,  1.47s/it]Running loglikelihood requests:  19%|█▉        | 77/400 [02:38<04:50,  1.11it/s]Running loglikelihood requests:  20%|█▉        | 78/400 [02:39<05:19,  1.01it/s]Running loglikelihood requests:  20%|█▉        | 79/400 [02:40<05:47,  1.08s/it]Running loglikelihood requests:  20%|██        | 81/400 [02:42<04:54,  1.08it/s]Running loglikelihood requests:  20%|██        | 82/400 [02:43<05:13,  1.01it/s]Running loglikelihood requests:  21%|██        | 83/400 [02:44<05:32,  1.05s/it]Running loglikelihood requests:  21%|██        | 84/400 [02:45<05:50,  1.11s/it]Running loglikelihood requests:  21%|██▏       | 85/400 [02:47<05:57,  1.14s/it]Running loglikelihood requests:  22%|██▏       | 86/400 [02:48<06:03,  1.16s/it]Running loglikelihood requests:  22%|██▏       | 89/400 [02:49<03:55,  1.32it/s]Running loglikelihood requests:  22%|██▎       | 90/400 [02:50<04:27,  1.16it/s]Running loglikelihood requests:  23%|██▎       | 91/400 [02:52<05:02,  1.02it/s]Running loglikelihood requests:  23%|██▎       | 92/400 [02:53<05:21,  1.04s/it]Running loglikelihood requests:  23%|██▎       | 93/400 [02:54<05:39,  1.11s/it]Running loglikelihood requests:  24%|██▍       | 97/400 [02:56<03:12,  1.57it/s]Running loglikelihood requests:  24%|██▍       | 98/400 [02:57<03:47,  1.33it/s]Running loglikelihood requests:  25%|██▍       | 99/400 [02:58<04:17,  1.17it/s]Running loglikelihood requests:  25%|██▌       | 100/400 [02:59<04:41,  1.07it/s]Running loglikelihood requests:  25%|██▌       | 101/400 [03:00<04:59,  1.00s/it]Running loglikelihood requests:  26%|██▌       | 102/400 [03:02<05:14,  1.06s/it]Running loglikelihood requests:  26%|██▌       | 103/400 [03:03<05:38,  1.14s/it]Running loglikelihood requests:  26%|██▌       | 104/400 [03:04<05:39,  1.15s/it]Running loglikelihood requests:  26%|██▋       | 105/400 [03:06<06:01,  1.23s/it]Running loglikelihood requests:  26%|██▋       | 106/400 [03:07<06:01,  1.23s/it]Running loglikelihood requests:  27%|██▋       | 107/400 [03:08<05:55,  1.21s/it]Running loglikelihood requests:  27%|██▋       | 108/400 [03:09<05:56,  1.22s/it]Running loglikelihood requests:  27%|██▋       | 109/400 [03:10<05:51,  1.21s/it]Running loglikelihood requests:  28%|██▊       | 110/400 [03:12<05:50,  1.21s/it]Running loglikelihood requests:  28%|██▊       | 111/400 [03:13<05:48,  1.21s/it]Running loglikelihood requests:  28%|██▊       | 112/400 [03:14<05:47,  1.21s/it]Running loglikelihood requests:  28%|██▊       | 113/400 [03:15<05:40,  1.19s/it]Running loglikelihood requests:  28%|██▊       | 114/400 [03:16<05:33,  1.17s/it]Running loglikelihood requests:  29%|██▉       | 115/400 [03:18<05:30,  1.16s/it]Running loglikelihood requests:  29%|██▉       | 116/400 [03:19<05:29,  1.16s/it]Running loglikelihood requests:  29%|██▉       | 117/400 [03:20<05:25,  1.15s/it]Running loglikelihood requests:  30%|██▉       | 118/400 [03:21<05:31,  1.17s/it]Running loglikelihood requests:  30%|██▉       | 119/400 [03:22<05:22,  1.15s/it]Running loglikelihood requests:  30%|███       | 120/400 [03:23<05:16,  1.13s/it]Running loglikelihood requests:  30%|███       | 121/400 [03:24<05:14,  1.13s/it]Running loglikelihood requests:  30%|███       | 122/400 [03:26<05:21,  1.16s/it]Running loglikelihood requests:  31%|███       | 123/400 [03:27<05:16,  1.14s/it]Running loglikelihood requests:  31%|███       | 124/400 [03:28<05:40,  1.23s/it]Running loglikelihood requests:  31%|███▏      | 125/400 [03:29<05:29,  1.20s/it]Running loglikelihood requests:  32%|███▏      | 126/400 [03:30<05:23,  1.18s/it]Running loglikelihood requests:  32%|███▏      | 127/400 [03:31<05:14,  1.15s/it]Running loglikelihood requests:  32%|███▏      | 128/400 [03:33<05:13,  1.15s/it]Running loglikelihood requests:  32%|███▏      | 129/400 [03:34<05:04,  1.12s/it]Running loglikelihood requests:  32%|███▎      | 130/400 [03:35<05:01,  1.12s/it]Running loglikelihood requests:  33%|███▎      | 131/400 [03:36<05:02,  1.12s/it]Running loglikelihood requests:  34%|███▎      | 134/400 [03:37<03:04,  1.44it/s]Running loglikelihood requests:  34%|███▍      | 135/400 [03:38<03:25,  1.29it/s]Running loglikelihood requests:  34%|███▍      | 136/400 [03:39<03:42,  1.19it/s]Running loglikelihood requests:  34%|███▍      | 137/400 [03:40<04:13,  1.04it/s]Running loglikelihood requests:  34%|███▍      | 138/400 [03:41<04:18,  1.01it/s]Running loglikelihood requests:  35%|███▍      | 139/400 [03:43<04:23,  1.01s/it]Running loglikelihood requests:  36%|███▌      | 142/400 [03:44<02:52,  1.49it/s]Running loglikelihood requests:  36%|███▌      | 143/400 [03:45<03:12,  1.34it/s]Running loglikelihood requests:  36%|███▌      | 144/400 [03:46<03:34,  1.20it/s]Running loglikelihood requests:  36%|███▋      | 145/400 [03:47<03:45,  1.13it/s]Running loglikelihood requests:  36%|███▋      | 146/400 [03:48<03:56,  1.07it/s]Running loglikelihood requests:  37%|███▋      | 147/400 [03:49<04:06,  1.02it/s]Running loglikelihood requests:  37%|███▋      | 148/400 [03:50<04:14,  1.01s/it]Running loglikelihood requests:  37%|███▋      | 149/400 [03:51<04:13,  1.01s/it]Running loglikelihood requests:  38%|███▊      | 150/400 [03:52<04:22,  1.05s/it]Running loglikelihood requests:  38%|███▊      | 151/400 [03:53<04:24,  1.06s/it]Running loglikelihood requests:  38%|███▊      | 152/400 [03:55<04:27,  1.08s/it]Running loglikelihood requests:  38%|███▊      | 153/400 [03:56<04:30,  1.09s/it]Running loglikelihood requests:  38%|███▊      | 154/400 [03:57<04:27,  1.09s/it]Running loglikelihood requests:  39%|███▉      | 155/400 [03:58<04:26,  1.09s/it]Running loglikelihood requests:  39%|███▉      | 156/400 [03:59<04:30,  1.11s/it]Running loglikelihood requests:  39%|███▉      | 157/400 [04:00<04:23,  1.08s/it]Running loglikelihood requests:  40%|███▉      | 158/400 [04:01<04:16,  1.06s/it]Running loglikelihood requests:  40%|███▉      | 159/400 [04:02<04:12,  1.05s/it]Running loglikelihood requests:  40%|████      | 160/400 [04:03<04:10,  1.04s/it]Running loglikelihood requests:  40%|████      | 161/400 [04:04<04:04,  1.03s/it]Running loglikelihood requests:  40%|████      | 162/400 [04:05<04:05,  1.03s/it]Running loglikelihood requests:  41%|████      | 163/400 [04:06<04:03,  1.03s/it]Running loglikelihood requests:  41%|████      | 164/400 [04:07<04:03,  1.03s/it]Running loglikelihood requests:  41%|████▏     | 165/400 [04:08<04:01,  1.03s/it]Running loglikelihood requests:  42%|████▏     | 166/400 [04:09<03:57,  1.01s/it]Running loglikelihood requests:  42%|████▏     | 167/400 [04:10<03:58,  1.02s/it]Running loglikelihood requests:  42%|████▏     | 168/400 [04:11<03:53,  1.01s/it]Running loglikelihood requests:  42%|████▏     | 169/400 [04:12<03:54,  1.02s/it]Running loglikelihood requests:  42%|████▎     | 170/400 [04:13<03:55,  1.02s/it]Running loglikelihood requests:  43%|████▎     | 172/400 [04:14<02:59,  1.27it/s]Running loglikelihood requests:  43%|████▎     | 173/400 [04:15<03:09,  1.20it/s]Running loglikelihood requests:  44%|████▎     | 174/400 [04:16<03:18,  1.14it/s]Running loglikelihood requests:  44%|████▍     | 177/400 [04:17<02:09,  1.73it/s]Running loglikelihood requests:  44%|████▍     | 178/400 [04:18<02:34,  1.43it/s]Running loglikelihood requests:  45%|████▍     | 179/400 [04:19<02:52,  1.28it/s]Running loglikelihood requests:  45%|████▌     | 180/400 [04:21<03:06,  1.18it/s]Running loglikelihood requests:  45%|████▌     | 181/400 [04:22<03:15,  1.12it/s]Running loglikelihood requests:  46%|████▌     | 182/400 [04:22<03:17,  1.10it/s]Running loglikelihood requests:  46%|████▌     | 183/400 [04:23<03:21,  1.08it/s]Running loglikelihood requests:  46%|████▌     | 184/400 [04:24<03:26,  1.04it/s]Running loglikelihood requests:  46%|████▋     | 185/400 [04:25<03:26,  1.04it/s]Running loglikelihood requests:  46%|████▋     | 186/400 [04:26<03:29,  1.02it/s]Running loglikelihood requests:  47%|████▋     | 187/400 [04:27<03:25,  1.04it/s]Running loglikelihood requests:  47%|████▋     | 188/400 [04:28<03:24,  1.04it/s]Running loglikelihood requests:  47%|████▋     | 189/400 [04:29<03:18,  1.06it/s]Running loglikelihood requests:  48%|████▊     | 190/400 [04:30<03:24,  1.03it/s]Running loglikelihood requests:  48%|████▊     | 191/400 [04:31<03:21,  1.04it/s]Running loglikelihood requests:  48%|████▊     | 192/400 [04:32<03:16,  1.06it/s]Running loglikelihood requests:  48%|████▊     | 193/400 [04:33<03:17,  1.05it/s]Running loglikelihood requests:  48%|████▊     | 194/400 [04:34<03:13,  1.06it/s]Running loglikelihood requests:  49%|████▉     | 195/400 [04:35<03:12,  1.06it/s]Running loglikelihood requests:  49%|████▉     | 196/400 [04:36<03:07,  1.09it/s]Running loglikelihood requests:  49%|████▉     | 197/400 [04:37<03:04,  1.10it/s]Running loglikelihood requests:  50%|████▉     | 198/400 [04:38<03:08,  1.07it/s]Running loglikelihood requests:  50%|████▉     | 199/400 [04:39<03:04,  1.09it/s]Running loglikelihood requests:  50%|█████     | 200/400 [04:40<03:06,  1.07it/s]Running loglikelihood requests:  50%|█████     | 201/400 [04:40<03:04,  1.08it/s]Running loglikelihood requests:  50%|█████     | 202/400 [04:41<03:03,  1.08it/s]Running loglikelihood requests:  51%|█████     | 203/400 [04:42<03:01,  1.09it/s]Running loglikelihood requests:  51%|█████     | 204/400 [04:43<02:56,  1.11it/s]Running loglikelihood requests:  51%|█████▏    | 205/400 [04:44<02:59,  1.09it/s]Running loglikelihood requests:  52%|█████▏    | 206/400 [04:45<02:54,  1.11it/s]Running loglikelihood requests:  52%|█████▏    | 207/400 [04:46<02:51,  1.13it/s]Running loglikelihood requests:  52%|█████▏    | 208/400 [04:47<02:54,  1.10it/s]Running loglikelihood requests:  52%|█████▏    | 209/400 [04:48<03:02,  1.05it/s]Running loglikelihood requests:  53%|█████▎    | 212/400 [04:49<01:48,  1.74it/s]Running loglikelihood requests:  53%|█████▎    | 213/400 [04:50<01:57,  1.59it/s]Running loglikelihood requests:  54%|█████▎    | 214/400 [04:50<02:08,  1.45it/s]Running loglikelihood requests:  54%|█████▍    | 215/400 [04:51<02:16,  1.36it/s]Running loglikelihood requests:  54%|█████▍    | 216/400 [04:52<02:25,  1.27it/s]Running loglikelihood requests:  54%|█████▍    | 217/400 [04:53<02:26,  1.25it/s]Running loglikelihood requests:  55%|█████▍    | 218/400 [04:54<02:29,  1.21it/s]Running loglikelihood requests:  55%|█████▍    | 219/400 [04:55<02:38,  1.14it/s]Running loglikelihood requests:  55%|█████▌    | 220/400 [04:56<02:50,  1.06it/s]Running loglikelihood requests:  55%|█████▌    | 221/400 [04:57<02:51,  1.04it/s]Running loglikelihood requests:  56%|█████▌    | 222/400 [04:58<02:42,  1.09it/s]Running loglikelihood requests:  56%|█████▌    | 223/400 [04:59<02:39,  1.11it/s]Running loglikelihood requests:  56%|█████▌    | 224/400 [05:00<02:43,  1.08it/s]Running loglikelihood requests:  56%|█████▋    | 225/400 [05:01<02:38,  1.10it/s]Running loglikelihood requests:  56%|█████▋    | 226/400 [05:02<02:39,  1.09it/s]Running loglikelihood requests:  57%|█████▋    | 227/400 [05:03<02:43,  1.06it/s]Running loglikelihood requests:  57%|█████▋    | 228/400 [05:03<02:35,  1.10it/s]Running loglikelihood requests:  57%|█████▋    | 229/400 [05:04<02:38,  1.08it/s]Running loglikelihood requests:  57%|█████▊    | 230/400 [05:06<02:59,  1.06s/it]Running loglikelihood requests:  58%|█████▊    | 231/400 [05:07<02:55,  1.04s/it]Running loglikelihood requests:  58%|█████▊    | 232/400 [05:07<02:42,  1.03it/s]Running loglikelihood requests:  58%|█████▊    | 233/400 [05:09<02:44,  1.02it/s]Running loglikelihood requests:  58%|█████▊    | 234/400 [05:10<03:25,  1.24s/it]Running loglikelihood requests:  59%|█████▉    | 235/400 [05:11<03:01,  1.10s/it]Running loglikelihood requests:  59%|█████▉    | 236/400 [05:12<02:58,  1.09s/it]Running loglikelihood requests:  59%|█████▉    | 237/400 [05:13<02:47,  1.03s/it]Running loglikelihood requests:  60%|██████    | 240/400 [05:14<01:36,  1.66it/s]Running loglikelihood requests:  60%|██████    | 241/400 [05:15<01:49,  1.45it/s]Running loglikelihood requests:  60%|██████    | 242/400 [05:16<01:53,  1.39it/s]Running loglikelihood requests:  61%|██████    | 243/400 [05:17<01:56,  1.35it/s]Running loglikelihood requests:  61%|██████    | 244/400 [05:17<02:04,  1.25it/s]Running loglikelihood requests:  61%|██████▏   | 245/400 [05:18<02:07,  1.22it/s]Running loglikelihood requests:  62%|██████▏   | 246/400 [05:19<02:08,  1.20it/s]Running loglikelihood requests:  62%|██████▏   | 247/400 [05:20<02:08,  1.19it/s]Running loglikelihood requests:  62%|██████▏   | 248/400 [05:21<02:04,  1.22it/s]Running loglikelihood requests:  62%|██████▏   | 249/400 [05:22<02:17,  1.10it/s]Running loglikelihood requests:  62%|██████▎   | 250/400 [05:23<02:13,  1.12it/s]Running loglikelihood requests:  63%|██████▎   | 251/400 [05:24<02:11,  1.14it/s]Running loglikelihood requests:  63%|██████▎   | 252/400 [05:25<02:14,  1.10it/s]Running loglikelihood requests:  63%|██████▎   | 253/400 [05:26<02:13,  1.10it/s]Running loglikelihood requests:  64%|██████▎   | 254/400 [05:26<02:08,  1.14it/s]Running loglikelihood requests:  64%|██████▍   | 255/400 [05:27<02:07,  1.14it/s]Running loglikelihood requests:  64%|██████▍   | 256/400 [05:28<02:00,  1.19it/s]Running loglikelihood requests:  64%|██████▍   | 257/400 [05:29<02:00,  1.19it/s]Running loglikelihood requests:  64%|██████▍   | 258/400 [05:30<02:02,  1.16it/s]Running loglikelihood requests:  65%|██████▍   | 259/400 [05:31<02:00,  1.17it/s]Running loglikelihood requests:  65%|██████▌   | 260/400 [05:31<01:56,  1.20it/s]Running loglikelihood requests:  65%|██████▌   | 261/400 [05:32<01:59,  1.16it/s]Running loglikelihood requests:  66%|██████▌   | 262/400 [05:33<01:55,  1.20it/s]Running loglikelihood requests:  66%|██████▌   | 263/400 [05:34<01:49,  1.25it/s]Running loglikelihood requests:  66%|██████▌   | 264/400 [05:35<01:51,  1.21it/s]Running loglikelihood requests:  66%|██████▋   | 265/400 [05:35<01:50,  1.22it/s]Running loglikelihood requests:  66%|██████▋   | 266/400 [05:36<01:45,  1.26it/s]Running loglikelihood requests:  67%|██████▋   | 267/400 [05:37<01:40,  1.33it/s]Running loglikelihood requests:  67%|██████▋   | 268/400 [05:38<01:46,  1.24it/s]Running loglikelihood requests:  67%|██████▋   | 269/400 [05:39<01:47,  1.21it/s]Running loglikelihood requests:  68%|██████▊   | 270/400 [05:39<01:44,  1.24it/s]Running loglikelihood requests:  68%|██████▊   | 271/400 [05:40<01:37,  1.32it/s]Running loglikelihood requests:  68%|██████▊   | 272/400 [05:41<01:39,  1.28it/s]Running loglikelihood requests:  68%|██████▊   | 273/400 [05:42<01:38,  1.28it/s]Running loglikelihood requests:  68%|██████▊   | 274/400 [05:42<01:31,  1.38it/s]Running loglikelihood requests:  69%|██████▉   | 275/400 [05:43<01:32,  1.35it/s]Running loglikelihood requests:  69%|██████▉   | 276/400 [05:44<01:38,  1.26it/s]Running loglikelihood requests:  69%|██████▉   | 277/400 [05:45<01:39,  1.24it/s]Running loglikelihood requests:  70%|██████▉   | 278/400 [05:45<01:32,  1.32it/s]Running loglikelihood requests:  70%|██████▉   | 279/400 [05:46<01:26,  1.40it/s]Running loglikelihood requests:  70%|███████   | 280/400 [05:47<01:24,  1.43it/s]Running loglikelihood requests:  70%|███████   | 281/400 [05:47<01:24,  1.41it/s]Running loglikelihood requests:  70%|███████   | 282/400 [05:48<01:25,  1.38it/s]Running loglikelihood requests:  71%|███████   | 283/400 [05:49<01:23,  1.40it/s]Running loglikelihood requests:  71%|███████   | 284/400 [05:50<01:22,  1.40it/s]Running loglikelihood requests:  71%|███████▏  | 285/400 [05:50<01:24,  1.37it/s]Running loglikelihood requests:  72%|███████▏  | 286/400 [05:51<01:22,  1.38it/s]Running loglikelihood requests:  72%|███████▏  | 287/400 [05:52<01:17,  1.46it/s]Running loglikelihood requests:  72%|███████▏  | 288/400 [05:52<01:15,  1.49it/s]Running loglikelihood requests:  72%|███████▏  | 289/400 [05:53<01:24,  1.31it/s]Running loglikelihood requests:  72%|███████▎  | 290/400 [05:54<01:21,  1.35it/s]Running loglikelihood requests:  73%|███████▎  | 291/400 [05:55<01:19,  1.38it/s]Running loglikelihood requests:  73%|███████▎  | 292/400 [05:55<01:17,  1.40it/s]Running loglikelihood requests:  73%|███████▎  | 293/400 [05:56<01:15,  1.42it/s]Running loglikelihood requests:  74%|███████▎  | 294/400 [05:57<01:13,  1.45it/s]Running loglikelihood requests:  74%|███████▍  | 295/400 [05:57<01:11,  1.47it/s]Running loglikelihood requests:  74%|███████▍  | 296/400 [05:58<01:10,  1.47it/s]Running loglikelihood requests:  74%|███████▍  | 297/400 [05:59<01:10,  1.46it/s]Running loglikelihood requests:  74%|███████▍  | 298/400 [05:59<01:06,  1.53it/s]Running loglikelihood requests:  75%|███████▍  | 299/400 [06:00<01:04,  1.56it/s]Running loglikelihood requests:  75%|███████▌  | 300/400 [06:01<01:06,  1.51it/s]Running loglikelihood requests:  75%|███████▌  | 301/400 [06:02<01:12,  1.36it/s]Running loglikelihood requests:  76%|███████▌  | 302/400 [06:02<01:13,  1.34it/s]Running loglikelihood requests:  76%|███████▌  | 303/400 [06:03<01:07,  1.44it/s]Running loglikelihood requests:  76%|███████▌  | 304/400 [06:03<01:02,  1.52it/s]Running loglikelihood requests:  76%|███████▋  | 305/400 [06:04<01:04,  1.47it/s]Running loglikelihood requests:  76%|███████▋  | 306/400 [06:05<01:06,  1.41it/s]Running loglikelihood requests:  77%|███████▋  | 307/400 [06:06<01:05,  1.42it/s]Running loglikelihood requests:  78%|███████▊  | 310/400 [06:06<00:39,  2.30it/s]Running loglikelihood requests:  78%|███████▊  | 311/400 [06:07<00:44,  2.00it/s]Running loglikelihood requests:  78%|███████▊  | 312/400 [06:08<00:45,  1.94it/s]Running loglikelihood requests:  78%|███████▊  | 313/400 [06:09<00:53,  1.63it/s]Running loglikelihood requests:  78%|███████▊  | 314/400 [06:09<00:56,  1.53it/s]Running loglikelihood requests:  79%|███████▉  | 315/400 [06:10<00:57,  1.48it/s]Running loglikelihood requests:  79%|███████▉  | 316/400 [06:11<00:57,  1.45it/s]Running loglikelihood requests:  79%|███████▉  | 317/400 [06:11<00:54,  1.51it/s]Running loglikelihood requests:  80%|███████▉  | 318/400 [06:12<01:00,  1.36it/s]Running loglikelihood requests:  80%|███████▉  | 319/400 [06:13<00:59,  1.36it/s]Running loglikelihood requests:  80%|████████  | 321/400 [06:14<00:41,  1.91it/s]Running loglikelihood requests:  80%|████████  | 322/400 [06:14<00:41,  1.87it/s]Running loglikelihood requests:  81%|████████  | 323/400 [06:15<00:47,  1.61it/s]Running loglikelihood requests:  81%|████████  | 324/400 [06:17<01:11,  1.07it/s]Running loglikelihood requests:  81%|████████▏ | 325/400 [06:17<01:02,  1.19it/s]Running loglikelihood requests:  82%|████████▏ | 326/400 [06:18<00:55,  1.33it/s]Running loglikelihood requests:  82%|████████▏ | 327/400 [06:18<00:50,  1.45it/s]Running loglikelihood requests:  82%|████████▏ | 328/400 [06:20<00:57,  1.24it/s]Running loglikelihood requests:  82%|████████▏ | 329/400 [06:21<01:12,  1.03s/it]Running loglikelihood requests:  82%|████████▎ | 330/400 [06:22<01:01,  1.14it/s]Running loglikelihood requests:  83%|████████▎ | 331/400 [06:22<00:53,  1.29it/s]Running loglikelihood requests:  83%|████████▎ | 332/400 [06:23<00:52,  1.29it/s]Running loglikelihood requests:  83%|████████▎ | 333/400 [06:24<00:54,  1.23it/s]Running loglikelihood requests:  84%|████████▎ | 334/400 [06:25<00:51,  1.29it/s]Running loglikelihood requests:  84%|████████▍ | 335/400 [06:25<00:45,  1.44it/s]Running loglikelihood requests:  84%|████████▍ | 336/400 [06:26<00:45,  1.40it/s]Running loglikelihood requests:  84%|████████▍ | 337/400 [06:26<00:44,  1.42it/s]Running loglikelihood requests:  84%|████████▍ | 338/400 [06:27<00:40,  1.55it/s]Running loglikelihood requests:  85%|████████▍ | 339/400 [06:28<00:37,  1.62it/s]Running loglikelihood requests:  85%|████████▌ | 340/400 [06:28<00:37,  1.61it/s]Running loglikelihood requests:  85%|████████▌ | 341/400 [06:29<00:37,  1.59it/s]Running loglikelihood requests:  86%|████████▌ | 342/400 [06:29<00:37,  1.56it/s]Running loglikelihood requests:  86%|████████▌ | 343/400 [06:30<00:34,  1.66it/s]Running loglikelihood requests:  86%|████████▌ | 344/400 [06:31<00:34,  1.63it/s]Running loglikelihood requests:  86%|████████▋ | 345/400 [06:31<00:35,  1.55it/s]Running loglikelihood requests:  86%|████████▋ | 346/400 [06:32<00:32,  1.64it/s]Running loglikelihood requests:  87%|████████▋ | 347/400 [06:32<00:31,  1.69it/s]Running loglikelihood requests:  87%|████████▋ | 348/400 [06:33<00:32,  1.61it/s]Running loglikelihood requests:  87%|████████▋ | 349/400 [06:34<00:31,  1.60it/s]Running loglikelihood requests:  88%|████████▊ | 350/400 [06:34<00:29,  1.70it/s]Running loglikelihood requests:  88%|████████▊ | 351/400 [06:35<00:27,  1.79it/s]Running loglikelihood requests:  88%|████████▊ | 352/400 [06:35<00:28,  1.66it/s]Running loglikelihood requests:  88%|████████▊ | 353/400 [06:36<00:28,  1.62it/s]Running loglikelihood requests:  88%|████████▊ | 354/400 [06:37<00:26,  1.72it/s]Running loglikelihood requests:  89%|████████▉ | 355/400 [06:37<00:25,  1.80it/s]Running loglikelihood requests:  89%|████████▉ | 356/400 [06:38<00:25,  1.70it/s]Running loglikelihood requests:  89%|████████▉ | 357/400 [06:38<00:25,  1.67it/s]Running loglikelihood requests:  90%|████████▉ | 358/400 [06:39<00:24,  1.71it/s]Running loglikelihood requests:  90%|████████▉ | 359/400 [06:40<00:23,  1.72it/s]Running loglikelihood requests:  90%|█████████ | 360/400 [06:40<00:23,  1.73it/s]Running loglikelihood requests:  90%|█████████ | 361/400 [06:41<00:21,  1.81it/s]Running loglikelihood requests:  90%|█████████ | 362/400 [06:41<00:21,  1.80it/s]Running loglikelihood requests:  91%|█████████ | 363/400 [06:42<00:21,  1.68it/s]Running loglikelihood requests:  91%|█████████ | 364/400 [06:42<00:20,  1.73it/s]Running loglikelihood requests:  91%|█████████▏| 365/400 [06:43<00:20,  1.72it/s]Running loglikelihood requests:  92%|█████████▏| 366/400 [06:43<00:18,  1.80it/s]Running loglikelihood requests:  92%|█████████▏| 368/400 [06:44<00:15,  2.06it/s]Running loglikelihood requests:  92%|█████████▏| 369/400 [06:45<00:15,  2.05it/s]Running loglikelihood requests:  92%|█████████▎| 370/400 [06:45<00:14,  2.01it/s]Running loglikelihood requests:  93%|█████████▎| 371/400 [06:46<00:16,  1.77it/s]Running loglikelihood requests:  93%|█████████▎| 373/400 [06:47<00:11,  2.25it/s]Running loglikelihood requests:  94%|█████████▎| 374/400 [06:47<00:12,  2.14it/s]Running loglikelihood requests:  94%|█████████▍| 375/400 [06:48<00:11,  2.11it/s]Running loglikelihood requests:  94%|█████████▍| 376/400 [06:48<00:12,  1.98it/s]Running loglikelihood requests:  94%|█████████▍| 377/400 [06:49<00:12,  1.90it/s]Running loglikelihood requests:  94%|█████████▍| 378/400 [06:49<00:12,  1.76it/s]Running loglikelihood requests:  95%|█████████▍| 379/400 [06:50<00:12,  1.66it/s]Running loglikelihood requests:  95%|█████████▌| 380/400 [06:51<00:11,  1.78it/s]Running loglikelihood requests:  95%|█████████▌| 381/400 [06:51<00:10,  1.87it/s]Running loglikelihood requests:  96%|█████████▌| 382/400 [06:52<00:10,  1.73it/s]Running loglikelihood requests:  96%|█████████▌| 383/400 [06:53<00:10,  1.60it/s]Running loglikelihood requests:  96%|█████████▌| 384/400 [06:53<00:09,  1.66it/s]Running loglikelihood requests:  96%|█████████▋| 385/400 [06:54<00:08,  1.78it/s]Running loglikelihood requests:  96%|█████████▋| 386/400 [06:54<00:07,  1.81it/s]Running loglikelihood requests:  97%|█████████▋| 387/400 [06:55<00:08,  1.54it/s]Running loglikelihood requests:  97%|█████████▋| 388/400 [06:56<00:07,  1.60it/s]Running loglikelihood requests:  97%|█████████▋| 389/400 [06:56<00:06,  1.73it/s]Running loglikelihood requests:  98%|█████████▊| 390/400 [06:56<00:05,  1.84it/s]Running loglikelihood requests:  98%|█████████▊| 391/400 [06:57<00:04,  1.83it/s]Running loglikelihood requests:  98%|█████████▊| 392/400 [06:58<00:04,  1.82it/s]Running loglikelihood requests:  98%|█████████▊| 393/400 [06:58<00:03,  1.82it/s]Running loglikelihood requests:  98%|█████████▊| 394/400 [06:59<00:03,  1.78it/s]Running loglikelihood requests:  99%|█████████▉| 395/400 [06:59<00:02,  1.76it/s]Running loglikelihood requests:  99%|█████████▉| 396/400 [07:00<00:02,  1.77it/s]Running loglikelihood requests:  99%|█████████▉| 397/400 [07:00<00:01,  1.80it/s]Running loglikelihood requests: 100%|█████████▉| 398/400 [07:01<00:01,  1.82it/s]Running loglikelihood requests: 100%|█████████▉| 399/400 [07:01<00:00,  1.82it/s]Running loglikelihood requests: 100%|██████████| 400/400 [07:02<00:00,  1.85it/s]Running loglikelihood requests: 100%|██████████| 400/400 [07:02<00:00,  1.06s/it]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:0'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}
full model:
{'sciq': {'alias': 'sciq', 'acc,none': 0.94, 'acc_stderr,none': 0.023868325657594204, 'acc_norm,none': 0.91, 'acc_norm_stderr,none': 0.028762349126466136}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.969062788859705
0.9024924890572922
0.7706109127217512
0.8221264026535647
0.9190490061886575
0.9866654579796295
0.6586322754204971
0.7962110384246164
0.8195614021629236
0.7124178311176441
0.787697814339696
0.7034455022322618
0.8136386046534271
0.8174990104652458
0.6784276389594894
0.8698440245672888
0.8886492811850213
0.6541737276411673
0.6560861559753316
0.8139845219953913
0.6714741870309046
0.6164364868717988
0.8331581872497299
0.9065420049234512
0.9246185715568276
0.7477515960551026
0.574165362968651
0.8586446364199891
0.8889771415746612
Total groups 70 exceeded the threshold, stopping comparison.
The group tensor is
[7, 3, 4, 2, 6, 1, 5, 0]
tensor([7, 3, 4, 2, 6, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 2, 5, 3, 4, 0, 7, 1]
tensor([6, 2, 5, 3, 4, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 3, 6, 2, 7, 1, 4, 0]
tensor([5, 3, 6, 2, 7, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 4, 2, 1, 3, 5, 1]
tensor([0, 0, 4, 2, 1, 3, 5, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 2, 3, 4, 5, 0, 1, 1]
tensor([0, 2, 3, 4, 5, 0, 1, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 1, 0, 2, 2, 3, 1]
tensor([0, 3, 1, 0, 2, 2, 3, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 3, 1, 1, 2, 2, 3, 0]
tensor([0, 3, 1, 1, 2, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 1, 1.0, 1.0, 1.0, 1.0, 1]
tensor([0, 0, 1, 1, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 2 to 4
done!
Normal merging for layer 5
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 6 to 9
done!
Normal merging for layer 10
tensor([0, 1])
tensor(0)
tensor([4, 7])
tensor(4)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 11 to 12
done!
Normal merging for layer 13
tensor([0, 5])
tensor(0)
tensor([6, 7])
tensor(6)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 14 to 19
done!
Normal merging for layer 20
tensor([0, 3])
tensor(0)
tensor([2, 7])
tensor(2)
tensor([4, 5])
tensor(4)
tensor([1, 6])
tensor(1)
done!
Normal merging for layer 21
tensor([0, 7])
tensor(0)
tensor([2, 3])
tensor(2)
tensor([4, 5])
tensor(4)
tensor([1, 6])
tensor(1)
done!
Cross-layer merge completed for layers 22 to 23
done!
Normal merging for layer 24
tensor([0, 1])
tensor(0)
tensor([2, 3, 4, 5, 6, 7])
tensor(2)
done!
Cross-layer merge completed for layers 25 to 31
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 17 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.2608 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 16 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

115
cuda:0
wnli
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [01:00<01:00, 60.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 34.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 38.33s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140430939479872 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140430939479872 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430939479872 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140430939479872 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140430945952944 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140430945952944 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430945952944 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140430945952944 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2575.69it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:01<03:35,  1.53s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:02<01:34,  1.47it/s]Running loglikelihood requests:   4%|▎         | 5/142 [00:03<01:12,  1.90it/s]Running loglikelihood requests:   5%|▍         | 7/142 [00:03<01:02,  2.15it/s]Running loglikelihood requests:   6%|▋         | 9/142 [00:04<00:57,  2.33it/s]Running loglikelihood requests:   8%|▊         | 11/142 [00:05<00:53,  2.47it/s]Running loglikelihood requests:   9%|▉         | 13/142 [00:05<00:50,  2.57it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:06<00:48,  2.64it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:07<00:45,  2.74it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:08<00:43,  2.85it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:08<00:41,  2.93it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:09<00:39,  3.02it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:09<00:37,  3.09it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:10<00:36,  3.14it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:11<00:35,  3.18it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:11<00:34,  3.22it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:12<00:33,  3.24it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:12<00:32,  3.26it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:13<00:32,  3.28it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:14<00:31,  3.29it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:14<00:30,  3.30it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:15<00:29,  3.32it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:15<00:28,  3.35it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:16<00:28,  3.39it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:17<00:27,  3.43it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:17<00:26,  3.47it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:18<00:25,  3.50it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:18<00:24,  3.54it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:19<00:24,  3.50it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:19<00:23,  3.53it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:20<00:22,  3.55it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:20<00:22,  3.57it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:21<00:21,  3.59it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:22<00:20,  3.60it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:22<00:20,  3.62it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:23<00:20,  3.50it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:23<00:19,  3.56it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [00:24<00:18,  3.60it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [00:24<00:17,  3.62it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [00:25<00:17,  3.61it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [00:25<00:16,  3.60it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [00:26<00:16,  3.63it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [00:27<00:15,  3.66it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [00:27<00:14,  3.69it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [00:28<00:14,  3.67it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [00:28<00:13,  3.71it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [00:29<00:13,  3.76it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [00:29<00:12,  3.74it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [00:30<00:11,  3.76it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [00:30<00:11,  3.78it/s]Running loglikelihood requests:  71%|███████   | 101/142 [00:31<00:10,  3.80it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [00:31<00:10,  3.83it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [00:32<00:09,  3.84it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [00:32<00:09,  3.85it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [00:33<00:08,  3.86it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [00:33<00:08,  3.87it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [00:34<00:07,  3.89it/s]Running loglikelihood requests:  81%|████████  | 115/142 [00:34<00:06,  3.90it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [00:35<00:06,  3.90it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [00:35<00:05,  3.92it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [00:36<00:05,  3.93it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [00:36<00:04,  3.95it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [00:37<00:04,  3.97it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [00:37<00:03,  3.98it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [00:38<00:03,  4.00it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [00:38<00:02,  4.01it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [00:39<00:02,  4.03it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [00:39<00:01,  4.06it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [00:40<00:01,  4.09it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [00:40<00:00,  4.11it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [00:41<00:00,  4.16it/s]Running loglikelihood requests: 100%|██████████| 142/142 [00:41<00:00,  3.44it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:1'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:1'}
full model:
{'wnli': {'alias': 'wnli', 'acc,none': 0.5352112676056338, 'acc_stderr,none': 0.0596130578497224}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.31190044950254875
0.7306280553786256
0.6985925052465822
0.5843516732063875
0.8124235844589114
0.820438203921003
0.6253838264581936
0.7600037006947045
0.8225872978677496
0.708398461303215
0.8646089269479391
0.8239362351853257
0.7608099850331435
0.6657423857513638
0.7943257460202938
0.7511476003698512
0.9073696655228775
0.8741838353767599
0.7945799099309127
0.9323691001541556
0.865243808509542
0.8176606226311932
0.6785099625983169
0.9579534328203848
0.788928884938056
0.9833718962298513
0.5933012307657521
0.7829988799240639
0.7823073743206628
0.31190044950254875
0.7306280553786256
0.6985925052465822
0.5843516732063875
0.8124235844589114
0.820438203921003
0.6253838264581936
0.7600037006947045
0.8225872978677496
0.708398461303215
0.8646089269479391
0.8239362351853257
0.7608099850331435
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[7, 4, 5, 1, 6, 3, 2, 0]
tensor([7, 4, 5, 1, 6, 3, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 2, 4, 5, 6, 1, 0, 3]
tensor([7, 2, 4, 5, 6, 1, 0, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 7, 5, 4, 1, 2, 0]
tensor([6, 3, 7, 5, 4, 1, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 3, 6, 4, 7, 1, 2, 0]
tensor([5, 3, 6, 4, 7, 1, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 3, 6, 5, 7, 2, 1, 0]
tensor([4, 3, 6, 5, 7, 2, 1, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1, 2, 3, 2, 3, 0]
tensor([0, 1, 1, 2, 3, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 1, 2, 2, 3, 0, 3, 1]
tensor([0, 1, 2, 2, 3, 0, 3, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 1, 1, 1.0, 1.0, 1.0, 1.0]
tensor([0, 0, 1, 1, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
Normal merging for layer 1
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
done!
Normal merging for layer 2
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
tensor([3])
tensor(3)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Normal merging for layer 4
tensor([7])
tensor(7)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 5 to 15
done!
Normal merging for layer 16
tensor([0, 7])
tensor(0)
tensor([1, 2])
tensor(1)
tensor([3, 5])
tensor(3)
tensor([4, 6])
tensor(4)
done!
Normal merging for layer 17
tensor([0, 5])
tensor(0)
tensor([1, 7])
tensor(1)
tensor([2, 3])
tensor(2)
tensor([4, 6])
tensor(4)
done!
Cross-layer merge completed for layers 18 to 30
done!
Normal merging for layer 31
tensor([0, 1])
tensor(0)
tensor([2, 3, 4, 5, 6, 7])
tensor(2)
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 16 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.2608 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 15 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

183
cuda:1
mastermind_24_easy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:58<00:58, 58.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 34.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 38.20s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_24_mcq_random HTTP/1.1" 200 772
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/flair/mastermind_24_mcq_random/flair/mastermind_24_mcq_random.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_24_mcq_random HTTP/1.1" 200 779
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/flair/mastermind_24_mcq_random/resolve/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_24_mcq_random/revision/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 779
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_24_mcq_random/tree/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5?recursive=False&expand=False HTTP/1.1" 200 290
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_24_mcq_random/tree/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5/data?recursive=False&expand=False HTTP/1.1" 200 358
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_24_mcq_random/revision/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 779
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/flair/mastermind_24_mcq_random/resolve/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:filelock:Attempting to acquire lock 140431072002016 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_24_mcq_random_default_0.0.0_cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5.lock
DEBUG:filelock:Lock 140431072002016 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_24_mcq_random_default_0.0.0_cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_24_mcq_random/default/0.0.0/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5/dataset_info.json
DEBUG:filelock:Attempting to release lock 140431072002016 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_24_mcq_random_default_0.0.0_cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5.lock
DEBUG:filelock:Lock 140431072002016 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_24_mcq_random_default_0.0.0_cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5.lock
DEBUG:filelock:Attempting to acquire lock 140430940687392 on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_24_mcq_random/default/0.0.0/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5_builder.lock
DEBUG:filelock:Lock 140430940687392 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_24_mcq_random/default/0.0.0/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_24_mcq_random/default/0.0.0/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430940687392 on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_24_mcq_random/default/0.0.0/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5_builder.lock
DEBUG:filelock:Lock 140430940687392 released on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_24_mcq_random/default/0.0.0/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mastermind_24_easy from None to 0
INFO:lm_eval.api.task:Building contexts for mastermind_24_easy on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1508.61it/s]
DEBUG:lm_eval.evaluator:Task: mastermind_24_easy; number of requests on this rank: 400
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/400 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/400 [00:01<12:26,  1.87s/it]Running loglikelihood requests:   0%|          | 2/400 [00:02<09:29,  1.43s/it]Running loglikelihood requests:   1%|          | 3/400 [00:04<08:30,  1.28s/it]Running loglikelihood requests:   1%|          | 4/400 [00:05<08:01,  1.22s/it]Running loglikelihood requests:   1%|▏         | 5/400 [00:06<07:43,  1.17s/it]Running loglikelihood requests:   2%|▏         | 6/400 [00:07<07:32,  1.15s/it]Running loglikelihood requests:   2%|▏         | 7/400 [00:08<07:24,  1.13s/it]Running loglikelihood requests:   2%|▏         | 8/400 [00:09<07:18,  1.12s/it]Running loglikelihood requests:   2%|▏         | 9/400 [00:10<07:14,  1.11s/it]Running loglikelihood requests:   2%|▎         | 10/400 [00:11<07:09,  1.10s/it]Running loglikelihood requests:   3%|▎         | 12/400 [00:12<05:22,  1.20it/s]Running loglikelihood requests:   3%|▎         | 13/400 [00:13<05:47,  1.11it/s]Running loglikelihood requests:   4%|▎         | 14/400 [00:15<06:05,  1.05it/s]Running loglikelihood requests:   4%|▍         | 16/400 [00:16<04:57,  1.29it/s]Running loglikelihood requests:   4%|▍         | 17/400 [00:17<05:24,  1.18it/s]Running loglikelihood requests:   4%|▍         | 18/400 [00:18<05:47,  1.10it/s]Running loglikelihood requests:   5%|▍         | 19/400 [00:19<06:04,  1.05it/s]Running loglikelihood requests:   5%|▌         | 20/400 [00:20<06:18,  1.01it/s]Running loglikelihood requests:   5%|▌         | 21/400 [00:21<06:24,  1.01s/it]Running loglikelihood requests:   6%|▌         | 22/400 [00:22<06:28,  1.03s/it]Running loglikelihood requests:   6%|▌         | 23/400 [00:23<06:31,  1.04s/it]Running loglikelihood requests:   6%|▋         | 25/400 [00:24<05:02,  1.24it/s]Running loglikelihood requests:   6%|▋         | 26/400 [00:25<05:25,  1.15it/s]Running loglikelihood requests:   7%|▋         | 27/400 [00:26<05:42,  1.09it/s]Running loglikelihood requests:   7%|▋         | 29/400 [00:27<04:39,  1.33it/s]Running loglikelihood requests:   8%|▊         | 30/400 [00:28<05:04,  1.21it/s]Running loglikelihood requests:   8%|▊         | 31/400 [00:30<05:29,  1.12it/s]Running loglikelihood requests:   8%|▊         | 32/400 [00:31<05:46,  1.06it/s]Running loglikelihood requests:   8%|▊         | 34/400 [00:32<04:41,  1.30it/s]Running loglikelihood requests:   9%|▉         | 35/400 [00:33<05:07,  1.19it/s]Running loglikelihood requests:  10%|▉         | 38/400 [00:34<03:37,  1.67it/s]Running loglikelihood requests:  10%|▉         | 39/400 [00:35<04:09,  1.45it/s]Running loglikelihood requests:  10%|█         | 40/400 [00:36<04:38,  1.29it/s]Running loglikelihood requests:  10%|█         | 41/400 [00:37<05:03,  1.18it/s]Running loglikelihood requests:  10%|█         | 42/400 [00:38<05:23,  1.11it/s]Running loglikelihood requests:  11%|█         | 43/400 [00:39<05:38,  1.05it/s]Running loglikelihood requests:  11%|█         | 44/400 [00:40<05:49,  1.02it/s]Running loglikelihood requests:  11%|█▏        | 45/400 [00:41<05:57,  1.01s/it]Running loglikelihood requests:  12%|█▏        | 47/400 [00:42<04:41,  1.25it/s]Running loglikelihood requests:  12%|█▏        | 48/400 [00:44<05:03,  1.16it/s]Running loglikelihood requests:  12%|█▏        | 49/400 [00:45<05:21,  1.09it/s]Running loglikelihood requests:  12%|█▎        | 50/400 [00:46<05:34,  1.05it/s]Running loglikelihood requests:  13%|█▎        | 52/400 [00:47<04:33,  1.27it/s]Running loglikelihood requests:  13%|█▎        | 53/400 [00:48<04:55,  1.18it/s]Running loglikelihood requests:  14%|█▎        | 54/400 [00:49<05:12,  1.11it/s]Running loglikelihood requests:  14%|█▍        | 56/400 [00:50<04:17,  1.34it/s]Running loglikelihood requests:  14%|█▍        | 57/400 [00:51<04:41,  1.22it/s]Running loglikelihood requests:  14%|█▍        | 58/400 [00:52<05:00,  1.14it/s]Running loglikelihood requests:  15%|█▍        | 59/400 [00:53<05:16,  1.08it/s]Running loglikelihood requests:  15%|█▌        | 60/400 [00:54<05:27,  1.04it/s]Running loglikelihood requests:  15%|█▌        | 61/400 [00:55<05:35,  1.01it/s]Running loglikelihood requests:  16%|█▌        | 62/400 [00:56<05:40,  1.01s/it]Running loglikelihood requests:  16%|█▌        | 63/400 [00:57<05:44,  1.02s/it]Running loglikelihood requests:  16%|█▌        | 64/400 [00:58<05:48,  1.04s/it]Running loglikelihood requests:  16%|█▋        | 65/400 [01:00<05:49,  1.04s/it]Running loglikelihood requests:  16%|█▋        | 66/400 [01:01<05:49,  1.05s/it]Running loglikelihood requests:  17%|█▋        | 67/400 [01:02<05:48,  1.05s/it]Running loglikelihood requests:  17%|█▋        | 68/400 [01:03<05:48,  1.05s/it]Running loglikelihood requests:  17%|█▋        | 69/400 [01:04<05:47,  1.05s/it]Running loglikelihood requests:  18%|█▊        | 70/400 [01:05<05:47,  1.05s/it]Running loglikelihood requests:  18%|█▊        | 71/400 [01:06<05:46,  1.05s/it]Running loglikelihood requests:  18%|█▊        | 72/400 [01:07<05:44,  1.05s/it]Running loglikelihood requests:  18%|█▊        | 73/400 [01:08<05:43,  1.05s/it]Running loglikelihood requests:  18%|█▊        | 74/400 [01:09<05:42,  1.05s/it]Running loglikelihood requests:  19%|█▉        | 76/400 [01:10<04:21,  1.24it/s]Running loglikelihood requests:  19%|█▉        | 77/400 [01:11<04:39,  1.15it/s]Running loglikelihood requests:  20%|█▉        | 78/400 [01:12<04:54,  1.09it/s]Running loglikelihood requests:  20%|█▉        | 79/400 [01:13<05:04,  1.05it/s]Running loglikelihood requests:  20%|██        | 80/400 [01:14<05:12,  1.02it/s]Running loglikelihood requests:  20%|██        | 81/400 [01:15<05:17,  1.00it/s]Running loglikelihood requests:  20%|██        | 82/400 [01:16<05:21,  1.01s/it]Running loglikelihood requests:  21%|██        | 83/400 [01:17<05:22,  1.02s/it]Running loglikelihood requests:  21%|██        | 84/400 [01:18<05:23,  1.03s/it]Running loglikelihood requests:  21%|██▏       | 85/400 [01:19<05:24,  1.03s/it]Running loglikelihood requests:  22%|██▏       | 87/400 [01:20<04:09,  1.25it/s]Running loglikelihood requests:  22%|██▏       | 88/400 [01:22<04:27,  1.17it/s]Running loglikelihood requests:  22%|██▏       | 89/400 [01:23<04:41,  1.11it/s]Running loglikelihood requests:  22%|██▎       | 90/400 [01:24<04:51,  1.06it/s]Running loglikelihood requests:  23%|██▎       | 91/400 [01:25<05:01,  1.02it/s]Running loglikelihood requests:  23%|██▎       | 92/400 [01:26<05:06,  1.01it/s]Running loglikelihood requests:  24%|██▎       | 94/400 [01:27<03:58,  1.28it/s]Running loglikelihood requests:  24%|██▍       | 95/400 [01:28<04:17,  1.19it/s]Running loglikelihood requests:  24%|██▍       | 96/400 [01:29<04:31,  1.12it/s]Running loglikelihood requests:  24%|██▍       | 98/400 [01:30<03:42,  1.36it/s]Running loglikelihood requests:  25%|██▌       | 100/400 [01:31<03:16,  1.53it/s]Running loglikelihood requests:  26%|██▌       | 102/400 [01:32<03:01,  1.65it/s]Running loglikelihood requests:  26%|██▌       | 103/400 [01:33<03:26,  1.44it/s]Running loglikelihood requests:  26%|██▌       | 104/400 [01:34<03:47,  1.30it/s]Running loglikelihood requests:  27%|██▋       | 107/400 [01:35<02:44,  1.78it/s]Running loglikelihood requests:  27%|██▋       | 108/400 [01:36<03:10,  1.54it/s]Running loglikelihood requests:  27%|██▋       | 109/400 [01:37<03:33,  1.37it/s]Running loglikelihood requests:  28%|██▊       | 110/400 [01:38<03:52,  1.25it/s]Running loglikelihood requests:  28%|██▊       | 111/400 [01:39<04:08,  1.16it/s]Running loglikelihood requests:  28%|██▊       | 112/400 [01:40<04:20,  1.10it/s]Running loglikelihood requests:  28%|██▊       | 113/400 [01:41<04:30,  1.06it/s]Running loglikelihood requests:  28%|██▊       | 114/400 [01:42<04:37,  1.03it/s]Running loglikelihood requests:  29%|██▉       | 116/400 [01:43<03:38,  1.30it/s]Running loglikelihood requests:  29%|██▉       | 117/400 [01:44<03:54,  1.20it/s]Running loglikelihood requests:  30%|██▉       | 118/400 [01:45<04:08,  1.14it/s]Running loglikelihood requests:  30%|███       | 121/400 [01:46<02:46,  1.67it/s]Running loglikelihood requests:  30%|███       | 122/400 [01:47<03:09,  1.46it/s]Running loglikelihood requests:  31%|███       | 123/400 [01:48<03:30,  1.32it/s]Running loglikelihood requests:  31%|███       | 124/400 [01:49<03:47,  1.22it/s]Running loglikelihood requests:  31%|███▏      | 125/400 [01:50<03:58,  1.15it/s]Running loglikelihood requests:  32%|███▏      | 126/400 [01:51<04:07,  1.11it/s]Running loglikelihood requests:  32%|███▏      | 127/400 [01:52<04:13,  1.08it/s]Running loglikelihood requests:  32%|███▏      | 128/400 [01:53<04:17,  1.05it/s]Running loglikelihood requests:  32%|███▎      | 130/400 [01:54<03:21,  1.34it/s]Running loglikelihood requests:  33%|███▎      | 132/400 [01:55<02:54,  1.54it/s]Running loglikelihood requests:  33%|███▎      | 133/400 [01:56<03:13,  1.38it/s]Running loglikelihood requests:  34%|███▎      | 134/400 [01:57<03:29,  1.27it/s]Running loglikelihood requests:  34%|███▍      | 135/400 [01:58<03:43,  1.19it/s]Running loglikelihood requests:  34%|███▍      | 136/400 [01:59<03:53,  1.13it/s]Running loglikelihood requests:  34%|███▍      | 137/400 [02:00<04:00,  1.09it/s]Running loglikelihood requests:  34%|███▍      | 138/400 [02:01<04:05,  1.07it/s]Running loglikelihood requests:  35%|███▍      | 139/400 [02:02<04:08,  1.05it/s]Running loglikelihood requests:  35%|███▌      | 140/400 [02:03<04:10,  1.04it/s]Running loglikelihood requests:  35%|███▌      | 141/400 [02:04<04:11,  1.03it/s]Running loglikelihood requests:  36%|███▌      | 142/400 [02:05<04:11,  1.03it/s]Running loglikelihood requests:  36%|███▌      | 143/400 [02:06<04:11,  1.02it/s]Running loglikelihood requests:  36%|███▋      | 145/400 [02:07<03:12,  1.32it/s]Running loglikelihood requests:  36%|███▋      | 146/400 [02:08<03:26,  1.23it/s]Running loglikelihood requests:  37%|███▋      | 147/400 [02:09<03:37,  1.16it/s]Running loglikelihood requests:  37%|███▋      | 148/400 [02:10<03:45,  1.12it/s]Running loglikelihood requests:  37%|███▋      | 149/400 [02:11<03:51,  1.09it/s]Running loglikelihood requests:  38%|███▊      | 150/400 [02:12<03:54,  1.06it/s]Running loglikelihood requests:  38%|███▊      | 152/400 [02:13<03:03,  1.35it/s]Running loglikelihood requests:  38%|███▊      | 153/400 [02:14<03:17,  1.25it/s]Running loglikelihood requests:  38%|███▊      | 154/400 [02:15<03:28,  1.18it/s]Running loglikelihood requests:  39%|███▉      | 155/400 [02:16<03:37,  1.13it/s]Running loglikelihood requests:  39%|███▉      | 157/400 [02:17<02:54,  1.40it/s]Running loglikelihood requests:  40%|███▉      | 158/400 [02:18<03:09,  1.28it/s]Running loglikelihood requests:  40%|████      | 160/400 [02:19<02:48,  1.42it/s]Running loglikelihood requests:  40%|████      | 161/400 [02:20<03:02,  1.31it/s]Running loglikelihood requests:  40%|████      | 162/400 [02:21<03:14,  1.22it/s]Running loglikelihood requests:  41%|████      | 163/400 [02:22<03:23,  1.16it/s]Running loglikelihood requests:  41%|████▏     | 165/400 [02:23<02:44,  1.43it/s]Running loglikelihood requests:  42%|████▏     | 166/400 [02:24<03:04,  1.27it/s]Running loglikelihood requests:  42%|████▏     | 167/400 [02:25<03:14,  1.20it/s]Running loglikelihood requests:  42%|████▏     | 168/400 [02:26<03:22,  1.15it/s]Running loglikelihood requests:  42%|████▎     | 170/400 [02:27<02:43,  1.41it/s]Running loglikelihood requests:  43%|████▎     | 171/400 [02:28<02:55,  1.30it/s]Running loglikelihood requests:  43%|████▎     | 172/400 [02:29<03:05,  1.23it/s]Running loglikelihood requests:  43%|████▎     | 173/400 [02:30<03:14,  1.17it/s]Running loglikelihood requests:  44%|████▎     | 174/400 [02:31<03:21,  1.12it/s]Running loglikelihood requests:  44%|████▍     | 175/400 [02:32<03:25,  1.09it/s]Running loglikelihood requests:  44%|████▍     | 176/400 [02:33<03:28,  1.08it/s]Running loglikelihood requests:  44%|████▍     | 178/400 [02:34<02:41,  1.37it/s]Running loglikelihood requests:  45%|████▍     | 179/400 [02:35<02:53,  1.27it/s]Running loglikelihood requests:  45%|████▌     | 180/400 [02:36<03:12,  1.14it/s]Running loglikelihood requests:  45%|████▌     | 181/400 [02:37<03:17,  1.11it/s]Running loglikelihood requests:  46%|████▌     | 183/400 [02:38<02:36,  1.39it/s]Running loglikelihood requests:  46%|████▌     | 184/400 [02:39<02:48,  1.29it/s]Running loglikelihood requests:  47%|████▋     | 187/400 [02:40<01:57,  1.82it/s]Running loglikelihood requests:  47%|████▋     | 188/400 [02:41<02:13,  1.59it/s]Running loglikelihood requests:  47%|████▋     | 189/400 [02:42<02:27,  1.43it/s]Running loglikelihood requests:  48%|████▊     | 190/400 [02:43<02:40,  1.31it/s]Running loglikelihood requests:  48%|████▊     | 191/400 [02:44<02:50,  1.23it/s]Running loglikelihood requests:  48%|████▊     | 192/400 [02:45<02:57,  1.17it/s]Running loglikelihood requests:  48%|████▊     | 193/400 [02:46<03:03,  1.13it/s]Running loglikelihood requests:  48%|████▊     | 194/400 [02:47<03:06,  1.10it/s]Running loglikelihood requests:  49%|████▉     | 196/400 [02:48<02:32,  1.34it/s]Running loglikelihood requests:  49%|████▉     | 197/400 [02:49<02:41,  1.25it/s]Running loglikelihood requests:  50%|████▉     | 198/400 [02:50<02:49,  1.19it/s]Running loglikelihood requests:  50%|████▉     | 199/400 [02:51<02:55,  1.15it/s]Running loglikelihood requests:  50%|█████     | 200/400 [02:52<02:59,  1.11it/s]Running loglikelihood requests:  50%|█████     | 202/400 [02:53<02:21,  1.40it/s]Running loglikelihood requests:  51%|█████     | 203/400 [02:54<02:32,  1.29it/s]Running loglikelihood requests:  51%|█████     | 204/400 [02:55<02:40,  1.22it/s]Running loglikelihood requests:  51%|█████▏    | 205/400 [02:56<02:47,  1.17it/s]Running loglikelihood requests:  52%|█████▏    | 206/400 [02:57<02:51,  1.13it/s]Running loglikelihood requests:  52%|█████▏    | 207/400 [02:58<02:55,  1.10it/s]Running loglikelihood requests:  52%|█████▎    | 210/400 [02:58<01:51,  1.71it/s]Running loglikelihood requests:  53%|█████▎    | 212/400 [02:59<01:43,  1.82it/s]Running loglikelihood requests:  53%|█████▎    | 213/400 [03:00<01:57,  1.59it/s]Running loglikelihood requests:  54%|█████▍    | 215/400 [03:01<01:46,  1.73it/s]Running loglikelihood requests:  54%|█████▍    | 216/400 [03:02<02:00,  1.53it/s]Running loglikelihood requests:  54%|█████▍    | 217/400 [03:03<02:12,  1.38it/s]Running loglikelihood requests:  55%|█████▍    | 219/400 [03:04<01:53,  1.59it/s]Running loglikelihood requests:  55%|█████▌    | 220/400 [03:05<02:06,  1.43it/s]Running loglikelihood requests:  55%|█████▌    | 221/400 [03:06<02:16,  1.31it/s]Running loglikelihood requests:  56%|█████▌    | 222/400 [03:07<02:24,  1.23it/s]Running loglikelihood requests:  56%|█████▌    | 223/400 [03:08<02:31,  1.17it/s]Running loglikelihood requests:  56%|█████▌    | 224/400 [03:09<02:35,  1.13it/s]Running loglikelihood requests:  56%|█████▋    | 225/400 [03:10<02:38,  1.11it/s]Running loglikelihood requests:  56%|█████▋    | 226/400 [03:11<02:40,  1.08it/s]Running loglikelihood requests:  57%|█████▋    | 227/400 [03:12<02:41,  1.07it/s]Running loglikelihood requests:  57%|█████▋    | 228/400 [03:13<02:41,  1.06it/s]Running loglikelihood requests:  57%|█████▋    | 229/400 [03:14<02:41,  1.06it/s]Running loglikelihood requests:  57%|█████▊    | 230/400 [03:15<02:41,  1.05it/s]Running loglikelihood requests:  58%|█████▊    | 231/400 [03:16<02:40,  1.05it/s]Running loglikelihood requests:  58%|█████▊    | 232/400 [03:17<02:40,  1.05it/s]Running loglikelihood requests:  58%|█████▊    | 233/400 [03:18<02:39,  1.05it/s]Running loglikelihood requests:  59%|█████▉    | 235/400 [03:19<02:01,  1.36it/s]Running loglikelihood requests:  59%|█████▉    | 236/400 [03:20<02:09,  1.26it/s]Running loglikelihood requests:  59%|█████▉    | 237/400 [03:21<02:15,  1.20it/s]Running loglikelihood requests:  60%|█████▉    | 238/400 [03:22<02:20,  1.15it/s]Running loglikelihood requests:  60%|█████▉    | 239/400 [03:22<02:23,  1.12it/s]Running loglikelihood requests:  60%|██████    | 240/400 [03:23<02:25,  1.10it/s]Running loglikelihood requests:  60%|██████    | 242/400 [03:24<01:53,  1.40it/s]Running loglikelihood requests:  61%|██████    | 243/400 [03:25<02:01,  1.29it/s]Running loglikelihood requests:  61%|██████    | 244/400 [03:26<02:08,  1.22it/s]Running loglikelihood requests:  61%|██████▏   | 245/400 [03:27<02:13,  1.17it/s]Running loglikelihood requests:  62%|██████▏   | 246/400 [03:28<02:16,  1.13it/s]Running loglikelihood requests:  62%|██████▏   | 247/400 [03:29<02:18,  1.11it/s]Running loglikelihood requests:  62%|██████▏   | 249/400 [03:30<01:47,  1.40it/s]Running loglikelihood requests:  62%|██████▎   | 250/400 [03:31<01:55,  1.30it/s]Running loglikelihood requests:  63%|██████▎   | 251/400 [03:32<02:01,  1.22it/s]Running loglikelihood requests:  63%|██████▎   | 252/400 [03:33<02:06,  1.17it/s]Running loglikelihood requests:  63%|██████▎   | 253/400 [03:34<02:09,  1.13it/s]Running loglikelihood requests:  64%|██████▎   | 254/400 [03:35<02:11,  1.11it/s]Running loglikelihood requests:  64%|██████▍   | 255/400 [03:36<02:12,  1.09it/s]Running loglikelihood requests:  64%|██████▍   | 256/400 [03:37<02:13,  1.08it/s]Running loglikelihood requests:  64%|██████▍   | 257/400 [03:38<02:13,  1.07it/s]Running loglikelihood requests:  64%|██████▍   | 258/400 [03:39<02:13,  1.06it/s]Running loglikelihood requests:  65%|██████▌   | 260/400 [03:40<01:41,  1.37it/s]Running loglikelihood requests:  65%|██████▌   | 261/400 [03:41<01:48,  1.28it/s]Running loglikelihood requests:  66%|██████▌   | 264/400 [03:42<01:14,  1.84it/s]Running loglikelihood requests:  66%|██████▋   | 265/400 [03:43<01:24,  1.60it/s]Running loglikelihood requests:  66%|██████▋   | 266/400 [03:43<01:33,  1.43it/s]Running loglikelihood requests:  67%|██████▋   | 267/400 [03:45<01:50,  1.20it/s]Running loglikelihood requests:  67%|██████▋   | 268/400 [03:46<01:53,  1.16it/s]Running loglikelihood requests:  67%|██████▋   | 269/400 [03:47<01:55,  1.13it/s]Running loglikelihood requests:  68%|██████▊   | 270/400 [03:48<01:57,  1.11it/s]Running loglikelihood requests:  68%|██████▊   | 271/400 [03:49<01:58,  1.09it/s]Running loglikelihood requests:  68%|██████▊   | 272/400 [03:49<01:58,  1.08it/s]Running loglikelihood requests:  68%|██████▊   | 273/400 [03:50<01:58,  1.07it/s]Running loglikelihood requests:  68%|██████▊   | 274/400 [03:51<02:02,  1.03it/s]Running loglikelihood requests:  69%|██████▉   | 277/400 [03:53<01:17,  1.60it/s]Running loglikelihood requests:  70%|██████▉   | 279/400 [03:54<01:09,  1.73it/s]Running loglikelihood requests:  70%|███████   | 281/400 [03:54<01:04,  1.84it/s]Running loglikelihood requests:  71%|███████   | 284/400 [03:55<00:52,  2.22it/s]Running loglikelihood requests:  71%|███████▏  | 285/400 [03:56<01:01,  1.88it/s]Running loglikelihood requests:  72%|███████▏  | 286/400 [03:57<01:09,  1.63it/s]Running loglikelihood requests:  72%|███████▏  | 287/400 [03:58<01:17,  1.46it/s]Running loglikelihood requests:  72%|███████▏  | 288/400 [03:59<01:24,  1.33it/s]Running loglikelihood requests:  72%|███████▏  | 289/400 [04:00<01:29,  1.24it/s]Running loglikelihood requests:  72%|███████▎  | 290/400 [04:01<01:32,  1.19it/s]Running loglikelihood requests:  73%|███████▎  | 291/400 [04:02<01:34,  1.15it/s]Running loglikelihood requests:  73%|███████▎  | 293/400 [04:03<01:14,  1.44it/s]Running loglikelihood requests:  74%|███████▎  | 294/400 [04:04<01:19,  1.33it/s]Running loglikelihood requests:  74%|███████▍  | 295/400 [04:05<01:24,  1.25it/s]Running loglikelihood requests:  74%|███████▍  | 296/400 [04:06<01:27,  1.19it/s]Running loglikelihood requests:  74%|███████▍  | 297/400 [04:07<01:29,  1.16it/s]Running loglikelihood requests:  75%|███████▍  | 299/400 [04:08<01:10,  1.44it/s]Running loglikelihood requests:  75%|███████▌  | 300/400 [04:09<01:15,  1.33it/s]Running loglikelihood requests:  75%|███████▌  | 301/400 [04:10<01:19,  1.25it/s]Running loglikelihood requests:  76%|███████▌  | 302/400 [04:11<01:21,  1.20it/s]Running loglikelihood requests:  76%|███████▌  | 304/400 [04:12<01:05,  1.48it/s]Running loglikelihood requests:  76%|███████▋  | 305/400 [04:12<01:10,  1.35it/s]Running loglikelihood requests:  77%|███████▋  | 307/400 [04:13<00:58,  1.59it/s]Running loglikelihood requests:  77%|███████▋  | 309/400 [04:14<00:51,  1.75it/s]Running loglikelihood requests:  78%|███████▊  | 310/400 [04:15<00:58,  1.55it/s]Running loglikelihood requests:  78%|███████▊  | 311/400 [04:16<01:03,  1.41it/s]Running loglikelihood requests:  78%|███████▊  | 312/400 [04:17<01:07,  1.31it/s]Running loglikelihood requests:  78%|███████▊  | 313/400 [04:18<01:10,  1.24it/s]Running loglikelihood requests:  79%|███████▉  | 315/400 [04:19<00:56,  1.51it/s]Running loglikelihood requests:  79%|███████▉  | 317/400 [04:20<00:48,  1.70it/s]Running loglikelihood requests:  80%|███████▉  | 318/400 [04:21<00:54,  1.51it/s]Running loglikelihood requests:  80%|███████▉  | 319/400 [04:22<00:58,  1.38it/s]Running loglikelihood requests:  80%|████████  | 321/400 [04:23<00:49,  1.61it/s]Running loglikelihood requests:  81%|████████  | 323/400 [04:24<00:43,  1.77it/s]Running loglikelihood requests:  82%|████████▏ | 326/400 [04:25<00:33,  2.20it/s]Running loglikelihood requests:  82%|████████▏ | 327/400 [04:26<00:39,  1.86it/s]Running loglikelihood requests:  82%|████████▏ | 328/400 [04:26<00:44,  1.62it/s]Running loglikelihood requests:  82%|████████▏ | 329/400 [04:27<00:48,  1.45it/s]Running loglikelihood requests:  82%|████████▎ | 330/400 [04:28<00:52,  1.34it/s]Running loglikelihood requests:  83%|████████▎ | 332/400 [04:29<00:42,  1.58it/s]Running loglikelihood requests:  83%|████████▎ | 333/400 [04:30<00:46,  1.43it/s]Running loglikelihood requests:  84%|████████▎ | 334/400 [04:31<00:49,  1.33it/s]Running loglikelihood requests:  84%|████████▍ | 335/400 [04:32<00:51,  1.25it/s]Running loglikelihood requests:  84%|████████▍ | 336/400 [04:33<00:53,  1.20it/s]Running loglikelihood requests:  84%|████████▍ | 337/400 [04:34<00:54,  1.16it/s]Running loglikelihood requests:  84%|████████▍ | 338/400 [04:35<00:54,  1.14it/s]Running loglikelihood requests:  85%|████████▍ | 339/400 [04:36<00:54,  1.12it/s]Running loglikelihood requests:  85%|████████▌ | 340/400 [04:37<00:54,  1.11it/s]Running loglikelihood requests:  85%|████████▌ | 341/400 [04:38<00:52,  1.13it/s]Running loglikelihood requests:  86%|████████▌ | 342/400 [04:38<00:50,  1.14it/s]Running loglikelihood requests:  86%|████████▌ | 343/400 [04:39<00:49,  1.15it/s]Running loglikelihood requests:  86%|████████▋ | 346/400 [04:40<00:29,  1.85it/s]Running loglikelihood requests:  87%|████████▋ | 348/400 [04:41<00:26,  2.00it/s]Running loglikelihood requests:  87%|████████▋ | 349/400 [04:42<00:29,  1.76it/s]Running loglikelihood requests:  88%|████████▊ | 350/400 [04:43<00:31,  1.58it/s]Running loglikelihood requests:  88%|████████▊ | 351/400 [04:43<00:33,  1.46it/s]Running loglikelihood requests:  88%|████████▊ | 352/400 [04:44<00:34,  1.38it/s]Running loglikelihood requests:  88%|████████▊ | 353/400 [04:45<00:35,  1.32it/s]Running loglikelihood requests:  88%|████████▊ | 354/400 [04:46<00:35,  1.28it/s]Running loglikelihood requests:  89%|████████▉ | 355/400 [04:47<00:36,  1.25it/s]Running loglikelihood requests:  89%|████████▉ | 356/400 [04:48<00:35,  1.23it/s]Running loglikelihood requests:  90%|████████▉ | 358/400 [04:49<00:26,  1.58it/s]Running loglikelihood requests:  90%|████████▉ | 359/400 [04:49<00:28,  1.45it/s]Running loglikelihood requests:  90%|█████████ | 360/400 [04:50<00:29,  1.36it/s]Running loglikelihood requests:  90%|█████████ | 361/400 [04:51<00:29,  1.30it/s]Running loglikelihood requests:  90%|█████████ | 362/400 [04:52<00:30,  1.26it/s]Running loglikelihood requests:  91%|█████████ | 364/400 [04:53<00:22,  1.59it/s]Running loglikelihood requests:  91%|█████████▏| 365/400 [04:54<00:23,  1.46it/s]Running loglikelihood requests:  92%|█████████▏| 367/400 [04:55<00:19,  1.72it/s]Running loglikelihood requests:  92%|█████████▏| 368/400 [04:55<00:20,  1.56it/s]Running loglikelihood requests:  92%|█████████▏| 369/400 [04:56<00:21,  1.45it/s]Running loglikelihood requests:  92%|█████████▎| 370/400 [04:57<00:21,  1.37it/s]Running loglikelihood requests:  93%|█████████▎| 371/400 [04:58<00:22,  1.32it/s]Running loglikelihood requests:  93%|█████████▎| 373/400 [04:59<00:16,  1.63it/s]Running loglikelihood requests:  94%|█████████▍| 375/400 [05:00<00:13,  1.85it/s]Running loglikelihood requests:  94%|█████████▍| 376/400 [05:00<00:14,  1.65it/s]Running loglikelihood requests:  95%|█████████▍| 379/400 [05:01<00:09,  2.22it/s]Running loglikelihood requests:  95%|█████████▌| 381/400 [05:02<00:08,  2.27it/s]Running loglikelihood requests:  96%|█████████▌| 382/400 [05:03<00:09,  1.95it/s]Running loglikelihood requests:  96%|█████████▌| 384/400 [05:04<00:07,  2.08it/s]Running loglikelihood requests:  96%|█████████▋| 386/400 [05:05<00:06,  2.17it/s]Running loglikelihood requests:  97%|█████████▋| 387/400 [05:05<00:06,  1.88it/s]Running loglikelihood requests:  97%|█████████▋| 389/400 [05:06<00:05,  2.01it/s]Running loglikelihood requests:  98%|█████████▊| 391/400 [05:07<00:04,  2.12it/s]Running loglikelihood requests:  98%|█████████▊| 393/400 [05:08<00:03,  2.21it/s]Running loglikelihood requests:  99%|█████████▉| 395/400 [05:09<00:02,  2.28it/s]Running loglikelihood requests:  99%|█████████▉| 397/400 [05:10<00:01,  2.33it/s]Running loglikelihood requests: 100%|█████████▉| 398/400 [05:10<00:01,  2.00it/s]Running loglikelihood requests: 100%|██████████| 400/400 [05:11<00:00,  2.13it/s]Running loglikelihood requests: 100%|██████████| 400/400 [05:11<00:00,  1.28it/s]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:2'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:2'}
full model:
{'mastermind_24_easy': {'alias': 'mastermind_24_easy', 'acc,none': 0.33, 'acc_stderr,none': 0.04725815626252609}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9705388716727775
0.9880227828623074
0.982119607496995
0.9941469535767887
0.984917378949356
0.9883609317461776
0.9752442385272352
0.9858149677985593
0.9966001900863091
0.9954965780195978
0.9982374916142641
0.987839947084121
0.9740425263242771
0.9802324544963317
0.9965978314947238
0.9890806289155061
0.971808392501808
0.9767123038440666
0.9820534501654181
0.9672299205809463
0.9753579231968917
0.9973837437819523
0.9951994747100236
0.9465102818948206
0.9757933184251313
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[7, 0, 1, 3, 6, 5, 4, 2]
tensor([7, 0, 1, 3, 6, 5, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 0, 1, 3, 7, 5, 4, 2]
tensor([6, 0, 1, 3, 7, 5, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 0, 1, 3, 6, 5, 4, 2]
tensor([7, 0, 1, 3, 6, 5, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 0, 1, 3, 7, 5, 4, 2]
tensor([6, 0, 1, 3, 7, 5, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 0, 1, 3, 6, 5, 4, 2]
tensor([7, 0, 1, 3, 6, 5, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 0, 2, 3, 6, 5, 4, 1]
tensor([7, 0, 2, 3, 6, 5, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Normal merging for layer 2
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
done!
Normal merging for layer 3
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Normal merging for layer 4
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
done!
Normal merging for layer 5
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 6 to 31
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 15 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.0718 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 14 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

70
cuda:2
mastermind_24_easy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:59<00:59, 59.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 34.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 38.07s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_24_mcq_random HTTP/1.1" 200 779
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/flair/mastermind_24_mcq_random/flair/mastermind_24_mcq_random.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_24_mcq_random HTTP/1.1" 200 779
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/flair/mastermind_24_mcq_random/resolve/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/flair/mastermind_24_mcq_random/resolve/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:filelock:Attempting to acquire lock 140431341456320 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_24_mcq_random_default_0.0.0_cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5.lock
DEBUG:filelock:Lock 140431341456320 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_24_mcq_random_default_0.0.0_cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_24_mcq_random/default/0.0.0/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5/dataset_info.json
DEBUG:filelock:Attempting to release lock 140431341456320 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_24_mcq_random_default_0.0.0_cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5.lock
DEBUG:filelock:Lock 140431341456320 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_24_mcq_random_default_0.0.0_cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5.lock
DEBUG:filelock:Attempting to acquire lock 140437043470480 on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_24_mcq_random/default/0.0.0/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5_builder.lock
DEBUG:filelock:Lock 140437043470480 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_24_mcq_random/default/0.0.0/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_24_mcq_random/default/0.0.0/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5/dataset_info.json
DEBUG:filelock:Attempting to release lock 140437043470480 on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_24_mcq_random/default/0.0.0/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5_builder.lock
DEBUG:filelock:Lock 140437043470480 released on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_24_mcq_random/default/0.0.0/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mastermind_24_easy from None to 0
INFO:lm_eval.api.task:Building contexts for mastermind_24_easy on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1520.45it/s]
DEBUG:lm_eval.evaluator:Task: mastermind_24_easy; number of requests on this rank: 400
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/400 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/400 [00:01<11:51,  1.78s/it]Running loglikelihood requests:   0%|          | 2/400 [00:02<09:08,  1.38s/it]Running loglikelihood requests:   1%|          | 3/400 [00:03<08:14,  1.24s/it]Running loglikelihood requests:   1%|          | 4/400 [00:05<07:47,  1.18s/it]Running loglikelihood requests:   1%|▏         | 5/400 [00:06<07:30,  1.14s/it]Running loglikelihood requests:   2%|▏         | 6/400 [00:07<07:20,  1.12s/it]Running loglikelihood requests:   2%|▏         | 7/400 [00:08<07:15,  1.11s/it]Running loglikelihood requests:   2%|▏         | 8/400 [00:09<07:07,  1.09s/it]Running loglikelihood requests:   2%|▏         | 9/400 [00:10<07:01,  1.08s/it]Running loglikelihood requests:   2%|▎         | 10/400 [00:11<06:56,  1.07s/it]Running loglikelihood requests:   3%|▎         | 12/400 [00:12<05:15,  1.23it/s]Running loglikelihood requests:   3%|▎         | 13/400 [00:13<05:37,  1.15it/s]Running loglikelihood requests:   4%|▎         | 14/400 [00:14<05:54,  1.09it/s]Running loglikelihood requests:   4%|▍         | 16/400 [00:15<04:47,  1.34it/s]Running loglikelihood requests:   4%|▍         | 17/400 [00:16<05:13,  1.22it/s]Running loglikelihood requests:   4%|▍         | 18/400 [00:17<05:34,  1.14it/s]Running loglikelihood requests:   5%|▍         | 19/400 [00:18<05:55,  1.07it/s]Running loglikelihood requests:   5%|▌         | 20/400 [00:19<06:09,  1.03it/s]Running loglikelihood requests:   5%|▌         | 21/400 [00:20<06:18,  1.00it/s]Running loglikelihood requests:   6%|▌         | 22/400 [00:22<06:28,  1.03s/it]Running loglikelihood requests:   6%|▌         | 23/400 [00:23<06:32,  1.04s/it]Running loglikelihood requests:   6%|▋         | 25/400 [00:24<05:03,  1.23it/s]Running loglikelihood requests:   6%|▋         | 26/400 [00:25<05:26,  1.14it/s]Running loglikelihood requests:   7%|▋         | 27/400 [00:26<05:44,  1.08it/s]Running loglikelihood requests:   7%|▋         | 29/400 [00:27<04:41,  1.32it/s]Running loglikelihood requests:   8%|▊         | 30/400 [00:28<05:07,  1.20it/s]Running loglikelihood requests:   8%|▊         | 31/400 [00:29<05:27,  1.13it/s]Running loglikelihood requests:   8%|▊         | 32/400 [00:30<05:44,  1.07it/s]Running loglikelihood requests:   8%|▊         | 34/400 [00:31<04:39,  1.31it/s]Running loglikelihood requests:   9%|▉         | 35/400 [00:32<05:04,  1.20it/s]Running loglikelihood requests:  10%|▉         | 38/400 [00:33<03:34,  1.69it/s]Running loglikelihood requests:  10%|▉         | 39/400 [00:34<04:06,  1.46it/s]Running loglikelihood requests:  10%|█         | 40/400 [00:35<04:35,  1.31it/s]Running loglikelihood requests:  10%|█         | 41/400 [00:36<05:01,  1.19it/s]Running loglikelihood requests:  10%|█         | 42/400 [00:38<05:20,  1.12it/s]Running loglikelihood requests:  11%|█         | 43/400 [00:39<05:34,  1.07it/s]Running loglikelihood requests:  11%|█         | 44/400 [00:40<05:44,  1.03it/s]Running loglikelihood requests:  11%|█▏        | 45/400 [00:41<05:52,  1.01it/s]Running loglikelihood requests:  12%|█▏        | 47/400 [00:42<04:36,  1.28it/s]Running loglikelihood requests:  12%|█▏        | 48/400 [00:43<04:58,  1.18it/s]Running loglikelihood requests:  12%|█▏        | 49/400 [00:44<05:15,  1.11it/s]Running loglikelihood requests:  12%|█▎        | 50/400 [00:45<05:31,  1.06it/s]Running loglikelihood requests:  13%|█▎        | 52/400 [00:46<04:25,  1.31it/s]Running loglikelihood requests:  13%|█▎        | 53/400 [00:47<04:47,  1.21it/s]Running loglikelihood requests:  14%|█▎        | 54/400 [00:48<05:05,  1.13it/s]Running loglikelihood requests:  14%|█▍        | 56/400 [00:49<04:11,  1.37it/s]Running loglikelihood requests:  14%|█▍        | 57/400 [00:50<04:34,  1.25it/s]Running loglikelihood requests:  14%|█▍        | 58/400 [00:51<04:54,  1.16it/s]Running loglikelihood requests:  15%|█▍        | 59/400 [00:52<05:09,  1.10it/s]Running loglikelihood requests:  15%|█▌        | 60/400 [00:53<05:20,  1.06it/s]Running loglikelihood requests:  15%|█▌        | 61/400 [00:54<05:28,  1.03it/s]Running loglikelihood requests:  16%|█▌        | 62/400 [00:55<05:34,  1.01it/s]Running loglikelihood requests:  16%|█▌        | 63/400 [00:56<05:38,  1.00s/it]Running loglikelihood requests:  16%|█▌        | 64/400 [00:57<05:41,  1.02s/it]Running loglikelihood requests:  16%|█▋        | 65/400 [00:59<05:55,  1.06s/it]Running loglikelihood requests:  16%|█▋        | 66/400 [01:00<05:53,  1.06s/it]Running loglikelihood requests:  17%|█▋        | 67/400 [01:01<05:57,  1.07s/it]Running loglikelihood requests:  17%|█▋        | 68/400 [01:02<05:55,  1.07s/it]Running loglikelihood requests:  17%|█▋        | 69/400 [01:03<05:51,  1.06s/it]Running loglikelihood requests:  18%|█▊        | 70/400 [01:04<05:50,  1.06s/it]Running loglikelihood requests:  18%|█▊        | 71/400 [01:05<05:47,  1.06s/it]Running loglikelihood requests:  18%|█▊        | 72/400 [01:06<05:43,  1.05s/it]Running loglikelihood requests:  18%|█▊        | 73/400 [01:07<05:43,  1.05s/it]Running loglikelihood requests:  18%|█▊        | 74/400 [01:08<05:42,  1.05s/it]Running loglikelihood requests:  19%|█▉        | 76/400 [01:09<04:21,  1.24it/s]Running loglikelihood requests:  19%|█▉        | 77/400 [01:10<04:39,  1.16it/s]Running loglikelihood requests:  20%|█▉        | 78/400 [01:11<04:53,  1.10it/s]Running loglikelihood requests:  20%|█▉        | 79/400 [01:12<05:04,  1.05it/s]Running loglikelihood requests:  20%|██        | 80/400 [01:13<05:12,  1.02it/s]Running loglikelihood requests:  20%|██        | 81/400 [01:14<05:17,  1.00it/s]Running loglikelihood requests:  20%|██        | 82/400 [01:15<05:21,  1.01s/it]Running loglikelihood requests:  21%|██        | 83/400 [01:16<05:22,  1.02s/it]Running loglikelihood requests:  21%|██        | 84/400 [01:17<05:23,  1.02s/it]Running loglikelihood requests:  21%|██▏       | 85/400 [01:19<05:24,  1.03s/it]Running loglikelihood requests:  22%|██▏       | 87/400 [01:20<04:10,  1.25it/s]Running loglikelihood requests:  22%|██▏       | 88/400 [01:21<04:28,  1.16it/s]Running loglikelihood requests:  22%|██▏       | 89/400 [01:22<04:41,  1.10it/s]Running loglikelihood requests:  22%|██▎       | 90/400 [01:23<04:51,  1.06it/s]Running loglikelihood requests:  23%|██▎       | 91/400 [01:24<04:59,  1.03it/s]Running loglikelihood requests:  23%|██▎       | 92/400 [01:25<05:02,  1.02it/s]Running loglikelihood requests:  24%|██▎       | 94/400 [01:26<03:54,  1.30it/s]Running loglikelihood requests:  24%|██▍       | 95/400 [01:27<04:13,  1.20it/s]Running loglikelihood requests:  24%|██▍       | 96/400 [01:28<04:25,  1.14it/s]Running loglikelihood requests:  24%|██▍       | 98/400 [01:29<03:36,  1.40it/s]Running loglikelihood requests:  25%|██▌       | 100/400 [01:30<03:10,  1.58it/s]Running loglikelihood requests:  26%|██▌       | 102/400 [01:31<02:55,  1.70it/s]Running loglikelihood requests:  26%|██▌       | 103/400 [01:32<03:19,  1.49it/s]Running loglikelihood requests:  26%|██▌       | 104/400 [01:33<03:39,  1.35it/s]Running loglikelihood requests:  27%|██▋       | 107/400 [01:34<02:38,  1.84it/s]Running loglikelihood requests:  27%|██▋       | 108/400 [01:35<03:03,  1.59it/s]Running loglikelihood requests:  27%|██▋       | 109/400 [01:36<03:25,  1.42it/s]Running loglikelihood requests:  28%|██▊       | 110/400 [01:37<03:44,  1.29it/s]Running loglikelihood requests:  28%|██▊       | 111/400 [01:38<04:02,  1.19it/s]Running loglikelihood requests:  28%|██▊       | 112/400 [01:39<04:16,  1.12it/s]Running loglikelihood requests:  28%|██▊       | 113/400 [01:40<04:26,  1.08it/s]Running loglikelihood requests:  28%|██▊       | 114/400 [01:41<04:33,  1.05it/s]Running loglikelihood requests:  29%|██▉       | 116/400 [01:42<03:35,  1.32it/s]Running loglikelihood requests:  29%|██▉       | 117/400 [01:43<03:52,  1.21it/s]Running loglikelihood requests:  30%|██▉       | 118/400 [01:44<04:06,  1.14it/s]Running loglikelihood requests:  30%|███       | 121/400 [01:45<02:45,  1.68it/s]Running loglikelihood requests:  30%|███       | 122/400 [01:46<03:07,  1.48it/s]Running loglikelihood requests:  31%|███       | 123/400 [01:47<03:26,  1.34it/s]Running loglikelihood requests:  31%|███       | 124/400 [01:48<03:41,  1.24it/s]Running loglikelihood requests:  31%|███▏      | 125/400 [01:49<03:52,  1.18it/s]Running loglikelihood requests:  32%|███▏      | 126/400 [01:50<04:01,  1.14it/s]Running loglikelihood requests:  32%|███▏      | 127/400 [01:51<04:08,  1.10it/s]Running loglikelihood requests:  32%|███▏      | 128/400 [01:52<04:14,  1.07it/s]Running loglikelihood requests:  32%|███▎      | 130/400 [01:53<03:18,  1.36it/s]Running loglikelihood requests:  33%|███▎      | 132/400 [01:54<02:51,  1.56it/s]Running loglikelihood requests:  33%|███▎      | 133/400 [01:55<03:11,  1.40it/s]Running loglikelihood requests:  34%|███▎      | 134/400 [01:56<03:28,  1.27it/s]Running loglikelihood requests:  34%|███▍      | 135/400 [01:57<03:41,  1.19it/s]Running loglikelihood requests:  34%|███▍      | 136/400 [01:58<03:51,  1.14it/s]Running loglikelihood requests:  34%|███▍      | 137/400 [01:59<03:59,  1.10it/s]Running loglikelihood requests:  34%|███▍      | 138/400 [02:00<04:04,  1.07it/s]Running loglikelihood requests:  35%|███▍      | 139/400 [02:01<04:08,  1.05it/s]Running loglikelihood requests:  35%|███▌      | 140/400 [02:02<04:10,  1.04it/s]Running loglikelihood requests:  35%|███▌      | 141/400 [02:03<04:09,  1.04it/s]Running loglikelihood requests:  36%|███▌      | 142/400 [02:04<04:08,  1.04it/s]Running loglikelihood requests:  36%|███▌      | 143/400 [02:05<04:08,  1.04it/s]Running loglikelihood requests:  36%|███▋      | 145/400 [02:06<03:11,  1.33it/s]Running loglikelihood requests:  36%|███▋      | 146/400 [02:07<03:26,  1.23it/s]Running loglikelihood requests:  37%|███▋      | 147/400 [02:08<03:35,  1.17it/s]Running loglikelihood requests:  37%|███▋      | 148/400 [02:09<03:41,  1.14it/s]Running loglikelihood requests:  37%|███▋      | 149/400 [02:10<03:46,  1.11it/s]Running loglikelihood requests:  38%|███▊      | 150/400 [02:11<03:49,  1.09it/s]Running loglikelihood requests:  38%|███▊      | 152/400 [02:11<02:58,  1.39it/s]Running loglikelihood requests:  38%|███▊      | 153/400 [02:12<03:12,  1.28it/s]Running loglikelihood requests:  38%|███▊      | 154/400 [02:13<03:22,  1.21it/s]Running loglikelihood requests:  39%|███▉      | 155/400 [02:14<03:31,  1.16it/s]Running loglikelihood requests:  39%|███▉      | 157/400 [02:15<02:48,  1.44it/s]Running loglikelihood requests:  40%|███▉      | 158/400 [02:16<03:03,  1.32it/s]Running loglikelihood requests:  40%|████      | 160/400 [02:17<02:34,  1.55it/s]Running loglikelihood requests:  40%|████      | 161/400 [02:18<02:50,  1.40it/s]Running loglikelihood requests:  40%|████      | 162/400 [02:19<03:03,  1.30it/s]Running loglikelihood requests:  41%|████      | 163/400 [02:20<03:16,  1.21it/s]Running loglikelihood requests:  41%|████▏     | 165/400 [02:21<02:40,  1.46it/s]Running loglikelihood requests:  42%|████▏     | 166/400 [02:22<02:56,  1.33it/s]Running loglikelihood requests:  42%|████▏     | 167/400 [02:23<03:08,  1.24it/s]Running loglikelihood requests:  42%|████▏     | 168/400 [02:24<03:18,  1.17it/s]Running loglikelihood requests:  42%|████▎     | 170/400 [02:25<02:40,  1.43it/s]Running loglikelihood requests:  43%|████▎     | 171/400 [02:26<02:54,  1.31it/s]Running loglikelihood requests:  43%|████▎     | 172/400 [02:27<03:06,  1.22it/s]Running loglikelihood requests:  43%|████▎     | 173/400 [02:28<03:15,  1.16it/s]Running loglikelihood requests:  44%|████▎     | 174/400 [02:29<03:21,  1.12it/s]Running loglikelihood requests:  44%|████▍     | 175/400 [02:30<03:26,  1.09it/s]Running loglikelihood requests:  44%|████▍     | 176/400 [02:31<03:29,  1.07it/s]Running loglikelihood requests:  44%|████▍     | 178/400 [02:32<02:42,  1.36it/s]Running loglikelihood requests:  45%|████▍     | 179/400 [02:33<02:55,  1.26it/s]Running loglikelihood requests:  45%|████▌     | 180/400 [02:34<03:04,  1.19it/s]Running loglikelihood requests:  45%|████▌     | 181/400 [02:35<03:11,  1.14it/s]Running loglikelihood requests:  46%|████▌     | 183/400 [02:36<02:33,  1.41it/s]Running loglikelihood requests:  46%|████▌     | 184/400 [02:37<02:47,  1.29it/s]Running loglikelihood requests:  47%|████▋     | 187/400 [02:38<01:57,  1.82it/s]Running loglikelihood requests:  47%|████▋     | 188/400 [02:39<02:14,  1.58it/s]Running loglikelihood requests:  47%|████▋     | 189/400 [02:40<02:29,  1.41it/s]Running loglikelihood requests:  48%|████▊     | 190/400 [02:41<02:42,  1.29it/s]Running loglikelihood requests:  48%|████▊     | 191/400 [02:42<02:50,  1.22it/s]Running loglikelihood requests:  48%|████▊     | 192/400 [02:43<03:00,  1.15it/s]Running loglikelihood requests:  48%|████▊     | 193/400 [02:44<03:05,  1.12it/s]Running loglikelihood requests:  48%|████▊     | 194/400 [02:45<03:09,  1.09it/s]Running loglikelihood requests:  49%|████▉     | 196/400 [02:46<02:28,  1.37it/s]Running loglikelihood requests:  49%|████▉     | 197/400 [02:47<02:41,  1.26it/s]Running loglikelihood requests:  50%|████▉     | 198/400 [02:48<02:50,  1.19it/s]Running loglikelihood requests:  50%|████▉     | 199/400 [02:49<02:57,  1.13it/s]Running loglikelihood requests:  50%|█████     | 200/400 [02:50<03:02,  1.09it/s]Running loglikelihood requests:  50%|█████     | 202/400 [02:51<02:23,  1.38it/s]Running loglikelihood requests:  51%|█████     | 203/400 [02:52<02:36,  1.26it/s]Running loglikelihood requests:  51%|█████     | 204/400 [02:52<02:44,  1.19it/s]Running loglikelihood requests:  51%|█████▏    | 205/400 [02:53<02:51,  1.14it/s]Running loglikelihood requests:  52%|█████▏    | 206/400 [02:54<02:56,  1.10it/s]Running loglikelihood requests:  52%|█████▏    | 207/400 [02:55<02:59,  1.07it/s]Running loglikelihood requests:  52%|█████▎    | 210/400 [02:56<01:54,  1.67it/s]Running loglikelihood requests:  53%|█████▎    | 212/400 [02:57<01:45,  1.78it/s]Running loglikelihood requests:  53%|█████▎    | 213/400 [02:58<02:00,  1.55it/s]Running loglikelihood requests:  54%|█████▍    | 215/400 [02:59<01:49,  1.70it/s]Running loglikelihood requests:  54%|█████▍    | 216/400 [03:00<02:03,  1.49it/s]Running loglikelihood requests:  54%|█████▍    | 217/400 [03:01<02:15,  1.35it/s]Running loglikelihood requests:  55%|█████▍    | 219/400 [03:02<01:56,  1.56it/s]Running loglikelihood requests:  55%|█████▌    | 220/400 [03:03<02:08,  1.40it/s]Running loglikelihood requests:  55%|█████▌    | 221/400 [03:04<02:19,  1.29it/s]Running loglikelihood requests:  56%|█████▌    | 222/400 [03:05<02:27,  1.21it/s]Running loglikelihood requests:  56%|█████▌    | 223/400 [03:06<02:33,  1.15it/s]Running loglikelihood requests:  56%|█████▌    | 224/400 [03:07<02:37,  1.12it/s]Running loglikelihood requests:  56%|█████▋    | 225/400 [03:08<02:40,  1.09it/s]Running loglikelihood requests:  56%|█████▋    | 226/400 [03:09<02:42,  1.07it/s]Running loglikelihood requests:  57%|█████▋    | 227/400 [03:10<02:43,  1.06it/s]Running loglikelihood requests:  57%|█████▋    | 228/400 [03:11<02:44,  1.05it/s]Running loglikelihood requests:  57%|█████▋    | 229/400 [03:12<02:44,  1.04it/s]Running loglikelihood requests:  57%|█████▊    | 230/400 [03:13<02:43,  1.04it/s]Running loglikelihood requests:  58%|█████▊    | 231/400 [03:14<02:43,  1.03it/s]Running loglikelihood requests:  58%|█████▊    | 232/400 [03:15<02:44,  1.02it/s]Running loglikelihood requests:  58%|█████▊    | 233/400 [03:16<02:43,  1.02it/s]Running loglikelihood requests:  59%|█████▉    | 235/400 [03:17<02:03,  1.33it/s]Running loglikelihood requests:  59%|█████▉    | 236/400 [03:18<02:11,  1.24it/s]Running loglikelihood requests:  59%|█████▉    | 237/400 [03:19<02:17,  1.18it/s]Running loglikelihood requests:  60%|█████▉    | 238/400 [03:20<02:22,  1.14it/s]Running loglikelihood requests:  60%|█████▉    | 239/400 [03:21<02:25,  1.11it/s]Running loglikelihood requests:  60%|██████    | 240/400 [03:22<02:27,  1.08it/s]Running loglikelihood requests:  60%|██████    | 242/400 [03:23<01:54,  1.38it/s]Running loglikelihood requests:  61%|██████    | 243/400 [03:24<02:03,  1.28it/s]Running loglikelihood requests:  61%|██████    | 244/400 [03:25<02:09,  1.20it/s]Running loglikelihood requests:  61%|██████▏   | 245/400 [03:26<02:14,  1.15it/s]Running loglikelihood requests:  62%|██████▏   | 246/400 [03:27<02:17,  1.12it/s]Running loglikelihood requests:  62%|██████▏   | 247/400 [03:28<02:19,  1.09it/s]Running loglikelihood requests:  62%|██████▏   | 249/400 [03:29<01:48,  1.39it/s]Running loglikelihood requests:  62%|██████▎   | 250/400 [03:30<01:57,  1.27it/s]Running loglikelihood requests:  63%|██████▎   | 251/400 [03:31<02:03,  1.20it/s]Running loglikelihood requests:  63%|██████▎   | 252/400 [03:31<02:08,  1.15it/s]Running loglikelihood requests:  63%|██████▎   | 253/400 [03:32<02:11,  1.12it/s]Running loglikelihood requests:  64%|██████▎   | 254/400 [03:33<02:13,  1.09it/s]Running loglikelihood requests:  64%|██████▍   | 255/400 [03:34<02:15,  1.07it/s]Running loglikelihood requests:  64%|██████▍   | 256/400 [03:35<02:15,  1.06it/s]Running loglikelihood requests:  64%|██████▍   | 257/400 [03:36<02:14,  1.06it/s]Running loglikelihood requests:  64%|██████▍   | 258/400 [03:37<02:14,  1.05it/s]Running loglikelihood requests:  65%|██████▌   | 260/400 [03:38<01:42,  1.36it/s]Running loglikelihood requests:  65%|██████▌   | 261/400 [03:39<01:49,  1.27it/s]Running loglikelihood requests:  66%|██████▌   | 264/400 [03:40<01:14,  1.82it/s]Running loglikelihood requests:  66%|██████▋   | 265/400 [03:41<01:24,  1.59it/s]Running loglikelihood requests:  66%|██████▋   | 266/400 [03:42<01:34,  1.42it/s]Running loglikelihood requests:  67%|██████▋   | 267/400 [03:43<01:41,  1.31it/s]Running loglikelihood requests:  67%|██████▋   | 268/400 [03:44<01:47,  1.23it/s]Running loglikelihood requests:  67%|██████▋   | 269/400 [03:45<01:52,  1.16it/s]Running loglikelihood requests:  68%|██████▊   | 270/400 [03:46<01:55,  1.13it/s]Running loglikelihood requests:  68%|██████▊   | 271/400 [03:47<01:57,  1.10it/s]Running loglikelihood requests:  68%|██████▊   | 272/400 [03:48<01:58,  1.08it/s]Running loglikelihood requests:  68%|██████▊   | 273/400 [03:49<02:00,  1.06it/s]Running loglikelihood requests:  68%|██████▊   | 274/400 [03:50<01:59,  1.05it/s]Running loglikelihood requests:  69%|██████▉   | 277/400 [03:51<01:13,  1.66it/s]Running loglikelihood requests:  70%|██████▉   | 279/400 [03:52<01:07,  1.79it/s]Running loglikelihood requests:  70%|███████   | 281/400 [03:53<01:03,  1.88it/s]Running loglikelihood requests:  71%|███████   | 284/400 [03:54<00:51,  2.25it/s]Running loglikelihood requests:  71%|███████▏  | 285/400 [03:55<01:00,  1.89it/s]Running loglikelihood requests:  72%|███████▏  | 286/400 [03:56<01:09,  1.64it/s]Running loglikelihood requests:  72%|███████▏  | 287/400 [03:57<01:17,  1.46it/s]Running loglikelihood requests:  72%|███████▏  | 288/400 [03:58<01:24,  1.33it/s]Running loglikelihood requests:  72%|███████▏  | 289/400 [03:58<01:29,  1.25it/s]Running loglikelihood requests:  72%|███████▎  | 290/400 [03:59<01:32,  1.19it/s]Running loglikelihood requests:  73%|███████▎  | 291/400 [04:00<01:35,  1.14it/s]Running loglikelihood requests:  73%|███████▎  | 293/400 [04:01<01:14,  1.43it/s]Running loglikelihood requests:  74%|███████▎  | 294/400 [04:02<01:20,  1.31it/s]Running loglikelihood requests:  74%|███████▍  | 295/400 [04:03<01:25,  1.23it/s]Running loglikelihood requests:  74%|███████▍  | 296/400 [04:04<01:28,  1.18it/s]Running loglikelihood requests:  74%|███████▍  | 297/400 [04:05<01:30,  1.14it/s]Running loglikelihood requests:  75%|███████▍  | 299/400 [04:06<01:10,  1.43it/s]Running loglikelihood requests:  75%|███████▌  | 300/400 [04:07<01:16,  1.31it/s]Running loglikelihood requests:  75%|███████▌  | 301/400 [04:08<01:20,  1.23it/s]Running loglikelihood requests:  76%|███████▌  | 302/400 [04:09<01:23,  1.18it/s]Running loglikelihood requests:  76%|███████▌  | 304/400 [04:10<01:05,  1.46it/s]Running loglikelihood requests:  76%|███████▋  | 305/400 [04:11<01:11,  1.34it/s]Running loglikelihood requests:  77%|███████▋  | 307/400 [04:12<00:59,  1.57it/s]Running loglikelihood requests:  77%|███████▋  | 309/400 [04:13<00:52,  1.73it/s]Running loglikelihood requests:  78%|███████▊  | 310/400 [04:14<00:58,  1.53it/s]Running loglikelihood requests:  78%|███████▊  | 311/400 [04:15<01:04,  1.39it/s]Running loglikelihood requests:  78%|███████▊  | 312/400 [04:16<01:08,  1.29it/s]Running loglikelihood requests:  78%|███████▊  | 313/400 [04:17<01:11,  1.21it/s]Running loglikelihood requests:  79%|███████▉  | 315/400 [04:17<00:57,  1.49it/s]Running loglikelihood requests:  79%|███████▉  | 317/400 [04:18<00:49,  1.69it/s]Running loglikelihood requests:  80%|███████▉  | 318/400 [04:19<00:54,  1.50it/s]Running loglikelihood requests:  80%|███████▉  | 319/400 [04:20<00:58,  1.38it/s]Running loglikelihood requests:  80%|████████  | 321/400 [04:21<00:49,  1.60it/s]Running loglikelihood requests:  81%|████████  | 323/400 [04:22<00:43,  1.77it/s]Running loglikelihood requests:  82%|████████▏ | 326/400 [04:23<00:33,  2.20it/s]Running loglikelihood requests:  82%|████████▏ | 327/400 [04:24<00:39,  1.86it/s]Running loglikelihood requests:  82%|████████▏ | 328/400 [04:25<00:44,  1.63it/s]Running loglikelihood requests:  82%|████████▏ | 329/400 [04:26<00:48,  1.46it/s]Running loglikelihood requests:  82%|████████▎ | 330/400 [04:27<00:51,  1.35it/s]Running loglikelihood requests:  83%|████████▎ | 332/400 [04:28<00:42,  1.59it/s]Running loglikelihood requests:  83%|████████▎ | 333/400 [04:29<00:46,  1.44it/s]Running loglikelihood requests:  84%|████████▎ | 334/400 [04:30<00:49,  1.32it/s]Running loglikelihood requests:  84%|████████▍ | 335/400 [04:31<00:51,  1.25it/s]Running loglikelihood requests:  84%|████████▍ | 336/400 [04:31<00:53,  1.21it/s]Running loglikelihood requests:  84%|████████▍ | 337/400 [04:32<00:53,  1.17it/s]Running loglikelihood requests:  84%|████████▍ | 338/400 [04:33<00:54,  1.15it/s]Running loglikelihood requests:  85%|████████▍ | 339/400 [04:34<00:53,  1.13it/s]Running loglikelihood requests:  85%|████████▌ | 340/400 [04:35<00:53,  1.12it/s]Running loglikelihood requests:  85%|████████▌ | 341/400 [04:36<00:51,  1.14it/s]Running loglikelihood requests:  86%|████████▌ | 342/400 [04:37<00:50,  1.15it/s]Running loglikelihood requests:  86%|████████▌ | 343/400 [04:38<00:49,  1.15it/s]Running loglikelihood requests:  86%|████████▋ | 346/400 [04:39<00:29,  1.84it/s]Running loglikelihood requests:  87%|████████▋ | 348/400 [04:39<00:26,  1.99it/s]Running loglikelihood requests:  87%|████████▋ | 349/400 [04:40<00:29,  1.74it/s]Running loglikelihood requests:  88%|████████▊ | 350/400 [04:41<00:31,  1.57it/s]Running loglikelihood requests:  88%|████████▊ | 351/400 [04:42<00:33,  1.45it/s]Running loglikelihood requests:  88%|████████▊ | 352/400 [04:43<00:35,  1.36it/s]Running loglikelihood requests:  88%|████████▊ | 353/400 [04:44<00:35,  1.31it/s]Running loglikelihood requests:  88%|████████▊ | 354/400 [04:45<00:36,  1.26it/s]Running loglikelihood requests:  89%|████████▉ | 355/400 [04:45<00:36,  1.23it/s]Running loglikelihood requests:  89%|████████▉ | 356/400 [04:46<00:36,  1.21it/s]Running loglikelihood requests:  90%|████████▉ | 358/400 [04:47<00:27,  1.55it/s]Running loglikelihood requests:  90%|████████▉ | 359/400 [04:48<00:28,  1.43it/s]Running loglikelihood requests:  90%|█████████ | 360/400 [04:49<00:29,  1.35it/s]Running loglikelihood requests:  90%|█████████ | 361/400 [04:50<00:29,  1.30it/s]Running loglikelihood requests:  90%|█████████ | 362/400 [04:51<00:30,  1.26it/s]Running loglikelihood requests:  91%|█████████ | 364/400 [04:51<00:22,  1.59it/s]Running loglikelihood requests:  91%|█████████▏| 365/400 [04:52<00:23,  1.46it/s]Running loglikelihood requests:  92%|█████████▏| 367/400 [04:53<00:19,  1.72it/s]Running loglikelihood requests:  92%|█████████▏| 368/400 [04:54<00:20,  1.56it/s]Running loglikelihood requests:  92%|█████████▏| 369/400 [04:55<00:21,  1.44it/s]Running loglikelihood requests:  92%|█████████▎| 370/400 [04:56<00:22,  1.36it/s]Running loglikelihood requests:  93%|█████████▎| 371/400 [04:56<00:22,  1.30it/s]Running loglikelihood requests:  93%|█████████▎| 373/400 [04:57<00:16,  1.61it/s]Running loglikelihood requests:  94%|█████████▍| 375/400 [04:58<00:13,  1.85it/s]Running loglikelihood requests:  94%|█████████▍| 376/400 [04:59<00:14,  1.66it/s]Running loglikelihood requests:  95%|█████████▍| 379/400 [05:00<00:09,  2.25it/s]Running loglikelihood requests:  95%|█████████▌| 381/400 [05:01<00:08,  2.30it/s]Running loglikelihood requests:  96%|█████████▌| 382/400 [05:01<00:09,  1.98it/s]Running loglikelihood requests:  96%|█████████▌| 384/400 [05:02<00:07,  2.11it/s]Running loglikelihood requests:  96%|█████████▋| 386/400 [05:03<00:06,  2.21it/s]Running loglikelihood requests:  97%|█████████▋| 387/400 [05:04<00:06,  1.91it/s]Running loglikelihood requests:  97%|█████████▋| 389/400 [05:05<00:05,  2.07it/s]Running loglikelihood requests:  98%|█████████▊| 391/400 [05:06<00:04,  2.18it/s]Running loglikelihood requests:  98%|█████████▊| 393/400 [05:06<00:03,  2.26it/s]Running loglikelihood requests:  99%|█████████▉| 395/400 [05:07<00:02,  2.31it/s]Running loglikelihood requests:  99%|█████████▉| 397/400 [05:08<00:01,  2.35it/s]Running loglikelihood requests: 100%|█████████▉| 398/400 [05:09<00:00,  2.02it/s]Running loglikelihood requests: 100%|██████████| 400/400 [05:10<00:00,  2.12it/s]Running loglikelihood requests: 100%|██████████| 400/400 [05:10<00:00,  1.29it/s]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:3'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:3'}
full model:
{'mastermind_24_easy': {'alias': 'mastermind_24_easy', 'acc,none': 0.33, 'acc_stderr,none': 0.04725815626252609}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9705388716727775
0.9880227828623074
0.982119607496995
0.9941469535767887
0.984917378949356
0.9883609317461776
0.9752442385272352
0.9858149677985593
0.9966001900863091
0.9954965780195978
0.9982374916142641
0.987839947084121
0.9740425263242771
0.9802324544963317
0.9965978314947238
0.9890806289155061
0.971808392501808
0.9767123038440666
0.9820534501654181
0.9672299205809463
0.9753579231968917
0.9973837437819523
0.9951994747100236
0.9465102818948206
0.9757933184251313
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[7, 0, 1, 3, 6, 5, 4, 2]
tensor([7, 0, 1, 3, 6, 5, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 0, 1, 3, 7, 5, 4, 2]
tensor([6, 0, 1, 3, 7, 5, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 0, 1, 3, 6, 5, 4, 2]
tensor([7, 0, 1, 3, 6, 5, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 0, 1, 3, 7, 5, 4, 2]
tensor([6, 0, 1, 3, 7, 5, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 0, 1, 3, 6, 5, 4, 2]
tensor([7, 0, 1, 3, 6, 5, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 0, 2, 3, 6, 5, 4, 1]
tensor([7, 0, 2, 3, 6, 5, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Normal merging for layer 2
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
done!
Normal merging for layer 3
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Normal merging for layer 4
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
done!
Normal merging for layer 5
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 6 to 31
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 14 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.0718 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 13 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

196
cuda:3
qnli
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:55<00:55, 55.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:12<00:00, 33.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:12<00:00, 36.43s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: qnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: qnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/qnli?recursive=False&expand=False HTTP/1.1" 307 141
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/qnli?recursive=False&expand=False HTTP/1.1" 200 361
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140437043158608 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_qnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140437043158608 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_qnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/qnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140437043158608 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_qnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140437043158608 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_qnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140430442091904 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/qnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140430442091904 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/qnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/qnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430442091904 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/qnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140430442091904 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/qnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of qnli from None to 0
INFO:lm_eval.api.task:Building contexts for qnli on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 2602.22it/s]
DEBUG:lm_eval.evaluator:Task: qnli; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:01<05:50,  1.76s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:02<02:53,  1.14it/s]Running loglikelihood requests:   2%|▎         | 5/200 [00:03<02:15,  1.44it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:04<01:58,  1.63it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:05<01:49,  1.75it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:06<01:41,  1.86it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:07<01:35,  1.95it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:08<01:33,  1.98it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:09<01:27,  2.09it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:10<01:23,  2.18it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:11<01:19,  2.24it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:12<01:16,  2.30it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:12<01:15,  2.33it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:13<01:13,  2.36it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:14<01:13,  2.31it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:15<01:11,  2.35it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:16<01:09,  2.39it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:17<01:08,  2.43it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:17<01:06,  2.45it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:18<01:05,  2.47it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:19<01:04,  2.48it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:20<01:03,  2.49it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:21<01:01,  2.52it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:21<01:00,  2.55it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:22<00:58,  2.57it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:23<00:57,  2.58it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:24<00:56,  2.59it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:24<00:56,  2.59it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:25<00:54,  2.60it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:26<00:53,  2.62it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:27<00:52,  2.63it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:27<00:51,  2.64it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:28<00:50,  2.65it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:29<00:49,  2.68it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:30<00:48,  2.71it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:30<00:47,  2.73it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:31<00:46,  2.75it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:32<00:45,  2.76it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:32<00:44,  2.79it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:33<00:42,  2.82it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:34<00:42,  2.83it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:35<00:41,  2.85it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:35<00:40,  2.83it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:36<00:39,  2.85it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:37<00:38,  2.86it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:37<00:37,  2.87it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:38<00:37,  2.88it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:39<00:36,  2.89it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:39<00:35,  2.91it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:40<00:34,  2.92it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:41<00:33,  2.93it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:41<00:32,  2.95it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:42<00:32,  2.94it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:43<00:31,  2.96it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:43<00:30,  2.98it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:44<00:29,  3.00it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:45<00:28,  3.01it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:45<00:28,  3.02it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:46<00:27,  3.03it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:47<00:26,  3.05it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:47<00:25,  3.07it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:48<00:25,  3.08it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:49<00:24,  3.11it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [00:49<00:23,  3.13it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [00:50<00:22,  3.14it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [00:51<00:21,  3.16it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [00:51<00:21,  3.17it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [00:52<00:20,  3.18it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [00:52<00:19,  3.19it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [00:53<00:19,  3.21it/s]Running loglikelihood requests:  70%|███████   | 141/200 [00:54<00:18,  3.22it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [00:54<00:17,  3.24it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [00:55<00:16,  3.25it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [00:55<00:16,  3.26it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [00:56<00:15,  3.27it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [00:57<00:14,  3.27it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [00:57<00:14,  3.28it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [00:58<00:13,  3.28it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [00:58<00:13,  3.29it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [00:59<00:12,  3.30it/s]Running loglikelihood requests:  80%|████████  | 161/200 [01:00<00:11,  3.30it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [01:00<00:11,  3.32it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [01:01<00:10,  3.33it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [01:01<00:09,  3.35it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [01:02<00:09,  3.36it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [01:03<00:08,  3.39it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [01:03<00:07,  3.42it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [01:04<00:07,  3.43it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [01:04<00:06,  3.44it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [01:05<00:06,  3.45it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [01:06<00:05,  3.46it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [01:06<00:04,  3.48it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [01:07<00:04,  3.50it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [01:07<00:03,  3.55it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [01:08<00:03,  3.59it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [01:08<00:02,  3.62it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [01:09<00:01,  3.64it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:09<00:01,  3.67it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:10<00:00,  3.70it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:10<00:00,  3.75it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:10<00:00,  2.82it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:4'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:4'}
full model:
{'qnli': {'alias': 'qnli', 'acc,none': 0.46, 'acc_stderr,none': 0.05009082659620332}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9846426504484882
0.5824664507839472
0.519615692575773
0.501155542927289
0.7945367166753022
0.308422053695068
0.8640142063914085
0.9138139850456612
0.4633856064809356
0.6590614315196575
0.6979080802987999
0.7199917897264415
0.7749024201981475
0.6702564595367945
0.48800861061165646
0.4420522818267443
0.9519161971847797
0.7484302940574024
0.5133259423607681
0.5588784666822361
0.6658633104669237
0.7569182042181317
0.5308683195195316
0.8457203515884096
0.2160432078364904
0.9025653665852331
0.9196489243365332
0.6742217686289
0.8668007010904994
0.9846426504484882
0.5824664507839472
0.519615692575773
0.501155542927289
0.7945367166753022
0.308422053695068
0.8640142063914085
0.9138139850456612
0.4633856064809356
0.6590614315196575
0.6979080802987999
0.7199917897264415
0.7749024201981475
0.6702564595367945
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[7, 5, 4, 2, 6, 1, 3, 0]
tensor([7, 5, 4, 2, 6, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 5, 1, 3, 6, 2, 7, 0]
tensor([4, 5, 1, 3, 6, 2, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 3, 4, 1, 2, 5, 0]
tensor([0, 1, 3, 4, 1, 2, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 1, 5, 2, 4, 1, 3, 0]
tensor([0, 1, 5, 2, 4, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 4, 1, 2, 1, 3, 5, 0]
tensor([0, 4, 1, 2, 1, 3, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[2, 4, 3, 0, 5, 1, 1, 0]
tensor([2, 4, 3, 0, 5, 1, 1, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 3, 4, 2, 1, 1, 5, 0]
tensor([0, 3, 4, 2, 1, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 2, 1, 3, 2, 0, 3, 1]
tensor([0, 2, 1, 3, 2, 0, 3, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([2])
tensor(2)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([0])
tensor(0)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 2 to 8
done!
Normal merging for layer 9
tensor([0, 7])
tensor(0)
tensor([1, 4])
tensor(1)
tensor([5])
tensor(5)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
done!
Normal merging for layer 10
tensor([0, 7])
tensor(0)
tensor([1, 5])
tensor(1)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
done!
Normal merging for layer 11
tensor([0, 7])
tensor(0)
tensor([2, 4])
tensor(2)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
done!
Normal merging for layer 12
tensor([3, 7])
tensor(3)
tensor([5, 6])
tensor(5)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
done!
Normal merging for layer 13
tensor([0, 7])
tensor(0)
tensor([4, 5])
tensor(4)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 14 to 15
done!
Normal merging for layer 16
tensor([0, 5])
tensor(0)
tensor([2, 7])
tensor(2)
tensor([1, 4])
tensor(1)
tensor([3, 6])
tensor(3)
done!
Cross-layer merge completed for layers 17 to 31
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 13 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.3238 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 12 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

22
cuda:4
sciq
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:54<00:54, 54.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 32.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 35.66s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq HTTP/1.1" 200 1237
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/sciq/sciq.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq HTTP/1.1" 200 1237
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/allenai/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/allenai/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:filelock:Attempting to acquire lock 140430946139888 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:filelock:Lock 140430946139888 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430946139888 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:filelock:Lock 140430946139888 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:filelock:Attempting to acquire lock 140431339740224 on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:filelock:Lock 140431339740224 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_info.json
DEBUG:filelock:Attempting to release lock 140431339740224 on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:filelock:Lock 140431339740224 released on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of sciq from None to 0
INFO:lm_eval.api.task:Building contexts for sciq on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1033.87it/s]
DEBUG:lm_eval.evaluator:Task: sciq; number of requests on this rank: 400
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/400 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/400 [00:04<27:05,  4.07s/it]Running loglikelihood requests:   0%|          | 2/400 [00:07<24:44,  3.73s/it]Running loglikelihood requests:   1%|          | 3/400 [00:11<23:53,  3.61s/it]Running loglikelihood requests:   1%|          | 4/400 [00:14<23:41,  3.59s/it]Running loglikelihood requests:   1%|▏         | 5/400 [00:17<22:54,  3.48s/it]Running loglikelihood requests:   2%|▏         | 6/400 [00:21<22:21,  3.40s/it]Running loglikelihood requests:   2%|▏         | 7/400 [00:24<22:05,  3.37s/it]Running loglikelihood requests:   2%|▏         | 8/400 [00:27<21:48,  3.34s/it]Running loglikelihood requests:   2%|▏         | 9/400 [00:30<21:02,  3.23s/it]Running loglikelihood requests:   2%|▎         | 10/400 [00:33<20:22,  3.14s/it]Running loglikelihood requests:   3%|▎         | 11/400 [00:36<19:51,  3.06s/it]Running loglikelihood requests:   3%|▎         | 12/400 [00:39<19:27,  3.01s/it]Running loglikelihood requests:   3%|▎         | 13/400 [00:42<18:41,  2.90s/it]Running loglikelihood requests:   4%|▎         | 14/400 [00:44<18:09,  2.82s/it]Running loglikelihood requests:   4%|▍         | 15/400 [00:47<17:43,  2.76s/it]Running loglikelihood requests:   4%|▍         | 16/400 [00:49<17:24,  2.72s/it]Running loglikelihood requests:   4%|▍         | 17/400 [00:52<16:59,  2.66s/it]Running loglikelihood requests:   4%|▍         | 18/400 [00:54<16:40,  2.62s/it]Running loglikelihood requests:   5%|▍         | 19/400 [00:57<16:26,  2.59s/it]Running loglikelihood requests:   5%|▌         | 20/400 [01:00<16:14,  2.56s/it]Running loglikelihood requests:   5%|▌         | 21/400 [01:02<16:04,  2.55s/it]Running loglikelihood requests:   6%|▌         | 22/400 [01:04<15:55,  2.53s/it]Running loglikelihood requests:   6%|▌         | 23/400 [01:07<15:49,  2.52s/it]Running loglikelihood requests:   6%|▌         | 24/400 [01:09<15:42,  2.51s/it]Running loglikelihood requests:   6%|▋         | 25/400 [01:12<15:18,  2.45s/it]Running loglikelihood requests:   6%|▋         | 26/400 [01:14<15:01,  2.41s/it]Running loglikelihood requests:   7%|▋         | 27/400 [01:16<14:43,  2.37s/it]Running loglikelihood requests:   7%|▋         | 28/400 [01:19<14:30,  2.34s/it]Running loglikelihood requests:   7%|▋         | 29/400 [01:21<13:57,  2.26s/it]Running loglikelihood requests:   8%|▊         | 30/400 [01:23<13:34,  2.20s/it]Running loglikelihood requests:   8%|▊         | 31/400 [01:25<13:24,  2.18s/it]Running loglikelihood requests:   8%|▊         | 32/400 [01:27<13:25,  2.19s/it]Running loglikelihood requests:   8%|▊         | 33/400 [01:29<13:01,  2.13s/it]Running loglikelihood requests:   8%|▊         | 34/400 [01:31<12:40,  2.08s/it]Running loglikelihood requests:   9%|▉         | 35/400 [01:33<12:21,  2.03s/it]Running loglikelihood requests:   9%|▉         | 36/400 [01:35<12:07,  2.00s/it]Running loglikelihood requests:   9%|▉         | 37/400 [01:37<12:05,  2.00s/it]Running loglikelihood requests:  10%|▉         | 38/400 [01:39<12:16,  2.04s/it]Running loglikelihood requests:  10%|█         | 40/400 [01:41<09:29,  1.58s/it]Running loglikelihood requests:  10%|█         | 41/400 [01:43<09:48,  1.64s/it]Running loglikelihood requests:  10%|█         | 42/400 [01:45<10:00,  1.68s/it]Running loglikelihood requests:  11%|█         | 43/400 [01:47<10:10,  1.71s/it]Running loglikelihood requests:  11%|█         | 44/400 [01:48<10:16,  1.73s/it]Running loglikelihood requests:  11%|█▏        | 45/400 [01:50<10:11,  1.72s/it]Running loglikelihood requests:  12%|█▏        | 46/400 [01:52<10:07,  1.72s/it]Running loglikelihood requests:  12%|█▏        | 47/400 [01:53<10:04,  1.71s/it]Running loglikelihood requests:  12%|█▏        | 48/400 [01:55<10:01,  1.71s/it]Running loglikelihood requests:  12%|█▏        | 49/400 [01:57<09:57,  1.70s/it]Running loglikelihood requests:  12%|█▎        | 50/400 [01:59<09:54,  1.70s/it]Running loglikelihood requests:  13%|█▎        | 51/400 [02:00<09:59,  1.72s/it]Running loglikelihood requests:  13%|█▎        | 52/400 [02:02<10:06,  1.74s/it]Running loglikelihood requests:  13%|█▎        | 53/400 [02:04<09:52,  1.71s/it]Running loglikelihood requests:  14%|█▎        | 54/400 [02:05<09:41,  1.68s/it]Running loglikelihood requests:  14%|█▍        | 55/400 [02:07<09:34,  1.66s/it]Running loglikelihood requests:  14%|█▍        | 57/400 [02:08<07:05,  1.24s/it]Running loglikelihood requests:  14%|█▍        | 58/400 [02:10<07:24,  1.30s/it]Running loglikelihood requests:  15%|█▍        | 59/400 [02:11<07:38,  1.35s/it]Running loglikelihood requests:  16%|█▌        | 62/400 [02:13<05:03,  1.11it/s]Running loglikelihood requests:  16%|█▌        | 63/400 [02:14<05:42,  1.02s/it]Running loglikelihood requests:  16%|█▌        | 64/400 [02:16<06:15,  1.12s/it]Running loglikelihood requests:  16%|█▋        | 65/400 [02:17<06:39,  1.19s/it]Running loglikelihood requests:  16%|█▋        | 66/400 [02:19<06:58,  1.25s/it]Running loglikelihood requests:  17%|█▋        | 67/400 [02:20<07:12,  1.30s/it]Running loglikelihood requests:  17%|█▋        | 68/400 [02:22<07:22,  1.33s/it]Running loglikelihood requests:  17%|█▋        | 69/400 [02:23<07:27,  1.35s/it]Running loglikelihood requests:  18%|█▊        | 70/400 [02:24<07:31,  1.37s/it]Running loglikelihood requests:  18%|█▊        | 71/400 [02:26<07:32,  1.38s/it]Running loglikelihood requests:  18%|█▊        | 72/400 [02:27<07:34,  1.39s/it]Running loglikelihood requests:  18%|█▊        | 73/400 [02:29<07:38,  1.40s/it]Running loglikelihood requests:  18%|█▊        | 74/400 [02:30<07:41,  1.41s/it]Running loglikelihood requests:  19%|█▉        | 77/400 [02:31<04:42,  1.14it/s]Running loglikelihood requests:  20%|█▉        | 78/400 [02:33<05:13,  1.03it/s]Running loglikelihood requests:  20%|█▉        | 79/400 [02:34<05:39,  1.06s/it]Running loglikelihood requests:  20%|██        | 81/400 [02:35<04:41,  1.13it/s]Running loglikelihood requests:  20%|██        | 82/400 [02:37<05:03,  1.05it/s]Running loglikelihood requests:  21%|██        | 83/400 [02:38<05:22,  1.02s/it]Running loglikelihood requests:  21%|██        | 84/400 [02:39<05:36,  1.07s/it]Running loglikelihood requests:  21%|██▏       | 85/400 [02:40<05:47,  1.10s/it]Running loglikelihood requests:  22%|██▏       | 86/400 [02:41<05:54,  1.13s/it]Running loglikelihood requests:  22%|██▏       | 89/400 [02:43<03:47,  1.36it/s]Running loglikelihood requests:  22%|██▎       | 90/400 [02:44<04:16,  1.21it/s]Running loglikelihood requests:  23%|██▎       | 91/400 [02:45<04:40,  1.10it/s]Running loglikelihood requests:  23%|██▎       | 92/400 [02:46<05:00,  1.03it/s]Running loglikelihood requests:  23%|██▎       | 93/400 [02:47<05:15,  1.03s/it]Running loglikelihood requests:  24%|██▍       | 97/400 [02:48<02:58,  1.70it/s]Running loglikelihood requests:  24%|██▍       | 98/400 [02:50<03:28,  1.45it/s]Running loglikelihood requests:  25%|██▍       | 99/400 [02:51<03:56,  1.27it/s]Running loglikelihood requests:  25%|██▌       | 100/400 [02:52<04:21,  1.15it/s]Running loglikelihood requests:  25%|██▌       | 101/400 [02:53<04:41,  1.06it/s]Running loglikelihood requests:  26%|██▌       | 102/400 [02:54<04:57,  1.00it/s]Running loglikelihood requests:  26%|██▌       | 103/400 [02:55<05:09,  1.04s/it]Running loglikelihood requests:  26%|██▌       | 104/400 [02:57<05:17,  1.07s/it]Running loglikelihood requests:  26%|██▋       | 105/400 [02:58<05:22,  1.09s/it]Running loglikelihood requests:  26%|██▋       | 106/400 [02:59<05:26,  1.11s/it]Running loglikelihood requests:  27%|██▋       | 107/400 [03:00<05:30,  1.13s/it]Running loglikelihood requests:  27%|██▋       | 108/400 [03:01<05:30,  1.13s/it]Running loglikelihood requests:  27%|██▋       | 109/400 [03:02<05:30,  1.14s/it]Running loglikelihood requests:  28%|██▊       | 110/400 [03:03<05:29,  1.14s/it]Running loglikelihood requests:  28%|██▊       | 111/400 [03:05<05:27,  1.13s/it]Running loglikelihood requests:  28%|██▊       | 112/400 [03:06<05:26,  1.13s/it]Running loglikelihood requests:  28%|██▊       | 113/400 [03:07<05:24,  1.13s/it]Running loglikelihood requests:  28%|██▊       | 114/400 [03:08<05:22,  1.13s/it]Running loglikelihood requests:  29%|██▉       | 115/400 [03:09<05:20,  1.12s/it]Running loglikelihood requests:  29%|██▉       | 116/400 [03:10<05:20,  1.13s/it]Running loglikelihood requests:  29%|██▉       | 117/400 [03:11<05:18,  1.13s/it]Running loglikelihood requests:  30%|██▉       | 118/400 [03:12<05:15,  1.12s/it]Running loglikelihood requests:  30%|██▉       | 119/400 [03:14<05:13,  1.12s/it]Running loglikelihood requests:  30%|███       | 120/400 [03:15<05:12,  1.12s/it]Running loglikelihood requests:  30%|███       | 121/400 [03:16<05:06,  1.10s/it]Running loglikelihood requests:  30%|███       | 122/400 [03:17<05:02,  1.09s/it]Running loglikelihood requests:  31%|███       | 123/400 [03:18<04:58,  1.08s/it]Running loglikelihood requests:  31%|███       | 124/400 [03:19<04:56,  1.07s/it]Running loglikelihood requests:  31%|███▏      | 125/400 [03:20<04:52,  1.06s/it]Running loglikelihood requests:  32%|███▏      | 126/400 [03:21<04:48,  1.05s/it]Running loglikelihood requests:  32%|███▏      | 127/400 [03:22<04:46,  1.05s/it]Running loglikelihood requests:  32%|███▏      | 128/400 [03:23<04:44,  1.05s/it]Running loglikelihood requests:  32%|███▏      | 129/400 [03:24<04:42,  1.04s/it]Running loglikelihood requests:  32%|███▎      | 130/400 [03:25<04:43,  1.05s/it]Running loglikelihood requests:  33%|███▎      | 131/400 [03:26<04:41,  1.05s/it]Running loglikelihood requests:  34%|███▎      | 134/400 [03:27<02:52,  1.54it/s]Running loglikelihood requests:  34%|███▍      | 135/400 [03:28<03:13,  1.37it/s]Running loglikelihood requests:  34%|███▍      | 136/400 [03:29<03:30,  1.25it/s]Running loglikelihood requests:  34%|███▍      | 137/400 [03:30<03:44,  1.17it/s]Running loglikelihood requests:  34%|███▍      | 138/400 [03:31<03:55,  1.11it/s]Running loglikelihood requests:  35%|███▍      | 139/400 [03:32<04:02,  1.07it/s]Running loglikelihood requests:  36%|███▌      | 142/400 [03:33<02:37,  1.63it/s]Running loglikelihood requests:  36%|███▌      | 143/400 [03:34<02:58,  1.44it/s]Running loglikelihood requests:  36%|███▌      | 144/400 [03:35<03:16,  1.30it/s]Running loglikelihood requests:  36%|███▋      | 145/400 [03:36<03:30,  1.21it/s]Running loglikelihood requests:  36%|███▋      | 146/400 [03:37<03:41,  1.15it/s]Running loglikelihood requests:  37%|███▋      | 147/400 [03:38<03:49,  1.10it/s]Running loglikelihood requests:  37%|███▋      | 148/400 [03:39<03:55,  1.07it/s]Running loglikelihood requests:  37%|███▋      | 149/400 [03:40<03:59,  1.05it/s]Running loglikelihood requests:  38%|███▊      | 150/400 [03:41<04:02,  1.03it/s]Running loglikelihood requests:  38%|███▊      | 151/400 [03:42<04:03,  1.02it/s]Running loglikelihood requests:  38%|███▊      | 152/400 [03:43<04:04,  1.01it/s]Running loglikelihood requests:  38%|███▊      | 153/400 [03:44<04:04,  1.01it/s]Running loglikelihood requests:  38%|███▊      | 154/400 [03:45<04:05,  1.00it/s]Running loglikelihood requests:  39%|███▉      | 155/400 [03:46<04:05,  1.00s/it]Running loglikelihood requests:  39%|███▉      | 156/400 [03:47<04:04,  1.00s/it]Running loglikelihood requests:  39%|███▉      | 157/400 [03:48<04:03,  1.00s/it]Running loglikelihood requests:  40%|███▉      | 158/400 [03:49<04:02,  1.00s/it]Running loglikelihood requests:  40%|███▉      | 159/400 [03:51<04:02,  1.01s/it]Running loglikelihood requests:  40%|████      | 160/400 [03:51<04:00,  1.00s/it]Running loglikelihood requests:  40%|████      | 161/400 [03:52<03:58,  1.00it/s]Running loglikelihood requests:  40%|████      | 162/400 [03:53<03:57,  1.00it/s]Running loglikelihood requests:  41%|████      | 163/400 [03:54<03:56,  1.00it/s]Running loglikelihood requests:  41%|████      | 164/400 [03:55<03:53,  1.01it/s]Running loglikelihood requests:  41%|████▏     | 165/400 [03:56<03:51,  1.02it/s]Running loglikelihood requests:  42%|████▏     | 166/400 [03:57<03:48,  1.02it/s]Running loglikelihood requests:  42%|████▏     | 167/400 [03:58<03:46,  1.03it/s]Running loglikelihood requests:  42%|████▏     | 168/400 [03:59<03:45,  1.03it/s]Running loglikelihood requests:  42%|████▏     | 169/400 [04:00<03:43,  1.03it/s]Running loglikelihood requests:  42%|████▎     | 170/400 [04:01<03:41,  1.04it/s]Running loglikelihood requests:  43%|████▎     | 172/400 [04:02<02:48,  1.35it/s]Running loglikelihood requests:  43%|████▎     | 173/400 [04:03<02:58,  1.27it/s]Running loglikelihood requests:  44%|████▎     | 174/400 [04:04<03:05,  1.22it/s]Running loglikelihood requests:  44%|████▍     | 177/400 [04:05<02:02,  1.82it/s]Running loglikelihood requests:  44%|████▍     | 178/400 [04:06<02:18,  1.60it/s]Running loglikelihood requests:  45%|████▍     | 179/400 [04:07<02:32,  1.45it/s]Running loglikelihood requests:  45%|████▌     | 180/400 [04:08<02:43,  1.34it/s]Running loglikelihood requests:  45%|████▌     | 181/400 [04:09<02:51,  1.27it/s]Running loglikelihood requests:  46%|████▌     | 182/400 [04:10<02:57,  1.23it/s]Running loglikelihood requests:  46%|████▌     | 183/400 [04:10<03:01,  1.19it/s]Running loglikelihood requests:  46%|████▌     | 184/400 [04:11<03:04,  1.17it/s]Running loglikelihood requests:  46%|████▋     | 185/400 [04:12<03:05,  1.16it/s]Running loglikelihood requests:  46%|████▋     | 186/400 [04:13<03:06,  1.15it/s]Running loglikelihood requests:  47%|████▋     | 187/400 [04:14<03:06,  1.14it/s]Running loglikelihood requests:  47%|████▋     | 188/400 [04:15<03:06,  1.14it/s]Running loglikelihood requests:  47%|████▋     | 189/400 [04:16<03:05,  1.13it/s]Running loglikelihood requests:  48%|████▊     | 190/400 [04:17<03:05,  1.13it/s]Running loglikelihood requests:  48%|████▊     | 191/400 [04:17<03:03,  1.14it/s]Running loglikelihood requests:  48%|████▊     | 192/400 [04:18<03:01,  1.14it/s]Running loglikelihood requests:  48%|████▊     | 193/400 [04:19<03:00,  1.15it/s]Running loglikelihood requests:  48%|████▊     | 194/400 [04:20<03:00,  1.14it/s]Running loglikelihood requests:  49%|████▉     | 195/400 [04:21<03:00,  1.13it/s]Running loglikelihood requests:  49%|████▉     | 196/400 [04:22<02:57,  1.15it/s]Running loglikelihood requests:  49%|████▉     | 197/400 [04:23<02:54,  1.16it/s]Running loglikelihood requests:  50%|████▉     | 198/400 [04:24<02:51,  1.18it/s]Running loglikelihood requests:  50%|████▉     | 199/400 [04:24<02:49,  1.19it/s]Running loglikelihood requests:  50%|█████     | 200/400 [04:25<02:51,  1.17it/s]Running loglikelihood requests:  50%|█████     | 201/400 [04:26<02:51,  1.16it/s]Running loglikelihood requests:  50%|█████     | 202/400 [04:27<02:51,  1.16it/s]Running loglikelihood requests:  51%|█████     | 203/400 [04:28<02:50,  1.15it/s]Running loglikelihood requests:  51%|█████     | 204/400 [04:29<02:50,  1.15it/s]Running loglikelihood requests:  51%|█████▏    | 205/400 [04:30<02:49,  1.15it/s]Running loglikelihood requests:  52%|█████▏    | 206/400 [04:30<02:49,  1.15it/s]Running loglikelihood requests:  52%|█████▏    | 207/400 [04:31<02:48,  1.15it/s]Running loglikelihood requests:  52%|█████▏    | 208/400 [04:32<02:47,  1.15it/s]Running loglikelihood requests:  52%|█████▏    | 209/400 [04:33<02:46,  1.14it/s]Running loglikelihood requests:  53%|█████▎    | 212/400 [04:34<01:42,  1.83it/s]Running loglikelihood requests:  53%|█████▎    | 213/400 [04:35<01:53,  1.64it/s]Running loglikelihood requests:  54%|█████▎    | 214/400 [04:36<02:03,  1.50it/s]Running loglikelihood requests:  54%|█████▍    | 215/400 [04:36<02:11,  1.41it/s]Running loglikelihood requests:  54%|█████▍    | 216/400 [04:37<02:17,  1.34it/s]Running loglikelihood requests:  54%|█████▍    | 217/400 [04:38<02:21,  1.30it/s]Running loglikelihood requests:  55%|█████▍    | 218/400 [04:39<02:24,  1.26it/s]Running loglikelihood requests:  55%|█████▍    | 219/400 [04:40<02:25,  1.24it/s]Running loglikelihood requests:  55%|█████▌    | 220/400 [04:41<02:27,  1.22it/s]Running loglikelihood requests:  55%|█████▌    | 221/400 [04:42<02:27,  1.21it/s]Running loglikelihood requests:  56%|█████▌    | 222/400 [04:42<02:27,  1.21it/s]Running loglikelihood requests:  56%|█████▌    | 223/400 [04:43<02:26,  1.21it/s]Running loglikelihood requests:  56%|█████▌    | 224/400 [04:44<02:25,  1.21it/s]Running loglikelihood requests:  56%|█████▋    | 225/400 [04:45<02:25,  1.21it/s]Running loglikelihood requests:  56%|█████▋    | 226/400 [04:46<02:23,  1.21it/s]Running loglikelihood requests:  57%|█████▋    | 227/400 [04:46<02:20,  1.23it/s]Running loglikelihood requests:  57%|█████▋    | 228/400 [04:47<02:18,  1.24it/s]Running loglikelihood requests:  57%|█████▋    | 229/400 [04:48<02:16,  1.25it/s]Running loglikelihood requests:  57%|█████▊    | 230/400 [04:49<02:15,  1.26it/s]Running loglikelihood requests:  58%|█████▊    | 231/400 [04:50<02:14,  1.26it/s]Running loglikelihood requests:  58%|█████▊    | 232/400 [04:50<02:13,  1.26it/s]Running loglikelihood requests:  58%|█████▊    | 233/400 [04:51<02:11,  1.27it/s]Running loglikelihood requests:  58%|█████▊    | 234/400 [04:52<02:12,  1.25it/s]Running loglikelihood requests:  59%|█████▉    | 235/400 [04:53<02:11,  1.25it/s]Running loglikelihood requests:  59%|█████▉    | 236/400 [04:54<02:13,  1.22it/s]Running loglikelihood requests:  59%|█████▉    | 237/400 [04:54<02:11,  1.24it/s]Running loglikelihood requests:  60%|██████    | 240/400 [04:55<01:19,  2.01it/s]Running loglikelihood requests:  60%|██████    | 241/400 [04:56<01:27,  1.81it/s]Running loglikelihood requests:  60%|██████    | 242/400 [04:57<01:34,  1.67it/s]Running loglikelihood requests:  61%|██████    | 243/400 [04:57<01:40,  1.57it/s]Running loglikelihood requests:  61%|██████    | 244/400 [04:58<01:44,  1.50it/s]Running loglikelihood requests:  61%|██████▏   | 245/400 [04:59<01:47,  1.45it/s]Running loglikelihood requests:  62%|██████▏   | 246/400 [05:00<01:48,  1.42it/s]Running loglikelihood requests:  62%|██████▏   | 247/400 [05:00<01:49,  1.39it/s]Running loglikelihood requests:  62%|██████▏   | 248/400 [05:01<01:50,  1.38it/s]Running loglikelihood requests:  62%|██████▏   | 249/400 [05:02<01:50,  1.37it/s]Running loglikelihood requests:  62%|██████▎   | 250/400 [05:03<01:50,  1.36it/s]Running loglikelihood requests:  63%|██████▎   | 251/400 [05:03<01:49,  1.36it/s]Running loglikelihood requests:  63%|██████▎   | 252/400 [05:04<01:49,  1.36it/s]Running loglikelihood requests:  63%|██████▎   | 253/400 [05:05<01:48,  1.36it/s]Running loglikelihood requests:  64%|██████▎   | 254/400 [05:06<01:47,  1.36it/s]Running loglikelihood requests:  64%|██████▍   | 255/400 [05:06<01:46,  1.36it/s]Running loglikelihood requests:  64%|██████▍   | 256/400 [05:07<01:46,  1.36it/s]Running loglikelihood requests:  64%|██████▍   | 257/400 [05:08<01:45,  1.36it/s]Running loglikelihood requests:  64%|██████▍   | 258/400 [05:09<01:44,  1.36it/s]Running loglikelihood requests:  65%|██████▍   | 259/400 [05:09<01:43,  1.37it/s]Running loglikelihood requests:  65%|██████▌   | 260/400 [05:10<01:42,  1.37it/s]Running loglikelihood requests:  65%|██████▌   | 261/400 [05:11<01:40,  1.38it/s]Running loglikelihood requests:  66%|██████▌   | 262/400 [05:11<01:38,  1.40it/s]Running loglikelihood requests:  66%|██████▌   | 263/400 [05:12<01:36,  1.42it/s]Running loglikelihood requests:  66%|██████▌   | 264/400 [05:13<01:35,  1.43it/s]Running loglikelihood requests:  66%|██████▋   | 265/400 [05:13<01:32,  1.46it/s]Running loglikelihood requests:  66%|██████▋   | 266/400 [05:14<01:30,  1.49it/s]Running loglikelihood requests:  67%|██████▋   | 267/400 [05:15<01:28,  1.50it/s]Running loglikelihood requests:  67%|██████▋   | 268/400 [05:15<01:27,  1.52it/s]Running loglikelihood requests:  67%|██████▋   | 269/400 [05:16<01:25,  1.53it/s]Running loglikelihood requests:  68%|██████▊   | 270/400 [05:17<01:23,  1.55it/s]Running loglikelihood requests:  68%|██████▊   | 271/400 [05:17<01:22,  1.56it/s]Running loglikelihood requests:  68%|██████▊   | 272/400 [05:18<01:22,  1.55it/s]Running loglikelihood requests:  68%|██████▊   | 273/400 [05:19<01:20,  1.57it/s]Running loglikelihood requests:  68%|██████▊   | 274/400 [05:19<01:19,  1.59it/s]Running loglikelihood requests:  69%|██████▉   | 275/400 [05:20<01:17,  1.61it/s]Running loglikelihood requests:  69%|██████▉   | 276/400 [05:20<01:16,  1.62it/s]Running loglikelihood requests:  69%|██████▉   | 277/400 [05:21<01:15,  1.63it/s]Running loglikelihood requests:  70%|██████▉   | 278/400 [05:22<01:14,  1.64it/s]Running loglikelihood requests:  70%|██████▉   | 279/400 [05:22<01:13,  1.65it/s]Running loglikelihood requests:  70%|███████   | 280/400 [05:23<01:12,  1.66it/s]Running loglikelihood requests:  70%|███████   | 281/400 [05:23<01:11,  1.67it/s]Running loglikelihood requests:  70%|███████   | 282/400 [05:24<01:10,  1.67it/s]Running loglikelihood requests:  71%|███████   | 283/400 [05:25<01:10,  1.66it/s]Running loglikelihood requests:  71%|███████   | 284/400 [05:25<01:10,  1.65it/s]Running loglikelihood requests:  71%|███████▏  | 285/400 [05:26<01:09,  1.66it/s]Running loglikelihood requests:  72%|███████▏  | 286/400 [05:26<01:08,  1.67it/s]Running loglikelihood requests:  72%|███████▏  | 287/400 [05:27<01:07,  1.68it/s]Running loglikelihood requests:  72%|███████▏  | 288/400 [05:28<01:06,  1.68it/s]Running loglikelihood requests:  72%|███████▏  | 289/400 [05:28<01:05,  1.69it/s]Running loglikelihood requests:  72%|███████▎  | 290/400 [05:29<01:05,  1.69it/s]Running loglikelihood requests:  73%|███████▎  | 291/400 [05:29<01:04,  1.70it/s]Running loglikelihood requests:  73%|███████▎  | 292/400 [05:30<01:03,  1.69it/s]Running loglikelihood requests:  73%|███████▎  | 293/400 [05:31<01:02,  1.70it/s]Running loglikelihood requests:  74%|███████▎  | 294/400 [05:31<01:02,  1.71it/s]Running loglikelihood requests:  74%|███████▍  | 295/400 [05:32<01:01,  1.72it/s]Running loglikelihood requests:  74%|███████▍  | 296/400 [05:32<01:00,  1.72it/s]Running loglikelihood requests:  74%|███████▍  | 297/400 [05:33<00:59,  1.73it/s]Running loglikelihood requests:  74%|███████▍  | 298/400 [05:33<00:58,  1.73it/s]Running loglikelihood requests:  75%|███████▍  | 299/400 [05:34<00:58,  1.73it/s]Running loglikelihood requests:  75%|███████▌  | 300/400 [05:35<00:57,  1.73it/s]Running loglikelihood requests:  75%|███████▌  | 301/400 [05:35<00:57,  1.73it/s]Running loglikelihood requests:  76%|███████▌  | 302/400 [05:36<00:57,  1.71it/s]Running loglikelihood requests:  76%|███████▌  | 303/400 [05:36<00:56,  1.72it/s]Running loglikelihood requests:  76%|███████▌  | 304/400 [05:37<00:55,  1.73it/s]Running loglikelihood requests:  76%|███████▋  | 305/400 [05:37<00:54,  1.73it/s]Running loglikelihood requests:  76%|███████▋  | 306/400 [05:38<00:54,  1.74it/s]Running loglikelihood requests:  77%|███████▋  | 307/400 [05:39<00:53,  1.74it/s]Running loglikelihood requests:  78%|███████▊  | 310/400 [05:39<00:32,  2.80it/s]Running loglikelihood requests:  78%|███████▊  | 311/400 [05:40<00:35,  2.49it/s]Running loglikelihood requests:  78%|███████▊  | 312/400 [05:40<00:38,  2.27it/s]Running loglikelihood requests:  78%|███████▊  | 313/400 [05:41<00:41,  2.12it/s]Running loglikelihood requests:  78%|███████▊  | 314/400 [05:41<00:42,  2.01it/s]Running loglikelihood requests:  79%|███████▉  | 315/400 [05:42<00:43,  1.94it/s]Running loglikelihood requests:  79%|███████▉  | 316/400 [05:43<00:44,  1.89it/s]Running loglikelihood requests:  79%|███████▉  | 317/400 [05:43<00:44,  1.87it/s]Running loglikelihood requests:  80%|███████▉  | 318/400 [05:44<00:44,  1.85it/s]Running loglikelihood requests:  80%|███████▉  | 319/400 [05:44<00:43,  1.84it/s]Running loglikelihood requests:  80%|████████  | 321/400 [05:45<00:33,  2.39it/s]Running loglikelihood requests:  80%|████████  | 322/400 [05:45<00:35,  2.23it/s]Running loglikelihood requests:  81%|████████  | 323/400 [05:46<00:36,  2.10it/s]Running loglikelihood requests:  81%|████████  | 324/400 [05:46<00:37,  2.00it/s]Running loglikelihood requests:  81%|████████▏ | 325/400 [05:47<00:38,  1.95it/s]Running loglikelihood requests:  82%|████████▏ | 326/400 [05:47<00:38,  1.93it/s]Running loglikelihood requests:  82%|████████▏ | 327/400 [05:48<00:38,  1.91it/s]Running loglikelihood requests:  82%|████████▏ | 328/400 [05:49<00:37,  1.90it/s]Running loglikelihood requests:  82%|████████▏ | 329/400 [05:49<00:37,  1.90it/s]Running loglikelihood requests:  82%|████████▎ | 330/400 [05:50<00:36,  1.89it/s]Running loglikelihood requests:  83%|████████▎ | 331/400 [05:50<00:36,  1.89it/s]Running loglikelihood requests:  83%|████████▎ | 332/400 [05:51<00:36,  1.88it/s]Running loglikelihood requests:  83%|████████▎ | 333/400 [05:51<00:35,  1.89it/s]Running loglikelihood requests:  84%|████████▎ | 334/400 [05:52<00:34,  1.90it/s]Running loglikelihood requests:  84%|████████▍ | 335/400 [05:52<00:33,  1.92it/s]Running loglikelihood requests:  84%|████████▍ | 336/400 [05:53<00:33,  1.93it/s]Running loglikelihood requests:  84%|████████▍ | 337/400 [05:53<00:32,  1.93it/s]Running loglikelihood requests:  84%|████████▍ | 338/400 [05:54<00:31,  1.94it/s]Running loglikelihood requests:  85%|████████▍ | 339/400 [05:54<00:31,  1.95it/s]Running loglikelihood requests:  85%|████████▌ | 340/400 [05:55<00:30,  1.96it/s]Running loglikelihood requests:  85%|████████▌ | 341/400 [05:55<00:30,  1.96it/s]Running loglikelihood requests:  86%|████████▌ | 342/400 [05:56<00:29,  1.96it/s]Running loglikelihood requests:  86%|████████▌ | 343/400 [05:56<00:29,  1.96it/s]Running loglikelihood requests:  86%|████████▌ | 344/400 [05:57<00:28,  1.96it/s]Running loglikelihood requests:  86%|████████▋ | 345/400 [05:57<00:27,  1.97it/s]Running loglikelihood requests:  86%|████████▋ | 346/400 [05:58<00:27,  1.98it/s]Running loglikelihood requests:  87%|████████▋ | 347/400 [05:58<00:26,  1.98it/s]Running loglikelihood requests:  87%|████████▋ | 348/400 [05:59<00:26,  1.98it/s]Running loglikelihood requests:  87%|████████▋ | 349/400 [05:59<00:25,  1.98it/s]Running loglikelihood requests:  88%|████████▊ | 350/400 [06:00<00:25,  1.98it/s]Running loglikelihood requests:  88%|████████▊ | 351/400 [06:00<00:24,  1.98it/s]Running loglikelihood requests:  88%|████████▊ | 352/400 [06:01<00:24,  1.98it/s]Running loglikelihood requests:  88%|████████▊ | 353/400 [06:01<00:23,  1.97it/s]Running loglikelihood requests:  88%|████████▊ | 354/400 [06:02<00:23,  1.99it/s]Running loglikelihood requests:  89%|████████▉ | 355/400 [06:02<00:22,  2.00it/s]Running loglikelihood requests:  89%|████████▉ | 356/400 [06:03<00:21,  2.01it/s]Running loglikelihood requests:  89%|████████▉ | 357/400 [06:03<00:21,  2.02it/s]Running loglikelihood requests:  90%|████████▉ | 358/400 [06:04<00:20,  2.02it/s]Running loglikelihood requests:  90%|████████▉ | 359/400 [06:04<00:20,  2.02it/s]Running loglikelihood requests:  90%|█████████ | 360/400 [06:05<00:19,  2.02it/s]Running loglikelihood requests:  90%|█████████ | 361/400 [06:05<00:19,  2.00it/s]Running loglikelihood requests:  90%|█████████ | 362/400 [06:06<00:18,  2.02it/s]Running loglikelihood requests:  91%|█████████ | 363/400 [06:06<00:18,  2.03it/s]Running loglikelihood requests:  91%|█████████ | 364/400 [06:07<00:17,  2.05it/s]Running loglikelihood requests:  91%|█████████▏| 365/400 [06:07<00:17,  2.05it/s]Running loglikelihood requests:  92%|█████████▏| 366/400 [06:08<00:16,  2.06it/s]Running loglikelihood requests:  92%|█████████▏| 368/400 [06:08<00:11,  2.68it/s]Running loglikelihood requests:  92%|█████████▏| 369/400 [06:09<00:12,  2.50it/s]Running loglikelihood requests:  92%|█████████▎| 370/400 [06:09<00:12,  2.37it/s]Running loglikelihood requests:  93%|█████████▎| 371/400 [06:10<00:12,  2.28it/s]Running loglikelihood requests:  93%|█████████▎| 373/400 [06:10<00:09,  2.84it/s]Running loglikelihood requests:  94%|█████████▎| 374/400 [06:11<00:10,  2.57it/s]Running loglikelihood requests:  94%|█████████▍| 375/400 [06:11<00:10,  2.42it/s]Running loglikelihood requests:  94%|█████████▍| 376/400 [06:12<00:10,  2.32it/s]Running loglikelihood requests:  94%|█████████▍| 377/400 [06:12<00:10,  2.26it/s]Running loglikelihood requests:  94%|█████████▍| 378/400 [06:13<00:09,  2.22it/s]Running loglikelihood requests:  95%|█████████▍| 379/400 [06:13<00:09,  2.20it/s]Running loglikelihood requests:  95%|█████████▌| 380/400 [06:14<00:09,  2.18it/s]Running loglikelihood requests:  95%|█████████▌| 381/400 [06:14<00:08,  2.17it/s]Running loglikelihood requests:  96%|█████████▌| 382/400 [06:14<00:08,  2.17it/s]Running loglikelihood requests:  96%|█████████▌| 383/400 [06:15<00:07,  2.16it/s]Running loglikelihood requests:  96%|█████████▌| 384/400 [06:15<00:07,  2.13it/s]Running loglikelihood requests:  96%|█████████▋| 385/400 [06:16<00:07,  2.13it/s]Running loglikelihood requests:  96%|█████████▋| 386/400 [06:16<00:06,  2.14it/s]Running loglikelihood requests:  97%|█████████▋| 387/400 [06:17<00:06,  2.15it/s]Running loglikelihood requests:  97%|█████████▋| 388/400 [06:17<00:05,  2.12it/s]Running loglikelihood requests:  97%|█████████▋| 389/400 [06:18<00:05,  2.15it/s]Running loglikelihood requests:  98%|█████████▊| 390/400 [06:18<00:04,  2.16it/s]Running loglikelihood requests:  98%|█████████▊| 391/400 [06:19<00:04,  2.17it/s]Running loglikelihood requests:  98%|█████████▊| 392/400 [06:19<00:03,  2.19it/s]Running loglikelihood requests:  98%|█████████▊| 393/400 [06:20<00:03,  2.21it/s]Running loglikelihood requests:  98%|█████████▊| 394/400 [06:20<00:02,  2.21it/s]Running loglikelihood requests:  99%|█████████▉| 395/400 [06:20<00:02,  2.22it/s]Running loglikelihood requests:  99%|█████████▉| 396/400 [06:21<00:01,  2.23it/s]Running loglikelihood requests:  99%|█████████▉| 397/400 [06:21<00:01,  2.24it/s]Running loglikelihood requests: 100%|█████████▉| 398/400 [06:22<00:00,  2.25it/s]Running loglikelihood requests: 100%|█████████▉| 399/400 [06:22<00:00,  2.25it/s]Running loglikelihood requests: 100%|██████████| 400/400 [06:23<00:00,  2.27it/s]Running loglikelihood requests: 100%|██████████| 400/400 [06:23<00:00,  1.04it/s]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:5'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:5'}
full model:
{'sciq': {'alias': 'sciq', 'acc,none': 0.94, 'acc_stderr,none': 0.023868325657594204, 'acc_norm,none': 0.91, 'acc_norm_stderr,none': 0.028762349126466136}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.969062788859705
0.9024924890572922
0.7706109127217512
0.8221264026535647
0.9190490061886575
0.9866654579796295
0.6586322754204971
0.7962110384246164
0.8195614021629236
0.7124178311176441
0.787697814339696
0.7034455022322618
0.8136386046534271
0.8174990104652458
0.6784276389594894
0.8698440245672888
0.8886492811850213
0.6541737276411673
0.6560861559753316
0.8139845219953913
0.6714741870309046
0.6164364868717988
0.8331581872497299
0.9065420049234512
0.9246185715568276
0.7477515960551026
0.574165362968651
0.8586446364199891
0.8889771415746612
Total groups 70 exceeded the threshold, stopping comparison.
The group tensor is
[7, 3, 4, 2, 6, 1, 5, 0]
tensor([7, 3, 4, 2, 6, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 2, 5, 3, 4, 0, 7, 1]
tensor([6, 2, 5, 3, 4, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 3, 6, 2, 7, 1, 4, 0]
tensor([5, 3, 6, 2, 7, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 4, 2, 1, 3, 5, 1]
tensor([0, 0, 4, 2, 1, 3, 5, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 2, 3, 4, 5, 0, 1, 1]
tensor([0, 2, 3, 4, 5, 0, 1, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 1, 0, 2, 2, 3, 1]
tensor([0, 3, 1, 0, 2, 2, 3, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 3, 1, 1, 2, 2, 3, 0]
tensor([0, 3, 1, 1, 2, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 1, 1.0, 1.0, 1.0, 1.0, 1]
tensor([0, 0, 1, 1, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 2 to 4
done!
Normal merging for layer 5
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 6 to 9
done!
Normal merging for layer 10
tensor([0, 1])
tensor(0)
tensor([4, 7])
tensor(4)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 11 to 12
done!
Normal merging for layer 13
tensor([0, 5])
tensor(0)
tensor([6, 7])
tensor(6)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 14 to 19
done!
Normal merging for layer 20
tensor([0, 3])
tensor(0)
tensor([2, 7])
tensor(2)
tensor([4, 5])
tensor(4)
tensor([1, 6])
tensor(1)
done!
Normal merging for layer 21
tensor([0, 7])
tensor(0)
tensor([2, 3])
tensor(2)
tensor([4, 5])
tensor(4)
tensor([1, 6])
tensor(1)
done!
Cross-layer merge completed for layers 22 to 23
done!
Normal merging for layer 24
tensor([0, 1])
tensor(0)
tensor([2, 3, 4, 5, 6, 7])
tensor(2)
done!
Cross-layer merge completed for layers 25 to 31
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 12 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.2608 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 11 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

123
cuda:5
wnli
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:55<00:55, 55.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:13<00:00, 33.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:13<00:00, 36.64s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140430712556768 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140430712556768 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430712556768 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140430712556768 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140430950657792 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140430950657792 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430950657792 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140430950657792 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2555.94it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:01<03:42,  1.58s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:02<01:38,  1.41it/s]Running loglikelihood requests:   4%|▎         | 5/142 [00:03<01:14,  1.84it/s]Running loglikelihood requests:   5%|▍         | 7/142 [00:03<01:04,  2.10it/s]Running loglikelihood requests:   6%|▋         | 9/142 [00:04<00:58,  2.27it/s]Running loglikelihood requests:   8%|▊         | 11/142 [00:05<00:55,  2.35it/s]Running loglikelihood requests:   9%|▉         | 13/142 [00:06<00:53,  2.43it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:06<00:49,  2.56it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:07<00:46,  2.68it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:08<00:44,  2.77it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:08<00:42,  2.85it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:09<00:40,  2.95it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:10<00:38,  3.04it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:10<00:37,  3.10it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:11<00:35,  3.16it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:12<00:34,  3.20it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:12<00:33,  3.23it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:13<00:32,  3.26it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:13<00:32,  3.27it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:14<00:31,  3.30it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:15<00:30,  3.31it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:15<00:30,  3.26it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:16<00:29,  3.31it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:16<00:28,  3.36it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:17<00:27,  3.36it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:17<00:26,  3.42it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:18<00:25,  3.43it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:19<00:25,  3.46it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:19<00:24,  3.50it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:20<00:23,  3.52it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:20<00:23,  3.49it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:21<00:22,  3.51it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:21<00:21,  3.55it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:22<00:20,  3.57it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:23<00:20,  3.60it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:23<00:19,  3.61it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:24<00:18,  3.64it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [00:24<00:18,  3.65it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [00:25<00:17,  3.66it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [00:25<00:17,  3.68it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [00:26<00:17,  3.50it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [00:26<00:16,  3.56it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [00:27<00:15,  3.60it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [00:27<00:15,  3.65it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [00:28<00:14,  3.68it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [00:29<00:13,  3.70it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [00:29<00:13,  3.72it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [00:30<00:12,  3.74it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [00:30<00:12,  3.75it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [00:31<00:11,  3.76it/s]Running loglikelihood requests:  71%|███████   | 101/142 [00:31<00:10,  3.78it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [00:32<00:10,  3.80it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [00:32<00:09,  3.81it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [00:33<00:09,  3.83it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [00:33<00:08,  3.83it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [00:34<00:08,  3.84it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [00:34<00:07,  3.84it/s]Running loglikelihood requests:  81%|████████  | 115/142 [00:35<00:07,  3.85it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [00:35<00:06,  3.81it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [00:36<00:05,  3.85it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [00:36<00:05,  3.87it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [00:37<00:04,  3.91it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [00:37<00:04,  3.93it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [00:38<00:03,  3.95it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [00:38<00:03,  3.97it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [00:39<00:02,  3.98it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [00:39<00:02,  4.01it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [00:40<00:01,  4.04it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [00:40<00:01,  4.06it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [00:41<00:00,  4.09it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [00:41<00:00,  4.14it/s]Running loglikelihood requests: 100%|██████████| 142/142 [00:41<00:00,  3.40it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:6'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:6'}
full model:
{'wnli': {'alias': 'wnli', 'acc,none': 0.5352112676056338, 'acc_stderr,none': 0.0596130578497224}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.31190044950254875
0.7306280553786256
0.6985925052465822
0.5843516732063875
0.8124235844589114
0.820438203921003
0.6253838264581936
0.7600037006947045
0.8225872978677496
0.708398461303215
0.8646089269479391
0.8239362351853257
0.7608099850331435
0.6657423857513638
0.7943257460202938
0.7511476003698512
0.9073696655228775
0.8741838353767599
0.7945799099309127
0.9323691001541556
0.865243808509542
0.8176606226311932
0.6785099625983169
0.9579534328203848
0.788928884938056
0.9833718962298513
0.5933012307657521
0.7829988799240639
0.7823073743206628
0.31190044950254875
0.7306280553786256
0.6985925052465822
0.5843516732063875
0.8124235844589114
0.820438203921003
0.6253838264581936
0.7600037006947045
0.8225872978677496
0.708398461303215
0.8646089269479391
0.8239362351853257
0.7608099850331435
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[7, 4, 5, 1, 6, 3, 2, 0]
tensor([7, 4, 5, 1, 6, 3, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 2, 4, 5, 6, 1, 0, 3]
tensor([7, 2, 4, 5, 6, 1, 0, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 7, 5, 4, 1, 2, 0]
tensor([6, 3, 7, 5, 4, 1, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 3, 6, 4, 7, 1, 2, 0]
tensor([5, 3, 6, 4, 7, 1, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 3, 6, 5, 7, 2, 1, 0]
tensor([4, 3, 6, 5, 7, 2, 1, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1, 2, 3, 2, 3, 0]
tensor([0, 1, 1, 2, 3, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 1, 2, 2, 3, 0, 3, 1]
tensor([0, 1, 2, 2, 3, 0, 3, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 1, 1, 1.0, 1.0, 1.0, 1.0]
tensor([0, 0, 1, 1, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
Normal merging for layer 1
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
done!
Normal merging for layer 2
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
tensor([3])
tensor(3)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Normal merging for layer 4
tensor([7])
tensor(7)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 5 to 15
done!
Normal merging for layer 16
tensor([0, 7])
tensor(0)
tensor([1, 2])
tensor(1)
tensor([3, 5])
tensor(3)
tensor([4, 6])
tensor(4)
done!
Normal merging for layer 17
tensor([0, 5])
tensor(0)
tensor([1, 7])
tensor(1)
tensor([2, 3])
tensor(2)
tensor([4, 6])
tensor(4)
done!
Cross-layer merge completed for layers 18 to 30
done!
Normal merging for layer 31
tensor([0, 1])
tensor(0)
tensor([2, 3, 4, 5, 6, 7])
tensor(2)
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 11 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.2608 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 10 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

105
cuda:6
eq_bench
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:51<00:51, 51.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:09<00:00, 31.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:09<00:00, 34.87s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:eq_bench: No `until` specified in `generation_kwargs`! Defaulting to the fewshot_delimiter='\n\n'
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/pbevan11/EQ-Bench HTTP/1.1" 200 787
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/pbevan11/EQ-Bench/pbevan11/EQ-Bench.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/pbevan11/EQ-Bench HTTP/1.1" 200 796
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/pbevan11/EQ-Bench/resolve/9ce8e5ffc1a36be5f946b37610ec8c516871f0d3/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/pbevan11/EQ-Bench/tree/9ce8e5ffc1a36be5f946b37610ec8c516871f0d3/data?recursive=False&expand=False HTTP/1.1" 404 79
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/pbevan11/EQ-Bench/tree/9ce8e5ffc1a36be5f946b37610ec8c516871f0d3/data?recursive=False&expand=False HTTP/1.1" 404 79
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/pbevan11/EQ-Bench/resolve/9ce8e5ffc1a36be5f946b37610ec8c516871f0d3/dataset_infos.json HTTP/1.1" 404 0
DEBUG:filelock:Attempting to acquire lock 140430945954336 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_pbevan11___eq-bench_default_0.0.0_9ce8e5ffc1a36be5f946b37610ec8c516871f0d3.lock
DEBUG:filelock:Lock 140430945954336 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_pbevan11___eq-bench_default_0.0.0_9ce8e5ffc1a36be5f946b37610ec8c516871f0d3.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/pbevan11___eq-bench/default/0.0.0/9ce8e5ffc1a36be5f946b37610ec8c516871f0d3/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430945954336 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_pbevan11___eq-bench_default_0.0.0_9ce8e5ffc1a36be5f946b37610ec8c516871f0d3.lock
DEBUG:filelock:Lock 140430945954336 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_pbevan11___eq-bench_default_0.0.0_9ce8e5ffc1a36be5f946b37610ec8c516871f0d3.lock
DEBUG:filelock:Attempting to acquire lock 140430675215856 on /public/home/zouyifei001/.cache/huggingface/datasets/pbevan11___eq-bench/default/0.0.0/9ce8e5ffc1a36be5f946b37610ec8c516871f0d3_builder.lock
DEBUG:filelock:Lock 140430675215856 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/pbevan11___eq-bench/default/0.0.0/9ce8e5ffc1a36be5f946b37610ec8c516871f0d3_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/pbevan11___eq-bench/default/0.0.0/9ce8e5ffc1a36be5f946b37610ec8c516871f0d3/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430675215856 on /public/home/zouyifei001/.cache/huggingface/datasets/pbevan11___eq-bench/default/0.0.0/9ce8e5ffc1a36be5f946b37610ec8c516871f0d3_builder.lock
DEBUG:filelock:Lock 140430675215856 released on /public/home/zouyifei001/.cache/huggingface/datasets/pbevan11___eq-bench/default/0.0.0/9ce8e5ffc1a36be5f946b37610ec8c516871f0d3_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
INFO:lm_eval.evaluator:eq_bench: Using gen_kwargs: {'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 80, 'until': ['\n\n']}
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of eq_bench from None to 0
INFO:lm_eval.api.task:Building contexts for eq_bench on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 97473.95it/s]
DEBUG:lm_eval.evaluator:Task: eq_bench; number of requests on this rank: 100
INFO:lm_eval.evaluator:Running generate_until requests
Running generate_until requests:   0%|          | 0/100 [00:00<?, ?it/s]Running generate_until requests:   1%|          | 1/100 [00:08<13:38,  8.27s/it]Running generate_until requests:   2%|▏         | 2/100 [00:15<12:28,  7.64s/it]Running generate_until requests:   3%|▎         | 3/100 [00:22<11:49,  7.31s/it]Running generate_until requests:   4%|▍         | 4/100 [00:29<11:40,  7.30s/it]Running generate_until requests:   5%|▌         | 5/100 [00:36<11:25,  7.21s/it]Running generate_until requests:   6%|▌         | 6/100 [00:43<11:08,  7.11s/it]Running generate_until requests:   7%|▋         | 7/100 [00:50<10:43,  6.92s/it]Running generate_until requests:   8%|▊         | 8/100 [00:56<10:29,  6.84s/it]Running generate_until requests:   9%|▉         | 9/100 [01:04<10:36,  6.99s/it]Running generate_until requests:  10%|█         | 10/100 [01:10<10:16,  6.85s/it]Running generate_until requests:  11%|█         | 11/100 [01:17<10:04,  6.79s/it]Running generate_until requests:  12%|█▏        | 12/100 [01:24<10:17,  7.02s/it]Running generate_until requests:  13%|█▎        | 13/100 [01:31<10:04,  6.95s/it]Running generate_until requests:  14%|█▍        | 14/100 [01:38<09:50,  6.86s/it]Running generate_until requests:  15%|█▌        | 15/100 [01:45<09:41,  6.84s/it]Running generate_until requests:  16%|█▌        | 16/100 [01:51<09:26,  6.74s/it]Running generate_until requests:  17%|█▋        | 17/100 [01:58<09:11,  6.65s/it]Running generate_until requests:  18%|█▊        | 18/100 [02:04<09:00,  6.59s/it]Running generate_until requests:  19%|█▉        | 19/100 [02:11<08:52,  6.58s/it]Running generate_until requests:  20%|██        | 20/100 [02:17<08:42,  6.53s/it]Running generate_until requests:  21%|██        | 21/100 [02:24<08:37,  6.55s/it]Running generate_until requests:  22%|██▏       | 22/100 [02:30<08:36,  6.62s/it]Running generate_until requests:  23%|██▎       | 23/100 [02:37<08:30,  6.63s/it]Running generate_until requests:  24%|██▍       | 24/100 [02:44<08:21,  6.60s/it]Running generate_until requests:  25%|██▌       | 25/100 [02:51<08:24,  6.73s/it]Running generate_until requests:  26%|██▌       | 26/100 [02:57<08:06,  6.58s/it]Running generate_until requests:  27%|██▋       | 27/100 [03:03<07:52,  6.47s/it]Running generate_until requests:  28%|██▊       | 28/100 [03:10<07:48,  6.50s/it]Running generate_until requests:  29%|██▉       | 29/100 [03:16<07:42,  6.52s/it]Running generate_until requests:  30%|███       | 30/100 [03:23<07:34,  6.50s/it]Running generate_until requests:  31%|███       | 31/100 [03:29<07:20,  6.39s/it]Running generate_until requests:  32%|███▏      | 32/100 [03:36<07:25,  6.55s/it]Running generate_until requests:  33%|███▎      | 33/100 [03:42<07:11,  6.44s/it]Running generate_until requests:  34%|███▍      | 34/100 [03:48<07:00,  6.37s/it]Running generate_until requests:  35%|███▌      | 35/100 [03:54<06:50,  6.31s/it]Running generate_until requests:  36%|███▌      | 36/100 [04:00<06:38,  6.23s/it]Running generate_until requests:  37%|███▋      | 37/100 [04:07<06:43,  6.41s/it]Running generate_until requests:  38%|███▊      | 38/100 [04:13<06:29,  6.29s/it]Running generate_until requests:  39%|███▉      | 39/100 [04:19<06:21,  6.26s/it]Running generate_until requests:  40%|████      | 40/100 [04:25<06:09,  6.15s/it]Running generate_until requests:  41%|████      | 41/100 [04:32<06:11,  6.30s/it]Running generate_until requests:  42%|████▏     | 42/100 [04:38<06:05,  6.31s/it]Running generate_until requests:  43%|████▎     | 43/100 [04:44<05:51,  6.17s/it]Running generate_until requests:  44%|████▍     | 44/100 [04:50<05:39,  6.07s/it]Running generate_until requests:  45%|████▌     | 45/100 [04:56<05:28,  5.98s/it]Running generate_until requests:  46%|████▌     | 46/100 [05:02<05:27,  6.07s/it]Running generate_until requests:  47%|████▋     | 47/100 [05:08<05:28,  6.20s/it]Running generate_until requests:  48%|████▊     | 48/100 [05:14<05:15,  6.08s/it]Running generate_until requests:  49%|████▉     | 49/100 [05:20<05:07,  6.03s/it]Running generate_until requests:  50%|█████     | 50/100 [05:26<05:05,  6.10s/it]Running generate_until requests:  51%|█████     | 51/100 [05:32<04:56,  6.05s/it]Running generate_until requests:  52%|█████▏    | 52/100 [05:38<04:47,  6.00s/it]Running generate_until requests:  53%|█████▎    | 53/100 [05:44<04:36,  5.87s/it]Running generate_until requests:  54%|█████▍    | 54/100 [05:50<04:32,  5.93s/it]Running generate_until requests:  55%|█████▌    | 55/100 [05:55<04:20,  5.78s/it]Running generate_until requests:  56%|█████▌    | 56/100 [06:01<04:11,  5.70s/it]Running generate_until requests:  57%|█████▋    | 57/100 [06:07<04:07,  5.77s/it]Running generate_until requests:  58%|█████▊    | 58/100 [06:13<04:02,  5.78s/it]Running generate_until requests:  59%|█████▉    | 59/100 [06:18<03:56,  5.77s/it]Running generate_until requests:  60%|██████    | 60/100 [06:24<03:51,  5.78s/it]Running generate_until requests:  61%|██████    | 61/100 [06:30<03:46,  5.80s/it]Running generate_until requests:  62%|██████▏   | 62/100 [06:36<03:42,  5.85s/it]Running generate_until requests:  63%|██████▎   | 63/100 [06:41<03:31,  5.72s/it]Running generate_until requests:  64%|██████▍   | 64/100 [06:47<03:24,  5.67s/it]Running generate_until requests:  65%|██████▌   | 65/100 [06:53<03:19,  5.69s/it]Running generate_until requests:  66%|██████▌   | 66/100 [06:55<02:37,  4.62s/it]Running generate_until requests:  67%|██████▋   | 67/100 [07:00<02:41,  4.89s/it]Running generate_until requests:  68%|██████▊   | 68/100 [07:06<02:47,  5.24s/it]Running generate_until requests:  69%|██████▉   | 69/100 [07:12<02:47,  5.41s/it]Running generate_until requests:  70%|███████   | 70/100 [07:18<02:42,  5.42s/it]Running generate_until requests:  71%|███████   | 71/100 [07:20<02:07,  4.39s/it]Running generate_until requests:  72%|███████▏  | 72/100 [07:26<02:16,  4.86s/it]Running generate_until requests:  73%|███████▎  | 73/100 [07:28<01:48,  4.01s/it]Running generate_until requests:  74%|███████▍  | 74/100 [07:33<01:54,  4.39s/it]Running generate_until requests:  75%|███████▌  | 75/100 [07:38<01:55,  4.61s/it]Running generate_until requests:  76%|███████▌  | 76/100 [07:43<01:56,  4.86s/it]Running generate_until requests:  77%|███████▋  | 77/100 [07:49<01:59,  5.18s/it]Running generate_until requests:  78%|███████▊  | 78/100 [07:55<01:57,  5.33s/it]Running generate_until requests:  79%|███████▉  | 79/100 [08:01<01:53,  5.39s/it]Running generate_until requests:  80%|████████  | 80/100 [08:06<01:47,  5.40s/it]Running generate_until requests:  81%|████████  | 81/100 [08:11<01:42,  5.41s/it]Running generate_until requests:  82%|████████▏ | 82/100 [08:17<01:37,  5.41s/it]Running generate_until requests:  83%|████████▎ | 83/100 [08:22<01:31,  5.37s/it]Running generate_until requests:  84%|████████▍ | 84/100 [08:27<01:25,  5.37s/it]Running generate_until requests:  85%|████████▌ | 85/100 [08:33<01:21,  5.45s/it]Running generate_until requests:  86%|████████▌ | 86/100 [08:38<01:16,  5.45s/it]Running generate_until requests:  87%|████████▋ | 87/100 [08:40<00:56,  4.38s/it]Running generate_until requests:  88%|████████▊ | 88/100 [08:46<00:57,  4.80s/it]Running generate_until requests:  89%|████████▉ | 89/100 [08:52<00:55,  5.05s/it]Running generate_until requests:  90%|█████████ | 90/100 [08:58<00:52,  5.27s/it]Running generate_until requests:  91%|█████████ | 91/100 [09:03<00:48,  5.33s/it]Running generate_until requests:  92%|█████████▏| 92/100 [09:08<00:42,  5.35s/it]Running generate_until requests:  93%|█████████▎| 93/100 [09:14<00:36,  5.27s/it]Running generate_until requests:  94%|█████████▍| 94/100 [09:19<00:31,  5.28s/it]Running generate_until requests:  95%|█████████▌| 95/100 [09:24<00:26,  5.21s/it]Running generate_until requests:  96%|█████████▌| 96/100 [09:26<00:16,  4.17s/it]Running generate_until requests:  97%|█████████▋| 97/100 [09:28<00:10,  3.48s/it]Running generate_until requests:  98%|█████████▊| 98/100 [09:33<00:07,  3.98s/it]Running generate_until requests:  99%|█████████▉| 99/100 [09:38<00:04,  4.35s/it]Running generate_until requests: 100%|██████████| 100/100 [09:43<00:00,  4.56s/it]Running generate_until requests: 100%|██████████| 100/100 [09:43<00:00,  5.83s/it]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:7'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:7'}
full model:
{'eq_bench': {'alias': 'eq_bench', 'eqbench,none': -9.075457665929516, 'eqbench_stderr,none': 3.722206958756126, 'percent_parseable,none': 94.0, 'percent_parseable_stderr,none': 2.3868325657594203}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.6639018561214101
0.48429197946127234
0.9515491395508957
0.5799692129526803
0.8892832964569847
0.5583880670373075
0.6815933931575056
0.8296184325732159
0.8572432652494972
0.7515568516065031
0.7498285715344476
0.6640770908835784
0.7344737024966144
0.8863376660708159
0.7840365418395101
0.7895254515113318
0.915557892351788
0.8364869594903738
0.8262221986876632
0.8424210311799578
0.9059689119946415
0.938938460185247
0.9139805997979817
0.8791150946846779
0.9604433557463424
0.36429086085480555
0.6224935475213342
0.9367462541020114
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[2, 3, 7, 0, 6, 1, 5, 4]
tensor([2, 3, 7, 0, 6, 1, 5, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 5, 2, 1, 6, 0, 3, 7]
tensor([4, 5, 2, 1, 6, 0, 3, 7], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 3, 4, 0, 7, 1, 2, 6]
tensor([5, 3, 4, 0, 7, 1, 2, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 6, 4, 0, 3, 1, 2, 7]
tensor([5, 6, 4, 0, 3, 1, 2, 7], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 3, 0, 1, 2, 2, 3]
tensor([0, 1, 3, 0, 1, 2, 2, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[2, 3, 0, 0, 1, 1, 2, 3]
tensor([2, 3, 0, 0, 1, 1, 2, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[2, 0, 1, 0, 3, 1, 2, 3]
tensor([2, 0, 1, 0, 3, 1, 2, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[2, 0, 1, 0, 2, 1, 3, 3]
tensor([2, 0, 1, 0, 2, 1, 3, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 0, 1.0, 1, 1.0, 1.0]
tensor([0, 1, 1, 0, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 0, 1.0, 1, 1.0, 1.0]
tensor([0, 1, 1, 0, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[0, 1, 1.0, 0, 1.0, 1, 1.0, 1.0]
tensor([0, 1, 1, 0, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
Normal merging for layer 1
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
tensor([7])
tensor(7)
done!
Normal merging for layer 2
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([7])
tensor(7)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 3 to 4
done!
Normal merging for layer 5
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([1])
tensor(1)
tensor([7])
tensor(7)
done!
Cross-layer merge completed for layers 6 to 15
done!
Normal merging for layer 16
tensor([0, 3])
tensor(0)
tensor([1, 4])
tensor(1)
tensor([5, 6])
tensor(5)
tensor([2, 7])
tensor(2)
done!
Cross-layer merge completed for layers 17 to 18
done!
Normal merging for layer 19
tensor([2, 3])
tensor(2)
tensor([4, 5])
tensor(4)
tensor([0, 6])
tensor(0)
tensor([1, 7])
tensor(1)
done!
Normal merging for layer 20
tensor([1, 3])
tensor(1)
tensor([2, 5])
tensor(2)
tensor([0, 6])
tensor(0)
tensor([4, 7])
tensor(4)
done!
Normal merging for layer 21
tensor([1, 3])
tensor(1)
tensor([2, 5])
tensor(2)
tensor([0, 4])
tensor(0)
tensor([6, 7])
tensor(6)
done!
Cross-layer merge completed for layers 22 to 24
done!
Normal merging for layer 25
tensor([0, 3])
tensor(0)
tensor([1, 2, 4, 5, 6, 7])
tensor(1)
done!
Cross-layer merge completed for layers 26 to 29
done!
Normal merging for layer 30
tensor([0, 3])
tensor(0)
tensor([1, 2, 4, 5, 6, 7])
tensor(1)
done!
Normal merging for layer 31
tensor([0, 3])
tensor(0)
tensor([1, 2, 4, 5, 6, 7])
tensor(1)
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 10 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.7017 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 9 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

30
cuda:7
coqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:56<00:56, 56.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 31.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 35.54s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa HTTP/1.1" 200 857
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/EleutherAI/coqa/EleutherAI/coqa.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa HTTP/1.1" 200 857
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/coqa/resolve/82e11af842af6c1396f5e9a5c7de260107c50cf1/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa/tree/82e11af842af6c1396f5e9a5c7de260107c50cf1/data?recursive=False&expand=False HTTP/1.1" 404 79
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa/tree/82e11af842af6c1396f5e9a5c7de260107c50cf1/data?recursive=False&expand=False HTTP/1.1" 404 79
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/coqa/resolve/82e11af842af6c1396f5e9a5c7de260107c50cf1/dataset_infos.json HTTP/1.1" 200 0
DEBUG:filelock:Attempting to acquire lock 140431339492496 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___coqa_default_0.0.0_82e11af842af6c1396f5e9a5c7de260107c50cf1.lock
DEBUG:filelock:Lock 140431339492496 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___coqa_default_0.0.0_82e11af842af6c1396f5e9a5c7de260107c50cf1.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1/dataset_info.json
DEBUG:filelock:Attempting to release lock 140431339492496 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___coqa_default_0.0.0_82e11af842af6c1396f5e9a5c7de260107c50cf1.lock
DEBUG:filelock:Lock 140431339492496 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___coqa_default_0.0.0_82e11af842af6c1396f5e9a5c7de260107c50cf1.lock
DEBUG:filelock:Attempting to acquire lock 140430961286304 on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1_builder.lock
DEBUG:filelock:Lock 140430961286304 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430961286304 on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1_builder.lock
DEBUG:filelock:Lock 140430961286304 released on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
DEBUG:lm_eval.api.task:doc_to_target returned a list. Assuming multiple targets.
INFO:lm_eval.evaluator:coqa: Using gen_kwargs: {'until': ['\nQ:']}
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of coqa from None to 0
INFO:lm_eval.api.task:Building contexts for coqa on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 76636.29it/s]
DEBUG:lm_eval.evaluator:Task: coqa; number of requests on this rank: 100
INFO:lm_eval.evaluator:Running generate_until requests
Running generate_until requests:   0%|          | 0/100 [00:00<?, ?it/s]Running generate_until requests:   1%|          | 1/100 [00:05<09:47,  5.93s/it]Running generate_until requests:   2%|▏         | 2/100 [00:11<09:01,  5.52s/it]Running generate_until requests:   3%|▎         | 3/100 [00:17<09:39,  5.98s/it]Running generate_until requests:   4%|▍         | 4/100 [00:22<09:00,  5.63s/it]Running generate_until requests:   5%|▌         | 5/100 [00:27<08:38,  5.46s/it]Running generate_until requests:   6%|▌         | 6/100 [00:32<08:13,  5.25s/it]Running generate_until requests:   7%|▋         | 7/100 [00:38<08:27,  5.46s/it]Running generate_until requests:   8%|▊         | 8/100 [00:43<08:02,  5.25s/it]Running generate_until requests:   9%|▉         | 9/100 [00:48<07:55,  5.23s/it]Running generate_until requests:  10%|█         | 10/100 [00:54<08:03,  5.38s/it]Running generate_until requests:  11%|█         | 11/100 [01:00<08:09,  5.50s/it]Running generate_until requests:  12%|█▏        | 12/100 [01:07<08:44,  5.96s/it]Running generate_until requests:  13%|█▎        | 13/100 [01:11<08:06,  5.59s/it]Running generate_until requests:  14%|█▍        | 14/100 [01:16<07:34,  5.28s/it]Running generate_until requests:  15%|█▌        | 15/100 [01:21<07:17,  5.14s/it]Running generate_until requests:  16%|█▌        | 16/100 [01:25<06:57,  4.97s/it]Running generate_until requests:  17%|█▋        | 17/100 [01:30<06:48,  4.92s/it]Running generate_until requests:  18%|█▊        | 18/100 [01:35<06:41,  4.90s/it]Running generate_until requests:  19%|█▉        | 19/100 [01:40<06:38,  4.92s/it]Running generate_until requests:  20%|██        | 20/100 [01:45<06:32,  4.90s/it]Running generate_until requests:  21%|██        | 21/100 [01:50<06:27,  4.90s/it]Running generate_until requests:  22%|██▏       | 22/100 [01:54<06:18,  4.85s/it]Running generate_until requests:  23%|██▎       | 23/100 [02:00<06:38,  5.17s/it]Running generate_until requests:  24%|██▍       | 24/100 [02:06<06:50,  5.40s/it]Running generate_until requests:  25%|██▌       | 25/100 [02:11<06:24,  5.12s/it]Running generate_until requests:  26%|██▌       | 26/100 [02:16<06:14,  5.07s/it]Running generate_until requests:  27%|██▋       | 27/100 [02:21<06:04,  5.00s/it]Running generate_until requests:  28%|██▊       | 28/100 [02:25<05:53,  4.92s/it]Running generate_until requests:  29%|██▉       | 29/100 [02:30<05:45,  4.86s/it]Running generate_until requests:  30%|███       | 30/100 [02:35<05:41,  4.88s/it]Running generate_until requests:  31%|███       | 31/100 [02:39<05:23,  4.69s/it]Running generate_until requests:  32%|███▏      | 32/100 [02:44<05:26,  4.81s/it]Running generate_until requests:  33%|███▎      | 33/100 [02:49<05:23,  4.83s/it]Running generate_until requests:  34%|███▍      | 34/100 [02:54<05:12,  4.74s/it]Running generate_until requests:  35%|███▌      | 35/100 [02:58<04:55,  4.55s/it]Running generate_until requests:  36%|███▌      | 36/100 [03:04<05:14,  4.92s/it]Running generate_until requests:  37%|███▋      | 37/100 [03:08<04:56,  4.71s/it]Running generate_until requests:  38%|███▊      | 38/100 [03:12<04:45,  4.60s/it]Running generate_until requests:  39%|███▉      | 39/100 [03:18<05:09,  5.08s/it]Running generate_until requests:  40%|████      | 40/100 [03:24<05:13,  5.22s/it]Running generate_until requests:  41%|████      | 41/100 [03:29<05:04,  5.16s/it]Running generate_until requests:  42%|████▏     | 42/100 [03:35<05:10,  5.35s/it]Running generate_until requests:  43%|████▎     | 43/100 [03:39<04:49,  5.07s/it]Running generate_until requests:  44%|████▍     | 44/100 [03:44<04:40,  5.01s/it]Running generate_until requests:  45%|████▌     | 45/100 [03:49<04:27,  4.87s/it]Running generate_until requests:  46%|████▌     | 46/100 [03:53<04:08,  4.61s/it]Running generate_until requests:  47%|████▋     | 47/100 [03:57<03:57,  4.48s/it]Running generate_until requests:  48%|████▊     | 48/100 [04:01<03:56,  4.55s/it]Running generate_until requests:  49%|████▉     | 49/100 [04:07<04:01,  4.73s/it]Running generate_until requests:  50%|█████     | 50/100 [04:11<03:44,  4.50s/it]Running generate_until requests:  51%|█████     | 51/100 [04:16<03:51,  4.72s/it]Running generate_until requests:  52%|█████▏    | 52/100 [04:20<03:33,  4.45s/it]Running generate_until requests:  53%|█████▎    | 53/100 [04:24<03:32,  4.52s/it]Running generate_until requests:  54%|█████▍    | 54/100 [04:28<03:18,  4.31s/it]Running generate_until requests:  55%|█████▌    | 55/100 [04:32<03:12,  4.29s/it]Running generate_until requests:  56%|█████▌    | 56/100 [04:37<03:16,  4.47s/it]Running generate_until requests:  57%|█████▋    | 57/100 [04:42<03:11,  4.45s/it]Running generate_until requests:  58%|█████▊    | 58/100 [04:45<02:59,  4.27s/it]Running generate_until requests:  59%|█████▉    | 59/100 [04:51<03:07,  4.57s/it]Running generate_until requests:  60%|██████    | 60/100 [04:55<02:55,  4.38s/it]Running generate_until requests:  61%|██████    | 61/100 [05:00<02:56,  4.54s/it]Running generate_until requests:  62%|██████▏   | 62/100 [05:04<02:53,  4.56s/it]Running generate_until requests:  63%|██████▎   | 63/100 [05:08<02:38,  4.27s/it]Running generate_until requests:  64%|██████▍   | 64/100 [05:11<02:27,  4.09s/it]Running generate_until requests:  65%|██████▌   | 65/100 [05:15<02:18,  3.95s/it]Running generate_until requests:  66%|██████▌   | 66/100 [05:19<02:11,  3.85s/it]Running generate_until requests:  67%|██████▋   | 67/100 [05:22<02:04,  3.77s/it]Running generate_until requests:  68%|██████▊   | 68/100 [05:27<02:05,  3.92s/it]Running generate_until requests:  69%|██████▉   | 69/100 [05:32<02:19,  4.49s/it]Running generate_until requests:  70%|███████   | 70/100 [05:36<02:11,  4.37s/it]Running generate_until requests:  71%|███████   | 71/100 [05:45<02:44,  5.67s/it]Running generate_until requests:  72%|███████▏  | 72/100 [05:49<02:23,  5.14s/it]Running generate_until requests:  73%|███████▎  | 73/100 [05:53<02:10,  4.83s/it]Running generate_until requests:  74%|███████▍  | 74/100 [05:57<02:01,  4.66s/it]Running generate_until requests:  75%|███████▌  | 75/100 [06:01<01:51,  4.45s/it]Running generate_until requests:  76%|███████▌  | 76/100 [06:05<01:42,  4.27s/it]Running generate_until requests:  77%|███████▋  | 77/100 [06:10<01:43,  4.51s/it]Running generate_until requests:  78%|███████▊  | 78/100 [06:14<01:36,  4.39s/it]Running generate_until requests:  79%|███████▉  | 79/100 [06:18<01:26,  4.14s/it]Running generate_until requests:  80%|████████  | 80/100 [06:22<01:21,  4.09s/it]Running generate_until requests:  81%|████████  | 81/100 [06:28<01:30,  4.74s/it]Running generate_until requests:  82%|████████▏ | 82/100 [06:32<01:19,  4.44s/it]Running generate_until requests:  83%|████████▎ | 83/100 [06:36<01:13,  4.35s/it]Running generate_until requests:  84%|████████▍ | 84/100 [06:40<01:05,  4.08s/it]Running generate_until requests:  85%|████████▌ | 85/100 [06:43<00:58,  3.87s/it]Running generate_until requests:  86%|████████▌ | 86/100 [06:47<00:53,  3.80s/it]Running generate_until requests:  87%|████████▋ | 87/100 [06:51<00:52,  4.03s/it]Running generate_until requests:  88%|████████▊ | 88/100 [06:55<00:46,  3.91s/it]Running generate_until requests:  89%|████████▉ | 89/100 [06:58<00:40,  3.68s/it]Running generate_until requests:  90%|█████████ | 90/100 [07:01<00:34,  3.47s/it]Running generate_until requests:  91%|█████████ | 91/100 [07:04<00:29,  3.27s/it]Running generate_until requests:  92%|█████████▏| 92/100 [07:07<00:25,  3.16s/it]Running generate_until requests:  93%|█████████▎| 93/100 [07:10<00:21,  3.12s/it]Running generate_until requests:  94%|█████████▍| 94/100 [07:13<00:18,  3.13s/it]Running generate_until requests:  95%|█████████▌| 95/100 [07:16<00:16,  3.21s/it]Running generate_until requests:  96%|█████████▌| 96/100 [07:19<00:12,  3.23s/it]Running generate_until requests:  97%|█████████▋| 97/100 [07:22<00:09,  3.07s/it]Running generate_until requests:  98%|█████████▊| 98/100 [07:25<00:05,  2.92s/it]Running generate_until requests:  99%|█████████▉| 99/100 [07:28<00:02,  2.90s/it]Running generate_until requests: 100%|██████████| 100/100 [07:31<00:00,  2.93s/it]Running generate_until requests: 100%|██████████| 100/100 [07:31<00:00,  4.51s/it]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:0'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}
full model:
{'coqa': {'alias': 'coqa', 'em,none': 0.595, 'em_stderr,none': 0.044774970461162564, 'f1,none': 0.7211574141733987, 'f1_stderr,none': 0.037128235455690536}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.6057853926542468
0.4195568875297668
0.5244744113321889
0.5202703028806769
0.6150870974034927
0.5299634576457063
0.9336763524510373
0.23649940737178063
0.388911200696845
0.6478041116722705
0.5517233675449297
0.6723258763091353
0.7175526480521238
0.8411089149883405
0.7404554224148189
0.26376935916880817
0.9373006475493478
0.5360566853939598
0.38729358133282565
0.4541602442018795
0.8623573205888978
0.7318340566806717
0.6643209906079897
0.8122565195147101
0.4707270481319977
0.9785001455445378
0.17075087907531752
0.489625917805058
0.7595051272431785
0.6057853926542468
0.4195568875297668
0.5244744113321889
0.5202703028806769
0.6150870974034927
0.5299634576457063
0.9336763524510373
0.23649940737178063
0.388911200696845
0.6478041116722705
0.5517233675449297
0.6723258763091353
0.7175526480521238
0.8411089149883405
0.7404554224148189
0.26376935916880817
0.9373006475493478
0.5360566853939598
0.38729358133282565
0.4541602442018795
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[5, 4, 3, 2, 0, 1, 7, 6]
tensor([5, 4, 3, 2, 0, 1, 7, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 3, 4, 0, 2, 1, 7, 6]
tensor([5, 3, 4, 0, 2, 1, 7, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 1, 7, 0, 6, 2, 3, 4]
tensor([5, 1, 7, 0, 6, 2, 3, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 3, 6, 0, 5, 2, 4, 1]
tensor([7, 3, 6, 0, 5, 2, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 5, 7, 2, 4, 0, 3, 1]
tensor([6, 5, 7, 2, 4, 0, 3, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 5, 0, 0, 1, 2, 1, 3]
tensor([4, 5, 0, 0, 1, 2, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1, 2, 2, 0, 3, 3]
tensor([0, 1, 1, 2, 2, 0, 3, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([7])
tensor(7)
tensor([6])
tensor(6)
done!
Normal merging for layer 2
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
done!
Normal merging for layer 4
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Cross-layer merge completed for layers 5 to 8
done!
Normal merging for layer 9
tensor([2, 3])
tensor(2)
tensor([4, 6])
tensor(4)
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([1])
tensor(1)
done!
Cross-layer merge completed for layers 10 to 22
done!
Normal merging for layer 23
tensor([0, 5])
tensor(0)
tensor([1, 2])
tensor(1)
tensor([3, 4])
tensor(3)
tensor([6, 7])
tensor(6)
done!
Cross-layer merge completed for layers 24 to 31
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 9 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.3238 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 8 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

199
cuda:0
cola
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:55<00:55, 55.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:12<00:00, 32.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:12<00:00, 36.16s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: cola] metric mcc is defined, but aggregation is not. using default aggregation=matthews_corrcoef
WARNING:lm_eval.api.task:[Task: cola] metric mcc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140437043476720 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_cola_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140437043476720 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_cola_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140437043476720 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_cola_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140437043476720 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_cola_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140430970400512 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140430970400512 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430970400512 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140430970400512 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of cola from None to 0
INFO:lm_eval.api.task:Building contexts for cola on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 3258.29it/s]
DEBUG:lm_eval.evaluator:Task: cola; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:01<03:59,  1.20s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:01<01:44,  1.89it/s]Running loglikelihood requests:   2%|▎         | 5/200 [00:02<01:15,  2.57it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:02<01:08,  2.83it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:03<01:00,  3.18it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:03<00:55,  3.43it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:04<00:51,  3.61it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:04<00:49,  3.74it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:05<00:47,  3.84it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:05<00:46,  3.92it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:06<00:45,  3.97it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:06<00:44,  4.00it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:07<00:43,  4.03it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:07<00:42,  4.06it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:08<00:41,  4.08it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:08<00:41,  4.10it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:09<00:40,  4.12it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:09<00:39,  4.14it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:10<00:39,  4.15it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:10<00:38,  4.17it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:11<00:38,  4.10it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:11<00:38,  4.11it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:12<00:37,  4.14it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:12<00:36,  4.15it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:13<00:36,  4.16it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:13<00:36,  4.10it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:14<00:35,  4.11it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:14<00:35,  4.11it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:15<00:34,  4.12it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:15<00:34,  4.13it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:16<00:33,  4.15it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:16<00:32,  4.16it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:17<00:32,  4.17it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:17<00:31,  4.18it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:17<00:31,  4.19it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:18<00:30,  4.20it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:18<00:30,  4.20it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:19<00:29,  4.20it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:19<00:29,  4.21it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:20<00:28,  4.21it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:20<00:28,  4.21it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:21<00:27,  4.22it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:21<00:27,  4.23it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:22<00:26,  4.25it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:22<00:26,  4.26it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:23<00:25,  4.26it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:23<00:25,  4.26it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:24<00:24,  4.27it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:24<00:24,  4.26it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:25<00:23,  4.28it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:25<00:23,  4.30it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:25<00:22,  4.31it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:26<00:22,  4.31it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:26<00:21,  4.31it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:27<00:21,  4.31it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:27<00:20,  4.31it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:28<00:20,  4.26it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:28<00:19,  4.32it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:29<00:18,  4.37it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:29<00:18,  4.41it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:30<00:17,  4.44it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:30<00:17,  4.46it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:30<00:16,  4.47it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [00:31<00:16,  4.48it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [00:31<00:15,  4.49it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [00:32<00:15,  4.52it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [00:32<00:14,  4.53it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [00:33<00:14,  4.54it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [00:33<00:13,  4.54it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [00:34<00:13,  4.55it/s]Running loglikelihood requests:  70%|███████   | 141/200 [00:34<00:12,  4.56it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [00:34<00:12,  4.57it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [00:35<00:12,  4.58it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [00:35<00:11,  4.59it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [00:36<00:11,  4.59it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [00:36<00:10,  4.60it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [00:37<00:10,  4.61it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [00:37<00:09,  4.61it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [00:37<00:09,  4.63it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [00:38<00:08,  4.65it/s]Running loglikelihood requests:  80%|████████  | 161/200 [00:38<00:08,  4.66it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [00:39<00:07,  4.66it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [00:39<00:07,  4.66it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [00:40<00:07,  4.66it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [00:40<00:06,  4.67it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [00:40<00:06,  4.69it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [00:41<00:05,  4.71it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [00:41<00:05,  4.71it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [00:42<00:04,  4.73it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [00:42<00:04,  4.73it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [00:43<00:04,  4.73it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [00:43<00:03,  4.74it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [00:43<00:03,  4.74it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [00:44<00:02,  4.75it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [00:44<00:02,  4.77it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [00:45<00:01,  4.78it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [00:45<00:01,  4.81it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [00:45<00:01,  4.82it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [00:46<00:00,  4.82it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [00:46<00:00,  4.84it/s]Running loglikelihood requests: 100%|██████████| 200/200 [00:46<00:00,  4.28it/s]
bootstrapping for stddev (sequential): matthews_corrcoef
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<01:33,  1.06it/s]  2%|▏         | 2/100 [00:01<01:31,  1.08it/s]  3%|▎         | 3/100 [00:02<01:30,  1.08it/s]  4%|▍         | 4/100 [00:03<01:28,  1.08it/s]  5%|▌         | 5/100 [00:04<01:27,  1.09it/s]  6%|▌         | 6/100 [00:05<01:26,  1.09it/s]  7%|▋         | 7/100 [00:06<01:25,  1.09it/s]  8%|▊         | 8/100 [00:07<01:24,  1.09it/s]  9%|▉         | 9/100 [00:08<01:23,  1.09it/s] 10%|█         | 10/100 [00:09<01:22,  1.09it/s] 11%|█         | 11/100 [00:10<01:22,  1.08it/s] 12%|█▏        | 12/100 [00:11<01:21,  1.08it/s] 13%|█▎        | 13/100 [00:11<01:20,  1.08it/s] 14%|█▍        | 14/100 [00:12<01:19,  1.09it/s] 15%|█▌        | 15/100 [00:13<01:18,  1.09it/s] 16%|█▌        | 16/100 [00:14<01:17,  1.09it/s] 17%|█▋        | 17/100 [00:15<01:16,  1.09it/s] 18%|█▊        | 18/100 [00:16<01:15,  1.09it/s] 19%|█▉        | 19/100 [00:17<01:14,  1.09it/s] 20%|██        | 20/100 [00:18<01:14,  1.08it/s] 21%|██        | 21/100 [00:19<01:13,  1.08it/s] 22%|██▏       | 22/100 [00:20<01:12,  1.08it/s] 23%|██▎       | 23/100 [00:21<01:11,  1.08it/s] 24%|██▍       | 24/100 [00:22<01:10,  1.07it/s] 25%|██▌       | 25/100 [00:23<01:10,  1.07it/s] 26%|██▌       | 26/100 [00:24<01:08,  1.07it/s] 27%|██▋       | 27/100 [00:24<01:07,  1.08it/s] 28%|██▊       | 28/100 [00:25<01:07,  1.07it/s] 29%|██▉       | 29/100 [00:26<01:05,  1.08it/s] 30%|███       | 30/100 [00:27<01:05,  1.07it/s] 31%|███       | 31/100 [00:28<01:04,  1.08it/s] 32%|███▏      | 32/100 [00:29<01:02,  1.08it/s] 33%|███▎      | 33/100 [00:30<01:01,  1.09it/s] 34%|███▍      | 34/100 [00:31<01:00,  1.09it/s] 35%|███▌      | 35/100 [00:32<00:59,  1.09it/s] 36%|███▌      | 36/100 [00:33<00:58,  1.09it/s] 37%|███▋      | 37/100 [00:34<00:57,  1.09it/s] 38%|███▊      | 38/100 [00:35<00:56,  1.09it/s] 39%|███▉      | 39/100 [00:36<00:55,  1.09it/s] 40%|████      | 40/100 [00:36<00:55,  1.09it/s] 41%|████      | 41/100 [00:37<00:54,  1.09it/s] 42%|████▏     | 42/100 [00:38<00:53,  1.09it/s] 43%|████▎     | 43/100 [00:39<00:52,  1.09it/s] 44%|████▍     | 44/100 [00:40<00:51,  1.09it/s] 45%|████▌     | 45/100 [00:41<00:50,  1.09it/s] 46%|████▌     | 46/100 [00:42<00:50,  1.08it/s] 47%|████▋     | 47/100 [00:43<00:50,  1.06it/s] 48%|████▊     | 48/100 [00:44<00:48,  1.07it/s] 49%|████▉     | 49/100 [00:45<00:47,  1.07it/s] 50%|█████     | 50/100 [00:46<00:46,  1.08it/s] 51%|█████     | 51/100 [00:47<00:45,  1.08it/s] 52%|█████▏    | 52/100 [00:48<00:44,  1.08it/s] 53%|█████▎    | 53/100 [00:49<00:44,  1.06it/s] 54%|█████▍    | 54/100 [00:49<00:43,  1.07it/s] 55%|█████▌    | 55/100 [00:50<00:41,  1.07it/s] 56%|█████▌    | 56/100 [00:51<00:40,  1.08it/s] 57%|█████▋    | 57/100 [00:52<00:39,  1.08it/s] 58%|█████▊    | 58/100 [00:53<00:38,  1.08it/s] 59%|█████▉    | 59/100 [00:54<00:37,  1.08it/s] 60%|██████    | 60/100 [00:55<00:37,  1.08it/s] 61%|██████    | 61/100 [00:56<00:36,  1.08it/s] 62%|██████▏   | 62/100 [00:57<00:35,  1.08it/s] 63%|██████▎   | 63/100 [00:58<00:34,  1.07it/s] 64%|██████▍   | 64/100 [00:59<00:33,  1.08it/s] 65%|██████▌   | 65/100 [01:00<00:32,  1.08it/s] 66%|██████▌   | 66/100 [01:01<00:31,  1.08it/s] 67%|██████▋   | 67/100 [01:02<00:30,  1.08it/s] 68%|██████▊   | 68/100 [01:02<00:29,  1.08it/s] 69%|██████▉   | 69/100 [01:03<00:28,  1.08it/s] 70%|███████   | 70/100 [01:04<00:27,  1.09it/s] 71%|███████   | 71/100 [01:05<00:26,  1.09it/s] 72%|███████▏  | 72/100 [01:06<00:25,  1.09it/s] 73%|███████▎  | 73/100 [01:07<00:24,  1.09it/s] 74%|███████▍  | 74/100 [01:08<00:24,  1.07it/s] 75%|███████▌  | 75/100 [01:09<00:23,  1.08it/s] 76%|███████▌  | 76/100 [01:10<00:22,  1.08it/s] 77%|███████▋  | 77/100 [01:11<00:21,  1.08it/s] 78%|███████▊  | 78/100 [01:12<00:20,  1.08it/s] 79%|███████▉  | 79/100 [01:13<00:19,  1.08it/s] 80%|████████  | 80/100 [01:14<00:18,  1.08it/s] 81%|████████  | 81/100 [01:14<00:17,  1.08it/s] 82%|████████▏ | 82/100 [01:15<00:16,  1.08it/s] 83%|████████▎ | 83/100 [01:16<00:15,  1.08it/s] 84%|████████▍ | 84/100 [01:17<00:14,  1.08it/s] 85%|████████▌ | 85/100 [01:18<00:13,  1.08it/s] 86%|████████▌ | 86/100 [01:19<00:12,  1.08it/s] 87%|████████▋ | 87/100 [01:20<00:12,  1.08it/s] 88%|████████▊ | 88/100 [01:21<00:11,  1.08it/s] 89%|████████▉ | 89/100 [01:22<00:10,  1.08it/s] 90%|█████████ | 90/100 [01:23<00:09,  1.07it/s] 91%|█████████ | 91/100 [01:24<00:08,  1.07it/s] 92%|█████████▏| 92/100 [01:25<00:07,  1.07it/s] 93%|█████████▎| 93/100 [01:26<00:06,  1.08it/s] 94%|█████████▍| 94/100 [01:27<00:05,  1.08it/s] 95%|█████████▌| 95/100 [01:27<00:04,  1.08it/s] 96%|█████████▌| 96/100 [01:28<00:03,  1.08it/s] 97%|█████████▋| 97/100 [01:29<00:02,  1.08it/s] 98%|█████████▊| 98/100 [01:30<00:01,  1.08it/s] 99%|█████████▉| 99/100 [01:31<00:00,  1.08it/s]100%|██████████| 100/100 [01:32<00:00,  1.08it/s]100%|██████████| 100/100 [01:32<00:00,  1.08it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:1'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:1'}
full model:
{'cola': {'alias': 'cola', 'mcc,none': np.float64(-0.0234083603222329), 'mcc_stderr,none': 0.10027612985654218}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9827615088085355
0.9302188892609604
0.7011961870018854
0.5626926521241726
0.8487059565524276
0.8497526414658526
0.9054485200458864
0.7394951536076
0.6615723249956142
0.3790091735780837
0.7669438266452424
0.6500882643740805
0.6039759750877352
0.8611545876684488
0.9595791152744535
0.7624866897939796
0.8585278638499474
0.9654871578633694
0.8537985077125277
0.9276026122967783
0.938072418626947
0.8815459403167786
0.6241194219560614
0.901256729143793
0.7007049393842223
0.6541093728101413
0.9141945519271818
0.7667764647672246
0.8091089193013563
Total groups 69 exceeded the threshold, stopping comparison.
The group tensor is
[3, 2, 6, 7, 5, 1, 4, 0]
tensor([3, 2, 6, 7, 5, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 3, 6, 7, 5, 1, 4, 0]
tensor([2, 3, 6, 7, 5, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 3, 5, 7, 6, 1, 2, 0]
tensor([4, 3, 5, 7, 6, 1, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[2, 3, 0, 1, 2, 1, 3, 0]
tensor([2, 3, 0, 1, 2, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[1, 0, 1, 2, 3, 2, 3, 0]
tensor([1, 0, 1, 2, 3, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 2, 1, 2, 3, 1, 3, 0]
tensor([0, 2, 1, 2, 3, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[1, 0, 0, 1, 2, 3, 3, 2]
tensor([1, 0, 0, 1, 2, 3, 3, 2], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[3, 1, 0, 1, 2, 2, 3, 0]
tensor([3, 1, 0, 1, 2, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1.0, 1.0, 1, 1.0, 0]
tensor([0, 1, 1, 1, 1, 1, 1, 0], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
done!
Cross-layer merge completed for layers 2 to 5
done!
Normal merging for layer 6
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
tensor([3])
tensor(3)
done!
Cross-layer merge completed for layers 7 to 18
done!
Normal merging for layer 19
tensor([2, 7])
tensor(2)
tensor([3, 5])
tensor(3)
tensor([0, 4])
tensor(0)
tensor([1, 6])
tensor(1)
done!
Normal merging for layer 20
tensor([1, 7])
tensor(1)
tensor([0, 2])
tensor(0)
tensor([3, 5])
tensor(3)
tensor([4, 6])
tensor(4)
done!
Normal merging for layer 21
tensor([0, 7])
tensor(0)
tensor([2, 5])
tensor(2)
tensor([1, 3])
tensor(1)
tensor([4, 6])
tensor(4)
done!
Normal merging for layer 22
tensor([1, 2])
tensor(1)
tensor([0, 3])
tensor(0)
tensor([4, 7])
tensor(4)
tensor([5, 6])
tensor(5)
done!
Normal merging for layer 23
tensor([2, 7])
tensor(2)
tensor([1, 3])
tensor(1)
tensor([4, 5])
tensor(4)
tensor([0, 6])
tensor(0)
done!
Cross-layer merge completed for layers 24 to 27
done!
Normal merging for layer 28
tensor([0, 7])
tensor(0)
tensor([1, 2, 3, 4, 5, 6])
tensor(1)
done!
Cross-layer merge completed for layers 29 to 31
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 8 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.1348 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 7 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

127
cuda:1
mastermind_46_easy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:54<00:54, 54.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 32.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 35.51s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_46_mcq_random HTTP/1.1" 200 778
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/flair/mastermind_46_mcq_random/flair/mastermind_46_mcq_random.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_46_mcq_random HTTP/1.1" 200 786
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/flair/mastermind_46_mcq_random/resolve/544d077942975b1664c0bc4fd54df026050329a4/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_46_mcq_random/revision/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 786
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_46_mcq_random/tree/544d077942975b1664c0bc4fd54df026050329a4?recursive=False&expand=False HTTP/1.1" 200 290
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_46_mcq_random/tree/544d077942975b1664c0bc4fd54df026050329a4/data?recursive=False&expand=False HTTP/1.1" 200 361
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_46_mcq_random/revision/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 786
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/flair/mastermind_46_mcq_random/resolve/544d077942975b1664c0bc4fd54df026050329a4/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:filelock:Attempting to acquire lock 140430968517456 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_46_mcq_random_default_0.0.0_544d077942975b1664c0bc4fd54df026050329a4.lock
DEBUG:filelock:Lock 140430968517456 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_46_mcq_random_default_0.0.0_544d077942975b1664c0bc4fd54df026050329a4.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_46_mcq_random/default/0.0.0/544d077942975b1664c0bc4fd54df026050329a4/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430968517456 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_46_mcq_random_default_0.0.0_544d077942975b1664c0bc4fd54df026050329a4.lock
DEBUG:filelock:Lock 140430968517456 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_46_mcq_random_default_0.0.0_544d077942975b1664c0bc4fd54df026050329a4.lock
DEBUG:filelock:Attempting to acquire lock 140430940486640 on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_46_mcq_random/default/0.0.0/544d077942975b1664c0bc4fd54df026050329a4_builder.lock
DEBUG:filelock:Lock 140430940486640 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_46_mcq_random/default/0.0.0/544d077942975b1664c0bc4fd54df026050329a4_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_46_mcq_random/default/0.0.0/544d077942975b1664c0bc4fd54df026050329a4/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430940486640 on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_46_mcq_random/default/0.0.0/544d077942975b1664c0bc4fd54df026050329a4_builder.lock
DEBUG:filelock:Lock 140430940486640 released on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_46_mcq_random/default/0.0.0/544d077942975b1664c0bc4fd54df026050329a4_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mastermind_46_easy from None to 0
INFO:lm_eval.api.task:Building contexts for mastermind_46_easy on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s] 85%|████████▌ | 85/100 [00:02<00:00, 28.79it/s]100%|██████████| 100/100 [00:02<00:00, 33.73it/s]
DEBUG:lm_eval.evaluator:Task: mastermind_46_easy; number of requests on this rank: 400
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/400 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/400 [00:02<15:17,  2.30s/it]Running loglikelihood requests:   0%|          | 2/400 [00:03<12:20,  1.86s/it]Running loglikelihood requests:   1%|          | 3/400 [00:05<11:29,  1.74s/it]Running loglikelihood requests:   1%|          | 4/400 [00:06<10:57,  1.66s/it]Running loglikelihood requests:   1%|▏         | 5/400 [00:08<10:26,  1.59s/it]Running loglikelihood requests:   2%|▏         | 6/400 [00:09<10:08,  1.54s/it]Running loglikelihood requests:   2%|▏         | 7/400 [00:11<09:54,  1.51s/it]Running loglikelihood requests:   2%|▏         | 8/400 [00:12<09:45,  1.49s/it]Running loglikelihood requests:   2%|▏         | 9/400 [00:14<09:38,  1.48s/it]Running loglikelihood requests:   2%|▎         | 10/400 [00:15<09:32,  1.47s/it]Running loglikelihood requests:   3%|▎         | 11/400 [00:17<09:27,  1.46s/it]Running loglikelihood requests:   3%|▎         | 12/400 [00:18<09:24,  1.45s/it]Running loglikelihood requests:   3%|▎         | 13/400 [00:20<09:21,  1.45s/it]Running loglikelihood requests:   4%|▎         | 14/400 [00:21<09:18,  1.45s/it]Running loglikelihood requests:   4%|▍         | 15/400 [00:22<09:15,  1.44s/it]Running loglikelihood requests:   4%|▍         | 16/400 [00:24<09:13,  1.44s/it]Running loglikelihood requests:   4%|▍         | 17/400 [00:25<09:25,  1.48s/it]Running loglikelihood requests:   4%|▍         | 18/400 [00:27<09:30,  1.49s/it]Running loglikelihood requests:   5%|▍         | 19/400 [00:28<09:32,  1.50s/it]Running loglikelihood requests:   5%|▌         | 20/400 [00:30<09:33,  1.51s/it]Running loglikelihood requests:   5%|▌         | 21/400 [00:31<09:33,  1.51s/it]Running loglikelihood requests:   6%|▌         | 22/400 [00:33<09:34,  1.52s/it]Running loglikelihood requests:   6%|▌         | 23/400 [00:35<09:33,  1.52s/it]Running loglikelihood requests:   6%|▌         | 24/400 [00:36<09:30,  1.52s/it]Running loglikelihood requests:   6%|▋         | 25/400 [00:38<09:28,  1.52s/it]Running loglikelihood requests:   6%|▋         | 26/400 [00:39<09:28,  1.52s/it]Running loglikelihood requests:   7%|▋         | 27/400 [00:41<09:26,  1.52s/it]Running loglikelihood requests:   7%|▋         | 28/400 [00:42<09:25,  1.52s/it]Running loglikelihood requests:   7%|▋         | 29/400 [00:44<09:24,  1.52s/it]Running loglikelihood requests:   8%|▊         | 30/400 [00:45<09:26,  1.53s/it]Running loglikelihood requests:   8%|▊         | 31/400 [00:47<09:22,  1.52s/it]Running loglikelihood requests:   8%|▊         | 32/400 [00:48<09:18,  1.52s/it]Running loglikelihood requests:   8%|▊         | 33/400 [00:50<09:14,  1.51s/it]Running loglikelihood requests:   8%|▊         | 34/400 [00:51<09:11,  1.51s/it]Running loglikelihood requests:   9%|▉         | 35/400 [00:53<09:09,  1.51s/it]Running loglikelihood requests:   9%|▉         | 36/400 [00:54<09:06,  1.50s/it]Running loglikelihood requests:   9%|▉         | 37/400 [00:56<09:05,  1.50s/it]Running loglikelihood requests:  10%|▉         | 38/400 [00:57<09:03,  1.50s/it]Running loglikelihood requests:  10%|▉         | 39/400 [00:59<09:02,  1.50s/it]Running loglikelihood requests:  10%|█         | 40/400 [01:00<09:01,  1.50s/it]Running loglikelihood requests:  10%|█         | 41/400 [01:02<08:59,  1.50s/it]Running loglikelihood requests:  10%|█         | 42/400 [01:03<08:57,  1.50s/it]Running loglikelihood requests:  11%|█         | 43/400 [01:05<08:55,  1.50s/it]Running loglikelihood requests:  11%|█         | 44/400 [01:06<08:56,  1.51s/it]Running loglikelihood requests:  11%|█▏        | 45/400 [01:08<08:59,  1.52s/it]Running loglikelihood requests:  12%|█▏        | 46/400 [01:09<08:57,  1.52s/it]Running loglikelihood requests:  12%|█▏        | 47/400 [01:11<08:54,  1.51s/it]Running loglikelihood requests:  12%|█▏        | 48/400 [01:12<08:51,  1.51s/it]Running loglikelihood requests:  12%|█▏        | 49/400 [01:14<08:48,  1.51s/it]Running loglikelihood requests:  12%|█▎        | 50/400 [01:15<08:46,  1.50s/it]Running loglikelihood requests:  13%|█▎        | 51/400 [01:17<08:44,  1.50s/it]Running loglikelihood requests:  13%|█▎        | 52/400 [01:18<08:41,  1.50s/it]Running loglikelihood requests:  13%|█▎        | 53/400 [01:20<08:39,  1.50s/it]Running loglikelihood requests:  14%|█▎        | 54/400 [01:21<08:37,  1.49s/it]Running loglikelihood requests:  14%|█▍        | 55/400 [01:23<08:34,  1.49s/it]Running loglikelihood requests:  14%|█▍        | 56/400 [01:24<08:33,  1.49s/it]Running loglikelihood requests:  14%|█▍        | 57/400 [01:26<08:31,  1.49s/it]Running loglikelihood requests:  14%|█▍        | 58/400 [01:27<08:29,  1.49s/it]Running loglikelihood requests:  15%|█▍        | 59/400 [01:29<08:28,  1.49s/it]Running loglikelihood requests:  15%|█▌        | 60/400 [01:30<08:26,  1.49s/it]Running loglikelihood requests:  15%|█▌        | 61/400 [01:32<08:24,  1.49s/it]Running loglikelihood requests:  16%|█▌        | 62/400 [01:33<08:22,  1.49s/it]Running loglikelihood requests:  16%|█▌        | 63/400 [01:35<08:21,  1.49s/it]Running loglikelihood requests:  16%|█▌        | 64/400 [01:36<08:19,  1.49s/it]Running loglikelihood requests:  16%|█▋        | 65/400 [01:38<08:18,  1.49s/it]Running loglikelihood requests:  16%|█▋        | 66/400 [01:39<08:16,  1.49s/it]Running loglikelihood requests:  17%|█▋        | 67/400 [01:41<08:15,  1.49s/it]Running loglikelihood requests:  17%|█▋        | 68/400 [01:42<08:13,  1.49s/it]Running loglikelihood requests:  17%|█▋        | 69/400 [01:44<08:11,  1.49s/it]Running loglikelihood requests:  18%|█▊        | 71/400 [01:45<06:16,  1.14s/it]Running loglikelihood requests:  18%|█▊        | 72/400 [01:47<06:42,  1.23s/it]Running loglikelihood requests:  18%|█▊        | 73/400 [01:48<07:03,  1.29s/it]Running loglikelihood requests:  18%|█▊        | 74/400 [01:50<07:27,  1.37s/it]Running loglikelihood requests:  19%|█▉        | 75/400 [01:51<07:36,  1.40s/it]Running loglikelihood requests:  19%|█▉        | 76/400 [01:53<07:41,  1.42s/it]Running loglikelihood requests:  19%|█▉        | 77/400 [01:54<07:44,  1.44s/it]Running loglikelihood requests:  20%|█▉        | 78/400 [01:56<07:46,  1.45s/it]Running loglikelihood requests:  20%|█▉        | 79/400 [01:57<07:47,  1.46s/it]Running loglikelihood requests:  20%|██        | 80/400 [01:58<07:47,  1.46s/it]Running loglikelihood requests:  20%|██        | 81/400 [02:00<07:44,  1.45s/it]Running loglikelihood requests:  20%|██        | 82/400 [02:01<07:41,  1.45s/it]Running loglikelihood requests:  21%|██        | 83/400 [02:03<07:38,  1.45s/it]Running loglikelihood requests:  21%|██        | 84/400 [02:04<07:35,  1.44s/it]Running loglikelihood requests:  21%|██▏       | 85/400 [02:06<07:40,  1.46s/it]Running loglikelihood requests:  22%|██▏       | 86/400 [02:07<07:42,  1.47s/it]Running loglikelihood requests:  22%|██▏       | 87/400 [02:09<07:41,  1.48s/it]Running loglikelihood requests:  22%|██▏       | 88/400 [02:10<07:42,  1.48s/it]Running loglikelihood requests:  22%|██▏       | 89/400 [02:12<07:40,  1.48s/it]Running loglikelihood requests:  22%|██▎       | 90/400 [02:13<07:36,  1.47s/it]Running loglikelihood requests:  23%|██▎       | 91/400 [02:15<07:33,  1.47s/it]Running loglikelihood requests:  23%|██▎       | 92/400 [02:16<07:30,  1.46s/it]Running loglikelihood requests:  23%|██▎       | 93/400 [02:18<07:27,  1.46s/it]Running loglikelihood requests:  24%|██▎       | 94/400 [02:19<07:26,  1.46s/it]Running loglikelihood requests:  24%|██▍       | 95/400 [02:20<07:24,  1.46s/it]Running loglikelihood requests:  24%|██▍       | 96/400 [02:22<07:22,  1.45s/it]Running loglikelihood requests:  24%|██▍       | 97/400 [02:23<07:19,  1.45s/it]Running loglikelihood requests:  24%|██▍       | 98/400 [02:25<07:19,  1.45s/it]Running loglikelihood requests:  25%|██▍       | 99/400 [02:26<07:17,  1.45s/it]Running loglikelihood requests:  25%|██▌       | 100/400 [02:28<07:14,  1.45s/it]Running loglikelihood requests:  25%|██▌       | 101/400 [02:29<07:12,  1.45s/it]Running loglikelihood requests:  26%|██▌       | 102/400 [02:31<07:10,  1.44s/it]Running loglikelihood requests:  26%|██▌       | 103/400 [02:32<07:07,  1.44s/it]Running loglikelihood requests:  26%|██▌       | 104/400 [02:33<07:05,  1.44s/it]Running loglikelihood requests:  26%|██▋       | 105/400 [02:35<07:03,  1.44s/it]Running loglikelihood requests:  26%|██▋       | 106/400 [02:36<07:01,  1.43s/it]Running loglikelihood requests:  27%|██▋       | 107/400 [02:38<06:59,  1.43s/it]Running loglikelihood requests:  27%|██▋       | 108/400 [02:39<06:57,  1.43s/it]Running loglikelihood requests:  27%|██▋       | 109/400 [02:41<06:55,  1.43s/it]Running loglikelihood requests:  28%|██▊       | 110/400 [02:42<06:54,  1.43s/it]Running loglikelihood requests:  28%|██▊       | 111/400 [02:43<06:52,  1.43s/it]Running loglikelihood requests:  28%|██▊       | 112/400 [02:45<06:50,  1.43s/it]Running loglikelihood requests:  28%|██▊       | 113/400 [02:46<06:48,  1.42s/it]Running loglikelihood requests:  28%|██▊       | 114/400 [02:48<06:47,  1.42s/it]Running loglikelihood requests:  29%|██▉       | 115/400 [02:49<06:47,  1.43s/it]Running loglikelihood requests:  29%|██▉       | 116/400 [02:51<06:47,  1.43s/it]Running loglikelihood requests:  29%|██▉       | 117/400 [02:52<06:45,  1.43s/it]Running loglikelihood requests:  30%|██▉       | 118/400 [02:53<06:43,  1.43s/it]Running loglikelihood requests:  30%|██▉       | 119/400 [02:55<06:42,  1.43s/it]Running loglikelihood requests:  30%|███       | 120/400 [02:56<06:40,  1.43s/it]Running loglikelihood requests:  30%|███       | 121/400 [02:58<06:38,  1.43s/it]Running loglikelihood requests:  30%|███       | 122/400 [02:59<06:36,  1.43s/it]Running loglikelihood requests:  31%|███       | 123/400 [03:01<06:35,  1.43s/it]Running loglikelihood requests:  31%|███       | 124/400 [03:02<06:34,  1.43s/it]Running loglikelihood requests:  31%|███▏      | 125/400 [03:03<06:34,  1.44s/it]Running loglikelihood requests:  32%|███▏      | 126/400 [03:05<06:31,  1.43s/it]Running loglikelihood requests:  32%|███▏      | 127/400 [03:06<06:30,  1.43s/it]Running loglikelihood requests:  32%|███▏      | 128/400 [03:08<06:28,  1.43s/it]Running loglikelihood requests:  32%|███▏      | 129/400 [03:09<06:26,  1.42s/it]Running loglikelihood requests:  32%|███▎      | 130/400 [03:11<06:23,  1.42s/it]Running loglikelihood requests:  33%|███▎      | 131/400 [03:12<06:21,  1.42s/it]Running loglikelihood requests:  33%|███▎      | 132/400 [03:13<06:20,  1.42s/it]Running loglikelihood requests:  33%|███▎      | 133/400 [03:15<06:18,  1.42s/it]Running loglikelihood requests:  34%|███▎      | 134/400 [03:16<06:19,  1.43s/it]Running loglikelihood requests:  34%|███▍      | 135/400 [03:18<06:19,  1.43s/it]Running loglikelihood requests:  34%|███▍      | 136/400 [03:19<06:17,  1.43s/it]Running loglikelihood requests:  34%|███▍      | 137/400 [03:21<06:14,  1.43s/it]Running loglikelihood requests:  34%|███▍      | 138/400 [03:22<06:16,  1.44s/it]Running loglikelihood requests:  35%|███▍      | 139/400 [03:23<06:13,  1.43s/it]Running loglikelihood requests:  35%|███▌      | 140/400 [03:25<06:12,  1.43s/it]Running loglikelihood requests:  35%|███▌      | 141/400 [03:26<06:11,  1.43s/it]Running loglikelihood requests:  36%|███▌      | 142/400 [03:28<06:09,  1.43s/it]Running loglikelihood requests:  36%|███▌      | 143/400 [03:29<06:06,  1.43s/it]Running loglikelihood requests:  36%|███▌      | 144/400 [03:31<06:04,  1.42s/it]Running loglikelihood requests:  36%|███▋      | 145/400 [03:32<06:02,  1.42s/it]Running loglikelihood requests:  36%|███▋      | 146/400 [03:33<06:00,  1.42s/it]Running loglikelihood requests:  37%|███▋      | 147/400 [03:35<05:58,  1.42s/it]Running loglikelihood requests:  37%|███▋      | 148/400 [03:36<05:56,  1.41s/it]Running loglikelihood requests:  37%|███▋      | 149/400 [03:38<05:54,  1.41s/it]Running loglikelihood requests:  38%|███▊      | 150/400 [03:39<05:54,  1.42s/it]Running loglikelihood requests:  38%|███▊      | 151/400 [03:40<05:52,  1.41s/it]Running loglikelihood requests:  38%|███▊      | 152/400 [03:42<05:49,  1.41s/it]Running loglikelihood requests:  38%|███▊      | 153/400 [03:43<05:47,  1.41s/it]Running loglikelihood requests:  38%|███▊      | 154/400 [03:45<05:45,  1.41s/it]Running loglikelihood requests:  39%|███▉      | 155/400 [03:46<05:44,  1.40s/it]Running loglikelihood requests:  39%|███▉      | 156/400 [03:47<05:42,  1.40s/it]Running loglikelihood requests:  39%|███▉      | 157/400 [03:49<05:41,  1.40s/it]Running loglikelihood requests:  40%|███▉      | 158/400 [03:50<05:39,  1.40s/it]Running loglikelihood requests:  40%|███▉      | 159/400 [03:52<05:37,  1.40s/it]Running loglikelihood requests:  40%|████      | 160/400 [03:53<05:35,  1.40s/it]Running loglikelihood requests:  40%|████      | 161/400 [03:54<05:33,  1.40s/it]Running loglikelihood requests:  40%|████      | 162/400 [03:56<05:32,  1.40s/it]Running loglikelihood requests:  41%|████      | 163/400 [03:57<05:30,  1.39s/it]Running loglikelihood requests:  41%|████      | 164/400 [03:59<05:30,  1.40s/it]Running loglikelihood requests:  41%|████▏     | 165/400 [04:00<05:28,  1.40s/it]Running loglikelihood requests:  42%|████▏     | 166/400 [04:01<05:27,  1.40s/it]Running loglikelihood requests:  42%|████▏     | 167/400 [04:03<05:26,  1.40s/it]Running loglikelihood requests:  42%|████▏     | 168/400 [04:04<05:24,  1.40s/it]Running loglikelihood requests:  42%|████▏     | 169/400 [04:06<05:27,  1.42s/it]Running loglikelihood requests:  42%|████▎     | 170/400 [04:07<05:24,  1.41s/it]Running loglikelihood requests:  43%|████▎     | 171/400 [04:08<05:21,  1.40s/it]Running loglikelihood requests:  43%|████▎     | 172/400 [04:10<05:19,  1.40s/it]Running loglikelihood requests:  43%|████▎     | 173/400 [04:11<05:19,  1.41s/it]Running loglikelihood requests:  44%|████▎     | 174/400 [04:13<05:17,  1.41s/it]Running loglikelihood requests:  44%|████▍     | 175/400 [04:14<05:16,  1.41s/it]Running loglikelihood requests:  44%|████▍     | 176/400 [04:15<05:14,  1.40s/it]Running loglikelihood requests:  44%|████▍     | 177/400 [04:17<05:13,  1.40s/it]Running loglikelihood requests:  44%|████▍     | 178/400 [04:18<05:11,  1.40s/it]Running loglikelihood requests:  45%|████▍     | 179/400 [04:20<05:10,  1.40s/it]Running loglikelihood requests:  45%|████▌     | 180/400 [04:21<05:08,  1.40s/it]Running loglikelihood requests:  45%|████▌     | 181/400 [04:22<05:07,  1.40s/it]Running loglikelihood requests:  46%|████▌     | 182/400 [04:24<05:05,  1.40s/it]Running loglikelihood requests:  46%|████▌     | 183/400 [04:25<05:03,  1.40s/it]Running loglikelihood requests:  46%|████▌     | 184/400 [04:27<05:02,  1.40s/it]Running loglikelihood requests:  46%|████▋     | 185/400 [04:28<05:00,  1.40s/it]Running loglikelihood requests:  46%|████▋     | 186/400 [04:29<04:59,  1.40s/it]Running loglikelihood requests:  47%|████▋     | 187/400 [04:31<04:57,  1.40s/it]Running loglikelihood requests:  47%|████▋     | 188/400 [04:32<04:55,  1.40s/it]Running loglikelihood requests:  47%|████▋     | 189/400 [04:34<04:55,  1.40s/it]Running loglikelihood requests:  48%|████▊     | 190/400 [04:35<04:54,  1.40s/it]Running loglikelihood requests:  48%|████▊     | 191/400 [04:36<04:53,  1.40s/it]Running loglikelihood requests:  48%|████▊     | 192/400 [04:38<04:51,  1.40s/it]Running loglikelihood requests:  48%|████▊     | 193/400 [04:39<04:50,  1.40s/it]Running loglikelihood requests:  48%|████▊     | 194/400 [04:41<04:48,  1.40s/it]Running loglikelihood requests:  49%|████▉     | 195/400 [04:42<04:47,  1.40s/it]Running loglikelihood requests:  49%|████▉     | 196/400 [04:43<04:45,  1.40s/it]Running loglikelihood requests:  49%|████▉     | 197/400 [04:45<04:43,  1.40s/it]Running loglikelihood requests:  50%|████▉     | 198/400 [04:46<04:42,  1.40s/it]Running loglikelihood requests:  50%|████▉     | 199/400 [04:48<04:40,  1.40s/it]Running loglikelihood requests:  50%|█████     | 200/400 [04:49<04:39,  1.40s/it]Running loglikelihood requests:  50%|█████     | 201/400 [04:50<04:37,  1.40s/it]Running loglikelihood requests:  50%|█████     | 202/400 [04:52<04:35,  1.39s/it]Running loglikelihood requests:  51%|█████     | 203/400 [04:53<04:34,  1.39s/it]Running loglikelihood requests:  51%|█████     | 204/400 [04:55<04:33,  1.39s/it]Running loglikelihood requests:  51%|█████▏    | 205/400 [04:56<04:31,  1.39s/it]Running loglikelihood requests:  52%|█████▏    | 206/400 [04:57<04:29,  1.39s/it]Running loglikelihood requests:  52%|█████▏    | 207/400 [04:59<04:28,  1.39s/it]Running loglikelihood requests:  52%|█████▏    | 208/400 [05:00<04:26,  1.39s/it]Running loglikelihood requests:  52%|█████▏    | 209/400 [05:02<04:25,  1.39s/it]Running loglikelihood requests:  52%|█████▎    | 210/400 [05:03<04:25,  1.40s/it]Running loglikelihood requests:  53%|█████▎    | 211/400 [05:04<04:23,  1.40s/it]Running loglikelihood requests:  53%|█████▎    | 212/400 [05:06<04:22,  1.40s/it]Running loglikelihood requests:  53%|█████▎    | 213/400 [05:07<04:21,  1.40s/it]Running loglikelihood requests:  54%|█████▎    | 214/400 [05:09<04:18,  1.39s/it]Running loglikelihood requests:  54%|█████▍    | 215/400 [05:10<04:15,  1.38s/it]Running loglikelihood requests:  54%|█████▍    | 216/400 [05:11<04:12,  1.37s/it]Running loglikelihood requests:  54%|█████▍    | 217/400 [05:13<04:10,  1.37s/it]Running loglikelihood requests:  55%|█████▍    | 218/400 [05:14<04:09,  1.37s/it]Running loglikelihood requests:  55%|█████▍    | 219/400 [05:15<04:08,  1.37s/it]Running loglikelihood requests:  55%|█████▌    | 220/400 [05:17<04:07,  1.38s/it]Running loglikelihood requests:  55%|█████▌    | 221/400 [05:18<04:05,  1.37s/it]Running loglikelihood requests:  56%|█████▌    | 222/400 [05:19<04:03,  1.37s/it]Running loglikelihood requests:  56%|█████▌    | 223/400 [05:21<04:03,  1.37s/it]Running loglikelihood requests:  56%|█████▌    | 224/400 [05:22<04:01,  1.37s/it]Running loglikelihood requests:  56%|█████▋    | 225/400 [05:24<03:59,  1.37s/it]Running loglikelihood requests:  56%|█████▋    | 226/400 [05:25<03:57,  1.36s/it]Running loglikelihood requests:  57%|█████▋    | 227/400 [05:26<03:55,  1.36s/it]Running loglikelihood requests:  57%|█████▋    | 228/400 [05:28<03:54,  1.36s/it]Running loglikelihood requests:  57%|█████▋    | 229/400 [05:29<03:52,  1.36s/it]Running loglikelihood requests:  57%|█████▊    | 230/400 [05:30<03:50,  1.35s/it]Running loglikelihood requests:  58%|█████▊    | 231/400 [05:32<03:48,  1.35s/it]Running loglikelihood requests:  58%|█████▊    | 232/400 [05:33<03:46,  1.35s/it]Running loglikelihood requests:  58%|█████▊    | 233/400 [05:34<03:45,  1.35s/it]Running loglikelihood requests:  58%|█████▊    | 234/400 [05:36<03:43,  1.35s/it]Running loglikelihood requests:  59%|█████▉    | 235/400 [05:37<03:42,  1.35s/it]Running loglikelihood requests:  59%|█████▉    | 236/400 [05:38<03:40,  1.34s/it]Running loglikelihood requests:  59%|█████▉    | 237/400 [05:40<03:39,  1.34s/it]Running loglikelihood requests:  60%|█████▉    | 238/400 [05:41<03:37,  1.34s/it]Running loglikelihood requests:  60%|█████▉    | 239/400 [05:42<03:35,  1.34s/it]Running loglikelihood requests:  60%|██████    | 240/400 [05:44<03:34,  1.34s/it]Running loglikelihood requests:  60%|██████    | 241/400 [05:45<03:32,  1.34s/it]Running loglikelihood requests:  60%|██████    | 242/400 [05:46<03:31,  1.34s/it]Running loglikelihood requests:  61%|██████    | 243/400 [05:48<03:28,  1.33s/it]Running loglikelihood requests:  61%|██████    | 244/400 [05:49<03:28,  1.33s/it]Running loglikelihood requests:  61%|██████▏   | 245/400 [05:50<03:27,  1.34s/it]Running loglikelihood requests:  62%|██████▏   | 246/400 [05:52<03:25,  1.33s/it]Running loglikelihood requests:  62%|██████▏   | 247/400 [05:53<03:23,  1.33s/it]Running loglikelihood requests:  62%|██████▏   | 248/400 [05:55<03:39,  1.45s/it]Running loglikelihood requests:  62%|██████▏   | 249/400 [05:56<03:34,  1.42s/it]Running loglikelihood requests:  62%|██████▎   | 250/400 [05:57<03:28,  1.39s/it]Running loglikelihood requests:  63%|██████▎   | 251/400 [05:59<03:23,  1.37s/it]Running loglikelihood requests:  63%|██████▎   | 252/400 [06:00<03:22,  1.37s/it]Running loglikelihood requests:  63%|██████▎   | 253/400 [06:02<03:19,  1.36s/it]Running loglikelihood requests:  64%|██████▎   | 254/400 [06:03<03:16,  1.35s/it]Running loglikelihood requests:  64%|██████▍   | 255/400 [06:04<03:13,  1.34s/it]Running loglikelihood requests:  64%|██████▍   | 256/400 [06:05<03:11,  1.33s/it]Running loglikelihood requests:  64%|██████▍   | 257/400 [06:07<03:09,  1.33s/it]Running loglikelihood requests:  64%|██████▍   | 258/400 [06:08<03:07,  1.32s/it]Running loglikelihood requests:  65%|██████▍   | 259/400 [06:09<03:06,  1.32s/it]Running loglikelihood requests:  65%|██████▌   | 260/400 [06:11<03:04,  1.32s/it]Running loglikelihood requests:  65%|██████▌   | 261/400 [06:12<03:03,  1.32s/it]Running loglikelihood requests:  66%|██████▌   | 262/400 [06:13<03:01,  1.32s/it]Running loglikelihood requests:  66%|██████▌   | 263/400 [06:15<03:00,  1.31s/it]Running loglikelihood requests:  66%|██████▌   | 264/400 [06:16<02:58,  1.32s/it]Running loglikelihood requests:  66%|██████▋   | 265/400 [06:17<02:57,  1.32s/it]Running loglikelihood requests:  66%|██████▋   | 266/400 [06:19<02:55,  1.31s/it]Running loglikelihood requests:  67%|██████▋   | 267/400 [06:20<02:54,  1.31s/it]Running loglikelihood requests:  67%|██████▋   | 268/400 [06:21<02:52,  1.31s/it]Running loglikelihood requests:  67%|██████▋   | 269/400 [06:23<02:52,  1.32s/it]Running loglikelihood requests:  68%|██████▊   | 270/400 [06:24<02:49,  1.31s/it]Running loglikelihood requests:  68%|██████▊   | 271/400 [06:25<02:47,  1.30s/it]Running loglikelihood requests:  68%|██████▊   | 272/400 [06:26<02:45,  1.29s/it]Running loglikelihood requests:  68%|██████▊   | 273/400 [06:28<02:43,  1.29s/it]Running loglikelihood requests:  68%|██████▊   | 274/400 [06:29<02:42,  1.29s/it]Running loglikelihood requests:  69%|██████▉   | 275/400 [06:30<02:40,  1.29s/it]Running loglikelihood requests:  69%|██████▉   | 276/400 [06:32<02:39,  1.29s/it]Running loglikelihood requests:  69%|██████▉   | 277/400 [06:33<02:37,  1.28s/it]Running loglikelihood requests:  70%|██████▉   | 278/400 [06:34<02:36,  1.28s/it]Running loglikelihood requests:  70%|██████▉   | 279/400 [06:35<02:35,  1.29s/it]Running loglikelihood requests:  70%|███████   | 280/400 [06:37<02:34,  1.29s/it]Running loglikelihood requests:  70%|███████   | 281/400 [06:38<02:33,  1.29s/it]Running loglikelihood requests:  70%|███████   | 282/400 [06:39<02:31,  1.29s/it]Running loglikelihood requests:  71%|███████   | 283/400 [06:41<02:30,  1.29s/it]Running loglikelihood requests:  71%|███████   | 284/400 [06:42<02:29,  1.29s/it]Running loglikelihood requests:  71%|███████▏  | 285/400 [06:43<02:30,  1.31s/it]Running loglikelihood requests:  72%|███████▏  | 286/400 [06:44<02:28,  1.30s/it]Running loglikelihood requests:  72%|███████▏  | 287/400 [06:46<02:26,  1.29s/it]Running loglikelihood requests:  72%|███████▏  | 288/400 [06:47<02:24,  1.29s/it]Running loglikelihood requests:  72%|███████▏  | 289/400 [06:48<02:22,  1.29s/it]Running loglikelihood requests:  72%|███████▎  | 290/400 [06:50<02:21,  1.29s/it]Running loglikelihood requests:  73%|███████▎  | 291/400 [06:51<02:20,  1.28s/it]Running loglikelihood requests:  73%|███████▎  | 292/400 [06:52<02:18,  1.28s/it]Running loglikelihood requests:  73%|███████▎  | 293/400 [06:53<02:17,  1.28s/it]Running loglikelihood requests:  74%|███████▎  | 294/400 [06:55<02:15,  1.28s/it]Running loglikelihood requests:  74%|███████▍  | 295/400 [06:56<02:14,  1.28s/it]Running loglikelihood requests:  74%|███████▍  | 296/400 [06:57<02:12,  1.28s/it]Running loglikelihood requests:  74%|███████▍  | 297/400 [06:59<02:11,  1.28s/it]Running loglikelihood requests:  74%|███████▍  | 298/400 [07:00<02:09,  1.27s/it]Running loglikelihood requests:  75%|███████▍  | 299/400 [07:01<02:08,  1.27s/it]Running loglikelihood requests:  75%|███████▌  | 300/400 [07:02<02:07,  1.27s/it]Running loglikelihood requests:  75%|███████▌  | 301/400 [07:04<02:05,  1.27s/it]Running loglikelihood requests:  76%|███████▌  | 302/400 [07:05<02:04,  1.27s/it]Running loglikelihood requests:  76%|███████▌  | 303/400 [07:06<02:02,  1.27s/it]Running loglikelihood requests:  76%|███████▌  | 304/400 [07:07<02:01,  1.27s/it]Running loglikelihood requests:  76%|███████▋  | 305/400 [07:09<02:00,  1.27s/it]Running loglikelihood requests:  76%|███████▋  | 306/400 [07:10<01:59,  1.27s/it]Running loglikelihood requests:  77%|███████▋  | 307/400 [07:11<01:58,  1.27s/it]Running loglikelihood requests:  77%|███████▋  | 308/400 [07:12<01:57,  1.28s/it]Running loglikelihood requests:  77%|███████▋  | 309/400 [07:14<01:56,  1.28s/it]Running loglikelihood requests:  78%|███████▊  | 310/400 [07:15<01:55,  1.28s/it]Running loglikelihood requests:  78%|███████▊  | 311/400 [07:16<01:54,  1.29s/it]Running loglikelihood requests:  78%|███████▊  | 312/400 [07:18<01:53,  1.29s/it]Running loglikelihood requests:  78%|███████▊  | 313/400 [07:19<01:52,  1.29s/it]Running loglikelihood requests:  78%|███████▊  | 314/400 [07:20<01:50,  1.28s/it]Running loglikelihood requests:  79%|███████▉  | 315/400 [07:21<01:48,  1.28s/it]Running loglikelihood requests:  79%|███████▉  | 316/400 [07:23<01:46,  1.27s/it]Running loglikelihood requests:  79%|███████▉  | 317/400 [07:24<01:45,  1.27s/it]Running loglikelihood requests:  80%|███████▉  | 318/400 [07:25<01:43,  1.27s/it]Running loglikelihood requests:  80%|███████▉  | 319/400 [07:27<01:42,  1.26s/it]Running loglikelihood requests:  80%|████████  | 320/400 [07:28<01:40,  1.26s/it]Running loglikelihood requests:  80%|████████  | 321/400 [07:29<01:39,  1.26s/it]Running loglikelihood requests:  80%|████████  | 322/400 [07:30<01:39,  1.27s/it]Running loglikelihood requests:  81%|████████  | 323/400 [07:32<01:37,  1.27s/it]Running loglikelihood requests:  81%|████████  | 324/400 [07:33<01:36,  1.26s/it]Running loglikelihood requests:  81%|████████▏ | 325/400 [07:34<01:34,  1.26s/it]Running loglikelihood requests:  82%|████████▏ | 326/400 [07:35<01:33,  1.26s/it]Running loglikelihood requests:  82%|████████▏ | 327/400 [07:37<01:31,  1.26s/it]Running loglikelihood requests:  82%|████████▏ | 328/400 [07:38<01:30,  1.25s/it]Running loglikelihood requests:  82%|████████▏ | 329/400 [07:39<01:28,  1.25s/it]Running loglikelihood requests:  82%|████████▎ | 330/400 [07:40<01:27,  1.25s/it]Running loglikelihood requests:  83%|████████▎ | 331/400 [07:42<01:26,  1.25s/it]Running loglikelihood requests:  83%|████████▎ | 332/400 [07:43<01:25,  1.25s/it]Running loglikelihood requests:  83%|████████▎ | 333/400 [07:44<01:23,  1.25s/it]Running loglikelihood requests:  84%|████████▎ | 334/400 [07:45<01:22,  1.25s/it]Running loglikelihood requests:  84%|████████▍ | 335/400 [07:47<01:21,  1.25s/it]Running loglikelihood requests:  84%|████████▍ | 336/400 [07:48<01:19,  1.25s/it]Running loglikelihood requests:  84%|████████▍ | 337/400 [07:49<01:18,  1.24s/it]Running loglikelihood requests:  84%|████████▍ | 338/400 [07:50<01:17,  1.24s/it]Running loglikelihood requests:  85%|████████▍ | 339/400 [07:52<01:15,  1.24s/it]Running loglikelihood requests:  85%|████████▌ | 340/400 [07:53<01:14,  1.24s/it]Running loglikelihood requests:  85%|████████▌ | 341/400 [07:54<01:13,  1.24s/it]Running loglikelihood requests:  86%|████████▌ | 342/400 [07:55<01:11,  1.24s/it]Running loglikelihood requests:  86%|████████▌ | 343/400 [07:57<01:11,  1.25s/it]Running loglikelihood requests:  86%|████████▌ | 344/400 [07:58<01:10,  1.25s/it]Running loglikelihood requests:  86%|████████▋ | 345/400 [07:59<01:08,  1.25s/it]Running loglikelihood requests:  86%|████████▋ | 346/400 [08:00<01:07,  1.25s/it]Running loglikelihood requests:  87%|████████▋ | 347/400 [08:02<01:06,  1.25s/it]Running loglikelihood requests:  87%|████████▋ | 348/400 [08:03<01:05,  1.26s/it]Running loglikelihood requests:  87%|████████▋ | 349/400 [08:04<01:03,  1.25s/it]Running loglikelihood requests:  88%|████████▊ | 350/400 [08:05<01:02,  1.26s/it]Running loglikelihood requests:  88%|████████▊ | 351/400 [08:07<01:01,  1.25s/it]Running loglikelihood requests:  88%|████████▊ | 352/400 [08:08<01:00,  1.25s/it]Running loglikelihood requests:  88%|████████▊ | 353/400 [08:09<00:58,  1.25s/it]Running loglikelihood requests:  88%|████████▊ | 354/400 [08:10<00:57,  1.25s/it]Running loglikelihood requests:  89%|████████▉ | 355/400 [08:12<00:56,  1.25s/it]Running loglikelihood requests:  89%|████████▉ | 356/400 [08:13<00:54,  1.25s/it]Running loglikelihood requests:  89%|████████▉ | 357/400 [08:14<00:53,  1.25s/it]Running loglikelihood requests:  90%|████████▉ | 358/400 [08:15<00:52,  1.25s/it]Running loglikelihood requests:  90%|████████▉ | 359/400 [08:17<00:51,  1.25s/it]Running loglikelihood requests:  90%|█████████ | 360/400 [08:18<00:50,  1.25s/it]Running loglikelihood requests:  90%|█████████ | 361/400 [08:19<00:50,  1.29s/it]Running loglikelihood requests:  90%|█████████ | 362/400 [08:21<00:49,  1.31s/it]Running loglikelihood requests:  91%|█████████ | 363/400 [08:22<00:47,  1.29s/it]Running loglikelihood requests:  91%|█████████ | 364/400 [08:23<00:46,  1.28s/it]Running loglikelihood requests:  91%|█████████▏| 365/400 [08:24<00:44,  1.27s/it]Running loglikelihood requests:  92%|█████████▏| 366/400 [08:26<00:42,  1.26s/it]Running loglikelihood requests:  92%|█████████▏| 367/400 [08:27<00:41,  1.26s/it]Running loglikelihood requests:  92%|█████████▏| 368/400 [08:28<00:40,  1.25s/it]Running loglikelihood requests:  92%|█████████▏| 369/400 [08:29<00:38,  1.25s/it]Running loglikelihood requests:  92%|█████████▎| 370/400 [08:31<00:37,  1.25s/it]Running loglikelihood requests:  93%|█████████▎| 371/400 [08:32<00:36,  1.24s/it]Running loglikelihood requests:  93%|█████████▎| 372/400 [08:33<00:34,  1.24s/it]Running loglikelihood requests:  93%|█████████▎| 373/400 [08:34<00:33,  1.24s/it]Running loglikelihood requests:  94%|█████████▎| 374/400 [08:35<00:32,  1.24s/it]Running loglikelihood requests:  94%|█████████▍| 375/400 [08:37<00:30,  1.23s/it]Running loglikelihood requests:  94%|█████████▍| 376/400 [08:38<00:29,  1.23s/it]Running loglikelihood requests:  94%|█████████▍| 377/400 [08:39<00:28,  1.23s/it]Running loglikelihood requests:  94%|█████████▍| 378/400 [08:40<00:27,  1.23s/it]Running loglikelihood requests:  95%|█████████▍| 379/400 [08:42<00:25,  1.22s/it]Running loglikelihood requests:  95%|█████████▌| 380/400 [08:43<00:24,  1.22s/it]Running loglikelihood requests:  95%|█████████▌| 381/400 [08:44<00:23,  1.22s/it]Running loglikelihood requests:  96%|█████████▌| 382/400 [08:45<00:21,  1.22s/it]Running loglikelihood requests:  96%|█████████▌| 383/400 [08:46<00:20,  1.22s/it]Running loglikelihood requests:  96%|█████████▌| 384/400 [08:48<00:19,  1.23s/it]Running loglikelihood requests:  96%|█████████▋| 385/400 [08:49<00:18,  1.21s/it]Running loglikelihood requests:  96%|█████████▋| 386/400 [08:50<00:16,  1.20s/it]Running loglikelihood requests:  97%|█████████▋| 387/400 [08:51<00:15,  1.19s/it]Running loglikelihood requests:  97%|█████████▋| 388/400 [08:52<00:14,  1.18s/it]Running loglikelihood requests:  97%|█████████▋| 389/400 [08:53<00:12,  1.15s/it]Running loglikelihood requests:  98%|█████████▊| 390/400 [08:55<00:11,  1.13s/it]Running loglikelihood requests:  98%|█████████▊| 391/400 [08:56<00:10,  1.11s/it]Running loglikelihood requests:  98%|█████████▊| 392/400 [08:57<00:08,  1.10s/it]Running loglikelihood requests:  98%|█████████▊| 393/400 [08:58<00:07,  1.09s/it]Running loglikelihood requests:  98%|█████████▊| 394/400 [08:59<00:06,  1.08s/it]Running loglikelihood requests:  99%|█████████▉| 395/400 [09:00<00:05,  1.07s/it]Running loglikelihood requests:  99%|█████████▉| 396/400 [09:01<00:04,  1.07s/it]Running loglikelihood requests:  99%|█████████▉| 397/400 [09:02<00:03,  1.05s/it]Running loglikelihood requests: 100%|█████████▉| 398/400 [09:03<00:02,  1.03s/it]Running loglikelihood requests: 100%|█████████▉| 399/400 [09:04<00:01,  1.02s/it]Running loglikelihood requests: 100%|██████████| 400/400 [09:05<00:00,  1.02s/it]Running loglikelihood requests: 100%|██████████| 400/400 [09:05<00:00,  1.36s/it]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:2'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:2'}
full model:
{'mastermind_46_easy': {'alias': 'mastermind_46_easy', 'acc,none': 0.75, 'acc_stderr,none': 0.04351941398892446}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9900730655060652
0.9975621416797388
0.9971758007187725
0.9980230222224056
0.9889479987910904
0.9764864248764976
0.9903944102306983
0.9944743493554844
0.9959595842537624
0.9872350810596702
0.9630442697748985
0.9836939129473328
0.9680042833072414
0.9739989664157891
0.9945965755000291
0.9874567967365809
0.9910190996776087
0.9888895436517939
0.9820307305549418
0.9881803990776891
0.9859944271811626
0.9931460182904469
0.984259193892523
0.99673879588459
0.9800909214289261
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[5, 2, 0, 3, 7, 6, 1, 4]
tensor([5, 2, 0, 3, 7, 6, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 0, 3, 7, 6, 1, 4]
tensor([5, 2, 0, 3, 7, 6, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 0, 3, 7, 6, 1, 4]
tensor([5, 2, 0, 3, 7, 6, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 0, 3, 7, 6, 1, 4]
tensor([5, 2, 0, 3, 7, 6, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 0, 3, 7, 6, 1, 4]
tensor([5, 2, 0, 3, 7, 6, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 0, 3, 7, 6, 1, 4]
tensor([5, 2, 0, 3, 7, 6, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Normal merging for layer 2
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Normal merging for layer 3
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Normal merging for layer 4
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Normal merging for layer 5
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 6 to 31
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 7 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.0718 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 6 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

108
cuda:2
rte
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:56<00:56, 56.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:13<00:00, 33.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:13<00:00, 36.72s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: rte] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: rte] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:filelock:Attempting to acquire lock 140437586247856 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140437586247856 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140437586247856 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140437586247856 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140437586247856 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140437586247856 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140437586247856 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140437586247856 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of rte from None to 0
INFO:lm_eval.api.task:Building contexts for rte on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 2607.54it/s]
DEBUG:lm_eval.evaluator:Task: rte; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:02<07:16,  2.19s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:03<03:43,  1.13s/it]Running loglikelihood requests:   2%|▎         | 5/200 [00:05<02:56,  1.10it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:06<02:34,  1.25it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:07<02:22,  1.34it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:09<02:13,  1.41it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:10<02:08,  1.46it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:11<02:03,  1.50it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:12<01:59,  1.53it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:14<01:58,  1.53it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:15<01:54,  1.57it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:16<01:50,  1.60it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:17<01:47,  1.63it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:18<01:43,  1.67it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:19<01:40,  1.71it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:21<01:37,  1.74it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:22<01:34,  1.76it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:23<01:32,  1.78it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:24<01:29,  1.82it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:25<01:26,  1.86it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:26<01:23,  1.91it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:27<01:21,  1.94it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:28<01:18,  1.96it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:29<01:16,  1.99it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:30<01:14,  2.02it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:31<01:12,  2.07it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:31<01:09,  2.11it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:32<01:06,  2.16it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:33<01:04,  2.22it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:34<01:02,  2.26it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:35<01:00,  2.30it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:36<00:58,  2.33it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:37<00:57,  2.34it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:37<00:56,  2.37it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:38<00:54,  2.40it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:39<00:53,  2.42it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:40<00:51,  2.45it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:41<00:50,  2.46it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:41<00:50,  2.45it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:42<00:48,  2.48it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:43<00:47,  2.52it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:44<00:46,  2.54it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:44<00:44,  2.57it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:45<00:43,  2.59it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:46<00:42,  2.62it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:47<00:41,  2.64it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:47<00:40,  2.66it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:48<00:39,  2.68it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:49<00:38,  2.69it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:50<00:37,  2.71it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:50<00:36,  2.72it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:51<00:35,  2.73it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:52<00:34,  2.75it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:53<00:33,  2.77it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:53<00:32,  2.78it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:54<00:31,  2.80it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:55<00:31,  2.80it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:55<00:30,  2.81it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:56<00:29,  2.82it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:57<00:28,  2.83it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:57<00:27,  2.84it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:58<00:27,  2.85it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:59<00:26,  2.85it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [01:00<00:25,  2.84it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [01:00<00:24,  2.85it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [01:01<00:24,  2.86it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [01:02<00:24,  2.69it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [01:03<00:23,  2.77it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [01:03<00:22,  2.81it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [01:04<00:21,  2.86it/s]Running loglikelihood requests:  70%|███████   | 141/200 [01:05<00:20,  2.90it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [01:05<00:19,  2.93it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [01:06<00:18,  2.96it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [01:07<00:17,  2.98it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [01:07<00:17,  3.00it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [01:08<00:16,  3.01it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [01:08<00:15,  3.03it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [01:09<00:14,  3.04it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [01:10<00:14,  3.06it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [01:10<00:13,  3.05it/s]Running loglikelihood requests:  80%|████████  | 161/200 [01:11<00:12,  3.08it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [01:12<00:12,  2.95it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [01:12<00:11,  3.00it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [01:13<00:11,  2.77it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [01:14<00:10,  2.87it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [01:15<00:09,  2.98it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [01:15<00:08,  3.06it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [01:16<00:08,  3.11it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [01:16<00:07,  3.16it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [01:17<00:06,  3.20it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [01:18<00:05,  3.23it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [01:18<00:05,  3.26it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [01:19<00:04,  3.27it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [01:19<00:03,  3.29it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [01:20<00:03,  3.27it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [01:21<00:02,  3.31it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [01:21<00:02,  3.34it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:22<00:01,  3.35it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:22<00:00,  3.43it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:23<00:00,  3.51it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:23<00:00,  2.40it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:3'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:3'}
full model:
{'rte': {'alias': 'rte', 'acc,none': 0.5, 'acc_stderr,none': 0.050251890762960605}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.34161229456626735
0.905233410256777
0.5205040718697735
0.4121994254524892
0.7398116665887099
0.6225415196831932
0.7923970242263771
0.7353888240887675
0.6535613357308766
0.7757058271862038
0.734046359122903
0.4471799126982846
0.773619360921301
0.7955347039939479
0.8672068064531693
0.8652880343596522
0.3302235467760883
0.6789268064017625
0.6072221471952108
0.9194446824778495
0.4812004589187253
0.5728915095234594
0.1682455054057436
0.93212414632396
0.9148362604533635
0.8268537756297094
0.7592245907029287
0.7256008379011685
0.7109756105942956
0.34161229456626735
0.905233410256777
0.5205040718697735
0.4121994254524892
0.7398116665887099
0.6225415196831932
0.7923970242263771
0.7353888240887675
0.6535613357308766
0.7757058271862038
0.734046359122903
0.4471799126982846
0.773619360921301
0.7955347039939479
0.8672068064531693
0.8652880343596522
0.3302235467760883
0.6789268064017625
0.6072221471952108
0.9194446824778495
0.4812004589187253
Total groups 73 exceeded the threshold, stopping comparison.
The group tensor is
[5, 2, 7, 1, 6, 4, 3, 0]
tensor([5, 2, 7, 1, 6, 4, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 6, 0, 7, 3, 4, 1]
tensor([5, 2, 6, 0, 7, 3, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 7, 2, 5, 4, 3, 0]
tensor([6, 1, 7, 2, 5, 4, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 7, 2, 4, 1, 5, 0]
tensor([6, 3, 7, 2, 4, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 5, 6, 2, 3, 1, 4, 0]
tensor([7, 5, 6, 2, 3, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 2, 5, 4, 1, 0, 1, 3]
tensor([0, 2, 5, 4, 1, 0, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1.0, 1.0, 0, 1.0, 1]
tensor([0, 1, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
Normal merging for layer 1
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Normal merging for layer 2
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 4
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 5 to 8
done!
Normal merging for layer 9
tensor([0, 5])
tensor(0)
tensor([4, 6])
tensor(4)
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
done!
Cross-layer merge completed for layers 10 to 30
done!
Normal merging for layer 31
tensor([0, 5])
tensor(0)
tensor([1, 2, 3, 4, 6, 7])
tensor(1)
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 6 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.1348 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 5 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

197
cuda:3
cb
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:57<00:57, 57.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:15<00:00, 34.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:15<00:00, 37.74s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: cb] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: cb] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
WARNING:lm_eval.api.task:[Task: cb] metric f1 is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/super_glue/super_glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue/revision/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue/revision/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue/tree/3de24cf8022e94f4ee4b9d55a6f539891524d646/cb?recursive=False&expand=False HTTP/1.1" 307 141
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue/tree/3de24cf8022e94f4ee4b9d55a6f539891524d646/cb?recursive=False&expand=False HTTP/1.1" 200 347
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:filelock:Attempting to acquire lock 140431339000160 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_cb_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 140431339000160 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_cb_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/cb/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 140431339000160 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_cb_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 140431339000160 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_cb_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Attempting to acquire lock 140437586247808 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/cb/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 140437586247808 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/cb/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/cb/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 140437586247808 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/cb/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 140437586247808 released on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/cb/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of cb from None to 0
INFO:lm_eval.api.task:Building contexts for cb on rank 0...
  0%|          | 0/56 [00:00<?, ?it/s]100%|██████████| 56/56 [00:00<00:00, 1646.52it/s]
DEBUG:lm_eval.evaluator:Task: cb; number of requests on this rank: 168
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/168 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/168 [00:02<06:27,  2.32s/it]Running loglikelihood requests:   1%|          | 2/168 [00:04<05:46,  2.09s/it]Running loglikelihood requests:   2%|▏         | 4/168 [00:06<03:39,  1.34s/it]Running loglikelihood requests:   3%|▎         | 5/168 [00:07<04:00,  1.47s/it]Running loglikelihood requests:   4%|▍         | 7/168 [00:09<03:04,  1.15s/it]Running loglikelihood requests:   5%|▍         | 8/168 [00:10<03:19,  1.25s/it]Running loglikelihood requests:   6%|▌         | 10/168 [00:12<02:37,  1.01it/s]Running loglikelihood requests:   7%|▋         | 11/168 [00:13<02:45,  1.05s/it]Running loglikelihood requests:   8%|▊         | 13/168 [00:14<02:15,  1.14it/s]Running loglikelihood requests:   8%|▊         | 14/168 [00:15<02:25,  1.06it/s]Running loglikelihood requests:  10%|▉         | 16/168 [00:17<02:04,  1.22it/s]Running loglikelihood requests:  10%|█         | 17/168 [00:18<02:18,  1.09it/s]Running loglikelihood requests:  11%|█▏        | 19/168 [00:19<01:58,  1.26it/s]Running loglikelihood requests:  12%|█▏        | 20/168 [00:20<02:10,  1.13it/s]Running loglikelihood requests:  13%|█▎        | 22/168 [00:21<01:50,  1.32it/s]Running loglikelihood requests:  14%|█▎        | 23/168 [00:22<02:00,  1.20it/s]Running loglikelihood requests:  15%|█▍        | 25/168 [00:24<01:43,  1.38it/s]Running loglikelihood requests:  15%|█▌        | 26/168 [00:25<01:53,  1.25it/s]Running loglikelihood requests:  17%|█▋        | 28/168 [00:26<01:37,  1.43it/s]Running loglikelihood requests:  17%|█▋        | 29/168 [00:27<01:47,  1.29it/s]Running loglikelihood requests:  18%|█▊        | 31/168 [00:28<01:33,  1.46it/s]Running loglikelihood requests:  19%|█▉        | 32/168 [00:29<01:43,  1.31it/s]Running loglikelihood requests:  20%|█▉        | 33/168 [00:30<01:52,  1.20it/s]Running loglikelihood requests:  21%|██        | 35/168 [00:31<01:34,  1.41it/s]Running loglikelihood requests:  22%|██▏       | 37/168 [00:32<01:23,  1.56it/s]Running loglikelihood requests:  23%|██▎       | 38/168 [00:33<01:33,  1.38it/s]Running loglikelihood requests:  24%|██▍       | 40/168 [00:34<01:22,  1.55it/s]Running loglikelihood requests:  24%|██▍       | 41/168 [00:35<01:31,  1.39it/s]Running loglikelihood requests:  26%|██▌       | 43/168 [00:36<01:20,  1.56it/s]Running loglikelihood requests:  26%|██▌       | 44/168 [00:37<01:29,  1.39it/s]Running loglikelihood requests:  27%|██▋       | 46/168 [00:38<01:17,  1.58it/s]Running loglikelihood requests:  28%|██▊       | 47/168 [00:39<01:24,  1.43it/s]Running loglikelihood requests:  29%|██▉       | 49/168 [00:40<01:12,  1.63it/s]Running loglikelihood requests:  30%|██▉       | 50/168 [00:41<01:20,  1.47it/s]Running loglikelihood requests:  30%|███       | 51/168 [00:42<01:26,  1.36it/s]Running loglikelihood requests:  31%|███       | 52/168 [00:43<01:31,  1.27it/s]Running loglikelihood requests:  32%|███▏      | 54/168 [00:44<01:14,  1.54it/s]Running loglikelihood requests:  33%|███▎      | 56/168 [00:45<01:04,  1.72it/s]Running loglikelihood requests:  35%|███▍      | 58/168 [00:46<00:59,  1.85it/s]Running loglikelihood requests:  35%|███▌      | 59/168 [00:46<01:07,  1.62it/s]Running loglikelihood requests:  36%|███▌      | 60/168 [00:47<01:13,  1.46it/s]Running loglikelihood requests:  37%|███▋      | 62/168 [00:48<01:03,  1.68it/s]Running loglikelihood requests:  38%|███▊      | 64/168 [00:49<00:56,  1.83it/s]Running loglikelihood requests:  39%|███▊      | 65/168 [00:50<01:04,  1.61it/s]Running loglikelihood requests:  40%|███▉      | 67/168 [00:51<00:56,  1.79it/s]Running loglikelihood requests:  40%|████      | 68/168 [00:52<01:03,  1.58it/s]Running loglikelihood requests:  42%|████▏     | 70/168 [00:53<00:55,  1.77it/s]Running loglikelihood requests:  42%|████▏     | 71/168 [00:54<01:01,  1.58it/s]Running loglikelihood requests:  43%|████▎     | 73/168 [00:55<00:52,  1.80it/s]Running loglikelihood requests:  44%|████▍     | 74/168 [00:55<00:58,  1.62it/s]Running loglikelihood requests:  45%|████▍     | 75/168 [00:56<01:02,  1.48it/s]Running loglikelihood requests:  45%|████▌     | 76/168 [00:57<01:06,  1.38it/s]Running loglikelihood requests:  46%|████▋     | 78/168 [00:58<00:53,  1.68it/s]Running loglikelihood requests:  48%|████▊     | 80/168 [00:59<00:47,  1.85it/s]Running loglikelihood requests:  49%|████▉     | 82/168 [01:00<00:43,  1.98it/s]Running loglikelihood requests:  49%|████▉     | 83/168 [01:01<00:49,  1.71it/s]Running loglikelihood requests:  51%|█████     | 85/168 [01:02<00:43,  1.89it/s]Running loglikelihood requests:  51%|█████     | 86/168 [01:02<00:48,  1.68it/s]Running loglikelihood requests:  52%|█████▏    | 88/168 [01:03<00:42,  1.88it/s]Running loglikelihood requests:  53%|█████▎    | 89/168 [01:04<00:47,  1.67it/s]Running loglikelihood requests:  54%|█████▎    | 90/168 [01:05<00:50,  1.53it/s]Running loglikelihood requests:  55%|█████▍    | 92/168 [01:06<00:42,  1.78it/s]Running loglikelihood requests:  56%|█████▌    | 94/168 [01:07<00:37,  1.97it/s]Running loglikelihood requests:  57%|█████▋    | 95/168 [01:07<00:41,  1.75it/s]Running loglikelihood requests:  58%|█████▊    | 97/168 [01:08<00:36,  1.95it/s]Running loglikelihood requests:  58%|█████▊    | 98/168 [01:09<00:40,  1.73it/s]Running loglikelihood requests:  60%|█████▉    | 100/168 [01:10<00:34,  1.95it/s]Running loglikelihood requests:  60%|██████    | 101/168 [01:11<00:38,  1.74it/s]Running loglikelihood requests:  61%|██████▏   | 103/168 [01:12<00:33,  1.97it/s]Running loglikelihood requests:  62%|██████▏   | 104/168 [01:12<00:36,  1.76it/s]Running loglikelihood requests:  62%|██████▎   | 105/168 [01:13<00:39,  1.61it/s]Running loglikelihood requests:  63%|██████▎   | 106/168 [01:14<00:41,  1.51it/s]Running loglikelihood requests:  64%|██████▍   | 108/168 [01:15<00:33,  1.82it/s]Running loglikelihood requests:  65%|██████▌   | 110/168 [01:15<00:28,  2.03it/s]Running loglikelihood requests:  66%|██████▌   | 111/168 [01:16<00:31,  1.80it/s]Running loglikelihood requests:  67%|██████▋   | 113/168 [01:17<00:27,  2.02it/s]Running loglikelihood requests:  68%|██████▊   | 114/168 [01:18<00:30,  1.80it/s]Running loglikelihood requests:  69%|██████▉   | 116/168 [01:19<00:25,  2.03it/s]Running loglikelihood requests:  70%|███████   | 118/168 [01:19<00:22,  2.18it/s]Running loglikelihood requests:  71%|███████   | 119/168 [01:20<00:25,  1.92it/s]Running loglikelihood requests:  71%|███████▏  | 120/168 [01:21<00:27,  1.73it/s]Running loglikelihood requests:  73%|███████▎  | 122/168 [01:22<00:23,  1.99it/s]Running loglikelihood requests:  74%|███████▍  | 124/168 [01:22<00:20,  2.16it/s]Running loglikelihood requests:  74%|███████▍  | 125/168 [01:23<00:22,  1.91it/s]Running loglikelihood requests:  76%|███████▌  | 127/168 [01:24<00:19,  2.12it/s]Running loglikelihood requests:  76%|███████▌  | 128/168 [01:25<00:21,  1.88it/s]Running loglikelihood requests:  77%|███████▋  | 129/168 [01:26<00:22,  1.71it/s]Running loglikelihood requests:  78%|███████▊  | 131/168 [01:26<00:18,  2.01it/s]Running loglikelihood requests:  79%|███████▉  | 133/168 [01:27<00:15,  2.26it/s]Running loglikelihood requests:  80%|███████▉  | 134/168 [01:28<00:16,  2.02it/s]Running loglikelihood requests:  81%|████████  | 136/168 [01:28<00:13,  2.29it/s]Running loglikelihood requests:  82%|████████▏ | 137/168 [01:29<00:15,  2.06it/s]Running loglikelihood requests:  82%|████████▏ | 138/168 [01:30<00:15,  1.90it/s]Running loglikelihood requests:  83%|████████▎ | 139/168 [01:30<00:16,  1.78it/s]Running loglikelihood requests:  83%|████████▎ | 140/168 [01:31<00:17,  1.61it/s]Running loglikelihood requests:  85%|████████▍ | 142/168 [01:32<00:13,  1.98it/s]Running loglikelihood requests:  86%|████████▌ | 144/168 [01:33<00:10,  2.25it/s]Running loglikelihood requests:  87%|████████▋ | 146/168 [01:33<00:09,  2.44it/s]Running loglikelihood requests:  88%|████████▊ | 148/168 [01:34<00:07,  2.58it/s]Running loglikelihood requests:  89%|████████▊ | 149/168 [01:35<00:08,  2.26it/s]Running loglikelihood requests:  89%|████████▉ | 150/168 [01:35<00:08,  2.03it/s]Running loglikelihood requests:  90%|█████████ | 152/168 [01:36<00:06,  2.31it/s]Running loglikelihood requests:  92%|█████████▏| 154/168 [01:37<00:05,  2.52it/s]Running loglikelihood requests:  92%|█████████▏| 155/168 [01:37<00:05,  2.23it/s]Running loglikelihood requests:  93%|█████████▎| 157/168 [01:38<00:04,  2.46it/s]Running loglikelihood requests:  94%|█████████▍| 158/168 [01:39<00:04,  2.19it/s]Running loglikelihood requests:  95%|█████████▌| 160/168 [01:39<00:03,  2.50it/s]Running loglikelihood requests:  96%|█████████▌| 161/168 [01:40<00:03,  2.26it/s]Running loglikelihood requests:  97%|█████████▋| 163/168 [01:40<00:01,  2.58it/s]Running loglikelihood requests:  98%|█████████▊| 164/168 [01:41<00:01,  2.33it/s]Running loglikelihood requests:  99%|█████████▉| 166/168 [01:41<00:00,  2.67it/s]Running loglikelihood requests:  99%|█████████▉| 167/168 [01:42<00:00,  2.41it/s]Running loglikelihood requests: 100%|██████████| 168/168 [01:42<00:00,  1.64it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:4'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:4'}
full model:
{'cb': {'alias': 'cb', 'acc,none': 0.44642857142857145, 'acc_stderr,none': 0.06703189227942397, 'f1,none': np.float64(0.2946127946127946), 'f1_stderr,none': 'N/A'}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8754479021250823
0.8035282713865031
0.9500865550679058
0.9469110267801961
0.9212663689239236
0.9365178765256775
0.671589453090406
0.6744336218334667
0.8076345549626031
0.7976470386087894
0.807072393829993
0.6600400889592184
0.7484904863798857
0.9363063771008698
0.6357711114598822
0.9166089836828051
0.6715835426958833
0.7409884813902188
0.412428535140908
0.8747283305135303
0.8491219158212996
0.9125101690232402
0.8366676259845086
0.705936129020536
0.7920385356495101
0.9243830461584077
0.9274604399644588
0.7835428130351293
0.8119111717866335
Total groups 67 exceeded the threshold, stopping comparison.
The group tensor is
[6, 3, 5, 2, 7, 1, 4, 0]
tensor([6, 3, 5, 2, 7, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 4, 7, 3, 6, 1, 2, 0]
tensor([5, 4, 7, 3, 6, 1, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 1, 6, 3, 7, 2, 4, 0]
tensor([5, 1, 6, 3, 7, 2, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 2, 0, 1, 5, 0, 1, 3]
tensor([4, 2, 0, 1, 5, 0, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[4, 3, 0, 2, 1, 1, 5, 0]
tensor([4, 3, 0, 2, 1, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 1, 2, 2, 1, 3, 0]
tensor([0, 3, 1, 2, 2, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1.0, 1.0, 0, 1.0, 1]
tensor([0, 1, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
done!
Cross-layer merge completed for layers 2 to 6
done!
Normal merging for layer 7
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 8 to 12
done!
Normal merging for layer 13
tensor([2, 5])
tensor(2)
tensor([3, 6])
tensor(3)
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Normal merging for layer 14
tensor([2, 7])
tensor(2)
tensor([4, 5])
tensor(4)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 15 to 18
done!
Normal merging for layer 19
tensor([0, 7])
tensor(0)
tensor([2, 5])
tensor(2)
tensor([3, 4])
tensor(3)
tensor([1, 6])
tensor(1)
done!
Cross-layer merge completed for layers 20 to 23
done!
Normal merging for layer 24
tensor([0, 5])
tensor(0)
tensor([1, 2, 3, 4, 6, 7])
tensor(1)
done!
Cross-layer merge completed for layers 25 to 31
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 5 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 11.9458 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 4 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

146
cuda:4
winogrande
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:54<00:54, 54.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 32.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 35.82s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/winogrande HTTP/1.1" 307 67
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/winogrande HTTP/1.1" 200 1036
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/winogrande/winogrande.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): datasets-server.hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://datasets-server.hf-mirror.com:443 "GET /parquet?dataset=winogrande HTTP/1.1" 302 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET / HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/winogrande/winogrande.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/winogrande/resolve/main/winogrande.py HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/allenai/winogrande/resolve/main/winogrande.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/winogrande/resolve/main/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/allenai/winogrande/resolve/main/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/winogrande/resolve/main/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/allenai/winogrande/resolve/main/README.md HTTP/1.1" 200 0
DEBUG:filelock:Attempting to acquire lock 140439815839744 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_winogrande_winogrande_xl_1.1.0_a826c3d3506aefe0e9e9390dcb53271070536586bab95849876b2c1743df56e2.lock
DEBUG:filelock:Lock 140439815839744 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_winogrande_winogrande_xl_1.1.0_a826c3d3506aefe0e9e9390dcb53271070536586bab95849876b2c1743df56e2.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/winogrande/winogrande_xl/1.1.0/a826c3d3506aefe0e9e9390dcb53271070536586bab95849876b2c1743df56e2/dataset_info.json
DEBUG:filelock:Attempting to release lock 140439815839744 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_winogrande_winogrande_xl_1.1.0_a826c3d3506aefe0e9e9390dcb53271070536586bab95849876b2c1743df56e2.lock
DEBUG:filelock:Lock 140439815839744 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_winogrande_winogrande_xl_1.1.0_a826c3d3506aefe0e9e9390dcb53271070536586bab95849876b2c1743df56e2.lock
DEBUG:filelock:Attempting to acquire lock 140430676188752 on /public/home/zouyifei001/.cache/huggingface/datasets/winogrande/winogrande_xl/1.1.0/a826c3d3506aefe0e9e9390dcb53271070536586bab95849876b2c1743df56e2_builder.lock
DEBUG:filelock:Lock 140430676188752 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/winogrande/winogrande_xl/1.1.0/a826c3d3506aefe0e9e9390dcb53271070536586bab95849876b2c1743df56e2_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/winogrande/winogrande_xl/1.1.0/a826c3d3506aefe0e9e9390dcb53271070536586bab95849876b2c1743df56e2/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430676188752 on /public/home/zouyifei001/.cache/huggingface/datasets/winogrande/winogrande_xl/1.1.0/a826c3d3506aefe0e9e9390dcb53271070536586bab95849876b2c1743df56e2_builder.lock
DEBUG:filelock:Lock 140430676188752 released on /public/home/zouyifei001/.cache/huggingface/datasets/winogrande/winogrande_xl/1.1.0/a826c3d3506aefe0e9e9390dcb53271070536586bab95849876b2c1743df56e2_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
DEBUG:lm_eval.api.task:doc_to_text returned an int. Assuming multiple inputs.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of winogrande from None to 0
INFO:lm_eval.api.task:Building contexts for winogrande on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 136889.82it/s]
DEBUG:lm_eval.evaluator:Task: winogrande; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:01<04:02,  1.22s/it]Running loglikelihood requests:   1%|          | 2/200 [00:01<02:42,  1.22it/s]Running loglikelihood requests:   2%|▏         | 3/200 [00:02<02:14,  1.47it/s]Running loglikelihood requests:   2%|▏         | 4/200 [00:02<02:00,  1.63it/s]Running loglikelihood requests:   2%|▎         | 5/200 [00:03<01:53,  1.71it/s]Running loglikelihood requests:   3%|▎         | 6/200 [00:03<01:47,  1.80it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:04<01:43,  1.86it/s]Running loglikelihood requests:   4%|▍         | 8/200 [00:04<01:40,  1.90it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:05<01:38,  1.94it/s]Running loglikelihood requests:   5%|▌         | 10/200 [00:05<01:37,  1.96it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:06<01:37,  1.94it/s]Running loglikelihood requests:   6%|▌         | 12/200 [00:06<01:35,  1.96it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:07<01:34,  1.98it/s]Running loglikelihood requests:   7%|▋         | 14/200 [00:07<01:33,  1.99it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:08<01:33,  1.97it/s]Running loglikelihood requests:   8%|▊         | 16/200 [00:08<01:32,  1.99it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:09<01:31,  2.01it/s]Running loglikelihood requests:   9%|▉         | 18/200 [00:09<01:30,  2.02it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:10<01:33,  1.95it/s]Running loglikelihood requests:  10%|█         | 20/200 [00:10<01:32,  1.95it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:11<01:31,  1.97it/s]Running loglikelihood requests:  11%|█         | 22/200 [00:11<01:29,  1.98it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:12<01:28,  1.99it/s]Running loglikelihood requests:  12%|█▏        | 24/200 [00:12<01:28,  2.00it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:13<01:27,  2.00it/s]Running loglikelihood requests:  13%|█▎        | 26/200 [00:13<01:26,  2.01it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:14<01:26,  2.01it/s]Running loglikelihood requests:  14%|█▍        | 28/200 [00:14<01:25,  2.01it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:15<01:24,  2.02it/s]Running loglikelihood requests:  15%|█▌        | 30/200 [00:15<01:24,  2.02it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:16<01:23,  2.03it/s]Running loglikelihood requests:  16%|█▌        | 32/200 [00:16<01:22,  2.03it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:17<01:22,  2.03it/s]Running loglikelihood requests:  17%|█▋        | 34/200 [00:17<01:21,  2.03it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:18<01:21,  2.03it/s]Running loglikelihood requests:  18%|█▊        | 36/200 [00:18<01:20,  2.04it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:19<01:19,  2.04it/s]Running loglikelihood requests:  19%|█▉        | 38/200 [00:19<01:19,  2.05it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:20<01:18,  2.05it/s]Running loglikelihood requests:  20%|██        | 40/200 [00:20<01:17,  2.05it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:21<01:17,  2.06it/s]Running loglikelihood requests:  21%|██        | 42/200 [00:21<01:16,  2.06it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:22<01:16,  2.05it/s]Running loglikelihood requests:  22%|██▏       | 44/200 [00:22<01:16,  2.05it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:23<01:15,  2.04it/s]Running loglikelihood requests:  23%|██▎       | 46/200 [00:23<01:15,  2.04it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:24<01:14,  2.04it/s]Running loglikelihood requests:  24%|██▍       | 48/200 [00:24<01:14,  2.05it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:25<01:13,  2.05it/s]Running loglikelihood requests:  25%|██▌       | 50/200 [00:25<01:13,  2.05it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:26<01:12,  2.05it/s]Running loglikelihood requests:  26%|██▌       | 52/200 [00:26<01:12,  2.04it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:27<01:13,  2.00it/s]Running loglikelihood requests:  27%|██▋       | 54/200 [00:27<01:12,  2.00it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:28<01:12,  1.99it/s]Running loglikelihood requests:  28%|██▊       | 56/200 [00:28<01:11,  2.01it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:29<01:10,  2.03it/s]Running loglikelihood requests:  29%|██▉       | 58/200 [00:29<01:09,  2.04it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:30<01:08,  2.05it/s]Running loglikelihood requests:  30%|███       | 60/200 [00:30<01:07,  2.06it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:31<01:07,  2.06it/s]Running loglikelihood requests:  31%|███       | 62/200 [00:31<01:06,  2.06it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:31<01:06,  2.06it/s]Running loglikelihood requests:  32%|███▏      | 64/200 [00:32<01:05,  2.06it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:32<01:05,  2.07it/s]Running loglikelihood requests:  33%|███▎      | 66/200 [00:33<01:04,  2.06it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:33<01:04,  2.07it/s]Running loglikelihood requests:  34%|███▍      | 68/200 [00:34<01:03,  2.06it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:34<01:03,  2.06it/s]Running loglikelihood requests:  35%|███▌      | 70/200 [00:35<01:02,  2.07it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:35<01:02,  2.06it/s]Running loglikelihood requests:  36%|███▌      | 72/200 [00:36<01:02,  2.06it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:36<01:01,  2.07it/s]Running loglikelihood requests:  37%|███▋      | 74/200 [00:37<01:00,  2.08it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:37<01:00,  2.06it/s]Running loglikelihood requests:  38%|███▊      | 76/200 [00:38<01:00,  2.06it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:38<00:59,  2.06it/s]Running loglikelihood requests:  39%|███▉      | 78/200 [00:39<00:58,  2.07it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:39<00:58,  2.06it/s]Running loglikelihood requests:  40%|████      | 80/200 [00:40<00:57,  2.07it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:40<00:58,  2.05it/s]Running loglikelihood requests:  41%|████      | 82/200 [00:41<00:57,  2.07it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:41<00:56,  2.07it/s]Running loglikelihood requests:  42%|████▏     | 84/200 [00:42<00:55,  2.08it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:42<00:54,  2.10it/s]Running loglikelihood requests:  43%|████▎     | 86/200 [00:43<00:54,  2.11it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:43<00:53,  2.11it/s]Running loglikelihood requests:  44%|████▍     | 88/200 [00:44<00:52,  2.11it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:44<00:52,  2.12it/s]Running loglikelihood requests:  45%|████▌     | 90/200 [00:44<00:51,  2.12it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:45<00:51,  2.12it/s]Running loglikelihood requests:  46%|████▌     | 92/200 [00:45<00:50,  2.12it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:46<00:50,  2.12it/s]Running loglikelihood requests:  47%|████▋     | 94/200 [00:46<00:50,  2.12it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:47<00:49,  2.12it/s]Running loglikelihood requests:  48%|████▊     | 96/200 [00:47<00:49,  2.12it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:48<00:48,  2.12it/s]Running loglikelihood requests:  49%|████▉     | 98/200 [00:48<00:48,  2.12it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:49<00:47,  2.12it/s]Running loglikelihood requests:  50%|█████     | 100/200 [00:49<00:47,  2.12it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:50<00:46,  2.13it/s]Running loglikelihood requests:  51%|█████     | 102/200 [00:50<00:45,  2.13it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:51<00:45,  2.14it/s]Running loglikelihood requests:  52%|█████▏    | 104/200 [00:51<00:44,  2.14it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:52<00:44,  2.14it/s]Running loglikelihood requests:  53%|█████▎    | 106/200 [00:52<00:43,  2.15it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:52<00:43,  2.15it/s]Running loglikelihood requests:  54%|█████▍    | 108/200 [00:53<00:42,  2.15it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:53<00:44,  2.07it/s]Running loglikelihood requests:  55%|█████▌    | 110/200 [00:54<00:43,  2.09it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:54<00:42,  2.11it/s]Running loglikelihood requests:  56%|█████▌    | 112/200 [00:55<00:41,  2.12it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:55<00:40,  2.12it/s]Running loglikelihood requests:  57%|█████▋    | 114/200 [00:56<00:40,  2.14it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:56<00:39,  2.14it/s]Running loglikelihood requests:  58%|█████▊    | 116/200 [00:57<00:39,  2.15it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:57<00:38,  2.15it/s]Running loglikelihood requests:  59%|█████▉    | 118/200 [00:58<00:38,  2.15it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:58<00:37,  2.15it/s]Running loglikelihood requests:  60%|██████    | 120/200 [00:59<00:37,  2.16it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:59<00:36,  2.16it/s]Running loglikelihood requests:  61%|██████    | 122/200 [00:59<00:36,  2.16it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [01:00<00:35,  2.16it/s]Running loglikelihood requests:  62%|██████▏   | 124/200 [01:00<00:35,  2.16it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [01:01<00:34,  2.16it/s]Running loglikelihood requests:  63%|██████▎   | 126/200 [01:01<00:34,  2.15it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [01:02<00:33,  2.16it/s]Running loglikelihood requests:  64%|██████▍   | 128/200 [01:02<00:33,  2.16it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [01:03<00:35,  1.99it/s]Running loglikelihood requests:  65%|██████▌   | 130/200 [01:03<00:34,  2.04it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [01:04<00:33,  2.08it/s]Running loglikelihood requests:  66%|██████▌   | 132/200 [01:04<00:32,  2.12it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [01:05<00:31,  2.14it/s]Running loglikelihood requests:  67%|██████▋   | 134/200 [01:05<00:30,  2.16it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [01:06<00:30,  2.16it/s]Running loglikelihood requests:  68%|██████▊   | 136/200 [01:06<00:29,  2.17it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [01:06<00:28,  2.18it/s]Running loglikelihood requests:  69%|██████▉   | 138/200 [01:07<00:28,  2.18it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [01:07<00:28,  2.17it/s]Running loglikelihood requests:  70%|███████   | 140/200 [01:08<00:27,  2.17it/s]Running loglikelihood requests:  70%|███████   | 141/200 [01:08<00:27,  2.18it/s]Running loglikelihood requests:  71%|███████   | 142/200 [01:09<00:26,  2.18it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [01:09<00:26,  2.19it/s]Running loglikelihood requests:  72%|███████▏  | 144/200 [01:10<00:25,  2.19it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [01:10<00:25,  2.19it/s]Running loglikelihood requests:  73%|███████▎  | 146/200 [01:11<00:24,  2.19it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [01:11<00:24,  2.19it/s]Running loglikelihood requests:  74%|███████▍  | 148/200 [01:12<00:23,  2.20it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [01:12<00:23,  2.20it/s]Running loglikelihood requests:  75%|███████▌  | 150/200 [01:12<00:22,  2.21it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [01:13<00:22,  2.20it/s]Running loglikelihood requests:  76%|███████▌  | 152/200 [01:13<00:21,  2.21it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [01:14<00:21,  2.21it/s]Running loglikelihood requests:  77%|███████▋  | 154/200 [01:14<00:20,  2.22it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [01:15<00:20,  2.22it/s]Running loglikelihood requests:  78%|███████▊  | 156/200 [01:15<00:19,  2.22it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [01:16<00:19,  2.22it/s]Running loglikelihood requests:  79%|███████▉  | 158/200 [01:16<00:18,  2.22it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [01:16<00:18,  2.22it/s]Running loglikelihood requests:  80%|████████  | 160/200 [01:17<00:18,  2.21it/s]Running loglikelihood requests:  80%|████████  | 161/200 [01:17<00:17,  2.21it/s]Running loglikelihood requests:  81%|████████  | 162/200 [01:18<00:17,  2.21it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [01:18<00:16,  2.21it/s]Running loglikelihood requests:  82%|████████▏ | 164/200 [01:19<00:16,  2.22it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [01:19<00:15,  2.23it/s]Running loglikelihood requests:  83%|████████▎ | 166/200 [01:20<00:15,  2.24it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [01:20<00:14,  2.24it/s]Running loglikelihood requests:  84%|████████▍ | 168/200 [01:21<00:14,  2.24it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [01:21<00:13,  2.24it/s]Running loglikelihood requests:  85%|████████▌ | 170/200 [01:21<00:13,  2.24it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [01:22<00:12,  2.25it/s]Running loglikelihood requests:  86%|████████▌ | 172/200 [01:22<00:12,  2.24it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [01:23<00:12,  2.24it/s]Running loglikelihood requests:  87%|████████▋ | 174/200 [01:23<00:11,  2.24it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [01:24<00:11,  2.24it/s]Running loglikelihood requests:  88%|████████▊ | 176/200 [01:24<00:10,  2.24it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [01:25<00:10,  2.25it/s]Running loglikelihood requests:  89%|████████▉ | 178/200 [01:25<00:09,  2.25it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [01:25<00:09,  2.26it/s]Running loglikelihood requests:  90%|█████████ | 180/200 [01:26<00:08,  2.27it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [01:26<00:08,  2.28it/s]Running loglikelihood requests:  91%|█████████ | 182/200 [01:27<00:07,  2.28it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [01:27<00:07,  2.29it/s]Running loglikelihood requests:  92%|█████████▏| 184/200 [01:28<00:06,  2.29it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [01:28<00:06,  2.29it/s]Running loglikelihood requests:  93%|█████████▎| 186/200 [01:28<00:06,  2.29it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [01:29<00:05,  2.29it/s]Running loglikelihood requests:  94%|█████████▍| 188/200 [01:29<00:05,  2.29it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [01:30<00:04,  2.29it/s]Running loglikelihood requests:  95%|█████████▌| 190/200 [01:30<00:04,  2.31it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [01:31<00:03,  2.33it/s]Running loglikelihood requests:  96%|█████████▌| 192/200 [01:31<00:03,  2.34it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [01:31<00:02,  2.34it/s]Running loglikelihood requests:  97%|█████████▋| 194/200 [01:32<00:02,  2.34it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:32<00:02,  2.34it/s]Running loglikelihood requests:  98%|█████████▊| 196/200 [01:33<00:01,  2.34it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:33<00:01,  2.34it/s]Running loglikelihood requests:  99%|█████████▉| 198/200 [01:34<00:00,  2.34it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:34<00:00,  2.35it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:34<00:00,  2.35it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:34<00:00,  2.11it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:5'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:5'}
full model:
{'winogrande': {'alias': 'winogrande', 'acc,none': 0.69, 'acc_stderr,none': 0.046482319871173176}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9565474555896152
0.9256436871263655
0.919777800952949
0.8502516827829548
0.9788217808920475
0.7842184683361061
0.5847175538207384
0.7741211354638314
0.8734705119073022
0.9731317123565076
0.9046875380381674
0.8858535931048256
0.9314298098713261
0.8442403312485581
0.7166029053748131
0.7061450250233585
0.7563059483803782
0.6877563559653158
0.8738989590810852
0.784285727893607
0.8409178900131131
0.8425380927376759
0.6782655591765769
0.7228968829640015
0.8418686487797186
0.9141168065903919
0.8562481461255738
0.6139553840231665
0.934088538459943
Total groups 66 exceeded the threshold, stopping comparison.
The group tensor is
[6, 2, 4, 3, 5, 1, 7, 0]
tensor([6, 2, 4, 3, 5, 1, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 2, 3, 1, 5, 4, 7, 0]
tensor([6, 2, 3, 1, 5, 4, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 4, 1, 0, 3, 0, 1, 2]
tensor([5, 4, 1, 0, 3, 0, 1, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 2, 3, 1, 4, 5, 1, 0]
tensor([0, 2, 3, 1, 4, 5, 1, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[5, 1, 2, 3, 4, 0, 1, 0]
tensor([5, 1, 2, 3, 4, 0, 1, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 2, 1, 1, 2, 3, 3, 0]
tensor([0, 2, 1, 1, 2, 3, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1, 1.0, 1.0, 1.0, 1.0, 0]
tensor([0, 1, 1, 1, 1, 1, 1, 0], dtype=torch.int32)
[0, 1]
The group tensor is
[0, 1, 1.0, 0, 1.0, 1.0, 1.0, 1]
tensor([0, 1, 1, 0, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 2 to 7
done!
Normal merging for layer 8
tensor([3, 5])
tensor(3)
tensor([2, 6])
tensor(2)
tensor([7])
tensor(7)
tensor([4])
tensor(4)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 9 to 13
done!
Normal merging for layer 14
tensor([0, 7])
tensor(0)
tensor([3, 6])
tensor(3)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
tensor([5])
tensor(5)
done!
Normal merging for layer 15
tensor([5, 7])
tensor(5)
tensor([1, 6])
tensor(1)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
done!
Normal merging for layer 16
tensor([0, 7])
tensor(0)
tensor([2, 3])
tensor(2)
tensor([1, 4])
tensor(1)
tensor([5, 6])
tensor(5)
done!
Cross-layer merge completed for layers 17 to 23
done!
Normal merging for layer 24
tensor([0, 7])
tensor(0)
tensor([1, 2, 3, 4, 5, 6])
tensor(1)
done!
Normal merging for layer 25
tensor([0, 3])
tensor(0)
tensor([1, 2, 4, 5, 6, 7])
tensor(1)
done!
Cross-layer merge completed for layers 26 to 31
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 4 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 11.8828 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 3 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

209
cuda:5
cb
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:58<00:58, 58.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:14<00:00, 33.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:14<00:00, 37.45s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: cb] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: cb] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
WARNING:lm_eval.api.task:[Task: cb] metric f1 is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/super_glue/super_glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:filelock:Attempting to acquire lock 140430455432848 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_cb_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 140430455432848 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_cb_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/cb/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430455432848 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_cb_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 140430455432848 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_cb_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Attempting to acquire lock 140431074194496 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/cb/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 140431074194496 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/cb/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/cb/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 140431074194496 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/cb/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 140431074194496 released on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/cb/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of cb from None to 0
INFO:lm_eval.api.task:Building contexts for cb on rank 0...
  0%|          | 0/56 [00:00<?, ?it/s]100%|██████████| 56/56 [00:00<00:00, 2136.99it/s]
DEBUG:lm_eval.evaluator:Task: cb; number of requests on this rank: 168
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/168 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/168 [00:02<06:23,  2.29s/it]Running loglikelihood requests:   1%|          | 2/168 [00:03<05:22,  1.94s/it]Running loglikelihood requests:   2%|▏         | 4/168 [00:05<03:24,  1.25s/it]Running loglikelihood requests:   3%|▎         | 5/168 [00:07<03:44,  1.38s/it]Running loglikelihood requests:   4%|▍         | 7/168 [00:08<02:54,  1.08s/it]Running loglikelihood requests:   5%|▍         | 8/168 [00:10<03:08,  1.18s/it]Running loglikelihood requests:   6%|▌         | 10/168 [00:11<02:29,  1.05it/s]Running loglikelihood requests:   7%|▋         | 11/168 [00:12<02:39,  1.01s/it]Running loglikelihood requests:   8%|▊         | 13/168 [00:13<02:11,  1.18it/s]Running loglikelihood requests:   8%|▊         | 14/168 [00:15<02:22,  1.08it/s]Running loglikelihood requests:  10%|▉         | 16/168 [00:16<02:00,  1.26it/s]Running loglikelihood requests:  10%|█         | 17/168 [00:17<02:12,  1.14it/s]Running loglikelihood requests:  11%|█▏        | 19/168 [00:18<01:55,  1.29it/s]Running loglikelihood requests:  12%|█▏        | 20/168 [00:19<02:05,  1.18it/s]Running loglikelihood requests:  13%|█▎        | 22/168 [00:20<01:45,  1.38it/s]Running loglikelihood requests:  14%|█▎        | 23/168 [00:21<01:55,  1.26it/s]Running loglikelihood requests:  15%|█▍        | 25/168 [00:22<01:38,  1.46it/s]Running loglikelihood requests:  15%|█▌        | 26/168 [00:24<01:47,  1.32it/s]Running loglikelihood requests:  17%|█▋        | 28/168 [00:25<01:32,  1.51it/s]Running loglikelihood requests:  17%|█▋        | 29/168 [00:26<01:41,  1.36it/s]Running loglikelihood requests:  18%|█▊        | 31/168 [00:27<01:28,  1.55it/s]Running loglikelihood requests:  19%|█▉        | 32/168 [00:27<01:37,  1.39it/s]Running loglikelihood requests:  20%|█▉        | 33/168 [00:29<01:47,  1.26it/s]Running loglikelihood requests:  21%|██        | 35/168 [00:30<01:31,  1.46it/s]Running loglikelihood requests:  22%|██▏       | 37/168 [00:31<01:21,  1.61it/s]Running loglikelihood requests:  23%|██▎       | 38/168 [00:32<01:30,  1.44it/s]Running loglikelihood requests:  24%|██▍       | 40/168 [00:33<01:19,  1.62it/s]Running loglikelihood requests:  24%|██▍       | 41/168 [00:34<01:27,  1.45it/s]Running loglikelihood requests:  26%|██▌       | 43/168 [00:34<01:16,  1.63it/s]Running loglikelihood requests:  26%|██▌       | 44/168 [00:35<01:24,  1.46it/s]Running loglikelihood requests:  27%|██▋       | 46/168 [00:36<01:12,  1.67it/s]Running loglikelihood requests:  28%|██▊       | 47/168 [00:37<01:20,  1.51it/s]Running loglikelihood requests:  29%|██▉       | 49/168 [00:38<01:08,  1.73it/s]Running loglikelihood requests:  30%|██▉       | 50/168 [00:39<01:15,  1.56it/s]Running loglikelihood requests:  30%|███       | 51/168 [00:40<01:22,  1.42it/s]Running loglikelihood requests:  31%|███       | 52/168 [00:41<01:27,  1.32it/s]Running loglikelihood requests:  32%|███▏      | 54/168 [00:42<01:11,  1.59it/s]Running loglikelihood requests:  33%|███▎      | 56/168 [00:43<01:03,  1.76it/s]Running loglikelihood requests:  35%|███▍      | 58/168 [00:44<00:58,  1.89it/s]Running loglikelihood requests:  35%|███▌      | 59/168 [00:44<01:05,  1.66it/s]Running loglikelihood requests:  36%|███▌      | 60/168 [00:45<01:12,  1.50it/s]Running loglikelihood requests:  37%|███▋      | 62/168 [00:46<01:01,  1.72it/s]Running loglikelihood requests:  38%|███▊      | 64/168 [00:47<00:55,  1.87it/s]Running loglikelihood requests:  39%|███▊      | 65/168 [00:48<01:02,  1.65it/s]Running loglikelihood requests:  40%|███▉      | 67/168 [00:49<00:55,  1.82it/s]Running loglikelihood requests:  40%|████      | 68/168 [00:50<01:01,  1.63it/s]Running loglikelihood requests:  42%|████▏     | 70/168 [00:51<00:53,  1.82it/s]Running loglikelihood requests:  42%|████▏     | 71/168 [00:52<01:00,  1.62it/s]Running loglikelihood requests:  43%|████▎     | 73/168 [00:52<00:52,  1.82it/s]Running loglikelihood requests:  44%|████▍     | 74/168 [00:53<00:58,  1.61it/s]Running loglikelihood requests:  45%|████▍     | 75/168 [00:54<01:02,  1.48it/s]Running loglikelihood requests:  45%|████▌     | 76/168 [00:55<01:06,  1.39it/s]Running loglikelihood requests:  46%|████▋     | 78/168 [00:56<00:54,  1.65it/s]Running loglikelihood requests:  48%|████▊     | 80/168 [00:57<00:47,  1.84it/s]Running loglikelihood requests:  49%|████▉     | 82/168 [00:58<00:43,  1.98it/s]Running loglikelihood requests:  49%|████▉     | 83/168 [00:59<00:49,  1.73it/s]Running loglikelihood requests:  51%|█████     | 85/168 [00:59<00:43,  1.92it/s]Running loglikelihood requests:  51%|█████     | 86/168 [01:00<00:48,  1.70it/s]Running loglikelihood requests:  52%|█████▏    | 88/168 [01:01<00:41,  1.91it/s]Running loglikelihood requests:  53%|█████▎    | 89/168 [01:02<00:46,  1.70it/s]Running loglikelihood requests:  54%|█████▎    | 90/168 [01:03<00:50,  1.55it/s]Running loglikelihood requests:  55%|█████▍    | 92/168 [01:04<00:42,  1.81it/s]Running loglikelihood requests:  56%|█████▌    | 94/168 [01:04<00:37,  2.00it/s]Running loglikelihood requests:  57%|█████▋    | 95/168 [01:05<00:41,  1.77it/s]Running loglikelihood requests:  58%|█████▊    | 97/168 [01:06<00:35,  1.97it/s]Running loglikelihood requests:  58%|█████▊    | 98/168 [01:07<00:39,  1.78it/s]Running loglikelihood requests:  60%|█████▉    | 100/168 [01:08<00:33,  2.02it/s]Running loglikelihood requests:  60%|██████    | 101/168 [01:08<00:36,  1.81it/s]Running loglikelihood requests:  61%|██████▏   | 103/168 [01:09<00:31,  2.06it/s]Running loglikelihood requests:  62%|██████▏   | 104/168 [01:10<00:34,  1.85it/s]Running loglikelihood requests:  62%|██████▎   | 105/168 [01:11<00:37,  1.69it/s]Running loglikelihood requests:  63%|██████▎   | 106/168 [01:11<00:38,  1.59it/s]Running loglikelihood requests:  64%|██████▍   | 108/168 [01:12<00:31,  1.91it/s]Running loglikelihood requests:  65%|██████▌   | 110/168 [01:13<00:27,  2.15it/s]Running loglikelihood requests:  66%|██████▌   | 111/168 [01:14<00:29,  1.91it/s]Running loglikelihood requests:  67%|██████▋   | 113/168 [01:14<00:26,  2.10it/s]Running loglikelihood requests:  68%|██████▊   | 114/168 [01:15<00:28,  1.88it/s]Running loglikelihood requests:  69%|██████▉   | 116/168 [01:16<00:24,  2.12it/s]Running loglikelihood requests:  70%|███████   | 118/168 [01:17<00:21,  2.30it/s]Running loglikelihood requests:  71%|███████   | 119/168 [01:17<00:24,  2.02it/s]Running loglikelihood requests:  71%|███████▏  | 120/168 [01:18<00:26,  1.83it/s]Running loglikelihood requests:  73%|███████▎  | 122/168 [01:19<00:22,  2.01it/s]Running loglikelihood requests:  74%|███████▍  | 124/168 [01:20<00:19,  2.22it/s]Running loglikelihood requests:  74%|███████▍  | 125/168 [01:20<00:22,  1.94it/s]Running loglikelihood requests:  76%|███████▌  | 127/168 [01:21<00:19,  2.16it/s]Running loglikelihood requests:  76%|███████▌  | 128/168 [01:22<00:21,  1.90it/s]Running loglikelihood requests:  77%|███████▋  | 129/168 [01:23<00:22,  1.76it/s]Running loglikelihood requests:  78%|███████▊  | 131/168 [01:23<00:17,  2.06it/s]Running loglikelihood requests:  79%|███████▉  | 133/168 [01:24<00:15,  2.31it/s]Running loglikelihood requests:  80%|███████▉  | 134/168 [01:25<00:16,  2.07it/s]Running loglikelihood requests:  81%|████████  | 136/168 [01:25<00:13,  2.34it/s]Running loglikelihood requests:  82%|████████▏ | 137/168 [01:26<00:14,  2.07it/s]Running loglikelihood requests:  82%|████████▏ | 138/168 [01:27<00:15,  1.89it/s]Running loglikelihood requests:  83%|████████▎ | 139/168 [01:27<00:16,  1.75it/s]Running loglikelihood requests:  83%|████████▎ | 140/168 [01:28<00:16,  1.66it/s]Running loglikelihood requests:  85%|████████▍ | 142/168 [01:29<00:12,  2.03it/s]Running loglikelihood requests:  86%|████████▌ | 144/168 [01:29<00:10,  2.30it/s]Running loglikelihood requests:  87%|████████▋ | 146/168 [01:30<00:08,  2.48it/s]Running loglikelihood requests:  88%|████████▊ | 148/168 [01:31<00:07,  2.60it/s]Running loglikelihood requests:  89%|████████▊ | 149/168 [01:31<00:08,  2.29it/s]Running loglikelihood requests:  89%|████████▉ | 150/168 [01:32<00:08,  2.04it/s]Running loglikelihood requests:  90%|█████████ | 152/168 [01:33<00:06,  2.34it/s]Running loglikelihood requests:  92%|█████████▏| 154/168 [01:33<00:05,  2.56it/s]Running loglikelihood requests:  92%|█████████▏| 155/168 [01:34<00:05,  2.24it/s]Running loglikelihood requests:  93%|█████████▎| 157/168 [01:35<00:04,  2.50it/s]Running loglikelihood requests:  94%|█████████▍| 158/168 [01:35<00:04,  2.22it/s]Running loglikelihood requests:  95%|█████████▌| 160/168 [01:36<00:03,  2.54it/s]Running loglikelihood requests:  96%|█████████▌| 161/168 [01:37<00:03,  2.30it/s]Running loglikelihood requests:  97%|█████████▋| 163/168 [01:37<00:01,  2.64it/s]Running loglikelihood requests:  98%|█████████▊| 164/168 [01:38<00:01,  2.38it/s]Running loglikelihood requests:  99%|█████████▉| 166/168 [01:38<00:00,  2.72it/s]Running loglikelihood requests:  99%|█████████▉| 167/168 [01:39<00:00,  2.45it/s]Running loglikelihood requests: 100%|██████████| 168/168 [01:39<00:00,  1.69it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:6'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:6'}
full model:
{'cb': {'alias': 'cb', 'acc,none': 0.44642857142857145, 'acc_stderr,none': 0.06703189227942397, 'f1,none': np.float64(0.2946127946127946), 'f1_stderr,none': 'N/A'}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8754479021250823
0.8035282713865031
0.9500865550679058
0.9469110267801961
0.9212663689239236
0.9365178765256775
0.671589453090406
0.6744336218334667
0.8076345549626031
0.7976470386087894
0.807072393829993
0.6600400889592184
0.7484904863798857
0.9363063771008698
0.6357711114598822
0.9166089836828051
0.6715835426958833
0.7409884813902188
0.412428535140908
0.8747283305135303
0.8491219158212996
0.9125101690232402
0.8366676259845086
0.705936129020536
0.7920385356495101
0.9243830461584077
0.9274604399644588
0.7835428130351293
0.8119111717866335
Total groups 67 exceeded the threshold, stopping comparison.
The group tensor is
[6, 3, 5, 2, 7, 1, 4, 0]
tensor([6, 3, 5, 2, 7, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 4, 7, 3, 6, 1, 2, 0]
tensor([5, 4, 7, 3, 6, 1, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 1, 6, 3, 7, 2, 4, 0]
tensor([5, 1, 6, 3, 7, 2, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 2, 0, 1, 5, 0, 1, 3]
tensor([4, 2, 0, 1, 5, 0, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[4, 3, 0, 2, 1, 1, 5, 0]
tensor([4, 3, 0, 2, 1, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 1, 2, 2, 1, 3, 0]
tensor([0, 3, 1, 2, 2, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1.0, 1.0, 0, 1.0, 1]
tensor([0, 1, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
done!
Cross-layer merge completed for layers 2 to 6
done!
Normal merging for layer 7
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 8 to 12
done!
Normal merging for layer 13
tensor([2, 5])
tensor(2)
tensor([3, 6])
tensor(3)
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Normal merging for layer 14
tensor([2, 7])
tensor(2)
tensor([4, 5])
tensor(4)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 15 to 18
done!
Normal merging for layer 19
tensor([0, 7])
tensor(0)
tensor([2, 5])
tensor(2)
tensor([3, 4])
tensor(3)
tensor([1, 6])
tensor(1)
done!
Cross-layer merge completed for layers 20 to 23
done!
Normal merging for layer 24
tensor([0, 5])
tensor(0)
tensor([1, 2, 3, 4, 6, 7])
tensor(1)
done!
Cross-layer merge completed for layers 25 to 31
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 3 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 11.9458 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 2 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

176
cuda:6
logiqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:55<00:55, 55.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:10<00:00, 31.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:10<00:00, 35.45s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/logiqa HTTP/1.1" 200 743
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/EleutherAI/logiqa/EleutherAI/logiqa.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): datasets-server.hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://datasets-server.hf-mirror.com:443 "GET /parquet?dataset=EleutherAI/logiqa HTTP/1.1" 302 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET / HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/EleutherAI/logiqa/EleutherAI/logiqa.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/logiqa/resolve/main/logiqa.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/logiqa/resolve/main/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/logiqa/resolve/main/README.md HTTP/1.1" 200 0
DEBUG:filelock:Attempting to acquire lock 140439805070368 on /public/home/zouyifei001/.cache/huggingface/modules/datasets_modules/datasets/EleutherAI--logiqa.lock
DEBUG:filelock:Lock 140439805070368 acquired on /public/home/zouyifei001/.cache/huggingface/modules/datasets_modules/datasets/EleutherAI--logiqa.lock
DEBUG:filelock:Attempting to release lock 140439805070368 on /public/home/zouyifei001/.cache/huggingface/modules/datasets_modules/datasets/EleutherAI--logiqa.lock
DEBUG:filelock:Lock 140439805070368 released on /public/home/zouyifei001/.cache/huggingface/modules/datasets_modules/datasets/EleutherAI--logiqa.lock
DEBUG:filelock:Attempting to acquire lock 140438521838336 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___logiqa_logiqa_0.0.1_5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81.lock
DEBUG:filelock:Lock 140438521838336 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___logiqa_logiqa_0.0.1_5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___logiqa/logiqa/0.0.1/5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81/dataset_info.json
DEBUG:filelock:Attempting to release lock 140438521838336 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___logiqa_logiqa_0.0.1_5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81.lock
DEBUG:filelock:Lock 140438521838336 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___logiqa_logiqa_0.0.1_5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81.lock
DEBUG:filelock:Attempting to acquire lock 140430961284000 on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___logiqa/logiqa/0.0.1/5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81_builder.lock
DEBUG:filelock:Lock 140430961284000 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___logiqa/logiqa/0.0.1/5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___logiqa/logiqa/0.0.1/5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430961284000 on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___logiqa/logiqa/0.0.1/5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81_builder.lock
DEBUG:filelock:Lock 140430961284000 released on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___logiqa/logiqa/0.0.1/5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of logiqa from None to 0
INFO:lm_eval.api.task:Building contexts for logiqa on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1651.89it/s]
DEBUG:lm_eval.evaluator:Task: logiqa; number of requests on this rank: 400
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/400 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/400 [00:02<19:47,  2.98s/it]Running loglikelihood requests:   0%|          | 2/400 [00:05<17:02,  2.57s/it]Running loglikelihood requests:   1%|          | 3/400 [00:07<16:03,  2.43s/it]Running loglikelihood requests:   1%|          | 4/400 [00:09<15:28,  2.35s/it]Running loglikelihood requests:   1%|▏         | 5/400 [00:11<15:04,  2.29s/it]Running loglikelihood requests:   2%|▏         | 6/400 [00:14<14:47,  2.25s/it]Running loglikelihood requests:   2%|▏         | 7/400 [00:16<14:36,  2.23s/it]Running loglikelihood requests:   2%|▏         | 8/400 [00:18<14:27,  2.21s/it]Running loglikelihood requests:   2%|▏         | 9/400 [00:20<14:18,  2.19s/it]Running loglikelihood requests:   2%|▎         | 10/400 [00:22<14:09,  2.18s/it]Running loglikelihood requests:   3%|▎         | 11/400 [00:24<13:59,  2.16s/it]Running loglikelihood requests:   3%|▎         | 12/400 [00:26<13:46,  2.13s/it]Running loglikelihood requests:   3%|▎         | 13/400 [00:29<13:36,  2.11s/it]Running loglikelihood requests:   4%|▎         | 14/400 [00:31<13:27,  2.09s/it]Running loglikelihood requests:   4%|▍         | 15/400 [00:33<13:20,  2.08s/it]Running loglikelihood requests:   4%|▍         | 16/400 [00:35<13:14,  2.07s/it]Running loglikelihood requests:   4%|▍         | 17/400 [00:37<13:11,  2.07s/it]Running loglikelihood requests:   4%|▍         | 18/400 [00:39<13:05,  2.06s/it]Running loglikelihood requests:   5%|▍         | 19/400 [00:41<13:07,  2.07s/it]Running loglikelihood requests:   5%|▌         | 20/400 [00:43<12:59,  2.05s/it]Running loglikelihood requests:   5%|▌         | 21/400 [00:45<12:50,  2.03s/it]Running loglikelihood requests:   6%|▌         | 22/400 [00:47<12:43,  2.02s/it]Running loglikelihood requests:   6%|▌         | 23/400 [00:49<12:40,  2.02s/it]Running loglikelihood requests:   6%|▌         | 24/400 [00:51<12:34,  2.01s/it]Running loglikelihood requests:   6%|▋         | 25/400 [00:53<12:28,  2.00s/it]Running loglikelihood requests:   6%|▋         | 26/400 [00:55<12:21,  1.98s/it]Running loglikelihood requests:   7%|▋         | 27/400 [00:57<12:15,  1.97s/it]Running loglikelihood requests:   7%|▋         | 28/400 [00:59<12:11,  1.97s/it]Running loglikelihood requests:   7%|▋         | 29/400 [01:01<12:04,  1.95s/it]Running loglikelihood requests:   8%|▊         | 30/400 [01:02<11:59,  1.94s/it]Running loglikelihood requests:   8%|▊         | 31/400 [01:04<11:54,  1.94s/it]Running loglikelihood requests:   8%|▊         | 32/400 [01:06<11:50,  1.93s/it]Running loglikelihood requests:   8%|▊         | 33/400 [01:08<11:46,  1.92s/it]Running loglikelihood requests:   8%|▊         | 34/400 [01:10<11:42,  1.92s/it]Running loglikelihood requests:   9%|▉         | 35/400 [01:12<11:38,  1.92s/it]Running loglikelihood requests:   9%|▉         | 36/400 [01:14<11:35,  1.91s/it]Running loglikelihood requests:   9%|▉         | 37/400 [01:16<11:29,  1.90s/it]Running loglikelihood requests:  10%|▉         | 38/400 [01:18<11:23,  1.89s/it]Running loglikelihood requests:  10%|▉         | 39/400 [01:20<11:18,  1.88s/it]Running loglikelihood requests:  10%|█         | 40/400 [01:21<11:13,  1.87s/it]Running loglikelihood requests:  10%|█         | 41/400 [01:23<11:09,  1.87s/it]Running loglikelihood requests:  10%|█         | 42/400 [01:25<11:06,  1.86s/it]Running loglikelihood requests:  11%|█         | 43/400 [01:27<11:02,  1.86s/it]Running loglikelihood requests:  11%|█         | 44/400 [01:29<10:58,  1.85s/it]Running loglikelihood requests:  11%|█▏        | 45/400 [01:31<10:57,  1.85s/it]Running loglikelihood requests:  12%|█▏        | 46/400 [01:32<10:53,  1.85s/it]Running loglikelihood requests:  12%|█▏        | 47/400 [01:34<10:48,  1.84s/it]Running loglikelihood requests:  12%|█▏        | 48/400 [01:36<10:45,  1.83s/it]Running loglikelihood requests:  12%|█▏        | 49/400 [01:38<10:41,  1.83s/it]Running loglikelihood requests:  12%|█▎        | 50/400 [01:40<10:38,  1.82s/it]Running loglikelihood requests:  13%|█▎        | 51/400 [01:42<10:36,  1.82s/it]Running loglikelihood requests:  13%|█▎        | 52/400 [01:43<10:33,  1.82s/it]Running loglikelihood requests:  13%|█▎        | 53/400 [01:45<10:31,  1.82s/it]Running loglikelihood requests:  14%|█▎        | 54/400 [01:47<10:28,  1.82s/it]Running loglikelihood requests:  14%|█▍        | 55/400 [01:49<10:28,  1.82s/it]Running loglikelihood requests:  14%|█▍        | 56/400 [01:51<10:25,  1.82s/it]Running loglikelihood requests:  14%|█▍        | 57/400 [01:52<10:21,  1.81s/it]Running loglikelihood requests:  14%|█▍        | 58/400 [01:54<10:17,  1.81s/it]Running loglikelihood requests:  15%|█▍        | 59/400 [01:56<10:15,  1.80s/it]Running loglikelihood requests:  15%|█▌        | 60/400 [01:58<10:10,  1.80s/it]Running loglikelihood requests:  15%|█▌        | 61/400 [02:00<10:04,  1.78s/it]Running loglikelihood requests:  16%|█▌        | 62/400 [02:01<09:59,  1.77s/it]Running loglikelihood requests:  16%|█▌        | 63/400 [02:03<09:54,  1.76s/it]Running loglikelihood requests:  16%|█▌        | 64/400 [02:05<09:50,  1.76s/it]Running loglikelihood requests:  16%|█▋        | 65/400 [02:07<09:45,  1.75s/it]Running loglikelihood requests:  16%|█▋        | 66/400 [02:08<09:41,  1.74s/it]Running loglikelihood requests:  17%|█▋        | 67/400 [02:10<09:36,  1.73s/it]Running loglikelihood requests:  17%|█▋        | 68/400 [02:12<09:32,  1.72s/it]Running loglikelihood requests:  17%|█▋        | 69/400 [02:13<09:27,  1.71s/it]Running loglikelihood requests:  18%|█▊        | 70/400 [02:15<09:23,  1.71s/it]Running loglikelihood requests:  18%|█▊        | 71/400 [02:17<09:20,  1.70s/it]Running loglikelihood requests:  18%|█▊        | 72/400 [02:18<09:16,  1.70s/it]Running loglikelihood requests:  18%|█▊        | 73/400 [02:20<09:11,  1.69s/it]Running loglikelihood requests:  18%|█▊        | 74/400 [02:22<09:10,  1.69s/it]Running loglikelihood requests:  19%|█▉        | 75/400 [02:23<09:05,  1.68s/it]Running loglikelihood requests:  19%|█▉        | 76/400 [02:25<09:00,  1.67s/it]Running loglikelihood requests:  19%|█▉        | 77/400 [02:27<08:55,  1.66s/it]Running loglikelihood requests:  20%|█▉        | 78/400 [02:28<08:51,  1.65s/it]Running loglikelihood requests:  20%|█▉        | 79/400 [02:30<08:46,  1.64s/it]Running loglikelihood requests:  20%|██        | 80/400 [02:32<08:42,  1.63s/it]Running loglikelihood requests:  20%|██        | 81/400 [02:33<08:37,  1.62s/it]Running loglikelihood requests:  20%|██        | 82/400 [02:35<08:33,  1.61s/it]Running loglikelihood requests:  21%|██        | 83/400 [02:36<08:29,  1.61s/it]Running loglikelihood requests:  21%|██        | 84/400 [02:38<08:25,  1.60s/it]Running loglikelihood requests:  21%|██▏       | 85/400 [02:40<08:22,  1.59s/it]Running loglikelihood requests:  22%|██▏       | 86/400 [02:41<08:19,  1.59s/it]Running loglikelihood requests:  22%|██▏       | 87/400 [02:43<08:16,  1.59s/it]Running loglikelihood requests:  22%|██▏       | 88/400 [02:44<08:13,  1.58s/it]Running loglikelihood requests:  22%|██▏       | 89/400 [02:46<08:12,  1.58s/it]Running loglikelihood requests:  22%|██▎       | 90/400 [02:47<08:09,  1.58s/it]Running loglikelihood requests:  23%|██▎       | 91/400 [02:49<08:08,  1.58s/it]Running loglikelihood requests:  23%|██▎       | 92/400 [02:51<08:06,  1.58s/it]Running loglikelihood requests:  23%|██▎       | 93/400 [02:52<08:04,  1.58s/it]Running loglikelihood requests:  24%|██▎       | 94/400 [02:54<08:02,  1.58s/it]Running loglikelihood requests:  24%|██▍       | 95/400 [02:55<08:00,  1.57s/it]Running loglikelihood requests:  24%|██▍       | 96/400 [02:57<07:58,  1.57s/it]Running loglikelihood requests:  24%|██▍       | 97/400 [02:58<07:54,  1.57s/it]Running loglikelihood requests:  24%|██▍       | 98/400 [03:00<07:50,  1.56s/it]Running loglikelihood requests:  25%|██▍       | 99/400 [03:02<07:48,  1.56s/it]Running loglikelihood requests:  25%|██▌       | 100/400 [03:03<07:45,  1.55s/it]Running loglikelihood requests:  25%|██▌       | 101/400 [03:05<07:43,  1.55s/it]Running loglikelihood requests:  26%|██▌       | 102/400 [03:06<07:43,  1.55s/it]Running loglikelihood requests:  26%|██▌       | 103/400 [03:08<07:40,  1.55s/it]Running loglikelihood requests:  26%|██▌       | 104/400 [03:09<07:38,  1.55s/it]Running loglikelihood requests:  26%|██▋       | 105/400 [03:11<07:36,  1.55s/it]Running loglikelihood requests:  26%|██▋       | 106/400 [03:12<07:34,  1.55s/it]Running loglikelihood requests:  27%|██▋       | 107/400 [03:14<07:31,  1.54s/it]Running loglikelihood requests:  27%|██▋       | 108/400 [03:15<07:29,  1.54s/it]Running loglikelihood requests:  27%|██▋       | 109/400 [03:17<07:26,  1.54s/it]Running loglikelihood requests:  28%|██▊       | 110/400 [03:18<07:24,  1.53s/it]Running loglikelihood requests:  28%|██▊       | 111/400 [03:20<07:22,  1.53s/it]Running loglikelihood requests:  28%|██▊       | 112/400 [03:22<07:20,  1.53s/it]Running loglikelihood requests:  28%|██▊       | 113/400 [03:23<07:18,  1.53s/it]Running loglikelihood requests:  28%|██▊       | 114/400 [03:25<07:15,  1.52s/it]Running loglikelihood requests:  29%|██▉       | 115/400 [03:26<07:13,  1.52s/it]Running loglikelihood requests:  29%|██▉       | 116/400 [03:28<07:10,  1.52s/it]Running loglikelihood requests:  29%|██▉       | 117/400 [03:29<07:08,  1.51s/it]Running loglikelihood requests:  30%|██▉       | 118/400 [03:31<07:07,  1.52s/it]Running loglikelihood requests:  30%|██▉       | 119/400 [03:32<07:08,  1.52s/it]Running loglikelihood requests:  30%|███       | 120/400 [03:34<07:02,  1.51s/it]Running loglikelihood requests:  30%|███       | 121/400 [03:35<06:59,  1.50s/it]Running loglikelihood requests:  30%|███       | 122/400 [03:37<06:55,  1.49s/it]Running loglikelihood requests:  31%|███       | 123/400 [03:38<06:51,  1.49s/it]Running loglikelihood requests:  31%|███       | 124/400 [03:40<06:48,  1.48s/it]Running loglikelihood requests:  31%|███▏      | 125/400 [03:41<06:46,  1.48s/it]Running loglikelihood requests:  32%|███▏      | 126/400 [03:42<06:44,  1.48s/it]Running loglikelihood requests:  32%|███▏      | 127/400 [03:44<06:41,  1.47s/it]Running loglikelihood requests:  32%|███▏      | 128/400 [03:45<06:38,  1.47s/it]Running loglikelihood requests:  32%|███▏      | 129/400 [03:47<06:36,  1.46s/it]Running loglikelihood requests:  32%|███▎      | 130/400 [03:48<06:35,  1.47s/it]Running loglikelihood requests:  33%|███▎      | 131/400 [03:50<06:41,  1.49s/it]Running loglikelihood requests:  33%|███▎      | 132/400 [03:51<06:38,  1.49s/it]Running loglikelihood requests:  33%|███▎      | 133/400 [03:53<06:34,  1.48s/it]Running loglikelihood requests:  34%|███▎      | 134/400 [03:54<06:31,  1.47s/it]Running loglikelihood requests:  34%|███▍      | 135/400 [03:56<06:28,  1.47s/it]Running loglikelihood requests:  34%|███▍      | 136/400 [03:57<06:26,  1.46s/it]Running loglikelihood requests:  34%|███▍      | 137/400 [03:59<06:23,  1.46s/it]Running loglikelihood requests:  34%|███▍      | 138/400 [04:00<06:21,  1.46s/it]Running loglikelihood requests:  35%|███▍      | 139/400 [04:02<06:20,  1.46s/it]Running loglikelihood requests:  35%|███▌      | 140/400 [04:03<06:18,  1.46s/it]Running loglikelihood requests:  36%|███▌      | 142/400 [04:04<04:49,  1.12s/it]Running loglikelihood requests:  36%|███▌      | 143/400 [04:06<05:11,  1.21s/it]Running loglikelihood requests:  36%|███▌      | 144/400 [04:07<05:27,  1.28s/it]Running loglikelihood requests:  36%|███▋      | 145/400 [04:09<05:40,  1.33s/it]Running loglikelihood requests:  36%|███▋      | 146/400 [04:10<05:49,  1.37s/it]Running loglikelihood requests:  37%|███▋      | 147/400 [04:12<05:54,  1.40s/it]Running loglikelihood requests:  37%|███▋      | 148/400 [04:13<05:58,  1.42s/it]Running loglikelihood requests:  37%|███▋      | 149/400 [04:15<06:00,  1.44s/it]Running loglikelihood requests:  38%|███▊      | 150/400 [04:16<06:00,  1.44s/it]Running loglikelihood requests:  38%|███▊      | 151/400 [04:18<06:00,  1.45s/it]Running loglikelihood requests:  38%|███▊      | 152/400 [04:19<06:00,  1.45s/it]Running loglikelihood requests:  38%|███▊      | 153/400 [04:21<05:59,  1.46s/it]Running loglikelihood requests:  38%|███▊      | 154/400 [04:22<05:58,  1.46s/it]Running loglikelihood requests:  39%|███▉      | 155/400 [04:24<05:57,  1.46s/it]Running loglikelihood requests:  39%|███▉      | 156/400 [04:25<05:56,  1.46s/it]Running loglikelihood requests:  39%|███▉      | 157/400 [04:26<05:54,  1.46s/it]Running loglikelihood requests:  40%|███▉      | 158/400 [04:28<05:53,  1.46s/it]Running loglikelihood requests:  40%|███▉      | 159/400 [04:29<05:51,  1.46s/it]Running loglikelihood requests:  40%|████      | 160/400 [04:31<05:50,  1.46s/it]Running loglikelihood requests:  40%|████      | 161/400 [04:32<05:48,  1.46s/it]Running loglikelihood requests:  40%|████      | 162/400 [04:34<05:46,  1.46s/it]Running loglikelihood requests:  41%|████      | 163/400 [04:35<05:44,  1.46s/it]Running loglikelihood requests:  41%|████      | 164/400 [04:37<05:43,  1.45s/it]Running loglikelihood requests:  41%|████▏     | 165/400 [04:38<05:41,  1.45s/it]Running loglikelihood requests:  42%|████▏     | 166/400 [04:40<05:39,  1.45s/it]Running loglikelihood requests:  42%|████▏     | 167/400 [04:41<05:37,  1.45s/it]Running loglikelihood requests:  42%|████▏     | 168/400 [04:42<05:35,  1.45s/it]Running loglikelihood requests:  42%|████▏     | 169/400 [04:44<05:34,  1.45s/it]Running loglikelihood requests:  42%|████▎     | 170/400 [04:45<05:32,  1.45s/it]Running loglikelihood requests:  43%|████▎     | 171/400 [04:47<05:31,  1.45s/it]Running loglikelihood requests:  43%|████▎     | 172/400 [04:48<05:29,  1.44s/it]Running loglikelihood requests:  43%|████▎     | 173/400 [04:50<05:27,  1.44s/it]Running loglikelihood requests:  44%|████▎     | 174/400 [04:51<05:25,  1.44s/it]Running loglikelihood requests:  44%|████▍     | 175/400 [04:53<05:23,  1.44s/it]Running loglikelihood requests:  44%|████▍     | 176/400 [04:54<05:21,  1.44s/it]Running loglikelihood requests:  44%|████▍     | 177/400 [04:55<05:19,  1.43s/it]Running loglikelihood requests:  44%|████▍     | 178/400 [04:57<05:18,  1.43s/it]Running loglikelihood requests:  45%|████▍     | 179/400 [04:58<05:14,  1.42s/it]Running loglikelihood requests:  45%|████▌     | 180/400 [05:00<05:10,  1.41s/it]Running loglikelihood requests:  45%|████▌     | 181/400 [05:01<05:09,  1.41s/it]Running loglikelihood requests:  46%|████▌     | 182/400 [05:02<05:08,  1.41s/it]Running loglikelihood requests:  46%|████▌     | 183/400 [05:04<05:06,  1.41s/it]Running loglikelihood requests:  46%|████▌     | 184/400 [05:05<05:12,  1.45s/it]Running loglikelihood requests:  46%|████▋     | 185/400 [05:07<05:09,  1.44s/it]Running loglikelihood requests:  46%|████▋     | 186/400 [05:08<05:05,  1.43s/it]Running loglikelihood requests:  47%|████▋     | 187/400 [05:10<05:03,  1.42s/it]Running loglikelihood requests:  47%|████▋     | 188/400 [05:11<05:02,  1.43s/it]Running loglikelihood requests:  47%|████▋     | 189/400 [05:12<04:59,  1.42s/it]Running loglikelihood requests:  48%|████▊     | 190/400 [05:14<04:56,  1.41s/it]Running loglikelihood requests:  48%|████▊     | 191/400 [05:15<04:53,  1.40s/it]Running loglikelihood requests:  48%|████▊     | 192/400 [05:17<04:51,  1.40s/it]Running loglikelihood requests:  48%|████▊     | 193/400 [05:18<04:48,  1.40s/it]Running loglikelihood requests:  48%|████▊     | 194/400 [05:19<04:46,  1.39s/it]Running loglikelihood requests:  49%|████▉     | 195/400 [05:21<04:44,  1.39s/it]Running loglikelihood requests:  49%|████▉     | 196/400 [05:22<04:42,  1.39s/it]Running loglikelihood requests:  49%|████▉     | 197/400 [05:23<04:40,  1.38s/it]Running loglikelihood requests:  50%|████▉     | 198/400 [05:25<04:38,  1.38s/it]Running loglikelihood requests:  50%|████▉     | 199/400 [05:26<04:37,  1.38s/it]Running loglikelihood requests:  50%|█████     | 200/400 [05:28<04:34,  1.37s/it]Running loglikelihood requests:  50%|█████     | 201/400 [05:29<04:32,  1.37s/it]Running loglikelihood requests:  50%|█████     | 202/400 [05:30<04:30,  1.37s/it]Running loglikelihood requests:  51%|█████     | 203/400 [05:32<04:28,  1.37s/it]Running loglikelihood requests:  51%|█████     | 204/400 [05:33<04:27,  1.36s/it]Running loglikelihood requests:  51%|█████▏    | 205/400 [05:34<04:25,  1.36s/it]Running loglikelihood requests:  52%|█████▏    | 206/400 [05:36<04:23,  1.36s/it]Running loglikelihood requests:  52%|█████▏    | 207/400 [05:37<04:22,  1.36s/it]Running loglikelihood requests:  52%|█████▏    | 208/400 [05:38<04:20,  1.36s/it]Running loglikelihood requests:  52%|█████▏    | 209/400 [05:40<04:19,  1.36s/it]Running loglikelihood requests:  52%|█████▎    | 210/400 [05:41<04:17,  1.36s/it]Running loglikelihood requests:  53%|█████▎    | 211/400 [05:43<04:16,  1.36s/it]Running loglikelihood requests:  53%|█████▎    | 212/400 [05:44<04:15,  1.36s/it]Running loglikelihood requests:  53%|█████▎    | 213/400 [05:45<04:13,  1.36s/it]Running loglikelihood requests:  54%|█████▎    | 214/400 [05:47<04:11,  1.35s/it]Running loglikelihood requests:  54%|█████▍    | 215/400 [05:48<04:10,  1.35s/it]Running loglikelihood requests:  54%|█████▍    | 216/400 [05:49<04:08,  1.35s/it]Running loglikelihood requests:  54%|█████▍    | 217/400 [05:51<04:07,  1.35s/it]Running loglikelihood requests:  55%|█████▍    | 218/400 [05:52<04:06,  1.35s/it]Running loglikelihood requests:  55%|█████▍    | 219/400 [05:53<04:04,  1.35s/it]Running loglikelihood requests:  55%|█████▌    | 220/400 [05:55<04:02,  1.35s/it]Running loglikelihood requests:  55%|█████▌    | 221/400 [05:56<04:01,  1.35s/it]Running loglikelihood requests:  56%|█████▌    | 222/400 [05:57<03:59,  1.35s/it]Running loglikelihood requests:  56%|█████▌    | 223/400 [05:59<03:57,  1.34s/it]Running loglikelihood requests:  56%|█████▌    | 224/400 [06:00<03:56,  1.34s/it]Running loglikelihood requests:  56%|█████▋    | 225/400 [06:01<03:54,  1.34s/it]Running loglikelihood requests:  56%|█████▋    | 226/400 [06:03<03:52,  1.34s/it]Running loglikelihood requests:  57%|█████▋    | 227/400 [06:04<03:51,  1.34s/it]Running loglikelihood requests:  57%|█████▋    | 228/400 [06:05<03:50,  1.34s/it]Running loglikelihood requests:  57%|█████▋    | 229/400 [06:07<03:48,  1.34s/it]Running loglikelihood requests:  57%|█████▊    | 230/400 [06:08<03:47,  1.34s/it]Running loglikelihood requests:  58%|█████▊    | 231/400 [06:09<03:45,  1.33s/it]Running loglikelihood requests:  58%|█████▊    | 232/400 [06:11<03:43,  1.33s/it]Running loglikelihood requests:  58%|█████▊    | 233/400 [06:12<03:42,  1.33s/it]Running loglikelihood requests:  58%|█████▊    | 234/400 [06:13<03:40,  1.33s/it]Running loglikelihood requests:  59%|█████▉    | 235/400 [06:15<03:39,  1.33s/it]Running loglikelihood requests:  59%|█████▉    | 236/400 [06:16<03:37,  1.32s/it]Running loglikelihood requests:  59%|█████▉    | 237/400 [06:17<03:35,  1.32s/it]Running loglikelihood requests:  60%|█████▉    | 238/400 [06:19<03:33,  1.32s/it]Running loglikelihood requests:  60%|█████▉    | 239/400 [06:20<03:32,  1.32s/it]Running loglikelihood requests:  60%|██████    | 240/400 [06:21<03:31,  1.32s/it]Running loglikelihood requests:  60%|██████    | 241/400 [06:23<03:29,  1.32s/it]Running loglikelihood requests:  60%|██████    | 242/400 [06:24<03:28,  1.32s/it]Running loglikelihood requests:  61%|██████    | 243/400 [06:25<03:27,  1.32s/it]Running loglikelihood requests:  61%|██████    | 244/400 [06:27<03:26,  1.32s/it]Running loglikelihood requests:  61%|██████▏   | 245/400 [06:28<03:24,  1.32s/it]Running loglikelihood requests:  62%|██████▏   | 246/400 [06:29<03:23,  1.32s/it]Running loglikelihood requests:  62%|██████▏   | 247/400 [06:31<03:21,  1.32s/it]Running loglikelihood requests:  62%|██████▏   | 248/400 [06:32<03:20,  1.32s/it]Running loglikelihood requests:  62%|██████▏   | 249/400 [06:33<03:19,  1.32s/it]Running loglikelihood requests:  62%|██████▎   | 250/400 [06:34<03:17,  1.32s/it]Running loglikelihood requests:  63%|██████▎   | 251/400 [06:36<03:16,  1.32s/it]Running loglikelihood requests:  63%|██████▎   | 252/400 [06:37<03:15,  1.32s/it]Running loglikelihood requests:  63%|██████▎   | 253/400 [06:38<03:13,  1.31s/it]Running loglikelihood requests:  64%|██████▎   | 254/400 [06:40<03:11,  1.31s/it]Running loglikelihood requests:  64%|██████▍   | 255/400 [06:41<03:09,  1.31s/it]Running loglikelihood requests:  64%|██████▍   | 256/400 [06:42<03:07,  1.31s/it]Running loglikelihood requests:  64%|██████▍   | 257/400 [06:44<03:06,  1.30s/it]Running loglikelihood requests:  64%|██████▍   | 258/400 [06:45<03:05,  1.30s/it]Running loglikelihood requests:  65%|██████▍   | 259/400 [06:46<03:03,  1.30s/it]Running loglikelihood requests:  65%|██████▌   | 260/400 [06:48<03:02,  1.30s/it]Running loglikelihood requests:  65%|██████▌   | 261/400 [06:49<03:00,  1.30s/it]Running loglikelihood requests:  66%|██████▌   | 262/400 [06:50<02:59,  1.30s/it]Running loglikelihood requests:  66%|██████▌   | 263/400 [06:51<02:57,  1.29s/it]Running loglikelihood requests:  66%|██████▌   | 264/400 [06:53<02:55,  1.29s/it]Running loglikelihood requests:  66%|██████▋   | 265/400 [06:54<02:53,  1.29s/it]Running loglikelihood requests:  66%|██████▋   | 266/400 [06:55<02:52,  1.28s/it]Running loglikelihood requests:  67%|██████▋   | 267/400 [06:57<02:50,  1.28s/it]Running loglikelihood requests:  67%|██████▋   | 268/400 [06:58<02:49,  1.28s/it]Running loglikelihood requests:  67%|██████▋   | 269/400 [06:59<02:47,  1.28s/it]Running loglikelihood requests:  68%|██████▊   | 270/400 [07:00<02:46,  1.28s/it]Running loglikelihood requests:  68%|██████▊   | 271/400 [07:02<02:45,  1.28s/it]Running loglikelihood requests:  68%|██████▊   | 272/400 [07:03<02:43,  1.28s/it]Running loglikelihood requests:  68%|██████▊   | 273/400 [07:04<02:41,  1.27s/it]Running loglikelihood requests:  68%|██████▊   | 274/400 [07:05<02:40,  1.27s/it]Running loglikelihood requests:  69%|██████▉   | 275/400 [07:07<02:38,  1.27s/it]Running loglikelihood requests:  69%|██████▉   | 276/400 [07:08<02:37,  1.27s/it]Running loglikelihood requests:  69%|██████▉   | 277/400 [07:09<02:35,  1.27s/it]Running loglikelihood requests:  70%|██████▉   | 278/400 [07:11<02:35,  1.27s/it]Running loglikelihood requests:  70%|███████   | 280/400 [07:12<01:57,  1.02it/s]Running loglikelihood requests:  70%|███████   | 281/400 [07:13<02:04,  1.05s/it]Running loglikelihood requests:  70%|███████   | 282/400 [07:14<02:10,  1.10s/it]Running loglikelihood requests:  71%|███████   | 283/400 [07:16<02:13,  1.14s/it]Running loglikelihood requests:  71%|███████   | 284/400 [07:17<02:16,  1.17s/it]Running loglikelihood requests:  71%|███████▏  | 285/400 [07:18<02:17,  1.20s/it]Running loglikelihood requests:  72%|███████▏  | 286/400 [07:19<02:18,  1.21s/it]Running loglikelihood requests:  72%|███████▏  | 287/400 [07:21<02:18,  1.22s/it]Running loglikelihood requests:  72%|███████▏  | 288/400 [07:22<02:17,  1.23s/it]Running loglikelihood requests:  72%|███████▏  | 289/400 [07:23<02:16,  1.23s/it]Running loglikelihood requests:  72%|███████▎  | 290/400 [07:24<02:16,  1.24s/it]Running loglikelihood requests:  73%|███████▎  | 291/400 [07:26<02:14,  1.24s/it]Running loglikelihood requests:  73%|███████▎  | 292/400 [07:27<02:13,  1.24s/it]Running loglikelihood requests:  73%|███████▎  | 293/400 [07:28<02:12,  1.23s/it]Running loglikelihood requests:  74%|███████▎  | 294/400 [07:29<02:10,  1.23s/it]Running loglikelihood requests:  74%|███████▍  | 295/400 [07:30<02:08,  1.23s/it]Running loglikelihood requests:  74%|███████▍  | 296/400 [07:32<02:07,  1.23s/it]Running loglikelihood requests:  74%|███████▍  | 297/400 [07:33<02:05,  1.22s/it]Running loglikelihood requests:  74%|███████▍  | 298/400 [07:34<02:04,  1.22s/it]Running loglikelihood requests:  75%|███████▍  | 299/400 [07:35<02:02,  1.22s/it]Running loglikelihood requests:  75%|███████▌  | 300/400 [07:37<02:02,  1.23s/it]Running loglikelihood requests:  75%|███████▌  | 301/400 [07:38<02:02,  1.23s/it]Running loglikelihood requests:  76%|███████▌  | 302/400 [07:39<01:59,  1.22s/it]Running loglikelihood requests:  76%|███████▌  | 303/400 [07:40<01:58,  1.22s/it]Running loglikelihood requests:  76%|███████▌  | 304/400 [07:41<01:56,  1.21s/it]Running loglikelihood requests:  76%|███████▋  | 305/400 [07:43<01:54,  1.21s/it]Running loglikelihood requests:  76%|███████▋  | 306/400 [07:44<01:53,  1.20s/it]Running loglikelihood requests:  77%|███████▋  | 307/400 [07:45<01:51,  1.20s/it]Running loglikelihood requests:  77%|███████▋  | 308/400 [07:46<01:50,  1.20s/it]Running loglikelihood requests:  77%|███████▋  | 309/400 [07:47<01:48,  1.20s/it]Running loglikelihood requests:  78%|███████▊  | 310/400 [07:49<01:47,  1.20s/it]Running loglikelihood requests:  78%|███████▊  | 311/400 [07:50<01:46,  1.20s/it]Running loglikelihood requests:  78%|███████▊  | 312/400 [07:51<01:44,  1.19s/it]Running loglikelihood requests:  78%|███████▊  | 313/400 [07:52<01:43,  1.19s/it]Running loglikelihood requests:  78%|███████▊  | 314/400 [07:53<01:44,  1.22s/it]Running loglikelihood requests:  79%|███████▉  | 315/400 [07:55<01:44,  1.23s/it]Running loglikelihood requests:  79%|███████▉  | 316/400 [07:56<01:42,  1.22s/it]Running loglikelihood requests:  79%|███████▉  | 317/400 [07:57<01:40,  1.21s/it]Running loglikelihood requests:  80%|███████▉  | 318/400 [07:58<01:38,  1.20s/it]Running loglikelihood requests:  80%|███████▉  | 319/400 [07:59<01:36,  1.19s/it]Running loglikelihood requests:  80%|████████  | 320/400 [08:01<01:35,  1.19s/it]Running loglikelihood requests:  80%|████████  | 321/400 [08:02<01:33,  1.18s/it]Running loglikelihood requests:  80%|████████  | 322/400 [08:03<01:32,  1.18s/it]Running loglikelihood requests:  81%|████████  | 323/400 [08:04<01:30,  1.18s/it]Running loglikelihood requests:  81%|████████  | 324/400 [08:05<01:29,  1.17s/it]Running loglikelihood requests:  81%|████████▏ | 325/400 [08:06<01:27,  1.17s/it]Running loglikelihood requests:  82%|████████▏ | 326/400 [08:08<01:26,  1.17s/it]Running loglikelihood requests:  82%|████████▏ | 327/400 [08:09<01:25,  1.17s/it]Running loglikelihood requests:  82%|████████▏ | 328/400 [08:10<01:24,  1.17s/it]Running loglikelihood requests:  82%|████████▏ | 329/400 [08:11<01:22,  1.17s/it]Running loglikelihood requests:  82%|████████▎ | 330/400 [08:12<01:21,  1.17s/it]Running loglikelihood requests:  83%|████████▎ | 331/400 [08:13<01:20,  1.16s/it]Running loglikelihood requests:  83%|████████▎ | 332/400 [08:15<01:19,  1.16s/it]Running loglikelihood requests:  83%|████████▎ | 333/400 [08:16<01:17,  1.16s/it]Running loglikelihood requests:  84%|████████▎ | 334/400 [08:17<01:16,  1.16s/it]Running loglikelihood requests:  84%|████████▍ | 335/400 [08:18<01:15,  1.16s/it]Running loglikelihood requests:  84%|████████▍ | 336/400 [08:19<01:13,  1.15s/it]Running loglikelihood requests:  84%|████████▍ | 337/400 [08:20<01:12,  1.15s/it]Running loglikelihood requests:  84%|████████▍ | 338/400 [08:21<01:11,  1.15s/it]Running loglikelihood requests:  85%|████████▍ | 339/400 [08:23<01:09,  1.15s/it]Running loglikelihood requests:  85%|████████▌ | 340/400 [08:24<01:08,  1.15s/it]Running loglikelihood requests:  85%|████████▌ | 341/400 [08:25<01:07,  1.14s/it]Running loglikelihood requests:  86%|████████▌ | 342/400 [08:26<01:06,  1.14s/it]Running loglikelihood requests:  86%|████████▌ | 343/400 [08:27<01:04,  1.14s/it]Running loglikelihood requests:  86%|████████▌ | 344/400 [08:28<01:03,  1.13s/it]Running loglikelihood requests:  86%|████████▋ | 345/400 [08:29<01:02,  1.13s/it]Running loglikelihood requests:  86%|████████▋ | 346/400 [08:31<01:01,  1.13s/it]Running loglikelihood requests:  87%|████████▋ | 347/400 [08:32<00:59,  1.13s/it]Running loglikelihood requests:  87%|████████▋ | 348/400 [08:33<00:58,  1.13s/it]Running loglikelihood requests:  87%|████████▋ | 349/400 [08:34<00:57,  1.13s/it]Running loglikelihood requests:  88%|████████▊ | 350/400 [08:35<00:56,  1.13s/it]Running loglikelihood requests:  88%|████████▊ | 351/400 [08:36<00:55,  1.12s/it]Running loglikelihood requests:  88%|████████▊ | 352/400 [08:37<00:53,  1.12s/it]Running loglikelihood requests:  88%|████████▊ | 353/400 [08:38<00:52,  1.12s/it]Running loglikelihood requests:  88%|████████▊ | 354/400 [08:40<00:52,  1.14s/it]Running loglikelihood requests:  89%|████████▉ | 355/400 [08:41<00:50,  1.13s/it]Running loglikelihood requests:  89%|████████▉ | 356/400 [08:42<00:49,  1.13s/it]Running loglikelihood requests:  89%|████████▉ | 357/400 [08:43<00:48,  1.14s/it]Running loglikelihood requests:  90%|████████▉ | 358/400 [08:44<00:47,  1.13s/it]Running loglikelihood requests:  90%|████████▉ | 359/400 [08:45<00:45,  1.12s/it]Running loglikelihood requests:  90%|█████████ | 360/400 [08:46<00:44,  1.11s/it]Running loglikelihood requests:  90%|█████████ | 361/400 [08:47<00:42,  1.10s/it]Running loglikelihood requests:  90%|█████████ | 362/400 [08:48<00:41,  1.10s/it]Running loglikelihood requests:  91%|█████████ | 363/400 [08:50<00:40,  1.09s/it]Running loglikelihood requests:  91%|█████████ | 364/400 [08:51<00:39,  1.09s/it]Running loglikelihood requests:  91%|█████████▏| 365/400 [08:52<00:37,  1.08s/it]Running loglikelihood requests:  92%|█████████▏| 366/400 [08:53<00:36,  1.08s/it]Running loglikelihood requests:  92%|█████████▏| 367/400 [08:54<00:35,  1.08s/it]Running loglikelihood requests:  92%|█████████▏| 368/400 [08:55<00:34,  1.08s/it]Running loglikelihood requests:  92%|█████████▏| 369/400 [08:56<00:33,  1.07s/it]Running loglikelihood requests:  92%|█████████▎| 370/400 [08:57<00:32,  1.08s/it]Running loglikelihood requests:  93%|█████████▎| 371/400 [08:58<00:31,  1.09s/it]Running loglikelihood requests:  93%|█████████▎| 372/400 [08:59<00:30,  1.10s/it]Running loglikelihood requests:  93%|█████████▎| 373/400 [09:00<00:29,  1.10s/it]Running loglikelihood requests:  94%|█████████▎| 374/400 [09:02<00:28,  1.10s/it]Running loglikelihood requests:  94%|█████████▍| 375/400 [09:03<00:27,  1.10s/it]Running loglikelihood requests:  94%|█████████▍| 376/400 [09:04<00:26,  1.10s/it]Running loglikelihood requests:  94%|█████████▍| 377/400 [09:05<00:25,  1.10s/it]Running loglikelihood requests:  94%|█████████▍| 378/400 [09:06<00:23,  1.08s/it]Running loglikelihood requests:  95%|█████████▍| 379/400 [09:07<00:22,  1.06s/it]Running loglikelihood requests:  95%|█████████▌| 380/400 [09:08<00:20,  1.04s/it]Running loglikelihood requests:  95%|█████████▌| 381/400 [09:09<00:19,  1.02s/it]Running loglikelihood requests:  96%|█████████▌| 382/400 [09:10<00:18,  1.01s/it]Running loglikelihood requests:  96%|█████████▌| 383/400 [09:11<00:17,  1.01s/it]Running loglikelihood requests:  96%|█████████▌| 384/400 [09:12<00:15,  1.00it/s]Running loglikelihood requests:  96%|█████████▋| 385/400 [09:13<00:14,  1.01it/s]Running loglikelihood requests:  96%|█████████▋| 386/400 [09:14<00:13,  1.02it/s]Running loglikelihood requests:  97%|█████████▋| 387/400 [09:15<00:12,  1.02it/s]Running loglikelihood requests:  97%|█████████▋| 389/400 [09:16<00:08,  1.34it/s]Running loglikelihood requests:  98%|█████████▊| 390/400 [09:17<00:07,  1.27it/s]Running loglikelihood requests:  98%|█████████▊| 391/400 [09:17<00:07,  1.21it/s]Running loglikelihood requests:  98%|█████████▊| 393/400 [09:18<00:04,  1.52it/s]Running loglikelihood requests:  98%|█████████▊| 394/400 [09:19<00:04,  1.42it/s]Running loglikelihood requests:  99%|█████████▉| 395/400 [09:20<00:03,  1.34it/s]Running loglikelihood requests:  99%|█████████▉| 396/400 [09:21<00:03,  1.28it/s]Running loglikelihood requests:  99%|█████████▉| 397/400 [09:22<00:02,  1.25it/s]Running loglikelihood requests: 100%|█████████▉| 398/400 [09:23<00:01,  1.23it/s]Running loglikelihood requests: 100%|█████████▉| 399/400 [09:24<00:00,  1.21it/s]Running loglikelihood requests: 100%|██████████| 400/400 [09:24<00:00,  1.20it/s]Running loglikelihood requests: 100%|██████████| 400/400 [09:24<00:00,  1.41s/it]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:7'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:7'}
full model:
{'logiqa': {'alias': 'logiqa', 'acc,none': 0.29, 'acc_stderr,none': 0.045604802157206865, 'acc_norm,none': 0.33, 'acc_norm_stderr,none': 0.04725815626252609}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9179964803140478
0.7817057225882229
0.8413553272072316
0.9274797474668193
0.8768807463293081
0.9494139907523571
0.8960692461846443
0.9131107283061946
0.6329173647892901
0.8375042173336539
0.8817471801904351
0.8172295355829869
0.7824572665005357
0.9227400642857845
0.9246594853497696
0.8075911590072223
0.6900210787422486
0.599615993999193
0.9308030044211123
0.9504015361511146
0.8866807231108503
0.540104242930401
0.6701728801805507
0.9744992661822648
0.8193037468812308
0.840784693447352
0.9052511591891966
Total groups 70 exceeded the threshold, stopping comparison.
The group tensor is
[3, 6, 7, 1, 5, 2, 4, 0]
tensor([3, 6, 7, 1, 5, 2, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 2, 6, 3, 7, 1, 5, 0]
tensor([4, 2, 6, 3, 7, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 3, 6, 1, 7, 2, 4, 0]
tensor([5, 3, 6, 1, 7, 2, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 4, 6, 1, 7, 2, 3, 0]
tensor([5, 4, 6, 1, 7, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 3, 0, 2, 1, 0, 4, 1]
tensor([5, 3, 0, 2, 1, 0, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 0, 5, 0, 1, 2, 3, 1]
tensor([4, 0, 5, 0, 1, 2, 3, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Normal merging for layer 2
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 4 to 8
done!
Normal merging for layer 9
tensor([2, 5])
tensor(2)
tensor([4, 7])
tensor(4)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 10 to 13
done!
Normal merging for layer 14
tensor([1, 3])
tensor(1)
tensor([4, 7])
tensor(4)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Cross-layer merge completed for layers 15 to 31
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 2 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 11.9458 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 1 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

222
cuda:7
wnli
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:57<00:57, 57.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:14<00:00, 33.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:14<00:00, 37.26s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140431340358496 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140431340358496 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140431340358496 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140431340358496 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140430457474752 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140430457474752 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430457474752 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140430457474752 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2633.49it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:01<04:00,  1.71s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:02<01:44,  1.33it/s]Running loglikelihood requests:   4%|▎         | 5/142 [00:03<01:17,  1.77it/s]Running loglikelihood requests:   5%|▍         | 7/142 [00:04<01:06,  2.04it/s]Running loglikelihood requests:   6%|▋         | 9/142 [00:04<00:59,  2.23it/s]Running loglikelihood requests:   8%|▊         | 11/142 [00:05<00:54,  2.39it/s]Running loglikelihood requests:   9%|▉         | 13/142 [00:06<00:51,  2.50it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:07<00:48,  2.60it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:07<00:46,  2.70it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:08<00:43,  2.81it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:09<00:42,  2.86it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:09<00:40,  2.91it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:10<00:39,  2.93it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:11<00:39,  2.95it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:11<00:37,  2.99it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:12<00:36,  3.03it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:12<00:35,  3.05it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:13<00:35,  3.05it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:14<00:35,  2.98it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:15<00:35,  2.90it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:15<00:34,  2.97it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:16<00:32,  3.01it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:17<00:32,  2.97it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:17<00:31,  2.98it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:18<00:29,  3.10it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:18<00:28,  3.23it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:19<00:26,  3.32it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:19<00:25,  3.39it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:20<00:24,  3.45it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:21<00:23,  3.47it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:21<00:23,  3.43it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:22<00:23,  3.38it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:22<00:23,  3.34it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:23<00:22,  3.33it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:24<00:21,  3.34it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:24<00:21,  3.37it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:25<00:20,  3.37it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [00:25<00:19,  3.40it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [00:26<00:19,  3.42it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [00:27<00:18,  3.41it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [00:27<00:17,  3.41it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [00:28<00:17,  3.37it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [00:28<00:17,  3.32it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [00:29<00:16,  3.24it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [00:30<00:16,  3.24it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [00:30<00:15,  3.21it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [00:31<00:14,  3.29it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [00:31<00:13,  3.39it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [00:32<00:12,  3.48it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [00:32<00:12,  3.55it/s]Running loglikelihood requests:  71%|███████   | 101/142 [00:33<00:11,  3.59it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [00:34<00:10,  3.64it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [00:34<00:10,  3.67it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [00:35<00:09,  3.70it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [00:35<00:08,  3.71it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [00:36<00:08,  3.70it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [00:36<00:07,  3.75it/s]Running loglikelihood requests:  81%|████████  | 115/142 [00:37<00:07,  3.77it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [00:37<00:06,  3.77it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [00:38<00:06,  3.71it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [00:38<00:05,  3.62it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [00:39<00:05,  3.61it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [00:39<00:04,  3.58it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [00:40<00:04,  3.58it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [00:41<00:03,  3.59it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [00:41<00:03,  3.63it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [00:42<00:02,  3.67it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [00:42<00:01,  3.73it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [00:43<00:01,  3.81it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [00:43<00:00,  3.83it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [00:44<00:00,  3.87it/s]Running loglikelihood requests: 100%|██████████| 142/142 [00:44<00:00,  3.21it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
full model:
{'wnli': {'alias': 'wnli', 'acc,none': 0.5352112676056338, 'acc_stderr,none': 0.0596130578497224}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.31190044950254875
0.7306280553786256
0.6985925052465822
0.5843516732063875
0.8124235844589114
0.820438203921003
0.6253838264581936
0.7600037006947045
0.8225872978677496
0.708398461303215
0.8646089269479391
0.8239362351853257
0.7608099850331435
0.6657423857513638
0.7943257460202938
0.7511476003698512
0.9073696655228775
0.8741838353767599
0.7945799099309127
0.9323691001541556
0.865243808509542
0.8176606226311932
0.6785099625983169
0.9579534328203848
0.788928884938056
0.9833718962298513
0.5933012307657521
0.7829988799240639
0.7823073743206628
0.31190044950254875
0.7306280553786256
0.6985925052465822
0.5843516732063875
0.8124235844589114
0.820438203921003
0.6253838264581936
0.7600037006947045
0.8225872978677496
0.708398461303215
0.8646089269479391
0.8239362351853257
0.7608099850331435
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[7, 4, 5, 1, 6, 3, 2, 0]
tensor([7, 4, 5, 1, 6, 3, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 2, 4, 5, 6, 1, 0, 3]
tensor([7, 2, 4, 5, 6, 1, 0, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 7, 5, 4, 1, 2, 0]
tensor([6, 3, 7, 5, 4, 1, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 3, 6, 4, 7, 1, 2, 0]
tensor([5, 3, 6, 4, 7, 1, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 3, 6, 5, 7, 2, 1, 0]
tensor([4, 3, 6, 5, 7, 2, 1, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1, 2, 3, 2, 3, 0]
tensor([0, 1, 1, 2, 3, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 1, 2, 2, 3, 0, 3, 1]
tensor([0, 1, 2, 2, 3, 0, 3, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 1, 1, 1.0, 1.0, 1.0, 1.0]
tensor([0, 0, 1, 1, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
Normal merging for layer 1
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
done!
Normal merging for layer 2
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
tensor([3])
tensor(3)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Normal merging for layer 4
tensor([7])
tensor(7)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 5 to 15
done!
Normal merging for layer 16
tensor([0, 7])
tensor(0)
tensor([1, 2])
tensor(1)
tensor([3, 5])
tensor(3)
tensor([4, 6])
tensor(4)
done!
Normal merging for layer 17
tensor([0, 5])
tensor(0)
tensor([1, 7])
tensor(1)
tensor([2, 3])
tensor(2)
tensor([4, 6])
tensor(4)
done!
Cross-layer merge completed for layers 18 to 30
done!
Normal merging for layer 31
tensor([0, 1])
tensor(0)
tensor([2, 3, 4, 5, 6, 7])
tensor(2)
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 1 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.2608 GB

===== 🚀【CUDA 检查开始】[after create model] =====
✅ 没有发现任何驻留在 CUDA 上的张量，显存清理成功。
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

Node 231 Flask server is running on port 5231...
Node 239 Flask server is running on port 5239...
Node 39 Flask server is running on port 5039...
Node 64 Flask server is running on port 5064...
Node 159 Flask server is running on port 5159...
Node 134 Flask server is running on port 5134...
Node 47 Flask server is running on port 5047...
Node 25 Flask server is running on port 5025...
Node 178 Flask server is running on port 5178...
Node 117 Flask server is running on port 5117...
Node 137 Flask server is running on port 5137...
Node 19 Flask server is running on port 5019...
Node 41 Flask server is running on port 5041...
 * Serving Flask app 'Node_llama_test'
Node 14 Flask server is running on port 5014...
Node 190 Flask server is running on port 5190...
Node 121 Flask server is running on port 5121...
 * Debug mode: off
Node 115 Flask server is running on port 5115...
Node 183 Flask server is running on port 5183...
Node 70 Flask server is running on port 5070...
Node 196 Flask server is running on port 5196...
 * Serving Flask app 'Node_llama_test'
Node 22 Flask server is running on port 5022...
 * Debug mode: off
Node 123 Flask server is running on port 5123...
Node 105 Flask server is running on port 5105...
Node 30 Flask server is running on port 5030...
Node 199 Flask server is running on port 5199...
Node 127 Flask server is running on port 5127...
Node 108 Flask server is running on port 5108...
 * Serving Flask app 'Node_llama_test'
Node 197 Flask server is running on port 5197...
Node 146 Flask server is running on port 5146...
 * Debug mode: off
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
Node 209 Flask server is running on port 5209...
Node 176 Flask server is running on port 5176...
Node 222 Flask server is running on port 5222...
[231] Inference Step Starting
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Debug mode: off
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Debug mode: off
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5039
 * Running on http://173.0.64.7:5039
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5231
 * Running on http://173.0.64.7:5231
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5047
 * Running on http://173.0.64.7:5047
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5183
 * Running on http://173.0.64.7:5183
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5014
 * Running on http://173.0.64.7:5014
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5123
 * Running on http://173.0.64.7:5123
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5176
 * Running on http://173.0.64.7:5176
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5070
 * Running on http://173.0.64.7:5070
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5105
 * Running on http://173.0.64.7:5105
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5041
 * Running on http://173.0.64.7:5041
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5117
 * Running on http://173.0.64.7:5117
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5137
 * Running on http://173.0.64.7:5137
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5197
 * Running on http://173.0.64.7:5197
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5159
 * Running on http://173.0.64.7:5159
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5115
 * Running on http://173.0.64.7:5115
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5025
 * Running on http://173.0.64.7:5025
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5127
 * Running on http://173.0.64.7:5127
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5146
 * Running on http://173.0.64.7:5146
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5196
 * Running on http://173.0.64.7:5196
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5178
 * Running on http://173.0.64.7:5178
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5222
 * Running on http://173.0.64.7:5222
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5134
 * Running on http://173.0.64.7:5134
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5190
 * Running on http://173.0.64.7:5190
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5030
 * Running on http://173.0.64.7:5030
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5022
 * Running on http://173.0.64.7:5022
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5019
 * Running on http://173.0.64.7:5019
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5108
 * Running on http://173.0.64.7:5108
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5064
 * Running on http://173.0.64.7:5064
INFO:werkzeug:[33mPress CTRL+C to quit[0m
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5121
 * Running on http://173.0.64.7:5121
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5239
 * Running on http://173.0.64.7:5239
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5209
 * Running on http://173.0.64.7:5209
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5199
 * Running on http://173.0.64.7:5199
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[33mPress CTRL+C to quit[0m
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/revision/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 111
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/revision/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140430729639408 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140430729639408 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430729639408 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140430729639408 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140430675419664 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140430675419664 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430675419664 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140430675419664 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2618.42it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:48<1:54:18, 48.64s/it]Running loglikelihood requests:   2%|▏         | 3/142 [01:45<1:18:00, 33.67s/it]Running loglikelihood requests:   4%|▎         | 5/142 [02:19<57:18, 25.10s/it]  Running loglikelihood requests:   5%|▍         | 7/142 [02:36<40:38, 18.07s/it]Running loglikelihood requests:   6%|▋         | 9/142 [02:57<33:50, 15.27s/it]Running loglikelihood requests:   8%|▊         | 11/142 [03:21<30:38, 14.03s/it]Running loglikelihood requests:   9%|▉         | 13/142 [03:29<22:57, 10.68s/it]Running loglikelihood requests:  11%|█         | 15/142 [03:36<17:43,  8.37s/it]Running loglikelihood requests:  12%|█▏        | 17/142 [03:52<17:12,  8.26s/it]Running loglikelihood requests:  13%|█▎        | 19/142 [03:57<13:29,  6.58s/it]Running loglikelihood requests:  15%|█▍        | 21/142 [04:07<12:09,  6.03s/it]Running loglikelihood requests:  16%|█▌        | 23/142 [04:16<11:00,  5.55s/it]Running loglikelihood requests:  18%|█▊        | 25/142 [04:25<10:19,  5.29s/it]Running loglikelihood requests:  19%|█▉        | 27/142 [04:52<14:45,  7.70s/it]Running loglikelihood requests:  20%|██        | 29/142 [04:59<12:04,  6.41s/it]Running loglikelihood requests:  22%|██▏       | 31/142 [05:25<15:30,  8.38s/it]Running loglikelihood requests:  23%|██▎       | 33/142 [06:29<28:16, 15.56s/it]Running loglikelihood requests:  25%|██▍       | 35/142 [06:59<27:18, 15.31s/it]Running loglikelihood requests:  26%|██▌       | 37/142 [07:03<19:56, 11.39s/it]Running loglikelihood requests:  27%|██▋       | 39/142 [07:14<16:32,  9.64s/it]Running loglikelihood requests:  29%|██▉       | 41/142 [07:40<17:52, 10.62s/it]Running loglikelihood requests:  30%|███       | 43/142 [07:50<14:48,  8.98s/it]Running loglikelihood requests:  32%|███▏      | 45/142 [08:04<13:25,  8.31s/it]Running loglikelihood requests:  33%|███▎      | 47/142 [08:08<10:07,  6.39s/it]Running loglikelihood requests:  35%|███▍      | 49/142 [08:36<13:26,  8.67s/it]Running loglikelihood requests:  36%|███▌      | 51/142 [09:54<27:00, 17.81s/it]Running loglikelihood requests:  37%|███▋      | 53/142 [10:24<25:05, 16.92s/it]Running loglikelihood requests:  39%|███▊      | 55/142 [11:41<34:05, 23.51s/it]Running loglikelihood requests:  40%|████      | 57/142 [12:32<34:03, 24.04s/it]Running loglikelihood requests:  42%|████▏     | 59/142 [13:57<40:54, 29.57s/it]Running loglikelihood requests:  43%|████▎     | 61/142 [15:06<41:54, 31.04s/it]Running loglikelihood requests:  44%|████▍     | 63/142 [16:17<42:42, 32.44s/it]Running loglikelihood requests:  46%|████▌     | 65/142 [17:45<45:57, 35.81s/it]Running loglikelihood requests:  47%|████▋     | 67/142 [19:04<46:15, 37.00s/it]Running loglikelihood requests:  49%|████▊     | 69/142 [20:07<43:00, 35.35s/it]Running loglikelihood requests:  50%|█████     | 71/142 [21:31<44:14, 37.38s/it]Running loglikelihood requests:  51%|█████▏    | 73/142 [22:50<43:37, 37.93s/it]Running loglikelihood requests:  53%|█████▎    | 75/142 [24:07<42:37, 38.17s/it]Running loglikelihood requests:  54%|█████▍    | 77/142 [25:26<41:44, 38.54s/it]Running loglikelihood requests:  56%|█████▌    | 79/142 [26:46<40:52, 38.92s/it]Running loglikelihood requests:  57%|█████▋    | 81/142 [28:01<39:14, 38.60s/it]Running loglikelihood requests:  58%|█████▊    | 83/142 [29:21<38:20, 39.00s/it]Running loglikelihood requests:  60%|█████▉    | 85/142 [30:24<34:51, 36.69s/it]Running loglikelihood requests:  61%|██████▏   | 87/142 [31:28<32:22, 35.32s/it]Running loglikelihood requests:  63%|██████▎   | 89/142 [32:13<27:48, 31.48s/it]Running loglikelihood requests:  64%|██████▍   | 91/142 [33:14<26:31, 31.21s/it]Running loglikelihood requests:  65%|██████▌   | 93/142 [34:39<28:13, 34.57s/it]Running loglikelihood requests:  67%|██████▋   | 95/142 [36:01<28:33, 36.46s/it]Running loglikelihood requests:  68%|██████▊   | 97/142 [37:21<28:12, 37.61s/it]Running loglikelihood requests:  70%|██████▉   | 99/142 [38:29<26:08, 36.49s/it]Running loglikelihood requests:  71%|███████   | 101/142 [39:51<25:52, 37.87s/it]Running loglikelihood requests:  73%|███████▎  | 103/142 [41:15<25:25, 39.10s/it]Running loglikelihood requests:  74%|███████▍  | 105/142 [42:17<22:36, 36.67s/it]Running loglikelihood requests:  75%|███████▌  | 107/142 [43:14<19:56, 34.20s/it]Running loglikelihood requests:  77%|███████▋  | 109/142 [43:49<16:04, 29.22s/it]Running loglikelihood requests:  78%|███████▊  | 111/142 [44:04<11:41, 22.63s/it]Running loglikelihood requests:  80%|███████▉  | 113/142 [44:50<11:02, 22.83s/it]Running loglikelihood requests:  81%|████████  | 115/142 [45:56<11:35, 25.78s/it]Running loglikelihood requests:  82%|████████▏ | 117/142 [46:57<11:18, 27.16s/it]Running loglikelihood requests:  84%|████████▍ | 119/142 [48:08<11:22, 29.69s/it]Running loglikelihood requests:  85%|████████▌ | 121/142 [49:24<11:17, 32.26s/it]Running loglikelihood requests:  87%|████████▋ | 123/142 [50:00<08:51, 27.98s/it]Running loglikelihood requests:  88%|████████▊ | 125/142 [50:44<07:24, 26.17s/it]Running loglikelihood requests:  89%|████████▉ | 127/142 [51:39<06:37, 26.47s/it]Running loglikelihood requests:  91%|█████████ | 129/142 [52:37<05:54, 27.28s/it]Running loglikelihood requests:  92%|█████████▏| 131/142 [53:37<05:08, 28.09s/it]Running loglikelihood requests:  94%|█████████▎| 133/142 [54:06<03:36, 24.04s/it]Running loglikelihood requests:  95%|█████████▌| 135/142 [54:20<02:12, 18.88s/it]Running loglikelihood requests:  96%|█████████▋| 137/142 [54:37<01:19, 15.83s/it]Running loglikelihood requests:  98%|█████████▊| 139/142 [54:47<00:37, 12.59s/it]Running loglikelihood requests:  99%|█████████▉| 141/142 [54:59<00:10, 10.64s/it]Running loglikelihood requests: 100%|██████████| 142/142 [54:59<00:00, 23.24s/it]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-2): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (3-4): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-7): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (8-28): 21 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (29): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (30-31): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-2): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (3-4): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-7): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (8-28): 21 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (29): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (30-31): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/231.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5146
INFO:werkzeug:127.0.0.1 - - [16/May/2025 21:55:56] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5146 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 146
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5190
INFO:werkzeug:127.0.0.1 - - [16/May/2025 21:55:56] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5190 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 190
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5019
INFO:werkzeug:127.0.0.1 - - [16/May/2025 21:55:56] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5019 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 19
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5025
INFO:werkzeug:127.0.0.1 - - [16/May/2025 21:55:56] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5025 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 25
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5022
INFO:werkzeug:127.0.0.1 - - [16/May/2025 21:55:56] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5022 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 22
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5121
INFO:werkzeug:127.0.0.1 - - [16/May/2025 21:55:56] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5121 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 121
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [16/May/2025 21:55:56] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [16/May/2025 21:55:56] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5137
INFO:werkzeug:127.0.0.1 - - [16/May/2025 21:55:56] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5137 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 137
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5047
INFO:werkzeug:127.0.0.1 - - [16/May/2025 21:55:56] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5047 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 47
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5105
INFO:werkzeug:127.0.0.1 - - [16/May/2025 21:55:57] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5105 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 105
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5041
INFO:werkzeug:127.0.0.1 - - [16/May/2025 21:55:57] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5041 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 41
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [16/May/2025 21:55:57] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5199
INFO:werkzeug:127.0.0.1 - - [16/May/2025 21:55:57] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5199 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 199
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5183
INFO:werkzeug:127.0.0.1 - - [16/May/2025 21:55:57] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5183 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 183
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [16/May/2025 21:55:57] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5176
INFO:werkzeug:127.0.0.1 - - [16/May/2025 21:55:57] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5176 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 176
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5115
INFO:werkzeug:127.0.0.1 - - [16/May/2025 21:55:57] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5115 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 115
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [16/May/2025 21:55:57] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5209
INFO:werkzeug:127.0.0.1 - - [16/May/2025 21:55:57] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5209 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 209
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5134
INFO:werkzeug:127.0.0.1 - - [16/May/2025 21:55:57] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5134 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 134
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5014
INFO:werkzeug:127.0.0.1 - - [16/May/2025 21:55:57] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5014 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 14
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5070
INFO:werkzeug:127.0.0.1 - - [16/May/2025 21:55:57] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5070 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 70
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5159
INFO:werkzeug:127.0.0.1 - - [16/May/2025 21:55:57] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5159 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 159
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5222
INFO:werkzeug:127.0.0.1 - - [16/May/2025 21:55:57] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5222 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 222
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [16/May/2025 21:55:57] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [16/May/2025 21:55:57] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5108
INFO:werkzeug:127.0.0.1 - - [16/May/2025 21:55:57] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5108 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 108
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [16/May/2025 21:55:57] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5197
INFO:werkzeug:127.0.0.1 - - [16/May/2025 21:55:57] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5197 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 197
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [16/May/2025 21:55:57] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140430806000480 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140430806000480 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430806000480 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140430806000480 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140430940474832 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140430940474832 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430940474832 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140430940474832 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[231] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4507042253521127, 'acc_stderr,none': 0.05947027187738001}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.6024646571659534
0.8979951240825792
0.626373129339755
0.44935206242731585
0.8784896158641048
0.6837759248511185
0.6015518094762149
0.3505110226931915
0.8777011536981446
0.9326494344559366
0.9677722596476288
0.8304234396005722
0.8190920250237561
0.9903242845857883
0.8267732717549456
0.828751210253346
0.9341138981557521
0.49221062986878583
0.3069647614672379
0.9540155558764357
0.17208911684447897
0.24981632210046514
0.9635863021858757
0.7455052133761656
0.8389345141460378
0.9946030373097186
0.6620732151580052
0.6342744878528105
0.8890512085844174
Total groups 67 exceeded the threshold, stopping comparison.
The group tensor is
[2, 4, 7, 1, 3, 0, 6, 5]
tensor([2, 4, 7, 1, 3, 0, 6, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 7, 6, 5, 0, 1, 4, 3]
tensor([2, 7, 6, 5, 0, 1, 4, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 6, 4, 3, 0, 1, 7, 2]
tensor([5, 6, 4, 3, 0, 1, 7, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 4, 1, 0, 1, 2, 5, 3]
tensor([0, 4, 1, 0, 1, 2, 5, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[2, 4, 0, 0, 5, 1, 1, 3]
tensor([2, 4, 0, 0, 5, 1, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 1, 1.0, 1.0, 1, 1.0, 1.0]
tensor([0, 0, 1, 1, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[0, 1, 1.0, 1.0, 0, 1, 1.0, 1.0]
tensor([0, 1, 1, 1, 0, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1.0, 1.0, 1, 1.0, 0]
tensor([0, 1, 1, 1, 1, 1, 1, 0], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 0, 1.0, 1.0, 1.0, 1]
tensor([0, 1, 1, 0, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
Model saved locally at saved_models/231.pt
[RECEIVE] Queued message from 231
[QUEUE] Processing info from 231
[QUEUE] Stored info from 231
[RECEIVE] Queued message from 231
[QUEUE] Processing info from 231
[QUEUE] Stored info from 231
[RECEIVE] Queued message from 231
[QUEUE] Processing info from 231
[QUEUE] Stored info from 231
[RECEIVE] Queued message from 231
[QUEUE] Processing info from 231
[QUEUE] Stored info from 231
[RECEIVE] Queued message from 231
[QUEUE] Processing info from 231
[QUEUE] Stored info from 231
[RECEIVE] Queued message from 231
[QUEUE] Processing info from 231
[QUEUE] Stored info from 231
[RECEIVE] Queued message from 231
[QUEUE] Processing info from 231
[QUEUE] Stored info from 231
[RECEIVE] Queued message from 231
[QUEUE] Processing info from 231
[QUEUE] Stored info from 231
[RECEIVE] Queued message from 231
[QUEUE] Processing info from 231
[QUEUE] Stored info from 231
[RECEIVE] Queued message from 231
[QUEUE] Processing info from 231
[QUEUE] Stored info from 231
[RECEIVE] Queued message from 231
[QUEUE] Processing info from 231
[QUEUE] Stored info from 231
[RECEIVE] Queued message from 231
[QUEUE] Processing info from 231
[QUEUE] Stored info from 231
[RECEIVE] Queued message from 231
[QUEUE] Processing info from 231
[QUEUE] Stored info from 231
[RECEIVE] Queued message from 231
[QUEUE] Processing info from 231
[QUEUE] Stored info from 231
[RECEIVE] Queued message from 231
[QUEUE] Processing info from 231
[QUEUE] Stored info from 231
[RECEIVE] Queued message from 231
[QUEUE] Processing info from 231
[QUEUE] Stored info from 231
[RECEIVE] Queued message from 231
[QUEUE] Processing info from 231
[QUEUE] Stored info from 231
[RECEIVE] Queued message from 231
[QUEUE] Processing info from 231
[QUEUE] Stored info from 231
[RECEIVE] Queued message from 231
[QUEUE] Processing info from 231
[QUEUE] Stored info from 231
[RECEIVE] Queued message from 231
[QUEUE] Processing info from 231
[QUEUE] Stored info from 231
[RECEIVE] Queued message from 231
[QUEUE] Processing info from 231
[QUEUE] Stored info from 231
[RECEIVE] Queued message from 231
[QUEUE] Processing info from 231
[QUEUE] Stored info from 231
[RECEIVE] Queued message from 231
[QUEUE] Processing info from 231
[QUEUE] Stored info from 231
[RECEIVE] Queued message from 231
[QUEUE] Processing info from 231
[QUEUE] Stored info from 231
[RECEIVE] Queued message from 231
[QUEUE] Processing info from 231
[QUEUE] Stored info from 231
[RECEIVE] Queued message from 231
[QUEUE] Processing info from 231
[QUEUE] Stored info from 231
[RECEIVE] Queued message from 231
[QUEUE] Processing info from 231
[QUEUE] Stored info from 231
[RECEIVE] Queued message from 231
[QUEUE] Processing info from 231
[QUEUE] Stored info from 231
[RECEIVE] Queued message from 231
[QUEUE] Processing info from 231
[QUEUE] Stored info from 231
[RECEIVE] Queued message from 231
[QUEUE] Processing info from 231
[QUEUE] Stored info from 231
[RECEIVE] Queued message from 231
[QUEUE] Processing info from 231
[QUEUE] Stored info from 231
[239] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2551.39it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:18<43:56, 18.70s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:34<24:34, 10.61s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:50<21:25,  9.38s/it]Running loglikelihood requests:   5%|▍         | 7/142 [01:13<22:50, 10.15s/it]Running loglikelihood requests:   6%|▋         | 9/142 [01:35<23:20, 10.53s/it]Running loglikelihood requests:   8%|▊         | 11/142 [01:56<23:05, 10.58s/it]Running loglikelihood requests:   9%|▉         | 13/142 [02:18<23:03, 10.72s/it]Running loglikelihood requests:  11%|█         | 15/142 [02:30<19:26,  9.18s/it]Running loglikelihood requests:  12%|█▏        | 17/142 [02:42<16:54,  8.12s/it]Running loglikelihood requests:  13%|█▎        | 19/142 [03:09<20:02,  9.77s/it]Running loglikelihood requests:  15%|█▍        | 21/142 [03:27<19:14,  9.54s/it]Running loglikelihood requests:  16%|█▌        | 23/142 [03:32<14:48,  7.47s/it]Running loglikelihood requests:  18%|█▊        | 25/142 [03:42<12:54,  6.62s/it]Running loglikelihood requests:  19%|█▉        | 27/142 [03:47<10:19,  5.39s/it]Running loglikelihood requests:  20%|██        | 29/142 [03:54<09:05,  4.83s/it]Running loglikelihood requests:  22%|██▏       | 31/142 [03:58<07:30,  4.06s/it]Running loglikelihood requests:  23%|██▎       | 33/142 [04:04<06:42,  3.70s/it]Running loglikelihood requests:  25%|██▍       | 35/142 [04:10<06:05,  3.41s/it]Running loglikelihood requests:  26%|██▌       | 37/142 [04:16<05:57,  3.41s/it]Running loglikelihood requests:  27%|██▋       | 39/142 [04:40<10:12,  5.95s/it]Running loglikelihood requests:  29%|██▉       | 41/142 [05:15<15:57,  9.48s/it]Running loglikelihood requests:  30%|███       | 43/142 [05:51<19:47, 11.99s/it]Running loglikelihood requests:  32%|███▏      | 45/142 [06:27<22:14, 13.76s/it]Running loglikelihood requests:  33%|███▎      | 47/142 [06:51<21:01, 13.28s/it]Running loglikelihood requests:  35%|███▍      | 49/142 [07:16<20:13, 13.05s/it]Running loglikelihood requests:  36%|███▌      | 51/142 [07:44<20:09, 13.29s/it]Running loglikelihood requests:  37%|███▋      | 53/142 [08:17<21:08, 14.26s/it]Running loglikelihood requests:  39%|███▊      | 55/142 [08:33<17:54, 12.35s/it]Running loglikelihood requests:  40%|████      | 57/142 [08:48<15:30, 10.95s/it]Running loglikelihood requests:  42%|████▏     | 59/142 [09:13<15:49, 11.44s/it]Running loglikelihood requests:  43%|████▎     | 61/142 [09:56<19:32, 14.47s/it]Running loglikelihood requests:  44%|████▍     | 63/142 [10:25<18:53, 14.35s/it]Running loglikelihood requests:  46%|████▌     | 65/142 [10:34<14:39, 11.42s/it]Running loglikelihood requests:  47%|████▋     | 67/142 [10:44<11:58,  9.58s/it]Running loglikelihood requests:  49%|████▊     | 69/142 [10:50<09:07,  7.50s/it]Running loglikelihood requests:  50%|█████     | 71/142 [10:59<07:55,  6.70s/it]Running loglikelihood requests:  51%|█████▏    | 73/142 [11:08<06:54,  6.01s/it]Running loglikelihood requests:  53%|█████▎    | 75/142 [11:14<05:42,  5.12s/it]Running loglikelihood requests:  54%|█████▍    | 77/142 [11:21<05:04,  4.68s/it]Running loglikelihood requests:  56%|█████▌    | 79/142 [11:49<07:50,  7.47s/it]Running loglikelihood requests:  57%|█████▋    | 81/142 [12:45<13:50, 13.62s/it]Running loglikelihood requests:  58%|█████▊    | 83/142 [13:19<14:23, 14.63s/it]Running loglikelihood requests:  60%|█████▉    | 85/142 [14:17<18:00, 18.96s/it]Running loglikelihood requests:  61%|██████▏   | 87/142 [14:55<17:21, 18.93s/it]Running loglikelihood requests:  63%|██████▎   | 89/142 [15:39<17:33, 19.87s/it]Running loglikelihood requests:  64%|██████▍   | 91/142 [16:24<17:27, 20.54s/it]Running loglikelihood requests:  65%|██████▌   | 93/142 [16:41<13:51, 16.97s/it]Running loglikelihood requests:  67%|██████▋   | 95/142 [17:09<12:39, 16.17s/it]Running loglikelihood requests:  68%|██████▊   | 97/142 [17:58<13:55, 18.56s/it]Running loglikelihood requests:  70%|██████▉   | 99/142 [18:17<11:22, 15.87s/it]Running loglikelihood requests:  71%|███████   | 101/142 [18:34<09:23, 13.73s/it]Running loglikelihood requests:  73%|███████▎  | 103/142 [18:46<07:25, 11.43s/it]Running loglikelihood requests:  74%|███████▍  | 105/142 [18:57<05:57,  9.65s/it]Running loglikelihood requests:  75%|███████▌  | 107/142 [19:13<05:19,  9.14s/it]Running loglikelihood requests:  77%|███████▋  | 109/142 [20:32<09:59, 18.18s/it]Running loglikelihood requests:  78%|███████▊  | 111/142 [21:40<11:50, 22.93s/it]Running loglikelihood requests:  80%|███████▉  | 113/142 [22:56<13:18, 27.52s/it]Running loglikelihood requests:  81%|████████  | 115/142 [24:13<13:49, 30.71s/it]Running loglikelihood requests:  82%|████████▏ | 117/142 [25:34<14:03, 33.74s/it]Running loglikelihood requests:  84%|████████▍ | 119/142 [26:47<13:12, 34.47s/it]Running loglikelihood requests:  85%|████████▌ | 121/142 [28:06<12:37, 36.05s/it]Running loglikelihood requests:  87%|████████▋ | 123/142 [29:15<11:16, 35.63s/it]Running loglikelihood requests:  88%|████████▊ | 125/142 [30:17<09:40, 34.12s/it]Running loglikelihood requests:  89%|████████▉ | 127/142 [31:33<08:50, 35.38s/it]Running loglikelihood requests:  91%|█████████ | 129/142 [32:30<07:11, 33.21s/it]Running loglikelihood requests:  92%|█████████▏| 131/142 [33:24<05:44, 31.36s/it]Running loglikelihood requests:  94%|█████████▎| 133/142 [34:43<05:05, 33.90s/it]Running loglikelihood requests:  95%|█████████▌| 135/142 [35:44<03:50, 32.87s/it]Running loglikelihood requests:  96%|█████████▋| 137/142 [36:45<02:40, 32.16s/it]Running loglikelihood requests:  98%|█████████▊| 139/142 [38:02<01:42, 34.08s/it]Running loglikelihood requests:  99%|█████████▉| 141/142 [39:15<00:34, 34.81s/it]Running loglikelihood requests: 100%|██████████| 142/142 [39:15<00:00, 16.59s/it]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-31): 26 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-31): 26 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/239.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5176
INFO:werkzeug:127.0.0.1 - - [16/May/2025 22:35:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5176 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 176
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5105
INFO:werkzeug:127.0.0.1 - - [16/May/2025 22:35:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5105 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 105
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5137
INFO:werkzeug:127.0.0.1 - - [16/May/2025 22:35:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5137 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 137
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [16/May/2025 22:35:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5199
INFO:werkzeug:127.0.0.1 - - [16/May/2025 22:35:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5199 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 199
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5025
INFO:werkzeug:127.0.0.1 - - [16/May/2025 22:35:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5025 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 25
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5047
INFO:werkzeug:127.0.0.1 - - [16/May/2025 22:35:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5047 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 47
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5041
INFO:werkzeug:127.0.0.1 - - [16/May/2025 22:35:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5041 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 41
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5108
INFO:werkzeug:127.0.0.1 - - [16/May/2025 22:35:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5108 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 108
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5231
INFO:werkzeug:127.0.0.1 - - [16/May/2025 22:35:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5231 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 231
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [16/May/2025 22:35:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [16/May/2025 22:35:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5019
INFO:werkzeug:127.0.0.1 - - [16/May/2025 22:35:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5019 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 19
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5222
INFO:werkzeug:127.0.0.1 - - [16/May/2025 22:35:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5222 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 222
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [16/May/2025 22:35:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5197
INFO:werkzeug:127.0.0.1 - - [16/May/2025 22:35:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5197 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 197
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5159
INFO:werkzeug:127.0.0.1 - - [16/May/2025 22:35:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5159 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 159
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [16/May/2025 22:35:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5022
INFO:werkzeug:127.0.0.1 - - [16/May/2025 22:35:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5022 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 22
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5134
INFO:werkzeug:127.0.0.1 - - [16/May/2025 22:35:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5134 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 134
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5121
INFO:werkzeug:127.0.0.1 - - [16/May/2025 22:35:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5121 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 121
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5115
INFO:werkzeug:127.0.0.1 - - [16/May/2025 22:35:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5115 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 115
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5014
INFO:werkzeug:127.0.0.1 - - [16/May/2025 22:35:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5014 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 14
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5146
INFO:werkzeug:127.0.0.1 - - [16/May/2025 22:35:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5146 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 146
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5209
INFO:werkzeug:127.0.0.1 - - [16/May/2025 22:35:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5209 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 209
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5183
INFO:werkzeug:127.0.0.1 - - [16/May/2025 22:35:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5183 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 183
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5190
INFO:werkzeug:127.0.0.1 - - [16/May/2025 22:35:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5190 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 190
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [16/May/2025 22:35:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [16/May/2025 22:35:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [16/May/2025 22:35:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5070
INFO:werkzeug:127.0.0.1 - - [16/May/2025 22:35:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5070 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 70
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140430455425360 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140430455425360 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430455425360 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140430455425360 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140430865005648 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140430865005648 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430865005648 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140430865005648 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[239] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4225352112676056, 'acc_stderr,none': 0.059039842056825796}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8301327615319641
0.7817720914227475
0.8113678911982368
0.2257173763133808
0.2927105469616105
0.5177793359335131
0.8145737190612207
0.7363478990038121
0.20758834533702153
0.2533018140549718
0.30764875086796684
0.29044714199656413
0.9350374080783923
0.6277994360424477
0.603553220567354
0.78279661631625
0.6718149226457006
0.5353760149732133
0.6848376228333551
0.9446001512801305
0.7972906165117697
0.5043025319455414
0.5939887608746786
0.6455402209569181
0.2505215486241291
0.321550947803521
0.8361163063826382
0.7208169010376037
0.9633188772100769
0.8301327615319641
0.7817720914227475
0.8113678911982368
0.2257173763133808
0.2927105469616105
0.5177793359335131
0.8145737190612207
0.7363478990038121
0.20758834533702153
0.2533018140549718
0.30764875086796684
0.29044714199656413
0.9350374080783923
0.6277994360424477
0.603553220567354
0.78279661631625
0.6718149226457006
0.5353760149732133
0.6848376228333551
0.9446001512801305
0.7972906165117697
0.5043025319455414
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[6, 5, 4, 1, 3, 0, 7, 2]
tensor([6, 5, 4, 1, 3, 0, 7, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 7, 5, 1, 0, 4, 2]
tensor([6, 3, 7, 5, 1, 0, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[6, 4, 7, 0, 3, 1, 5, 2]
tensor([6, 4, 7, 0, 3, 1, 5, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 5, 3, 4, 1, 0, 7, 6]
tensor([2, 5, 3, 4, 1, 0, 7, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 5, 0, 2, 4, 0, 1, 1]
tensor([3, 5, 0, 2, 4, 0, 1, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 1, 0, 2, 1, 2, 3]
tensor([0, 3, 1, 0, 2, 1, 2, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 3, 1, 2, 2, 1, 3, 0]
tensor([0, 3, 1, 2, 2, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 1, 2, 0, 3, 3, 2, 1]
tensor([0, 1, 2, 0, 3, 3, 2, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1, 0, 1.0, 1.0, 1.0, 1.0]
tensor([0, 1, 1, 0, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/239.pt
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[39] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2484.88it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [01:47<4:13:16, 107.78s/it]Running loglikelihood requests:   2%|▏         | 3/142 [02:03<1:18:07, 33.72s/it] Running loglikelihood requests:   4%|▎         | 5/142 [02:49<1:04:34, 28.28s/it]Running loglikelihood requests:   5%|▍         | 7/142 [03:19<51:06, 22.72s/it]  Running loglikelihood requests:   6%|▋         | 9/142 [03:26<34:18, 15.48s/it]Running loglikelihood requests:   8%|▊         | 11/142 [03:52<31:39, 14.50s/it]Running loglikelihood requests:   9%|▉         | 13/142 [04:41<38:25, 17.87s/it]Running loglikelihood requests:  11%|█         | 15/142 [06:29<1:02:21, 29.46s/it]Running loglikelihood requests:  12%|█▏        | 17/142 [08:23<1:19:31, 38.17s/it]Running loglikelihood requests:  13%|█▎        | 19/142 [10:03<1:25:50, 41.87s/it]Running loglikelihood requests:  15%|█▍        | 21/142 [11:47<1:30:38, 44.94s/it]Running loglikelihood requests:  16%|█▌        | 23/142 [13:25<1:31:42, 46.24s/it]Running loglikelihood requests:  18%|█▊        | 25/142 [14:59<1:30:26, 46.38s/it]Running loglikelihood requests:  19%|█▉        | 27/142 [16:32<1:29:04, 46.47s/it]Running loglikelihood requests:  20%|██        | 29/142 [18:08<1:28:32, 47.01s/it]Running loglikelihood requests:  22%|██▏       | 31/142 [19:45<1:27:44, 47.43s/it]Running loglikelihood requests:  23%|██▎       | 33/142 [21:26<1:27:53, 48.39s/it]Running loglikelihood requests:  25%|██▍       | 35/142 [22:51<1:22:53, 46.48s/it]Running loglikelihood requests:  26%|██▌       | 37/142 [24:12<1:18:26, 44.83s/it]Running loglikelihood requests:  27%|██▋       | 39/142 [25:41<1:16:39, 44.65s/it]Running loglikelihood requests:  29%|██▉       | 41/142 [27:22<1:18:09, 46.43s/it]Running loglikelihood requests:  30%|███       | 43/142 [29:01<1:18:10, 47.38s/it]Running loglikelihood requests:  32%|███▏      | 45/142 [30:35<1:16:24, 47.26s/it]Running loglikelihood requests:  33%|███▎      | 47/142 [32:01<1:12:42, 45.92s/it]Running loglikelihood requests:  35%|███▍      | 49/142 [33:15<1:07:01, 43.25s/it]Running loglikelihood requests:  36%|███▌      | 51/142 [34:34<1:03:53, 42.12s/it]Running loglikelihood requests:  37%|███▋      | 53/142 [35:48<1:00:07, 40.53s/it]Running loglikelihood requests:  39%|███▊      | 55/142 [37:19<1:00:59, 42.06s/it]Running loglikelihood requests:  40%|████      | 57/142 [38:27<56:16, 39.73s/it]  Running loglikelihood requests:  42%|████▏     | 59/142 [38:38<40:39, 29.39s/it]Running loglikelihood requests:  43%|████▎     | 61/142 [39:19<36:00, 26.68s/it]Running loglikelihood requests:  44%|████▍     | 63/142 [40:09<34:35, 26.27s/it]Running loglikelihood requests:  46%|████▌     | 65/142 [40:27<27:01, 21.06s/it]Running loglikelihood requests:  47%|████▋     | 67/142 [41:15<27:26, 21.95s/it]Running loglikelihood requests:  49%|████▊     | 69/142 [41:48<24:39, 20.27s/it]Running loglikelihood requests:  50%|█████     | 71/142 [43:04<30:18, 25.62s/it]Running loglikelihood requests:  51%|█████▏    | 73/142 [44:23<34:12, 29.74s/it]Running loglikelihood requests:  53%|█████▎    | 75/142 [45:41<36:24, 32.60s/it]Running loglikelihood requests:  54%|█████▍    | 77/142 [46:59<37:19, 34.46s/it]Running loglikelihood requests:  56%|█████▌    | 79/142 [48:18<37:47, 36.00s/it]Running loglikelihood requests:  57%|█████▋    | 81/142 [49:36<37:29, 36.88s/it]Running loglikelihood requests:  58%|█████▊    | 83/142 [50:58<37:29, 38.13s/it]Running loglikelihood requests:  60%|█████▉    | 85/142 [52:23<37:31, 39.50s/it]Running loglikelihood requests:  61%|██████▏   | 87/142 [53:48<36:55, 40.28s/it]Running loglikelihood requests:  63%|██████▎   | 89/142 [55:07<35:26, 40.12s/it]Running loglikelihood requests:  64%|██████▍   | 91/142 [56:19<33:02, 38.88s/it]Running loglikelihood requests:  65%|██████▌   | 93/142 [57:32<31:07, 38.10s/it]Running loglikelihood requests:  67%|██████▋   | 95/142 [58:50<30:06, 38.44s/it]Running loglikelihood requests:  68%|██████▊   | 97/142 [1:00:09<29:06, 38.81s/it]Running loglikelihood requests:  70%|██████▉   | 99/142 [1:01:26<27:39, 38.59s/it]Running loglikelihood requests:  71%|███████   | 101/142 [1:02:39<25:58, 38.02s/it]Running loglikelihood requests:  73%|███████▎  | 103/142 [1:04:04<25:37, 39.43s/it]Running loglikelihood requests:  74%|███████▍  | 105/142 [1:05:29<24:49, 40.25s/it]Running loglikelihood requests:  75%|███████▌  | 107/142 [1:06:39<22:35, 38.72s/it]Running loglikelihood requests:  77%|███████▋  | 109/142 [1:07:11<17:31, 31.86s/it]Running loglikelihood requests:  78%|███████▊  | 111/142 [1:07:25<12:36, 24.42s/it]Running loglikelihood requests:  80%|███████▉  | 113/142 [1:08:19<12:09, 25.16s/it]Running loglikelihood requests:  81%|████████  | 115/142 [1:08:30<08:40, 19.28s/it]Running loglikelihood requests:  82%|████████▏ | 117/142 [1:09:05<07:51, 18.85s/it]Running loglikelihood requests:  84%|████████▍ | 119/142 [1:09:48<07:30, 19.61s/it]Running loglikelihood requests:  85%|████████▌ | 121/142 [1:10:25<06:44, 19.27s/it]Running loglikelihood requests:  87%|████████▋ | 123/142 [1:10:44<05:10, 16.32s/it]Running loglikelihood requests:  88%|████████▊ | 125/142 [1:10:53<03:36, 12.75s/it]Running loglikelihood requests:  89%|████████▉ | 127/142 [1:11:27<03:31, 14.07s/it]Running loglikelihood requests:  91%|█████████ | 129/142 [1:12:34<04:18, 19.89s/it]Running loglikelihood requests:  92%|█████████▏| 131/142 [1:12:52<03:02, 16.61s/it]Running loglikelihood requests:  94%|█████████▎| 133/142 [1:13:05<02:02, 13.65s/it]Running loglikelihood requests:  95%|█████████▌| 135/142 [1:13:10<01:11, 10.25s/it]Running loglikelihood requests:  96%|█████████▋| 137/142 [1:13:17<00:41,  8.25s/it]Running loglikelihood requests:  98%|█████████▊| 139/142 [1:13:28<00:22,  7.44s/it]Running loglikelihood requests:  99%|█████████▉| 141/142 [1:13:46<00:07,  7.84s/it]Running loglikelihood requests: 100%|██████████| 142/142 [1:13:46<00:00, 31.17s/it]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-2): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (3-4): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-15): 10 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (16): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (17-18): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (19-20): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (21): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (22-24): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (25): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (26-29): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (30-31): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-2): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (3-4): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-15): 10 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (16): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (17-18): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (19-20): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (21): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (22-24): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (25): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (26-29): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (30-31): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/39.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [16/May/2025 23:50:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [16/May/2025 23:50:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5047
INFO:werkzeug:127.0.0.1 - - [16/May/2025 23:50:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5047 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 47
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5190
INFO:werkzeug:127.0.0.1 - - [16/May/2025 23:50:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5190 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 190
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5108
INFO:werkzeug:127.0.0.1 - - [16/May/2025 23:50:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5108 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 108
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5121
INFO:werkzeug:127.0.0.1 - - [16/May/2025 23:50:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5121 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 121
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5146
INFO:werkzeug:127.0.0.1 - - [16/May/2025 23:50:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5146 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 146
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5176
INFO:werkzeug:127.0.0.1 - - [16/May/2025 23:50:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5176 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 176
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5134
INFO:werkzeug:127.0.0.1 - - [16/May/2025 23:50:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5134 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 134
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5022
INFO:werkzeug:127.0.0.1 - - [16/May/2025 23:50:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5022 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 22
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [16/May/2025 23:50:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [16/May/2025 23:50:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5159
INFO:werkzeug:127.0.0.1 - - [16/May/2025 23:50:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5159 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 159
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5019
INFO:werkzeug:127.0.0.1 - - [16/May/2025 23:50:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5019 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 19
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5231
INFO:werkzeug:127.0.0.1 - - [16/May/2025 23:50:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5231 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 231
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5115
INFO:werkzeug:127.0.0.1 - - [16/May/2025 23:50:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5115 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 115
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5105
INFO:werkzeug:127.0.0.1 - - [16/May/2025 23:50:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5105 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 105
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5041
INFO:werkzeug:127.0.0.1 - - [16/May/2025 23:50:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5041 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 41
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5183
INFO:werkzeug:127.0.0.1 - - [16/May/2025 23:50:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5183 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 183
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [16/May/2025 23:50:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [16/May/2025 23:50:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5137
INFO:werkzeug:127.0.0.1 - - [16/May/2025 23:50:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5137 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 137
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [16/May/2025 23:50:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5025
INFO:werkzeug:127.0.0.1 - - [16/May/2025 23:50:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5025 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 25
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5199
INFO:werkzeug:127.0.0.1 - - [16/May/2025 23:50:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5199 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 199
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5197
INFO:werkzeug:127.0.0.1 - - [16/May/2025 23:50:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5197 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 197
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5222
INFO:werkzeug:127.0.0.1 - - [16/May/2025 23:50:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5222 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 222
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5070
INFO:werkzeug:127.0.0.1 - - [16/May/2025 23:50:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5070 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 70
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5014
INFO:werkzeug:127.0.0.1 - - [16/May/2025 23:50:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5014 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 14
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [16/May/2025 23:50:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5209
INFO:werkzeug:127.0.0.1 - - [16/May/2025 23:50:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5209 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 209
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140430951416224 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140430951416224 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430951416224 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140430951416224 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140430452077344 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140430452077344 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430452077344 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140430452077344 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[39] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4225352112676056, 'acc_stderr,none': 0.059039842056825796}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.14760664350766747
0.8352462310811678
0.8321308433128256
0.6921610173004006
0.8887821417891327
0.9002690003330746
0.8806289653487678
0.28445629778111486
0.40731743116347024
0.9213637317788009
0.7749865640431746
0.5716601976941454
0.9731922502549005
0.5670705490427793
0.6522486093895017
0.8529538656844128
0.2520467552169693
0.5031341434536605
0.9297274773443689
0.8347846730794728
0.5913302222348289
0.6213415287437887
0.7775301720773112
0.5931169444310043
0.46564608236144167
0.4429317777448297
0.534169366976033
0.5376905800175403
0.7666618949093333
0.14760664350766747
0.8352462310811678
0.8321308433128256
0.6921610173004006
0.8887821417891327
0.9002690003330746
0.8806289653487678
0.28445629778111486
0.40731743116347024
0.9213637317788009
0.7749865640431746
0.5716601976941454
0.9731922502549005
0.5670705490427793
0.6522486093895017
0.8529538656844128
0.2520467552169693
0.5031341434536605
0.9297274773443689
0.8347846730794728
0.5913302222348289
0.6213415287437887
0.7775301720773112
0.5931169444310043
0.46564608236144167
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[2, 6, 7, 3, 1, 0, 5, 4]
tensor([2, 6, 7, 3, 1, 0, 5, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 6, 4, 7, 1, 0, 2, 3]
tensor([5, 6, 4, 7, 1, 0, 2, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 6, 7, 3, 1, 0, 5, 2]
tensor([4, 6, 7, 3, 1, 0, 5, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 2, 5, 1, 4, 0, 6, 3]
tensor([7, 2, 5, 1, 4, 0, 6, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 7, 4, 6, 2, 0, 5, 1]
tensor([3, 7, 4, 6, 2, 0, 5, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 6, 4, 1, 5, 0, 7, 2]
tensor([3, 6, 4, 1, 5, 0, 7, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1.0, 1.0, 1, 1.0, 0]
tensor([0, 1, 1, 1, 1, 1, 1, 0], dtype=torch.int32)
[0, 1]
Model saved locally at saved_models/39.pt
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[64] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2574.51it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:16<39:23, 16.76s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:25<17:28,  7.54s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:33<13:19,  5.84s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:45<13:21,  5.94s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:58<13:29,  6.09s/it]Running loglikelihood requests:   8%|▊         | 11/142 [01:13<14:25,  6.61s/it]Running loglikelihood requests:   9%|▉         | 13/142 [01:24<13:25,  6.25s/it]Running loglikelihood requests:  11%|█         | 15/142 [01:35<12:30,  5.91s/it]Running loglikelihood requests:  12%|█▏        | 17/142 [01:45<11:47,  5.66s/it]Running loglikelihood requests:  13%|█▎        | 19/142 [01:56<11:24,  5.57s/it]Running loglikelihood requests:  15%|█▍        | 21/142 [02:06<11:01,  5.47s/it]Running loglikelihood requests:  16%|█▌        | 23/142 [02:13<09:41,  4.89s/it]Running loglikelihood requests:  18%|█▊        | 25/142 [02:25<10:03,  5.16s/it]Running loglikelihood requests:  19%|█▉        | 27/142 [02:45<12:38,  6.60s/it]Running loglikelihood requests:  20%|██        | 29/142 [03:02<13:40,  7.26s/it]Running loglikelihood requests:  22%|██▏       | 31/142 [03:24<15:27,  8.36s/it]Running loglikelihood requests:  23%|██▎       | 33/142 [03:35<13:41,  7.54s/it]Running loglikelihood requests:  25%|██▍       | 35/142 [03:48<12:47,  7.17s/it]Running loglikelihood requests:  26%|██▌       | 37/142 [04:07<13:53,  7.94s/it]Running loglikelihood requests:  27%|██▋       | 39/142 [04:28<14:45,  8.60s/it]Running loglikelihood requests:  29%|██▉       | 41/142 [04:33<11:33,  6.87s/it]Running loglikelihood requests:  30%|███       | 43/142 [04:42<10:06,  6.13s/it]Running loglikelihood requests:  32%|███▏      | 45/142 [05:25<17:21, 10.74s/it]Running loglikelihood requests:  33%|███▎      | 47/142 [06:21<25:06, 15.86s/it]Running loglikelihood requests:  35%|███▍      | 49/142 [07:08<28:14, 18.22s/it]Running loglikelihood requests:  36%|███▌      | 51/142 [08:00<31:09, 20.55s/it]Running loglikelihood requests:  37%|███▋      | 53/142 [08:40<30:13, 20.38s/it]Running loglikelihood requests:  39%|███▊      | 55/142 [09:12<27:42, 19.11s/it]Running loglikelihood requests:  40%|████      | 57/142 [09:29<22:24, 15.82s/it]Running loglikelihood requests:  42%|████▏     | 59/142 [09:43<18:13, 13.17s/it]Running loglikelihood requests:  43%|████▎     | 61/142 [10:08<17:36, 13.04s/it]Running loglikelihood requests:  44%|████▍     | 63/142 [10:48<19:55, 15.13s/it]Running loglikelihood requests:  46%|████▌     | 65/142 [11:30<21:33, 16.80s/it]Running loglikelihood requests:  47%|████▋     | 67/142 [12:08<21:56, 17.55s/it]Running loglikelihood requests:  49%|████▊     | 69/142 [13:00<24:21, 20.02s/it]Running loglikelihood requests:  50%|█████     | 71/142 [13:15<19:11, 16.22s/it]Running loglikelihood requests:  51%|█████▏    | 73/142 [13:32<16:03, 13.96s/it]Running loglikelihood requests:  53%|█████▎    | 75/142 [13:42<12:32, 11.23s/it]Running loglikelihood requests:  54%|█████▍    | 77/142 [13:55<10:41,  9.88s/it]Running loglikelihood requests:  56%|█████▌    | 79/142 [14:08<09:20,  8.90s/it]Running loglikelihood requests:  57%|█████▋    | 81/142 [15:06<15:12, 14.95s/it]Running loglikelihood requests:  58%|█████▊    | 83/142 [16:26<22:03, 22.43s/it]Running loglikelihood requests:  60%|█████▉    | 85/142 [17:33<24:26, 25.73s/it]Running loglikelihood requests:  61%|██████▏   | 87/142 [18:46<26:31, 28.93s/it]Running loglikelihood requests:  63%|██████▎   | 89/142 [20:12<29:20, 33.23s/it]Running loglikelihood requests:  64%|██████▍   | 91/142 [21:38<30:38, 36.05s/it]Running loglikelihood requests:  65%|██████▌   | 93/142 [23:01<30:50, 37.77s/it]Running loglikelihood requests:  67%|██████▋   | 95/142 [24:24<30:23, 38.79s/it]Running loglikelihood requests:  68%|██████▊   | 97/142 [25:48<29:54, 39.88s/it]Running loglikelihood requests:  70%|██████▉   | 99/142 [26:52<26:50, 37.45s/it]Running loglikelihood requests:  71%|███████   | 101/142 [27:59<24:46, 36.26s/it]Running loglikelihood requests:  73%|███████▎  | 103/142 [28:59<22:20, 34.37s/it]Running loglikelihood requests:  74%|███████▍  | 105/142 [30:05<20:58, 34.01s/it]Running loglikelihood requests:  75%|███████▌  | 107/142 [31:24<20:49, 35.70s/it]Running loglikelihood requests:  77%|███████▋  | 109/142 [32:44<20:18, 36.92s/it]Running loglikelihood requests:  78%|███████▊  | 111/142 [34:02<19:26, 37.61s/it]Running loglikelihood requests:  80%|███████▉  | 113/142 [35:16<18:04, 37.39s/it]Running loglikelihood requests:  81%|████████  | 115/142 [36:35<17:07, 38.07s/it]Running loglikelihood requests:  82%|████████▏ | 117/142 [37:51<15:49, 37.98s/it]Running loglikelihood requests:  84%|████████▍ | 119/142 [38:46<13:20, 34.82s/it]Running loglikelihood requests:  85%|████████▌ | 121/142 [39:32<10:55, 31.23s/it]Running loglikelihood requests:  87%|████████▋ | 123/142 [40:01<08:19, 26.30s/it]Running loglikelihood requests:  88%|████████▊ | 125/142 [40:08<05:29, 19.41s/it]Running loglikelihood requests:  89%|████████▉ | 127/142 [40:22<03:54, 15.64s/it]Running loglikelihood requests:  91%|█████████ | 129/142 [40:49<03:16, 15.12s/it]Running loglikelihood requests:  92%|█████████▏| 131/142 [41:53<03:41, 20.17s/it]Running loglikelihood requests:  94%|█████████▎| 133/142 [43:03<03:41, 24.61s/it]Running loglikelihood requests:  95%|█████████▌| 135/142 [44:22<03:23, 29.04s/it]Running loglikelihood requests:  96%|█████████▋| 137/142 [45:29<02:31, 30.36s/it]Running loglikelihood requests:  98%|█████████▊| 139/142 [46:47<01:39, 33.01s/it]Running loglikelihood requests:  99%|█████████▉| 141/142 [47:47<00:32, 32.14s/it]Running loglikelihood requests: 100%|██████████| 142/142 [47:47<00:00, 20.20s/it]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-4): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-9): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (11-12): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (13): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14-19): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (20-21): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (22-23): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (25-31): 7 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-4): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-9): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (11-12): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (13): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14-19): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (20-21): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (22-23): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (25-31): 7 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/64.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5190
INFO:werkzeug:127.0.0.1 - - [17/May/2025 00:38:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5190 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 190
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [17/May/2025 00:38:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5115
INFO:werkzeug:127.0.0.1 - - [17/May/2025 00:38:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5115 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 115
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5041
INFO:werkzeug:127.0.0.1 - - [17/May/2025 00:38:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5041 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 41
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [17/May/2025 00:38:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [17/May/2025 00:38:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5105
INFO:werkzeug:127.0.0.1 - - [17/May/2025 00:38:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5105 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 105
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5137
INFO:werkzeug:127.0.0.1 - - [17/May/2025 00:38:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5137 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 137
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5199
INFO:werkzeug:127.0.0.1 - - [17/May/2025 00:38:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5199 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 199
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5019
INFO:werkzeug:127.0.0.1 - - [17/May/2025 00:38:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5019 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 19
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5108
INFO:werkzeug:127.0.0.1 - - [17/May/2025 00:38:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5108 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 108
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5146
INFO:werkzeug:127.0.0.1 - - [17/May/2025 00:38:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5146 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 146
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [17/May/2025 00:38:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [17/May/2025 00:38:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5121
INFO:werkzeug:127.0.0.1 - - [17/May/2025 00:38:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5121 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 121
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5047
INFO:werkzeug:127.0.0.1 - - [17/May/2025 00:38:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5047 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 47
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5159
INFO:werkzeug:127.0.0.1 - - [17/May/2025 00:38:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5159 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 159
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5014
INFO:werkzeug:127.0.0.1 - - [17/May/2025 00:38:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5014 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 14
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5070
INFO:werkzeug:127.0.0.1 - - [17/May/2025 00:38:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5070 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 70
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5183
INFO:werkzeug:127.0.0.1 - - [17/May/2025 00:38:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5183 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 183
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [17/May/2025 00:38:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5022
INFO:werkzeug:127.0.0.1 - - [17/May/2025 00:38:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5022 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 22
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5231
INFO:werkzeug:127.0.0.1 - - [17/May/2025 00:38:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5231 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 231
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5197
INFO:werkzeug:127.0.0.1 - - [17/May/2025 00:38:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5197 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 197
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5025
INFO:werkzeug:127.0.0.1 - - [17/May/2025 00:38:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5025 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 25
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5176
INFO:werkzeug:127.0.0.1 - - [17/May/2025 00:38:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5176 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 176
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5222
INFO:werkzeug:127.0.0.1 - - [17/May/2025 00:38:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5222 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 222
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [17/May/2025 00:38:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5134
INFO:werkzeug:127.0.0.1 - - [17/May/2025 00:38:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5134 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 134
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5209
INFO:werkzeug:127.0.0.1 - - [17/May/2025 00:38:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5209 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 209
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [17/May/2025 00:38:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140430442094736 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140430442094736 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430442094736 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140430442094736 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140430728454624 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140430728454624 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430728454624 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140430728454624 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[64] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.43661971830985913, 'acc_stderr,none': 0.05927935558412972}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8840011732877091
0.9530187867791682
0.922962504956303
0.7839472459406365
0.8981387177104178
0.9267264969548299
0.5821108615798573
0.2837945650872556
0.6077879555368297
0.40197237439213185
0.8904940347912964
0.7509530386402397
0.901875691813653
0.9122390055224058
0.7316046462179062
0.7968435583929763
0.548007144578676
0.5393492220671232
0.9101317167988644
0.5489553505889563
0.4310648048222707
0.3687557715800523
0.8114931082909914
0.5012706843250611
0.2095243909347347
0.3518983916697559
0.9676050865236582
0.8840253404453832
0.6389046419601837
0.8840011732877091
0.9530187867791682
0.922962504956303
0.7839472459406365
0.8981387177104178
0.9267264969548299
0.5821108615798573
0.2837945650872556
0.6077879555368297
0.40197237439213185
0.8904940347912964
0.7509530386402397
0.901875691813653
0.9122390055224058
0.7316046462179062
0.7968435583929763
0.548007144578676
0.5393492220671232
0.9101317167988644
0.5489553505889563
Total groups 72 exceeded the threshold, stopping comparison.
The group tensor is
[1, 2, 7, 4, 3, 0, 6, 5]
tensor([1, 2, 7, 4, 3, 0, 6, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 5, 4, 1, 0, 7, 2]
tensor([6, 3, 5, 4, 1, 0, 7, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[1, 3, 6, 4, 2, 0, 7, 5]
tensor([1, 3, 6, 4, 2, 0, 7, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 3, 6, 4, 0, 1, 7, 2]
tensor([5, 3, 6, 4, 0, 1, 7, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 4, 6, 5, 3, 0, 7, 1]
tensor([2, 4, 6, 5, 3, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 5, 2, 4, 0, 1, 3]
tensor([0, 1, 5, 2, 4, 0, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/64.pt
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[159] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2594.67it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [02:03<4:50:32, 123.64s/it]Running loglikelihood requests:   2%|▏         | 3/142 [03:59<2:53:37, 74.95s/it] Running loglikelihood requests:   4%|▎         | 5/142 [05:38<2:21:32, 61.99s/it]Running loglikelihood requests:   5%|▍         | 7/142 [06:52<1:55:31, 51.35s/it]Running loglikelihood requests:   6%|▋         | 9/142 [08:32<1:52:47, 50.89s/it]Running loglikelihood requests:   8%|▊         | 11/142 [09:53<1:42:51, 47.11s/it]Running loglikelihood requests:   9%|▉         | 13/142 [10:48<1:27:32, 40.72s/it]Running loglikelihood requests:  11%|█         | 15/142 [12:01<1:23:07, 39.27s/it]Running loglikelihood requests:  12%|█▏        | 17/142 [13:43<1:29:39, 43.03s/it]Running loglikelihood requests:  13%|█▎        | 19/142 [15:28<1:34:06, 45.91s/it]Running loglikelihood requests:  15%|█▍        | 21/142 [16:59<1:32:23, 45.82s/it]Running loglikelihood requests:  16%|█▌        | 23/142 [18:08<1:23:57, 42.33s/it]Running loglikelihood requests:  18%|█▊        | 25/142 [19:08<1:15:10, 38.55s/it]Running loglikelihood requests:  19%|█▉        | 27/142 [20:43<1:19:17, 41.37s/it]Running loglikelihood requests:  20%|██        | 29/142 [22:18<1:21:19, 43.18s/it]Running loglikelihood requests:  22%|██▏       | 31/142 [23:47<1:20:26, 43.48s/it]Running loglikelihood requests:  23%|██▎       | 33/142 [25:09<1:17:44, 42.79s/it]Running loglikelihood requests:  25%|██▍       | 35/142 [26:35<1:16:34, 42.94s/it]Running loglikelihood requests:  26%|██▌       | 37/142 [28:13<1:18:15, 44.72s/it]Running loglikelihood requests:  27%|██▋       | 39/142 [29:44<1:17:05, 44.91s/it]Running loglikelihood requests:  29%|██▉       | 41/142 [31:20<1:17:07, 45.82s/it]Running loglikelihood requests:  30%|███       | 43/142 [32:45<1:14:07, 44.93s/it]Running loglikelihood requests:  32%|███▏      | 45/142 [34:17<1:13:09, 45.25s/it]Running loglikelihood requests:  33%|███▎      | 47/142 [35:54<1:13:06, 46.18s/it]Running loglikelihood requests:  35%|███▍      | 49/142 [37:11<1:07:51, 43.78s/it]Running loglikelihood requests:  36%|███▌      | 51/142 [38:00<57:44, 38.07s/it]  Running loglikelihood requests:  37%|███▋      | 53/142 [39:06<54:16, 36.59s/it]Running loglikelihood requests:  39%|███▊      | 55/142 [40:21<53:17, 36.75s/it]Running loglikelihood requests:  40%|████      | 57/142 [41:45<54:28, 38.45s/it]Running loglikelihood requests:  42%|████▏     | 59/142 [42:58<52:14, 37.76s/it]Running loglikelihood requests:  43%|████▎     | 61/142 [44:16<51:29, 38.15s/it]Running loglikelihood requests:  44%|████▍     | 63/142 [45:34<50:41, 38.49s/it]Running loglikelihood requests:  46%|████▌     | 65/142 [46:58<50:37, 39.45s/it]Running loglikelihood requests:  47%|████▋     | 67/142 [48:25<50:57, 40.77s/it]Running loglikelihood requests:  49%|████▊     | 69/142 [49:55<50:58, 41.90s/it]Running loglikelihood requests:  50%|█████     | 71/142 [51:23<50:22, 42.57s/it]Running loglikelihood requests:  51%|█████▏    | 73/142 [52:44<48:15, 41.96s/it]Running loglikelihood requests:  53%|█████▎    | 75/142 [53:23<39:18, 35.20s/it]Running loglikelihood requests:  54%|█████▍    | 77/142 [54:05<33:37, 31.04s/it]Running loglikelihood requests:  56%|█████▌    | 79/142 [54:30<26:39, 25.39s/it]Running loglikelihood requests:  57%|█████▋    | 81/142 [55:10<24:12, 23.82s/it]Running loglikelihood requests:  58%|█████▊    | 83/142 [56:16<26:11, 26.63s/it]Running loglikelihood requests:  60%|█████▉    | 85/142 [57:35<28:54, 30.43s/it]Running loglikelihood requests:  61%|██████▏   | 87/142 [58:45<29:06, 31.75s/it]Running loglikelihood requests:  63%|██████▎   | 89/142 [1:00:06<30:24, 34.42s/it]Running loglikelihood requests:  64%|██████▍   | 91/142 [1:01:05<27:59, 32.94s/it]Running loglikelihood requests:  65%|██████▌   | 93/142 [1:02:26<28:42, 35.16s/it]Running loglikelihood requests:  67%|██████▋   | 95/142 [1:03:44<28:28, 36.35s/it]Running loglikelihood requests:  68%|██████▊   | 97/142 [1:04:35<24:52, 33.17s/it]Running loglikelihood requests:  70%|██████▉   | 99/142 [1:05:58<25:28, 35.55s/it]Running loglikelihood requests:  71%|███████   | 101/142 [1:07:24<25:53, 37.88s/it]Running loglikelihood requests:  73%|███████▎  | 103/142 [1:08:44<25:00, 38.46s/it]Running loglikelihood requests:  74%|███████▍  | 105/142 [1:09:57<23:24, 37.96s/it]Running loglikelihood requests:  75%|███████▌  | 107/142 [1:11:17<22:27, 38.51s/it]Running loglikelihood requests:  77%|███████▋  | 109/142 [1:12:31<20:53, 37.99s/it]Running loglikelihood requests:  78%|███████▊  | 111/142 [1:13:35<18:42, 36.20s/it]Running loglikelihood requests:  80%|███████▉  | 113/142 [1:14:44<17:15, 35.72s/it]Running loglikelihood requests:  81%|████████  | 115/142 [1:15:55<16:05, 35.75s/it]Running loglikelihood requests:  82%|████████▏ | 117/142 [1:16:41<13:15, 31.83s/it]Running loglikelihood requests:  84%|████████▍ | 119/142 [1:17:37<11:45, 30.66s/it]Running loglikelihood requests:  85%|████████▌ | 121/142 [1:18:53<11:32, 32.97s/it]Running loglikelihood requests:  87%|████████▋ | 123/142 [1:20:01<10:32, 33.28s/it]Running loglikelihood requests:  88%|████████▊ | 125/142 [1:21:21<09:57, 35.16s/it]Running loglikelihood requests:  89%|████████▉ | 127/142 [1:22:28<08:39, 34.67s/it]Running loglikelihood requests:  91%|█████████ | 129/142 [1:23:37<07:30, 34.64s/it]Running loglikelihood requests:  92%|█████████▏| 131/142 [1:24:39<06:09, 33.62s/it]Running loglikelihood requests:  94%|█████████▎| 133/142 [1:25:13<04:16, 28.54s/it]Running loglikelihood requests:  95%|█████████▌| 135/142 [1:25:56<03:05, 26.47s/it]Running loglikelihood requests:  96%|█████████▋| 137/142 [1:26:30<01:58, 23.61s/it]Running loglikelihood requests:  98%|█████████▊| 139/142 [1:27:08<01:06, 22.31s/it]Running loglikelihood requests:  99%|█████████▉| 141/142 [1:28:07<00:24, 24.40s/it]Running loglikelihood requests: 100%|██████████| 142/142 [1:28:07<00:00, 37.23s/it]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-3): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (4-8): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10-20): 11 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (21): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (22-23): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24-25): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (26): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (27-31): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-3): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (4-8): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10-20): 11 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (21): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (22-23): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24-25): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (26): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (27-31): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/159.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5231
INFO:werkzeug:127.0.0.1 - - [17/May/2025 02:07:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5231 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 231
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5047
INFO:werkzeug:127.0.0.1 - - [17/May/2025 02:07:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5047 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 47
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5121
INFO:werkzeug:127.0.0.1 - - [17/May/2025 02:07:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5121 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 121
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5025
INFO:werkzeug:127.0.0.1 - - [17/May/2025 02:07:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5025 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 25
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5222
INFO:werkzeug:127.0.0.1 - - [17/May/2025 02:07:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5222 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 222
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5014
INFO:werkzeug:127.0.0.1 - - [17/May/2025 02:07:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5014 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 14
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5209
INFO:werkzeug:127.0.0.1 - - [17/May/2025 02:07:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5209 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 209
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5146
INFO:werkzeug:127.0.0.1 - - [17/May/2025 02:07:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5146 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 146
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5070
INFO:werkzeug:127.0.0.1 - - [17/May/2025 02:07:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5070 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 70
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5041
INFO:werkzeug:127.0.0.1 - - [17/May/2025 02:07:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5041 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 41
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5183
INFO:werkzeug:127.0.0.1 - - [17/May/2025 02:07:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5183 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 183
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5176
INFO:werkzeug:127.0.0.1 - - [17/May/2025 02:07:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5176 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 176
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5190
INFO:werkzeug:127.0.0.1 - - [17/May/2025 02:07:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5190 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 190
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5199
INFO:werkzeug:127.0.0.1 - - [17/May/2025 02:07:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5199 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 199
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [17/May/2025 02:07:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5105
INFO:werkzeug:127.0.0.1 - - [17/May/2025 02:07:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5105 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 105
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5115
INFO:werkzeug:127.0.0.1 - - [17/May/2025 02:07:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5115 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 115
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [17/May/2025 02:07:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [17/May/2025 02:07:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5022
INFO:werkzeug:127.0.0.1 - - [17/May/2025 02:07:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5022 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 22
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [17/May/2025 02:07:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [17/May/2025 02:07:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5108
INFO:werkzeug:127.0.0.1 - - [17/May/2025 02:07:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5108 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 108
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [17/May/2025 02:07:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5019
INFO:werkzeug:127.0.0.1 - - [17/May/2025 02:07:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5019 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 19
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [17/May/2025 02:07:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5134
INFO:werkzeug:127.0.0.1 - - [17/May/2025 02:07:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5134 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 134
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [17/May/2025 02:07:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5197
INFO:werkzeug:127.0.0.1 - - [17/May/2025 02:07:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5197 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 197
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5137
INFO:werkzeug:127.0.0.1 - - [17/May/2025 02:07:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5137 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 137
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [17/May/2025 02:07:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140430571109888 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140430571109888 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430571109888 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140430571109888 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140430455434720 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140430455434720 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430455434720 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140430455434720 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[159] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.43661971830985913, 'acc_stderr,none': 0.05927935558412972}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8745617680355892
0.4870053329545456
0.7039635907698274
0.13683136283338845
0.45491781836309914
0.7394007339170455
0.7100810563328822
0.5089938007827006
0.6148932447522303
0.6097500975530942
0.2557945445996536
0.6585024343395449
0.3077968033302773
0.5696663704302732
0.4357302352587323
0.8508165638532892
0.2937402676601578
0.5546720889398816
0.456887590217546
0.8515148368106646
0.6351128178266827
0.587082322906938
0.4014945886309545
0.6816643170727646
0.7647343638504926
0.15578350583970074
0.7065213224778255
0.687952127174302
0.881700230921547
0.8745617680355892
0.4870053329545456
0.7039635907698274
0.13683136283338845
0.45491781836309914
0.7394007339170455
0.7100810563328822
0.5089938007827006
0.6148932447522303
0.6097500975530942
0.2557945445996536
0.6585024343395449
0.3077968033302773
0.5696663704302732
0.4357302352587323
0.8508165638532892
0.2937402676601578
0.5546720889398816
0.456887590217546
0.8515148368106646
0.6351128178266827
0.587082322906938
0.4014945886309545
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[5, 3, 7, 6, 1, 0, 4, 2]
tensor([5, 3, 7, 6, 1, 0, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 7, 1, 5, 6, 0, 4, 2]
tensor([3, 7, 1, 5, 6, 0, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[6, 3, 2, 4, 5, 1, 7, 0]
tensor([6, 3, 2, 4, 5, 1, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 4, 7, 5, 1, 3, 6, 0]
tensor([2, 4, 7, 5, 1, 3, 6, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[0, 2, 4, 6, 5, 1, 7, 3]
tensor([0, 2, 4, 6, 5, 1, 7, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 2, 5, 3, 6, 0, 7, 1]
tensor([4, 2, 5, 3, 6, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/159.pt
[RECEIVE] Queued message from 159
[QUEUE] Processing info from 159
[QUEUE] Stored info from 159
[RECEIVE] Queued message from 159
[QUEUE] Processing info from 159
[QUEUE] Stored info from 159
[RECEIVE] Queued message from 159
[QUEUE] Processing info from 159
[QUEUE] Stored info from 159
[RECEIVE] Queued message from 159
[QUEUE] Processing info from 159
[QUEUE] Stored info from 159
[RECEIVE] Queued message from 159
[QUEUE] Processing info from 159
[QUEUE] Stored info from 159
[RECEIVE] Queued message from 159
[QUEUE] Processing info from 159
[QUEUE] Stored info from 159
[RECEIVE] Queued message from 159
[QUEUE] Processing info from 159
[QUEUE] Stored info from 159
[RECEIVE] Queued message from 159
[QUEUE] Processing info from 159
[QUEUE] Stored info from 159
[RECEIVE] Queued message from 159
[QUEUE] Processing info from 159
[QUEUE] Stored info from 159
[RECEIVE] Queued message from 159
[QUEUE] Processing info from 159
[QUEUE] Stored info from 159
[RECEIVE] Queued message from 159
[QUEUE] Processing info from 159
[QUEUE] Stored info from 159
[RECEIVE] Queued message from 159
[QUEUE] Processing info from 159
[QUEUE] Stored info from 159
[RECEIVE] Queued message from 159
[QUEUE] Processing info from 159
[QUEUE] Stored info from 159
[RECEIVE] Queued message from 159
[QUEUE] Processing info from 159
[QUEUE] Stored info from 159
[RECEIVE] Queued message from 159
[QUEUE] Processing info from 159
[QUEUE] Stored info from 159
[RECEIVE] Queued message from 159
[QUEUE] Processing info from 159
[QUEUE] Stored info from 159
[RECEIVE] Queued message from 159
[QUEUE] Processing info from 159
[QUEUE] Stored info from 159
[RECEIVE] Queued message from 159
[QUEUE] Processing info from 159
[QUEUE] Stored info from 159
[RECEIVE] Queued message from 159
[QUEUE] Processing info from 159
[QUEUE] Stored info from 159
[RECEIVE] Queued message from 159
[QUEUE] Processing info from 159
[QUEUE] Stored info from 159
[RECEIVE] Queued message from 159
[QUEUE] Processing info from 159
[QUEUE] Stored info from 159
[RECEIVE] Queued message from 159
[QUEUE] Processing info from 159
[QUEUE] Stored info from 159
[RECEIVE] Queued message from 159
[QUEUE] Processing info from 159
[QUEUE] Stored info from 159
[RECEIVE] Queued message from 159
[QUEUE] Processing info from 159
[QUEUE] Stored info from 159
[RECEIVE] Queued message from 159
[QUEUE] Processing info from 159
[QUEUE] Stored info from 159
[RECEIVE] Queued message from 159
[QUEUE] Processing info from 159
[QUEUE] Stored info from 159
[RECEIVE] Queued message from 159
[QUEUE] Processing info from 159
[QUEUE] Stored info from 159
[RECEIVE] Queued message from 159
[QUEUE] Processing info from 159
[QUEUE] Stored info from 159
[RECEIVE] Queued message from 159
[QUEUE] Processing info from 159
[QUEUE] Stored info from 159
[RECEIVE] Queued message from 159
[QUEUE] Processing info from 159
[QUEUE] Stored info from 159
[RECEIVE] Queued message from 159
[QUEUE] Processing info from 159
[QUEUE] Stored info from 159
[134] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2608.92it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:58<2:16:18, 58.00s/it]Running loglikelihood requests:   2%|▏         | 3/142 [02:14<1:40:21, 43.32s/it]Running loglikelihood requests:   4%|▎         | 5/142 [03:30<1:32:53, 40.68s/it]Running loglikelihood requests:   5%|▍         | 7/142 [04:58<1:34:29, 42.00s/it]Running loglikelihood requests:   6%|▋         | 9/142 [06:19<1:31:49, 41.42s/it]Running loglikelihood requests:   8%|▊         | 11/142 [07:07<1:17:12, 35.36s/it]Running loglikelihood requests:   9%|▉         | 13/142 [08:21<1:17:13, 35.92s/it]Running loglikelihood requests:  11%|█         | 15/142 [09:29<1:14:35, 35.24s/it]Running loglikelihood requests:  12%|█▏        | 17/142 [10:47<1:16:08, 36.55s/it]Running loglikelihood requests:  13%|█▎        | 19/142 [12:17<1:20:16, 39.16s/it]Running loglikelihood requests:  15%|█▍        | 21/142 [13:16<1:12:57, 36.18s/it]Running loglikelihood requests:  16%|█▌        | 23/142 [13:56<1:01:45, 31.14s/it]Running loglikelihood requests:  18%|█▊        | 25/142 [15:01<1:01:41, 31.64s/it]Running loglikelihood requests:  19%|█▉        | 27/142 [16:11<1:02:38, 32.68s/it]Running loglikelihood requests:  20%|██        | 29/142 [17:29<1:05:05, 34.56s/it]Running loglikelihood requests:  22%|██▏       | 31/142 [19:00<1:09:59, 37.83s/it]Running loglikelihood requests:  23%|██▎       | 33/142 [20:33<1:13:29, 40.46s/it]Running loglikelihood requests:  25%|██▍       | 35/142 [21:33<1:06:33, 37.32s/it]Running loglikelihood requests:  26%|██▌       | 37/142 [22:35<1:02:04, 35.47s/it]Running loglikelihood requests:  27%|██▋       | 39/142 [23:24<55:12, 32.16s/it]  Running loglikelihood requests:  29%|██▉       | 41/142 [24:00<46:45, 27.78s/it]Running loglikelihood requests:  30%|███       | 43/142 [25:21<52:16, 31.68s/it]Running loglikelihood requests:  32%|███▏      | 45/142 [26:26<51:35, 31.91s/it]Running loglikelihood requests:  33%|███▎      | 47/142 [27:11<46:01, 29.07s/it]Running loglikelihood requests:  35%|███▍      | 49/142 [28:31<50:04, 32.31s/it]Running loglikelihood requests:  36%|███▌      | 51/142 [29:34<48:48, 32.19s/it]Running loglikelihood requests:  37%|███▋      | 53/142 [30:49<50:02, 33.73s/it]Running loglikelihood requests:  39%|███▊      | 55/142 [32:00<49:40, 34.26s/it]Running loglikelihood requests:  40%|████      | 57/142 [32:49<44:17, 31.27s/it]Running loglikelihood requests:  42%|████▏     | 59/142 [33:22<37:12, 26.90s/it]Running loglikelihood requests:  43%|████▎     | 61/142 [34:28<38:45, 28.71s/it]Running loglikelihood requests:  44%|████▍     | 63/142 [35:41<40:59, 31.13s/it]Running loglikelihood requests:  46%|████▌     | 65/142 [36:47<40:35, 31.63s/it]Running loglikelihood requests:  47%|████▋     | 67/142 [38:10<43:08, 34.51s/it]Running loglikelihood requests:  49%|████▊     | 69/142 [39:16<41:35, 34.18s/it]Running loglikelihood requests:  50%|█████     | 71/142 [40:43<43:38, 36.89s/it]Running loglikelihood requests:  51%|█████▏    | 73/142 [41:43<40:09, 34.92s/it]Running loglikelihood requests:  53%|█████▎    | 75/142 [43:08<41:32, 37.20s/it]Running loglikelihood requests:  54%|█████▍    | 77/142 [43:59<36:22, 33.57s/it]Running loglikelihood requests:  56%|█████▌    | 79/142 [45:08<35:37, 33.94s/it]Running loglikelihood requests:  57%|█████▋    | 81/142 [46:15<34:19, 33.77s/it]Running loglikelihood requests:  58%|█████▊    | 83/142 [47:18<32:32, 33.09s/it]Running loglikelihood requests:  60%|█████▉    | 85/142 [48:15<30:04, 31.65s/it]Running loglikelihood requests:  61%|██████▏   | 87/142 [49:25<29:56, 32.67s/it]Running loglikelihood requests:  63%|██████▎   | 89/142 [50:38<29:53, 33.83s/it]Running loglikelihood requests:  64%|██████▍   | 91/142 [51:48<29:01, 34.16s/it]Running loglikelihood requests:  65%|██████▌   | 93/142 [52:30<24:42, 30.25s/it]Running loglikelihood requests:  67%|██████▋   | 95/142 [53:31<23:49, 30.41s/it]Running loglikelihood requests:  68%|██████▊   | 97/142 [53:58<18:55, 25.24s/it]Running loglikelihood requests:  70%|██████▉   | 99/142 [55:00<19:21, 27.01s/it]Running loglikelihood requests:  71%|███████   | 101/142 [56:18<20:52, 30.55s/it]Running loglikelihood requests:  73%|███████▎  | 103/142 [57:18<19:48, 30.48s/it]Running loglikelihood requests:  74%|███████▍  | 105/142 [58:18<18:42, 30.33s/it]Running loglikelihood requests:  75%|███████▌  | 107/142 [59:27<18:23, 31.54s/it]Running loglikelihood requests:  77%|███████▋  | 109/142 [1:00:44<18:29, 33.61s/it]Running loglikelihood requests:  78%|███████▊  | 111/142 [1:02:03<18:18, 35.43s/it]Running loglikelihood requests:  80%|███████▉  | 113/142 [1:03:18<17:24, 36.00s/it]Running loglikelihood requests:  81%|████████  | 115/142 [1:04:23<15:43, 34.93s/it]Running loglikelihood requests:  82%|████████▏ | 117/142 [1:05:36<14:47, 35.50s/it]Running loglikelihood requests:  84%|████████▍ | 119/142 [1:06:47<13:33, 35.37s/it]Running loglikelihood requests:  85%|████████▌ | 121/142 [1:07:54<12:13, 34.92s/it]Running loglikelihood requests:  87%|████████▋ | 123/142 [1:08:40<09:55, 31.32s/it]Running loglikelihood requests:  88%|████████▊ | 125/142 [1:09:59<09:34, 33.79s/it]Running loglikelihood requests:  89%|████████▉ | 127/142 [1:11:03<08:17, 33.19s/it]Running loglikelihood requests:  91%|█████████ | 129/142 [1:12:20<07:31, 34.76s/it]Running loglikelihood requests:  92%|█████████▏| 131/142 [1:13:32<06:27, 35.24s/it]Running loglikelihood requests:  94%|█████████▎| 133/142 [1:14:40<05:13, 34.78s/it]Running loglikelihood requests:  95%|█████████▌| 135/142 [1:15:09<03:20, 28.70s/it]Running loglikelihood requests:  96%|█████████▋| 137/142 [1:15:26<01:53, 22.72s/it]Running loglikelihood requests:  98%|█████████▊| 139/142 [1:16:23<01:13, 24.45s/it]Running loglikelihood requests:  99%|█████████▉| 141/142 [1:17:33<00:27, 27.61s/it]Running loglikelihood requests: 100%|██████████| 142/142 [1:17:33<00:00, 32.77s/it]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-4): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-9): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (11-12): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (13): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14-19): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (20-21): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (22-23): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (25-31): 7 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-4): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-9): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (11-12): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (13): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14-19): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (20-21): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (22-23): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (25-31): 7 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/134.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5108
INFO:werkzeug:127.0.0.1 - - [17/May/2025 03:25:24] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5108 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 108
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5022
INFO:werkzeug:127.0.0.1 - - [17/May/2025 03:25:24] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5022 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 22
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5159
INFO:werkzeug:127.0.0.1 - - [17/May/2025 03:25:24] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5159 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 159
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5137
INFO:werkzeug:127.0.0.1 - - [17/May/2025 03:25:24] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5137 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 137
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [17/May/2025 03:25:24] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5025
INFO:werkzeug:127.0.0.1 - - [17/May/2025 03:25:24] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5025 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 25
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5190
INFO:werkzeug:127.0.0.1 - - [17/May/2025 03:25:24] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5190 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 190
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [17/May/2025 03:25:24] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5146
INFO:werkzeug:127.0.0.1 - - [17/May/2025 03:25:24] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5146 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 146
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5019
INFO:werkzeug:127.0.0.1 - - [17/May/2025 03:25:24] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5019 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 19
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [17/May/2025 03:25:24] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5121
INFO:werkzeug:127.0.0.1 - - [17/May/2025 03:25:24] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5121 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 121
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [17/May/2025 03:25:24] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [17/May/2025 03:25:24] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5222
INFO:werkzeug:127.0.0.1 - - [17/May/2025 03:25:24] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5222 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 222
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5209
INFO:werkzeug:127.0.0.1 - - [17/May/2025 03:25:24] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5209 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 209
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5115
INFO:werkzeug:127.0.0.1 - - [17/May/2025 03:25:24] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5115 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 115
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5070
INFO:werkzeug:127.0.0.1 - - [17/May/2025 03:25:24] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5070 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 70
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5047
INFO:werkzeug:127.0.0.1 - - [17/May/2025 03:25:24] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5047 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 47
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5041
INFO:werkzeug:127.0.0.1 - - [17/May/2025 03:25:24] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5041 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 41
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [17/May/2025 03:25:24] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5199
INFO:werkzeug:127.0.0.1 - - [17/May/2025 03:25:24] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5199 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 199
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5176
INFO:werkzeug:127.0.0.1 - - [17/May/2025 03:25:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5176 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 176
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5014
INFO:werkzeug:127.0.0.1 - - [17/May/2025 03:25:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5014 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 14
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5183
INFO:werkzeug:127.0.0.1 - - [17/May/2025 03:25:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5183 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 183
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5231
INFO:werkzeug:127.0.0.1 - - [17/May/2025 03:25:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5231 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 231
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [17/May/2025 03:25:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5105
INFO:werkzeug:127.0.0.1 - - [17/May/2025 03:25:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5105 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 105
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5197
INFO:werkzeug:127.0.0.1 - - [17/May/2025 03:25:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5197 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 197
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [17/May/2025 03:25:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [17/May/2025 03:25:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140430727476144 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140430727476144 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430727476144 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140430727476144 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140430676476752 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140430676476752 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430676476752 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140430676476752 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[134] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.43661971830985913, 'acc_stderr,none': 0.05927935558412972}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8840011732877091
0.9530187867791682
0.922962504956303
0.7839472459406365
0.8981387177104178
0.9267264969548299
0.5821108615798573
0.2837945650872556
0.6077879555368297
0.40197237439213185
0.8904940347912964
0.7509530386402397
0.901875691813653
0.9122390055224058
0.7316046462179062
0.7968435583929763
0.548007144578676
0.5393492220671232
0.9101317167988644
0.5489553505889563
0.4310648048222707
0.3687557715800523
0.8114931082909914
0.5012706843250611
0.2095243909347347
0.3518983916697559
0.9676050865236582
0.8840253404453832
0.6389046419601837
0.8840011732877091
0.9530187867791682
0.922962504956303
0.7839472459406365
0.8981387177104178
0.9267264969548299
0.5821108615798573
0.2837945650872556
0.6077879555368297
0.40197237439213185
0.8904940347912964
0.7509530386402397
0.901875691813653
0.9122390055224058
0.7316046462179062
0.7968435583929763
0.548007144578676
0.5393492220671232
0.9101317167988644
0.5489553505889563
Total groups 72 exceeded the threshold, stopping comparison.
The group tensor is
[1, 2, 7, 4, 3, 0, 6, 5]
tensor([1, 2, 7, 4, 3, 0, 6, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 5, 4, 1, 0, 7, 2]
tensor([6, 3, 5, 4, 1, 0, 7, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[1, 3, 6, 4, 2, 0, 7, 5]
tensor([1, 3, 6, 4, 2, 0, 7, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 3, 6, 4, 0, 1, 7, 2]
tensor([5, 3, 6, 4, 0, 1, 7, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 4, 6, 5, 3, 0, 7, 1]
tensor([2, 4, 6, 5, 3, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 5, 2, 4, 0, 1, 3]
tensor([0, 1, 5, 2, 4, 0, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/134.pt
[RECEIVE] Queued message from 134
[QUEUE] Processing info from 134
[QUEUE] Stored info from 134
[RECEIVE] Queued message from 134
[QUEUE] Processing info from 134
[QUEUE] Stored info from 134
[RECEIVE] Queued message from 134
[QUEUE] Processing info from 134
[QUEUE] Stored info from 134
[RECEIVE] Queued message from 134
[QUEUE] Processing info from 134
[QUEUE] Stored info from 134
[RECEIVE] Queued message from 134
[QUEUE] Processing info from 134
[QUEUE] Stored info from 134
[RECEIVE] Queued message from 134
[QUEUE] Processing info from 134
[QUEUE] Stored info from 134
[RECEIVE] Queued message from 134
[QUEUE] Processing info from 134
[QUEUE] Stored info from 134
[RECEIVE] Queued message from 134
[QUEUE] Processing info from 134
[QUEUE] Stored info from 134
[RECEIVE] Queued message from 134
[QUEUE] Processing info from 134
[QUEUE] Stored info from 134
[RECEIVE] Queued message from 134
[QUEUE] Processing info from 134
[QUEUE] Stored info from 134
[RECEIVE] Queued message from 134
[QUEUE] Processing info from 134
[QUEUE] Stored info from 134
[RECEIVE] Queued message from 134
[QUEUE] Processing info from 134
[QUEUE] Stored info from 134
[RECEIVE] Queued message from 134
[QUEUE] Processing info from 134
[QUEUE] Stored info from 134
[RECEIVE] Queued message from 134
[QUEUE] Processing info from 134
[QUEUE] Stored info from 134
[RECEIVE] Queued message from 134
[QUEUE] Processing info from 134
[QUEUE] Stored info from 134
[RECEIVE] Queued message from 134
[QUEUE] Processing info from 134
[QUEUE] Stored info from 134
[RECEIVE] Queued message from 134
[QUEUE] Processing info from 134
[QUEUE] Stored info from 134
[RECEIVE] Queued message from 134
[QUEUE] Processing info from 134
[QUEUE] Stored info from 134
[RECEIVE] Queued message from 134
[QUEUE] Processing info from 134
[QUEUE] Stored info from 134
[RECEIVE] Queued message from 134
[QUEUE] Processing info from 134
[QUEUE] Stored info from 134
[RECEIVE] Queued message from 134
[QUEUE] Processing info from 134
[QUEUE] Stored info from 134
[RECEIVE] Queued message from 134
[QUEUE] Processing info from 134
[QUEUE] Stored info from 134
[RECEIVE] Queued message from 134
[QUEUE] Processing info from 134
[QUEUE] Stored info from 134
[RECEIVE] Queued message from 134
[QUEUE] Processing info from 134
[QUEUE] Stored info from 134
[RECEIVE] Queued message from 134
[QUEUE] Processing info from 134
[QUEUE] Stored info from 134
[RECEIVE] Queued message from 134
[QUEUE] Processing info from 134
[QUEUE] Stored info from 134
[RECEIVE] Queued message from 134
[QUEUE] Processing info from 134
[QUEUE] Stored info from 134
[RECEIVE] Queued message from 134
[QUEUE] Processing info from 134
[QUEUE] Stored info from 134
[RECEIVE] Queued message from 134
[QUEUE] Processing info from 134
[QUEUE] Stored info from 134
[RECEIVE] Queued message from 134
[QUEUE] Processing info from 134
[QUEUE] Stored info from 134
[RECEIVE] Queued message from 134
[QUEUE] Processing info from 134
[QUEUE] Stored info from 134
[47] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2574.37it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [01:48<4:14:40, 108.37s/it]Running loglikelihood requests:   2%|▏         | 3/142 [03:25<2:28:29, 64.10s/it] Running loglikelihood requests:   4%|▎         | 5/142 [05:09<2:12:19, 57.95s/it]Running loglikelihood requests:   5%|▍         | 7/142 [06:30<1:53:43, 50.55s/it]Running loglikelihood requests:   6%|▋         | 9/142 [07:42<1:39:49, 45.03s/it]Running loglikelihood requests:   8%|▊         | 11/142 [08:58<1:32:55, 42.56s/it]Running loglikelihood requests:   9%|▉         | 13/142 [10:24<1:31:43, 42.66s/it]Running loglikelihood requests:  11%|█         | 15/142 [12:01<1:34:25, 44.61s/it]Running loglikelihood requests:  12%|█▏        | 17/142 [13:21<1:29:57, 43.18s/it]Running loglikelihood requests:  13%|█▎        | 19/142 [14:14<1:17:41, 37.90s/it]Running loglikelihood requests:  15%|█▍        | 21/142 [15:10<1:10:23, 34.91s/it]Running loglikelihood requests:  16%|█▌        | 23/142 [15:42<57:43, 29.10s/it]  Running loglikelihood requests:  18%|█▊        | 25/142 [16:10<48:00, 24.62s/it]Running loglikelihood requests:  19%|█▉        | 27/142 [16:24<36:52, 19.24s/it]Running loglikelihood requests:  20%|██        | 29/142 [16:42<30:17, 16.09s/it]Running loglikelihood requests:  22%|██▏       | 31/142 [16:59<25:42, 13.90s/it]Running loglikelihood requests:  23%|██▎       | 33/142 [17:12<21:05, 11.61s/it]Running loglikelihood requests:  25%|██▍       | 35/142 [17:30<19:16, 10.81s/it]Running loglikelihood requests:  26%|██▌       | 37/142 [17:51<18:55, 10.81s/it]Running loglikelihood requests:  27%|██▋       | 39/142 [18:04<16:06,  9.39s/it]Running loglikelihood requests:  29%|██▉       | 41/142 [18:12<13:17,  7.89s/it]Running loglikelihood requests:  30%|███       | 43/142 [18:35<14:45,  8.95s/it]Running loglikelihood requests:  32%|███▏      | 45/142 [18:55<14:48,  9.16s/it]Running loglikelihood requests:  33%|███▎      | 47/142 [19:16<15:10,  9.58s/it]Running loglikelihood requests:  35%|███▍      | 49/142 [19:39<15:48, 10.20s/it]Running loglikelihood requests:  36%|███▌      | 51/142 [20:08<17:22, 11.45s/it]Running loglikelihood requests:  37%|███▋      | 53/142 [20:17<14:01,  9.46s/it]Running loglikelihood requests:  39%|███▊      | 55/142 [20:33<13:00,  8.97s/it]Running loglikelihood requests:  40%|████      | 57/142 [20:48<12:01,  8.49s/it]Running loglikelihood requests:  42%|████▏     | 59/142 [21:02<11:04,  8.01s/it]Running loglikelihood requests:  43%|████▎     | 61/142 [21:20<11:16,  8.36s/it]Running loglikelihood requests:  44%|████▍     | 63/142 [21:34<10:31,  8.00s/it]Running loglikelihood requests:  46%|████▌     | 65/142 [21:56<11:21,  8.85s/it]Running loglikelihood requests:  47%|████▋     | 67/142 [22:14<11:09,  8.92s/it]Running loglikelihood requests:  49%|████▊     | 69/142 [22:31<10:45,  8.84s/it]Running loglikelihood requests:  50%|█████     | 71/142 [22:44<09:37,  8.13s/it]Running loglikelihood requests:  51%|█████▏    | 73/142 [23:00<09:15,  8.05s/it]Running loglikelihood requests:  53%|█████▎    | 75/142 [23:16<08:59,  8.06s/it]Running loglikelihood requests:  54%|█████▍    | 77/142 [23:39<09:47,  9.04s/it]Running loglikelihood requests:  56%|█████▌    | 79/142 [24:08<11:15, 10.73s/it]Running loglikelihood requests:  57%|█████▋    | 81/142 [24:15<08:40,  8.53s/it]Running loglikelihood requests:  58%|█████▊    | 83/142 [24:31<08:14,  8.38s/it]Running loglikelihood requests:  60%|█████▉    | 85/142 [24:55<08:58,  9.44s/it]Running loglikelihood requests:  61%|██████▏   | 87/142 [25:07<07:43,  8.42s/it]Running loglikelihood requests:  63%|██████▎   | 89/142 [25:35<08:57, 10.13s/it]Running loglikelihood requests:  64%|██████▍   | 91/142 [25:50<07:58,  9.38s/it]Running loglikelihood requests:  65%|██████▌   | 93/142 [26:02<06:46,  8.30s/it]Running loglikelihood requests:  67%|██████▋   | 95/142 [26:32<08:06, 10.35s/it]Running loglikelihood requests:  68%|██████▊   | 97/142 [26:52<07:39, 10.20s/it]Running loglikelihood requests:  70%|██████▉   | 99/142 [27:04<06:22,  8.90s/it]Running loglikelihood requests:  71%|███████   | 101/142 [27:28<06:46,  9.90s/it]Running loglikelihood requests:  73%|███████▎  | 103/142 [27:57<07:16, 11.18s/it]Running loglikelihood requests:  74%|███████▍  | 105/142 [28:24<07:19, 11.88s/it]Running loglikelihood requests:  75%|███████▌  | 107/142 [28:57<07:45, 13.29s/it]Running loglikelihood requests:  77%|███████▋  | 109/142 [29:55<09:55, 18.05s/it]Running loglikelihood requests:  78%|███████▊  | 111/142 [30:59<11:30, 22.26s/it]Running loglikelihood requests:  80%|███████▉  | 113/142 [32:03<12:09, 25.16s/it]Running loglikelihood requests:  81%|████████  | 115/142 [33:07<12:12, 27.14s/it]Running loglikelihood requests:  82%|████████▏ | 117/142 [34:10<11:52, 28.51s/it]Running loglikelihood requests:  84%|████████▍ | 119/142 [35:16<11:27, 29.87s/it]Running loglikelihood requests:  85%|████████▌ | 121/142 [36:07<09:58, 28.52s/it]Running loglikelihood requests:  87%|████████▋ | 123/142 [36:57<08:41, 27.47s/it]Running loglikelihood requests:  88%|████████▊ | 125/142 [37:47<07:34, 26.76s/it]Running loglikelihood requests:  89%|████████▉ | 127/142 [38:28<06:12, 24.84s/it]Running loglikelihood requests:  91%|█████████ | 129/142 [39:19<05:26, 25.08s/it]Running loglikelihood requests:  92%|█████████▏| 131/142 [40:12<04:39, 25.44s/it]Running loglikelihood requests:  94%|█████████▎| 133/142 [41:08<03:56, 26.25s/it]Running loglikelihood requests:  95%|█████████▌| 135/142 [42:06<03:09, 27.13s/it]Running loglikelihood requests:  96%|█████████▋| 137/142 [42:39<01:59, 23.95s/it]Running loglikelihood requests:  98%|█████████▊| 139/142 [43:22<01:09, 23.20s/it]Running loglikelihood requests:  99%|█████████▉| 141/142 [44:11<00:23, 23.54s/it]Running loglikelihood requests: 100%|██████████| 142/142 [44:11<00:00, 18.67s/it]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-8): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10-30): 21 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (31): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-8): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10-30): 21 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (31): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/47.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5190
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:10:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5190 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 190
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:10:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5183
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:10:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5183 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 183
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5159
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:10:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5159 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 159
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5231
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:10:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5231 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 231
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5025
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:10:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5025 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 25
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:10:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5105
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:10:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5105 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 105
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5108
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:10:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5108 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 108
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5222
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:10:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5222 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 222
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5041
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:10:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5041 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 41
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:10:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:10:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:10:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5176
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:10:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5176 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 176
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:10:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5121
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:10:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5121 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 121
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5022
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:10:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5022 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 22
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:10:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5134
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:10:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5134 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 134
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5197
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:10:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5197 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 197
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5209
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:10:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5209 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 209
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5070
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:10:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5070 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 70
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5146
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:10:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5146 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 146
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5019
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:10:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5019 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 19
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:10:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:10:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5115
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:10:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5115 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 115
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5137
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:10:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5137 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 137
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5199
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:10:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5199 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 199
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5014
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:10:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5014 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 14
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140430960242672 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140430960242672 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430960242672 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140430960242672 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140430583340960 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140430583340960 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430583340960 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140430583340960 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[47] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4507042253521127, 'acc_stderr,none': 0.05947027187738001}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.891975958338049
0.3982001908036579
0.26652204443251004
0.14111026067874816
0.11763525057572936
0.8635004180455561
0.8741394655456793
0.5304527321557103
0.44617634270319845
0.7007455592903002
0.6799150362476898
0.3511365594568724
0.47145939463701925
0.4744673317050211
0.905435493752087
0.903612941640167
0.8893763849001028
0.6821933807976941
0.6796182015499347
0.7774502436639344
0.8164788896198145
0.9011095591650676
0.8564639597370403
0.9528866120532432
0.4784452972921274
0.48852492817861076
0.8397355586186119
0.7433051149723976
0.5457687574271932
0.891975958338049
0.3982001908036579
0.26652204443251004
0.14111026067874816
0.11763525057572936
0.8635004180455561
0.8741394655456793
0.5304527321557103
0.44617634270319845
0.7007455592903002
0.6799150362476898
0.3511365594568724
0.47145939463701925
0.4744673317050211
0.905435493752087
0.903612941640167
0.8893763849001028
0.6821933807976941
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[6, 5, 4, 3, 2, 1, 7, 0]
tensor([6, 5, 4, 3, 2, 1, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 7, 4, 1, 0, 6, 3]
tensor([5, 2, 7, 4, 1, 0, 6, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 6, 5, 2, 4, 0, 7, 1]
tensor([3, 6, 5, 2, 4, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 4, 6, 0, 2, 1, 7, 3]
tensor([5, 4, 6, 0, 2, 1, 7, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 0, 7, 3, 5, 1, 6, 2]
tensor([4, 0, 7, 3, 5, 1, 6, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 5, 1, 3, 2, 0, 1, 4]
tensor([0, 5, 1, 3, 2, 0, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[1, 0, 0, 1, 1.0, 1.0, 1.0, 1.0]
tensor([1, 0, 0, 1, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[1, 0, 1, 1.0, 1.0, 0, 1.0, 1.0]
tensor([1, 0, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[0, 1, 1.0, 1.0, 0, 1, 1.0, 1.0]
tensor([0, 1, 1, 1, 0, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/47.pt
[RECEIVE] Queued message from 47
[QUEUE] Processing info from 47
[QUEUE] Stored info from 47
[RECEIVE] Queued message from 47
[QUEUE] Processing info from 47
[QUEUE] Stored info from 47
[RECEIVE] Queued message from 47
[QUEUE] Processing info from 47
[QUEUE] Stored info from 47
[RECEIVE] Queued message from 47
[QUEUE] Processing info from 47
[QUEUE] Stored info from 47
[RECEIVE] Queued message from 47
[QUEUE] Processing info from 47
[QUEUE] Stored info from 47
[RECEIVE] Queued message from 47
[QUEUE] Processing info from 47
[QUEUE] Stored info from 47
[RECEIVE] Queued message from 47
[QUEUE] Processing info from 47
[QUEUE] Stored info from 47
[RECEIVE] Queued message from 47
[QUEUE] Processing info from 47
[QUEUE] Stored info from 47
[RECEIVE] Queued message from 47
[QUEUE] Processing info from 47
[QUEUE] Stored info from 47
[RECEIVE] Queued message from 47
[QUEUE] Processing info from 47
[QUEUE] Stored info from 47
[RECEIVE] Queued message from 47
[QUEUE] Processing info from 47
[QUEUE] Stored info from 47
[RECEIVE] Queued message from 47
[QUEUE] Processing info from 47
[QUEUE] Stored info from 47
[RECEIVE] Queued message from 47
[QUEUE] Processing info from 47
[QUEUE] Stored info from 47
[RECEIVE] Queued message from 47
[QUEUE] Processing info from 47
[QUEUE] Stored info from 47
[RECEIVE] Queued message from 47
[QUEUE] Processing info from 47
[QUEUE] Stored info from 47
[RECEIVE] Queued message from 47
[QUEUE] Processing info from 47
[QUEUE] Stored info from 47
[RECEIVE] Queued message from 47
[QUEUE] Processing info from 47
[QUEUE] Stored info from 47
[RECEIVE] Queued message from 47
[QUEUE] Processing info from 47
[QUEUE] Stored info from 47
[RECEIVE] Queued message from 47
[QUEUE] Processing info from 47
[QUEUE] Stored info from 47
[RECEIVE] Queued message from 47
[QUEUE] Processing info from 47
[QUEUE] Stored info from 47
[RECEIVE] Queued message from 47
[QUEUE] Processing info from 47
[QUEUE] Stored info from 47
[RECEIVE] Queued message from 47
[QUEUE] Processing info from 47
[QUEUE] Stored info from 47
[RECEIVE] Queued message from 47
[QUEUE] Processing info from 47
[QUEUE] Stored info from 47
[RECEIVE] Queued message from 47
[QUEUE] Processing info from 47
[QUEUE] Stored info from 47
[RECEIVE] Queued message from 47
[QUEUE] Processing info from 47
[QUEUE] Stored info from 47
[RECEIVE] Queued message from 47
[QUEUE] Processing info from 47
[QUEUE] Stored info from 47
[RECEIVE] Queued message from 47
[QUEUE] Processing info from 47
[QUEUE] Stored info from 47
[RECEIVE] Queued message from 47
[QUEUE] Processing info from 47
[QUEUE] Stored info from 47
[RECEIVE] Queued message from 47
[QUEUE] Processing info from 47
[QUEUE] Stored info from 47
[RECEIVE] Queued message from 47
[QUEUE] Processing info from 47
[QUEUE] Stored info from 47
[RECEIVE] Queued message from 47
[QUEUE] Processing info from 47
[QUEUE] Stored info from 47
[25] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2606.73it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [01:31<3:34:51, 91.43s/it]Running loglikelihood requests:   2%|▏         | 3/142 [02:08<1:26:44, 37.44s/it]Running loglikelihood requests:   4%|▎         | 5/142 [02:53<1:07:50, 29.71s/it]Running loglikelihood requests:   5%|▍         | 7/142 [03:48<1:04:42, 28.76s/it]Running loglikelihood requests:   6%|▋         | 9/142 [04:49<1:05:14, 29.43s/it]Running loglikelihood requests:   8%|▊         | 11/142 [06:00<1:08:53, 31.55s/it]Running loglikelihood requests:   9%|▉         | 13/142 [06:38<58:52, 27.38s/it]  Running loglikelihood requests:  11%|█         | 15/142 [06:48<42:34, 20.12s/it]Running loglikelihood requests:  12%|█▏        | 17/142 [06:59<32:32, 15.62s/it]Running loglikelihood requests:  13%|█▎        | 19/142 [07:14<26:36, 12.98s/it]Running loglikelihood requests:  15%|█▍        | 21/142 [07:32<23:45, 11.78s/it]Running loglikelihood requests:  16%|█▌        | 23/142 [07:46<20:30, 10.34s/it]Running loglikelihood requests:  18%|█▊        | 25/142 [07:58<17:30,  8.98s/it]Running loglikelihood requests:  19%|█▉        | 27/142 [08:18<17:56,  9.36s/it]Running loglikelihood requests:  20%|██        | 29/142 [08:34<16:56,  8.99s/it]Running loglikelihood requests:  22%|██▏       | 31/142 [08:48<15:17,  8.27s/it]Running loglikelihood requests:  23%|██▎       | 33/142 [09:03<14:49,  8.16s/it]Running loglikelihood requests:  25%|██▍       | 35/142 [09:24<15:47,  8.85s/it]Running loglikelihood requests:  26%|██▌       | 37/142 [09:44<16:01,  9.15s/it]Running loglikelihood requests:  27%|██▋       | 39/142 [09:57<14:14,  8.30s/it]Running loglikelihood requests:  29%|██▉       | 41/142 [10:15<14:29,  8.61s/it]Running loglikelihood requests:  30%|███       | 43/142 [10:38<15:32,  9.42s/it]Running loglikelihood requests:  32%|███▏      | 45/142 [10:48<13:06,  8.11s/it]Running loglikelihood requests:  33%|███▎      | 47/142 [10:54<10:23,  6.57s/it]Running loglikelihood requests:  35%|███▍      | 49/142 [10:59<08:22,  5.40s/it]Running loglikelihood requests:  36%|███▌      | 51/142 [11:05<07:02,  4.64s/it]Running loglikelihood requests:  37%|███▋      | 53/142 [11:13<06:39,  4.48s/it]Running loglikelihood requests:  39%|███▊      | 55/142 [11:48<12:06,  8.35s/it]Running loglikelihood requests:  40%|████      | 57/142 [12:08<12:26,  8.78s/it]Running loglikelihood requests:  42%|████▏     | 59/142 [12:16<10:10,  7.35s/it]Running loglikelihood requests:  43%|████▎     | 61/142 [12:34<10:38,  7.88s/it]Running loglikelihood requests:  44%|████▍     | 63/142 [13:07<13:53, 10.55s/it]Running loglikelihood requests:  46%|████▌     | 65/142 [13:42<16:09, 12.60s/it]Running loglikelihood requests:  47%|████▋     | 67/142 [14:09<16:04, 12.86s/it]Running loglikelihood requests:  49%|████▊     | 69/142 [14:27<14:17, 11.75s/it]Running loglikelihood requests:  50%|█████     | 71/142 [14:49<13:35, 11.49s/it]Running loglikelihood requests:  51%|█████▏    | 73/142 [15:10<12:53, 11.22s/it]Running loglikelihood requests:  53%|█████▎    | 75/142 [15:48<15:05, 13.51s/it]Running loglikelihood requests:  54%|█████▍    | 77/142 [16:52<20:34, 19.00s/it]Running loglikelihood requests:  56%|█████▌    | 79/142 [17:16<17:45, 16.91s/it]Running loglikelihood requests:  57%|█████▋    | 81/142 [17:45<16:34, 16.30s/it]Running loglikelihood requests:  58%|█████▊    | 83/142 [18:20<16:22, 16.66s/it]Running loglikelihood requests:  60%|█████▉    | 85/142 [19:12<18:22, 19.33s/it]Running loglikelihood requests:  61%|██████▏   | 87/142 [19:41<16:23, 17.89s/it]Running loglikelihood requests:  63%|██████▎   | 89/142 [20:16<15:47, 17.89s/it]Running loglikelihood requests:  64%|██████▍   | 91/142 [20:28<12:07, 14.26s/it]Running loglikelihood requests:  65%|██████▌   | 93/142 [20:48<10:35, 12.96s/it]Running loglikelihood requests:  67%|██████▋   | 95/142 [21:08<09:26, 12.06s/it]Running loglikelihood requests:  68%|██████▊   | 97/142 [21:33<09:10, 12.24s/it]Running loglikelihood requests:  70%|██████▉   | 99/142 [21:41<06:56,  9.69s/it]Running loglikelihood requests:  71%|███████   | 101/142 [22:01<06:44,  9.86s/it]Running loglikelihood requests:  73%|███████▎  | 103/142 [22:10<05:22,  8.27s/it]Running loglikelihood requests:  74%|███████▍  | 105/142 [22:18<04:16,  6.94s/it]Running loglikelihood requests:  75%|███████▌  | 107/142 [22:28<03:41,  6.32s/it]Running loglikelihood requests:  77%|███████▋  | 109/142 [22:49<04:11,  7.63s/it]Running loglikelihood requests:  78%|███████▊  | 111/142 [23:04<03:57,  7.66s/it]Running loglikelihood requests:  80%|███████▉  | 113/142 [23:13<03:11,  6.59s/it]Running loglikelihood requests:  81%|████████  | 115/142 [23:24<02:52,  6.38s/it]Running loglikelihood requests:  82%|████████▏ | 117/142 [23:39<02:45,  6.62s/it]Running loglikelihood requests:  84%|████████▍ | 119/142 [24:22<04:15, 11.10s/it]Running loglikelihood requests:  85%|████████▌ | 121/142 [25:18<05:39, 16.16s/it]Running loglikelihood requests:  87%|████████▋ | 123/142 [26:26<06:48, 21.48s/it]Running loglikelihood requests:  88%|████████▊ | 125/142 [27:21<06:37, 23.41s/it]Running loglikelihood requests:  89%|████████▉ | 127/142 [28:36<06:52, 27.50s/it]Running loglikelihood requests:  91%|█████████ | 129/142 [29:15<05:27, 25.19s/it]Running loglikelihood requests:  92%|█████████▏| 131/142 [30:06<04:37, 25.21s/it]Running loglikelihood requests:  94%|█████████▎| 133/142 [30:38<03:22, 22.46s/it]Running loglikelihood requests:  95%|█████████▌| 135/142 [31:28<02:42, 23.23s/it]Running loglikelihood requests:  96%|█████████▋| 137/142 [32:06<01:49, 21.92s/it]Running loglikelihood requests:  98%|█████████▊| 139/142 [32:39<01:01, 20.44s/it]Running loglikelihood requests:  99%|█████████▉| 141/142 [33:46<00:24, 24.22s/it]Running loglikelihood requests: 100%|██████████| 142/142 [33:46<00:00, 14.27s/it]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-3): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (4-11): 8 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (12): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (13): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14-31): 18 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-3): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (4-11): 8 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (12): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (13): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14-31): 18 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/25.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5137
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:44:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5137 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 137
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:44:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5146
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:44:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5146 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 146
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5183
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:44:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5183 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 183
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5190
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:44:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5190 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 190
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:44:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5199
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:44:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5199 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 199
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:44:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5041
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:44:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5041 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 41
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5022
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:44:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5022 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 22
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:44:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5105
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:44:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5105 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 105
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:44:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5222
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:44:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5222 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 222
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5134
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:44:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5134 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 134
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5209
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:44:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5209 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 209
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5197
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:44:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5197 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 197
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:44:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5121
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:44:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5121 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 121
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5019
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:44:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5019 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 19
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:44:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5115
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:44:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5115 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 115
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5231
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:44:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5231 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 231
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5159
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:44:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5159 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 159
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5070
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:44:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5070 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 70
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5014
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:44:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5014 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 14
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:44:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5047
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:44:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5047 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 47
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:44:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5108
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:44:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5108 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 108
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5176
INFO:werkzeug:127.0.0.1 - - [17/May/2025 04:44:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5176 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 176
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140430675084304 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140430675084304 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430675084304 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140430675084304 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140430568498832 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140430568498832 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140430568498832 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140430568498832 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[25] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4788732394366197, 'acc_stderr,none': 0.05970805879899505}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.6890224269714
0.6519987454814186
0.44009979043140846
0.5066155659876163
0.7217003976797293
0.12899593918836094
0.4620116191334168
0.3468065225687064
0.10107939599729882
0.5600103662507451
0.577132167051305
0.6748045019607131
0.4004557650420357
0.700349463047757
0.9095160148001629
0.6131975246160634
0.5678386109581075
0.8437866782628755
0.3536670789186643
0.44960924435079147
0.5862896519346712
0.8246697057441258
0.5484674172302575
0.3288911762125467
0.6478473442183775
0.571596663207821
0.7179565348178579
0.38406312361402845
0.42349247998810474
0.6890224269714
0.6519987454814186
0.44009979043140846
0.5066155659876163
0.7217003976797293
0.12899593918836094
0.4620116191334168
0.3468065225687064
0.10107939599729882
0.5600103662507451
0.577132167051305
0.6748045019607131
0.4004557650420357
0.700349463047757
0.9095160148001629
0.6131975246160634
0.5678386109581075
0.8437866782628755
0.3536670789186643
0.44960924435079147
0.5862896519346712
0.8246697057441258
0.5484674172302575
0.3288911762125467
0.6478473442183775
0.571596663207821
Total groups 70 exceeded the threshold, stopping comparison.
The group tensor is
[5, 3, 7, 6, 2, 1, 4, 0]
tensor([5, 3, 7, 6, 2, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 5, 1, 3, 4, 0, 6, 2]
tensor([7, 5, 1, 3, 4, 0, 6, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 7, 2, 1, 0, 4, 5]
tensor([6, 3, 7, 2, 1, 0, 4, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 7, 5, 2, 1, 4, 0]
tensor([6, 3, 7, 5, 2, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 3, 2, 5, 1, 0, 4, 6]
tensor([7, 3, 2, 5, 1, 0, 4, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 2, 3, 0, 3, 2, 1]
tensor([0, 1, 2, 3, 0, 3, 2, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/25.pt
[RECEIVE] Queued message from 25
[QUEUE] Processing info from 25
[QUEUE] Stored info from 25
[RECEIVE] Queued message from 25
[QUEUE] Processing info from 25
[QUEUE] Stored info from 25
[RECEIVE] Queued message from 25
[QUEUE] Processing info from 25
[QUEUE] Stored info from 25
[RECEIVE] Queued message from 25
[QUEUE] Processing info from 25
[QUEUE] Stored info from 25
[RECEIVE] Queued message from 25
[QUEUE] Processing info from 25
[QUEUE] Stored info from 25
[RECEIVE] Queued message from 25
[QUEUE] Processing info from 25
[QUEUE] Stored info from 25
[RECEIVE] Queued message from 25
[QUEUE] Processing info from 25
[QUEUE] Stored info from 25
[RECEIVE] Queued message from 25
[QUEUE] Processing info from 25
[QUEUE] Stored info from 25
[RECEIVE] Queued message from 25
[QUEUE] Processing info from 25
[QUEUE] Stored info from 25
[RECEIVE] Queued message from 25
[QUEUE] Processing info from 25
[QUEUE] Stored info from 25
[RECEIVE] Queued message from 25
[QUEUE] Processing info from 25
[QUEUE] Stored info from 25
[RECEIVE] Queued message from 25
[QUEUE] Processing info from 25
[QUEUE] Stored info from 25
[RECEIVE] Queued message from 25
[QUEUE] Processing info from 25
[QUEUE] Stored info from 25
[RECEIVE] Queued message from 25
[QUEUE] Processing info from 25
[QUEUE] Stored info from 25
[RECEIVE] Queued message from 25
[QUEUE] Processing info from 25
[QUEUE] Stored info from 25
[RECEIVE] Queued message from 25
[QUEUE] Processing info from 25
[QUEUE] Stored info from 25
[RECEIVE] Queued message from 25
[QUEUE] Processing info from 25
[QUEUE] Stored info from 25
[RECEIVE] Queued message from 25
[QUEUE] Processing info from 25
[QUEUE] Stored info from 25
[RECEIVE] Queued message from 25
[QUEUE] Processing info from 25
[QUEUE] Stored info from 25
[RECEIVE] Queued message from 25
[QUEUE] Processing info from 25
[QUEUE] Stored info from 25
[RECEIVE] Queued message from 25
[QUEUE] Processing info from 25
[QUEUE] Stored info from 25
[RECEIVE] Queued message from 25
[QUEUE] Processing info from 25
[QUEUE] Stored info from 25
[RECEIVE] Queued message from 25
[QUEUE] Processing info from 25
[QUEUE] Stored info from 25
[RECEIVE] Queued message from 25
[QUEUE] Processing info from 25
[QUEUE] Stored info from 25
[RECEIVE] Queued message from 25
[QUEUE] Processing info from 25
[QUEUE] Stored info from 25
[RECEIVE] Queued message from 25
[QUEUE] Processing info from 25
[QUEUE] Stored info from 25
[RECEIVE] Queued message from 25
[QUEUE] Processing info from 25
[QUEUE] Stored info from 25
[RECEIVE] Queued message from 25
[QUEUE] Processing info from 25
[QUEUE] Stored info from 25
[RECEIVE] Queued message from 25
[QUEUE] Processing info from 25
[QUEUE] Stored info from 25
[RECEIVE] Queued message from 25
[QUEUE] Processing info from 25
[QUEUE] Stored info from 25
[RECEIVE] Queued message from 25
[QUEUE] Processing info from 25
[QUEUE] Stored info from 25
[178] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2583.24it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [01:27<3:24:58, 87.22s/it]Running loglikelihood requests:   2%|▏         | 3/142 [02:41<1:55:56, 50.05s/it]Running loglikelihood requests:   4%|▎         | 5/142 [03:01<1:07:17, 29.47s/it]Running loglikelihood requests:   5%|▍         | 7/142 [03:29<51:45, 23.00s/it]  Running loglikelihood requests:   6%|▋         | 9/142 [05:17<1:16:52, 34.68s/it]Running loglikelihood requests:   8%|▊         | 11/142 [06:52<1:25:18, 39.07s/it]Running loglikelihood requests:   9%|▉         | 13/142 [08:41<1:35:07, 44.24s/it]