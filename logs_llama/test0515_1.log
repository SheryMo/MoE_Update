nohup: ignoring input
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:0'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}
网络架构：{'183': ['40', '108', '110', '157', '234', '202', '30', '73', '225', '81', '148', '218', '101', '53', '19'], '53': ['108', '30', '73', '101', '148', '110', '19', '81', '225', '218', '157', '234', '40', '202', '183'], '148': ['81', '202', '101', '234', '218', '108', '225', '19', '40', '183', '73', '53', '30', '157', '110'], '40': ['110', '202', '19', '148', '218', '183', '108', '225', '30', '53', '81', '234', '157', '101', '73'], '157': ['183', '19', '218', '81', '30', '110', '73', '108', '148', '101', '234', '225', '53', '202', '40'], '101': ['40', '108', '183', '218', '30', '73', '19', '202', '110', '148', '81', '157', '53', '234', '225'], '30': ['101', '40', '234', '225', '81', '53', '73', '157', '19', '218', '202', '110', '183', '108', '148'], '218': ['30', '225', '40', '234', '73', '157', '19', '148', '110', '183', '81', '202', '101', '53', '108'], '73': ['148', '183', '19', '81', '110', '157', '30', '101', '218', '225', '108', '202', '53', '234', '40'], '19': ['53', '101', '40', '183', '81', '73', '30', '157', '148', '110', '225', '108', '218', '234', '202'], '202': ['19', '101', '30', '225', '40', '148', '234', '183', '81', '73', '157', '108', '53', '110', '218'], '108': ['157', '19', '30', '110', '218', '73', '40', '81', '234', '148', '53', '225', '101', '202', '183'], '225': ['234', '148', '218', '30', '110', '202', '101', '157', '53', '108', '73', '40', '183', '19', '81'], '81': ['19', '110', '108', '218', '202', '157', '53', '73', '183', '234', '40', '225', '148', '101', '30'], '110': ['73', '225', '108', '19', '101', '218', '157', '40', '53', '202', '148', '81', '30', '183', '234'], '234': ['225', '218', '53', '110', '108', '101', '73', '19', '202', '183', '148', '81', '157', '30', '40']}
183
cuda:0
sciq
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [01:00<01:00, 60.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:19<00:00, 36.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:19<00:00, 39.96s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq HTTP/1.1" 200 1238
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/sciq/sciq.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq HTTP/1.1" 200 1238
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/allenai/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq/revision/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 111
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq/revision/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 1238
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq/tree/2c94ad3e1aafab77146f384e23536f97a4849815?recursive=False&expand=False HTTP/1.1" 307 136
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq/tree/2c94ad3e1aafab77146f384e23536f97a4849815?recursive=False&expand=False HTTP/1.1" 200 291
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq/tree/2c94ad3e1aafab77146f384e23536f97a4849815/data?recursive=False&expand=False HTTP/1.1" 307 141
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq/tree/2c94ad3e1aafab77146f384e23536f97a4849815/data?recursive=False&expand=False HTTP/1.1" 200 358
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq/revision/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 111
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq/revision/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 1238
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/allenai/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:filelock:Attempting to acquire lock 139708038834144 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:filelock:Lock 139708038834144 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_info.json
DEBUG:filelock:Attempting to release lock 139708038834144 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:filelock:Lock 139708038834144 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:filelock:Attempting to acquire lock 139706769210400 on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:filelock:Lock 139706769210400 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_info.json
DEBUG:filelock:Attempting to release lock 139706769210400 on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:filelock:Lock 139706769210400 released on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of sciq from None to 0
INFO:lm_eval.api.task:Building contexts for sciq on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1020.73it/s]
DEBUG:lm_eval.evaluator:Task: sciq; number of requests on this rank: 400
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/400 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/400 [00:05<39:39,  5.96s/it]Running loglikelihood requests:   0%|          | 2/400 [00:09<29:09,  4.40s/it]Running loglikelihood requests:   1%|          | 3/400 [00:12<25:38,  3.87s/it]Running loglikelihood requests:   1%|          | 4/400 [00:15<23:56,  3.63s/it]Running loglikelihood requests:   1%|▏         | 5/400 [00:18<22:35,  3.43s/it]Running loglikelihood requests:   2%|▏         | 6/400 [00:21<21:40,  3.30s/it]Running loglikelihood requests:   2%|▏         | 7/400 [00:24<21:04,  3.22s/it]Running loglikelihood requests:   2%|▏         | 8/400 [00:27<20:39,  3.16s/it]Running loglikelihood requests:   2%|▏         | 9/400 [00:30<19:42,  3.03s/it]Running loglikelihood requests:   2%|▎         | 10/400 [00:33<19:02,  2.93s/it]Running loglikelihood requests:   3%|▎         | 11/400 [00:36<18:34,  2.86s/it]Running loglikelihood requests:   3%|▎         | 12/400 [00:38<18:12,  2.82s/it]Running loglikelihood requests:   3%|▎         | 13/400 [00:41<17:33,  2.72s/it]Running loglikelihood requests:   4%|▎         | 14/400 [00:43<17:04,  2.66s/it]Running loglikelihood requests:   4%|▍         | 15/400 [00:46<16:44,  2.61s/it]Running loglikelihood requests:   4%|▍         | 16/400 [00:48<16:30,  2.58s/it]Running loglikelihood requests:   4%|▍         | 17/400 [00:51<16:16,  2.55s/it]Running loglikelihood requests:   4%|▍         | 18/400 [00:53<15:58,  2.51s/it]Running loglikelihood requests:   5%|▍         | 19/400 [00:56<15:44,  2.48s/it]Running loglikelihood requests:   5%|▌         | 20/400 [00:58<15:39,  2.47s/it]Running loglikelihood requests:   5%|▌         | 21/400 [01:01<15:27,  2.45s/it]Running loglikelihood requests:   6%|▌         | 22/400 [01:03<15:18,  2.43s/it]Running loglikelihood requests:   6%|▌         | 23/400 [01:05<15:10,  2.42s/it]Running loglikelihood requests:   6%|▌         | 24/400 [01:08<15:04,  2.41s/it]Running loglikelihood requests:   6%|▋         | 25/400 [01:10<14:42,  2.35s/it]Running loglikelihood requests:   6%|▋         | 26/400 [01:12<14:26,  2.32s/it]Running loglikelihood requests:   7%|▋         | 27/400 [01:14<14:14,  2.29s/it]Running loglikelihood requests:   7%|▋         | 28/400 [01:17<14:04,  2.27s/it]Running loglikelihood requests:   7%|▋         | 29/400 [01:19<13:34,  2.20s/it]Running loglikelihood requests:   8%|▊         | 30/400 [01:21<13:13,  2.14s/it]Running loglikelihood requests:   8%|▊         | 31/400 [01:23<12:56,  2.11s/it]Running loglikelihood requests:   8%|▊         | 32/400 [01:25<12:44,  2.08s/it]Running loglikelihood requests:   8%|▊         | 33/400 [01:27<12:21,  2.02s/it]Running loglikelihood requests:   8%|▊         | 34/400 [01:28<12:05,  1.98s/it]Running loglikelihood requests:   9%|▉         | 35/400 [01:30<11:53,  1.96s/it]Running loglikelihood requests:   9%|▉         | 36/400 [01:32<11:45,  1.94s/it]Running loglikelihood requests:   9%|▉         | 37/400 [01:34<11:37,  1.92s/it]Running loglikelihood requests:  10%|▉         | 38/400 [01:36<11:32,  1.91s/it]Running loglikelihood requests:  10%|█         | 40/400 [01:38<08:47,  1.46s/it]Running loglikelihood requests:  10%|█         | 41/400 [01:40<09:09,  1.53s/it]Running loglikelihood requests:  10%|█         | 42/400 [01:41<09:26,  1.58s/it]Running loglikelihood requests:  11%|█         | 43/400 [01:43<09:39,  1.62s/it]Running loglikelihood requests:  11%|█         | 44/400 [01:45<09:47,  1.65s/it]Running loglikelihood requests:  11%|█▏        | 45/400 [01:46<09:46,  1.65s/it]Running loglikelihood requests:  12%|█▏        | 46/400 [01:48<09:44,  1.65s/it]Running loglikelihood requests:  12%|█▏        | 47/400 [01:50<09:42,  1.65s/it]Running loglikelihood requests:  12%|█▏        | 48/400 [01:51<09:41,  1.65s/it]Running loglikelihood requests:  12%|█▏        | 49/400 [01:53<09:39,  1.65s/it]Running loglikelihood requests:  12%|█▎        | 50/400 [01:55<09:36,  1.65s/it]Running loglikelihood requests:  13%|█▎        | 51/400 [01:56<09:33,  1.64s/it]Running loglikelihood requests:  13%|█▎        | 52/400 [01:58<09:31,  1.64s/it]Running loglikelihood requests:  13%|█▎        | 53/400 [01:59<09:12,  1.59s/it]Running loglikelihood requests:  14%|█▎        | 54/400 [02:01<08:58,  1.56s/it]Running loglikelihood requests:  14%|█▍        | 55/400 [02:02<08:47,  1.53s/it]Running loglikelihood requests:  14%|█▍        | 57/400 [02:04<06:34,  1.15s/it]Running loglikelihood requests:  14%|█▍        | 58/400 [02:05<06:54,  1.21s/it]Running loglikelihood requests:  15%|█▍        | 59/400 [02:07<07:10,  1.26s/it]Running loglikelihood requests:  16%|█▌        | 62/400 [02:08<04:44,  1.19it/s]Running loglikelihood requests:  16%|█▌        | 63/400 [02:09<05:21,  1.05it/s]Running loglikelihood requests:  16%|█▌        | 64/400 [02:11<05:54,  1.05s/it]Running loglikelihood requests:  16%|█▋        | 65/400 [02:12<06:17,  1.13s/it]Running loglikelihood requests:  16%|█▋        | 66/400 [02:14<06:35,  1.18s/it]Running loglikelihood requests:  17%|█▋        | 67/400 [02:15<06:49,  1.23s/it]Running loglikelihood requests:  17%|█▋        | 68/400 [02:16<06:59,  1.26s/it]Running loglikelihood requests:  17%|█▋        | 69/400 [02:18<07:03,  1.28s/it]Running loglikelihood requests:  18%|█▊        | 70/400 [02:19<07:07,  1.29s/it]Running loglikelihood requests:  18%|█▊        | 71/400 [02:20<07:08,  1.30s/it]Running loglikelihood requests:  18%|█▊        | 72/400 [02:22<07:09,  1.31s/it]Running loglikelihood requests:  18%|█▊        | 73/400 [02:23<07:37,  1.40s/it]Running loglikelihood requests:  18%|█▊        | 74/400 [02:24<07:28,  1.38s/it]Running loglikelihood requests:  19%|█▉        | 77/400 [02:26<04:32,  1.18it/s]Running loglikelihood requests:  20%|█▉        | 78/400 [02:27<05:01,  1.07it/s]Running loglikelihood requests:  20%|█▉        | 79/400 [02:28<05:25,  1.01s/it]Running loglikelihood requests:  20%|██        | 81/400 [02:29<04:28,  1.19it/s]Running loglikelihood requests:  20%|██        | 82/400 [02:31<04:50,  1.10it/s]Running loglikelihood requests:  21%|██        | 83/400 [02:32<05:07,  1.03it/s]Running loglikelihood requests:  21%|██        | 84/400 [02:33<05:22,  1.02s/it]Running loglikelihood requests:  21%|██▏       | 85/400 [02:34<05:32,  1.06s/it]Running loglikelihood requests:  22%|██▏       | 86/400 [02:35<05:38,  1.08s/it]Running loglikelihood requests:  22%|██▏       | 89/400 [02:36<03:37,  1.43it/s]Running loglikelihood requests:  22%|██▎       | 90/400 [02:37<04:04,  1.27it/s]Running loglikelihood requests:  23%|██▎       | 91/400 [02:39<04:27,  1.16it/s]Running loglikelihood requests:  23%|██▎       | 92/400 [02:40<04:46,  1.08it/s]Running loglikelihood requests:  23%|██▎       | 93/400 [02:41<05:00,  1.02it/s]Running loglikelihood requests:  24%|██▍       | 97/400 [02:42<02:50,  1.78it/s]Running loglikelihood requests:  24%|██▍       | 98/400 [02:43<03:18,  1.52it/s]Running loglikelihood requests:  25%|██▍       | 99/400 [02:44<03:45,  1.34it/s]Running loglikelihood requests:  25%|██▌       | 100/400 [02:45<04:08,  1.21it/s]Running loglikelihood requests:  25%|██▌       | 101/400 [02:46<04:27,  1.12it/s]Running loglikelihood requests:  26%|██▌       | 102/400 [02:48<04:42,  1.06it/s]Running loglikelihood requests:  26%|██▌       | 103/400 [02:49<04:53,  1.01it/s]Running loglikelihood requests:  26%|██▌       | 104/400 [02:50<05:01,  1.02s/it]Running loglikelihood requests:  26%|██▋       | 105/400 [02:51<05:06,  1.04s/it]Running loglikelihood requests:  26%|██▋       | 106/400 [02:52<05:09,  1.05s/it]Running loglikelihood requests:  27%|██▋       | 107/400 [02:53<05:11,  1.06s/it]Running loglikelihood requests:  27%|██▋       | 108/400 [02:54<05:12,  1.07s/it]Running loglikelihood requests:  27%|██▋       | 109/400 [02:55<05:10,  1.07s/it]Running loglikelihood requests:  28%|██▊       | 110/400 [02:56<05:09,  1.07s/it]Running loglikelihood requests:  28%|██▊       | 111/400 [02:57<05:07,  1.06s/it]Running loglikelihood requests:  28%|██▊       | 112/400 [02:58<05:06,  1.06s/it]Running loglikelihood requests:  28%|██▊       | 113/400 [02:59<05:04,  1.06s/it]Running loglikelihood requests:  28%|██▊       | 114/400 [03:00<05:03,  1.06s/it]Running loglikelihood requests:  29%|██▉       | 115/400 [03:01<05:01,  1.06s/it]Running loglikelihood requests:  29%|██▉       | 116/400 [03:03<04:58,  1.05s/it]Running loglikelihood requests:  29%|██▉       | 117/400 [03:04<04:55,  1.05s/it]Running loglikelihood requests:  30%|██▉       | 118/400 [03:05<04:52,  1.04s/it]Running loglikelihood requests:  30%|██▉       | 119/400 [03:06<04:49,  1.03s/it]Running loglikelihood requests:  30%|███       | 120/400 [03:07<04:48,  1.03s/it]Running loglikelihood requests:  30%|███       | 121/400 [03:08<04:46,  1.03s/it]Running loglikelihood requests:  30%|███       | 122/400 [03:09<04:44,  1.02s/it]Running loglikelihood requests:  31%|███       | 123/400 [03:10<04:43,  1.02s/it]Running loglikelihood requests:  31%|███       | 124/400 [03:11<04:41,  1.02s/it]Running loglikelihood requests:  31%|███▏      | 125/400 [03:12<04:39,  1.01s/it]Running loglikelihood requests:  32%|███▏      | 126/400 [03:13<04:36,  1.01s/it]Running loglikelihood requests:  32%|███▏      | 127/400 [03:14<04:34,  1.01s/it]Running loglikelihood requests:  32%|███▏      | 128/400 [03:15<04:32,  1.00s/it]Running loglikelihood requests:  32%|███▏      | 129/400 [03:16<04:30,  1.00it/s]Running loglikelihood requests:  32%|███▎      | 130/400 [03:17<04:30,  1.00s/it]Running loglikelihood requests:  33%|███▎      | 131/400 [03:18<04:28,  1.00it/s]Running loglikelihood requests:  34%|███▎      | 134/400 [03:19<02:45,  1.61it/s]Running loglikelihood requests:  34%|███▍      | 135/400 [03:20<03:04,  1.43it/s]Running loglikelihood requests:  34%|███▍      | 136/400 [03:21<03:20,  1.31it/s]Running loglikelihood requests:  34%|███▍      | 137/400 [03:22<03:34,  1.23it/s]Running loglikelihood requests:  34%|███▍      | 138/400 [03:23<03:44,  1.17it/s]Running loglikelihood requests:  35%|███▍      | 139/400 [03:24<03:51,  1.13it/s]Running loglikelihood requests:  36%|███▌      | 142/400 [03:24<02:30,  1.71it/s]Running loglikelihood requests:  36%|███▌      | 143/400 [03:25<02:50,  1.51it/s]Running loglikelihood requests:  36%|███▌      | 144/400 [03:26<03:07,  1.37it/s]Running loglikelihood requests:  36%|███▋      | 145/400 [03:27<03:21,  1.27it/s]Running loglikelihood requests:  36%|███▋      | 146/400 [03:28<03:31,  1.20it/s]Running loglikelihood requests:  37%|███▋      | 147/400 [03:29<03:39,  1.15it/s]Running loglikelihood requests:  37%|███▋      | 148/400 [03:30<03:45,  1.12it/s]Running loglikelihood requests:  37%|███▋      | 149/400 [03:31<03:48,  1.10it/s]Running loglikelihood requests:  38%|███▊      | 150/400 [03:32<03:52,  1.08it/s]Running loglikelihood requests:  38%|███▊      | 151/400 [03:34<04:25,  1.07s/it]Running loglikelihood requests:  38%|███▊      | 152/400 [03:35<04:21,  1.05s/it]Running loglikelihood requests:  38%|███▊      | 153/400 [03:36<04:18,  1.05s/it]Running loglikelihood requests:  38%|███▊      | 154/400 [03:37<04:10,  1.02s/it]Running loglikelihood requests:  39%|███▉      | 155/400 [03:38<04:07,  1.01s/it]Running loglikelihood requests:  39%|███▉      | 156/400 [03:39<04:01,  1.01it/s]Running loglikelihood requests:  39%|███▉      | 157/400 [03:39<03:57,  1.02it/s]Running loglikelihood requests:  40%|███▉      | 158/400 [03:40<03:53,  1.04it/s]Running loglikelihood requests:  40%|███▉      | 159/400 [03:41<03:50,  1.04it/s]Running loglikelihood requests:  40%|████      | 160/400 [03:42<03:48,  1.05it/s]Running loglikelihood requests:  40%|████      | 161/400 [03:43<03:46,  1.05it/s]Running loglikelihood requests:  40%|████      | 162/400 [03:44<03:44,  1.06it/s]Running loglikelihood requests:  41%|████      | 163/400 [03:45<03:42,  1.06it/s]Running loglikelihood requests:  41%|████      | 164/400 [03:46<03:41,  1.07it/s]Running loglikelihood requests:  41%|████▏     | 165/400 [03:47<03:38,  1.07it/s]Running loglikelihood requests:  42%|████▏     | 166/400 [03:48<03:37,  1.08it/s]Running loglikelihood requests:  42%|████▏     | 167/400 [03:49<03:35,  1.08it/s]Running loglikelihood requests:  42%|████▏     | 168/400 [03:50<03:33,  1.09it/s]Running loglikelihood requests:  42%|████▏     | 169/400 [03:51<03:32,  1.09it/s]Running loglikelihood requests:  42%|████▎     | 170/400 [03:52<03:30,  1.09it/s]Running loglikelihood requests:  43%|████▎     | 172/400 [03:52<02:39,  1.43it/s]Running loglikelihood requests:  43%|████▎     | 173/400 [03:53<02:49,  1.34it/s]Running loglikelihood requests:  44%|████▎     | 174/400 [03:54<02:56,  1.28it/s]Running loglikelihood requests:  44%|████▍     | 177/400 [03:55<01:56,  1.91it/s]Running loglikelihood requests:  44%|████▍     | 178/400 [03:56<02:11,  1.68it/s]Running loglikelihood requests:  45%|████▍     | 179/400 [03:57<02:24,  1.52it/s]Running loglikelihood requests:  45%|████▌     | 180/400 [03:58<02:35,  1.41it/s]Running loglikelihood requests:  45%|████▌     | 181/400 [03:59<02:43,  1.34it/s]Running loglikelihood requests:  46%|████▌     | 182/400 [03:59<02:49,  1.29it/s]Running loglikelihood requests:  46%|████▌     | 183/400 [04:00<02:52,  1.25it/s]Running loglikelihood requests:  46%|████▌     | 184/400 [04:01<02:55,  1.23it/s]Running loglikelihood requests:  46%|████▋     | 185/400 [04:02<02:57,  1.21it/s]Running loglikelihood requests:  46%|████▋     | 186/400 [04:03<02:57,  1.20it/s]Running loglikelihood requests:  47%|████▋     | 187/400 [04:04<02:57,  1.20it/s]Running loglikelihood requests:  47%|████▋     | 188/400 [04:05<02:59,  1.18it/s]Running loglikelihood requests:  47%|████▋     | 189/400 [04:05<02:58,  1.18it/s]Running loglikelihood requests:  48%|████▊     | 190/400 [04:06<02:57,  1.18it/s]Running loglikelihood requests:  48%|████▊     | 191/400 [04:07<02:56,  1.19it/s]Running loglikelihood requests:  48%|████▊     | 192/400 [04:08<02:54,  1.19it/s]Running loglikelihood requests:  48%|████▊     | 193/400 [04:09<02:52,  1.20it/s]Running loglikelihood requests:  48%|████▊     | 194/400 [04:10<02:50,  1.21it/s]Running loglikelihood requests:  49%|████▉     | 195/400 [04:10<02:49,  1.21it/s]Running loglikelihood requests:  49%|████▉     | 196/400 [04:11<02:47,  1.22it/s]Running loglikelihood requests:  49%|████▉     | 197/400 [04:12<02:46,  1.22it/s]Running loglikelihood requests:  50%|████▉     | 198/400 [04:13<02:44,  1.23it/s]Running loglikelihood requests:  50%|████▉     | 199/400 [04:14<02:43,  1.23it/s]Running loglikelihood requests:  50%|█████     | 200/400 [04:14<02:42,  1.23it/s]Running loglikelihood requests:  50%|█████     | 201/400 [04:15<02:40,  1.24it/s]Running loglikelihood requests:  50%|█████     | 202/400 [04:16<02:39,  1.24it/s]Running loglikelihood requests:  51%|█████     | 203/400 [04:17<02:38,  1.24it/s]Running loglikelihood requests:  51%|█████     | 204/400 [04:18<02:37,  1.24it/s]Running loglikelihood requests:  51%|█████▏    | 205/400 [04:18<02:37,  1.24it/s]Running loglikelihood requests:  52%|█████▏    | 206/400 [04:19<02:36,  1.24it/s]Running loglikelihood requests:  52%|█████▏    | 207/400 [04:20<02:35,  1.24it/s]Running loglikelihood requests:  52%|█████▏    | 208/400 [04:21<02:35,  1.24it/s]Running loglikelihood requests:  52%|█████▏    | 209/400 [04:22<02:34,  1.24it/s]Running loglikelihood requests:  53%|█████▎    | 212/400 [04:22<01:34,  1.99it/s]Running loglikelihood requests:  53%|█████▎    | 213/400 [04:23<01:45,  1.78it/s]Running loglikelihood requests:  54%|█████▎    | 214/400 [04:24<01:53,  1.63it/s]Running loglikelihood requests:  54%|█████▍    | 215/400 [04:25<02:00,  1.53it/s]Running loglikelihood requests:  54%|█████▍    | 216/400 [04:26<02:06,  1.46it/s]Running loglikelihood requests:  54%|█████▍    | 217/400 [04:26<02:09,  1.41it/s]Running loglikelihood requests:  55%|█████▍    | 218/400 [04:27<02:12,  1.37it/s]Running loglikelihood requests:  55%|█████▍    | 219/400 [04:28<02:14,  1.35it/s]Running loglikelihood requests:  55%|█████▌    | 220/400 [04:29<02:15,  1.33it/s]Running loglikelihood requests:  55%|█████▌    | 221/400 [04:29<02:15,  1.32it/s]Running loglikelihood requests:  56%|█████▌    | 222/400 [04:30<02:15,  1.31it/s]Running loglikelihood requests:  56%|█████▌    | 223/400 [04:31<02:15,  1.31it/s]Running loglikelihood requests:  56%|█████▌    | 224/400 [04:32<02:14,  1.31it/s]Running loglikelihood requests:  56%|█████▋    | 225/400 [04:32<02:13,  1.31it/s]Running loglikelihood requests:  56%|█████▋    | 226/400 [04:33<02:12,  1.31it/s]Running loglikelihood requests:  57%|█████▋    | 227/400 [04:34<02:12,  1.31it/s]Running loglikelihood requests:  57%|█████▋    | 228/400 [04:35<02:11,  1.31it/s]Running loglikelihood requests:  57%|█████▋    | 229/400 [04:36<02:10,  1.31it/s]Running loglikelihood requests:  57%|█████▊    | 230/400 [04:36<02:09,  1.31it/s]Running loglikelihood requests:  58%|█████▊    | 231/400 [04:37<02:17,  1.23it/s]Running loglikelihood requests:  58%|█████▊    | 232/400 [04:38<02:14,  1.25it/s]Running loglikelihood requests:  58%|█████▊    | 233/400 [04:39<02:12,  1.26it/s]Running loglikelihood requests:  58%|█████▊    | 234/400 [04:40<02:10,  1.28it/s]Running loglikelihood requests:  59%|█████▉    | 235/400 [04:40<02:07,  1.29it/s]Running loglikelihood requests:  59%|█████▉    | 236/400 [04:41<02:06,  1.30it/s]Running loglikelihood requests:  59%|█████▉    | 237/400 [04:42<02:04,  1.31it/s]Running loglikelihood requests:  60%|██████    | 240/400 [04:43<01:19,  2.01it/s]Running loglikelihood requests:  60%|██████    | 241/400 [04:43<01:28,  1.80it/s]Running loglikelihood requests:  60%|██████    | 242/400 [04:44<01:35,  1.65it/s]Running loglikelihood requests:  61%|██████    | 243/400 [04:45<01:40,  1.56it/s]Running loglikelihood requests:  61%|██████    | 244/400 [04:46<01:44,  1.50it/s]Running loglikelihood requests:  61%|██████▏   | 245/400 [04:46<01:46,  1.46it/s]Running loglikelihood requests:  62%|██████▏   | 246/400 [04:47<01:47,  1.43it/s]Running loglikelihood requests:  62%|██████▏   | 247/400 [04:48<01:48,  1.42it/s]Running loglikelihood requests:  62%|██████▏   | 248/400 [04:49<01:48,  1.40it/s]Running loglikelihood requests:  62%|██████▏   | 249/400 [04:49<01:48,  1.40it/s]Running loglikelihood requests:  62%|██████▎   | 250/400 [04:50<01:47,  1.39it/s]Running loglikelihood requests:  63%|██████▎   | 251/400 [04:51<01:47,  1.39it/s]Running loglikelihood requests:  63%|██████▎   | 252/400 [04:52<01:46,  1.39it/s]Running loglikelihood requests:  63%|██████▎   | 253/400 [04:52<01:45,  1.39it/s]Running loglikelihood requests:  64%|██████▎   | 254/400 [04:53<01:44,  1.39it/s]Running loglikelihood requests:  64%|██████▍   | 255/400 [04:54<01:44,  1.39it/s]Running loglikelihood requests:  64%|██████▍   | 256/400 [04:54<01:43,  1.39it/s]Running loglikelihood requests:  64%|██████▍   | 257/400 [04:55<01:42,  1.40it/s]Running loglikelihood requests:  64%|██████▍   | 258/400 [04:56<01:41,  1.40it/s]Running loglikelihood requests:  65%|██████▍   | 259/400 [04:57<01:40,  1.40it/s]Running loglikelihood requests:  65%|██████▌   | 260/400 [04:57<01:39,  1.40it/s]Running loglikelihood requests:  65%|██████▌   | 261/400 [04:58<01:37,  1.43it/s]Running loglikelihood requests:  66%|██████▌   | 262/400 [04:59<01:35,  1.45it/s]Running loglikelihood requests:  66%|██████▌   | 263/400 [04:59<01:33,  1.46it/s]Running loglikelihood requests:  66%|██████▌   | 264/400 [05:00<01:32,  1.48it/s]Running loglikelihood requests:  66%|██████▋   | 265/400 [05:01<01:29,  1.51it/s]Running loglikelihood requests:  66%|██████▋   | 266/400 [05:01<01:27,  1.53it/s]Running loglikelihood requests:  67%|██████▋   | 267/400 [05:02<01:25,  1.55it/s]Running loglikelihood requests:  67%|██████▋   | 268/400 [05:02<01:24,  1.56it/s]Running loglikelihood requests:  67%|██████▋   | 269/400 [05:03<01:24,  1.56it/s]Running loglikelihood requests:  68%|██████▊   | 270/400 [05:04<01:22,  1.57it/s]Running loglikelihood requests:  68%|██████▊   | 271/400 [05:04<01:21,  1.58it/s]Running loglikelihood requests:  68%|██████▊   | 272/400 [05:05<01:20,  1.59it/s]Running loglikelihood requests:  68%|██████▊   | 273/400 [05:06<01:18,  1.62it/s]Running loglikelihood requests:  68%|██████▊   | 274/400 [05:06<01:16,  1.64it/s]Running loglikelihood requests:  69%|██████▉   | 275/400 [05:07<01:15,  1.66it/s]Running loglikelihood requests:  69%|██████▉   | 276/400 [05:07<01:14,  1.67it/s]Running loglikelihood requests:  69%|██████▉   | 277/400 [05:08<01:13,  1.67it/s]Running loglikelihood requests:  70%|██████▉   | 278/400 [05:08<01:12,  1.69it/s]Running loglikelihood requests:  70%|██████▉   | 279/400 [05:09<01:11,  1.70it/s]Running loglikelihood requests:  70%|███████   | 280/400 [05:10<01:10,  1.71it/s]Running loglikelihood requests:  70%|███████   | 281/400 [05:10<01:09,  1.72it/s]Running loglikelihood requests:  70%|███████   | 282/400 [05:11<01:08,  1.73it/s]Running loglikelihood requests:  71%|███████   | 283/400 [05:11<01:07,  1.74it/s]Running loglikelihood requests:  71%|███████   | 284/400 [05:12<01:06,  1.74it/s]Running loglikelihood requests:  71%|███████▏  | 285/400 [05:12<01:05,  1.75it/s]Running loglikelihood requests:  72%|███████▏  | 286/400 [05:13<01:05,  1.75it/s]Running loglikelihood requests:  72%|███████▏  | 287/400 [05:14<01:04,  1.76it/s]Running loglikelihood requests:  72%|███████▏  | 288/400 [05:14<01:03,  1.76it/s]Running loglikelihood requests:  72%|███████▏  | 289/400 [05:15<01:02,  1.76it/s]Running loglikelihood requests:  72%|███████▎  | 290/400 [05:15<01:02,  1.76it/s]Running loglikelihood requests:  73%|███████▎  | 291/400 [05:16<01:01,  1.77it/s]Running loglikelihood requests:  73%|███████▎  | 292/400 [05:16<01:01,  1.77it/s]Running loglikelihood requests:  73%|███████▎  | 293/400 [05:17<01:01,  1.74it/s]Running loglikelihood requests:  74%|███████▎  | 294/400 [05:18<01:00,  1.76it/s]Running loglikelihood requests:  74%|███████▍  | 295/400 [05:18<00:58,  1.78it/s]Running loglikelihood requests:  74%|███████▍  | 296/400 [05:19<00:57,  1.79it/s]Running loglikelihood requests:  74%|███████▍  | 297/400 [05:19<00:57,  1.80it/s]Running loglikelihood requests:  74%|███████▍  | 298/400 [05:20<00:56,  1.81it/s]Running loglikelihood requests:  75%|███████▍  | 299/400 [05:20<00:55,  1.81it/s]Running loglikelihood requests:  75%|███████▌  | 300/400 [05:21<00:55,  1.81it/s]Running loglikelihood requests:  75%|███████▌  | 301/400 [05:21<00:54,  1.81it/s]Running loglikelihood requests:  76%|███████▌  | 302/400 [05:22<01:08,  1.44it/s]Running loglikelihood requests:  76%|███████▌  | 303/400 [05:23<01:05,  1.48it/s]Running loglikelihood requests:  76%|███████▌  | 304/400 [05:24<01:01,  1.57it/s]Running loglikelihood requests:  76%|███████▋  | 305/400 [05:24<00:57,  1.64it/s]Running loglikelihood requests:  76%|███████▋  | 306/400 [05:25<00:55,  1.70it/s]Running loglikelihood requests:  77%|███████▋  | 307/400 [05:25<00:53,  1.74it/s]Running loglikelihood requests:  78%|███████▊  | 310/400 [05:26<00:31,  2.83it/s]Running loglikelihood requests:  78%|███████▊  | 311/400 [05:26<00:34,  2.55it/s]Running loglikelihood requests:  78%|███████▊  | 312/400 [05:27<00:37,  2.34it/s]Running loglikelihood requests:  78%|███████▊  | 313/400 [05:27<00:39,  2.20it/s]Running loglikelihood requests:  78%|███████▊  | 314/400 [05:28<00:41,  2.09it/s]Running loglikelihood requests:  79%|███████▉  | 315/400 [05:29<00:42,  2.00it/s]Running loglikelihood requests:  79%|███████▉  | 316/400 [05:29<00:43,  1.95it/s]Running loglikelihood requests:  79%|███████▉  | 317/400 [05:30<00:42,  1.93it/s]Running loglikelihood requests:  80%|███████▉  | 318/400 [05:30<00:43,  1.90it/s]Running loglikelihood requests:  80%|███████▉  | 319/400 [05:31<00:42,  1.90it/s]Running loglikelihood requests:  80%|████████  | 321/400 [05:31<00:32,  2.46it/s]Running loglikelihood requests:  80%|████████  | 322/400 [05:32<00:33,  2.30it/s]Running loglikelihood requests:  81%|████████  | 323/400 [05:32<00:35,  2.19it/s]Running loglikelihood requests:  81%|████████  | 324/400 [05:33<00:35,  2.12it/s]Running loglikelihood requests:  81%|████████▏ | 325/400 [05:33<00:36,  2.07it/s]Running loglikelihood requests:  82%|████████▏ | 326/400 [05:34<00:36,  2.03it/s]Running loglikelihood requests:  82%|████████▏ | 327/400 [05:34<00:36,  2.01it/s]Running loglikelihood requests:  82%|████████▏ | 328/400 [05:35<00:35,  2.00it/s]Running loglikelihood requests:  82%|████████▏ | 329/400 [05:35<00:35,  2.00it/s]Running loglikelihood requests:  82%|████████▎ | 330/400 [05:36<00:35,  1.99it/s]Running loglikelihood requests:  83%|████████▎ | 331/400 [05:36<00:34,  1.99it/s]Running loglikelihood requests:  83%|████████▎ | 332/400 [05:37<00:34,  1.99it/s]Running loglikelihood requests:  83%|████████▎ | 333/400 [05:37<00:33,  2.00it/s]Running loglikelihood requests:  84%|████████▎ | 334/400 [05:38<00:32,  2.01it/s]Running loglikelihood requests:  84%|████████▍ | 335/400 [05:38<00:32,  2.02it/s]Running loglikelihood requests:  84%|████████▍ | 336/400 [05:39<00:31,  2.03it/s]Running loglikelihood requests:  84%|████████▍ | 337/400 [05:39<00:30,  2.03it/s]Running loglikelihood requests:  84%|████████▍ | 338/400 [05:40<00:30,  2.04it/s]Running loglikelihood requests:  85%|████████▍ | 339/400 [05:40<00:29,  2.05it/s]Running loglikelihood requests:  85%|████████▌ | 340/400 [05:41<00:29,  2.05it/s]Running loglikelihood requests:  85%|████████▌ | 341/400 [05:41<00:28,  2.06it/s]Running loglikelihood requests:  86%|████████▌ | 342/400 [05:42<00:28,  2.06it/s]Running loglikelihood requests:  86%|████████▌ | 343/400 [05:42<00:27,  2.06it/s]Running loglikelihood requests:  86%|████████▌ | 344/400 [05:43<00:27,  2.06it/s]Running loglikelihood requests:  86%|████████▋ | 345/400 [05:43<00:26,  2.07it/s]Running loglikelihood requests:  86%|████████▋ | 346/400 [05:44<00:26,  2.07it/s]Running loglikelihood requests:  87%|████████▋ | 347/400 [05:44<00:25,  2.08it/s]Running loglikelihood requests:  87%|████████▋ | 348/400 [05:45<00:25,  2.08it/s]Running loglikelihood requests:  87%|████████▋ | 349/400 [05:45<00:24,  2.08it/s]Running loglikelihood requests:  88%|████████▊ | 350/400 [05:46<00:24,  2.08it/s]Running loglikelihood requests:  88%|████████▊ | 351/400 [05:46<00:23,  2.09it/s]Running loglikelihood requests:  88%|████████▊ | 352/400 [05:46<00:23,  2.09it/s]Running loglikelihood requests:  88%|████████▊ | 353/400 [05:47<00:22,  2.09it/s]Running loglikelihood requests:  88%|████████▊ | 354/400 [05:47<00:21,  2.10it/s]Running loglikelihood requests:  89%|████████▉ | 355/400 [05:48<00:21,  2.10it/s]Running loglikelihood requests:  89%|████████▉ | 356/400 [05:48<00:20,  2.10it/s]Running loglikelihood requests:  89%|████████▉ | 357/400 [05:49<00:20,  2.11it/s]Running loglikelihood requests:  90%|████████▉ | 358/400 [05:49<00:19,  2.11it/s]Running loglikelihood requests:  90%|████████▉ | 359/400 [05:50<00:19,  2.12it/s]Running loglikelihood requests:  90%|█████████ | 360/400 [05:50<00:18,  2.12it/s]Running loglikelihood requests:  90%|█████████ | 361/400 [05:51<00:18,  2.12it/s]Running loglikelihood requests:  90%|█████████ | 362/400 [05:51<00:17,  2.12it/s]Running loglikelihood requests:  91%|█████████ | 363/400 [05:52<00:17,  2.13it/s]Running loglikelihood requests:  91%|█████████ | 364/400 [05:52<00:16,  2.14it/s]Running loglikelihood requests:  91%|█████████▏| 365/400 [05:53<00:16,  2.14it/s]Running loglikelihood requests:  92%|█████████▏| 366/400 [05:53<00:15,  2.14it/s]Running loglikelihood requests:  92%|█████████▏| 368/400 [05:54<00:11,  2.78it/s]Running loglikelihood requests:  92%|█████████▏| 369/400 [05:54<00:12,  2.58it/s]Running loglikelihood requests:  92%|█████████▎| 370/400 [05:54<00:12,  2.45it/s]Running loglikelihood requests:  93%|█████████▎| 371/400 [05:55<00:12,  2.36it/s]Running loglikelihood requests:  93%|█████████▎| 373/400 [05:55<00:09,  2.94it/s]Running loglikelihood requests:  94%|█████████▎| 374/400 [05:56<00:09,  2.71it/s]Running loglikelihood requests:  94%|█████████▍| 375/400 [05:56<00:09,  2.54it/s]Running loglikelihood requests:  94%|█████████▍| 376/400 [05:57<00:12,  1.99it/s]Running loglikelihood requests:  94%|█████████▍| 377/400 [05:58<00:11,  2.01it/s]Running loglikelihood requests:  94%|█████████▍| 378/400 [05:58<00:10,  2.07it/s]Running loglikelihood requests:  95%|█████████▍| 379/400 [05:59<00:09,  2.11it/s]Running loglikelihood requests:  95%|█████████▌| 380/400 [05:59<00:09,  2.14it/s]Running loglikelihood requests:  95%|█████████▌| 381/400 [05:59<00:08,  2.17it/s]Running loglikelihood requests:  96%|█████████▌| 382/400 [06:00<00:08,  2.19it/s]Running loglikelihood requests:  96%|█████████▌| 383/400 [06:00<00:07,  2.21it/s]Running loglikelihood requests:  96%|█████████▌| 384/400 [06:01<00:07,  2.23it/s]Running loglikelihood requests:  96%|█████████▋| 385/400 [06:01<00:06,  2.24it/s]Running loglikelihood requests:  96%|█████████▋| 386/400 [06:02<00:06,  2.25it/s]Running loglikelihood requests:  97%|█████████▋| 387/400 [06:02<00:05,  2.26it/s]Running loglikelihood requests:  97%|█████████▋| 388/400 [06:03<00:05,  2.27it/s]Running loglikelihood requests:  97%|█████████▋| 389/400 [06:03<00:04,  2.28it/s]Running loglikelihood requests:  98%|█████████▊| 390/400 [06:03<00:04,  2.28it/s]Running loglikelihood requests:  98%|█████████▊| 391/400 [06:04<00:03,  2.28it/s]Running loglikelihood requests:  98%|█████████▊| 392/400 [06:04<00:03,  2.29it/s]Running loglikelihood requests:  98%|█████████▊| 393/400 [06:05<00:03,  2.30it/s]Running loglikelihood requests:  98%|█████████▊| 394/400 [06:05<00:02,  2.30it/s]Running loglikelihood requests:  99%|█████████▉| 395/400 [06:06<00:02,  2.31it/s]Running loglikelihood requests:  99%|█████████▉| 396/400 [06:06<00:01,  2.31it/s]Running loglikelihood requests:  99%|█████████▉| 397/400 [06:06<00:01,  2.32it/s]Running loglikelihood requests: 100%|█████████▉| 398/400 [06:07<00:00,  2.33it/s]Running loglikelihood requests: 100%|█████████▉| 399/400 [06:07<00:00,  2.33it/s]Running loglikelihood requests: 100%|██████████| 400/400 [06:08<00:00,  2.34it/s]Running loglikelihood requests: 100%|██████████| 400/400 [06:08<00:00,  1.09it/s]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:1'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:1'}
full model:
{'sciq': {'alias': 'sciq', 'acc,none': 0.94, 'acc_stderr,none': 0.023868325657594204, 'acc_norm,none': 0.91, 'acc_norm_stderr,none': 0.028762349126466136}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.969062788859705
0.9024924890572922
0.7706109127217512
0.8221264026535647
0.9190490061886575
0.9866654579796295
0.6586322754204971
0.7962110384246164
0.8195614021629236
0.7124178311176441
0.787697814339696
0.7034455022322618
0.8136386046534271
0.8174990104652458
0.6784276389594894
0.8698440245672888
0.8886492811850213
0.6541737276411673
0.6560861559753316
0.8139845219953913
0.6714741870309046
0.6164364868717988
0.8331581872497299
0.9065420049234512
0.9246185715568276
0.7477515960551026
0.574165362968651
0.8586446364199891
0.8889771415746612
Total groups 70 exceeded the threshold, stopping comparison.
The group tensor is
[7, 3, 4, 2, 6, 1, 5, 0]
tensor([7, 3, 4, 2, 6, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 2, 5, 3, 4, 0, 7, 1]
tensor([6, 2, 5, 3, 4, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 3, 6, 2, 7, 1, 4, 0]
tensor([5, 3, 6, 2, 7, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 4, 2, 1, 3, 5, 1]
tensor([0, 0, 4, 2, 1, 3, 5, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 2, 3, 4, 5, 0, 1, 1]
tensor([0, 2, 3, 4, 5, 0, 1, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 1, 0, 2, 2, 3, 1]
tensor([0, 3, 1, 0, 2, 2, 3, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 3, 1, 1, 2, 2, 3, 0]
tensor([0, 3, 1, 1, 2, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 1, 1.0, 1.0, 1.0, 1.0, 1]
tensor([0, 0, 1, 1, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 2 to 4
done!
Normal merging for layer 5
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 6 to 9
done!
Normal merging for layer 10
tensor([0, 1])
tensor(0)
tensor([4, 7])
tensor(4)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 11 to 12
done!
Normal merging for layer 13
tensor([0, 5])
tensor(0)
tensor([6, 7])
tensor(6)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 14 to 19
done!
Normal merging for layer 20
tensor([0, 3])
tensor(0)
tensor([2, 7])
tensor(2)
tensor([4, 5])
tensor(4)
tensor([1, 6])
tensor(1)
done!
Normal merging for layer 21
tensor([0, 7])
tensor(0)
tensor([2, 3])
tensor(2)
tensor([4, 5])
tensor(4)
tensor([1, 6])
tensor(1)
done!
Cross-layer merge completed for layers 22 to 23
done!
Normal merging for layer 24
tensor([0, 1])
tensor(0)
tensor([2, 3, 4, 5, 6, 7])
tensor(2)
done!
Cross-layer merge completed for layers 25 to 31
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 16 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.2608 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 15 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

53
cuda:1
openbookqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:58<00:58, 58.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:15<00:00, 34.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:15<00:00, 37.73s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/openbookqa HTTP/1.1" 307 67
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/openbookqa HTTP/1.1" 200 1409
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/openbookqa/openbookqa.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/openbookqa HTTP/1.1" 307 67
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/openbookqa HTTP/1.1" 200 1409
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/openbookqa/resolve/388097ea7776314e93a529163e0fea805b8a6454/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/allenai/openbookqa/resolve/388097ea7776314e93a529163e0fea805b8a6454/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/openbookqa/revision/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 117
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/openbookqa/revision/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 1409
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/openbookqa/tree/388097ea7776314e93a529163e0fea805b8a6454?recursive=False&expand=False HTTP/1.1" 307 142
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/openbookqa/tree/388097ea7776314e93a529163e0fea805b8a6454?recursive=False&expand=False HTTP/1.1" 200 390
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 119
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 241
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/openbookqa/tree/388097ea7776314e93a529163e0fea805b8a6454/additional?recursive=False&expand=False HTTP/1.1" 307 153
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/openbookqa/tree/388097ea7776314e93a529163e0fea805b8a6454/additional?recursive=False&expand=False HTTP/1.1" 200 363
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 119
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 241
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/openbookqa/revision/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 117
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/openbookqa/revision/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 1409
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 119
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 241
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 119
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 241
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 119
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 241
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 119
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 241
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/openbookqa/resolve/388097ea7776314e93a529163e0fea805b8a6454/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/allenai/openbookqa/resolve/388097ea7776314e93a529163e0fea805b8a6454/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 119
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/openbookqa/tree/388097ea7776314e93a529163e0fea805b8a6454/main?recursive=False&expand=False HTTP/1.1" 307 147
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/openbookqa/tree/388097ea7776314e93a529163e0fea805b8a6454/main?recursive=False&expand=False HTTP/1.1" 200 359
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 119
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 119
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 119
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 119
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 119
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 235
DEBUG:filelock:Attempting to acquire lock 139708536398640 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_openbookqa_main_0.0.0_388097ea7776314e93a529163e0fea805b8a6454.lock
DEBUG:filelock:Lock 139708536398640 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_openbookqa_main_0.0.0_388097ea7776314e93a529163e0fea805b8a6454.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/openbookqa/main/0.0.0/388097ea7776314e93a529163e0fea805b8a6454/dataset_info.json
DEBUG:filelock:Attempting to release lock 139708536398640 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_openbookqa_main_0.0.0_388097ea7776314e93a529163e0fea805b8a6454.lock
DEBUG:filelock:Lock 139708536398640 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_openbookqa_main_0.0.0_388097ea7776314e93a529163e0fea805b8a6454.lock
DEBUG:filelock:Attempting to acquire lock 139708536398640 on /public/home/zouyifei001/.cache/huggingface/datasets/openbookqa/main/0.0.0/388097ea7776314e93a529163e0fea805b8a6454_builder.lock
DEBUG:filelock:Lock 139708536398640 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/openbookqa/main/0.0.0/388097ea7776314e93a529163e0fea805b8a6454_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/openbookqa/main/0.0.0/388097ea7776314e93a529163e0fea805b8a6454/dataset_info.json
DEBUG:filelock:Attempting to release lock 139708536398640 on /public/home/zouyifei001/.cache/huggingface/datasets/openbookqa/main/0.0.0/388097ea7776314e93a529163e0fea805b8a6454_builder.lock
DEBUG:filelock:Lock 139708536398640 released on /public/home/zouyifei001/.cache/huggingface/datasets/openbookqa/main/0.0.0/388097ea7776314e93a529163e0fea805b8a6454_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of openbookqa from None to 0
INFO:lm_eval.api.task:Building contexts for openbookqa on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 2096.64it/s]
DEBUG:lm_eval.evaluator:Task: openbookqa; number of requests on this rank: 400
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/400 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/400 [00:01<10:47,  1.62s/it]Running loglikelihood requests:   0%|          | 2/400 [00:02<07:20,  1.11s/it]Running loglikelihood requests:   1%|          | 3/400 [00:03<06:11,  1.07it/s]Running loglikelihood requests:   1%|          | 4/400 [00:03<05:33,  1.19it/s]Running loglikelihood requests:   1%|▏         | 5/400 [00:04<04:54,  1.34it/s]Running loglikelihood requests:   2%|▏         | 6/400 [00:04<04:34,  1.44it/s]Running loglikelihood requests:   2%|▏         | 7/400 [00:05<04:18,  1.52it/s]Running loglikelihood requests:   2%|▏         | 8/400 [00:06<04:07,  1.59it/s]Running loglikelihood requests:   2%|▏         | 9/400 [00:06<03:59,  1.63it/s]Running loglikelihood requests:   2%|▎         | 10/400 [00:07<03:51,  1.68it/s]Running loglikelihood requests:   3%|▎         | 11/400 [00:07<03:46,  1.72it/s]Running loglikelihood requests:   3%|▎         | 12/400 [00:08<03:42,  1.75it/s]Running loglikelihood requests:   3%|▎         | 13/400 [00:08<03:38,  1.77it/s]Running loglikelihood requests:   4%|▍         | 15/400 [00:09<02:45,  2.33it/s]Running loglikelihood requests:   4%|▍         | 16/400 [00:10<02:58,  2.16it/s]Running loglikelihood requests:   4%|▍         | 17/400 [00:10<03:05,  2.06it/s]Running loglikelihood requests:   4%|▍         | 18/400 [00:11<03:10,  2.01it/s]Running loglikelihood requests:   5%|▍         | 19/400 [00:11<03:13,  1.97it/s]Running loglikelihood requests:   5%|▌         | 20/400 [00:12<03:14,  1.95it/s]Running loglikelihood requests:   5%|▌         | 21/400 [00:12<03:15,  1.94it/s]Running loglikelihood requests:   6%|▌         | 22/400 [00:13<03:15,  1.93it/s]Running loglikelihood requests:   6%|▌         | 23/400 [00:13<03:15,  1.93it/s]Running loglikelihood requests:   6%|▌         | 24/400 [00:14<03:15,  1.93it/s]Running loglikelihood requests:   6%|▋         | 25/400 [00:14<03:14,  1.93it/s]Running loglikelihood requests:   6%|▋         | 26/400 [00:15<03:13,  1.93it/s]Running loglikelihood requests:   7%|▋         | 27/400 [00:15<03:12,  1.94it/s]Running loglikelihood requests:   7%|▋         | 28/400 [00:16<03:10,  1.95it/s]Running loglikelihood requests:   7%|▋         | 29/400 [00:16<03:08,  1.97it/s]Running loglikelihood requests:   8%|▊         | 33/400 [00:17<01:38,  3.74it/s]Running loglikelihood requests:   8%|▊         | 34/400 [00:17<01:52,  3.25it/s]Running loglikelihood requests:   9%|▉         | 35/400 [00:18<02:04,  2.92it/s]Running loglikelihood requests:   9%|▉         | 36/400 [00:18<02:15,  2.68it/s]Running loglikelihood requests:   9%|▉         | 37/400 [00:19<02:24,  2.52it/s]Running loglikelihood requests:  10%|▉         | 38/400 [00:19<02:31,  2.39it/s]Running loglikelihood requests:  10%|▉         | 39/400 [00:20<02:36,  2.31it/s]Running loglikelihood requests:  10%|█         | 40/400 [00:20<02:48,  2.14it/s]Running loglikelihood requests:  10%|█         | 41/400 [00:21<02:47,  2.14it/s]Running loglikelihood requests:  10%|█         | 42/400 [00:21<02:46,  2.14it/s]Running loglikelihood requests:  11%|█         | 43/400 [00:22<02:46,  2.14it/s]Running loglikelihood requests:  11%|█         | 44/400 [00:22<02:45,  2.15it/s]Running loglikelihood requests:  11%|█▏        | 45/400 [00:23<02:45,  2.15it/s]Running loglikelihood requests:  12%|█▏        | 46/400 [00:23<02:44,  2.15it/s]Running loglikelihood requests:  12%|█▏        | 47/400 [00:23<02:44,  2.15it/s]Running loglikelihood requests:  12%|█▏        | 48/400 [00:24<02:43,  2.16it/s]Running loglikelihood requests:  12%|█▏        | 49/400 [00:24<02:42,  2.16it/s]Running loglikelihood requests:  12%|█▎        | 50/400 [00:25<02:41,  2.16it/s]Running loglikelihood requests:  13%|█▎        | 51/400 [00:25<02:41,  2.17it/s]Running loglikelihood requests:  13%|█▎        | 52/400 [00:26<02:40,  2.17it/s]Running loglikelihood requests:  13%|█▎        | 53/400 [00:26<02:39,  2.18it/s]Running loglikelihood requests:  14%|█▎        | 54/400 [00:27<02:38,  2.18it/s]Running loglikelihood requests:  14%|█▍        | 55/400 [00:27<02:37,  2.18it/s]Running loglikelihood requests:  14%|█▍        | 57/400 [00:28<02:00,  2.84it/s]Running loglikelihood requests:  15%|█▌        | 60/400 [00:28<01:25,  3.96it/s]Running loglikelihood requests:  15%|█▌        | 61/400 [00:28<01:38,  3.44it/s]Running loglikelihood requests:  16%|█▌        | 62/400 [00:29<01:49,  3.08it/s]Running loglikelihood requests:  16%|█▌        | 63/400 [00:29<01:59,  2.82it/s]Running loglikelihood requests:  16%|█▌        | 64/400 [00:30<02:07,  2.64it/s]Running loglikelihood requests:  16%|█▋        | 65/400 [00:30<02:13,  2.51it/s]Running loglikelihood requests:  16%|█▋        | 66/400 [00:31<02:17,  2.42it/s]Running loglikelihood requests:  17%|█▋        | 67/400 [00:31<02:21,  2.36it/s]Running loglikelihood requests:  17%|█▋        | 68/400 [00:32<02:22,  2.32it/s]Running loglikelihood requests:  17%|█▋        | 69/400 [00:32<02:24,  2.30it/s]Running loglikelihood requests:  18%|█▊        | 70/400 [00:33<02:24,  2.28it/s]Running loglikelihood requests:  18%|█▊        | 71/400 [00:33<02:25,  2.27it/s]Running loglikelihood requests:  18%|█▊        | 72/400 [00:33<02:25,  2.26it/s]Running loglikelihood requests:  18%|█▊        | 73/400 [00:34<02:25,  2.25it/s]Running loglikelihood requests:  18%|█▊        | 74/400 [00:34<02:24,  2.25it/s]Running loglikelihood requests:  19%|█▉        | 75/400 [00:35<02:24,  2.25it/s]Running loglikelihood requests:  19%|█▉        | 76/400 [00:35<02:24,  2.25it/s]Running loglikelihood requests:  19%|█▉        | 77/400 [00:36<02:24,  2.24it/s]Running loglikelihood requests:  20%|█▉        | 78/400 [00:36<02:23,  2.24it/s]Running loglikelihood requests:  20%|█▉        | 79/400 [00:37<02:22,  2.25it/s]Running loglikelihood requests:  20%|██        | 81/400 [00:37<01:48,  2.93it/s]Running loglikelihood requests:  20%|██        | 82/400 [00:37<01:56,  2.73it/s]Running loglikelihood requests:  21%|██        | 83/400 [00:38<02:02,  2.59it/s]Running loglikelihood requests:  21%|██        | 84/400 [00:38<02:06,  2.49it/s]Running loglikelihood requests:  22%|██▏       | 86/400 [00:39<01:41,  3.10it/s]Running loglikelihood requests:  22%|██▏       | 87/400 [00:39<01:49,  2.86it/s]Running loglikelihood requests:  22%|██▏       | 88/400 [00:40<01:56,  2.68it/s]Running loglikelihood requests:  22%|██▏       | 89/400 [00:40<02:01,  2.56it/s]Running loglikelihood requests:  22%|██▎       | 90/400 [00:41<02:05,  2.48it/s]Running loglikelihood requests:  23%|██▎       | 91/400 [00:41<02:08,  2.41it/s]Running loglikelihood requests:  23%|██▎       | 92/400 [00:41<02:10,  2.37it/s]Running loglikelihood requests:  23%|██▎       | 93/400 [00:42<02:11,  2.34it/s]Running loglikelihood requests:  24%|██▎       | 94/400 [00:42<02:11,  2.32it/s]Running loglikelihood requests:  24%|██▍       | 95/400 [00:43<02:12,  2.31it/s]Running loglikelihood requests:  24%|██▍       | 96/400 [00:43<02:12,  2.29it/s]Running loglikelihood requests:  24%|██▍       | 97/400 [00:44<02:12,  2.28it/s]Running loglikelihood requests:  24%|██▍       | 98/400 [00:44<02:12,  2.28it/s]Running loglikelihood requests:  25%|██▍       | 99/400 [00:44<02:12,  2.27it/s]Running loglikelihood requests:  25%|██▌       | 100/400 [00:45<02:12,  2.27it/s]Running loglikelihood requests:  25%|██▌       | 101/400 [00:45<02:11,  2.28it/s]Running loglikelihood requests:  26%|██▌       | 102/400 [00:46<02:10,  2.28it/s]Running loglikelihood requests:  26%|██▌       | 103/400 [00:46<02:09,  2.29it/s]Running loglikelihood requests:  26%|██▋       | 106/400 [00:47<01:20,  3.67it/s]Running loglikelihood requests:  27%|██▋       | 107/400 [00:47<01:29,  3.26it/s]Running loglikelihood requests:  27%|██▋       | 108/400 [00:48<01:38,  2.97it/s]Running loglikelihood requests:  27%|██▋       | 109/400 [00:48<01:45,  2.77it/s]Running loglikelihood requests:  28%|██▊       | 110/400 [00:48<01:50,  2.62it/s]Running loglikelihood requests:  28%|██▊       | 111/400 [00:49<01:54,  2.52it/s]Running loglikelihood requests:  28%|██▊       | 112/400 [00:49<01:58,  2.44it/s]Running loglikelihood requests:  28%|██▊       | 113/400 [00:50<02:01,  2.35it/s]Running loglikelihood requests:  28%|██▊       | 114/400 [00:50<02:03,  2.32it/s]Running loglikelihood requests:  29%|██▉       | 115/400 [00:51<02:02,  2.32it/s]Running loglikelihood requests:  29%|██▉       | 116/400 [00:51<02:01,  2.33it/s]Running loglikelihood requests:  29%|██▉       | 117/400 [00:51<02:01,  2.33it/s]Running loglikelihood requests:  30%|██▉       | 118/400 [00:52<02:00,  2.33it/s]Running loglikelihood requests:  30%|██▉       | 119/400 [00:52<02:00,  2.33it/s]Running loglikelihood requests:  30%|███       | 120/400 [00:53<02:00,  2.33it/s]Running loglikelihood requests:  30%|███       | 121/400 [00:53<01:59,  2.33it/s]Running loglikelihood requests:  30%|███       | 122/400 [00:54<01:59,  2.33it/s]Running loglikelihood requests:  31%|███       | 123/400 [00:54<01:59,  2.32it/s]Running loglikelihood requests:  31%|███       | 124/400 [00:54<01:58,  2.32it/s]Running loglikelihood requests:  31%|███▏      | 125/400 [00:55<01:58,  2.32it/s]Running loglikelihood requests:  32%|███▏      | 126/400 [00:55<01:57,  2.32it/s]Running loglikelihood requests:  32%|███▏      | 127/400 [00:56<01:57,  2.33it/s]Running loglikelihood requests:  32%|███▏      | 128/400 [00:56<01:57,  2.32it/s]Running loglikelihood requests:  32%|███▏      | 129/400 [00:57<01:56,  2.32it/s]Running loglikelihood requests:  32%|███▎      | 130/400 [00:57<01:55,  2.33it/s]Running loglikelihood requests:  33%|███▎      | 131/400 [00:58<01:55,  2.33it/s]Running loglikelihood requests:  33%|███▎      | 132/400 [00:58<01:54,  2.34it/s]Running loglikelihood requests:  33%|███▎      | 133/400 [00:58<01:54,  2.34it/s]Running loglikelihood requests:  34%|███▎      | 134/400 [00:59<01:53,  2.34it/s]Running loglikelihood requests:  34%|███▍      | 138/400 [00:59<00:58,  4.45it/s]Running loglikelihood requests:  35%|███▍      | 139/400 [01:00<01:08,  3.81it/s]Running loglikelihood requests:  35%|███▌      | 140/400 [01:00<01:17,  3.37it/s]Running loglikelihood requests:  35%|███▌      | 141/400 [01:00<01:24,  3.06it/s]Running loglikelihood requests:  36%|███▌      | 142/400 [01:01<01:30,  2.84it/s]Running loglikelihood requests:  36%|███▌      | 143/400 [01:01<01:40,  2.55it/s]Running loglikelihood requests:  36%|███▌      | 144/400 [01:02<01:42,  2.49it/s]Running loglikelihood requests:  36%|███▋      | 145/400 [01:02<01:44,  2.45it/s]Running loglikelihood requests:  37%|███▋      | 147/400 [01:03<01:21,  3.11it/s]Running loglikelihood requests:  37%|███▋      | 148/400 [01:03<01:27,  2.90it/s]Running loglikelihood requests:  37%|███▋      | 149/400 [01:04<01:31,  2.75it/s]Running loglikelihood requests:  38%|███▊      | 151/400 [01:04<01:14,  3.34it/s]Running loglikelihood requests:  38%|███▊      | 152/400 [01:04<01:21,  3.05it/s]Running loglikelihood requests:  38%|███▊      | 153/400 [01:05<01:26,  2.84it/s]Running loglikelihood requests:  38%|███▊      | 154/400 [01:05<01:30,  2.71it/s]Running loglikelihood requests:  39%|███▉      | 155/400 [01:06<01:34,  2.60it/s]Running loglikelihood requests:  39%|███▉      | 156/400 [01:06<01:36,  2.54it/s]Running loglikelihood requests:  39%|███▉      | 157/400 [01:06<01:37,  2.49it/s]Running loglikelihood requests:  40%|███▉      | 158/400 [01:07<01:38,  2.45it/s]Running loglikelihood requests:  40%|███▉      | 159/400 [01:07<01:38,  2.44it/s]Running loglikelihood requests:  40%|████      | 160/400 [01:08<01:39,  2.42it/s]Running loglikelihood requests:  40%|████      | 161/400 [01:08<01:39,  2.41it/s]Running loglikelihood requests:  40%|████      | 162/400 [01:09<01:39,  2.40it/s]Running loglikelihood requests:  41%|████      | 163/400 [01:09<01:38,  2.40it/s]Running loglikelihood requests:  42%|████▏     | 166/400 [01:09<01:01,  3.83it/s]Running loglikelihood requests:  42%|████▏     | 167/400 [01:10<01:08,  3.40it/s]Running loglikelihood requests:  43%|████▎     | 171/400 [01:10<00:43,  5.25it/s]Running loglikelihood requests:  43%|████▎     | 172/400 [01:11<00:51,  4.41it/s]Running loglikelihood requests:  43%|████▎     | 173/400 [01:11<00:59,  3.81it/s]Running loglikelihood requests:  44%|████▎     | 174/400 [01:12<01:06,  3.39it/s]Running loglikelihood requests:  44%|████▍     | 175/400 [01:12<01:12,  3.10it/s]Running loglikelihood requests:  44%|████▍     | 176/400 [01:12<01:17,  2.90it/s]Running loglikelihood requests:  44%|████▍     | 177/400 [01:13<01:20,  2.76it/s]Running loglikelihood requests:  44%|████▍     | 178/400 [01:13<01:23,  2.66it/s]Running loglikelihood requests:  45%|████▍     | 179/400 [01:14<01:25,  2.58it/s]Running loglikelihood requests:  45%|████▌     | 180/400 [01:14<01:26,  2.54it/s]Running loglikelihood requests:  45%|████▌     | 181/400 [01:14<01:27,  2.50it/s]Running loglikelihood requests:  46%|████▌     | 182/400 [01:15<01:28,  2.47it/s]Running loglikelihood requests:  46%|████▌     | 183/400 [01:15<01:28,  2.45it/s]Running loglikelihood requests:  46%|████▌     | 184/400 [01:16<01:27,  2.46it/s]Running loglikelihood requests:  46%|████▋     | 185/400 [01:16<01:27,  2.45it/s]Running loglikelihood requests:  46%|████▋     | 186/400 [01:16<01:27,  2.45it/s]Running loglikelihood requests:  47%|████▋     | 187/400 [01:17<01:26,  2.45it/s]Running loglikelihood requests:  47%|████▋     | 188/400 [01:17<01:26,  2.45it/s]Running loglikelihood requests:  48%|████▊     | 190/400 [01:18<01:05,  3.19it/s]Running loglikelihood requests:  48%|████▊     | 192/400 [01:18<00:56,  3.70it/s]Running loglikelihood requests:  48%|████▊     | 193/400 [01:18<01:02,  3.32it/s]Running loglikelihood requests:  48%|████▊     | 194/400 [01:19<01:07,  3.05it/s]Running loglikelihood requests:  49%|████▉     | 195/400 [01:19<01:11,  2.87it/s]Running loglikelihood requests:  49%|████▉     | 196/400 [01:20<01:14,  2.74it/s]Running loglikelihood requests:  49%|████▉     | 197/400 [01:20<01:16,  2.64it/s]Running loglikelihood requests:  50%|████▉     | 198/400 [01:21<01:18,  2.58it/s]Running loglikelihood requests:  50%|█████     | 202/400 [01:21<00:41,  4.75it/s]Running loglikelihood requests:  51%|█████     | 203/400 [01:21<00:48,  4.08it/s]Running loglikelihood requests:  51%|█████     | 204/400 [01:22<00:54,  3.62it/s]Running loglikelihood requests:  51%|█████▏    | 205/400 [01:22<00:59,  3.29it/s]Running loglikelihood requests:  52%|█████▏    | 206/400 [01:23<01:03,  3.05it/s]Running loglikelihood requests:  52%|█████▏    | 207/400 [01:23<01:07,  2.88it/s]Running loglikelihood requests:  52%|█████▏    | 209/400 [01:23<00:54,  3.52it/s]Running loglikelihood requests:  52%|█████▎    | 210/400 [01:24<00:59,  3.21it/s]Running loglikelihood requests:  53%|█████▎    | 211/400 [01:24<01:03,  2.99it/s]Running loglikelihood requests:  53%|█████▎    | 212/400 [01:25<01:06,  2.83it/s]Running loglikelihood requests:  53%|█████▎    | 213/400 [01:25<01:08,  2.72it/s]Running loglikelihood requests:  54%|█████▎    | 214/400 [01:25<01:10,  2.64it/s]Running loglikelihood requests:  54%|█████▍    | 215/400 [01:26<01:11,  2.59it/s]Running loglikelihood requests:  54%|█████▍    | 216/400 [01:26<01:11,  2.56it/s]Running loglikelihood requests:  54%|█████▍    | 217/400 [01:27<01:11,  2.55it/s]Running loglikelihood requests:  55%|█████▍    | 218/400 [01:27<01:11,  2.53it/s]Running loglikelihood requests:  55%|█████▍    | 219/400 [01:27<01:11,  2.52it/s]Running loglikelihood requests:  55%|█████▌    | 220/400 [01:28<01:11,  2.50it/s]Running loglikelihood requests:  55%|█████▌    | 221/400 [01:28<01:11,  2.51it/s]Running loglikelihood requests:  56%|█████▌    | 222/400 [01:29<01:11,  2.50it/s]Running loglikelihood requests:  56%|█████▌    | 223/400 [01:29<01:10,  2.50it/s]Running loglikelihood requests:  56%|█████▌    | 224/400 [01:29<01:09,  2.52it/s]Running loglikelihood requests:  56%|█████▋    | 225/400 [01:30<01:09,  2.52it/s]Running loglikelihood requests:  56%|█████▋    | 226/400 [01:30<01:09,  2.51it/s]Running loglikelihood requests:  57%|█████▋    | 227/400 [01:31<01:08,  2.51it/s]Running loglikelihood requests:  57%|█████▋    | 228/400 [01:31<01:08,  2.52it/s]Running loglikelihood requests:  57%|█████▋    | 229/400 [01:31<01:07,  2.53it/s]Running loglikelihood requests:  57%|█████▊    | 230/400 [01:32<01:08,  2.50it/s]Running loglikelihood requests:  58%|█████▊    | 231/400 [01:32<01:07,  2.50it/s]Running loglikelihood requests:  58%|█████▊    | 232/400 [01:33<01:06,  2.51it/s]Running loglikelihood requests:  58%|█████▊    | 233/400 [01:33<01:06,  2.53it/s]Running loglikelihood requests:  58%|█████▊    | 234/400 [01:33<01:05,  2.52it/s]Running loglikelihood requests:  59%|█████▉    | 235/400 [01:34<01:05,  2.54it/s]Running loglikelihood requests:  59%|█████▉    | 237/400 [01:34<00:49,  3.30it/s]Running loglikelihood requests:  60%|█████▉    | 239/400 [01:35<00:41,  3.85it/s]Running loglikelihood requests:  60%|██████    | 240/400 [01:35<00:46,  3.45it/s]Running loglikelihood requests:  60%|██████    | 241/400 [01:35<00:50,  3.18it/s]Running loglikelihood requests:  60%|██████    | 242/400 [01:36<00:52,  2.99it/s]Running loglikelihood requests:  61%|██████    | 243/400 [01:36<00:55,  2.85it/s]Running loglikelihood requests:  61%|██████    | 244/400 [01:36<00:56,  2.75it/s]Running loglikelihood requests:  61%|██████▏   | 245/400 [01:37<00:57,  2.68it/s]Running loglikelihood requests:  62%|██████▏   | 246/400 [01:37<00:58,  2.63it/s]Running loglikelihood requests:  62%|██████▏   | 247/400 [01:38<00:58,  2.60it/s]Running loglikelihood requests:  62%|██████▏   | 248/400 [01:38<00:58,  2.58it/s]Running loglikelihood requests:  62%|██████▏   | 249/400 [01:38<00:58,  2.56it/s]Running loglikelihood requests:  62%|██████▎   | 250/400 [01:39<00:58,  2.56it/s]Running loglikelihood requests:  63%|██████▎   | 251/400 [01:39<00:58,  2.54it/s]Running loglikelihood requests:  63%|██████▎   | 252/400 [01:40<00:58,  2.54it/s]Running loglikelihood requests:  63%|██████▎   | 253/400 [01:40<00:58,  2.53it/s]Running loglikelihood requests:  64%|██████▎   | 254/400 [01:40<00:57,  2.54it/s]Running loglikelihood requests:  64%|██████▍   | 255/400 [01:41<00:56,  2.55it/s]Running loglikelihood requests:  64%|██████▍   | 256/400 [01:41<00:55,  2.58it/s]Running loglikelihood requests:  64%|██████▍   | 257/400 [01:42<00:55,  2.57it/s]Running loglikelihood requests:  64%|██████▍   | 258/400 [01:42<00:55,  2.57it/s]Running loglikelihood requests:  65%|██████▍   | 259/400 [01:42<00:54,  2.57it/s]Running loglikelihood requests:  65%|██████▌   | 260/400 [01:43<00:54,  2.56it/s]Running loglikelihood requests:  65%|██████▌   | 261/400 [01:43<00:54,  2.56it/s]Running loglikelihood requests:  66%|██████▌   | 262/400 [01:44<00:53,  2.56it/s]Running loglikelihood requests:  66%|██████▌   | 263/400 [01:44<00:53,  2.58it/s]Running loglikelihood requests:  66%|██████▋   | 265/400 [01:44<00:40,  3.37it/s]Running loglikelihood requests:  66%|██████▋   | 266/400 [01:45<00:42,  3.14it/s]Running loglikelihood requests:  67%|██████▋   | 267/400 [01:45<00:44,  2.97it/s]Running loglikelihood requests:  67%|██████▋   | 268/400 [01:45<00:46,  2.86it/s]Running loglikelihood requests:  67%|██████▋   | 269/400 [01:46<00:47,  2.78it/s]Running loglikelihood requests:  68%|██████▊   | 270/400 [01:46<00:47,  2.76it/s]Running loglikelihood requests:  68%|██████▊   | 271/400 [01:47<00:47,  2.71it/s]Running loglikelihood requests:  68%|██████▊   | 272/400 [01:47<00:47,  2.68it/s]Running loglikelihood requests:  68%|██████▊   | 273/400 [01:47<00:47,  2.68it/s]Running loglikelihood requests:  68%|██████▊   | 274/400 [01:48<00:47,  2.64it/s]Running loglikelihood requests:  69%|██████▉   | 275/400 [01:48<00:47,  2.61it/s]Running loglikelihood requests:  69%|██████▉   | 276/400 [01:49<00:47,  2.60it/s]Running loglikelihood requests:  69%|██████▉   | 277/400 [01:49<00:47,  2.59it/s]Running loglikelihood requests:  70%|██████▉   | 278/400 [01:49<00:47,  2.59it/s]Running loglikelihood requests:  70%|██████▉   | 279/400 [01:50<00:46,  2.58it/s]Running loglikelihood requests:  70%|███████   | 280/400 [01:50<00:46,  2.57it/s]Running loglikelihood requests:  70%|███████   | 281/400 [01:50<00:45,  2.60it/s]Running loglikelihood requests:  70%|███████   | 282/400 [01:51<00:45,  2.60it/s]Running loglikelihood requests:  71%|███████   | 283/400 [01:51<00:45,  2.59it/s]Running loglikelihood requests:  71%|███████   | 284/400 [01:52<00:44,  2.60it/s]Running loglikelihood requests:  71%|███████▏  | 285/400 [01:52<00:43,  2.62it/s]Running loglikelihood requests:  72%|███████▏  | 286/400 [01:52<00:43,  2.63it/s]Running loglikelihood requests:  72%|███████▏  | 287/400 [01:53<00:42,  2.63it/s]Running loglikelihood requests:  72%|███████▏  | 288/400 [01:53<00:42,  2.64it/s]Running loglikelihood requests:  72%|███████▏  | 289/400 [01:54<00:41,  2.65it/s]Running loglikelihood requests:  72%|███████▎  | 290/400 [01:54<00:41,  2.67it/s]Running loglikelihood requests:  73%|███████▎  | 291/400 [01:54<00:40,  2.68it/s]Running loglikelihood requests:  73%|███████▎  | 292/400 [01:55<00:40,  2.67it/s]Running loglikelihood requests:  73%|███████▎  | 293/400 [01:55<00:40,  2.66it/s]Running loglikelihood requests:  74%|███████▎  | 294/400 [01:55<00:39,  2.66it/s]Running loglikelihood requests:  74%|███████▍  | 297/400 [01:56<00:24,  4.29it/s]Running loglikelihood requests:  74%|███████▍  | 298/400 [01:56<00:27,  3.76it/s]Running loglikelihood requests:  75%|███████▍  | 299/400 [01:57<00:29,  3.42it/s]Running loglikelihood requests:  75%|███████▌  | 300/400 [01:57<00:31,  3.19it/s]Running loglikelihood requests:  75%|███████▌  | 301/400 [01:57<00:32,  3.02it/s]Running loglikelihood requests:  76%|███████▌  | 302/400 [01:58<00:33,  2.90it/s]Running loglikelihood requests:  76%|███████▌  | 303/400 [01:58<00:34,  2.80it/s]Running loglikelihood requests:  77%|███████▋  | 307/400 [01:58<00:18,  5.10it/s]Running loglikelihood requests:  77%|███████▋  | 308/400 [01:59<00:21,  4.37it/s]Running loglikelihood requests:  77%|███████▋  | 309/400 [01:59<00:23,  3.87it/s]Running loglikelihood requests:  78%|███████▊  | 310/400 [02:00<00:25,  3.50it/s]Running loglikelihood requests:  78%|███████▊  | 311/400 [02:00<00:27,  3.26it/s]Running loglikelihood requests:  78%|███████▊  | 312/400 [02:00<00:28,  3.06it/s]Running loglikelihood requests:  78%|███████▊  | 313/400 [02:01<00:29,  2.92it/s]Running loglikelihood requests:  78%|███████▊  | 314/400 [02:01<00:30,  2.83it/s]Running loglikelihood requests:  79%|███████▉  | 315/400 [02:01<00:30,  2.78it/s]Running loglikelihood requests:  79%|███████▉  | 316/400 [02:02<00:30,  2.76it/s]Running loglikelihood requests:  79%|███████▉  | 317/400 [02:02<00:30,  2.75it/s]Running loglikelihood requests:  80%|███████▉  | 318/400 [02:03<00:30,  2.72it/s]Running loglikelihood requests:  80%|████████  | 321/400 [02:03<00:18,  4.33it/s]Running loglikelihood requests:  80%|████████  | 322/400 [02:03<00:20,  3.84it/s]Running loglikelihood requests:  81%|████████  | 323/400 [02:04<00:21,  3.51it/s]Running loglikelihood requests:  81%|████████  | 324/400 [02:04<00:23,  3.28it/s]Running loglikelihood requests:  81%|████████▏ | 325/400 [02:04<00:24,  3.10it/s]Running loglikelihood requests:  82%|████████▏ | 326/400 [02:05<00:24,  2.98it/s]Running loglikelihood requests:  82%|████████▏ | 327/400 [02:05<00:25,  2.90it/s]Running loglikelihood requests:  82%|████████▏ | 328/400 [02:06<00:25,  2.85it/s]Running loglikelihood requests:  82%|████████▏ | 329/400 [02:06<00:25,  2.80it/s]Running loglikelihood requests:  82%|████████▎ | 330/400 [02:06<00:25,  2.75it/s]Running loglikelihood requests:  83%|████████▎ | 331/400 [02:07<00:24,  2.76it/s]Running loglikelihood requests:  83%|████████▎ | 332/400 [02:07<00:24,  2.74it/s]Running loglikelihood requests:  83%|████████▎ | 333/400 [02:07<00:24,  2.79it/s]Running loglikelihood requests:  84%|████████▎ | 334/400 [02:08<00:24,  2.74it/s]Running loglikelihood requests:  84%|████████▍ | 336/400 [02:08<00:17,  3.56it/s]Running loglikelihood requests:  84%|████████▍ | 337/400 [02:08<00:19,  3.31it/s]Running loglikelihood requests:  84%|████████▍ | 338/400 [02:09<00:19,  3.14it/s]Running loglikelihood requests:  85%|████████▍ | 339/400 [02:09<00:20,  3.00it/s]Running loglikelihood requests:  85%|████████▌ | 340/400 [02:10<00:20,  2.91it/s]Running loglikelihood requests:  85%|████████▌ | 341/400 [02:10<00:20,  2.85it/s]Running loglikelihood requests:  86%|████████▌ | 342/400 [02:10<00:20,  2.80it/s]Running loglikelihood requests:  86%|████████▌ | 343/400 [02:11<00:20,  2.74it/s]Running loglikelihood requests:  86%|████████▌ | 344/400 [02:11<00:20,  2.74it/s]Running loglikelihood requests:  86%|████████▋ | 345/400 [02:11<00:20,  2.74it/s]Running loglikelihood requests:  86%|████████▋ | 346/400 [02:12<00:19,  2.82it/s]Running loglikelihood requests:  87%|████████▋ | 347/400 [02:12<00:19,  2.79it/s]Running loglikelihood requests:  87%|████████▋ | 348/400 [02:12<00:18,  2.77it/s]Running loglikelihood requests:  87%|████████▋ | 349/400 [02:13<00:18,  2.77it/s]Running loglikelihood requests:  88%|████████▊ | 350/400 [02:13<00:18,  2.76it/s]Running loglikelihood requests:  88%|████████▊ | 351/400 [02:14<00:17,  2.76it/s]Running loglikelihood requests:  88%|████████▊ | 352/400 [02:14<00:17,  2.81it/s]Running loglikelihood requests:  88%|████████▊ | 353/400 [02:14<00:16,  2.85it/s]Running loglikelihood requests:  88%|████████▊ | 354/400 [02:15<00:16,  2.81it/s]Running loglikelihood requests:  89%|████████▉ | 355/400 [02:15<00:16,  2.79it/s]Running loglikelihood requests:  89%|████████▉ | 356/400 [02:15<00:15,  2.82it/s]Running loglikelihood requests:  89%|████████▉ | 357/400 [02:16<00:15,  2.81it/s]Running loglikelihood requests:  90%|████████▉ | 358/400 [02:16<00:15,  2.80it/s]Running loglikelihood requests:  90%|████████▉ | 359/400 [02:16<00:14,  2.80it/s]Running loglikelihood requests:  90%|█████████ | 360/400 [02:17<00:14,  2.83it/s]Running loglikelihood requests:  91%|█████████ | 363/400 [02:17<00:08,  4.52it/s]Running loglikelihood requests:  91%|█████████ | 364/400 [02:17<00:09,  3.99it/s]Running loglikelihood requests:  91%|█████████▏| 365/400 [02:18<00:09,  3.67it/s]Running loglikelihood requests:  92%|█████████▏| 366/400 [02:18<00:09,  3.46it/s]Running loglikelihood requests:  92%|█████████▏| 367/400 [02:19<00:09,  3.30it/s]Running loglikelihood requests:  92%|█████████▏| 368/400 [02:19<00:10,  3.15it/s]Running loglikelihood requests:  92%|█████████▏| 369/400 [02:19<00:10,  3.04it/s]Running loglikelihood requests:  92%|█████████▎| 370/400 [02:20<00:10,  2.98it/s]Running loglikelihood requests:  93%|█████████▎| 371/400 [02:20<00:09,  2.97it/s]Running loglikelihood requests:  93%|█████████▎| 372/400 [02:20<00:09,  2.98it/s]Running loglikelihood requests:  93%|█████████▎| 373/400 [02:21<00:09,  2.98it/s]Running loglikelihood requests:  94%|█████████▎| 374/400 [02:21<00:08,  2.95it/s]Running loglikelihood requests:  94%|█████████▍| 377/400 [02:21<00:04,  4.79it/s]Running loglikelihood requests:  94%|█████████▍| 378/400 [02:22<00:05,  4.26it/s]Running loglikelihood requests:  95%|█████████▍| 379/400 [02:22<00:05,  3.86it/s]Running loglikelihood requests:  95%|█████████▌| 380/400 [02:22<00:05,  3.63it/s]Running loglikelihood requests:  95%|█████████▌| 381/400 [02:23<00:05,  3.49it/s]Running loglikelihood requests:  96%|█████████▌| 382/400 [02:23<00:05,  3.36it/s]Running loglikelihood requests:  96%|█████████▌| 383/400 [02:23<00:05,  3.26it/s]Running loglikelihood requests:  96%|█████████▌| 384/400 [02:24<00:05,  3.20it/s]Running loglikelihood requests:  97%|█████████▋| 387/400 [02:24<00:02,  4.98it/s]Running loglikelihood requests:  97%|█████████▋| 388/400 [02:24<00:02,  4.41it/s]Running loglikelihood requests:  98%|█████████▊| 390/400 [02:25<00:02,  4.86it/s]Running loglikelihood requests:  98%|█████████▊| 391/400 [02:25<00:02,  4.37it/s]Running loglikelihood requests:  98%|█████████▊| 392/400 [02:25<00:01,  4.03it/s]Running loglikelihood requests:  98%|█████████▊| 393/400 [02:25<00:01,  3.86it/s]Running loglikelihood requests:  98%|█████████▊| 394/400 [02:26<00:01,  3.63it/s]Running loglikelihood requests:  99%|█████████▉| 395/400 [02:26<00:01,  3.50it/s]Running loglikelihood requests:  99%|█████████▉| 396/400 [02:26<00:01,  3.45it/s]Running loglikelihood requests: 100%|█████████▉| 398/400 [02:27<00:00,  4.42it/s]Running loglikelihood requests: 100%|█████████▉| 399/400 [02:27<00:00,  4.34it/s]Running loglikelihood requests: 100%|██████████| 400/400 [02:27<00:00,  2.71it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:2'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:2'}
full model:
{'openbookqa': {'alias': 'openbookqa', 'acc,none': 0.25, 'acc_stderr,none': 0.04351941398892446, 'acc_norm,none': 0.39, 'acc_norm_stderr,none': 0.04902071300001973}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.7187319796021299
0.7542307644255121
0.9218102409329888
0.9507846064925026
0.9244473932111009
0.9697851265705995
0.9088369054586506
0.9555908644563589
0.6065244449438403
0.8380982140772407
0.9227293008726757
0.940339967265193
0.8763319017557598
0.8956221731459367
0.8537768995934096
0.9486125995141542
0.9673324054839537
0.9137514724447725
0.9379677722073356
0.9822722776537973
0.9198472199854921
0.886666948473494
0.9000260607563779
0.9759633945879138
0.9869744580755335
Total groups 76 exceeded the threshold, stopping comparison.
The group tensor is
[6, 2, 3, 1, 5, 4, 7, 0]
tensor([6, 2, 3, 1, 5, 4, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 2, 3, 1, 4, 5, 7, 0]
tensor([6, 2, 3, 1, 4, 5, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 2, 3, 1, 4, 5, 7, 0]
tensor([6, 2, 3, 1, 4, 5, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 5, 2, 4, 3, 7, 0]
tensor([6, 1, 5, 2, 4, 3, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 1, 3, 2, 5, 4, 6, 0]
tensor([7, 1, 3, 2, 5, 4, 6, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 2, 3, 1, 5, 4, 7, 0]
tensor([6, 2, 3, 1, 5, 4, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1, 1.0, 1.0, 1.0, 1.0, 0]
tensor([0, 1, 1, 1, 1, 1, 1, 0], dtype=torch.int32)
[0, 1]
The group tensor is
[0, 1, 1.0, 1, 1.0, 1.0, 1.0, 0]
tensor([0, 1, 1, 1, 1, 1, 1, 0], dtype=torch.int32)
[0, 1]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
done!
Normal merging for layer 2
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
done!
Normal merging for layer 4
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
done!
Normal merging for layer 5
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 6 to 29
done!
Normal merging for layer 30
tensor([0, 7])
tensor(0)
tensor([1, 2, 3, 4, 5, 6])
tensor(1)
done!
Normal merging for layer 31
tensor([0, 7])
tensor(0)
tensor([1, 2, 3, 4, 5, 6])
tensor(1)
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 15 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.3238 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 14 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

148
cuda:2
fda
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:55<00:55, 55.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:12<00:00, 32.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:12<00:00, 36.20s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:None: No `generation_kwargs` specified in task config, defaulting to {'until': ['\n\n'], 'do_sample': False, 'temperature': 0}
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/hazyresearch/based-fda HTTP/1.1" 200 1042
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/hazyresearch/based-fda/hazyresearch/based-fda.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/hazyresearch/based-fda HTTP/1.1" 200 1042
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/hazyresearch/based-fda/resolve/42569d301e12fbcf8d5a69e04e892aa013e20314/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/hazyresearch/based-fda/revision/42569d301e12fbcf8d5a69e04e892aa013e20314 HTTP/1.1" 200 1042
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/hazyresearch/based-fda/tree/42569d301e12fbcf8d5a69e04e892aa013e20314?recursive=False&expand=False HTTP/1.1" 200 291
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/hazyresearch/based-fda/paths-info/42569d301e12fbcf8d5a69e04e892aa013e20314 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/hazyresearch/based-fda/tree/42569d301e12fbcf8d5a69e04e892aa013e20314/data?recursive=False&expand=False HTTP/1.1" 200 484
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/hazyresearch/based-fda/paths-info/42569d301e12fbcf8d5a69e04e892aa013e20314 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/hazyresearch/based-fda/revision/42569d301e12fbcf8d5a69e04e892aa013e20314 HTTP/1.1" 200 1042
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/hazyresearch/based-fda/resolve/42569d301e12fbcf8d5a69e04e892aa013e20314/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/hazyresearch/based-fda/paths-info/42569d301e12fbcf8d5a69e04e892aa013e20314 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/hazyresearch/based-fda/paths-info/42569d301e12fbcf8d5a69e04e892aa013e20314 HTTP/1.1" 200 218
DEBUG:filelock:Attempting to acquire lock 139708535391056 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_hazyresearch___based-fda_default_0.0.0_42569d301e12fbcf8d5a69e04e892aa013e20314.lock
DEBUG:filelock:Lock 139708535391056 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_hazyresearch___based-fda_default_0.0.0_42569d301e12fbcf8d5a69e04e892aa013e20314.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/hazyresearch___based-fda/default/0.0.0/42569d301e12fbcf8d5a69e04e892aa013e20314/dataset_info.json
DEBUG:filelock:Attempting to release lock 139708535391056 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_hazyresearch___based-fda_default_0.0.0_42569d301e12fbcf8d5a69e04e892aa013e20314.lock
DEBUG:filelock:Lock 139708535391056 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_hazyresearch___based-fda_default_0.0.0_42569d301e12fbcf8d5a69e04e892aa013e20314.lock
DEBUG:filelock:Attempting to acquire lock 139705425945824 on /public/home/zouyifei001/.cache/huggingface/datasets/hazyresearch___based-fda/default/0.0.0/42569d301e12fbcf8d5a69e04e892aa013e20314_builder.lock
DEBUG:filelock:Lock 139705425945824 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/hazyresearch___based-fda/default/0.0.0/42569d301e12fbcf8d5a69e04e892aa013e20314_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/hazyresearch___based-fda/default/0.0.0/42569d301e12fbcf8d5a69e04e892aa013e20314/dataset_info.json
DEBUG:filelock:Attempting to release lock 139705425945824 on /public/home/zouyifei001/.cache/huggingface/datasets/hazyresearch___based-fda/default/0.0.0/42569d301e12fbcf8d5a69e04e892aa013e20314_builder.lock
DEBUG:filelock:Lock 139705425945824 released on /public/home/zouyifei001/.cache/huggingface/datasets/hazyresearch___based-fda/default/0.0.0/42569d301e12fbcf8d5a69e04e892aa013e20314_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
INFO:lm_eval.evaluator:fda: Using gen_kwargs: {'until': ['\n\n'], 'do_sample': False, 'temperature': 0}
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of fda from None to 0
INFO:lm_eval.api.task:Building contexts for fda on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 231857.60it/s]
DEBUG:lm_eval.evaluator:Task: fda; number of requests on this rank: 100
INFO:lm_eval.evaluator:Running generate_until requests
Running generate_until requests:   0%|          | 0/100 [00:00<?, ?it/s]Running generate_until requests:   1%|          | 1/100 [00:19<32:49, 19.89s/it]Running generate_until requests:   2%|▏         | 2/100 [00:33<26:05, 15.98s/it]Running generate_until requests:   3%|▎         | 3/100 [00:46<23:37, 14.61s/it]Running generate_until requests:   4%|▍         | 4/100 [01:03<25:16, 15.79s/it]Running generate_until requests:   5%|▌         | 5/100 [01:18<24:42, 15.61s/it]Running generate_until requests:   6%|▌         | 6/100 [01:33<23:40, 15.12s/it]Running generate_until requests:   7%|▋         | 7/100 [01:50<24:41, 15.93s/it]Running generate_until requests:   8%|▊         | 8/100 [02:08<25:14, 16.47s/it]Running generate_until requests:   9%|▉         | 9/100 [02:20<23:08, 15.26s/it]Running generate_until requests:  10%|█         | 10/100 [02:32<21:12, 14.14s/it]Running generate_until requests:  11%|█         | 11/100 [02:44<19:49, 13.37s/it]Running generate_until requests:  12%|█▏        | 12/100 [03:01<21:31, 14.67s/it]Running generate_until requests:  13%|█▎        | 13/100 [03:14<20:10, 13.91s/it]Running generate_until requests:  14%|█▍        | 14/100 [03:31<21:32, 15.03s/it]Running generate_until requests:  15%|█▌        | 15/100 [03:43<20:00, 14.12s/it]Running generate_until requests:  16%|█▌        | 16/100 [03:56<19:06, 13.65s/it]Running generate_until requests:  17%|█▋        | 17/100 [04:08<18:14, 13.19s/it]Running generate_until requests:  18%|█▊        | 18/100 [04:25<19:45, 14.46s/it]Running generate_until requests:  19%|█▉        | 19/100 [04:37<18:27, 13.67s/it]Running generate_until requests:  20%|██        | 20/100 [04:55<19:48, 14.85s/it]Running generate_until requests:  21%|██        | 21/100 [05:12<20:38, 15.68s/it]Running generate_until requests:  22%|██▏       | 22/100 [05:27<19:51, 15.28s/it]Running generate_until requests:  23%|██▎       | 23/100 [05:44<20:29, 15.97s/it]Running generate_until requests:  24%|██▍       | 24/100 [05:57<18:53, 14.92s/it]Running generate_until requests:  25%|██▌       | 25/100 [06:14<19:38, 15.72s/it]Running generate_until requests:  26%|██▌       | 26/100 [06:32<20:01, 16.24s/it]Running generate_until requests:  27%|██▋       | 27/100 [06:49<20:12, 16.61s/it]Running generate_until requests:  28%|██▊       | 28/100 [07:02<18:34, 15.48s/it]Running generate_until requests:  29%|██▉       | 29/100 [07:19<18:59, 16.04s/it]Running generate_until requests:  30%|███       | 30/100 [07:33<17:53, 15.33s/it]Running generate_until requests:  31%|███       | 31/100 [07:51<18:28, 16.06s/it]Running generate_until requests:  32%|███▏      | 32/100 [08:04<17:12, 15.18s/it]Running generate_until requests:  33%|███▎      | 33/100 [08:21<17:41, 15.85s/it]Running generate_until requests:  34%|███▍      | 34/100 [08:39<17:58, 16.34s/it]Running generate_until requests:  35%|███▌      | 35/100 [08:52<16:44, 15.46s/it]Running generate_until requests:  36%|███▌      | 36/100 [09:05<15:31, 14.56s/it]Running generate_until requests:  37%|███▋      | 37/100 [09:17<14:37, 13.93s/it]Running generate_until requests:  38%|███▊      | 38/100 [09:31<14:15, 13.79s/it]Running generate_until requests:  39%|███▉      | 39/100 [09:48<15:09, 14.92s/it]Running generate_until requests:  40%|████      | 40/100 [10:01<14:20, 14.34s/it]Running generate_until requests:  41%|████      | 41/100 [10:19<15:02, 15.30s/it]Running generate_until requests:  42%|████▏     | 42/100 [10:31<13:55, 14.41s/it]Running generate_until requests:  43%|████▎     | 43/100 [10:43<13:04, 13.77s/it]Running generate_until requests:  44%|████▍     | 44/100 [10:56<12:29, 13.38s/it]Running generate_until requests:  45%|████▌     | 45/100 [11:07<11:42, 12.77s/it]Running generate_until requests:  46%|████▌     | 46/100 [11:25<12:44, 14.15s/it]Running generate_until requests:  47%|████▋     | 47/100 [11:42<13:20, 15.10s/it]Running generate_until requests:  48%|████▊     | 48/100 [11:54<12:24, 14.33s/it]Running generate_until requests:  49%|████▉     | 49/100 [12:06<11:28, 13.50s/it]Running generate_until requests:  50%|█████     | 50/100 [12:19<11:11, 13.42s/it]Running generate_until requests:  51%|█████     | 51/100 [12:31<10:39, 13.06s/it]Running generate_until requests:  52%|█████▏    | 52/100 [12:49<11:29, 14.37s/it]Running generate_until requests:  53%|█████▎    | 53/100 [13:01<10:48, 13.80s/it]Running generate_until requests:  54%|█████▍    | 54/100 [13:14<10:14, 13.35s/it]Running generate_until requests:  55%|█████▌    | 55/100 [13:31<10:57, 14.61s/it]Running generate_until requests:  56%|█████▌    | 56/100 [13:43<10:05, 13.76s/it]Running generate_until requests:  57%|█████▋    | 57/100 [13:59<10:17, 14.36s/it]Running generate_until requests:  58%|█████▊    | 58/100 [14:13<10:01, 14.33s/it]Running generate_until requests:  59%|█████▉    | 59/100 [14:30<10:24, 15.22s/it]Running generate_until requests:  60%|██████    | 60/100 [14:48<10:35, 15.88s/it]Running generate_until requests:  61%|██████    | 61/100 [15:04<10:26, 16.06s/it]Running generate_until requests:  62%|██████▏   | 62/100 [15:18<09:39, 15.25s/it]Running generate_until requests:  63%|██████▎   | 63/100 [15:29<08:43, 14.16s/it]Running generate_until requests:  64%|██████▍   | 64/100 [15:41<08:03, 13.42s/it]Running generate_until requests:  65%|██████▌   | 65/100 [15:58<08:33, 14.67s/it]Running generate_until requests:  66%|██████▌   | 66/100 [16:16<08:47, 15.52s/it]Running generate_until requests:  67%|██████▋   | 67/100 [16:33<08:50, 16.07s/it]Running generate_until requests:  68%|██████▊   | 68/100 [16:51<08:49, 16.56s/it]Running generate_until requests:  69%|██████▉   | 69/100 [17:08<08:41, 16.83s/it]Running generate_until requests:  70%|███████   | 70/100 [17:23<08:00, 16.03s/it]Running generate_until requests:  71%|███████   | 71/100 [17:40<07:55, 16.41s/it]Running generate_until requests:  72%|███████▏  | 72/100 [17:57<07:49, 16.77s/it]Running generate_until requests:  73%|███████▎  | 73/100 [18:09<06:53, 15.31s/it]Running generate_until requests:  74%|███████▍  | 74/100 [18:27<06:56, 16.02s/it]Running generate_until requests:  75%|███████▌  | 75/100 [18:39<06:12, 14.89s/it]Running generate_until requests:  76%|███████▌  | 76/100 [18:51<05:32, 13.87s/it]Running generate_until requests:  77%|███████▋  | 77/100 [19:02<05:02, 13.16s/it]Running generate_until requests:  78%|███████▊  | 78/100 [19:14<04:37, 12.63s/it]Running generate_until requests:  79%|███████▉  | 79/100 [19:31<04:51, 13.90s/it]Running generate_until requests:  80%|████████  | 80/100 [19:44<04:34, 13.72s/it]Running generate_until requests:  81%|████████  | 81/100 [20:01<04:38, 14.67s/it]Running generate_until requests:  82%|████████▏ | 82/100 [20:18<04:36, 15.38s/it]Running generate_until requests:  83%|████████▎ | 83/100 [20:31<04:10, 14.75s/it]Running generate_until requests:  84%|████████▍ | 84/100 [20:43<03:42, 13.94s/it]Running generate_until requests:  85%|████████▌ | 85/100 [20:54<03:16, 13.13s/it]Running generate_until requests:  86%|████████▌ | 86/100 [21:10<03:12, 13.78s/it]Running generate_until requests:  87%|████████▋ | 87/100 [21:21<02:51, 13.16s/it]Running generate_until requests:  88%|████████▊ | 88/100 [21:33<02:32, 12.71s/it]Running generate_until requests:  89%|████████▉ | 89/100 [21:47<02:25, 13.19s/it]Running generate_until requests:  90%|█████████ | 90/100 [21:58<02:03, 12.35s/it]Running generate_until requests:  91%|█████████ | 91/100 [22:04<01:35, 10.56s/it]Running generate_until requests:  92%|█████████▏| 92/100 [22:12<01:16,  9.62s/it]Running generate_until requests:  93%|█████████▎| 93/100 [22:22<01:08,  9.80s/it]Running generate_until requests:  94%|█████████▍| 94/100 [22:30<00:56,  9.34s/it]Running generate_until requests:  95%|█████████▌| 95/100 [22:36<00:41,  8.39s/it]Running generate_until requests:  96%|█████████▌| 96/100 [22:47<00:35,  8.99s/it]Running generate_until requests:  97%|█████████▋| 97/100 [22:51<00:22,  7.56s/it]Running generate_until requests:  98%|█████████▊| 98/100 [22:59<00:15,  7.73s/it]Running generate_until requests:  99%|█████████▉| 99/100 [23:07<00:07,  7.86s/it]Running generate_until requests: 100%|██████████| 100/100 [23:11<00:00,  6.79s/it]Running generate_until requests: 100%|██████████| 100/100 [23:11<00:00, 13.92s/it]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:3'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:3'}
full model:
{'fda': {'alias': 'fda', 'contains,none': np.float64(0.87), 'contains_stderr,none': 'N/A'}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.21659225770002863
0.3676799923890141
0.7718276709674655
0.684178265870135
0.5285482451872934
0.273816514287302
0.7566340923804737
0.4195302615712732
0.7048918175177445
0.8024335694665047
0.2596571673087474
0.2906758673048459
0.6559956854150746
0.2288937672529506
0.2941846927212091
0.14545644431597915
0.27237013713290037
0.1954083722558289
0.191889756656264
0.3231769309584375
0.763391177198558
0.7591908569872912
0.47699609290977873
0.24147181909203896
0.6276241833035655
0.5039903698909594
0.506775271104323
0.17806387173399968
0.3609346134453604
0.21659225770002863
0.3676799923890141
0.7718276709674655
0.684178265870135
0.5285482451872934
0.273816514287302
0.7566340923804737
0.4195302615712732
0.7048918175177445
0.8024335694665047
0.2596571673087474
0.2906758673048459
0.6559956854150746
0.2288937672529506
0.2941846927212091
0.14545644431597915
0.27237013713290037
0.1954083722558289
0.191889756656264
0.3231769309584375
0.763391177198558
0.7591908569872912
0.47699609290977873
0.24147181909203896
0.6276241833035655
0.5039903698909594
0.506775271104323
0.17806387173399968
0.3609346134453604
0.21659225770002863
0.3676799923890141
0.7718276709674655
0.684178265870135
0.5285482451872934
0.273816514287302
0.7566340923804737
0.4195302615712732
0.7048918175177445
0.8024335694665047
0.2596571673087474
0.2906758673048459
0.6559956854150746
0.2288937672529506
0.2941846927212091
0.14545644431597915
0.27237013713290037
Total groups 70 exceeded the threshold, stopping comparison.
The group tensor is
[6, 2, 7, 0, 5, 1, 4, 3]
tensor([6, 2, 7, 0, 5, 1, 4, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 0, 1, 5, 2, 7, 6, 3]
tensor([4, 0, 1, 5, 2, 7, 6, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[1, 0, 4, 2, 6, 3, 7, 5]
tensor([1, 0, 4, 2, 6, 3, 7, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 0, 6, 3, 5, 1, 4, 2]
tensor([7, 0, 6, 3, 5, 1, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 0, 2, 5, 1, 1, 4]
tensor([0, 3, 0, 2, 5, 1, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 3, 1, 4, 1, 5, 2, 0]
tensor([0, 3, 1, 4, 1, 5, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
done!
Normal merging for layer 2
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([2])
tensor(2)
tensor([7])
tensor(7)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
done!
Normal merging for layer 3
tensor([1])
tensor(1)
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 4 to 11
done!
Normal merging for layer 12
tensor([0, 2])
tensor(0)
tensor([5, 6])
tensor(5)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([4])
tensor(4)
done!
Normal merging for layer 13
tensor([0, 7])
tensor(0)
tensor([2, 4])
tensor(2)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
done!
Cross-layer merge completed for layers 14 to 31
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 14 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 11.8828 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 13 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

40
cuda:3
logiqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:57<00:57, 57.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:18<00:00, 36.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:18<00:00, 39.28s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/logiqa HTTP/1.1" 200 743
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/EleutherAI/logiqa/EleutherAI/logiqa.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): datasets-server.hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://datasets-server.hf-mirror.com:443 "GET /parquet?dataset=EleutherAI/logiqa HTTP/1.1" 302 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET / HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/EleutherAI/logiqa/EleutherAI/logiqa.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/logiqa/resolve/main/logiqa.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/logiqa/resolve/main/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/logiqa/resolve/main/README.md HTTP/1.1" 200 0
DEBUG:filelock:Attempting to acquire lock 139706770221600 on /public/home/zouyifei001/.cache/huggingface/modules/datasets_modules/datasets/EleutherAI--logiqa.lock
DEBUG:filelock:Lock 139706770221600 acquired on /public/home/zouyifei001/.cache/huggingface/modules/datasets_modules/datasets/EleutherAI--logiqa.lock
DEBUG:filelock:Attempting to release lock 139706770221600 on /public/home/zouyifei001/.cache/huggingface/modules/datasets_modules/datasets/EleutherAI--logiqa.lock
DEBUG:filelock:Lock 139706770221600 released on /public/home/zouyifei001/.cache/huggingface/modules/datasets_modules/datasets/EleutherAI--logiqa.lock
DEBUG:filelock:Attempting to acquire lock 139706770217808 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___logiqa_logiqa_0.0.1_5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81.lock
DEBUG:filelock:Lock 139706770217808 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___logiqa_logiqa_0.0.1_5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___logiqa/logiqa/0.0.1/5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81/dataset_info.json
DEBUG:filelock:Attempting to release lock 139706770217808 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___logiqa_logiqa_0.0.1_5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81.lock
DEBUG:filelock:Lock 139706770217808 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___logiqa_logiqa_0.0.1_5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81.lock
DEBUG:filelock:Attempting to acquire lock 139716772907248 on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___logiqa/logiqa/0.0.1/5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81_builder.lock
DEBUG:filelock:Lock 139716772907248 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___logiqa/logiqa/0.0.1/5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___logiqa/logiqa/0.0.1/5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81/dataset_info.json
DEBUG:filelock:Attempting to release lock 139716772907248 on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___logiqa/logiqa/0.0.1/5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81_builder.lock
DEBUG:filelock:Lock 139716772907248 released on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___logiqa/logiqa/0.0.1/5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of logiqa from None to 0
INFO:lm_eval.api.task:Building contexts for logiqa on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 2795.01it/s]
DEBUG:lm_eval.evaluator:Task: logiqa; number of requests on this rank: 400
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/400 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/400 [00:03<22:50,  3.44s/it]Running loglikelihood requests:   0%|          | 2/400 [00:05<18:41,  2.82s/it]Running loglikelihood requests:   1%|          | 3/400 [00:08<17:12,  2.60s/it]Running loglikelihood requests:   1%|          | 4/400 [00:10<16:26,  2.49s/it]Running loglikelihood requests:   1%|▏         | 5/400 [00:12<15:52,  2.41s/it]Running loglikelihood requests:   2%|▏         | 6/400 [00:15<15:30,  2.36s/it]Running loglikelihood requests:   2%|▏         | 7/400 [00:17<15:16,  2.33s/it]Running loglikelihood requests:   2%|▏         | 8/400 [00:19<15:04,  2.31s/it]Running loglikelihood requests:   2%|▏         | 9/400 [00:21<14:53,  2.28s/it]Running loglikelihood requests:   2%|▎         | 10/400 [00:24<14:43,  2.27s/it]Running loglikelihood requests:   3%|▎         | 11/400 [00:26<14:31,  2.24s/it]Running loglikelihood requests:   3%|▎         | 12/400 [00:28<14:17,  2.21s/it]Running loglikelihood requests:   3%|▎         | 13/400 [00:30<14:06,  2.19s/it]Running loglikelihood requests:   4%|▎         | 14/400 [00:32<14:05,  2.19s/it]Running loglikelihood requests:   4%|▍         | 15/400 [00:34<13:58,  2.18s/it]Running loglikelihood requests:   4%|▍         | 16/400 [00:36<13:50,  2.16s/it]Running loglikelihood requests:   4%|▍         | 17/400 [00:39<13:45,  2.16s/it]Running loglikelihood requests:   4%|▍         | 18/400 [00:41<13:39,  2.15s/it]Running loglikelihood requests:   5%|▍         | 19/400 [00:43<13:34,  2.14s/it]Running loglikelihood requests:   5%|▌         | 20/400 [00:45<13:29,  2.13s/it]Running loglikelihood requests:   5%|▌         | 21/400 [00:47<13:23,  2.12s/it]Running loglikelihood requests:   6%|▌         | 22/400 [00:49<13:19,  2.12s/it]Running loglikelihood requests:   6%|▌         | 23/400 [00:51<13:12,  2.10s/it]Running loglikelihood requests:   6%|▌         | 24/400 [00:53<13:07,  2.09s/it]Running loglikelihood requests:   6%|▋         | 25/400 [00:55<13:09,  2.10s/it]Running loglikelihood requests:   6%|▋         | 26/400 [00:57<13:01,  2.09s/it]Running loglikelihood requests:   7%|▋         | 27/400 [01:00<12:53,  2.07s/it]Running loglikelihood requests:   7%|▋         | 28/400 [01:02<12:48,  2.07s/it]Running loglikelihood requests:   7%|▋         | 29/400 [01:04<12:41,  2.05s/it]Running loglikelihood requests:   8%|▊         | 30/400 [01:06<12:35,  2.04s/it]Running loglikelihood requests:   8%|▊         | 31/400 [01:08<12:31,  2.04s/it]Running loglikelihood requests:   8%|▊         | 32/400 [01:10<12:26,  2.03s/it]Running loglikelihood requests:   8%|▊         | 33/400 [01:12<12:24,  2.03s/it]Running loglikelihood requests:   8%|▊         | 34/400 [01:14<12:19,  2.02s/it]Running loglikelihood requests:   9%|▉         | 35/400 [01:16<12:14,  2.01s/it]Running loglikelihood requests:   9%|▉         | 36/400 [01:18<12:11,  2.01s/it]Running loglikelihood requests:   9%|▉         | 37/400 [01:20<12:05,  2.00s/it]Running loglikelihood requests:  10%|▉         | 38/400 [01:22<11:59,  1.99s/it]Running loglikelihood requests:  10%|▉         | 39/400 [01:24<11:53,  1.98s/it]Running loglikelihood requests:  10%|█         | 40/400 [01:25<11:47,  1.97s/it]Running loglikelihood requests:  10%|█         | 41/400 [01:27<11:43,  1.96s/it]Running loglikelihood requests:  10%|█         | 42/400 [01:29<11:38,  1.95s/it]Running loglikelihood requests:  11%|█         | 43/400 [01:31<11:35,  1.95s/it]Running loglikelihood requests:  11%|█         | 44/400 [01:33<11:31,  1.94s/it]Running loglikelihood requests:  11%|█▏        | 45/400 [01:35<11:28,  1.94s/it]Running loglikelihood requests:  12%|█▏        | 46/400 [01:37<11:24,  1.93s/it]Running loglikelihood requests:  12%|█▏        | 47/400 [01:39<11:19,  1.93s/it]Running loglikelihood requests:  12%|█▏        | 48/400 [01:41<11:15,  1.92s/it]Running loglikelihood requests:  12%|█▏        | 49/400 [01:43<11:12,  1.92s/it]Running loglikelihood requests:  12%|█▎        | 50/400 [01:45<11:09,  1.91s/it]Running loglikelihood requests:  13%|█▎        | 51/400 [01:47<11:06,  1.91s/it]Running loglikelihood requests:  13%|█▎        | 52/400 [01:49<11:04,  1.91s/it]Running loglikelihood requests:  13%|█▎        | 53/400 [01:50<11:02,  1.91s/it]Running loglikelihood requests:  14%|█▎        | 54/400 [01:52<10:59,  1.90s/it]Running loglikelihood requests:  14%|█▍        | 55/400 [01:54<10:54,  1.90s/it]Running loglikelihood requests:  14%|█▍        | 56/400 [01:56<10:50,  1.89s/it]Running loglikelihood requests:  14%|█▍        | 57/400 [01:58<10:44,  1.88s/it]Running loglikelihood requests:  14%|█▍        | 58/400 [02:00<10:39,  1.87s/it]Running loglikelihood requests:  15%|█▍        | 59/400 [02:02<10:35,  1.86s/it]Running loglikelihood requests:  15%|█▌        | 60/400 [02:03<10:31,  1.86s/it]Running loglikelihood requests:  15%|█▌        | 61/400 [02:05<10:27,  1.85s/it]Running loglikelihood requests:  16%|█▌        | 62/400 [02:07<10:21,  1.84s/it]Running loglikelihood requests:  16%|█▌        | 63/400 [02:09<10:16,  1.83s/it]Running loglikelihood requests:  16%|█▌        | 64/400 [02:11<10:12,  1.82s/it]Running loglikelihood requests:  16%|█▋        | 65/400 [02:12<10:05,  1.81s/it]Running loglikelihood requests:  16%|█▋        | 66/400 [02:14<10:01,  1.80s/it]Running loglikelihood requests:  17%|█▋        | 67/400 [02:16<09:55,  1.79s/it]Running loglikelihood requests:  17%|█▋        | 68/400 [02:18<09:51,  1.78s/it]Running loglikelihood requests:  17%|█▋        | 69/400 [02:20<09:46,  1.77s/it]Running loglikelihood requests:  18%|█▊        | 70/400 [02:21<09:42,  1.77s/it]Running loglikelihood requests:  18%|█▊        | 71/400 [02:23<09:39,  1.76s/it]Running loglikelihood requests:  18%|█▊        | 72/400 [02:25<09:35,  1.75s/it]Running loglikelihood requests:  18%|█▊        | 73/400 [02:27<09:29,  1.74s/it]Running loglikelihood requests:  18%|█▊        | 74/400 [02:28<09:24,  1.73s/it]Running loglikelihood requests:  19%|█▉        | 75/400 [02:30<09:20,  1.72s/it]Running loglikelihood requests:  19%|█▉        | 76/400 [02:32<09:15,  1.72s/it]Running loglikelihood requests:  19%|█▉        | 77/400 [02:33<09:10,  1.70s/it]Running loglikelihood requests:  20%|█▉        | 78/400 [02:35<09:06,  1.70s/it]Running loglikelihood requests:  20%|█▉        | 79/400 [02:37<09:01,  1.69s/it]Running loglikelihood requests:  20%|██        | 80/400 [02:38<08:58,  1.68s/it]Running loglikelihood requests:  20%|██        | 81/400 [02:40<08:53,  1.67s/it]Running loglikelihood requests:  20%|██        | 82/400 [02:42<08:48,  1.66s/it]Running loglikelihood requests:  21%|██        | 83/400 [02:43<08:45,  1.66s/it]Running loglikelihood requests:  21%|██        | 84/400 [02:45<08:42,  1.65s/it]Running loglikelihood requests:  21%|██▏       | 85/400 [02:47<08:38,  1.64s/it]Running loglikelihood requests:  22%|██▏       | 86/400 [02:48<08:34,  1.64s/it]Running loglikelihood requests:  22%|██▏       | 87/400 [02:50<08:32,  1.64s/it]Running loglikelihood requests:  22%|██▏       | 88/400 [02:51<08:30,  1.63s/it]Running loglikelihood requests:  22%|██▏       | 89/400 [02:53<08:27,  1.63s/it]Running loglikelihood requests:  22%|██▎       | 90/400 [02:55<08:26,  1.63s/it]Running loglikelihood requests:  23%|██▎       | 91/400 [02:56<08:23,  1.63s/it]Running loglikelihood requests:  23%|██▎       | 92/400 [02:58<08:20,  1.63s/it]Running loglikelihood requests:  23%|██▎       | 93/400 [03:00<08:18,  1.62s/it]Running loglikelihood requests:  24%|██▎       | 94/400 [03:01<08:16,  1.62s/it]Running loglikelihood requests:  24%|██▍       | 95/400 [03:03<08:14,  1.62s/it]Running loglikelihood requests:  24%|██▍       | 96/400 [03:04<08:11,  1.62s/it]Running loglikelihood requests:  24%|██▍       | 97/400 [03:06<08:09,  1.62s/it]Running loglikelihood requests:  24%|██▍       | 98/400 [03:08<08:07,  1.61s/it]Running loglikelihood requests:  25%|██▍       | 99/400 [03:09<08:05,  1.61s/it]Running loglikelihood requests:  25%|██▌       | 100/400 [03:11<08:03,  1.61s/it]Running loglikelihood requests:  25%|██▌       | 101/400 [03:12<08:01,  1.61s/it]Running loglikelihood requests:  26%|██▌       | 102/400 [03:14<07:59,  1.61s/it]Running loglikelihood requests:  26%|██▌       | 103/400 [03:16<07:56,  1.61s/it]Running loglikelihood requests:  26%|██▌       | 104/400 [03:17<07:57,  1.61s/it]Running loglikelihood requests:  26%|██▋       | 105/400 [03:19<07:55,  1.61s/it]Running loglikelihood requests:  26%|██▋       | 106/400 [03:20<07:52,  1.61s/it]Running loglikelihood requests:  27%|██▋       | 107/400 [03:22<07:50,  1.61s/it]Running loglikelihood requests:  27%|██▋       | 108/400 [03:24<07:46,  1.60s/it]Running loglikelihood requests:  27%|██▋       | 109/400 [03:25<07:44,  1.60s/it]Running loglikelihood requests:  28%|██▊       | 110/400 [03:27<07:42,  1.60s/it]Running loglikelihood requests:  28%|██▊       | 111/400 [03:28<07:41,  1.60s/it]Running loglikelihood requests:  28%|██▊       | 112/400 [03:30<07:37,  1.59s/it]Running loglikelihood requests:  28%|██▊       | 113/400 [03:32<07:35,  1.59s/it]Running loglikelihood requests:  28%|██▊       | 114/400 [03:33<07:32,  1.58s/it]Running loglikelihood requests:  29%|██▉       | 115/400 [03:35<07:29,  1.58s/it]Running loglikelihood requests:  29%|██▉       | 116/400 [03:36<07:27,  1.58s/it]Running loglikelihood requests:  29%|██▉       | 117/400 [03:38<07:25,  1.57s/it]Running loglikelihood requests:  30%|██▉       | 118/400 [03:39<07:24,  1.58s/it]Running loglikelihood requests:  30%|██▉       | 119/400 [03:41<07:22,  1.58s/it]Running loglikelihood requests:  30%|███       | 120/400 [03:43<07:17,  1.56s/it]Running loglikelihood requests:  30%|███       | 121/400 [03:44<07:30,  1.62s/it]Running loglikelihood requests:  30%|███       | 122/400 [03:46<07:24,  1.60s/it]Running loglikelihood requests:  31%|███       | 123/400 [03:47<07:17,  1.58s/it]Running loglikelihood requests:  31%|███       | 124/400 [03:49<07:11,  1.56s/it]Running loglikelihood requests:  31%|███▏      | 125/400 [03:50<07:10,  1.57s/it]Running loglikelihood requests:  32%|███▏      | 126/400 [03:52<07:06,  1.56s/it]Running loglikelihood requests:  32%|███▏      | 127/400 [03:54<07:02,  1.55s/it]Running loglikelihood requests:  32%|███▏      | 128/400 [03:55<07:11,  1.59s/it]Running loglikelihood requests:  32%|███▏      | 129/400 [03:57<07:07,  1.58s/it]Running loglikelihood requests:  32%|███▎      | 130/400 [03:58<07:00,  1.56s/it]Running loglikelihood requests:  33%|███▎      | 131/400 [04:00<06:55,  1.54s/it]Running loglikelihood requests:  33%|███▎      | 132/400 [04:01<06:52,  1.54s/it]Running loglikelihood requests:  33%|███▎      | 133/400 [04:03<06:48,  1.53s/it]Running loglikelihood requests:  34%|███▎      | 134/400 [04:04<06:45,  1.53s/it]Running loglikelihood requests:  34%|███▍      | 135/400 [04:06<06:43,  1.52s/it]Running loglikelihood requests:  34%|███▍      | 136/400 [04:07<06:40,  1.52s/it]Running loglikelihood requests:  34%|███▍      | 137/400 [04:09<06:38,  1.52s/it]Running loglikelihood requests:  34%|███▍      | 138/400 [04:10<06:37,  1.52s/it]Running loglikelihood requests:  35%|███▍      | 139/400 [04:12<06:35,  1.51s/it]Running loglikelihood requests:  35%|███▌      | 140/400 [04:13<06:33,  1.51s/it]Running loglikelihood requests:  36%|███▌      | 142/400 [04:15<05:00,  1.16s/it]Running loglikelihood requests:  36%|███▌      | 143/400 [04:16<05:20,  1.25s/it]Running loglikelihood requests:  36%|███▌      | 144/400 [04:18<05:36,  1.32s/it]Running loglikelihood requests:  36%|███▋      | 145/400 [04:19<05:47,  1.36s/it]Running loglikelihood requests:  36%|███▋      | 146/400 [04:21<05:55,  1.40s/it]Running loglikelihood requests:  37%|███▋      | 147/400 [04:22<06:01,  1.43s/it]Running loglikelihood requests:  37%|███▋      | 148/400 [04:24<06:06,  1.45s/it]Running loglikelihood requests:  37%|███▋      | 149/400 [04:25<06:08,  1.47s/it]Running loglikelihood requests:  38%|███▊      | 150/400 [04:27<06:08,  1.47s/it]Running loglikelihood requests:  38%|███▊      | 151/400 [04:28<06:08,  1.48s/it]Running loglikelihood requests:  38%|███▊      | 152/400 [04:30<06:07,  1.48s/it]Running loglikelihood requests:  38%|███▊      | 153/400 [04:31<06:06,  1.48s/it]Running loglikelihood requests:  38%|███▊      | 154/400 [04:33<06:05,  1.48s/it]Running loglikelihood requests:  39%|███▉      | 155/400 [04:34<06:04,  1.49s/it]Running loglikelihood requests:  39%|███▉      | 156/400 [04:36<06:02,  1.48s/it]Running loglikelihood requests:  39%|███▉      | 157/400 [04:37<06:00,  1.49s/it]Running loglikelihood requests:  40%|███▉      | 158/400 [04:39<05:59,  1.49s/it]Running loglikelihood requests:  40%|███▉      | 159/400 [04:40<05:58,  1.49s/it]Running loglikelihood requests:  40%|████      | 160/400 [04:42<05:56,  1.48s/it]Running loglikelihood requests:  40%|████      | 161/400 [04:43<05:54,  1.48s/it]Running loglikelihood requests:  40%|████      | 162/400 [04:45<05:52,  1.48s/it]Running loglikelihood requests:  41%|████      | 163/400 [04:46<05:49,  1.47s/it]Running loglikelihood requests:  41%|████      | 164/400 [04:48<05:46,  1.47s/it]Running loglikelihood requests:  41%|████▏     | 165/400 [04:49<05:43,  1.46s/it]Running loglikelihood requests:  42%|████▏     | 166/400 [04:51<05:42,  1.46s/it]Running loglikelihood requests:  42%|████▏     | 167/400 [04:52<05:43,  1.47s/it]Running loglikelihood requests:  42%|████▏     | 168/400 [04:54<05:43,  1.48s/it]Running loglikelihood requests:  42%|████▏     | 169/400 [04:55<05:43,  1.48s/it]Running loglikelihood requests:  42%|████▎     | 170/400 [04:57<05:42,  1.49s/it]Running loglikelihood requests:  43%|████▎     | 171/400 [04:58<05:41,  1.49s/it]Running loglikelihood requests:  43%|████▎     | 172/400 [05:00<05:39,  1.49s/it]Running loglikelihood requests:  43%|████▎     | 173/400 [05:01<05:38,  1.49s/it]Running loglikelihood requests:  44%|████▎     | 174/400 [05:03<05:36,  1.49s/it]Running loglikelihood requests:  44%|████▍     | 175/400 [05:04<05:34,  1.49s/it]Running loglikelihood requests:  44%|████▍     | 176/400 [05:05<05:32,  1.49s/it]Running loglikelihood requests:  44%|████▍     | 177/400 [05:07<05:30,  1.48s/it]Running loglikelihood requests:  44%|████▍     | 178/400 [05:08<05:28,  1.48s/it]Running loglikelihood requests:  45%|████▍     | 179/400 [05:10<05:26,  1.48s/it]Running loglikelihood requests:  45%|████▌     | 180/400 [05:11<05:23,  1.47s/it]Running loglikelihood requests:  45%|████▌     | 181/400 [05:13<05:21,  1.47s/it]Running loglikelihood requests:  46%|████▌     | 182/400 [05:14<05:19,  1.47s/it]Running loglikelihood requests:  46%|████▌     | 183/400 [05:16<05:18,  1.47s/it]Running loglikelihood requests:  46%|████▌     | 184/400 [05:17<05:15,  1.46s/it]Running loglikelihood requests:  46%|████▋     | 185/400 [05:19<05:14,  1.46s/it]Running loglikelihood requests:  46%|████▋     | 186/400 [05:20<05:12,  1.46s/it]Running loglikelihood requests:  47%|████▋     | 187/400 [05:22<05:10,  1.46s/it]Running loglikelihood requests:  47%|████▋     | 188/400 [05:23<05:08,  1.45s/it]Running loglikelihood requests:  47%|████▋     | 189/400 [05:24<05:06,  1.45s/it]Running loglikelihood requests:  48%|████▊     | 190/400 [05:26<05:04,  1.45s/it]Running loglikelihood requests:  48%|████▊     | 191/400 [05:27<05:02,  1.45s/it]Running loglikelihood requests:  48%|████▊     | 192/400 [05:29<05:00,  1.45s/it]Running loglikelihood requests:  48%|████▊     | 193/400 [05:30<04:58,  1.44s/it]Running loglikelihood requests:  48%|████▊     | 194/400 [05:32<04:56,  1.44s/it]Running loglikelihood requests:  49%|████▉     | 195/400 [05:33<04:54,  1.43s/it]Running loglikelihood requests:  49%|████▉     | 196/400 [05:35<04:52,  1.43s/it]Running loglikelihood requests:  49%|████▉     | 197/400 [05:36<04:59,  1.48s/it]Running loglikelihood requests:  50%|████▉     | 198/400 [05:38<04:56,  1.47s/it]Running loglikelihood requests:  50%|████▉     | 199/400 [05:39<04:52,  1.45s/it]Running loglikelihood requests:  50%|█████     | 200/400 [05:40<04:48,  1.44s/it]Running loglikelihood requests:  50%|█████     | 201/400 [05:42<04:46,  1.44s/it]Running loglikelihood requests:  50%|█████     | 202/400 [05:43<04:42,  1.43s/it]Running loglikelihood requests:  51%|█████     | 203/400 [05:45<04:39,  1.42s/it]Running loglikelihood requests:  51%|█████     | 204/400 [05:46<04:37,  1.41s/it]Running loglikelihood requests:  51%|█████▏    | 205/400 [05:47<04:35,  1.41s/it]Running loglikelihood requests:  52%|█████▏    | 206/400 [05:49<04:33,  1.41s/it]Running loglikelihood requests:  52%|█████▏    | 207/400 [05:50<04:32,  1.41s/it]Running loglikelihood requests:  52%|█████▏    | 208/400 [05:52<04:30,  1.41s/it]Running loglikelihood requests:  52%|█████▏    | 209/400 [05:53<04:27,  1.40s/it]Running loglikelihood requests:  52%|█████▎    | 210/400 [05:54<04:25,  1.40s/it]Running loglikelihood requests:  53%|█████▎    | 211/400 [05:56<04:22,  1.39s/it]Running loglikelihood requests:  53%|█████▎    | 212/400 [05:57<04:19,  1.38s/it]Running loglikelihood requests:  53%|█████▎    | 213/400 [05:59<04:17,  1.38s/it]Running loglikelihood requests:  54%|█████▎    | 214/400 [06:00<04:17,  1.38s/it]Running loglikelihood requests:  54%|█████▍    | 215/400 [06:01<04:15,  1.38s/it]Running loglikelihood requests:  54%|█████▍    | 216/400 [06:03<04:14,  1.38s/it]Running loglikelihood requests:  54%|█████▍    | 217/400 [06:04<04:13,  1.38s/it]Running loglikelihood requests:  55%|█████▍    | 218/400 [06:05<04:11,  1.38s/it]Running loglikelihood requests:  55%|█████▍    | 219/400 [06:07<04:11,  1.39s/it]Running loglikelihood requests:  55%|█████▌    | 220/400 [06:08<04:09,  1.38s/it]Running loglikelihood requests:  55%|█████▌    | 221/400 [06:10<04:07,  1.38s/it]Running loglikelihood requests:  56%|█████▌    | 222/400 [06:11<04:05,  1.38s/it]Running loglikelihood requests:  56%|█████▌    | 223/400 [06:12<04:03,  1.38s/it]Running loglikelihood requests:  56%|█████▌    | 224/400 [06:14<04:02,  1.38s/it]Running loglikelihood requests:  56%|█████▋    | 225/400 [06:15<04:01,  1.38s/it]Running loglikelihood requests:  56%|█████▋    | 226/400 [06:17<04:03,  1.40s/it]Running loglikelihood requests:  57%|█████▋    | 227/400 [06:18<04:02,  1.40s/it]Running loglikelihood requests:  57%|█████▋    | 228/400 [06:19<03:59,  1.40s/it]Running loglikelihood requests:  57%|█████▋    | 229/400 [06:21<03:57,  1.39s/it]Running loglikelihood requests:  57%|█████▊    | 230/400 [06:22<03:55,  1.39s/it]Running loglikelihood requests:  58%|█████▊    | 231/400 [06:23<03:53,  1.38s/it]Running loglikelihood requests:  58%|█████▊    | 232/400 [06:25<03:52,  1.38s/it]Running loglikelihood requests:  58%|█████▊    | 233/400 [06:26<03:50,  1.38s/it]Running loglikelihood requests:  58%|█████▊    | 234/400 [06:28<03:48,  1.38s/it]Running loglikelihood requests:  59%|█████▉    | 235/400 [06:29<03:46,  1.37s/it]Running loglikelihood requests:  59%|█████▉    | 236/400 [06:31<03:54,  1.43s/it]Running loglikelihood requests:  59%|█████▉    | 237/400 [06:32<03:50,  1.41s/it]Running loglikelihood requests:  60%|█████▉    | 238/400 [06:33<03:46,  1.40s/it]Running loglikelihood requests:  60%|█████▉    | 239/400 [06:35<03:43,  1.39s/it]Running loglikelihood requests:  60%|██████    | 240/400 [06:36<03:41,  1.38s/it]Running loglikelihood requests:  60%|██████    | 241/400 [06:37<03:39,  1.38s/it]Running loglikelihood requests:  60%|██████    | 242/400 [06:39<03:37,  1.37s/it]Running loglikelihood requests:  61%|██████    | 243/400 [06:40<03:35,  1.37s/it]Running loglikelihood requests:  61%|██████    | 244/400 [06:41<03:33,  1.37s/it]Running loglikelihood requests:  61%|██████▏   | 245/400 [06:43<03:31,  1.37s/it]Running loglikelihood requests:  62%|██████▏   | 246/400 [06:44<03:30,  1.37s/it]Running loglikelihood requests:  62%|██████▏   | 247/400 [06:46<03:28,  1.37s/it]Running loglikelihood requests:  62%|██████▏   | 248/400 [06:47<03:27,  1.37s/it]Running loglikelihood requests:  62%|██████▏   | 249/400 [06:48<03:25,  1.36s/it]Running loglikelihood requests:  62%|██████▎   | 250/400 [06:50<03:23,  1.36s/it]Running loglikelihood requests:  63%|██████▎   | 251/400 [06:51<03:22,  1.36s/it]Running loglikelihood requests:  63%|██████▎   | 252/400 [06:52<03:21,  1.36s/it]Running loglikelihood requests:  63%|██████▎   | 253/400 [06:54<03:19,  1.36s/it]Running loglikelihood requests:  64%|██████▎   | 254/400 [06:55<03:17,  1.35s/it]Running loglikelihood requests:  64%|██████▍   | 255/400 [06:56<03:16,  1.35s/it]Running loglikelihood requests:  64%|██████▍   | 256/400 [06:58<03:14,  1.35s/it]Running loglikelihood requests:  64%|██████▍   | 257/400 [06:59<03:13,  1.35s/it]Running loglikelihood requests:  64%|██████▍   | 258/400 [07:00<03:11,  1.35s/it]Running loglikelihood requests:  65%|██████▍   | 259/400 [07:02<03:10,  1.35s/it]Running loglikelihood requests:  65%|██████▌   | 260/400 [07:03<03:08,  1.35s/it]Running loglikelihood requests:  65%|██████▌   | 261/400 [07:04<03:07,  1.35s/it]Running loglikelihood requests:  66%|██████▌   | 262/400 [07:06<03:05,  1.34s/it]Running loglikelihood requests:  66%|██████▌   | 263/400 [07:07<03:03,  1.34s/it]Running loglikelihood requests:  66%|██████▌   | 264/400 [07:08<03:01,  1.34s/it]Running loglikelihood requests:  66%|██████▋   | 265/400 [07:10<02:59,  1.33s/it]Running loglikelihood requests:  66%|██████▋   | 266/400 [07:11<02:58,  1.33s/it]Running loglikelihood requests:  67%|██████▋   | 267/400 [07:12<02:56,  1.33s/it]Running loglikelihood requests:  67%|██████▋   | 268/400 [07:14<02:55,  1.33s/it]Running loglikelihood requests:  67%|██████▋   | 269/400 [07:15<02:53,  1.33s/it]Running loglikelihood requests:  68%|██████▊   | 270/400 [07:16<02:51,  1.32s/it]Running loglikelihood requests:  68%|██████▊   | 271/400 [07:18<02:50,  1.32s/it]Running loglikelihood requests:  68%|██████▊   | 272/400 [07:19<02:47,  1.31s/it]Running loglikelihood requests:  68%|██████▊   | 273/400 [07:20<02:46,  1.31s/it]Running loglikelihood requests:  68%|██████▊   | 274/400 [07:22<02:45,  1.31s/it]Running loglikelihood requests:  69%|██████▉   | 275/400 [07:23<02:43,  1.31s/it]Running loglikelihood requests:  69%|██████▉   | 276/400 [07:24<02:42,  1.31s/it]Running loglikelihood requests:  69%|██████▉   | 277/400 [07:26<02:40,  1.30s/it]Running loglikelihood requests:  70%|██████▉   | 278/400 [07:27<02:38,  1.30s/it]Running loglikelihood requests:  70%|███████   | 280/400 [07:28<01:59,  1.00it/s]Running loglikelihood requests:  70%|███████   | 281/400 [07:29<02:07,  1.07s/it]Running loglikelihood requests:  70%|███████   | 282/400 [07:31<02:13,  1.13s/it]Running loglikelihood requests:  71%|███████   | 283/400 [07:32<02:16,  1.17s/it]Running loglikelihood requests:  71%|███████   | 284/400 [07:33<02:19,  1.20s/it]Running loglikelihood requests:  71%|███████▏  | 285/400 [07:35<02:20,  1.22s/it]Running loglikelihood requests:  72%|███████▏  | 286/400 [07:36<02:21,  1.24s/it]Running loglikelihood requests:  72%|███████▏  | 287/400 [07:37<02:21,  1.25s/it]Running loglikelihood requests:  72%|███████▏  | 288/400 [07:38<02:20,  1.26s/it]Running loglikelihood requests:  72%|███████▏  | 289/400 [07:40<02:19,  1.26s/it]Running loglikelihood requests:  72%|███████▎  | 290/400 [07:41<02:18,  1.26s/it]Running loglikelihood requests:  73%|███████▎  | 291/400 [07:42<02:16,  1.26s/it]Running loglikelihood requests:  73%|███████▎  | 292/400 [07:43<02:15,  1.25s/it]Running loglikelihood requests:  73%|███████▎  | 293/400 [07:45<02:13,  1.25s/it]Running loglikelihood requests:  74%|███████▎  | 294/400 [07:46<02:12,  1.25s/it]Running loglikelihood requests:  74%|███████▍  | 295/400 [07:47<02:11,  1.25s/it]Running loglikelihood requests:  74%|███████▍  | 296/400 [07:48<02:09,  1.25s/it]Running loglikelihood requests:  74%|███████▍  | 297/400 [07:50<02:08,  1.24s/it]Running loglikelihood requests:  74%|███████▍  | 298/400 [07:51<02:06,  1.24s/it]Running loglikelihood requests:  75%|███████▍  | 299/400 [07:52<02:05,  1.24s/it]Running loglikelihood requests:  75%|███████▌  | 300/400 [07:53<02:03,  1.24s/it]Running loglikelihood requests:  75%|███████▌  | 301/400 [07:55<02:02,  1.23s/it]Running loglikelihood requests:  76%|███████▌  | 302/400 [07:56<02:00,  1.23s/it]Running loglikelihood requests:  76%|███████▌  | 303/400 [07:57<01:59,  1.23s/it]Running loglikelihood requests:  76%|███████▌  | 304/400 [07:58<01:58,  1.23s/it]Running loglikelihood requests:  76%|███████▋  | 305/400 [07:59<01:56,  1.23s/it]Running loglikelihood requests:  76%|███████▋  | 306/400 [08:01<01:55,  1.22s/it]Running loglikelihood requests:  77%|███████▋  | 307/400 [08:02<01:53,  1.22s/it]Running loglikelihood requests:  77%|███████▋  | 308/400 [08:03<01:52,  1.22s/it]Running loglikelihood requests:  77%|███████▋  | 309/400 [08:04<01:50,  1.22s/it]Running loglikelihood requests:  78%|███████▊  | 310/400 [08:05<01:49,  1.22s/it]Running loglikelihood requests:  78%|███████▊  | 311/400 [08:07<01:48,  1.22s/it]Running loglikelihood requests:  78%|███████▊  | 312/400 [08:08<01:46,  1.22s/it]Running loglikelihood requests:  78%|███████▊  | 313/400 [08:09<01:45,  1.21s/it]Running loglikelihood requests:  78%|███████▊  | 314/400 [08:10<01:44,  1.21s/it]Running loglikelihood requests:  79%|███████▉  | 315/400 [08:12<01:43,  1.21s/it]Running loglikelihood requests:  79%|███████▉  | 316/400 [08:13<01:41,  1.21s/it]Running loglikelihood requests:  79%|███████▉  | 317/400 [08:14<01:40,  1.21s/it]Running loglikelihood requests:  80%|███████▉  | 318/400 [08:15<01:39,  1.21s/it]Running loglikelihood requests:  80%|███████▉  | 319/400 [08:16<01:37,  1.21s/it]Running loglikelihood requests:  80%|████████  | 320/400 [08:18<01:36,  1.20s/it]Running loglikelihood requests:  80%|████████  | 321/400 [08:19<01:34,  1.20s/it]Running loglikelihood requests:  80%|████████  | 322/400 [08:20<01:33,  1.20s/it]Running loglikelihood requests:  81%|████████  | 323/400 [08:21<01:32,  1.20s/it]Running loglikelihood requests:  81%|████████  | 324/400 [08:22<01:30,  1.20s/it]Running loglikelihood requests:  81%|████████▏ | 325/400 [08:24<01:29,  1.19s/it]Running loglikelihood requests:  82%|████████▏ | 326/400 [08:25<01:28,  1.19s/it]Running loglikelihood requests:  82%|████████▏ | 327/400 [08:26<01:27,  1.19s/it]Running loglikelihood requests:  82%|████████▏ | 328/400 [08:27<01:25,  1.19s/it]Running loglikelihood requests:  82%|████████▏ | 329/400 [08:28<01:24,  1.19s/it]Running loglikelihood requests:  82%|████████▎ | 330/400 [08:29<01:23,  1.19s/it]Running loglikelihood requests:  83%|████████▎ | 331/400 [08:31<01:21,  1.19s/it]Running loglikelihood requests:  83%|████████▎ | 332/400 [08:32<01:20,  1.19s/it]Running loglikelihood requests:  83%|████████▎ | 333/400 [08:33<01:19,  1.18s/it]Running loglikelihood requests:  84%|████████▎ | 334/400 [08:34<01:17,  1.18s/it]Running loglikelihood requests:  84%|████████▍ | 335/400 [08:35<01:16,  1.18s/it]Running loglikelihood requests:  84%|████████▍ | 336/400 [08:37<01:15,  1.18s/it]Running loglikelihood requests:  84%|████████▍ | 337/400 [08:38<01:14,  1.17s/it]Running loglikelihood requests:  84%|████████▍ | 338/400 [08:39<01:12,  1.17s/it]Running loglikelihood requests:  85%|████████▍ | 339/400 [08:40<01:11,  1.17s/it]Running loglikelihood requests:  85%|████████▌ | 340/400 [08:41<01:10,  1.17s/it]Running loglikelihood requests:  85%|████████▌ | 341/400 [08:42<01:08,  1.17s/it]Running loglikelihood requests:  86%|████████▌ | 342/400 [08:44<01:07,  1.16s/it]Running loglikelihood requests:  86%|████████▌ | 343/400 [08:45<01:05,  1.16s/it]Running loglikelihood requests:  86%|████████▌ | 344/400 [08:46<01:04,  1.15s/it]Running loglikelihood requests:  86%|████████▋ | 345/400 [08:47<01:03,  1.15s/it]Running loglikelihood requests:  86%|████████▋ | 346/400 [08:48<01:02,  1.15s/it]Running loglikelihood requests:  87%|████████▋ | 347/400 [08:50<01:07,  1.26s/it]Running loglikelihood requests:  87%|████████▋ | 348/400 [08:51<01:04,  1.24s/it]Running loglikelihood requests:  87%|████████▋ | 349/400 [08:52<01:04,  1.26s/it]Running loglikelihood requests:  88%|████████▊ | 350/400 [08:53<01:01,  1.23s/it]Running loglikelihood requests:  88%|████████▊ | 351/400 [08:54<00:59,  1.21s/it]Running loglikelihood requests:  88%|████████▊ | 352/400 [08:56<00:57,  1.19s/it]Running loglikelihood requests:  88%|████████▊ | 353/400 [08:57<00:55,  1.18s/it]Running loglikelihood requests:  88%|████████▊ | 354/400 [08:58<00:53,  1.17s/it]Running loglikelihood requests:  89%|████████▉ | 355/400 [08:59<00:52,  1.16s/it]Running loglikelihood requests:  89%|████████▉ | 356/400 [09:00<00:50,  1.15s/it]Running loglikelihood requests:  89%|████████▉ | 357/400 [09:01<00:49,  1.15s/it]Running loglikelihood requests:  90%|████████▉ | 358/400 [09:02<00:47,  1.14s/it]Running loglikelihood requests:  90%|████████▉ | 359/400 [09:04<00:46,  1.14s/it]Running loglikelihood requests:  90%|█████████ | 360/400 [09:05<00:45,  1.13s/it]Running loglikelihood requests:  90%|█████████ | 361/400 [09:06<00:44,  1.15s/it]Running loglikelihood requests:  90%|█████████ | 362/400 [09:07<00:43,  1.14s/it]Running loglikelihood requests:  91%|█████████ | 363/400 [09:08<00:42,  1.14s/it]Running loglikelihood requests:  91%|█████████ | 364/400 [09:09<00:40,  1.13s/it]Running loglikelihood requests:  91%|█████████▏| 365/400 [09:10<00:39,  1.12s/it]Running loglikelihood requests:  92%|█████████▏| 366/400 [09:11<00:38,  1.12s/it]Running loglikelihood requests:  92%|█████████▏| 367/400 [09:13<00:36,  1.12s/it]Running loglikelihood requests:  92%|█████████▏| 368/400 [09:14<00:35,  1.11s/it]Running loglikelihood requests:  92%|█████████▏| 369/400 [09:15<00:34,  1.12s/it]Running loglikelihood requests:  92%|█████████▎| 370/400 [09:16<00:33,  1.11s/it]Running loglikelihood requests:  93%|█████████▎| 371/400 [09:17<00:32,  1.11s/it]Running loglikelihood requests:  93%|█████████▎| 372/400 [09:18<00:30,  1.10s/it]Running loglikelihood requests:  93%|█████████▎| 373/400 [09:19<00:29,  1.10s/it]Running loglikelihood requests:  94%|█████████▎| 374/400 [09:20<00:28,  1.09s/it]Running loglikelihood requests:  94%|█████████▍| 375/400 [09:21<00:27,  1.09s/it]Running loglikelihood requests:  94%|█████████▍| 376/400 [09:22<00:25,  1.08s/it]Running loglikelihood requests:  94%|█████████▍| 377/400 [09:23<00:24,  1.07s/it]Running loglikelihood requests:  94%|█████████▍| 378/400 [09:24<00:23,  1.06s/it]Running loglikelihood requests:  95%|█████████▍| 379/400 [09:26<00:22,  1.05s/it]Running loglikelihood requests:  95%|█████████▌| 380/400 [09:27<00:20,  1.04s/it]Running loglikelihood requests:  95%|█████████▌| 381/400 [09:28<00:19,  1.03s/it]Running loglikelihood requests:  96%|█████████▌| 382/400 [09:29<00:18,  1.02s/it]Running loglikelihood requests:  96%|█████████▌| 383/400 [09:30<00:17,  1.02s/it]Running loglikelihood requests:  96%|█████████▌| 384/400 [09:31<00:16,  1.01s/it]Running loglikelihood requests:  96%|█████████▋| 385/400 [09:32<00:15,  1.01s/it]Running loglikelihood requests:  96%|█████████▋| 386/400 [09:33<00:14,  1.01s/it]Running loglikelihood requests:  97%|█████████▋| 387/400 [09:34<00:13,  1.00s/it]Running loglikelihood requests:  97%|█████████▋| 389/400 [09:35<00:08,  1.31it/s]Running loglikelihood requests:  98%|█████████▊| 390/400 [09:35<00:08,  1.24it/s]Running loglikelihood requests:  98%|█████████▊| 391/400 [09:36<00:07,  1.19it/s]Running loglikelihood requests:  98%|█████████▊| 393/400 [09:37<00:04,  1.49it/s]Running loglikelihood requests:  98%|█████████▊| 394/400 [09:38<00:04,  1.39it/s]Running loglikelihood requests:  99%|█████████▉| 395/400 [09:39<00:03,  1.32it/s]Running loglikelihood requests:  99%|█████████▉| 396/400 [09:40<00:03,  1.25it/s]Running loglikelihood requests:  99%|█████████▉| 397/400 [09:41<00:02,  1.20it/s]Running loglikelihood requests: 100%|█████████▉| 398/400 [09:42<00:01,  1.18it/s]Running loglikelihood requests: 100%|█████████▉| 399/400 [09:43<00:00,  1.17it/s]Running loglikelihood requests: 100%|██████████| 400/400 [09:44<00:00,  1.16it/s]Running loglikelihood requests: 100%|██████████| 400/400 [09:44<00:00,  1.46s/it]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:4'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:4'}
full model:
{'logiqa': {'alias': 'logiqa', 'acc,none': 0.29, 'acc_stderr,none': 0.045604802157206865, 'acc_norm,none': 0.33, 'acc_norm_stderr,none': 0.04725815626252609}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9179964803140478
0.7817057225882229
0.8413553272072316
0.9274797474668193
0.8768807463293081
0.9494139907523571
0.8960692461846443
0.9131107283061946
0.6329173647892901
0.8375042173336539
0.8817471801904351
0.8172295355829869
0.7824572665005357
0.9227400642857845
0.9246594853497696
0.8075911590072223
0.6900210787422486
0.599615993999193
0.9308030044211123
0.9504015361511146
0.8866807231108503
0.540104242930401
0.6701728801805507
0.9744992661822648
0.8193037468812308
0.840784693447352
0.9052511591891966
Total groups 70 exceeded the threshold, stopping comparison.
The group tensor is
[3, 6, 7, 1, 5, 2, 4, 0]
tensor([3, 6, 7, 1, 5, 2, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 2, 6, 3, 7, 1, 5, 0]
tensor([4, 2, 6, 3, 7, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 3, 6, 1, 7, 2, 4, 0]
tensor([5, 3, 6, 1, 7, 2, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 4, 6, 1, 7, 2, 3, 0]
tensor([5, 4, 6, 1, 7, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 3, 0, 2, 1, 0, 4, 1]
tensor([5, 3, 0, 2, 1, 0, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 0, 5, 0, 1, 2, 3, 1]
tensor([4, 0, 5, 0, 1, 2, 3, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Normal merging for layer 2
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 4 to 8
done!
Normal merging for layer 9
tensor([2, 5])
tensor(2)
tensor([4, 7])
tensor(4)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 10 to 13
done!
Normal merging for layer 14
tensor([1, 3])
tensor(1)
tensor([4, 7])
tensor(4)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Cross-layer merge completed for layers 15 to 31
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 13 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 11.9458 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 12 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

157
cuda:4
cola
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:55<00:55, 55.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:13<00:00, 33.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:13<00:00, 36.75s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: cola] metric mcc is defined, but aggregation is not. using default aggregation=matthews_corrcoef
WARNING:lm_eval.api.task:[Task: cola] metric mcc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/revision/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 111
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/revision/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c?recursive=False&expand=False HTTP/1.1" 307 136
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c?recursive=False&expand=False HTTP/1.1" 200 530
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/ax?recursive=False&expand=False HTTP/1.1" 307 139
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/ax?recursive=False&expand=False HTTP/1.1" 200 231
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/revision/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 111
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/revision/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cola?recursive=False&expand=False HTTP/1.1" 307 141
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cola?recursive=False&expand=False HTTP/1.1" 200 358
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139706362675520 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_cola_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139706362675520 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_cola_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139706362675520 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_cola_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139706362675520 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_cola_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139706770224960 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139706770224960 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139706770224960 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139706770224960 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of cola from None to 0
INFO:lm_eval.api.task:Building contexts for cola on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 3204.99it/s]
DEBUG:lm_eval.evaluator:Task: cola; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:01<04:53,  1.47s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:02<01:54,  1.72it/s]Running loglikelihood requests:   2%|▎         | 5/200 [00:02<01:21,  2.40it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:03<01:07,  2.84it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:03<01:00,  3.17it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:04<00:55,  3.40it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:04<00:53,  3.51it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:05<00:50,  3.65it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:05<00:48,  3.75it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:06<00:47,  3.83it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:06<00:46,  3.89it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:07<00:45,  3.92it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:07<00:44,  3.96it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:08<00:44,  3.91it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:08<00:43,  3.95it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:09<00:42,  3.97it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:09<00:41,  3.99it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:10<00:40,  4.03it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:10<00:40,  4.05it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:11<00:39,  4.07it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:11<00:38,  4.08it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:12<00:38,  4.09it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:12<00:37,  4.10it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:13<00:37,  4.11it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:13<00:36,  4.12it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:13<00:35,  4.14it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:14<00:35,  4.15it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:14<00:34,  4.16it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:15<00:34,  4.16it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:15<00:33,  4.16it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:16<00:33,  4.18it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:16<00:32,  4.19it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:17<00:32,  4.19it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:17<00:31,  4.19it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:18<00:31,  4.21it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:18<00:30,  4.23it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:19<00:29,  4.24it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:19<00:29,  4.25it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:20<00:28,  4.26it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:20<00:28,  4.27it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:21<00:27,  4.27it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:21<00:27,  4.28it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:22<00:26,  4.29it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:22<00:26,  4.30it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:22<00:25,  4.29it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:23<00:25,  4.29it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:23<00:24,  4.30it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:24<00:24,  4.30it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:24<00:23,  4.31it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:25<00:23,  4.31it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:25<00:22,  4.31it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:26<00:22,  4.32it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:26<00:21,  4.32it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:27<00:21,  4.34it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:27<00:20,  4.35it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:28<00:20,  4.34it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:28<00:20,  4.34it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:28<00:19,  4.35it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:29<00:19,  4.36it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:29<00:18,  4.38it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:30<00:18,  4.39it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:30<00:17,  4.38it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:31<00:17,  4.39it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [00:31<00:16,  4.40it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [00:32<00:16,  4.41it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [00:32<00:15,  4.43it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [00:33<00:15,  4.45it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [00:33<00:14,  4.45it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [00:33<00:14,  4.46it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [00:34<00:13,  4.46it/s]Running loglikelihood requests:  70%|███████   | 141/200 [00:34<00:13,  4.47it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [00:35<00:12,  4.48it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [00:35<00:12,  4.48it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [00:36<00:11,  4.49it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [00:36<00:11,  4.50it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [00:37<00:10,  4.50it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [00:37<00:10,  4.49it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [00:37<00:10,  4.49it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [00:38<00:09,  4.50it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [00:38<00:09,  4.18it/s]Running loglikelihood requests:  80%|████████  | 161/200 [00:39<00:09,  4.30it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [00:39<00:08,  4.40it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [00:40<00:07,  4.47it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [00:40<00:07,  4.51it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [00:41<00:06,  4.54it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [00:41<00:06,  4.58it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [00:41<00:05,  4.62it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [00:42<00:05,  4.63it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [00:42<00:04,  4.66it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [00:43<00:04,  4.66it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [00:43<00:04,  4.66it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [00:44<00:03,  4.68it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [00:44<00:03,  4.68it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [00:44<00:02,  4.69it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [00:45<00:02,  4.71it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [00:45<00:01,  4.73it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [00:46<00:01,  4.75it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [00:46<00:01,  4.77it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [00:47<00:00,  4.77it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [00:47<00:00,  4.79it/s]Running loglikelihood requests: 100%|██████████| 200/200 [00:47<00:00,  4.22it/s]
bootstrapping for stddev (sequential): matthews_corrcoef
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<01:32,  1.07it/s]  2%|▏         | 2/100 [00:01<01:31,  1.08it/s]  3%|▎         | 3/100 [00:02<01:29,  1.08it/s]  4%|▍         | 4/100 [00:03<01:28,  1.09it/s]  5%|▌         | 5/100 [00:04<01:27,  1.09it/s]  6%|▌         | 6/100 [00:05<01:26,  1.09it/s]  7%|▋         | 7/100 [00:06<01:25,  1.09it/s]  8%|▊         | 8/100 [00:07<01:24,  1.08it/s]  9%|▉         | 9/100 [00:08<01:23,  1.09it/s] 10%|█         | 10/100 [00:09<01:22,  1.09it/s] 11%|█         | 11/100 [00:10<01:21,  1.09it/s] 12%|█▏        | 12/100 [00:11<01:20,  1.09it/s] 13%|█▎        | 13/100 [00:11<01:20,  1.08it/s] 14%|█▍        | 14/100 [00:12<01:19,  1.09it/s] 15%|█▌        | 15/100 [00:13<01:18,  1.09it/s] 16%|█▌        | 16/100 [00:14<01:17,  1.09it/s] 17%|█▋        | 17/100 [00:15<01:16,  1.09it/s] 18%|█▊        | 18/100 [00:16<01:15,  1.09it/s] 19%|█▉        | 19/100 [00:17<01:14,  1.08it/s] 20%|██        | 20/100 [00:18<01:13,  1.08it/s] 21%|██        | 21/100 [00:19<01:12,  1.08it/s] 22%|██▏       | 22/100 [00:20<01:11,  1.08it/s] 23%|██▎       | 23/100 [00:21<01:10,  1.09it/s] 24%|██▍       | 24/100 [00:22<01:10,  1.08it/s] 25%|██▌       | 25/100 [00:23<01:09,  1.08it/s] 26%|██▌       | 26/100 [00:23<01:08,  1.09it/s] 27%|██▋       | 27/100 [00:24<01:07,  1.09it/s] 28%|██▊       | 28/100 [00:25<01:06,  1.09it/s] 29%|██▉       | 29/100 [00:26<01:05,  1.09it/s] 30%|███       | 30/100 [00:27<01:04,  1.08it/s] 31%|███       | 31/100 [00:28<01:03,  1.09it/s] 32%|███▏      | 32/100 [00:29<01:02,  1.09it/s] 33%|███▎      | 33/100 [00:30<01:01,  1.09it/s] 34%|███▍      | 34/100 [00:31<01:00,  1.09it/s] 35%|███▌      | 35/100 [00:32<01:00,  1.08it/s] 36%|███▌      | 36/100 [00:33<00:59,  1.08it/s] 37%|███▋      | 37/100 [00:34<00:58,  1.08it/s] 38%|███▊      | 38/100 [00:35<00:57,  1.08it/s] 39%|███▉      | 39/100 [00:35<00:56,  1.09it/s] 40%|████      | 40/100 [00:36<00:55,  1.09it/s] 41%|████      | 41/100 [00:37<00:54,  1.08it/s] 42%|████▏     | 42/100 [00:38<00:53,  1.08it/s] 43%|████▎     | 43/100 [00:39<00:53,  1.06it/s] 44%|████▍     | 44/100 [00:40<00:52,  1.07it/s] 45%|████▌     | 45/100 [00:41<00:51,  1.07it/s] 46%|████▌     | 46/100 [00:42<00:50,  1.07it/s] 47%|████▋     | 47/100 [00:43<00:49,  1.07it/s] 48%|████▊     | 48/100 [00:44<00:48,  1.08it/s] 49%|████▉     | 49/100 [00:45<00:47,  1.08it/s] 50%|█████     | 50/100 [00:46<00:46,  1.08it/s] 51%|█████     | 51/100 [00:47<00:45,  1.08it/s] 52%|█████▏    | 52/100 [00:48<00:44,  1.08it/s] 53%|█████▎    | 53/100 [00:48<00:43,  1.08it/s] 54%|█████▍    | 54/100 [00:49<00:42,  1.08it/s] 55%|█████▌    | 55/100 [00:50<00:41,  1.09it/s] 56%|█████▌    | 56/100 [00:51<00:40,  1.09it/s] 57%|█████▋    | 57/100 [00:52<00:39,  1.08it/s] 58%|█████▊    | 58/100 [00:53<00:38,  1.08it/s] 59%|█████▉    | 59/100 [00:54<00:37,  1.08it/s] 60%|██████    | 60/100 [00:55<00:36,  1.08it/s] 61%|██████    | 61/100 [00:56<00:35,  1.09it/s] 62%|██████▏   | 62/100 [00:57<00:35,  1.08it/s] 63%|██████▎   | 63/100 [00:58<00:34,  1.08it/s] 64%|██████▍   | 64/100 [00:59<00:33,  1.08it/s] 65%|██████▌   | 65/100 [01:00<00:32,  1.08it/s] 66%|██████▌   | 66/100 [01:00<00:31,  1.08it/s] 67%|██████▋   | 67/100 [01:01<00:30,  1.08it/s] 68%|██████▊   | 68/100 [01:02<00:29,  1.08it/s] 69%|██████▉   | 69/100 [01:03<00:28,  1.08it/s] 70%|███████   | 70/100 [01:04<00:27,  1.08it/s] 71%|███████   | 71/100 [01:05<00:26,  1.09it/s] 72%|███████▏  | 72/100 [01:06<00:25,  1.09it/s] 73%|███████▎  | 73/100 [01:07<00:25,  1.07it/s] 74%|███████▍  | 74/100 [01:08<00:24,  1.07it/s] 75%|███████▌  | 75/100 [01:09<00:23,  1.07it/s] 76%|███████▌  | 76/100 [01:10<00:22,  1.07it/s] 77%|███████▋  | 77/100 [01:11<00:21,  1.08it/s] 78%|███████▊  | 78/100 [01:12<00:20,  1.07it/s] 79%|███████▉  | 79/100 [01:13<00:19,  1.07it/s] 80%|████████  | 80/100 [01:13<00:18,  1.07it/s] 81%|████████  | 81/100 [01:14<00:17,  1.07it/s] 82%|████████▏ | 82/100 [01:15<00:16,  1.08it/s] 83%|████████▎ | 83/100 [01:16<00:15,  1.08it/s] 84%|████████▍ | 84/100 [01:17<00:14,  1.07it/s] 85%|████████▌ | 85/100 [01:18<00:13,  1.07it/s] 86%|████████▌ | 86/100 [01:19<00:13,  1.07it/s] 87%|████████▋ | 87/100 [01:20<00:12,  1.07it/s] 88%|████████▊ | 88/100 [01:21<00:11,  1.08it/s] 89%|████████▉ | 89/100 [01:22<00:10,  1.07it/s] 90%|█████████ | 90/100 [01:23<00:09,  1.07it/s] 91%|█████████ | 91/100 [01:24<00:08,  1.07it/s] 92%|█████████▏| 92/100 [01:25<00:07,  1.08it/s] 93%|█████████▎| 93/100 [01:26<00:06,  1.08it/s] 94%|█████████▍| 94/100 [01:27<00:05,  1.08it/s] 95%|█████████▌| 95/100 [01:27<00:04,  1.07it/s] 96%|█████████▌| 96/100 [01:28<00:03,  1.08it/s] 97%|█████████▋| 97/100 [01:29<00:02,  1.08it/s] 98%|█████████▊| 98/100 [01:30<00:01,  1.08it/s] 99%|█████████▉| 99/100 [01:31<00:00,  1.08it/s]100%|██████████| 100/100 [01:32<00:00,  1.07it/s]100%|██████████| 100/100 [01:32<00:00,  1.08it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:5'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:5'}
full model:
{'cola': {'alias': 'cola', 'mcc,none': np.float64(-0.0234083603222329), 'mcc_stderr,none': 0.10027612985654218}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9827615088085355
0.9302188892609604
0.7011961870018854
0.5626926521241726
0.8487059565524276
0.8497526414658526
0.9054485200458864
0.7394951536076
0.6615723249956142
0.3790091735780837
0.7669438266452424
0.6500882643740805
0.6039759750877352
0.8611545876684488
0.9595791152744535
0.7624866897939796
0.8585278638499474
0.9654871578633694
0.8537985077125277
0.9276026122967783
0.938072418626947
0.8815459403167786
0.6241194219560614
0.901256729143793
0.7007049393842223
0.6541093728101413
0.9141945519271818
0.7667764647672246
0.8091089193013563
Total groups 69 exceeded the threshold, stopping comparison.
The group tensor is
[3, 2, 6, 7, 5, 1, 4, 0]
tensor([3, 2, 6, 7, 5, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 3, 6, 7, 5, 1, 4, 0]
tensor([2, 3, 6, 7, 5, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 3, 5, 7, 6, 1, 2, 0]
tensor([4, 3, 5, 7, 6, 1, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[2, 3, 0, 1, 2, 1, 3, 0]
tensor([2, 3, 0, 1, 2, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[1, 0, 1, 2, 3, 2, 3, 0]
tensor([1, 0, 1, 2, 3, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 2, 1, 2, 3, 1, 3, 0]
tensor([0, 2, 1, 2, 3, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[1, 0, 0, 1, 2, 3, 3, 2]
tensor([1, 0, 0, 1, 2, 3, 3, 2], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[3, 1, 0, 1, 2, 2, 3, 0]
tensor([3, 1, 0, 1, 2, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1.0, 1.0, 1, 1.0, 0]
tensor([0, 1, 1, 1, 1, 1, 1, 0], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
done!
Cross-layer merge completed for layers 2 to 5
done!
Normal merging for layer 6
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
tensor([3])
tensor(3)
done!
Cross-layer merge completed for layers 7 to 18
done!
Normal merging for layer 19
tensor([2, 7])
tensor(2)
tensor([3, 5])
tensor(3)
tensor([0, 4])
tensor(0)
tensor([1, 6])
tensor(1)
done!
Normal merging for layer 20
tensor([1, 7])
tensor(1)
tensor([0, 2])
tensor(0)
tensor([3, 5])
tensor(3)
tensor([4, 6])
tensor(4)
done!
Normal merging for layer 21
tensor([0, 7])
tensor(0)
tensor([2, 5])
tensor(2)
tensor([1, 3])
tensor(1)
tensor([4, 6])
tensor(4)
done!
Normal merging for layer 22
tensor([1, 2])
tensor(1)
tensor([0, 3])
tensor(0)
tensor([4, 7])
tensor(4)
tensor([5, 6])
tensor(5)
done!
Normal merging for layer 23
tensor([2, 7])
tensor(2)
tensor([1, 3])
tensor(1)
tensor([4, 5])
tensor(4)
tensor([0, 6])
tensor(0)
done!
Cross-layer merge completed for layers 24 to 27
done!
Normal merging for layer 28
tensor([0, 7])
tensor(0)
tensor([1, 2, 3, 4, 5, 6])
tensor(1)
done!
Cross-layer merge completed for layers 29 to 31
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 12 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.1348 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 11 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

101
cuda:5
qnli
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:57<00:57, 57.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:13<00:00, 32.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:13<00:00, 36.60s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: qnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: qnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/qnli?recursive=False&expand=False HTTP/1.1" 307 141
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/qnli?recursive=False&expand=False HTTP/1.1" 200 361
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139706898763552 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_qnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139706898763552 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_qnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/qnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139706898763552 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_qnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139706898763552 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_qnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139683749084672 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/qnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139683749084672 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/qnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/qnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139683749084672 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/qnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139683749084672 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/qnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of qnli from None to 0
INFO:lm_eval.api.task:Building contexts for qnli on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 2555.40it/s]
DEBUG:lm_eval.evaluator:Task: qnli; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:02<07:24,  2.23s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:03<03:11,  1.03it/s]Running loglikelihood requests:   2%|▎         | 5/200 [00:04<02:21,  1.38it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:05<02:01,  1.59it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:06<01:48,  1.76it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:07<01:39,  1.89it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:07<01:32,  2.02it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:08<01:27,  2.10it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:09<01:22,  2.21it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:10<01:18,  2.31it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:11<01:15,  2.37it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:12<01:12,  2.43it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:12<01:10,  2.47it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:13<01:09,  2.50it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:14<01:07,  2.53it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:15<01:06,  2.55it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:15<01:04,  2.57it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:16<01:03,  2.59it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:17<01:02,  2.60it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:18<01:01,  2.60it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:18<01:00,  2.61it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:19<00:59,  2.62it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:20<00:58,  2.64it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:21<00:57,  2.66it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:21<00:56,  2.69it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:22<00:55,  2.70it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:23<00:54,  2.71it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:24<00:53,  2.71it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:24<00:52,  2.72it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:25<00:51,  2.73it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:26<00:50,  2.74it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:26<00:50,  2.74it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:27<00:49,  2.75it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:28<00:47,  2.78it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:29<00:46,  2.80it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:29<00:45,  2.82it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:30<00:44,  2.84it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:31<00:43,  2.86it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:31<00:42,  2.89it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:32<00:41,  2.91it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:33<00:40,  2.92it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:33<00:39,  2.94it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:34<00:38,  2.95it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:35<00:38,  2.97it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:35<00:37,  2.97it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:36<00:36,  2.98it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:37<00:35,  2.99it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:37<00:35,  2.99it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:38<00:34,  2.98it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:39<00:33,  3.00it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:39<00:32,  3.02it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:40<00:31,  3.04it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:41<00:31,  3.05it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:41<00:30,  3.06it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:42<00:29,  3.06it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:43<00:29,  3.06it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:43<00:28,  3.07it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:44<00:27,  3.07it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:45<00:26,  3.08it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:45<00:26,  3.10it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:46<00:25,  3.12it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:46<00:24,  3.13it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:47<00:23,  3.17it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [00:48<00:22,  3.19it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [00:48<00:22,  3.21it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [00:49<00:21,  3.22it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [00:50<00:20,  3.23it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [00:50<00:20,  3.25it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [00:51<00:19,  3.26it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [00:51<00:18,  3.27it/s]Running loglikelihood requests:  70%|███████   | 141/200 [00:52<00:17,  3.29it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [00:53<00:17,  3.31it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [00:53<00:16,  3.32it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [00:54<00:15,  3.33it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [00:54<00:15,  3.33it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [00:55<00:14,  3.34it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [00:56<00:14,  3.34it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [00:56<00:13,  3.34it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [00:57<00:12,  3.35it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [00:57<00:12,  3.36it/s]Running loglikelihood requests:  80%|████████  | 161/200 [00:58<00:11,  3.37it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [00:59<00:10,  3.37it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [00:59<00:10,  3.39it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [01:00<00:09,  3.41it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [01:00<00:09,  3.42it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [01:01<00:08,  3.46it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [01:01<00:07,  3.48it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [01:02<00:07,  3.50it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [01:03<00:06,  3.51it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [01:03<00:05,  3.53it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [01:04<00:05,  3.54it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [01:04<00:04,  3.55it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [01:05<00:04,  3.53it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [01:05<00:03,  3.58it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [01:06<00:03,  3.62it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [01:06<00:02,  3.66it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [01:07<00:01,  3.69it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:07<00:01,  3.73it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:08<00:00,  3.77it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:08<00:00,  3.80it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:08<00:00,  2.90it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:6'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:6'}
full model:
{'qnli': {'alias': 'qnli', 'acc,none': 0.46, 'acc_stderr,none': 0.05009082659620332}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9846426504484882
0.5824664507839472
0.519615692575773
0.501155542927289
0.7945367166753022
0.308422053695068
0.8640142063914085
0.9138139850456612
0.4633856064809356
0.6590614315196575
0.6979080802987999
0.7199917897264415
0.7749024201981475
0.6702564595367945
0.48800861061165646
0.4420522818267443
0.9519161971847797
0.7484302940574024
0.5133259423607681
0.5588784666822361
0.6658633104669237
0.7569182042181317
0.5308683195195316
0.8457203515884096
0.2160432078364904
0.9025653665852331
0.9196489243365332
0.6742217686289
0.8668007010904994
0.9846426504484882
0.5824664507839472
0.519615692575773
0.501155542927289
0.7945367166753022
0.308422053695068
0.8640142063914085
0.9138139850456612
0.4633856064809356
0.6590614315196575
0.6979080802987999
0.7199917897264415
0.7749024201981475
0.6702564595367945
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[7, 5, 4, 2, 6, 1, 3, 0]
tensor([7, 5, 4, 2, 6, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 5, 1, 3, 6, 2, 7, 0]
tensor([4, 5, 1, 3, 6, 2, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 3, 4, 1, 2, 5, 0]
tensor([0, 1, 3, 4, 1, 2, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 1, 5, 2, 4, 1, 3, 0]
tensor([0, 1, 5, 2, 4, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 4, 1, 2, 1, 3, 5, 0]
tensor([0, 4, 1, 2, 1, 3, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[2, 4, 3, 0, 5, 1, 1, 0]
tensor([2, 4, 3, 0, 5, 1, 1, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 3, 4, 2, 1, 1, 5, 0]
tensor([0, 3, 4, 2, 1, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 2, 1, 3, 2, 0, 3, 1]
tensor([0, 2, 1, 3, 2, 0, 3, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([2])
tensor(2)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([0])
tensor(0)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 2 to 8
done!
Normal merging for layer 9
tensor([0, 7])
tensor(0)
tensor([1, 4])
tensor(1)
tensor([5])
tensor(5)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
done!
Normal merging for layer 10
tensor([0, 7])
tensor(0)
tensor([1, 5])
tensor(1)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
done!
Normal merging for layer 11
tensor([0, 7])
tensor(0)
tensor([2, 4])
tensor(2)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
done!
Normal merging for layer 12
tensor([3, 7])
tensor(3)
tensor([5, 6])
tensor(5)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
done!
Normal merging for layer 13
tensor([0, 7])
tensor(0)
tensor([4, 5])
tensor(4)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 14 to 15
done!
Normal merging for layer 16
tensor([0, 5])
tensor(0)
tensor([2, 7])
tensor(2)
tensor([1, 4])
tensor(1)
tensor([3, 6])
tensor(3)
done!
Cross-layer merge completed for layers 17 to 31
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 11 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.3238 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 10 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

30
cuda:6
openbookqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:56<00:56, 56.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 34.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 38.16s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/openbookqa HTTP/1.1" 307 67
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/openbookqa HTTP/1.1" 200 1409
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/openbookqa/openbookqa.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/openbookqa HTTP/1.1" 307 67
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/openbookqa HTTP/1.1" 200 1409
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/openbookqa/resolve/388097ea7776314e93a529163e0fea805b8a6454/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/allenai/openbookqa/resolve/388097ea7776314e93a529163e0fea805b8a6454/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 119
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 241
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 119
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 241
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 119
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 241
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 119
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 241
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 119
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 241
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 119
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 241
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/openbookqa/resolve/388097ea7776314e93a529163e0fea805b8a6454/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/allenai/openbookqa/resolve/388097ea7776314e93a529163e0fea805b8a6454/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 119
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 119
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 119
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 119
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 119
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 119
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 235
DEBUG:filelock:Attempting to acquire lock 139705825469280 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_openbookqa_main_0.0.0_388097ea7776314e93a529163e0fea805b8a6454.lock
DEBUG:filelock:Lock 139705825469280 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_openbookqa_main_0.0.0_388097ea7776314e93a529163e0fea805b8a6454.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/openbookqa/main/0.0.0/388097ea7776314e93a529163e0fea805b8a6454/dataset_info.json
DEBUG:filelock:Attempting to release lock 139705825469280 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_openbookqa_main_0.0.0_388097ea7776314e93a529163e0fea805b8a6454.lock
DEBUG:filelock:Lock 139705825469280 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_openbookqa_main_0.0.0_388097ea7776314e93a529163e0fea805b8a6454.lock
DEBUG:filelock:Attempting to acquire lock 139705422004192 on /public/home/zouyifei001/.cache/huggingface/datasets/openbookqa/main/0.0.0/388097ea7776314e93a529163e0fea805b8a6454_builder.lock
DEBUG:filelock:Lock 139705422004192 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/openbookqa/main/0.0.0/388097ea7776314e93a529163e0fea805b8a6454_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/openbookqa/main/0.0.0/388097ea7776314e93a529163e0fea805b8a6454/dataset_info.json
DEBUG:filelock:Attempting to release lock 139705422004192 on /public/home/zouyifei001/.cache/huggingface/datasets/openbookqa/main/0.0.0/388097ea7776314e93a529163e0fea805b8a6454_builder.lock
DEBUG:filelock:Lock 139705422004192 released on /public/home/zouyifei001/.cache/huggingface/datasets/openbookqa/main/0.0.0/388097ea7776314e93a529163e0fea805b8a6454_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of openbookqa from None to 0
INFO:lm_eval.api.task:Building contexts for openbookqa on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 2813.65it/s]
DEBUG:lm_eval.evaluator:Task: openbookqa; number of requests on this rank: 400
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/400 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/400 [00:01<10:02,  1.51s/it]Running loglikelihood requests:   0%|          | 2/400 [00:02<06:57,  1.05s/it]Running loglikelihood requests:   1%|          | 3/400 [00:02<05:51,  1.13it/s]Running loglikelihood requests:   1%|          | 4/400 [00:03<05:18,  1.24it/s]Running loglikelihood requests:   1%|▏         | 5/400 [00:04<04:42,  1.40it/s]Running loglikelihood requests:   2%|▏         | 6/400 [00:04<04:20,  1.51it/s]Running loglikelihood requests:   2%|▏         | 7/400 [00:05<04:07,  1.59it/s]Running loglikelihood requests:   2%|▏         | 8/400 [00:05<03:56,  1.66it/s]Running loglikelihood requests:   2%|▏         | 9/400 [00:06<03:47,  1.72it/s]Running loglikelihood requests:   2%|▎         | 10/400 [00:06<03:41,  1.76it/s]Running loglikelihood requests:   3%|▎         | 11/400 [00:07<03:40,  1.76it/s]Running loglikelihood requests:   3%|▎         | 12/400 [00:08<03:36,  1.79it/s]Running loglikelihood requests:   3%|▎         | 13/400 [00:08<03:32,  1.82it/s]Running loglikelihood requests:   4%|▍         | 15/400 [00:09<02:40,  2.39it/s]Running loglikelihood requests:   4%|▍         | 16/400 [00:09<02:51,  2.24it/s]Running loglikelihood requests:   4%|▍         | 17/400 [00:10<02:59,  2.14it/s]Running loglikelihood requests:   4%|▍         | 18/400 [00:10<03:04,  2.07it/s]Running loglikelihood requests:   5%|▍         | 19/400 [00:11<03:08,  2.02it/s]Running loglikelihood requests:   5%|▌         | 20/400 [00:11<03:10,  2.00it/s]Running loglikelihood requests:   5%|▌         | 21/400 [00:12<03:12,  1.97it/s]Running loglikelihood requests:   6%|▌         | 22/400 [00:12<03:12,  1.97it/s]Running loglikelihood requests:   6%|▌         | 23/400 [00:13<03:11,  1.97it/s]Running loglikelihood requests:   6%|▌         | 24/400 [00:13<03:10,  1.97it/s]Running loglikelihood requests:   6%|▋         | 25/400 [00:14<03:09,  1.97it/s]Running loglikelihood requests:   6%|▋         | 26/400 [00:14<03:08,  1.98it/s]Running loglikelihood requests:   7%|▋         | 27/400 [00:15<03:07,  1.99it/s]Running loglikelihood requests:   7%|▋         | 28/400 [00:15<03:05,  2.00it/s]Running loglikelihood requests:   7%|▋         | 29/400 [00:16<03:03,  2.02it/s]Running loglikelihood requests:   8%|▊         | 33/400 [00:16<01:34,  3.87it/s]Running loglikelihood requests:   8%|▊         | 34/400 [00:17<01:48,  3.36it/s]Running loglikelihood requests:   9%|▉         | 35/400 [00:17<02:01,  3.00it/s]Running loglikelihood requests:   9%|▉         | 36/400 [00:18<02:12,  2.75it/s]Running loglikelihood requests:   9%|▉         | 37/400 [00:18<02:21,  2.57it/s]Running loglikelihood requests:  10%|▉         | 38/400 [00:19<02:27,  2.45it/s]Running loglikelihood requests:  10%|▉         | 39/400 [00:19<02:33,  2.36it/s]Running loglikelihood requests:  10%|█         | 40/400 [00:19<02:36,  2.30it/s]Running loglikelihood requests:  10%|█         | 41/400 [00:20<02:37,  2.27it/s]Running loglikelihood requests:  10%|█         | 42/400 [00:20<02:38,  2.25it/s]Running loglikelihood requests:  11%|█         | 43/400 [00:21<02:39,  2.24it/s]Running loglikelihood requests:  11%|█         | 44/400 [00:21<02:39,  2.23it/s]Running loglikelihood requests:  11%|█▏        | 45/400 [00:22<02:39,  2.22it/s]Running loglikelihood requests:  12%|█▏        | 46/400 [00:22<02:39,  2.22it/s]Running loglikelihood requests:  12%|█▏        | 47/400 [00:23<02:38,  2.22it/s]Running loglikelihood requests:  12%|█▏        | 48/400 [00:23<02:38,  2.22it/s]Running loglikelihood requests:  12%|█▏        | 49/400 [00:24<02:37,  2.22it/s]Running loglikelihood requests:  12%|█▎        | 50/400 [00:24<02:37,  2.22it/s]Running loglikelihood requests:  13%|█▎        | 51/400 [00:24<02:37,  2.22it/s]Running loglikelihood requests:  13%|█▎        | 52/400 [00:25<02:37,  2.21it/s]Running loglikelihood requests:  13%|█▎        | 53/400 [00:25<02:36,  2.22it/s]Running loglikelihood requests:  14%|█▎        | 54/400 [00:26<02:35,  2.22it/s]Running loglikelihood requests:  14%|█▍        | 55/400 [00:26<02:35,  2.22it/s]Running loglikelihood requests:  14%|█▍        | 57/400 [00:27<01:58,  2.89it/s]Running loglikelihood requests:  15%|█▌        | 60/400 [00:27<01:24,  4.03it/s]Running loglikelihood requests:  15%|█▌        | 61/400 [00:28<01:37,  3.49it/s]Running loglikelihood requests:  16%|█▌        | 62/400 [00:28<01:48,  3.12it/s]Running loglikelihood requests:  16%|█▌        | 63/400 [00:28<01:57,  2.86it/s]Running loglikelihood requests:  16%|█▌        | 64/400 [00:29<02:05,  2.68it/s]Running loglikelihood requests:  16%|█▋        | 65/400 [00:29<02:11,  2.54it/s]Running loglikelihood requests:  16%|█▋        | 66/400 [00:30<02:16,  2.45it/s]Running loglikelihood requests:  17%|█▋        | 67/400 [00:30<02:19,  2.39it/s]Running loglikelihood requests:  17%|█▋        | 68/400 [00:31<02:21,  2.35it/s]Running loglikelihood requests:  17%|█▋        | 69/400 [00:31<02:22,  2.32it/s]Running loglikelihood requests:  18%|█▊        | 70/400 [00:32<02:22,  2.31it/s]Running loglikelihood requests:  18%|█▊        | 71/400 [00:32<02:23,  2.30it/s]Running loglikelihood requests:  18%|█▊        | 72/400 [00:32<02:23,  2.29it/s]Running loglikelihood requests:  18%|█▊        | 73/400 [00:33<02:23,  2.28it/s]Running loglikelihood requests:  18%|█▊        | 74/400 [00:33<02:23,  2.28it/s]Running loglikelihood requests:  19%|█▉        | 75/400 [00:34<02:23,  2.27it/s]Running loglikelihood requests:  19%|█▉        | 76/400 [00:34<02:23,  2.26it/s]Running loglikelihood requests:  19%|█▉        | 77/400 [00:35<02:23,  2.26it/s]Running loglikelihood requests:  20%|█▉        | 78/400 [00:35<02:22,  2.26it/s]Running loglikelihood requests:  20%|█▉        | 79/400 [00:36<02:21,  2.27it/s]Running loglikelihood requests:  20%|██        | 81/400 [00:36<01:49,  2.91it/s]Running loglikelihood requests:  20%|██        | 82/400 [00:36<01:56,  2.73it/s]Running loglikelihood requests:  21%|██        | 83/400 [00:37<02:01,  2.61it/s]Running loglikelihood requests:  21%|██        | 84/400 [00:37<02:05,  2.52it/s]Running loglikelihood requests:  22%|██▏       | 86/400 [00:38<01:40,  3.12it/s]Running loglikelihood requests:  22%|██▏       | 87/400 [00:38<01:58,  2.65it/s]Running loglikelihood requests:  22%|██▏       | 88/400 [00:39<02:02,  2.55it/s]Running loglikelihood requests:  22%|██▏       | 89/400 [00:39<02:05,  2.49it/s]Running loglikelihood requests:  22%|██▎       | 90/400 [00:40<02:06,  2.45it/s]Running loglikelihood requests:  23%|██▎       | 91/400 [00:40<02:08,  2.41it/s]Running loglikelihood requests:  23%|██▎       | 92/400 [00:40<02:09,  2.38it/s]Running loglikelihood requests:  23%|██▎       | 93/400 [00:41<02:09,  2.37it/s]Running loglikelihood requests:  24%|██▎       | 94/400 [00:41<02:09,  2.36it/s]Running loglikelihood requests:  24%|██▍       | 95/400 [00:42<02:10,  2.35it/s]Running loglikelihood requests:  24%|██▍       | 96/400 [00:42<02:10,  2.34it/s]Running loglikelihood requests:  24%|██▍       | 97/400 [00:43<02:09,  2.33it/s]Running loglikelihood requests:  24%|██▍       | 98/400 [00:43<02:09,  2.33it/s]Running loglikelihood requests:  25%|██▍       | 99/400 [00:43<02:09,  2.33it/s]Running loglikelihood requests:  25%|██▌       | 100/400 [00:44<02:09,  2.32it/s]Running loglikelihood requests:  25%|██▌       | 101/400 [00:44<02:08,  2.33it/s]Running loglikelihood requests:  26%|██▌       | 102/400 [00:45<02:07,  2.33it/s]Running loglikelihood requests:  26%|██▌       | 103/400 [00:45<02:06,  2.34it/s]Running loglikelihood requests:  26%|██▋       | 106/400 [00:46<01:18,  3.76it/s]Running loglikelihood requests:  27%|██▋       | 107/400 [00:46<01:27,  3.33it/s]Running loglikelihood requests:  27%|██▋       | 108/400 [00:46<01:36,  3.04it/s]Running loglikelihood requests:  27%|██▋       | 109/400 [00:47<01:42,  2.83it/s]Running loglikelihood requests:  28%|██▊       | 110/400 [00:47<01:48,  2.68it/s]Running loglikelihood requests:  28%|██▊       | 111/400 [00:48<01:51,  2.58it/s]Running loglikelihood requests:  28%|██▊       | 112/400 [00:48<01:54,  2.51it/s]Running loglikelihood requests:  28%|██▊       | 113/400 [00:49<01:56,  2.46it/s]Running loglikelihood requests:  28%|██▊       | 114/400 [00:49<01:58,  2.42it/s]Running loglikelihood requests:  29%|██▉       | 115/400 [00:49<01:58,  2.41it/s]Running loglikelihood requests:  29%|██▉       | 116/400 [00:50<01:58,  2.40it/s]Running loglikelihood requests:  29%|██▉       | 117/400 [00:50<01:58,  2.40it/s]Running loglikelihood requests:  30%|██▉       | 118/400 [00:51<01:57,  2.39it/s]Running loglikelihood requests:  30%|██▉       | 119/400 [00:51<01:58,  2.38it/s]Running loglikelihood requests:  30%|███       | 120/400 [00:52<01:58,  2.37it/s]Running loglikelihood requests:  30%|███       | 121/400 [00:52<01:57,  2.37it/s]Running loglikelihood requests:  30%|███       | 122/400 [00:52<01:57,  2.37it/s]Running loglikelihood requests:  31%|███       | 123/400 [00:53<01:56,  2.37it/s]Running loglikelihood requests:  31%|███       | 124/400 [00:53<01:56,  2.37it/s]Running loglikelihood requests:  31%|███▏      | 125/400 [00:54<01:56,  2.36it/s]Running loglikelihood requests:  32%|███▏      | 126/400 [00:54<01:56,  2.35it/s]Running loglikelihood requests:  32%|███▏      | 127/400 [00:55<01:55,  2.36it/s]Running loglikelihood requests:  32%|███▏      | 128/400 [00:55<01:55,  2.35it/s]Running loglikelihood requests:  32%|███▏      | 129/400 [00:55<01:55,  2.35it/s]Running loglikelihood requests:  32%|███▎      | 130/400 [00:56<01:54,  2.36it/s]Running loglikelihood requests:  33%|███▎      | 131/400 [00:56<01:53,  2.37it/s]Running loglikelihood requests:  33%|███▎      | 132/400 [00:57<01:52,  2.38it/s]Running loglikelihood requests:  33%|███▎      | 133/400 [00:57<01:52,  2.38it/s]Running loglikelihood requests:  34%|███▎      | 134/400 [00:57<01:51,  2.38it/s]Running loglikelihood requests:  34%|███▍      | 138/400 [00:58<00:57,  4.52it/s]Running loglikelihood requests:  35%|███▍      | 139/400 [00:58<01:07,  3.88it/s]Running loglikelihood requests:  35%|███▌      | 140/400 [00:59<01:15,  3.42it/s]Running loglikelihood requests:  35%|███▌      | 141/400 [00:59<01:23,  3.11it/s]Running loglikelihood requests:  36%|███▌      | 142/400 [01:00<01:29,  2.89it/s]Running loglikelihood requests:  36%|███▌      | 143/400 [01:00<01:33,  2.74it/s]Running loglikelihood requests:  36%|███▌      | 144/400 [01:00<01:36,  2.64it/s]Running loglikelihood requests:  36%|███▋      | 145/400 [01:01<01:39,  2.56it/s]Running loglikelihood requests:  37%|███▋      | 147/400 [01:01<01:18,  3.22it/s]Running loglikelihood requests:  37%|███▋      | 148/400 [01:02<01:24,  2.99it/s]Running loglikelihood requests:  37%|███▋      | 149/400 [01:02<01:29,  2.82it/s]Running loglikelihood requests:  38%|███▊      | 151/400 [01:02<01:12,  3.42it/s]Running loglikelihood requests:  38%|███▊      | 152/400 [01:03<01:19,  3.12it/s]Running loglikelihood requests:  38%|███▊      | 153/400 [01:03<01:24,  2.91it/s]Running loglikelihood requests:  38%|███▊      | 154/400 [01:04<01:28,  2.77it/s]Running loglikelihood requests:  39%|███▉      | 155/400 [01:04<01:31,  2.67it/s]Running loglikelihood requests:  39%|███▉      | 156/400 [01:05<01:33,  2.60it/s]Running loglikelihood requests:  39%|███▉      | 157/400 [01:05<01:35,  2.55it/s]Running loglikelihood requests:  40%|███▉      | 158/400 [01:05<01:36,  2.51it/s]Running loglikelihood requests:  40%|███▉      | 159/400 [01:06<01:36,  2.49it/s]Running loglikelihood requests:  40%|████      | 160/400 [01:06<01:37,  2.47it/s]Running loglikelihood requests:  40%|████      | 161/400 [01:07<01:37,  2.46it/s]Running loglikelihood requests:  40%|████      | 162/400 [01:07<01:37,  2.45it/s]Running loglikelihood requests:  41%|████      | 163/400 [01:07<01:36,  2.45it/s]Running loglikelihood requests:  42%|████▏     | 166/400 [01:08<00:59,  3.92it/s]Running loglikelihood requests:  42%|████▏     | 167/400 [01:08<01:06,  3.48it/s]Running loglikelihood requests:  43%|████▎     | 171/400 [01:09<00:42,  5.37it/s]Running loglikelihood requests:  43%|████▎     | 172/400 [01:09<00:50,  4.51it/s]Running loglikelihood requests:  43%|████▎     | 173/400 [01:09<00:58,  3.88it/s]Running loglikelihood requests:  44%|████▎     | 174/400 [01:10<01:05,  3.45it/s]Running loglikelihood requests:  44%|████▍     | 175/400 [01:10<01:11,  3.15it/s]Running loglikelihood requests:  44%|████▍     | 176/400 [01:11<01:15,  2.95it/s]Running loglikelihood requests:  44%|████▍     | 177/400 [01:11<01:19,  2.80it/s]Running loglikelihood requests:  44%|████▍     | 178/400 [01:12<01:21,  2.71it/s]Running loglikelihood requests:  45%|████▍     | 179/400 [01:12<01:26,  2.56it/s]Running loglikelihood requests:  45%|████▌     | 180/400 [01:12<01:28,  2.50it/s]Running loglikelihood requests:  45%|████▌     | 181/400 [01:13<01:28,  2.48it/s]Running loglikelihood requests:  46%|████▌     | 182/400 [01:13<01:28,  2.47it/s]Running loglikelihood requests:  46%|████▌     | 183/400 [01:14<01:28,  2.46it/s]Running loglikelihood requests:  46%|████▌     | 184/400 [01:14<01:27,  2.47it/s]Running loglikelihood requests:  46%|████▋     | 185/400 [01:14<01:26,  2.47it/s]Running loglikelihood requests:  46%|████▋     | 186/400 [01:15<01:26,  2.47it/s]Running loglikelihood requests:  47%|████▋     | 187/400 [01:15<01:26,  2.48it/s]Running loglikelihood requests:  47%|████▋     | 188/400 [01:16<01:25,  2.48it/s]Running loglikelihood requests:  48%|████▊     | 190/400 [01:16<01:05,  3.23it/s]Running loglikelihood requests:  48%|████▊     | 192/400 [01:16<00:55,  3.75it/s]Running loglikelihood requests:  48%|████▊     | 193/400 [01:17<01:01,  3.37it/s]Running loglikelihood requests:  48%|████▊     | 194/400 [01:17<01:06,  3.10it/s]Running loglikelihood requests:  49%|████▉     | 195/400 [01:18<01:10,  2.92it/s]Running loglikelihood requests:  49%|████▉     | 196/400 [01:18<01:13,  2.79it/s]Running loglikelihood requests:  49%|████▉     | 197/400 [01:18<01:15,  2.69it/s]Running loglikelihood requests:  50%|████▉     | 198/400 [01:19<01:16,  2.63it/s]Running loglikelihood requests:  50%|█████     | 202/400 [01:19<00:40,  4.84it/s]Running loglikelihood requests:  51%|█████     | 203/400 [01:20<00:47,  4.15it/s]Running loglikelihood requests:  51%|█████     | 204/400 [01:20<00:53,  3.69it/s]Running loglikelihood requests:  51%|█████▏    | 205/400 [01:20<00:58,  3.36it/s]Running loglikelihood requests:  52%|█████▏    | 206/400 [01:21<01:02,  3.11it/s]Running loglikelihood requests:  52%|█████▏    | 207/400 [01:21<01:07,  2.86it/s]Running loglikelihood requests:  52%|█████▏    | 209/400 [01:22<00:54,  3.52it/s]Running loglikelihood requests:  52%|█████▎    | 210/400 [01:22<00:58,  3.22it/s]Running loglikelihood requests:  53%|█████▎    | 211/400 [01:22<01:02,  3.00it/s]Running loglikelihood requests:  53%|█████▎    | 212/400 [01:23<01:06,  2.83it/s]Running loglikelihood requests:  53%|█████▎    | 213/400 [01:23<01:08,  2.72it/s]Running loglikelihood requests:  54%|█████▎    | 214/400 [01:24<01:10,  2.64it/s]Running loglikelihood requests:  54%|█████▍    | 215/400 [01:24<01:11,  2.59it/s]Running loglikelihood requests:  54%|█████▍    | 216/400 [01:24<01:11,  2.57it/s]Running loglikelihood requests:  54%|█████▍    | 217/400 [01:25<01:11,  2.56it/s]Running loglikelihood requests:  55%|█████▍    | 218/400 [01:25<01:18,  2.33it/s]Running loglikelihood requests:  55%|█████▍    | 219/400 [01:26<01:15,  2.38it/s]Running loglikelihood requests:  55%|█████▌    | 220/400 [01:26<01:14,  2.41it/s]Running loglikelihood requests:  55%|█████▌    | 221/400 [01:27<01:13,  2.45it/s]Running loglikelihood requests:  56%|█████▌    | 222/400 [01:27<01:11,  2.48it/s]Running loglikelihood requests:  56%|█████▌    | 223/400 [01:27<01:10,  2.50it/s]Running loglikelihood requests:  56%|█████▌    | 224/400 [01:28<01:09,  2.53it/s]Running loglikelihood requests:  56%|█████▋    | 225/400 [01:28<01:08,  2.54it/s]Running loglikelihood requests:  56%|█████▋    | 226/400 [01:28<01:08,  2.55it/s]Running loglikelihood requests:  57%|█████▋    | 227/400 [01:29<01:07,  2.55it/s]Running loglikelihood requests:  57%|█████▋    | 228/400 [01:29<01:07,  2.57it/s]Running loglikelihood requests:  57%|█████▋    | 229/400 [01:30<01:06,  2.58it/s]Running loglikelihood requests:  57%|█████▊    | 230/400 [01:30<01:07,  2.53it/s]Running loglikelihood requests:  58%|█████▊    | 231/400 [01:30<01:06,  2.53it/s]Running loglikelihood requests:  58%|█████▊    | 232/400 [01:31<01:05,  2.55it/s]Running loglikelihood requests:  58%|█████▊    | 233/400 [01:31<01:05,  2.56it/s]Running loglikelihood requests:  58%|█████▊    | 234/400 [01:32<01:04,  2.56it/s]Running loglikelihood requests:  59%|█████▉    | 235/400 [01:32<01:04,  2.57it/s]Running loglikelihood requests:  59%|█████▉    | 237/400 [01:32<00:48,  3.35it/s]Running loglikelihood requests:  60%|█████▉    | 239/400 [01:33<00:41,  3.91it/s]Running loglikelihood requests:  60%|██████    | 240/400 [01:33<00:45,  3.50it/s]Running loglikelihood requests:  60%|██████    | 241/400 [01:34<00:49,  3.23it/s]Running loglikelihood requests:  60%|██████    | 242/400 [01:34<00:52,  3.03it/s]Running loglikelihood requests:  61%|██████    | 243/400 [01:34<00:54,  2.90it/s]Running loglikelihood requests:  61%|██████    | 244/400 [01:35<00:55,  2.80it/s]Running loglikelihood requests:  61%|██████▏   | 245/400 [01:35<00:56,  2.73it/s]Running loglikelihood requests:  62%|██████▏   | 246/400 [01:36<00:57,  2.68it/s]Running loglikelihood requests:  62%|██████▏   | 247/400 [01:36<00:57,  2.64it/s]Running loglikelihood requests:  62%|██████▏   | 248/400 [01:36<00:58,  2.62it/s]Running loglikelihood requests:  62%|██████▏   | 249/400 [01:37<00:57,  2.61it/s]Running loglikelihood requests:  62%|██████▎   | 250/400 [01:37<00:57,  2.61it/s]Running loglikelihood requests:  63%|██████▎   | 251/400 [01:37<00:57,  2.59it/s]Running loglikelihood requests:  63%|██████▎   | 252/400 [01:38<00:57,  2.58it/s]Running loglikelihood requests:  63%|██████▎   | 253/400 [01:38<00:57,  2.58it/s]Running loglikelihood requests:  64%|██████▎   | 254/400 [01:39<00:56,  2.59it/s]Running loglikelihood requests:  64%|██████▍   | 255/400 [01:39<00:56,  2.59it/s]Running loglikelihood requests:  64%|██████▍   | 256/400 [01:39<00:58,  2.48it/s]Running loglikelihood requests:  64%|██████▍   | 257/400 [01:40<00:57,  2.50it/s]Running loglikelihood requests:  64%|██████▍   | 258/400 [01:40<00:56,  2.53it/s]Running loglikelihood requests:  65%|██████▍   | 259/400 [01:41<00:55,  2.55it/s]Running loglikelihood requests:  65%|██████▌   | 260/400 [01:41<00:54,  2.57it/s]Running loglikelihood requests:  65%|██████▌   | 261/400 [01:41<00:53,  2.58it/s]Running loglikelihood requests:  66%|██████▌   | 262/400 [01:42<00:53,  2.59it/s]Running loglikelihood requests:  66%|██████▌   | 263/400 [01:42<00:52,  2.62it/s]Running loglikelihood requests:  66%|██████▋   | 265/400 [01:42<00:39,  3.43it/s]Running loglikelihood requests:  66%|██████▋   | 266/400 [01:43<00:41,  3.20it/s]Running loglikelihood requests:  67%|██████▋   | 267/400 [01:43<00:43,  3.02it/s]Running loglikelihood requests:  67%|██████▋   | 268/400 [01:44<00:45,  2.91it/s]Running loglikelihood requests:  67%|██████▋   | 269/400 [01:44<00:46,  2.83it/s]Running loglikelihood requests:  68%|██████▊   | 270/400 [01:44<00:46,  2.81it/s]Running loglikelihood requests:  68%|██████▊   | 271/400 [01:45<00:46,  2.76it/s]Running loglikelihood requests:  68%|██████▊   | 272/400 [01:45<00:46,  2.73it/s]Running loglikelihood requests:  68%|██████▊   | 273/400 [01:45<00:46,  2.73it/s]Running loglikelihood requests:  68%|██████▊   | 274/400 [01:46<00:46,  2.69it/s]Running loglikelihood requests:  69%|██████▉   | 275/400 [01:46<00:47,  2.65it/s]Running loglikelihood requests:  69%|██████▉   | 276/400 [01:47<00:47,  2.63it/s]Running loglikelihood requests:  69%|██████▉   | 277/400 [01:47<00:46,  2.62it/s]Running loglikelihood requests:  70%|██████▉   | 278/400 [01:47<00:46,  2.62it/s]Running loglikelihood requests:  70%|██████▉   | 279/400 [01:48<00:46,  2.60it/s]Running loglikelihood requests:  70%|███████   | 280/400 [01:48<00:46,  2.59it/s]Running loglikelihood requests:  70%|███████   | 281/400 [01:49<00:45,  2.61it/s]Running loglikelihood requests:  70%|███████   | 282/400 [01:49<00:45,  2.61it/s]Running loglikelihood requests:  71%|███████   | 283/400 [01:49<00:44,  2.63it/s]Running loglikelihood requests:  71%|███████   | 284/400 [01:50<00:43,  2.64it/s]Running loglikelihood requests:  71%|███████▏  | 285/400 [01:50<00:43,  2.64it/s]Running loglikelihood requests:  72%|███████▏  | 286/400 [01:50<00:42,  2.65it/s]Running loglikelihood requests:  72%|███████▏  | 287/400 [01:51<00:42,  2.65it/s]Running loglikelihood requests:  72%|███████▏  | 288/400 [01:51<00:43,  2.60it/s]Running loglikelihood requests:  72%|███████▏  | 289/400 [01:52<00:42,  2.62it/s]Running loglikelihood requests:  72%|███████▎  | 290/400 [01:52<00:41,  2.66it/s]Running loglikelihood requests:  73%|███████▎  | 291/400 [01:52<00:40,  2.67it/s]Running loglikelihood requests:  73%|███████▎  | 292/400 [01:53<00:40,  2.67it/s]Running loglikelihood requests:  73%|███████▎  | 293/400 [01:53<00:40,  2.66it/s]Running loglikelihood requests:  74%|███████▎  | 294/400 [01:53<00:39,  2.66it/s]Running loglikelihood requests:  74%|███████▍  | 297/400 [01:54<00:23,  4.31it/s]Running loglikelihood requests:  74%|███████▍  | 298/400 [01:54<00:26,  3.78it/s]Running loglikelihood requests:  75%|███████▍  | 299/400 [01:55<00:29,  3.44it/s]Running loglikelihood requests:  75%|███████▌  | 300/400 [01:55<00:31,  3.20it/s]Running loglikelihood requests:  75%|███████▌  | 301/400 [01:55<00:32,  3.04it/s]Running loglikelihood requests:  76%|███████▌  | 302/400 [01:56<00:33,  2.92it/s]Running loglikelihood requests:  76%|███████▌  | 303/400 [01:56<00:34,  2.81it/s]Running loglikelihood requests:  77%|███████▋  | 307/400 [01:57<00:18,  5.13it/s]Running loglikelihood requests:  77%|███████▋  | 308/400 [01:57<00:20,  4.39it/s]Running loglikelihood requests:  77%|███████▋  | 309/400 [01:57<00:23,  3.89it/s]Running loglikelihood requests:  78%|███████▊  | 310/400 [01:58<00:25,  3.53it/s]Running loglikelihood requests:  78%|███████▊  | 311/400 [01:58<00:27,  3.28it/s]Running loglikelihood requests:  78%|███████▊  | 312/400 [01:58<00:28,  3.08it/s]Running loglikelihood requests:  78%|███████▊  | 313/400 [01:59<00:29,  2.94it/s]Running loglikelihood requests:  78%|███████▊  | 314/400 [01:59<00:30,  2.84it/s]Running loglikelihood requests:  79%|███████▉  | 315/400 [02:00<00:30,  2.79it/s]Running loglikelihood requests:  79%|███████▉  | 316/400 [02:00<00:30,  2.77it/s]Running loglikelihood requests:  79%|███████▉  | 317/400 [02:00<00:30,  2.76it/s]Running loglikelihood requests:  80%|███████▉  | 318/400 [02:01<00:30,  2.73it/s]Running loglikelihood requests:  80%|████████  | 321/400 [02:01<00:18,  4.35it/s]Running loglikelihood requests:  80%|████████  | 322/400 [02:01<00:20,  3.86it/s]Running loglikelihood requests:  81%|████████  | 323/400 [02:02<00:21,  3.53it/s]Running loglikelihood requests:  81%|████████  | 324/400 [02:02<00:22,  3.31it/s]Running loglikelihood requests:  81%|████████▏ | 325/400 [02:02<00:24,  3.12it/s]Running loglikelihood requests:  82%|████████▏ | 326/400 [02:03<00:24,  3.01it/s]Running loglikelihood requests:  82%|████████▏ | 327/400 [02:03<00:25,  2.92it/s]Running loglikelihood requests:  82%|████████▏ | 328/400 [02:04<00:25,  2.87it/s]Running loglikelihood requests:  82%|████████▏ | 329/400 [02:04<00:25,  2.82it/s]Running loglikelihood requests:  82%|████████▎ | 330/400 [02:04<00:25,  2.77it/s]Running loglikelihood requests:  83%|████████▎ | 331/400 [02:05<00:24,  2.78it/s]Running loglikelihood requests:  83%|████████▎ | 332/400 [02:05<00:24,  2.76it/s]Running loglikelihood requests:  83%|████████▎ | 333/400 [02:05<00:23,  2.81it/s]Running loglikelihood requests:  84%|████████▎ | 334/400 [02:06<00:23,  2.76it/s]Running loglikelihood requests:  84%|████████▍ | 336/400 [02:06<00:17,  3.59it/s]Running loglikelihood requests:  84%|████████▍ | 337/400 [02:06<00:18,  3.32it/s]Running loglikelihood requests:  84%|████████▍ | 338/400 [02:07<00:19,  3.16it/s]Running loglikelihood requests:  85%|████████▍ | 339/400 [02:07<00:20,  3.01it/s]Running loglikelihood requests:  85%|████████▌ | 340/400 [02:08<00:20,  2.92it/s]Running loglikelihood requests:  85%|████████▌ | 341/400 [02:08<00:20,  2.86it/s]Running loglikelihood requests:  86%|████████▌ | 342/400 [02:08<00:20,  2.81it/s]Running loglikelihood requests:  86%|████████▌ | 343/400 [02:09<00:20,  2.76it/s]Running loglikelihood requests:  86%|████████▌ | 344/400 [02:09<00:20,  2.75it/s]Running loglikelihood requests:  86%|████████▋ | 345/400 [02:09<00:19,  2.76it/s]Running loglikelihood requests:  86%|████████▋ | 346/400 [02:10<00:19,  2.84it/s]Running loglikelihood requests:  87%|████████▋ | 347/400 [02:10<00:19,  2.78it/s]Running loglikelihood requests:  87%|████████▋ | 348/400 [02:11<00:23,  2.19it/s]Running loglikelihood requests:  87%|████████▋ | 349/400 [02:11<00:21,  2.33it/s]Running loglikelihood requests:  88%|████████▊ | 350/400 [02:12<00:20,  2.44it/s]Running loglikelihood requests:  88%|████████▊ | 351/400 [02:12<00:19,  2.54it/s]Running loglikelihood requests:  88%|████████▊ | 352/400 [02:12<00:18,  2.66it/s]Running loglikelihood requests:  88%|████████▊ | 353/400 [02:13<00:17,  2.75it/s]Running loglikelihood requests:  88%|████████▊ | 354/400 [02:13<00:16,  2.76it/s]Running loglikelihood requests:  89%|████████▉ | 355/400 [02:13<00:16,  2.76it/s]Running loglikelihood requests:  89%|████████▉ | 356/400 [02:14<00:15,  2.82it/s]Running loglikelihood requests:  89%|████████▉ | 357/400 [02:14<00:15,  2.81it/s]Running loglikelihood requests:  90%|████████▉ | 358/400 [02:14<00:14,  2.82it/s]Running loglikelihood requests:  90%|████████▉ | 359/400 [02:15<00:14,  2.83it/s]Running loglikelihood requests:  90%|█████████ | 360/400 [02:15<00:13,  2.86it/s]Running loglikelihood requests:  91%|█████████ | 363/400 [02:15<00:08,  4.58it/s]Running loglikelihood requests:  91%|█████████ | 364/400 [02:16<00:08,  4.06it/s]Running loglikelihood requests:  91%|█████████▏| 365/400 [02:16<00:09,  3.73it/s]Running loglikelihood requests:  92%|█████████▏| 366/400 [02:16<00:09,  3.51it/s]Running loglikelihood requests:  92%|█████████▏| 367/400 [02:17<00:09,  3.36it/s]Running loglikelihood requests:  92%|█████████▏| 368/400 [02:17<00:09,  3.21it/s]Running loglikelihood requests:  92%|█████████▏| 369/400 [02:17<00:10,  3.10it/s]Running loglikelihood requests:  92%|█████████▎| 370/400 [02:18<00:09,  3.04it/s]Running loglikelihood requests:  93%|█████████▎| 371/400 [02:18<00:09,  3.03it/s]Running loglikelihood requests:  93%|█████████▎| 372/400 [02:18<00:09,  3.04it/s]Running loglikelihood requests:  93%|█████████▎| 373/400 [02:19<00:08,  3.03it/s]Running loglikelihood requests:  94%|█████████▎| 374/400 [02:19<00:08,  3.01it/s]Running loglikelihood requests:  94%|█████████▍| 377/400 [02:19<00:04,  4.87it/s]Running loglikelihood requests:  94%|█████████▍| 378/400 [02:20<00:05,  4.33it/s]Running loglikelihood requests:  95%|█████████▍| 379/400 [02:20<00:05,  3.93it/s]Running loglikelihood requests:  95%|█████████▌| 380/400 [02:20<00:05,  3.70it/s]Running loglikelihood requests:  95%|█████████▌| 381/400 [02:21<00:05,  3.54it/s]Running loglikelihood requests:  96%|█████████▌| 382/400 [02:21<00:05,  3.42it/s]Running loglikelihood requests:  96%|█████████▌| 383/400 [02:21<00:05,  3.31it/s]Running loglikelihood requests:  96%|█████████▌| 384/400 [02:22<00:04,  3.25it/s]Running loglikelihood requests:  97%|█████████▋| 387/400 [02:22<00:02,  5.06it/s]Running loglikelihood requests:  97%|█████████▋| 388/400 [02:22<00:02,  4.49it/s]Running loglikelihood requests:  98%|█████████▊| 390/400 [02:23<00:02,  4.94it/s]Running loglikelihood requests:  98%|█████████▊| 391/400 [02:23<00:02,  4.44it/s]Running loglikelihood requests:  98%|█████████▊| 392/400 [02:23<00:01,  4.09it/s]Running loglikelihood requests:  98%|█████████▊| 393/400 [02:24<00:01,  3.93it/s]Running loglikelihood requests:  98%|█████████▊| 394/400 [02:24<00:01,  3.68it/s]Running loglikelihood requests:  99%|█████████▉| 395/400 [02:24<00:01,  3.56it/s]Running loglikelihood requests:  99%|█████████▉| 396/400 [02:24<00:01,  3.51it/s]Running loglikelihood requests: 100%|█████████▉| 398/400 [02:25<00:00,  4.50it/s]Running loglikelihood requests: 100%|█████████▉| 399/400 [02:25<00:00,  4.41it/s]Running loglikelihood requests: 100%|██████████| 400/400 [02:25<00:00,  2.75it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:7'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:7'}
full model:
{'openbookqa': {'alias': 'openbookqa', 'acc,none': 0.25, 'acc_stderr,none': 0.04351941398892446, 'acc_norm,none': 0.39, 'acc_norm_stderr,none': 0.04902071300001973}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.7187319796021299
0.7542307644255121
0.9218102409329888
0.9507846064925026
0.9244473932111009
0.9697851265705995
0.9088369054586506
0.9555908644563589
0.6065244449438403
0.8380982140772407
0.9227293008726757
0.940339967265193
0.8763319017557598
0.8956221731459367
0.8537768995934096
0.9486125995141542
0.9673324054839537
0.9137514724447725
0.9379677722073356
0.9822722776537973
0.9198472199854921
0.886666948473494
0.9000260607563779
0.9759633945879138
0.9869744580755335
Total groups 76 exceeded the threshold, stopping comparison.
The group tensor is
[6, 2, 3, 1, 5, 4, 7, 0]
tensor([6, 2, 3, 1, 5, 4, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 2, 3, 1, 4, 5, 7, 0]
tensor([6, 2, 3, 1, 4, 5, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 2, 3, 1, 4, 5, 7, 0]
tensor([6, 2, 3, 1, 4, 5, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 5, 2, 4, 3, 7, 0]
tensor([6, 1, 5, 2, 4, 3, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 1, 3, 2, 5, 4, 6, 0]
tensor([7, 1, 3, 2, 5, 4, 6, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 2, 3, 1, 5, 4, 7, 0]
tensor([6, 2, 3, 1, 5, 4, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1, 1.0, 1.0, 1.0, 1.0, 0]
tensor([0, 1, 1, 1, 1, 1, 1, 0], dtype=torch.int32)
[0, 1]
The group tensor is
[0, 1, 1.0, 1, 1.0, 1.0, 1.0, 0]
tensor([0, 1, 1, 1, 1, 1, 1, 0], dtype=torch.int32)
[0, 1]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
done!
Normal merging for layer 2
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
done!
Normal merging for layer 4
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
done!
Normal merging for layer 5
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 6 to 29
done!
Normal merging for layer 30
tensor([0, 7])
tensor(0)
tensor([1, 2, 3, 4, 5, 6])
tensor(1)
done!
Normal merging for layer 31
tensor([0, 7])
tensor(0)
tensor([1, 2, 3, 4, 5, 6])
tensor(1)
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 10 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.3238 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 9 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

218
cuda:7
sciq
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:57<00:57, 57.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:15<00:00, 34.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:15<00:00, 37.79s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq HTTP/1.1" 200 1238
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/sciq/sciq.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq HTTP/1.1" 200 1238
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/allenai/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq/revision/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 111
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq/revision/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 1238
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/allenai/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:filelock:Attempting to acquire lock 139705827279312 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:filelock:Lock 139705827279312 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_info.json
DEBUG:filelock:Attempting to release lock 139705827279312 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:filelock:Lock 139705827279312 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:filelock:Attempting to acquire lock 139705425217776 on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:filelock:Lock 139705425217776 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_info.json
DEBUG:filelock:Attempting to release lock 139705425217776 on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:filelock:Lock 139705425217776 released on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of sciq from None to 0
INFO:lm_eval.api.task:Building contexts for sciq on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1022.61it/s]
DEBUG:lm_eval.evaluator:Task: sciq; number of requests on this rank: 400
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/400 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/400 [00:04<26:51,  4.04s/it]Running loglikelihood requests:   0%|          | 2/400 [00:07<24:26,  3.68s/it]Running loglikelihood requests:   1%|          | 3/400 [00:10<23:51,  3.61s/it]Running loglikelihood requests:   1%|          | 4/400 [00:14<23:11,  3.51s/it]Running loglikelihood requests:   1%|▏         | 5/400 [00:17<22:15,  3.38s/it]Running loglikelihood requests:   2%|▏         | 6/400 [00:20<21:30,  3.28s/it]Running loglikelihood requests:   2%|▏         | 7/400 [00:23<21:03,  3.22s/it]Running loglikelihood requests:   2%|▏         | 8/400 [00:26<20:47,  3.18s/it]Running loglikelihood requests:   2%|▏         | 9/400 [00:29<19:54,  3.05s/it]Running loglikelihood requests:   2%|▎         | 10/400 [00:32<19:16,  2.96s/it]Running loglikelihood requests:   3%|▎         | 11/400 [00:35<18:48,  2.90s/it]Running loglikelihood requests:   3%|▎         | 12/400 [00:37<18:28,  2.86s/it]Running loglikelihood requests:   3%|▎         | 13/400 [00:40<17:50,  2.77s/it]Running loglikelihood requests:   4%|▎         | 14/400 [00:42<17:24,  2.70s/it]Running loglikelihood requests:   4%|▍         | 15/400 [00:45<17:08,  2.67s/it]Running loglikelihood requests:   4%|▍         | 16/400 [00:48<16:49,  2.63s/it]Running loglikelihood requests:   4%|▍         | 17/400 [00:50<16:34,  2.60s/it]Running loglikelihood requests:   4%|▍         | 18/400 [00:53<16:56,  2.66s/it]Running loglikelihood requests:   5%|▍         | 19/400 [00:55<16:28,  2.60s/it]Running loglikelihood requests:   5%|▌         | 20/400 [00:58<16:36,  2.62s/it]Running loglikelihood requests:   5%|▌         | 21/400 [01:00<16:12,  2.57s/it]Running loglikelihood requests:   6%|▌         | 22/400 [01:03<16:04,  2.55s/it]Running loglikelihood requests:   6%|▌         | 23/400 [01:05<15:51,  2.52s/it]Running loglikelihood requests:   6%|▌         | 24/400 [01:08<15:46,  2.52s/it]Running loglikelihood requests:   6%|▋         | 25/400 [01:10<15:20,  2.45s/it]Running loglikelihood requests:   6%|▋         | 26/400 [01:13<14:58,  2.40s/it]Running loglikelihood requests:   7%|▋         | 27/400 [01:15<14:46,  2.38s/it]Running loglikelihood requests:   7%|▋         | 28/400 [01:17<14:36,  2.36s/it]Running loglikelihood requests:   7%|▋         | 29/400 [01:19<14:03,  2.27s/it]Running loglikelihood requests:   8%|▊         | 30/400 [01:22<14:32,  2.36s/it]Running loglikelihood requests:   8%|▊         | 31/400 [01:24<13:59,  2.28s/it]Running loglikelihood requests:   8%|▊         | 32/400 [01:26<13:38,  2.22s/it]Running loglikelihood requests:   8%|▊         | 33/400 [01:28<13:08,  2.15s/it]Running loglikelihood requests:   8%|▊         | 34/400 [01:30<12:54,  2.12s/it]Running loglikelihood requests:   9%|▉         | 35/400 [01:32<12:36,  2.07s/it]Running loglikelihood requests:   9%|▉         | 36/400 [01:34<12:19,  2.03s/it]Running loglikelihood requests:   9%|▉         | 37/400 [01:36<12:08,  2.01s/it]Running loglikelihood requests:  10%|▉         | 38/400 [01:38<12:02,  2.00s/it]Running loglikelihood requests:  10%|█         | 40/400 [01:40<09:09,  1.53s/it]Running loglikelihood requests:  10%|█         | 41/400 [01:42<09:38,  1.61s/it]Running loglikelihood requests:  10%|█         | 42/400 [01:43<09:57,  1.67s/it]Running loglikelihood requests:  11%|█         | 43/400 [01:45<10:09,  1.71s/it]Running loglikelihood requests:  11%|█         | 44/400 [01:47<10:16,  1.73s/it]Running loglikelihood requests:  11%|█▏        | 45/400 [01:49<10:15,  1.73s/it]Running loglikelihood requests:  12%|█▏        | 46/400 [01:51<10:10,  1.73s/it]Running loglikelihood requests:  12%|█▏        | 47/400 [01:52<10:09,  1.73s/it]Running loglikelihood requests:  12%|█▏        | 48/400 [01:54<10:13,  1.74s/it]Running loglikelihood requests:  12%|█▏        | 49/400 [01:56<10:12,  1.74s/it]Running loglikelihood requests:  12%|█▎        | 50/400 [01:58<10:22,  1.78s/it]Running loglikelihood requests:  13%|█▎        | 51/400 [01:59<10:22,  1.78s/it]Running loglikelihood requests:  13%|█▎        | 52/400 [02:01<10:19,  1.78s/it]Running loglikelihood requests:  13%|█▎        | 53/400 [02:03<10:01,  1.73s/it]Running loglikelihood requests:  14%|█▎        | 54/400 [02:04<09:43,  1.69s/it]Running loglikelihood requests:  14%|█▍        | 55/400 [02:06<09:37,  1.68s/it]Running loglikelihood requests:  14%|█▍        | 57/400 [02:08<07:14,  1.27s/it]Running loglikelihood requests:  14%|█▍        | 58/400 [02:09<07:41,  1.35s/it]Running loglikelihood requests:  15%|█▍        | 59/400 [02:11<08:03,  1.42s/it]Running loglikelihood requests:  16%|█▌        | 62/400 [02:12<05:18,  1.06it/s]Running loglikelihood requests:  16%|█▌        | 63/400 [02:14<05:56,  1.06s/it]Running loglikelihood requests:  16%|█▌        | 64/400 [02:15<06:27,  1.15s/it]Running loglikelihood requests:  16%|█▋        | 65/400 [02:17<06:53,  1.23s/it]Running loglikelihood requests:  16%|█▋        | 66/400 [02:19<07:45,  1.39s/it]Running loglikelihood requests:  17%|█▋        | 67/400 [02:20<07:52,  1.42s/it]Running loglikelihood requests:  17%|█▋        | 68/400 [02:22<08:00,  1.45s/it]Running loglikelihood requests:  17%|█▋        | 69/400 [02:23<08:25,  1.53s/it]Running loglikelihood requests:  18%|█▊        | 70/400 [02:25<08:12,  1.49s/it]Running loglikelihood requests:  18%|█▊        | 71/400 [02:27<08:31,  1.55s/it]Running loglikelihood requests:  18%|█▊        | 72/400 [02:28<08:15,  1.51s/it]Running loglikelihood requests:  18%|█▊        | 73/400 [02:30<08:31,  1.56s/it]Running loglikelihood requests:  18%|█▊        | 74/400 [02:31<08:17,  1.53s/it]Running loglikelihood requests:  19%|█▉        | 77/400 [02:33<04:59,  1.08it/s]Running loglikelihood requests:  20%|█▉        | 78/400 [02:34<05:31,  1.03s/it]Running loglikelihood requests:  20%|█▉        | 79/400 [02:35<05:53,  1.10s/it]Running loglikelihood requests:  20%|██        | 81/400 [02:37<04:53,  1.09it/s]Running loglikelihood requests:  20%|██        | 82/400 [02:38<05:23,  1.02s/it]Running loglikelihood requests:  21%|██        | 83/400 [02:39<05:43,  1.08s/it]Running loglikelihood requests:  21%|██        | 84/400 [02:41<06:02,  1.15s/it]Running loglikelihood requests:  21%|██▏       | 85/400 [02:42<06:13,  1.19s/it]Running loglikelihood requests:  22%|██▏       | 86/400 [02:43<06:13,  1.19s/it]Running loglikelihood requests:  22%|██▏       | 89/400 [02:44<04:03,  1.28it/s]Running loglikelihood requests:  22%|██▎       | 90/400 [02:46<04:28,  1.15it/s]Running loglikelihood requests:  23%|██▎       | 91/400 [02:47<05:08,  1.00it/s]Running loglikelihood requests:  23%|██▎       | 92/400 [02:48<05:32,  1.08s/it]Running loglikelihood requests:  23%|██▎       | 93/400 [02:50<05:48,  1.13s/it]Running loglikelihood requests:  24%|██▍       | 97/400 [02:51<03:14,  1.56it/s]Running loglikelihood requests:  24%|██▍       | 98/400 [02:52<03:42,  1.36it/s]Running loglikelihood requests:  25%|██▍       | 99/400 [02:53<04:08,  1.21it/s]Running loglikelihood requests:  25%|██▌       | 100/400 [02:54<04:35,  1.09it/s]Running loglikelihood requests:  25%|██▌       | 101/400 [02:56<04:59,  1.00s/it]Running loglikelihood requests:  26%|██▌       | 102/400 [02:57<05:25,  1.09s/it]Running loglikelihood requests:  26%|██▌       | 103/400 [02:58<05:36,  1.13s/it]Running loglikelihood requests:  26%|██▌       | 104/400 [03:00<05:46,  1.17s/it]Running loglikelihood requests:  26%|██▋       | 105/400 [03:01<05:48,  1.18s/it]Running loglikelihood requests:  26%|██▋       | 106/400 [03:02<06:04,  1.24s/it]Running loglikelihood requests:  27%|██▋       | 107/400 [03:03<05:54,  1.21s/it]Running loglikelihood requests:  27%|██▋       | 108/400 [03:05<05:58,  1.23s/it]Running loglikelihood requests:  27%|██▋       | 109/400 [03:06<06:32,  1.35s/it]Running loglikelihood requests:  28%|██▊       | 110/400 [03:07<06:14,  1.29s/it]Running loglikelihood requests:  28%|██▊       | 111/400 [03:09<06:13,  1.29s/it]Running loglikelihood requests:  28%|██▊       | 112/400 [03:10<05:59,  1.25s/it]Running loglikelihood requests:  28%|██▊       | 113/400 [03:11<05:59,  1.25s/it]Running loglikelihood requests:  28%|██▊       | 114/400 [03:12<05:56,  1.25s/it]Running loglikelihood requests:  29%|██▉       | 115/400 [03:13<05:50,  1.23s/it]Running loglikelihood requests:  29%|██▉       | 116/400 [03:15<05:38,  1.19s/it]Running loglikelihood requests:  29%|██▉       | 117/400 [03:16<05:29,  1.17s/it]Running loglikelihood requests:  30%|██▉       | 118/400 [03:17<05:33,  1.18s/it]Running loglikelihood requests:  30%|██▉       | 119/400 [03:18<05:22,  1.15s/it]Running loglikelihood requests:  30%|███       | 120/400 [03:19<05:29,  1.18s/it]Running loglikelihood requests:  30%|███       | 121/400 [03:20<05:19,  1.14s/it]Running loglikelihood requests:  30%|███       | 122/400 [03:21<05:19,  1.15s/it]Running loglikelihood requests:  31%|███       | 123/400 [03:23<05:14,  1.14s/it]Running loglikelihood requests:  31%|███       | 124/400 [03:24<05:10,  1.13s/it]Running loglikelihood requests:  31%|███▏      | 125/400 [03:25<05:07,  1.12s/it]Running loglikelihood requests:  32%|███▏      | 126/400 [03:26<05:02,  1.10s/it]Running loglikelihood requests:  32%|███▏      | 127/400 [03:27<04:57,  1.09s/it]Running loglikelihood requests:  32%|███▏      | 128/400 [03:28<04:56,  1.09s/it]Running loglikelihood requests:  32%|███▏      | 129/400 [03:29<04:50,  1.07s/it]Running loglikelihood requests:  32%|███▎      | 130/400 [03:30<04:58,  1.11s/it]Running loglikelihood requests:  33%|███▎      | 131/400 [03:31<04:55,  1.10s/it]Running loglikelihood requests:  34%|███▎      | 134/400 [03:32<03:07,  1.42it/s]Running loglikelihood requests:  34%|███▍      | 135/400 [03:33<03:24,  1.30it/s]Running loglikelihood requests:  34%|███▍      | 136/400 [03:35<03:48,  1.15it/s]Running loglikelihood requests:  34%|███▍      | 137/400 [03:36<03:57,  1.11it/s]Running loglikelihood requests:  34%|███▍      | 138/400 [03:37<04:12,  1.04it/s]Running loglikelihood requests:  35%|███▍      | 139/400 [03:38<04:18,  1.01it/s]Running loglikelihood requests:  36%|███▌      | 142/400 [03:39<02:45,  1.56it/s]Running loglikelihood requests:  36%|███▌      | 143/400 [03:40<03:08,  1.36it/s]Running loglikelihood requests:  36%|███▌      | 144/400 [03:41<03:27,  1.23it/s]Running loglikelihood requests:  36%|███▋      | 145/400 [03:42<03:49,  1.11it/s]Running loglikelihood requests:  36%|███▋      | 146/400 [03:43<03:55,  1.08it/s]Running loglikelihood requests:  37%|███▋      | 147/400 [03:44<04:08,  1.02it/s]Running loglikelihood requests:  37%|███▋      | 148/400 [03:45<04:10,  1.01it/s]Running loglikelihood requests:  37%|███▋      | 149/400 [03:46<04:12,  1.00s/it]Running loglikelihood requests:  38%|███▊      | 150/400 [03:48<04:14,  1.02s/it]Running loglikelihood requests:  38%|███▊      | 151/400 [03:49<04:17,  1.04s/it]Running loglikelihood requests:  38%|███▊      | 152/400 [03:50<04:17,  1.04s/it]Running loglikelihood requests:  38%|███▊      | 153/400 [03:51<04:16,  1.04s/it]Running loglikelihood requests:  38%|███▊      | 154/400 [03:52<04:14,  1.03s/it]Running loglikelihood requests:  39%|███▉      | 155/400 [03:53<04:16,  1.05s/it]Running loglikelihood requests:  39%|███▉      | 156/400 [03:54<04:20,  1.07s/it]Running loglikelihood requests:  39%|███▉      | 157/400 [03:55<04:19,  1.07s/it]Running loglikelihood requests:  40%|███▉      | 158/400 [03:56<04:17,  1.07s/it]Running loglikelihood requests:  40%|███▉      | 159/400 [03:57<04:43,  1.18s/it]Running loglikelihood requests:  40%|████      | 160/400 [03:59<04:35,  1.15s/it]Running loglikelihood requests:  40%|████      | 161/400 [04:00<04:25,  1.11s/it]Running loglikelihood requests:  40%|████      | 162/400 [04:01<04:14,  1.07s/it]Running loglikelihood requests:  41%|████      | 163/400 [04:02<04:15,  1.08s/it]Running loglikelihood requests:  41%|████      | 164/400 [04:03<04:12,  1.07s/it]Running loglikelihood requests:  41%|████▏     | 165/400 [04:04<04:03,  1.04s/it]Running loglikelihood requests:  42%|████▏     | 166/400 [04:05<04:00,  1.03s/it]Running loglikelihood requests:  42%|████▏     | 167/400 [04:06<04:01,  1.04s/it]Running loglikelihood requests:  42%|████▏     | 168/400 [04:07<03:56,  1.02s/it]Running loglikelihood requests:  42%|████▏     | 169/400 [04:08<03:52,  1.01s/it]Running loglikelihood requests:  42%|████▎     | 170/400 [04:09<03:53,  1.01s/it]Running loglikelihood requests:  43%|████▎     | 172/400 [04:10<03:00,  1.26it/s]Running loglikelihood requests:  43%|████▎     | 173/400 [04:11<03:08,  1.20it/s]Running loglikelihood requests:  44%|████▎     | 174/400 [04:12<03:17,  1.14it/s]Running loglikelihood requests:  44%|████▍     | 177/400 [04:13<02:11,  1.69it/s]Running loglikelihood requests:  44%|████▍     | 178/400 [04:14<02:27,  1.50it/s]Running loglikelihood requests:  45%|████▍     | 179/400 [04:15<02:47,  1.32it/s]Running loglikelihood requests:  45%|████▌     | 180/400 [04:16<02:58,  1.23it/s]Running loglikelihood requests:  45%|████▌     | 181/400 [04:17<03:04,  1.19it/s]Running loglikelihood requests:  46%|████▌     | 182/400 [04:18<03:16,  1.11it/s]Running loglikelihood requests:  46%|████▌     | 183/400 [04:19<03:19,  1.09it/s]Running loglikelihood requests:  46%|████▌     | 184/400 [04:20<03:22,  1.06it/s]Running loglikelihood requests:  46%|████▋     | 185/400 [04:21<03:28,  1.03it/s]Running loglikelihood requests:  46%|████▋     | 186/400 [04:22<03:23,  1.05it/s]Running loglikelihood requests:  47%|████▋     | 187/400 [04:23<03:24,  1.04it/s]Running loglikelihood requests:  47%|████▋     | 188/400 [04:24<03:22,  1.05it/s]Running loglikelihood requests:  47%|████▋     | 189/400 [04:24<03:20,  1.05it/s]Running loglikelihood requests:  48%|████▊     | 190/400 [04:26<03:23,  1.03it/s]Running loglikelihood requests:  48%|████▊     | 191/400 [04:27<03:29,  1.00s/it]Running loglikelihood requests:  48%|████▊     | 192/400 [04:28<03:23,  1.02it/s]Running loglikelihood requests:  48%|████▊     | 193/400 [04:29<03:23,  1.02it/s]Running loglikelihood requests:  48%|████▊     | 194/400 [04:30<03:47,  1.11s/it]Running loglikelihood requests:  49%|████▉     | 195/400 [04:31<03:36,  1.05s/it]Running loglikelihood requests:  49%|████▉     | 196/400 [04:32<03:27,  1.01s/it]Running loglikelihood requests:  49%|████▉     | 197/400 [04:33<03:37,  1.07s/it]Running loglikelihood requests:  50%|████▉     | 198/400 [04:34<03:53,  1.16s/it]Running loglikelihood requests:  50%|████▉     | 199/400 [04:35<03:33,  1.06s/it]Running loglikelihood requests:  50%|█████     | 200/400 [04:36<03:35,  1.08s/it]Running loglikelihood requests:  50%|█████     | 201/400 [04:37<03:19,  1.00s/it]Running loglikelihood requests:  50%|█████     | 202/400 [04:38<03:17,  1.00it/s]Running loglikelihood requests:  51%|█████     | 203/400 [04:39<03:12,  1.02it/s]Running loglikelihood requests:  51%|█████     | 204/400 [04:40<03:15,  1.00it/s]Running loglikelihood requests:  51%|█████▏    | 205/400 [04:41<03:07,  1.04it/s]Running loglikelihood requests:  52%|█████▏    | 206/400 [04:42<03:06,  1.04it/s]Running loglikelihood requests:  52%|█████▏    | 207/400 [04:43<02:58,  1.08it/s]Running loglikelihood requests:  52%|█████▏    | 208/400 [04:44<02:56,  1.08it/s]Running loglikelihood requests:  52%|█████▏    | 209/400 [04:45<03:02,  1.05it/s]Running loglikelihood requests:  53%|█████▎    | 212/400 [04:46<01:55,  1.63it/s]Running loglikelihood requests:  53%|█████▎    | 213/400 [04:47<02:07,  1.47it/s]Running loglikelihood requests:  54%|█████▎    | 214/400 [04:48<02:21,  1.32it/s]Running loglikelihood requests:  54%|█████▍    | 215/400 [04:49<02:37,  1.17it/s]Running loglikelihood requests:  54%|█████▍    | 216/400 [04:50<02:41,  1.14it/s]Running loglikelihood requests:  54%|█████▍    | 217/400 [04:51<02:37,  1.16it/s]Running loglikelihood requests:  55%|█████▍    | 218/400 [04:52<02:45,  1.10it/s]Running loglikelihood requests:  55%|█████▍    | 219/400 [04:53<02:47,  1.08it/s]Running loglikelihood requests:  55%|█████▌    | 220/400 [04:53<02:46,  1.08it/s]Running loglikelihood requests:  55%|█████▌    | 221/400 [04:54<02:40,  1.11it/s]Running loglikelihood requests:  56%|█████▌    | 222/400 [04:55<02:48,  1.06it/s]Running loglikelihood requests:  56%|█████▌    | 223/400 [04:56<02:46,  1.06it/s]Running loglikelihood requests:  56%|█████▌    | 224/400 [04:57<02:47,  1.05it/s]Running loglikelihood requests:  56%|█████▋    | 225/400 [04:58<02:42,  1.08it/s]Running loglikelihood requests:  56%|█████▋    | 226/400 [04:59<02:36,  1.11it/s]Running loglikelihood requests:  57%|█████▋    | 227/400 [05:00<02:51,  1.01it/s]Running loglikelihood requests:  57%|█████▋    | 228/400 [05:01<02:41,  1.07it/s]Running loglikelihood requests:  57%|█████▋    | 229/400 [05:02<02:42,  1.05it/s]Running loglikelihood requests:  57%|█████▊    | 230/400 [05:03<02:53,  1.02s/it]Running loglikelihood requests:  58%|█████▊    | 231/400 [05:04<02:41,  1.05it/s]Running loglikelihood requests:  58%|█████▊    | 232/400 [05:05<02:51,  1.02s/it]Running loglikelihood requests:  58%|█████▊    | 233/400 [05:06<02:51,  1.03s/it]Running loglikelihood requests:  58%|█████▊    | 234/400 [05:07<02:38,  1.05it/s]Running loglikelihood requests:  59%|█████▉    | 235/400 [05:08<02:43,  1.01it/s]Running loglikelihood requests:  59%|█████▉    | 236/400 [05:09<02:38,  1.04it/s]Running loglikelihood requests:  59%|█████▉    | 237/400 [05:10<02:29,  1.09it/s]Running loglikelihood requests:  60%|██████    | 240/400 [05:11<01:39,  1.61it/s]Running loglikelihood requests:  60%|██████    | 241/400 [05:12<01:44,  1.53it/s]Running loglikelihood requests:  60%|██████    | 242/400 [05:13<01:48,  1.46it/s]Running loglikelihood requests:  61%|██████    | 243/400 [05:14<02:04,  1.26it/s]Running loglikelihood requests:  61%|██████    | 244/400 [05:14<02:03,  1.26it/s]Running loglikelihood requests:  61%|██████▏   | 245/400 [05:15<02:12,  1.17it/s]Running loglikelihood requests:  62%|██████▏   | 246/400 [05:16<02:08,  1.19it/s]Running loglikelihood requests:  62%|██████▏   | 247/400 [05:17<02:04,  1.23it/s]Running loglikelihood requests:  62%|██████▏   | 248/400 [05:18<02:02,  1.24it/s]Running loglikelihood requests:  62%|██████▏   | 249/400 [05:20<02:43,  1.08s/it]Running loglikelihood requests:  62%|██████▎   | 250/400 [05:20<02:29,  1.00it/s]Running loglikelihood requests:  63%|██████▎   | 251/400 [05:21<02:18,  1.08it/s]Running loglikelihood requests:  63%|██████▎   | 252/400 [05:22<02:28,  1.00s/it]Running loglikelihood requests:  63%|██████▎   | 253/400 [05:24<02:42,  1.10s/it]Running loglikelihood requests:  64%|██████▎   | 254/400 [05:24<02:27,  1.01s/it]Running loglikelihood requests:  64%|██████▍   | 255/400 [05:25<02:22,  1.02it/s]Running loglikelihood requests:  64%|██████▍   | 256/400 [05:26<02:24,  1.00s/it]Running loglikelihood requests:  64%|██████▍   | 257/400 [05:27<02:13,  1.07it/s]Running loglikelihood requests:  64%|██████▍   | 258/400 [05:28<02:13,  1.07it/s]Running loglikelihood requests:  65%|██████▍   | 259/400 [05:29<02:03,  1.14it/s]Running loglikelihood requests:  65%|██████▌   | 260/400 [05:30<02:07,  1.10it/s]Running loglikelihood requests:  65%|██████▌   | 261/400 [05:31<01:59,  1.17it/s]Running loglikelihood requests:  66%|██████▌   | 262/400 [05:31<01:59,  1.16it/s]Running loglikelihood requests:  66%|██████▌   | 263/400 [05:32<01:54,  1.20it/s]Running loglikelihood requests:  66%|██████▌   | 264/400 [05:33<01:56,  1.16it/s]Running loglikelihood requests:  66%|██████▋   | 265/400 [05:34<01:47,  1.25it/s]Running loglikelihood requests:  66%|██████▋   | 266/400 [05:35<01:48,  1.24it/s]Running loglikelihood requests:  67%|██████▋   | 267/400 [05:35<01:42,  1.30it/s]Running loglikelihood requests:  67%|██████▋   | 268/400 [05:36<01:40,  1.32it/s]Running loglikelihood requests:  67%|██████▋   | 269/400 [05:37<01:44,  1.25it/s]Running loglikelihood requests:  68%|██████▊   | 270/400 [05:38<01:37,  1.34it/s]Running loglikelihood requests:  68%|██████▊   | 271/400 [05:38<01:41,  1.27it/s]Running loglikelihood requests:  68%|██████▊   | 272/400 [05:39<01:35,  1.35it/s]Running loglikelihood requests:  68%|██████▊   | 273/400 [05:40<01:36,  1.31it/s]Running loglikelihood requests:  68%|██████▊   | 274/400 [05:40<01:30,  1.39it/s]Running loglikelihood requests:  69%|██████▉   | 275/400 [05:41<01:35,  1.31it/s]Running loglikelihood requests:  69%|██████▉   | 276/400 [05:42<01:29,  1.39it/s]Running loglikelihood requests:  69%|██████▉   | 277/400 [05:43<01:37,  1.26it/s]Running loglikelihood requests:  70%|██████▉   | 278/400 [05:44<01:32,  1.32it/s]Running loglikelihood requests:  70%|██████▉   | 279/400 [05:44<01:28,  1.36it/s]Running loglikelihood requests:  70%|███████   | 280/400 [05:45<01:33,  1.28it/s]Running loglikelihood requests:  70%|███████   | 281/400 [05:46<01:25,  1.38it/s]Running loglikelihood requests:  70%|███████   | 282/400 [05:46<01:25,  1.38it/s]Running loglikelihood requests:  71%|███████   | 283/400 [05:47<01:27,  1.34it/s]Running loglikelihood requests:  71%|███████   | 284/400 [05:48<01:23,  1.39it/s]Running loglikelihood requests:  71%|███████▏  | 285/400 [05:49<01:19,  1.45it/s]Running loglikelihood requests:  72%|███████▏  | 286/400 [05:50<01:28,  1.28it/s]Running loglikelihood requests:  72%|███████▏  | 287/400 [05:50<01:33,  1.20it/s]Running loglikelihood requests:  72%|███████▏  | 288/400 [05:51<01:25,  1.31it/s]Running loglikelihood requests:  72%|███████▏  | 289/400 [05:52<01:21,  1.37it/s]Running loglikelihood requests:  72%|███████▎  | 290/400 [05:53<01:31,  1.21it/s]Running loglikelihood requests:  73%|███████▎  | 291/400 [05:53<01:22,  1.32it/s]Running loglikelihood requests:  73%|███████▎  | 292/400 [05:54<01:26,  1.25it/s]Running loglikelihood requests:  73%|███████▎  | 293/400 [05:55<01:24,  1.27it/s]Running loglikelihood requests:  74%|███████▎  | 294/400 [05:56<01:18,  1.35it/s]Running loglikelihood requests:  74%|███████▍  | 295/400 [05:57<01:25,  1.23it/s]Running loglikelihood requests:  74%|███████▍  | 296/400 [05:57<01:18,  1.32it/s]Running loglikelihood requests:  74%|███████▍  | 297/400 [05:58<01:13,  1.40it/s]Running loglikelihood requests:  74%|███████▍  | 298/400 [05:59<01:17,  1.31it/s]Running loglikelihood requests:  75%|███████▍  | 299/400 [05:59<01:11,  1.42it/s]Running loglikelihood requests:  75%|███████▌  | 300/400 [06:00<01:13,  1.37it/s]Running loglikelihood requests:  75%|███████▌  | 301/400 [06:01<01:09,  1.41it/s]Running loglikelihood requests:  76%|███████▌  | 302/400 [06:02<01:09,  1.42it/s]Running loglikelihood requests:  76%|███████▌  | 303/400 [06:02<01:09,  1.40it/s]Running loglikelihood requests:  76%|███████▌  | 304/400 [06:03<01:06,  1.43it/s]Running loglikelihood requests:  76%|███████▋  | 305/400 [06:04<01:06,  1.42it/s]Running loglikelihood requests:  76%|███████▋  | 306/400 [06:04<01:06,  1.41it/s]Running loglikelihood requests:  77%|███████▋  | 307/400 [06:05<01:05,  1.41it/s]Running loglikelihood requests:  78%|███████▊  | 310/400 [06:06<00:38,  2.35it/s]Running loglikelihood requests:  78%|███████▊  | 311/400 [06:06<00:43,  2.05it/s]Running loglikelihood requests:  78%|███████▊  | 312/400 [06:07<00:44,  1.98it/s]Running loglikelihood requests:  78%|███████▊  | 313/400 [06:08<00:50,  1.71it/s]Running loglikelihood requests:  78%|███████▊  | 314/400 [06:08<00:49,  1.72it/s]Running loglikelihood requests:  79%|███████▉  | 315/400 [06:09<00:56,  1.50it/s]Running loglikelihood requests:  79%|███████▉  | 316/400 [06:10<00:55,  1.52it/s]Running loglikelihood requests:  79%|███████▉  | 317/400 [06:11<00:57,  1.46it/s]Running loglikelihood requests:  80%|███████▉  | 318/400 [06:11<00:53,  1.53it/s]Running loglikelihood requests:  80%|███████▉  | 319/400 [06:12<00:50,  1.61it/s]Running loglikelihood requests:  80%|████████  | 321/400 [06:13<00:44,  1.78it/s]Running loglikelihood requests:  80%|████████  | 322/400 [06:13<00:43,  1.78it/s]Running loglikelihood requests:  81%|████████  | 323/400 [06:14<00:50,  1.54it/s]Running loglikelihood requests:  81%|████████  | 324/400 [06:15<00:52,  1.45it/s]Running loglikelihood requests:  81%|████████▏ | 325/400 [06:16<00:48,  1.54it/s]Running loglikelihood requests:  82%|████████▏ | 326/400 [06:17<00:56,  1.30it/s]Running loglikelihood requests:  82%|████████▏ | 327/400 [06:17<00:51,  1.43it/s]Running loglikelihood requests:  82%|████████▏ | 328/400 [06:18<00:50,  1.43it/s]Running loglikelihood requests:  82%|████████▏ | 329/400 [06:19<00:52,  1.36it/s]Running loglikelihood requests:  82%|████████▎ | 330/400 [06:19<00:47,  1.48it/s]Running loglikelihood requests:  83%|████████▎ | 331/400 [06:20<00:50,  1.36it/s]Running loglikelihood requests:  83%|████████▎ | 332/400 [06:21<00:46,  1.46it/s]Running loglikelihood requests:  83%|████████▎ | 333/400 [06:21<00:42,  1.58it/s]Running loglikelihood requests:  84%|████████▎ | 334/400 [06:22<00:46,  1.43it/s]Running loglikelihood requests:  84%|████████▍ | 335/400 [06:23<00:42,  1.53it/s]Running loglikelihood requests:  84%|████████▍ | 336/400 [06:23<00:39,  1.63it/s]Running loglikelihood requests:  84%|████████▍ | 337/400 [06:24<00:48,  1.31it/s]Running loglikelihood requests:  84%|████████▍ | 338/400 [06:25<00:45,  1.36it/s]Running loglikelihood requests:  85%|████████▍ | 339/400 [06:25<00:40,  1.50it/s]Running loglikelihood requests:  85%|████████▌ | 340/400 [06:26<00:47,  1.27it/s]Running loglikelihood requests:  85%|████████▌ | 341/400 [06:27<00:43,  1.37it/s]Running loglikelihood requests:  86%|████████▌ | 342/400 [06:28<00:42,  1.36it/s]Running loglikelihood requests:  86%|████████▌ | 343/400 [06:28<00:38,  1.50it/s]Running loglikelihood requests:  86%|████████▌ | 344/400 [06:29<00:39,  1.40it/s]Running loglikelihood requests:  86%|████████▋ | 345/400 [06:30<00:35,  1.53it/s]Running loglikelihood requests:  86%|████████▋ | 346/400 [06:30<00:32,  1.65it/s]Running loglikelihood requests:  87%|████████▋ | 347/400 [06:31<00:38,  1.38it/s]Running loglikelihood requests:  87%|████████▋ | 348/400 [06:32<00:37,  1.39it/s]Running loglikelihood requests:  87%|████████▋ | 349/400 [06:32<00:33,  1.53it/s]Running loglikelihood requests:  88%|████████▊ | 350/400 [06:33<00:30,  1.64it/s]Running loglikelihood requests:  88%|████████▊ | 351/400 [06:34<00:37,  1.30it/s]Running loglikelihood requests:  88%|████████▊ | 352/400 [06:35<00:38,  1.25it/s]Running loglikelihood requests:  88%|████████▊ | 353/400 [06:35<00:33,  1.42it/s]Running loglikelihood requests:  88%|████████▊ | 354/400 [06:36<00:32,  1.40it/s]Running loglikelihood requests:  89%|████████▉ | 355/400 [06:37<00:30,  1.49it/s]Running loglikelihood requests:  89%|████████▉ | 356/400 [06:37<00:30,  1.43it/s]Running loglikelihood requests:  89%|████████▉ | 357/400 [06:38<00:30,  1.41it/s]Running loglikelihood requests:  90%|████████▉ | 358/400 [06:39<00:26,  1.56it/s]Running loglikelihood requests:  90%|████████▉ | 359/400 [06:39<00:26,  1.54it/s]Running loglikelihood requests:  90%|█████████ | 360/400 [06:40<00:25,  1.58it/s]Running loglikelihood requests:  90%|█████████ | 361/400 [06:40<00:23,  1.69it/s]Running loglikelihood requests:  90%|█████████ | 362/400 [06:41<00:28,  1.35it/s]Running loglikelihood requests:  91%|█████████ | 363/400 [06:42<00:24,  1.50it/s]Running loglikelihood requests:  91%|█████████ | 364/400 [06:43<00:27,  1.32it/s]Running loglikelihood requests:  91%|█████████▏| 365/400 [06:44<00:25,  1.36it/s]Running loglikelihood requests:  92%|█████████▏| 366/400 [06:44<00:24,  1.42it/s]Running loglikelihood requests:  92%|█████████▏| 368/400 [06:45<00:16,  1.92it/s]Running loglikelihood requests:  92%|█████████▏| 369/400 [06:45<00:16,  1.83it/s]Running loglikelihood requests:  92%|█████████▎| 370/400 [06:46<00:17,  1.67it/s]Running loglikelihood requests:  93%|█████████▎| 371/400 [06:47<00:16,  1.75it/s]Running loglikelihood requests:  93%|█████████▎| 373/400 [06:48<00:14,  1.83it/s]Running loglikelihood requests:  94%|█████████▎| 374/400 [06:48<00:14,  1.83it/s]Running loglikelihood requests:  94%|█████████▍| 375/400 [06:49<00:14,  1.78it/s]Running loglikelihood requests:  94%|█████████▍| 376/400 [06:50<00:15,  1.51it/s]Running loglikelihood requests:  94%|█████████▍| 377/400 [06:50<00:15,  1.51it/s]Running loglikelihood requests:  94%|█████████▍| 378/400 [06:51<00:14,  1.50it/s]Running loglikelihood requests:  95%|█████████▍| 379/400 [06:52<00:13,  1.59it/s]Running loglikelihood requests:  95%|█████████▌| 380/400 [06:52<00:13,  1.48it/s]Running loglikelihood requests:  95%|█████████▌| 381/400 [06:53<00:11,  1.62it/s]Running loglikelihood requests:  96%|█████████▌| 382/400 [06:54<00:12,  1.44it/s]Running loglikelihood requests:  96%|█████████▌| 383/400 [06:55<00:12,  1.34it/s]Running loglikelihood requests:  96%|█████████▌| 384/400 [06:55<00:10,  1.51it/s]Running loglikelihood requests:  96%|█████████▋| 385/400 [06:56<00:10,  1.37it/s]Running loglikelihood requests:  96%|█████████▋| 386/400 [06:57<00:09,  1.49it/s]Running loglikelihood requests:  97%|█████████▋| 387/400 [06:57<00:07,  1.65it/s]Running loglikelihood requests:  97%|█████████▋| 388/400 [06:58<00:07,  1.62it/s]Running loglikelihood requests:  97%|█████████▋| 389/400 [06:58<00:07,  1.55it/s]Running loglikelihood requests:  98%|█████████▊| 390/400 [06:59<00:06,  1.59it/s]Running loglikelihood requests:  98%|█████████▊| 391/400 [07:00<00:05,  1.50it/s]Running loglikelihood requests:  98%|█████████▊| 392/400 [07:00<00:04,  1.66it/s]Running loglikelihood requests:  98%|█████████▊| 393/400 [07:01<00:04,  1.44it/s]Running loglikelihood requests:  98%|█████████▊| 394/400 [07:02<00:03,  1.59it/s]Running loglikelihood requests:  99%|█████████▉| 395/400 [07:02<00:02,  1.71it/s]Running loglikelihood requests:  99%|█████████▉| 396/400 [07:03<00:02,  1.45it/s]Running loglikelihood requests:  99%|█████████▉| 397/400 [07:03<00:01,  1.63it/s]Running loglikelihood requests: 100%|█████████▉| 398/400 [07:04<00:01,  1.78it/s]Running loglikelihood requests: 100%|█████████▉| 399/400 [07:05<00:00,  1.64it/s]Running loglikelihood requests: 100%|██████████| 400/400 [07:05<00:00,  1.70it/s]Running loglikelihood requests: 100%|██████████| 400/400 [07:05<00:00,  1.06s/it]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:0'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}
full model:
{'sciq': {'alias': 'sciq', 'acc,none': 0.94, 'acc_stderr,none': 0.023868325657594204, 'acc_norm,none': 0.91, 'acc_norm_stderr,none': 0.028762349126466136}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.969062788859705
0.9024924890572922
0.7706109127217512
0.8221264026535647
0.9190490061886575
0.9866654579796295
0.6586322754204971
0.7962110384246164
0.8195614021629236
0.7124178311176441
0.787697814339696
0.7034455022322618
0.8136386046534271
0.8174990104652458
0.6784276389594894
0.8698440245672888
0.8886492811850213
0.6541737276411673
0.6560861559753316
0.8139845219953913
0.6714741870309046
0.6164364868717988
0.8331581872497299
0.9065420049234512
0.9246185715568276
0.7477515960551026
0.574165362968651
0.8586446364199891
0.8889771415746612
Total groups 70 exceeded the threshold, stopping comparison.
The group tensor is
[7, 3, 4, 2, 6, 1, 5, 0]
tensor([7, 3, 4, 2, 6, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 2, 5, 3, 4, 0, 7, 1]
tensor([6, 2, 5, 3, 4, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 3, 6, 2, 7, 1, 4, 0]
tensor([5, 3, 6, 2, 7, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 4, 2, 1, 3, 5, 1]
tensor([0, 0, 4, 2, 1, 3, 5, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 2, 3, 4, 5, 0, 1, 1]
tensor([0, 2, 3, 4, 5, 0, 1, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 1, 0, 2, 2, 3, 1]
tensor([0, 3, 1, 0, 2, 2, 3, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 3, 1, 1, 2, 2, 3, 0]
tensor([0, 3, 1, 1, 2, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 1, 1.0, 1.0, 1.0, 1.0, 1]
tensor([0, 0, 1, 1, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 2 to 4
done!
Normal merging for layer 5
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 6 to 9
done!
Normal merging for layer 10
tensor([0, 1])
tensor(0)
tensor([4, 7])
tensor(4)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 11 to 12
done!
Normal merging for layer 13
tensor([0, 5])
tensor(0)
tensor([6, 7])
tensor(6)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 14 to 19
done!
Normal merging for layer 20
tensor([0, 3])
tensor(0)
tensor([2, 7])
tensor(2)
tensor([4, 5])
tensor(4)
tensor([1, 6])
tensor(1)
done!
Normal merging for layer 21
tensor([0, 7])
tensor(0)
tensor([2, 3])
tensor(2)
tensor([4, 5])
tensor(4)
tensor([1, 6])
tensor(1)
done!
Cross-layer merge completed for layers 22 to 23
done!
Normal merging for layer 24
tensor([0, 1])
tensor(0)
tensor([2, 3, 4, 5, 6, 7])
tensor(2)
done!
Cross-layer merge completed for layers 25 to 31
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 9 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.2608 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 8 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

73
cuda:0
qqp
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [01:01<01:01, 61.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:23<00:00, 38.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:23<00:00, 41.70s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: qqp] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: qqp] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
WARNING:lm_eval.api.task:[Task: qqp] metric f1 is defined, but aggregation is not. using default aggregation=f1
WARNING:lm_eval.api.task:[Task: qqp] metric f1 is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/qqp?recursive=False&expand=False HTTP/1.1" 307 140
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/qqp?recursive=False&expand=False HTTP/1.1" 200 355
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:filelock:Attempting to acquire lock 139704482689296 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_qqp_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139704482689296 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_qqp_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/qqp/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139704482689296 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_qqp_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139704482689296 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_qqp_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139686162902592 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/qqp/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139686162902592 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/qqp/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/qqp/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139686162902592 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/qqp/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139686162902592 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/qqp/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of qqp from None to 0
INFO:lm_eval.api.task:Building contexts for qqp on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 2488.54it/s]
DEBUG:lm_eval.evaluator:Task: qqp; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:01<05:31,  1.67s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:02<02:26,  1.35it/s]Running loglikelihood requests:   2%|▎         | 5/200 [00:03<01:47,  1.81it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:03<01:32,  2.10it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:04<01:22,  2.33it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:05<01:17,  2.43it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:06<01:12,  2.56it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:06<01:09,  2.67it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:07<01:06,  2.74it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:08<01:04,  2.80it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:08<01:03,  2.82it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:09<01:02,  2.84it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:10<01:01,  2.87it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:10<01:00,  2.88it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:11<00:58,  2.93it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:12<00:57,  2.96it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:12<00:55,  2.99it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:13<00:54,  3.01it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:14<00:53,  3.03it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:14<00:52,  3.05it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:15<00:52,  3.06it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:16<00:51,  3.06it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:16<00:50,  3.08it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:17<00:49,  3.09it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:18<00:48,  3.10it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:18<00:47,  3.12it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:19<00:46,  3.14it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:20<00:46,  3.15it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:20<00:45,  3.16it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:21<00:44,  3.18it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:21<00:43,  3.18it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:22<00:42,  3.19it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:23<00:42,  3.21it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:23<00:41,  3.22it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:24<00:40,  3.23it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:24<00:39,  3.23it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:25<00:39,  3.23it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:26<00:38,  3.24it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:26<00:37,  3.24it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:27<00:37,  3.25it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:28<00:36,  3.27it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:28<00:36,  3.25it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:29<00:35,  3.26it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:29<00:34,  3.27it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:30<00:33,  3.28it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:31<00:33,  3.29it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:31<00:32,  3.30it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:32<00:31,  3.31it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:32<00:30,  3.32it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:33<00:30,  3.34it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:34<00:29,  3.34it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:34<00:28,  3.36it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:35<00:28,  3.37it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:35<00:27,  3.38it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:36<00:26,  3.39it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:36<00:26,  3.41it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:37<00:25,  3.43it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:38<00:24,  3.43it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:38<00:24,  3.44it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:39<00:23,  3.45it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:39<00:22,  3.46it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:40<00:22,  3.47it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:41<00:21,  3.47it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [00:41<00:20,  3.48it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [00:42<00:20,  3.49it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [00:42<00:19,  3.51it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [00:43<00:19,  3.52it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [00:43<00:18,  3.52it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [00:44<00:17,  3.53it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [00:44<00:17,  3.53it/s]Running loglikelihood requests:  70%|███████   | 141/200 [00:45<00:16,  3.54it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [00:46<00:16,  3.55it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [00:46<00:15,  3.56it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [00:47<00:14,  3.57it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [00:47<00:14,  3.57it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [00:48<00:13,  3.59it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [00:48<00:13,  3.60it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [00:49<00:12,  3.61it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [00:49<00:11,  3.63it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [00:50<00:11,  3.64it/s]Running loglikelihood requests:  80%|████████  | 161/200 [00:51<00:10,  3.64it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [00:51<00:10,  3.65it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [00:52<00:09,  3.65it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [00:52<00:09,  3.66it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [00:53<00:08,  3.67it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [00:53<00:07,  3.67it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [00:54<00:07,  3.68it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [00:54<00:06,  3.69it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [00:55<00:06,  3.70it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [00:55<00:05,  3.70it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [00:56<00:05,  3.71it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [00:57<00:04,  3.71it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [00:57<00:04,  3.71it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [00:58<00:03,  3.70it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [00:58<00:02,  3.72it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [00:59<00:02,  3.66it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [00:59<00:01,  3.69it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:00<00:01,  3.74it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:00<00:00,  3.78it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:01<00:00,  3.83it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:01<00:00,  3.26it/s]
bootstrapping for stddev (sequential): f1_score
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:01<01:58,  1.19s/it]  2%|▏         | 2/100 [00:02<01:56,  1.19s/it]  3%|▎         | 3/100 [00:03<01:55,  1.19s/it]  4%|▍         | 4/100 [00:04<01:54,  1.19s/it]  5%|▌         | 5/100 [00:05<01:53,  1.19s/it]  6%|▌         | 6/100 [00:07<01:51,  1.19s/it]  7%|▋         | 7/100 [00:08<01:50,  1.19s/it]  8%|▊         | 8/100 [00:09<01:49,  1.19s/it]  9%|▉         | 9/100 [00:10<01:47,  1.19s/it] 10%|█         | 10/100 [00:11<01:46,  1.19s/it] 11%|█         | 11/100 [00:13<01:45,  1.19s/it] 12%|█▏        | 12/100 [00:14<01:44,  1.19s/it] 13%|█▎        | 13/100 [00:15<01:43,  1.19s/it] 14%|█▍        | 14/100 [00:16<01:41,  1.19s/it] 15%|█▌        | 15/100 [00:17<01:40,  1.19s/it] 16%|█▌        | 16/100 [00:19<01:39,  1.19s/it] 17%|█▋        | 17/100 [00:20<01:38,  1.19s/it] 18%|█▊        | 18/100 [00:21<01:37,  1.19s/it] 19%|█▉        | 19/100 [00:22<01:36,  1.19s/it] 20%|██        | 20/100 [00:23<01:35,  1.19s/it] 21%|██        | 21/100 [00:24<01:34,  1.19s/it] 22%|██▏       | 22/100 [00:26<01:32,  1.19s/it] 23%|██▎       | 23/100 [00:27<01:31,  1.19s/it] 24%|██▍       | 24/100 [00:28<01:30,  1.19s/it] 25%|██▌       | 25/100 [00:29<01:29,  1.19s/it] 26%|██▌       | 26/100 [00:30<01:28,  1.19s/it] 27%|██▋       | 27/100 [00:32<01:26,  1.19s/it] 28%|██▊       | 28/100 [00:33<01:25,  1.19s/it] 29%|██▉       | 29/100 [00:34<01:24,  1.19s/it] 30%|███       | 30/100 [00:35<01:23,  1.19s/it] 31%|███       | 31/100 [00:36<01:22,  1.19s/it] 32%|███▏      | 32/100 [00:38<01:20,  1.19s/it] 33%|███▎      | 33/100 [00:39<01:19,  1.19s/it] 34%|███▍      | 34/100 [00:40<01:18,  1.19s/it] 35%|███▌      | 35/100 [00:41<01:17,  1.19s/it] 36%|███▌      | 36/100 [00:42<01:16,  1.19s/it] 37%|███▋      | 37/100 [00:43<01:14,  1.19s/it] 38%|███▊      | 38/100 [00:45<01:13,  1.19s/it] 39%|███▉      | 39/100 [00:46<01:12,  1.19s/it] 40%|████      | 40/100 [00:47<01:11,  1.19s/it] 41%|████      | 41/100 [00:48<01:10,  1.19s/it] 42%|████▏     | 42/100 [00:49<01:08,  1.19s/it] 43%|████▎     | 43/100 [00:51<01:07,  1.19s/it] 44%|████▍     | 44/100 [00:52<01:07,  1.20s/it] 45%|████▌     | 45/100 [00:53<01:05,  1.20s/it] 46%|████▌     | 46/100 [00:54<01:04,  1.19s/it] 47%|████▋     | 47/100 [00:55<01:03,  1.19s/it] 48%|████▊     | 48/100 [00:57<01:02,  1.19s/it] 49%|████▉     | 49/100 [00:58<01:00,  1.19s/it] 50%|█████     | 50/100 [00:59<00:59,  1.19s/it] 51%|█████     | 51/100 [01:00<00:58,  1.19s/it] 52%|█████▏    | 52/100 [01:01<00:57,  1.19s/it] 53%|█████▎    | 53/100 [01:03<00:56,  1.19s/it] 54%|█████▍    | 54/100 [01:04<00:54,  1.19s/it] 55%|█████▌    | 55/100 [01:05<00:53,  1.19s/it] 56%|█████▌    | 56/100 [01:06<00:52,  1.19s/it] 57%|█████▋    | 57/100 [01:07<00:51,  1.19s/it] 58%|█████▊    | 58/100 [01:09<00:49,  1.19s/it] 59%|█████▉    | 59/100 [01:10<00:48,  1.19s/it] 60%|██████    | 60/100 [01:11<00:47,  1.19s/it] 61%|██████    | 61/100 [01:12<00:46,  1.19s/it] 62%|██████▏   | 62/100 [01:13<00:45,  1.19s/it] 63%|██████▎   | 63/100 [01:14<00:43,  1.19s/it] 64%|██████▍   | 64/100 [01:16<00:42,  1.19s/it] 65%|██████▌   | 65/100 [01:17<00:41,  1.19s/it] 66%|██████▌   | 66/100 [01:18<00:40,  1.19s/it] 67%|██████▋   | 67/100 [01:19<00:39,  1.19s/it] 68%|██████▊   | 68/100 [01:20<00:37,  1.19s/it] 69%|██████▉   | 69/100 [01:22<00:36,  1.19s/it] 70%|███████   | 70/100 [01:23<00:35,  1.19s/it] 71%|███████   | 71/100 [01:24<00:34,  1.19s/it] 72%|███████▏  | 72/100 [01:25<00:33,  1.19s/it] 73%|███████▎  | 73/100 [01:26<00:32,  1.19s/it] 74%|███████▍  | 74/100 [01:28<00:30,  1.19s/it] 75%|███████▌  | 75/100 [01:29<00:29,  1.19s/it] 76%|███████▌  | 76/100 [01:30<00:28,  1.19s/it] 77%|███████▋  | 77/100 [01:31<00:27,  1.19s/it] 78%|███████▊  | 78/100 [01:32<00:26,  1.19s/it] 79%|███████▉  | 79/100 [01:33<00:24,  1.19s/it] 80%|████████  | 80/100 [01:35<00:23,  1.19s/it] 81%|████████  | 81/100 [01:36<00:22,  1.19s/it] 82%|████████▏ | 82/100 [01:37<00:21,  1.19s/it] 83%|████████▎ | 83/100 [01:38<00:20,  1.19s/it] 84%|████████▍ | 84/100 [01:39<00:19,  1.19s/it] 85%|████████▌ | 85/100 [01:41<00:17,  1.19s/it] 86%|████████▌ | 86/100 [01:42<00:16,  1.19s/it] 87%|████████▋ | 87/100 [01:43<00:15,  1.19s/it] 88%|████████▊ | 88/100 [01:44<00:14,  1.19s/it] 89%|████████▉ | 89/100 [01:45<00:13,  1.19s/it] 90%|█████████ | 90/100 [01:46<00:11,  1.19s/it] 91%|█████████ | 91/100 [01:48<00:10,  1.19s/it] 92%|█████████▏| 92/100 [01:49<00:09,  1.18s/it] 93%|█████████▎| 93/100 [01:50<00:08,  1.18s/it] 94%|█████████▍| 94/100 [01:51<00:07,  1.18s/it] 95%|█████████▌| 95/100 [01:52<00:05,  1.19s/it] 96%|█████████▌| 96/100 [01:54<00:04,  1.18s/it] 97%|█████████▋| 97/100 [01:55<00:03,  1.19s/it] 98%|█████████▊| 98/100 [01:56<00:02,  1.19s/it] 99%|█████████▉| 99/100 [01:57<00:01,  1.19s/it]100%|██████████| 100/100 [01:58<00:00,  1.19s/it]100%|██████████| 100/100 [01:58<00:00,  1.19s/it]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:1'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:1'}
full model:
{'qqp': {'alias': 'qqp', 'acc,none': 0.3, 'acc_stderr,none': 0.04605661864718382, 'f1,none': np.float64(0.46153846153846156), 'f1_stderr,none': 0.05409397997448054}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.7956670939612598
0.9434665619842647
0.7711450328862919
0.8003111158987146
0.8660685706927677
0.6448594355779524
0.8450704433196731
0.7858702319299253
0.44571740342828275
0.8279983705061201
0.5649013775668057
0.5764430622159564
0.7600312367627909
0.4667905570890965
0.6441885742762831
0.5956490746171949
0.7561037067659027
0.6832036593513438
0.703034342774608
0.741950763385666
0.9094352412525417
0.3828457019607829
0.592762753179094
0.5983336442242687
0.5414593978662989
0.3299447012562784
0.4799857918750434
0.8524920468933548
0.713165518996795
0.7956670939612598
0.9434665619842647
0.7711450328862919
0.8003111158987146
0.8660685706927677
0.6448594355779524
0.8450704433196731
0.7858702319299253
0.44571740342828275
0.8279983705061201
0.5649013775668057
0.5764430622159564
0.7600312367627909
0.4667905570890965
0.6441885742762831
0.5956490746171949
0.7561037067659027
0.6832036593513438
0.703034342774608
0.741950763385666
0.9094352412525417
0.3828457019607829
0.592762753179094
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[5, 4, 6, 2, 7, 1, 3, 0]
tensor([5, 4, 6, 2, 7, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 4, 5, 2, 6, 1, 3, 0]
tensor([7, 4, 5, 2, 6, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 4, 6, 2, 7, 1, 3, 0]
tensor([5, 4, 6, 2, 7, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[6, 4, 5, 2, 7, 3, 0, 1]
tensor([6, 4, 5, 2, 7, 3, 0, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 7, 4, 2, 5, 0, 1, 3]
tensor([6, 7, 4, 2, 5, 0, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 6, 4, 3, 7, 1, 0, 2]
tensor([5, 6, 4, 3, 7, 1, 0, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
done!
Normal merging for layer 2
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 3 to 4
done!
Normal merging for layer 5
tensor([6])
tensor(6)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Normal merging for layer 6
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
tensor([1])
tensor(1)
done!
Normal merging for layer 7
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 8 to 31
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 8 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.1348 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 7 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

19
cuda:1
sciq
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:57<00:57, 57.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:14<00:00, 33.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:14<00:00, 37.08s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq HTTP/1.1" 200 1238
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/sciq/sciq.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq HTTP/1.1" 200 1238
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/allenai/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/allenai/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:filelock:Attempting to acquire lock 139716772761136 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:filelock:Lock 139716772761136 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_info.json
DEBUG:filelock:Attempting to release lock 139716772761136 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:filelock:Lock 139716772761136 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:filelock:Attempting to acquire lock 139706899976400 on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:filelock:Lock 139706899976400 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_info.json
DEBUG:filelock:Attempting to release lock 139706899976400 on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:filelock:Lock 139706899976400 released on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of sciq from None to 0
INFO:lm_eval.api.task:Building contexts for sciq on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1032.58it/s]
DEBUG:lm_eval.evaluator:Task: sciq; number of requests on this rank: 400
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/400 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/400 [00:04<30:33,  4.59s/it]Running loglikelihood requests:   0%|          | 2/400 [00:08<26:40,  4.02s/it]Running loglikelihood requests:   1%|          | 3/400 [00:11<25:22,  3.83s/it]Running loglikelihood requests:   1%|          | 4/400 [00:15<24:54,  3.77s/it]Running loglikelihood requests:   1%|▏         | 5/400 [00:18<23:56,  3.64s/it]Running loglikelihood requests:   2%|▏         | 6/400 [00:22<23:19,  3.55s/it]Running loglikelihood requests:   2%|▏         | 7/400 [00:25<22:56,  3.50s/it]Running loglikelihood requests:   2%|▏         | 8/400 [00:29<22:43,  3.48s/it]Running loglikelihood requests:   2%|▏         | 9/400 [00:32<21:42,  3.33s/it]Running loglikelihood requests:   2%|▎         | 10/400 [00:35<20:56,  3.22s/it]Running loglikelihood requests:   3%|▎         | 11/400 [00:38<20:24,  3.15s/it]Running loglikelihood requests:   3%|▎         | 12/400 [00:41<20:03,  3.10s/it]Running loglikelihood requests:   3%|▎         | 13/400 [00:43<19:13,  2.98s/it]Running loglikelihood requests:   4%|▎         | 14/400 [00:46<18:36,  2.89s/it]Running loglikelihood requests:   4%|▍         | 15/400 [00:49<18:17,  2.85s/it]Running loglikelihood requests:   4%|▍         | 16/400 [00:52<18:10,  2.84s/it]Running loglikelihood requests:   4%|▍         | 17/400 [00:54<17:48,  2.79s/it]Running loglikelihood requests:   4%|▍         | 18/400 [00:57<17:30,  2.75s/it]Running loglikelihood requests:   5%|▍         | 19/400 [00:59<17:10,  2.71s/it]Running loglikelihood requests:   5%|▌         | 20/400 [01:02<16:56,  2.67s/it]Running loglikelihood requests:   5%|▌         | 21/400 [01:05<16:41,  2.64s/it]Running loglikelihood requests:   6%|▌         | 22/400 [01:07<16:30,  2.62s/it]Running loglikelihood requests:   6%|▌         | 23/400 [01:10<16:21,  2.60s/it]Running loglikelihood requests:   6%|▌         | 24/400 [01:12<16:14,  2.59s/it]Running loglikelihood requests:   6%|▋         | 25/400 [01:15<15:50,  2.54s/it]Running loglikelihood requests:   6%|▋         | 26/400 [01:17<15:34,  2.50s/it]Running loglikelihood requests:   7%|▋         | 27/400 [01:20<15:21,  2.47s/it]Running loglikelihood requests:   7%|▋         | 28/400 [01:22<15:10,  2.45s/it]Running loglikelihood requests:   7%|▋         | 29/400 [01:24<14:38,  2.37s/it]Running loglikelihood requests:   8%|▊         | 30/400 [01:26<14:15,  2.31s/it]Running loglikelihood requests:   8%|▊         | 31/400 [01:28<13:57,  2.27s/it]Running loglikelihood requests:   8%|▊         | 32/400 [01:31<13:44,  2.24s/it]Running loglikelihood requests:   8%|▊         | 33/400 [01:33<13:19,  2.18s/it]Running loglikelihood requests:   8%|▊         | 34/400 [01:35<13:01,  2.13s/it]Running loglikelihood requests:   9%|▉         | 35/400 [01:37<12:47,  2.10s/it]Running loglikelihood requests:   9%|▉         | 36/400 [01:39<12:37,  2.08s/it]Running loglikelihood requests:   9%|▉         | 37/400 [01:41<12:29,  2.06s/it]Running loglikelihood requests:  10%|▉         | 38/400 [01:43<12:25,  2.06s/it]Running loglikelihood requests:  10%|█         | 40/400 [01:45<09:32,  1.59s/it]Running loglikelihood requests:  10%|█         | 41/400 [01:47<09:55,  1.66s/it]Running loglikelihood requests:  10%|█         | 42/400 [01:49<10:12,  1.71s/it]Running loglikelihood requests:  11%|█         | 43/400 [01:51<10:25,  1.75s/it]Running loglikelihood requests:  11%|█         | 44/400 [01:52<10:32,  1.78s/it]Running loglikelihood requests:  11%|█▏        | 45/400 [01:54<10:30,  1.78s/it]Running loglikelihood requests:  12%|█▏        | 46/400 [01:56<10:28,  1.78s/it]Running loglikelihood requests:  12%|█▏        | 47/400 [01:58<10:26,  1.77s/it]Running loglikelihood requests:  12%|█▏        | 48/400 [01:59<10:23,  1.77s/it]Running loglikelihood requests:  12%|█▏        | 49/400 [02:01<10:20,  1.77s/it]Running loglikelihood requests:  12%|█▎        | 50/400 [02:03<10:22,  1.78s/it]Running loglikelihood requests:  13%|█▎        | 51/400 [02:05<10:18,  1.77s/it]Running loglikelihood requests:  13%|█▎        | 52/400 [02:07<10:15,  1.77s/it]Running loglikelihood requests:  13%|█▎        | 53/400 [02:08<09:56,  1.72s/it]Running loglikelihood requests:  14%|█▎        | 54/400 [02:10<09:39,  1.68s/it]Running loglikelihood requests:  14%|█▍        | 55/400 [02:11<09:28,  1.65s/it]Running loglikelihood requests:  14%|█▍        | 57/400 [02:13<07:04,  1.24s/it]Running loglikelihood requests:  14%|█▍        | 58/400 [02:14<07:26,  1.31s/it]Running loglikelihood requests:  15%|█▍        | 59/400 [02:16<07:43,  1.36s/it]Running loglikelihood requests:  16%|█▌        | 62/400 [02:17<05:06,  1.10it/s]Running loglikelihood requests:  16%|█▌        | 63/400 [02:19<05:45,  1.03s/it]Running loglikelihood requests:  16%|█▌        | 64/400 [02:20<06:20,  1.13s/it]Running loglikelihood requests:  16%|█▋        | 65/400 [02:22<06:45,  1.21s/it]Running loglikelihood requests:  16%|█▋        | 66/400 [02:23<07:04,  1.27s/it]Running loglikelihood requests:  17%|█▋        | 67/400 [02:25<07:18,  1.32s/it]Running loglikelihood requests:  17%|█▋        | 68/400 [02:26<07:29,  1.35s/it]Running loglikelihood requests:  17%|█▋        | 69/400 [02:28<07:34,  1.37s/it]Running loglikelihood requests:  18%|█▊        | 70/400 [02:29<07:37,  1.39s/it]Running loglikelihood requests:  18%|█▊        | 71/400 [02:30<07:39,  1.40s/it]Running loglikelihood requests:  18%|█▊        | 72/400 [02:32<07:56,  1.45s/it]Running loglikelihood requests:  18%|█▊        | 73/400 [02:33<07:51,  1.44s/it]Running loglikelihood requests:  18%|█▊        | 74/400 [02:35<07:46,  1.43s/it]Running loglikelihood requests:  19%|█▉        | 77/400 [02:36<04:46,  1.13it/s]Running loglikelihood requests:  20%|█▉        | 78/400 [02:38<05:17,  1.01it/s]Running loglikelihood requests:  20%|█▉        | 79/400 [02:39<05:44,  1.07s/it]Running loglikelihood requests:  20%|██        | 81/400 [02:40<04:45,  1.12it/s]Running loglikelihood requests:  20%|██        | 82/400 [02:41<05:09,  1.03it/s]Running loglikelihood requests:  21%|██        | 83/400 [02:43<05:28,  1.04s/it]Running loglikelihood requests:  21%|██        | 84/400 [02:44<05:44,  1.09s/it]Running loglikelihood requests:  21%|██▏       | 85/400 [02:45<05:54,  1.13s/it]Running loglikelihood requests:  22%|██▏       | 86/400 [02:46<06:02,  1.15s/it]Running loglikelihood requests:  22%|██▏       | 89/400 [02:48<03:52,  1.34it/s]Running loglikelihood requests:  22%|██▎       | 90/400 [02:49<04:21,  1.19it/s]Running loglikelihood requests:  23%|██▎       | 91/400 [02:50<04:46,  1.08it/s]Running loglikelihood requests:  23%|██▎       | 92/400 [02:51<05:06,  1.00it/s]Running loglikelihood requests:  23%|██▎       | 93/400 [02:52<05:22,  1.05s/it]Running loglikelihood requests:  24%|██▍       | 97/400 [02:54<03:02,  1.66it/s]Running loglikelihood requests:  24%|██▍       | 98/400 [02:55<03:32,  1.42it/s]Running loglikelihood requests:  25%|██▍       | 99/400 [02:56<04:00,  1.25it/s]Running loglikelihood requests:  25%|██▌       | 100/400 [02:57<04:25,  1.13it/s]Running loglikelihood requests:  25%|██▌       | 101/400 [02:58<04:46,  1.04it/s]Running loglikelihood requests:  26%|██▌       | 102/400 [03:00<05:01,  1.01s/it]Running loglikelihood requests:  26%|██▌       | 103/400 [03:01<05:13,  1.06s/it]Running loglikelihood requests:  26%|██▌       | 104/400 [03:02<05:22,  1.09s/it]Running loglikelihood requests:  26%|██▋       | 105/400 [03:03<05:27,  1.11s/it]Running loglikelihood requests:  26%|██▋       | 106/400 [03:04<05:30,  1.12s/it]Running loglikelihood requests:  27%|██▋       | 107/400 [03:05<05:32,  1.13s/it]Running loglikelihood requests:  27%|██▋       | 108/400 [03:07<05:36,  1.15s/it]Running loglikelihood requests:  27%|██▋       | 109/400 [03:08<05:38,  1.16s/it]Running loglikelihood requests:  28%|██▊       | 110/400 [03:09<05:35,  1.16s/it]Running loglikelihood requests:  28%|██▊       | 111/400 [03:10<05:36,  1.17s/it]Running loglikelihood requests:  28%|██▊       | 112/400 [03:11<05:36,  1.17s/it]Running loglikelihood requests:  28%|██▊       | 113/400 [03:12<05:31,  1.16s/it]Running loglikelihood requests:  28%|██▊       | 114/400 [03:13<05:28,  1.15s/it]Running loglikelihood requests:  29%|██▉       | 115/400 [03:15<05:27,  1.15s/it]Running loglikelihood requests:  29%|██▉       | 116/400 [03:16<05:23,  1.14s/it]Running loglikelihood requests:  29%|██▉       | 117/400 [03:17<05:19,  1.13s/it]Running loglikelihood requests:  30%|██▉       | 118/400 [03:18<05:14,  1.12s/it]Running loglikelihood requests:  30%|██▉       | 119/400 [03:19<05:11,  1.11s/it]Running loglikelihood requests:  30%|███       | 120/400 [03:20<05:25,  1.16s/it]Running loglikelihood requests:  30%|███       | 121/400 [03:21<05:20,  1.15s/it]Running loglikelihood requests:  30%|███       | 122/400 [03:23<05:13,  1.13s/it]Running loglikelihood requests:  31%|███       | 123/400 [03:24<05:10,  1.12s/it]Running loglikelihood requests:  31%|███       | 124/400 [03:25<05:08,  1.12s/it]Running loglikelihood requests:  31%|███▏      | 125/400 [03:26<05:03,  1.10s/it]Running loglikelihood requests:  32%|███▏      | 126/400 [03:27<05:01,  1.10s/it]Running loglikelihood requests:  32%|███▏      | 127/400 [03:28<04:57,  1.09s/it]Running loglikelihood requests:  32%|███▏      | 128/400 [03:29<04:53,  1.08s/it]Running loglikelihood requests:  32%|███▏      | 129/400 [03:30<04:49,  1.07s/it]Running loglikelihood requests:  32%|███▎      | 130/400 [03:31<04:47,  1.06s/it]Running loglikelihood requests:  33%|███▎      | 131/400 [03:32<04:44,  1.06s/it]Running loglikelihood requests:  34%|███▎      | 134/400 [03:33<02:55,  1.52it/s]Running loglikelihood requests:  34%|███▍      | 135/400 [03:34<03:15,  1.35it/s]Running loglikelihood requests:  34%|███▍      | 136/400 [03:35<03:33,  1.24it/s]Running loglikelihood requests:  34%|███▍      | 137/400 [03:36<03:47,  1.16it/s]Running loglikelihood requests:  34%|███▍      | 138/400 [03:37<03:58,  1.10it/s]Running loglikelihood requests:  35%|███▍      | 139/400 [03:38<04:05,  1.06it/s]Running loglikelihood requests:  36%|███▌      | 142/400 [03:39<02:39,  1.61it/s]Running loglikelihood requests:  36%|███▌      | 143/400 [03:40<03:01,  1.42it/s]Running loglikelihood requests:  36%|███▌      | 144/400 [03:41<03:19,  1.28it/s]Running loglikelihood requests:  36%|███▋      | 145/400 [03:42<03:34,  1.19it/s]Running loglikelihood requests:  36%|███▋      | 146/400 [03:44<03:45,  1.13it/s]Running loglikelihood requests:  37%|███▋      | 147/400 [03:45<03:54,  1.08it/s]Running loglikelihood requests:  37%|███▋      | 148/400 [03:46<04:00,  1.05it/s]Running loglikelihood requests:  37%|███▋      | 149/400 [03:47<04:03,  1.03it/s]Running loglikelihood requests:  38%|███▊      | 150/400 [03:48<04:05,  1.02it/s]Running loglikelihood requests:  38%|███▊      | 151/400 [03:49<04:06,  1.01it/s]Running loglikelihood requests:  38%|███▊      | 152/400 [03:50<04:07,  1.00it/s]Running loglikelihood requests:  38%|███▊      | 153/400 [03:51<04:07,  1.00s/it]Running loglikelihood requests:  38%|███▊      | 154/400 [03:52<04:06,  1.00s/it]Running loglikelihood requests:  39%|███▉      | 155/400 [03:53<04:05,  1.00s/it]Running loglikelihood requests:  39%|███▉      | 156/400 [03:54<04:04,  1.00s/it]Running loglikelihood requests:  39%|███▉      | 157/400 [03:55<04:03,  1.00s/it]Running loglikelihood requests:  40%|███▉      | 158/400 [03:56<04:02,  1.00s/it]Running loglikelihood requests:  40%|███▉      | 159/400 [03:57<04:01,  1.00s/it]Running loglikelihood requests:  40%|████      | 160/400 [03:58<03:59,  1.00it/s]Running loglikelihood requests:  40%|████      | 161/400 [03:59<03:58,  1.00it/s]Running loglikelihood requests:  40%|████      | 162/400 [04:00<03:56,  1.00it/s]Running loglikelihood requests:  41%|████      | 163/400 [04:01<03:55,  1.01it/s]Running loglikelihood requests:  41%|████      | 164/400 [04:02<03:53,  1.01it/s]Running loglikelihood requests:  41%|████▏     | 165/400 [04:03<03:51,  1.01it/s]Running loglikelihood requests:  42%|████▏     | 166/400 [04:04<03:49,  1.02it/s]Running loglikelihood requests:  42%|████▏     | 167/400 [04:05<03:48,  1.02it/s]Running loglikelihood requests:  42%|████▏     | 168/400 [04:06<03:47,  1.02it/s]Running loglikelihood requests:  42%|████▏     | 169/400 [04:06<03:45,  1.02it/s]Running loglikelihood requests:  42%|████▎     | 170/400 [04:07<03:43,  1.03it/s]Running loglikelihood requests:  43%|████▎     | 172/400 [04:08<02:50,  1.34it/s]Running loglikelihood requests:  43%|████▎     | 173/400 [04:09<03:00,  1.26it/s]Running loglikelihood requests:  44%|████▎     | 174/400 [04:10<03:07,  1.20it/s]Running loglikelihood requests:  44%|████▍     | 177/400 [04:11<02:03,  1.80it/s]Running loglikelihood requests:  44%|████▍     | 178/400 [04:12<02:20,  1.58it/s]Running loglikelihood requests:  45%|████▍     | 179/400 [04:13<02:34,  1.43it/s]Running loglikelihood requests:  45%|████▌     | 180/400 [04:14<02:45,  1.33it/s]Running loglikelihood requests:  45%|████▌     | 181/400 [04:15<02:53,  1.26it/s]Running loglikelihood requests:  46%|████▌     | 182/400 [04:16<02:59,  1.21it/s]Running loglikelihood requests:  46%|████▌     | 183/400 [04:17<03:03,  1.18it/s]Running loglikelihood requests:  46%|████▌     | 184/400 [04:18<03:05,  1.16it/s]Running loglikelihood requests:  46%|████▋     | 185/400 [04:19<03:07,  1.15it/s]Running loglikelihood requests:  46%|████▋     | 186/400 [04:19<03:08,  1.14it/s]Running loglikelihood requests:  47%|████▋     | 187/400 [04:20<03:08,  1.13it/s]Running loglikelihood requests:  47%|████▋     | 188/400 [04:21<03:08,  1.13it/s]Running loglikelihood requests:  47%|████▋     | 189/400 [04:22<03:07,  1.12it/s]Running loglikelihood requests:  48%|████▊     | 190/400 [04:23<03:06,  1.13it/s]Running loglikelihood requests:  48%|████▊     | 191/400 [04:24<03:05,  1.13it/s]Running loglikelihood requests:  48%|████▊     | 192/400 [04:25<03:03,  1.13it/s]Running loglikelihood requests:  48%|████▊     | 193/400 [04:26<03:04,  1.12it/s]Running loglikelihood requests:  48%|████▊     | 194/400 [04:27<03:02,  1.13it/s]Running loglikelihood requests:  49%|████▉     | 195/400 [04:27<03:00,  1.14it/s]Running loglikelihood requests:  49%|████▉     | 196/400 [04:28<03:01,  1.12it/s]Running loglikelihood requests:  49%|████▉     | 197/400 [04:29<02:58,  1.14it/s]Running loglikelihood requests:  50%|████▉     | 198/400 [04:30<02:55,  1.15it/s]Running loglikelihood requests:  50%|████▉     | 199/400 [04:31<02:53,  1.16it/s]Running loglikelihood requests:  50%|█████     | 200/400 [04:32<02:52,  1.16it/s]Running loglikelihood requests:  50%|█████     | 201/400 [04:33<02:50,  1.17it/s]Running loglikelihood requests:  50%|█████     | 202/400 [04:33<02:49,  1.17it/s]Running loglikelihood requests:  51%|█████     | 203/400 [04:34<02:47,  1.18it/s]Running loglikelihood requests:  51%|█████     | 204/400 [04:35<02:46,  1.18it/s]Running loglikelihood requests:  51%|█████▏    | 205/400 [04:36<02:45,  1.18it/s]Running loglikelihood requests:  52%|█████▏    | 206/400 [04:37<02:44,  1.18it/s]Running loglikelihood requests:  52%|█████▏    | 207/400 [04:38<02:43,  1.18it/s]Running loglikelihood requests:  52%|█████▏    | 208/400 [04:38<02:43,  1.18it/s]Running loglikelihood requests:  52%|█████▏    | 209/400 [04:39<02:44,  1.16it/s]Running loglikelihood requests:  53%|█████▎    | 212/400 [04:40<01:42,  1.84it/s]Running loglikelihood requests:  53%|█████▎    | 213/400 [04:41<01:53,  1.65it/s]Running loglikelihood requests:  54%|█████▎    | 214/400 [04:42<02:02,  1.51it/s]Running loglikelihood requests:  54%|█████▍    | 215/400 [04:43<02:10,  1.42it/s]Running loglikelihood requests:  54%|█████▍    | 216/400 [04:44<02:16,  1.35it/s]Running loglikelihood requests:  54%|█████▍    | 217/400 [04:44<02:20,  1.30it/s]Running loglikelihood requests:  55%|█████▍    | 218/400 [04:45<02:22,  1.27it/s]Running loglikelihood requests:  55%|█████▍    | 219/400 [04:46<02:26,  1.24it/s]Running loglikelihood requests:  55%|█████▌    | 220/400 [04:47<02:28,  1.21it/s]Running loglikelihood requests:  55%|█████▌    | 221/400 [04:48<02:27,  1.21it/s]Running loglikelihood requests:  56%|█████▌    | 222/400 [04:49<02:26,  1.22it/s]Running loglikelihood requests:  56%|█████▌    | 223/400 [04:50<02:27,  1.20it/s]Running loglikelihood requests:  56%|█████▌    | 224/400 [04:50<02:26,  1.20it/s]Running loglikelihood requests:  56%|█████▋    | 225/400 [04:51<02:25,  1.20it/s]Running loglikelihood requests:  56%|█████▋    | 226/400 [04:52<02:24,  1.20it/s]Running loglikelihood requests:  57%|█████▋    | 227/400 [04:53<02:33,  1.12it/s]Running loglikelihood requests:  57%|█████▋    | 228/400 [04:54<02:42,  1.06it/s]Running loglikelihood requests:  57%|█████▋    | 229/400 [04:55<03:02,  1.07s/it]Running loglikelihood requests:  57%|█████▊    | 230/400 [04:56<02:51,  1.01s/it]Running loglikelihood requests:  58%|█████▊    | 231/400 [04:57<02:39,  1.06it/s]Running loglikelihood requests:  58%|█████▊    | 232/400 [04:58<02:32,  1.10it/s]Running loglikelihood requests:  58%|█████▊    | 233/400 [04:59<02:26,  1.14it/s]Running loglikelihood requests:  58%|█████▊    | 234/400 [05:00<02:21,  1.17it/s]Running loglikelihood requests:  59%|█████▉    | 235/400 [05:00<02:18,  1.20it/s]Running loglikelihood requests:  59%|█████▉    | 236/400 [05:01<02:15,  1.21it/s]Running loglikelihood requests:  59%|█████▉    | 237/400 [05:02<02:13,  1.22it/s]Running loglikelihood requests:  60%|██████    | 240/400 [05:03<01:20,  1.98it/s]Running loglikelihood requests:  60%|██████    | 241/400 [05:04<01:29,  1.77it/s]Running loglikelihood requests:  60%|██████    | 242/400 [05:04<01:36,  1.63it/s]Running loglikelihood requests:  61%|██████    | 243/400 [05:05<01:42,  1.53it/s]Running loglikelihood requests:  61%|██████    | 244/400 [05:06<01:46,  1.46it/s]Running loglikelihood requests:  61%|██████▏   | 245/400 [05:07<01:49,  1.41it/s]Running loglikelihood requests:  62%|██████▏   | 246/400 [05:07<01:51,  1.38it/s]Running loglikelihood requests:  62%|██████▏   | 247/400 [05:08<01:53,  1.35it/s]Running loglikelihood requests:  62%|██████▏   | 248/400 [05:09<01:53,  1.34it/s]Running loglikelihood requests:  62%|██████▏   | 249/400 [05:10<01:54,  1.32it/s]Running loglikelihood requests:  62%|██████▎   | 250/400 [05:10<01:53,  1.32it/s]Running loglikelihood requests:  63%|██████▎   | 251/400 [05:11<01:53,  1.31it/s]Running loglikelihood requests:  63%|██████▎   | 252/400 [05:12<01:53,  1.31it/s]Running loglikelihood requests:  63%|██████▎   | 253/400 [05:13<01:51,  1.31it/s]Running loglikelihood requests:  64%|██████▎   | 254/400 [05:14<01:51,  1.31it/s]Running loglikelihood requests:  64%|██████▍   | 255/400 [05:14<01:50,  1.31it/s]Running loglikelihood requests:  64%|██████▍   | 256/400 [05:15<01:49,  1.31it/s]Running loglikelihood requests:  64%|██████▍   | 257/400 [05:16<01:48,  1.32it/s]Running loglikelihood requests:  64%|██████▍   | 258/400 [05:17<01:47,  1.32it/s]Running loglikelihood requests:  65%|██████▍   | 259/400 [05:17<01:46,  1.32it/s]Running loglikelihood requests:  65%|██████▌   | 260/400 [05:18<01:45,  1.33it/s]Running loglikelihood requests:  65%|██████▌   | 261/400 [05:19<01:42,  1.36it/s]Running loglikelihood requests:  66%|██████▌   | 262/400 [05:19<01:41,  1.37it/s]Running loglikelihood requests:  66%|██████▌   | 263/400 [05:20<01:39,  1.38it/s]Running loglikelihood requests:  66%|██████▌   | 264/400 [05:21<01:38,  1.38it/s]Running loglikelihood requests:  66%|██████▋   | 265/400 [05:22<01:35,  1.42it/s]Running loglikelihood requests:  66%|██████▋   | 266/400 [05:22<01:32,  1.44it/s]Running loglikelihood requests:  67%|██████▋   | 267/400 [05:23<01:30,  1.46it/s]Running loglikelihood requests:  67%|██████▋   | 268/400 [05:24<01:38,  1.34it/s]Running loglikelihood requests:  67%|██████▋   | 269/400 [05:24<01:34,  1.39it/s]Running loglikelihood requests:  68%|██████▊   | 270/400 [05:25<01:30,  1.44it/s]Running loglikelihood requests:  68%|██████▊   | 271/400 [05:26<01:27,  1.47it/s]Running loglikelihood requests:  68%|██████▊   | 272/400 [05:26<01:25,  1.50it/s]Running loglikelihood requests:  68%|██████▊   | 273/400 [05:27<01:22,  1.54it/s]Running loglikelihood requests:  68%|██████▊   | 274/400 [05:28<01:20,  1.57it/s]Running loglikelihood requests:  69%|██████▉   | 275/400 [05:28<01:18,  1.60it/s]Running loglikelihood requests:  69%|██████▉   | 276/400 [05:29<01:16,  1.61it/s]Running loglikelihood requests:  69%|██████▉   | 277/400 [05:29<01:16,  1.60it/s]Running loglikelihood requests:  70%|██████▉   | 278/400 [05:30<01:15,  1.62it/s]Running loglikelihood requests:  70%|██████▉   | 279/400 [05:31<01:13,  1.64it/s]Running loglikelihood requests:  70%|███████   | 280/400 [05:31<01:12,  1.65it/s]Running loglikelihood requests:  70%|███████   | 281/400 [05:32<01:11,  1.66it/s]Running loglikelihood requests:  70%|███████   | 282/400 [05:32<01:10,  1.67it/s]Running loglikelihood requests:  71%|███████   | 283/400 [05:33<01:09,  1.68it/s]Running loglikelihood requests:  71%|███████   | 284/400 [05:34<01:08,  1.69it/s]Running loglikelihood requests:  71%|███████▏  | 285/400 [05:34<01:08,  1.69it/s]Running loglikelihood requests:  72%|███████▏  | 286/400 [05:35<01:07,  1.70it/s]Running loglikelihood requests:  72%|███████▏  | 287/400 [05:35<01:06,  1.70it/s]Running loglikelihood requests:  72%|███████▏  | 288/400 [05:36<01:18,  1.43it/s]Running loglikelihood requests:  72%|███████▏  | 289/400 [05:37<01:22,  1.35it/s]Running loglikelihood requests:  72%|███████▎  | 290/400 [05:38<01:16,  1.44it/s]Running loglikelihood requests:  73%|███████▎  | 291/400 [05:38<01:12,  1.51it/s]Running loglikelihood requests:  73%|███████▎  | 292/400 [05:39<01:08,  1.57it/s]Running loglikelihood requests:  73%|███████▎  | 293/400 [05:39<01:06,  1.61it/s]Running loglikelihood requests:  74%|███████▎  | 294/400 [05:40<01:04,  1.64it/s]Running loglikelihood requests:  74%|███████▍  | 295/400 [05:41<01:09,  1.51it/s]Running loglikelihood requests:  74%|███████▍  | 296/400 [05:41<01:06,  1.56it/s]Running loglikelihood requests:  74%|███████▍  | 297/400 [05:42<01:03,  1.61it/s]Running loglikelihood requests:  74%|███████▍  | 298/400 [05:43<01:01,  1.65it/s]Running loglikelihood requests:  75%|███████▍  | 299/400 [05:43<01:00,  1.68it/s]Running loglikelihood requests:  75%|███████▌  | 300/400 [05:44<00:58,  1.70it/s]Running loglikelihood requests:  75%|███████▌  | 301/400 [05:44<00:57,  1.71it/s]Running loglikelihood requests:  76%|███████▌  | 302/400 [05:45<00:57,  1.72it/s]Running loglikelihood requests:  76%|███████▌  | 303/400 [05:45<00:56,  1.73it/s]Running loglikelihood requests:  76%|███████▌  | 304/400 [05:46<00:55,  1.74it/s]Running loglikelihood requests:  76%|███████▋  | 305/400 [05:47<00:54,  1.74it/s]Running loglikelihood requests:  76%|███████▋  | 306/400 [05:47<00:53,  1.75it/s]Running loglikelihood requests:  77%|███████▋  | 307/400 [05:48<00:53,  1.75it/s]Running loglikelihood requests:  78%|███████▊  | 310/400 [05:48<00:31,  2.82it/s]Running loglikelihood requests:  78%|███████▊  | 311/400 [05:49<00:35,  2.51it/s]Running loglikelihood requests:  78%|███████▊  | 312/400 [05:49<00:38,  2.29it/s]Running loglikelihood requests:  78%|███████▊  | 313/400 [05:50<00:40,  2.13it/s]Running loglikelihood requests:  78%|███████▊  | 314/400 [05:51<00:42,  2.02it/s]Running loglikelihood requests:  79%|███████▉  | 315/400 [05:51<00:44,  1.93it/s]Running loglikelihood requests:  79%|███████▉  | 316/400 [05:52<00:45,  1.84it/s]Running loglikelihood requests:  79%|███████▉  | 317/400 [05:52<00:45,  1.82it/s]Running loglikelihood requests:  80%|███████▉  | 318/400 [05:53<00:45,  1.80it/s]Running loglikelihood requests:  80%|███████▉  | 319/400 [05:53<00:44,  1.81it/s]Running loglikelihood requests:  80%|████████  | 321/400 [05:54<00:33,  2.36it/s]Running loglikelihood requests:  80%|████████  | 322/400 [05:54<00:35,  2.22it/s]Running loglikelihood requests:  81%|████████  | 323/400 [05:55<00:36,  2.11it/s]Running loglikelihood requests:  81%|████████  | 324/400 [05:56<00:37,  2.04it/s]Running loglikelihood requests:  81%|████████▏ | 325/400 [05:56<00:37,  1.99it/s]Running loglikelihood requests:  82%|████████▏ | 326/400 [05:57<00:37,  1.96it/s]Running loglikelihood requests:  82%|████████▏ | 327/400 [05:57<00:37,  1.94it/s]Running loglikelihood requests:  82%|████████▏ | 328/400 [05:58<00:37,  1.93it/s]Running loglikelihood requests:  82%|████████▏ | 329/400 [05:58<00:36,  1.93it/s]Running loglikelihood requests:  82%|████████▎ | 330/400 [05:59<00:36,  1.92it/s]Running loglikelihood requests:  83%|████████▎ | 331/400 [05:59<00:35,  1.92it/s]Running loglikelihood requests:  83%|████████▎ | 332/400 [06:00<00:35,  1.91it/s]Running loglikelihood requests:  83%|████████▎ | 333/400 [06:00<00:34,  1.93it/s]Running loglikelihood requests:  84%|████████▎ | 334/400 [06:01<00:33,  1.94it/s]Running loglikelihood requests:  84%|████████▍ | 335/400 [06:01<00:33,  1.92it/s]Running loglikelihood requests:  84%|████████▍ | 336/400 [06:02<00:32,  1.94it/s]Running loglikelihood requests:  84%|████████▍ | 337/400 [06:02<00:32,  1.95it/s]Running loglikelihood requests:  84%|████████▍ | 338/400 [06:03<00:31,  1.97it/s]Running loglikelihood requests:  85%|████████▍ | 339/400 [06:03<00:30,  1.98it/s]Running loglikelihood requests:  85%|████████▌ | 340/400 [06:04<00:30,  1.99it/s]Running loglikelihood requests:  85%|████████▌ | 341/400 [06:04<00:29,  1.99it/s]Running loglikelihood requests:  86%|████████▌ | 342/400 [06:05<00:29,  1.99it/s]Running loglikelihood requests:  86%|████████▌ | 343/400 [06:05<00:28,  1.99it/s]Running loglikelihood requests:  86%|████████▌ | 344/400 [06:06<00:28,  1.99it/s]Running loglikelihood requests:  86%|████████▋ | 345/400 [06:06<00:27,  2.00it/s]Running loglikelihood requests:  86%|████████▋ | 346/400 [06:07<00:26,  2.01it/s]Running loglikelihood requests:  87%|████████▋ | 347/400 [06:07<00:26,  2.01it/s]Running loglikelihood requests:  87%|████████▋ | 348/400 [06:08<00:25,  2.02it/s]Running loglikelihood requests:  87%|████████▋ | 349/400 [06:08<00:25,  2.02it/s]Running loglikelihood requests:  88%|████████▊ | 350/400 [06:09<00:24,  2.01it/s]Running loglikelihood requests:  88%|████████▊ | 351/400 [06:09<00:24,  2.02it/s]Running loglikelihood requests:  88%|████████▊ | 352/400 [06:10<00:23,  2.01it/s]Running loglikelihood requests:  88%|████████▊ | 353/400 [06:10<00:23,  2.02it/s]Running loglikelihood requests:  88%|████████▊ | 354/400 [06:11<00:22,  2.02it/s]Running loglikelihood requests:  89%|████████▉ | 355/400 [06:11<00:22,  2.02it/s]Running loglikelihood requests:  89%|████████▉ | 356/400 [06:12<00:21,  2.04it/s]Running loglikelihood requests:  89%|████████▉ | 357/400 [06:12<00:21,  2.04it/s]Running loglikelihood requests:  90%|████████▉ | 358/400 [06:13<00:20,  2.05it/s]Running loglikelihood requests:  90%|████████▉ | 359/400 [06:13<00:19,  2.05it/s]Running loglikelihood requests:  90%|█████████ | 360/400 [06:14<00:19,  2.05it/s]Running loglikelihood requests:  90%|█████████ | 361/400 [06:14<00:18,  2.06it/s]Running loglikelihood requests:  90%|█████████ | 362/400 [06:15<00:18,  2.06it/s]Running loglikelihood requests:  91%|█████████ | 363/400 [06:15<00:17,  2.06it/s]Running loglikelihood requests:  91%|█████████ | 364/400 [06:16<00:17,  2.07it/s]Running loglikelihood requests:  91%|█████████▏| 365/400 [06:16<00:16,  2.07it/s]Running loglikelihood requests:  92%|█████████▏| 366/400 [06:17<00:16,  2.07it/s]Running loglikelihood requests:  92%|█████████▏| 368/400 [06:17<00:11,  2.70it/s]Running loglikelihood requests:  92%|█████████▏| 369/400 [06:18<00:12,  2.52it/s]Running loglikelihood requests:  92%|█████████▎| 370/400 [06:18<00:12,  2.39it/s]Running loglikelihood requests:  93%|█████████▎| 371/400 [06:18<00:12,  2.30it/s]Running loglikelihood requests:  93%|█████████▎| 373/400 [06:19<00:09,  2.86it/s]Running loglikelihood requests:  94%|█████████▎| 374/400 [06:19<00:09,  2.63it/s]Running loglikelihood requests:  94%|█████████▍| 375/400 [06:20<00:10,  2.47it/s]Running loglikelihood requests:  94%|█████████▍| 376/400 [06:20<00:10,  2.37it/s]Running loglikelihood requests:  94%|█████████▍| 377/400 [06:21<00:09,  2.30it/s]Running loglikelihood requests:  94%|█████████▍| 378/400 [06:21<00:09,  2.26it/s]Running loglikelihood requests:  95%|█████████▍| 379/400 [06:22<00:09,  2.24it/s]Running loglikelihood requests:  95%|█████████▌| 380/400 [06:22<00:09,  2.21it/s]Running loglikelihood requests:  95%|█████████▌| 381/400 [06:23<00:08,  2.20it/s]Running loglikelihood requests:  96%|█████████▌| 382/400 [06:23<00:08,  2.20it/s]Running loglikelihood requests:  96%|█████████▌| 383/400 [06:24<00:07,  2.20it/s]Running loglikelihood requests:  96%|█████████▌| 384/400 [06:24<00:07,  2.21it/s]Running loglikelihood requests:  96%|█████████▋| 385/400 [06:25<00:06,  2.21it/s]Running loglikelihood requests:  96%|█████████▋| 386/400 [06:25<00:06,  2.21it/s]Running loglikelihood requests:  97%|█████████▋| 387/400 [06:25<00:05,  2.22it/s]Running loglikelihood requests:  97%|█████████▋| 388/400 [06:26<00:05,  2.22it/s]Running loglikelihood requests:  97%|█████████▋| 389/400 [06:26<00:04,  2.22it/s]Running loglikelihood requests:  98%|█████████▊| 390/400 [06:27<00:04,  2.23it/s]Running loglikelihood requests:  98%|█████████▊| 391/400 [06:27<00:04,  2.23it/s]Running loglikelihood requests:  98%|█████████▊| 392/400 [06:28<00:03,  2.24it/s]Running loglikelihood requests:  98%|█████████▊| 393/400 [06:28<00:03,  2.25it/s]Running loglikelihood requests:  98%|█████████▊| 394/400 [06:29<00:02,  2.25it/s]Running loglikelihood requests:  99%|█████████▉| 395/400 [06:29<00:02,  2.26it/s]Running loglikelihood requests:  99%|█████████▉| 396/400 [06:29<00:01,  2.26it/s]Running loglikelihood requests:  99%|█████████▉| 397/400 [06:30<00:01,  2.27it/s]Running loglikelihood requests: 100%|█████████▉| 398/400 [06:30<00:00,  2.27it/s]Running loglikelihood requests: 100%|█████████▉| 399/400 [06:31<00:00,  2.28it/s]Running loglikelihood requests: 100%|██████████| 400/400 [06:31<00:00,  2.29it/s]Running loglikelihood requests: 100%|██████████| 400/400 [06:31<00:00,  1.02it/s]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:2'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:2'}
full model:
{'sciq': {'alias': 'sciq', 'acc,none': 0.94, 'acc_stderr,none': 0.023868325657594204, 'acc_norm,none': 0.91, 'acc_norm_stderr,none': 0.028762349126466136}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.969062788859705
0.9024924890572922
0.7706109127217512
0.8221264026535647
0.9190490061886575
0.9866654579796295
0.6586322754204971
0.7962110384246164
0.8195614021629236
0.7124178311176441
0.787697814339696
0.7034455022322618
0.8136386046534271
0.8174990104652458
0.6784276389594894
0.8698440245672888
0.8886492811850213
0.6541737276411673
0.6560861559753316
0.8139845219953913
0.6714741870309046
0.6164364868717988
0.8331581872497299
0.9065420049234512
0.9246185715568276
0.7477515960551026
0.574165362968651
0.8586446364199891
0.8889771415746612
Total groups 70 exceeded the threshold, stopping comparison.
The group tensor is
[7, 3, 4, 2, 6, 1, 5, 0]
tensor([7, 3, 4, 2, 6, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 2, 5, 3, 4, 0, 7, 1]
tensor([6, 2, 5, 3, 4, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 3, 6, 2, 7, 1, 4, 0]
tensor([5, 3, 6, 2, 7, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 4, 2, 1, 3, 5, 1]
tensor([0, 0, 4, 2, 1, 3, 5, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 2, 3, 4, 5, 0, 1, 1]
tensor([0, 2, 3, 4, 5, 0, 1, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 1, 0, 2, 2, 3, 1]
tensor([0, 3, 1, 0, 2, 2, 3, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 3, 1, 1, 2, 2, 3, 0]
tensor([0, 3, 1, 1, 2, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 1, 1.0, 1.0, 1.0, 1.0, 1]
tensor([0, 0, 1, 1, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 2 to 4
done!
Normal merging for layer 5
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 6 to 9
done!
Normal merging for layer 10
tensor([0, 1])
tensor(0)
tensor([4, 7])
tensor(4)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 11 to 12
done!
Normal merging for layer 13
tensor([0, 5])
tensor(0)
tensor([6, 7])
tensor(6)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 14 to 19
done!
Normal merging for layer 20
tensor([0, 3])
tensor(0)
tensor([2, 7])
tensor(2)
tensor([4, 5])
tensor(4)
tensor([1, 6])
tensor(1)
done!
Normal merging for layer 21
tensor([0, 7])
tensor(0)
tensor([2, 3])
tensor(2)
tensor([4, 5])
tensor(4)
tensor([1, 6])
tensor(1)
done!
Cross-layer merge completed for layers 22 to 23
done!
Normal merging for layer 24
tensor([0, 1])
tensor(0)
tensor([2, 3, 4, 5, 6, 7])
tensor(2)
done!
Cross-layer merge completed for layers 25 to 31
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 7 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.2608 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 6 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

202
cuda:2
logiqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:58<00:58, 58.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:14<00:00, 33.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:14<00:00, 37.41s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/logiqa HTTP/1.1" 200 743
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/EleutherAI/logiqa/EleutherAI/logiqa.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): datasets-server.hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://datasets-server.hf-mirror.com:443 "GET /parquet?dataset=EleutherAI/logiqa HTTP/1.1" 302 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET / HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/EleutherAI/logiqa/EleutherAI/logiqa.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/logiqa/resolve/main/logiqa.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/logiqa/resolve/main/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/logiqa/resolve/main/README.md HTTP/1.1" 200 0
DEBUG:filelock:Attempting to acquire lock 139706765595504 on /public/home/zouyifei001/.cache/huggingface/modules/datasets_modules/datasets/EleutherAI--logiqa.lock
DEBUG:filelock:Lock 139706765595504 acquired on /public/home/zouyifei001/.cache/huggingface/modules/datasets_modules/datasets/EleutherAI--logiqa.lock
DEBUG:filelock:Attempting to release lock 139706765595504 on /public/home/zouyifei001/.cache/huggingface/modules/datasets_modules/datasets/EleutherAI--logiqa.lock
DEBUG:filelock:Lock 139706765595504 released on /public/home/zouyifei001/.cache/huggingface/modules/datasets_modules/datasets/EleutherAI--logiqa.lock
DEBUG:filelock:Attempting to acquire lock 139703946588000 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___logiqa_logiqa_0.0.1_5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81.lock
DEBUG:filelock:Lock 139703946588000 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___logiqa_logiqa_0.0.1_5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___logiqa/logiqa/0.0.1/5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81/dataset_info.json
DEBUG:filelock:Attempting to release lock 139703946588000 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___logiqa_logiqa_0.0.1_5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81.lock
DEBUG:filelock:Lock 139703946588000 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___logiqa_logiqa_0.0.1_5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81.lock
DEBUG:filelock:Attempting to acquire lock 139703006995728 on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___logiqa/logiqa/0.0.1/5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81_builder.lock
DEBUG:filelock:Lock 139703006995728 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___logiqa/logiqa/0.0.1/5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___logiqa/logiqa/0.0.1/5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81/dataset_info.json
DEBUG:filelock:Attempting to release lock 139703006995728 on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___logiqa/logiqa/0.0.1/5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81_builder.lock
DEBUG:filelock:Lock 139703006995728 released on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___logiqa/logiqa/0.0.1/5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of logiqa from None to 0
INFO:lm_eval.api.task:Building contexts for logiqa on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 3040.08it/s]
DEBUG:lm_eval.evaluator:Task: logiqa; number of requests on this rank: 400
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/400 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/400 [00:03<21:21,  3.21s/it]Running loglikelihood requests:   0%|          | 2/400 [00:05<18:11,  2.74s/it]Running loglikelihood requests:   1%|          | 3/400 [00:07<16:58,  2.56s/it]Running loglikelihood requests:   1%|          | 4/400 [00:10<16:17,  2.47s/it]Running loglikelihood requests:   1%|▏         | 5/400 [00:12<15:48,  2.40s/it]Running loglikelihood requests:   2%|▏         | 6/400 [00:14<15:29,  2.36s/it]Running loglikelihood requests:   2%|▏         | 7/400 [00:17<15:16,  2.33s/it]Running loglikelihood requests:   2%|▏         | 8/400 [00:19<15:05,  2.31s/it]Running loglikelihood requests:   2%|▏         | 9/400 [00:21<14:54,  2.29s/it]Running loglikelihood requests:   2%|▎         | 10/400 [00:23<14:44,  2.27s/it]Running loglikelihood requests:   3%|▎         | 11/400 [00:26<14:35,  2.25s/it]Running loglikelihood requests:   3%|▎         | 12/400 [00:28<14:19,  2.22s/it]Running loglikelihood requests:   3%|▎         | 13/400 [00:30<14:06,  2.19s/it]Running loglikelihood requests:   4%|▎         | 14/400 [00:32<13:56,  2.17s/it]Running loglikelihood requests:   4%|▍         | 15/400 [00:34<13:50,  2.16s/it]Running loglikelihood requests:   4%|▍         | 16/400 [00:36<13:44,  2.15s/it]Running loglikelihood requests:   4%|▍         | 17/400 [00:38<13:40,  2.14s/it]Running loglikelihood requests:   4%|▍         | 18/400 [00:40<13:35,  2.13s/it]Running loglikelihood requests:   5%|▍         | 19/400 [00:43<13:28,  2.12s/it]Running loglikelihood requests:   5%|▌         | 20/400 [00:45<13:23,  2.11s/it]Running loglikelihood requests:   5%|▌         | 21/400 [00:47<13:16,  2.10s/it]Running loglikelihood requests:   6%|▌         | 22/400 [00:49<13:11,  2.10s/it]Running loglikelihood requests:   6%|▌         | 23/400 [00:51<13:06,  2.09s/it]Running loglikelihood requests:   6%|▌         | 24/400 [00:53<13:02,  2.08s/it]Running loglikelihood requests:   6%|▋         | 25/400 [00:55<12:56,  2.07s/it]Running loglikelihood requests:   6%|▋         | 26/400 [00:57<12:55,  2.07s/it]Running loglikelihood requests:   7%|▋         | 27/400 [00:59<12:50,  2.06s/it]Running loglikelihood requests:   7%|▋         | 28/400 [01:01<12:43,  2.05s/it]Running loglikelihood requests:   7%|▋         | 29/400 [01:03<12:35,  2.04s/it]Running loglikelihood requests:   8%|▊         | 30/400 [01:05<12:30,  2.03s/it]Running loglikelihood requests:   8%|▊         | 31/400 [01:07<12:26,  2.02s/it]Running loglikelihood requests:   8%|▊         | 32/400 [01:09<12:23,  2.02s/it]Running loglikelihood requests:   8%|▊         | 33/400 [01:11<12:18,  2.01s/it]Running loglikelihood requests:   8%|▊         | 34/400 [01:13<12:13,  2.00s/it]Running loglikelihood requests:   9%|▉         | 35/400 [01:15<12:08,  2.00s/it]Running loglikelihood requests:   9%|▉         | 36/400 [01:17<12:05,  1.99s/it]Running loglikelihood requests:   9%|▉         | 37/400 [01:19<11:58,  1.98s/it]Running loglikelihood requests:  10%|▉         | 38/400 [01:21<11:53,  1.97s/it]Running loglikelihood requests:  10%|▉         | 39/400 [01:23<11:47,  1.96s/it]Running loglikelihood requests:  10%|█         | 40/400 [01:25<11:42,  1.95s/it]Running loglikelihood requests:  10%|█         | 41/400 [01:27<11:37,  1.94s/it]Running loglikelihood requests:  10%|█         | 42/400 [01:29<11:33,  1.94s/it]Running loglikelihood requests:  11%|█         | 43/400 [01:31<11:29,  1.93s/it]Running loglikelihood requests:  11%|█         | 44/400 [01:33<11:26,  1.93s/it]Running loglikelihood requests:  11%|█▏        | 45/400 [01:34<11:23,  1.93s/it]Running loglikelihood requests:  12%|█▏        | 46/400 [01:36<11:19,  1.92s/it]Running loglikelihood requests:  12%|█▏        | 47/400 [01:38<11:15,  1.91s/it]Running loglikelihood requests:  12%|█▏        | 48/400 [01:40<11:11,  1.91s/it]Running loglikelihood requests:  12%|█▏        | 49/400 [01:42<11:08,  1.90s/it]Running loglikelihood requests:  12%|█▎        | 50/400 [01:44<11:05,  1.90s/it]Running loglikelihood requests:  13%|█▎        | 51/400 [01:46<11:02,  1.90s/it]Running loglikelihood requests:  13%|█▎        | 52/400 [01:48<10:59,  1.90s/it]Running loglikelihood requests:  13%|█▎        | 53/400 [01:50<10:59,  1.90s/it]Running loglikelihood requests:  14%|█▎        | 54/400 [01:52<10:54,  1.89s/it]Running loglikelihood requests:  14%|█▍        | 55/400 [01:53<10:55,  1.90s/it]Running loglikelihood requests:  14%|█▍        | 56/400 [01:55<10:52,  1.90s/it]Running loglikelihood requests:  14%|█▍        | 57/400 [01:57<10:47,  1.89s/it]Running loglikelihood requests:  14%|█▍        | 58/400 [01:59<10:43,  1.88s/it]Running loglikelihood requests:  15%|█▍        | 59/400 [02:01<10:40,  1.88s/it]Running loglikelihood requests:  15%|█▌        | 60/400 [02:03<10:37,  1.87s/it]Running loglikelihood requests:  15%|█▌        | 61/400 [02:05<10:31,  1.86s/it]Running loglikelihood requests:  16%|█▌        | 62/400 [02:06<10:25,  1.85s/it]Running loglikelihood requests:  16%|█▌        | 63/400 [02:08<10:20,  1.84s/it]Running loglikelihood requests:  16%|█▌        | 64/400 [02:10<10:15,  1.83s/it]Running loglikelihood requests:  16%|█▋        | 65/400 [02:12<10:10,  1.82s/it]Running loglikelihood requests:  16%|█▋        | 66/400 [02:14<10:06,  1.82s/it]Running loglikelihood requests:  17%|█▋        | 67/400 [02:15<10:01,  1.81s/it]Running loglikelihood requests:  17%|█▋        | 68/400 [02:17<09:56,  1.80s/it]Running loglikelihood requests:  17%|█▋        | 69/400 [02:19<09:52,  1.79s/it]Running loglikelihood requests:  18%|█▊        | 70/400 [02:21<09:48,  1.78s/it]Running loglikelihood requests:  18%|█▊        | 71/400 [02:23<09:45,  1.78s/it]Running loglikelihood requests:  18%|█▊        | 72/400 [02:24<09:40,  1.77s/it]Running loglikelihood requests:  18%|█▊        | 73/400 [02:26<09:35,  1.76s/it]Running loglikelihood requests:  18%|█▊        | 74/400 [02:28<09:30,  1.75s/it]Running loglikelihood requests:  19%|█▉        | 75/400 [02:30<09:26,  1.74s/it]Running loglikelihood requests:  19%|█▉        | 76/400 [02:31<09:21,  1.73s/it]Running loglikelihood requests:  19%|█▉        | 77/400 [02:33<09:16,  1.72s/it]Running loglikelihood requests:  20%|█▉        | 78/400 [02:35<09:12,  1.72s/it]Running loglikelihood requests:  20%|█▉        | 79/400 [02:36<09:07,  1.70s/it]Running loglikelihood requests:  20%|██        | 80/400 [02:38<09:02,  1.70s/it]Running loglikelihood requests:  20%|██        | 81/400 [02:40<08:58,  1.69s/it]Running loglikelihood requests:  20%|██        | 82/400 [02:41<08:53,  1.68s/it]Running loglikelihood requests:  21%|██        | 83/400 [02:43<08:49,  1.67s/it]Running loglikelihood requests:  21%|██        | 84/400 [02:45<08:46,  1.67s/it]Running loglikelihood requests:  21%|██▏       | 85/400 [02:46<08:42,  1.66s/it]Running loglikelihood requests:  22%|██▏       | 86/400 [02:48<08:38,  1.65s/it]Running loglikelihood requests:  22%|██▏       | 87/400 [02:50<08:36,  1.65s/it]Running loglikelihood requests:  22%|██▏       | 88/400 [02:51<08:33,  1.65s/it]Running loglikelihood requests:  22%|██▏       | 89/400 [02:53<08:31,  1.65s/it]Running loglikelihood requests:  22%|██▎       | 90/400 [02:54<08:30,  1.65s/it]Running loglikelihood requests:  23%|██▎       | 91/400 [02:56<08:28,  1.64s/it]Running loglikelihood requests:  23%|██▎       | 92/400 [02:58<08:26,  1.64s/it]Running loglikelihood requests:  23%|██▎       | 93/400 [02:59<08:23,  1.64s/it]Running loglikelihood requests:  24%|██▎       | 94/400 [03:01<08:21,  1.64s/it]Running loglikelihood requests:  24%|██▍       | 95/400 [03:03<08:19,  1.64s/it]Running loglikelihood requests:  24%|██▍       | 96/400 [03:04<08:16,  1.63s/it]Running loglikelihood requests:  24%|██▍       | 97/400 [03:06<08:13,  1.63s/it]Running loglikelihood requests:  24%|██▍       | 98/400 [03:07<08:11,  1.63s/it]Running loglikelihood requests:  25%|██▍       | 99/400 [03:09<08:11,  1.63s/it]Running loglikelihood requests:  25%|██▌       | 100/400 [03:11<08:06,  1.62s/it]Running loglikelihood requests:  25%|██▌       | 101/400 [03:12<08:03,  1.62s/it]Running loglikelihood requests:  26%|██▌       | 102/400 [03:14<08:00,  1.61s/it]Running loglikelihood requests:  26%|██▌       | 103/400 [03:16<07:56,  1.60s/it]Running loglikelihood requests:  26%|██▌       | 104/400 [03:17<07:53,  1.60s/it]Running loglikelihood requests:  26%|██▋       | 105/400 [03:19<07:52,  1.60s/it]Running loglikelihood requests:  26%|██▋       | 106/400 [03:20<07:51,  1.60s/it]Running loglikelihood requests:  27%|██▋       | 107/400 [03:22<07:50,  1.61s/it]Running loglikelihood requests:  27%|██▋       | 108/400 [03:24<07:50,  1.61s/it]Running loglikelihood requests:  27%|██▋       | 109/400 [03:25<07:47,  1.61s/it]Running loglikelihood requests:  28%|██▊       | 110/400 [03:27<07:44,  1.60s/it]Running loglikelihood requests:  28%|██▊       | 111/400 [03:28<07:41,  1.60s/it]Running loglikelihood requests:  28%|██▊       | 112/400 [03:30<07:39,  1.59s/it]Running loglikelihood requests:  28%|██▊       | 113/400 [03:32<07:36,  1.59s/it]Running loglikelihood requests:  28%|██▊       | 114/400 [03:33<07:34,  1.59s/it]Running loglikelihood requests:  29%|██▉       | 115/400 [03:35<07:31,  1.59s/it]Running loglikelihood requests:  29%|██▉       | 116/400 [03:36<07:29,  1.58s/it]Running loglikelihood requests:  29%|██▉       | 117/400 [03:38<07:27,  1.58s/it]Running loglikelihood requests:  30%|██▉       | 118/400 [03:39<07:23,  1.57s/it]Running loglikelihood requests:  30%|██▉       | 119/400 [03:41<07:21,  1.57s/it]Running loglikelihood requests:  30%|███       | 120/400 [03:42<07:18,  1.56s/it]Running loglikelihood requests:  30%|███       | 121/400 [03:44<07:16,  1.56s/it]Running loglikelihood requests:  30%|███       | 122/400 [03:46<07:13,  1.56s/it]Running loglikelihood requests:  31%|███       | 123/400 [03:47<07:13,  1.57s/it]Running loglikelihood requests:  31%|███       | 124/400 [03:49<07:09,  1.56s/it]Running loglikelihood requests:  31%|███▏      | 125/400 [03:50<07:07,  1.55s/it]Running loglikelihood requests:  32%|███▏      | 126/400 [03:52<07:05,  1.55s/it]Running loglikelihood requests:  32%|███▏      | 127/400 [03:53<07:02,  1.55s/it]Running loglikelihood requests:  32%|███▏      | 128/400 [03:55<07:00,  1.55s/it]Running loglikelihood requests:  32%|███▏      | 129/400 [03:56<06:58,  1.54s/it]Running loglikelihood requests:  32%|███▎      | 130/400 [03:58<06:54,  1.54s/it]Running loglikelihood requests:  33%|███▎      | 131/400 [03:59<06:51,  1.53s/it]Running loglikelihood requests:  33%|███▎      | 132/400 [04:01<06:49,  1.53s/it]Running loglikelihood requests:  33%|███▎      | 133/400 [04:03<06:46,  1.52s/it]Running loglikelihood requests:  34%|███▎      | 134/400 [04:04<06:46,  1.53s/it]Running loglikelihood requests:  34%|███▍      | 135/400 [04:06<06:44,  1.53s/it]Running loglikelihood requests:  34%|███▍      | 136/400 [04:07<06:43,  1.53s/it]Running loglikelihood requests:  34%|███▍      | 137/400 [04:09<06:43,  1.54s/it]Running loglikelihood requests:  34%|███▍      | 138/400 [04:10<06:41,  1.53s/it]Running loglikelihood requests:  35%|███▍      | 139/400 [04:12<06:41,  1.54s/it]Running loglikelihood requests:  35%|███▌      | 140/400 [04:13<06:40,  1.54s/it]Running loglikelihood requests:  36%|███▌      | 142/400 [04:15<05:03,  1.18s/it]Running loglikelihood requests:  36%|███▌      | 143/400 [04:16<05:23,  1.26s/it]Running loglikelihood requests:  36%|███▌      | 144/400 [04:18<05:38,  1.32s/it]Running loglikelihood requests:  36%|███▋      | 145/400 [04:19<05:52,  1.38s/it]Running loglikelihood requests:  36%|███▋      | 146/400 [04:21<06:05,  1.44s/it]Running loglikelihood requests:  37%|███▋      | 147/400 [04:22<06:08,  1.46s/it]Running loglikelihood requests:  37%|███▋      | 148/400 [04:24<06:10,  1.47s/it]Running loglikelihood requests:  37%|███▋      | 149/400 [04:25<06:10,  1.48s/it]Running loglikelihood requests:  38%|███▊      | 150/400 [04:27<06:10,  1.48s/it]Running loglikelihood requests:  38%|███▊      | 151/400 [04:28<06:11,  1.49s/it]Running loglikelihood requests:  38%|███▊      | 152/400 [04:30<06:11,  1.50s/it]Running loglikelihood requests:  38%|███▊      | 153/400 [04:31<06:10,  1.50s/it]Running loglikelihood requests:  38%|███▊      | 154/400 [04:33<06:10,  1.50s/it]Running loglikelihood requests:  39%|███▉      | 155/400 [04:34<06:08,  1.51s/it]Running loglikelihood requests:  39%|███▉      | 156/400 [04:36<06:08,  1.51s/it]Running loglikelihood requests:  39%|███▉      | 157/400 [04:37<06:06,  1.51s/it]Running loglikelihood requests:  40%|███▉      | 158/400 [04:39<06:03,  1.50s/it]Running loglikelihood requests:  40%|███▉      | 159/400 [04:40<06:02,  1.50s/it]Running loglikelihood requests:  40%|████      | 160/400 [04:42<05:59,  1.50s/it]Running loglikelihood requests:  40%|████      | 161/400 [04:43<05:58,  1.50s/it]Running loglikelihood requests:  40%|████      | 162/400 [04:45<05:56,  1.50s/it]Running loglikelihood requests:  41%|████      | 163/400 [04:46<05:55,  1.50s/it]Running loglikelihood requests:  41%|████      | 164/400 [04:48<05:53,  1.50s/it]Running loglikelihood requests:  41%|████▏     | 165/400 [04:49<05:51,  1.50s/it]Running loglikelihood requests:  42%|████▏     | 166/400 [04:51<05:49,  1.50s/it]Running loglikelihood requests:  42%|████▏     | 167/400 [04:52<05:47,  1.49s/it]Running loglikelihood requests:  42%|████▏     | 168/400 [04:54<05:46,  1.49s/it]Running loglikelihood requests:  42%|████▏     | 169/400 [04:55<05:44,  1.49s/it]Running loglikelihood requests:  42%|████▎     | 170/400 [04:57<05:42,  1.49s/it]Running loglikelihood requests:  43%|████▎     | 171/400 [04:58<05:40,  1.49s/it]Running loglikelihood requests:  43%|████▎     | 172/400 [05:00<05:38,  1.48s/it]Running loglikelihood requests:  43%|████▎     | 173/400 [05:01<05:36,  1.48s/it]Running loglikelihood requests:  44%|████▎     | 174/400 [05:03<05:34,  1.48s/it]Running loglikelihood requests:  44%|████▍     | 175/400 [05:04<05:33,  1.48s/it]Running loglikelihood requests:  44%|████▍     | 176/400 [05:06<05:31,  1.48s/it]Running loglikelihood requests:  44%|████▍     | 177/400 [05:07<05:28,  1.47s/it]Running loglikelihood requests:  44%|████▍     | 178/400 [05:09<05:25,  1.47s/it]Running loglikelihood requests:  45%|████▍     | 179/400 [05:10<05:23,  1.46s/it]Running loglikelihood requests:  45%|████▌     | 180/400 [05:12<05:20,  1.46s/it]Running loglikelihood requests:  45%|████▌     | 181/400 [05:13<05:18,  1.45s/it]Running loglikelihood requests:  46%|████▌     | 182/400 [05:14<05:16,  1.45s/it]Running loglikelihood requests:  46%|████▌     | 183/400 [05:16<05:14,  1.45s/it]Running loglikelihood requests:  46%|████▌     | 184/400 [05:17<05:12,  1.45s/it]Running loglikelihood requests:  46%|████▋     | 185/400 [05:19<05:10,  1.44s/it]Running loglikelihood requests:  46%|████▋     | 186/400 [05:20<05:07,  1.44s/it]Running loglikelihood requests:  47%|████▋     | 187/400 [05:22<05:05,  1.44s/it]Running loglikelihood requests:  47%|████▋     | 188/400 [05:23<05:03,  1.43s/it]Running loglikelihood requests:  47%|████▋     | 189/400 [05:24<05:01,  1.43s/it]Running loglikelihood requests:  48%|████▊     | 190/400 [05:26<04:59,  1.43s/it]Running loglikelihood requests:  48%|████▊     | 191/400 [05:27<04:57,  1.43s/it]Running loglikelihood requests:  48%|████▊     | 192/400 [05:29<04:56,  1.43s/it]Running loglikelihood requests:  48%|████▊     | 193/400 [05:30<04:54,  1.42s/it]Running loglikelihood requests:  48%|████▊     | 194/400 [05:32<04:52,  1.42s/it]Running loglikelihood requests:  49%|████▉     | 195/400 [05:33<04:50,  1.42s/it]Running loglikelihood requests:  49%|████▉     | 196/400 [05:34<04:48,  1.41s/it]Running loglikelihood requests:  49%|████▉     | 197/400 [05:36<04:45,  1.41s/it]Running loglikelihood requests:  50%|████▉     | 198/400 [05:37<04:44,  1.41s/it]Running loglikelihood requests:  50%|████▉     | 199/400 [05:39<04:42,  1.41s/it]Running loglikelihood requests:  50%|█████     | 200/400 [05:40<04:43,  1.42s/it]Running loglikelihood requests:  50%|█████     | 201/400 [05:42<04:44,  1.43s/it]Running loglikelihood requests:  50%|█████     | 202/400 [05:43<04:40,  1.42s/it]Running loglikelihood requests:  51%|█████     | 203/400 [05:44<04:45,  1.45s/it]Running loglikelihood requests:  51%|█████     | 204/400 [05:46<04:41,  1.44s/it]Running loglikelihood requests:  51%|█████▏    | 205/400 [05:47<04:37,  1.42s/it]Running loglikelihood requests:  52%|█████▏    | 206/400 [05:49<04:34,  1.41s/it]Running loglikelihood requests:  52%|█████▏    | 207/400 [05:50<04:31,  1.41s/it]Running loglikelihood requests:  52%|█████▏    | 208/400 [05:51<04:28,  1.40s/it]Running loglikelihood requests:  52%|█████▏    | 209/400 [05:53<04:26,  1.40s/it]Running loglikelihood requests:  52%|█████▎    | 210/400 [05:54<04:24,  1.39s/it]Running loglikelihood requests:  53%|█████▎    | 211/400 [05:56<04:23,  1.39s/it]Running loglikelihood requests:  53%|█████▎    | 212/400 [05:57<04:21,  1.39s/it]Running loglikelihood requests:  53%|█████▎    | 213/400 [05:58<04:20,  1.39s/it]Running loglikelihood requests:  54%|█████▎    | 214/400 [06:00<04:18,  1.39s/it]Running loglikelihood requests:  54%|█████▍    | 215/400 [06:01<04:16,  1.39s/it]Running loglikelihood requests:  54%|█████▍    | 216/400 [06:02<04:14,  1.38s/it]Running loglikelihood requests:  54%|█████▍    | 217/400 [06:04<04:13,  1.38s/it]Running loglikelihood requests:  55%|█████▍    | 218/400 [06:05<04:11,  1.38s/it]Running loglikelihood requests:  55%|█████▍    | 219/400 [06:07<04:12,  1.40s/it]Running loglikelihood requests:  55%|█████▌    | 220/400 [06:08<04:11,  1.40s/it]Running loglikelihood requests:  55%|█████▌    | 221/400 [06:09<04:11,  1.40s/it]Running loglikelihood requests:  56%|█████▌    | 222/400 [06:11<04:09,  1.40s/it]Running loglikelihood requests:  56%|█████▌    | 223/400 [06:12<04:07,  1.40s/it]Running loglikelihood requests:  56%|█████▌    | 224/400 [06:14<04:05,  1.40s/it]Running loglikelihood requests:  56%|█████▋    | 225/400 [06:15<04:04,  1.40s/it]Running loglikelihood requests:  56%|█████▋    | 226/400 [06:16<04:02,  1.39s/it]Running loglikelihood requests:  57%|█████▋    | 227/400 [06:18<04:01,  1.39s/it]Running loglikelihood requests:  57%|█████▋    | 228/400 [06:19<03:59,  1.39s/it]Running loglikelihood requests:  57%|█████▋    | 229/400 [06:21<03:57,  1.39s/it]Running loglikelihood requests:  57%|█████▊    | 230/400 [06:22<03:56,  1.39s/it]Running loglikelihood requests:  58%|█████▊    | 231/400 [06:23<03:54,  1.39s/it]Running loglikelihood requests:  58%|█████▊    | 232/400 [06:25<03:52,  1.39s/it]Running loglikelihood requests:  58%|█████▊    | 233/400 [06:26<03:51,  1.38s/it]Running loglikelihood requests:  58%|█████▊    | 234/400 [06:28<03:49,  1.38s/it]Running loglikelihood requests:  59%|█████▉    | 235/400 [06:29<03:47,  1.38s/it]Running loglikelihood requests:  59%|█████▉    | 236/400 [06:30<03:45,  1.38s/it]Running loglikelihood requests:  59%|█████▉    | 237/400 [06:32<03:45,  1.38s/it]Running loglikelihood requests:  60%|█████▉    | 238/400 [06:33<03:42,  1.38s/it]Running loglikelihood requests:  60%|█████▉    | 239/400 [06:34<03:40,  1.37s/it]Running loglikelihood requests:  60%|██████    | 240/400 [06:36<03:38,  1.36s/it]Running loglikelihood requests:  60%|██████    | 241/400 [06:37<03:36,  1.36s/it]Running loglikelihood requests:  60%|██████    | 242/400 [06:38<03:34,  1.36s/it]Running loglikelihood requests:  61%|██████    | 243/400 [06:40<03:32,  1.36s/it]Running loglikelihood requests:  61%|██████    | 244/400 [06:41<03:31,  1.35s/it]Running loglikelihood requests:  61%|██████▏   | 245/400 [06:42<03:29,  1.35s/it]Running loglikelihood requests:  62%|██████▏   | 246/400 [06:44<03:28,  1.35s/it]Running loglikelihood requests:  62%|██████▏   | 247/400 [06:45<03:27,  1.35s/it]Running loglikelihood requests:  62%|██████▏   | 248/400 [06:47<03:25,  1.35s/it]Running loglikelihood requests:  62%|██████▏   | 249/400 [06:48<03:23,  1.35s/it]Running loglikelihood requests:  62%|██████▎   | 250/400 [06:49<03:21,  1.35s/it]Running loglikelihood requests:  63%|██████▎   | 251/400 [06:51<03:20,  1.34s/it]Running loglikelihood requests:  63%|██████▎   | 252/400 [06:52<03:18,  1.34s/it]Running loglikelihood requests:  63%|██████▎   | 253/400 [06:53<03:17,  1.34s/it]Running loglikelihood requests:  64%|██████▎   | 254/400 [06:55<03:17,  1.35s/it]Running loglikelihood requests:  64%|██████▍   | 255/400 [06:56<03:14,  1.34s/it]Running loglikelihood requests:  64%|██████▍   | 256/400 [06:57<03:14,  1.35s/it]Running loglikelihood requests:  64%|██████▍   | 257/400 [06:59<03:13,  1.35s/it]Running loglikelihood requests:  64%|██████▍   | 258/400 [07:00<03:11,  1.35s/it]Running loglikelihood requests:  65%|██████▍   | 259/400 [07:01<03:10,  1.35s/it]Running loglikelihood requests:  65%|██████▌   | 260/400 [07:03<03:09,  1.35s/it]Running loglikelihood requests:  65%|██████▌   | 261/400 [07:04<03:08,  1.35s/it]Running loglikelihood requests:  66%|██████▌   | 262/400 [07:05<03:06,  1.35s/it]Running loglikelihood requests:  66%|██████▌   | 263/400 [07:07<03:04,  1.34s/it]Running loglikelihood requests:  66%|██████▌   | 264/400 [07:08<03:02,  1.34s/it]Running loglikelihood requests:  66%|██████▋   | 265/400 [07:09<03:00,  1.34s/it]Running loglikelihood requests:  66%|██████▋   | 266/400 [07:11<02:59,  1.34s/it]Running loglikelihood requests:  67%|██████▋   | 267/400 [07:12<02:57,  1.33s/it]Running loglikelihood requests:  67%|██████▋   | 268/400 [07:13<02:55,  1.33s/it]Running loglikelihood requests:  67%|██████▋   | 269/400 [07:15<02:54,  1.33s/it]Running loglikelihood requests:  68%|██████▊   | 270/400 [07:16<02:52,  1.33s/it]Running loglikelihood requests:  68%|██████▊   | 271/400 [07:17<02:51,  1.33s/it]Running loglikelihood requests:  68%|██████▊   | 272/400 [07:19<03:07,  1.46s/it]Running loglikelihood requests:  68%|██████▊   | 273/400 [07:21<03:02,  1.44s/it]Running loglikelihood requests:  68%|██████▊   | 274/400 [07:22<02:56,  1.40s/it]Running loglikelihood requests:  69%|██████▉   | 275/400 [07:23<02:51,  1.37s/it]Running loglikelihood requests:  69%|██████▉   | 276/400 [07:24<02:47,  1.35s/it]Running loglikelihood requests:  69%|██████▉   | 277/400 [07:26<02:44,  1.34s/it]Running loglikelihood requests:  70%|██████▉   | 278/400 [07:27<02:41,  1.32s/it]Running loglikelihood requests:  70%|███████   | 280/400 [07:28<02:01,  1.01s/it]Running loglikelihood requests:  70%|███████   | 281/400 [07:30<02:09,  1.08s/it]Running loglikelihood requests:  70%|███████   | 282/400 [07:31<02:14,  1.14s/it]Running loglikelihood requests:  71%|███████   | 283/400 [07:32<02:18,  1.18s/it]Running loglikelihood requests:  71%|███████   | 284/400 [07:34<02:20,  1.21s/it]Running loglikelihood requests:  71%|███████▏  | 285/400 [07:35<02:21,  1.23s/it]Running loglikelihood requests:  72%|███████▏  | 286/400 [07:36<02:22,  1.25s/it]Running loglikelihood requests:  72%|███████▏  | 287/400 [07:37<02:22,  1.26s/it]Running loglikelihood requests:  72%|███████▏  | 288/400 [07:39<02:22,  1.27s/it]Running loglikelihood requests:  72%|███████▏  | 289/400 [07:40<02:20,  1.27s/it]Running loglikelihood requests:  72%|███████▎  | 290/400 [07:41<02:19,  1.27s/it]Running loglikelihood requests:  73%|███████▎  | 291/400 [07:42<02:17,  1.26s/it]Running loglikelihood requests:  73%|███████▎  | 292/400 [07:44<02:16,  1.27s/it]Running loglikelihood requests:  73%|███████▎  | 293/400 [07:45<02:15,  1.27s/it]Running loglikelihood requests:  74%|███████▎  | 294/400 [07:46<02:13,  1.26s/it]Running loglikelihood requests:  74%|███████▍  | 295/400 [07:48<02:12,  1.26s/it]Running loglikelihood requests:  74%|███████▍  | 296/400 [07:49<02:10,  1.26s/it]Running loglikelihood requests:  74%|███████▍  | 297/400 [07:50<02:09,  1.26s/it]Running loglikelihood requests:  74%|███████▍  | 298/400 [07:51<02:07,  1.25s/it]Running loglikelihood requests:  75%|███████▍  | 299/400 [07:53<02:06,  1.25s/it]Running loglikelihood requests:  75%|███████▌  | 300/400 [07:54<02:05,  1.25s/it]Running loglikelihood requests:  75%|███████▌  | 301/400 [07:55<02:03,  1.25s/it]Running loglikelihood requests:  76%|███████▌  | 302/400 [07:56<02:01,  1.24s/it]Running loglikelihood requests:  76%|███████▌  | 303/400 [07:57<02:00,  1.24s/it]Running loglikelihood requests:  76%|███████▌  | 304/400 [07:59<01:59,  1.24s/it]Running loglikelihood requests:  76%|███████▋  | 305/400 [08:00<01:57,  1.24s/it]Running loglikelihood requests:  76%|███████▋  | 306/400 [08:01<01:56,  1.24s/it]Running loglikelihood requests:  77%|███████▋  | 307/400 [08:02<01:54,  1.24s/it]Running loglikelihood requests:  77%|███████▋  | 308/400 [08:04<01:53,  1.23s/it]Running loglikelihood requests:  77%|███████▋  | 309/400 [08:05<01:51,  1.23s/it]Running loglikelihood requests:  78%|███████▊  | 310/400 [08:06<01:50,  1.23s/it]Running loglikelihood requests:  78%|███████▊  | 311/400 [08:07<01:49,  1.23s/it]Running loglikelihood requests:  78%|███████▊  | 312/400 [08:09<01:47,  1.23s/it]Running loglikelihood requests:  78%|███████▊  | 313/400 [08:10<01:46,  1.22s/it]Running loglikelihood requests:  78%|███████▊  | 314/400 [08:11<01:45,  1.23s/it]Running loglikelihood requests:  79%|███████▉  | 315/400 [08:12<01:44,  1.22s/it]Running loglikelihood requests:  79%|███████▉  | 316/400 [08:13<01:42,  1.23s/it]Running loglikelihood requests:  79%|███████▉  | 317/400 [08:15<01:41,  1.22s/it]Running loglikelihood requests:  80%|███████▉  | 318/400 [08:16<01:40,  1.22s/it]Running loglikelihood requests:  80%|███████▉  | 319/400 [08:17<01:38,  1.22s/it]Running loglikelihood requests:  80%|████████  | 320/400 [08:18<01:37,  1.22s/it]Running loglikelihood requests:  80%|████████  | 321/400 [08:20<01:35,  1.21s/it]Running loglikelihood requests:  80%|████████  | 322/400 [08:21<01:34,  1.22s/it]Running loglikelihood requests:  81%|████████  | 323/400 [08:22<01:33,  1.21s/it]Running loglikelihood requests:  81%|████████  | 324/400 [08:23<01:32,  1.21s/it]Running loglikelihood requests:  81%|████████▏ | 325/400 [08:24<01:30,  1.21s/it]Running loglikelihood requests:  82%|████████▏ | 326/400 [08:26<01:29,  1.21s/it]Running loglikelihood requests:  82%|████████▏ | 327/400 [08:27<01:28,  1.21s/it]Running loglikelihood requests:  82%|████████▏ | 328/400 [08:28<01:27,  1.22s/it]Running loglikelihood requests:  82%|████████▏ | 329/400 [08:29<01:26,  1.22s/it]Running loglikelihood requests:  82%|████████▎ | 330/400 [08:30<01:24,  1.21s/it]Running loglikelihood requests:  83%|████████▎ | 331/400 [08:32<01:23,  1.21s/it]Running loglikelihood requests:  83%|████████▎ | 332/400 [08:33<01:21,  1.20s/it]Running loglikelihood requests:  83%|████████▎ | 333/400 [08:34<01:20,  1.20s/it]Running loglikelihood requests:  84%|████████▎ | 334/400 [08:35<01:18,  1.19s/it]Running loglikelihood requests:  84%|████████▍ | 335/400 [08:36<01:17,  1.19s/it]Running loglikelihood requests:  84%|████████▍ | 336/400 [08:38<01:15,  1.19s/it]Running loglikelihood requests:  84%|████████▍ | 337/400 [08:39<01:14,  1.18s/it]Running loglikelihood requests:  84%|████████▍ | 338/400 [08:40<01:13,  1.18s/it]Running loglikelihood requests:  85%|████████▍ | 339/400 [08:41<01:11,  1.18s/it]Running loglikelihood requests:  85%|████████▌ | 340/400 [08:42<01:10,  1.17s/it]Running loglikelihood requests:  85%|████████▌ | 341/400 [08:43<01:09,  1.17s/it]Running loglikelihood requests:  86%|████████▌ | 342/400 [08:45<01:07,  1.17s/it]Running loglikelihood requests:  86%|████████▌ | 343/400 [08:46<01:06,  1.17s/it]Running loglikelihood requests:  86%|████████▌ | 344/400 [08:47<01:06,  1.18s/it]Running loglikelihood requests:  86%|████████▋ | 345/400 [08:48<01:04,  1.17s/it]Running loglikelihood requests:  86%|████████▋ | 346/400 [08:49<01:03,  1.17s/it]Running loglikelihood requests:  87%|████████▋ | 347/400 [08:51<01:03,  1.20s/it]Running loglikelihood requests:  87%|████████▋ | 348/400 [08:52<01:01,  1.19s/it]Running loglikelihood requests:  87%|████████▋ | 349/400 [08:53<00:59,  1.18s/it]Running loglikelihood requests:  88%|████████▊ | 350/400 [08:54<00:58,  1.17s/it]Running loglikelihood requests:  88%|████████▊ | 351/400 [08:55<00:56,  1.16s/it]Running loglikelihood requests:  88%|████████▊ | 352/400 [08:56<00:55,  1.15s/it]Running loglikelihood requests:  88%|████████▊ | 353/400 [08:57<00:54,  1.15s/it]Running loglikelihood requests:  88%|████████▊ | 354/400 [08:59<00:52,  1.15s/it]Running loglikelihood requests:  89%|████████▉ | 355/400 [09:00<00:51,  1.14s/it]Running loglikelihood requests:  89%|████████▉ | 356/400 [09:01<00:50,  1.14s/it]Running loglikelihood requests:  89%|████████▉ | 357/400 [09:02<00:48,  1.14s/it]Running loglikelihood requests:  90%|████████▉ | 358/400 [09:03<00:47,  1.14s/it]Running loglikelihood requests:  90%|████████▉ | 359/400 [09:04<00:46,  1.13s/it]Running loglikelihood requests:  90%|█████████ | 360/400 [09:05<00:45,  1.13s/it]Running loglikelihood requests:  90%|█████████ | 361/400 [09:06<00:43,  1.13s/it]Running loglikelihood requests:  90%|█████████ | 362/400 [09:08<00:42,  1.12s/it]Running loglikelihood requests:  91%|█████████ | 363/400 [09:09<00:41,  1.12s/it]Running loglikelihood requests:  91%|█████████ | 364/400 [09:10<00:40,  1.12s/it]Running loglikelihood requests:  91%|█████████▏| 365/400 [09:11<00:39,  1.12s/it]Running loglikelihood requests:  92%|█████████▏| 366/400 [09:12<00:38,  1.12s/it]Running loglikelihood requests:  92%|█████████▏| 367/400 [09:13<00:36,  1.12s/it]Running loglikelihood requests:  92%|█████████▏| 368/400 [09:14<00:35,  1.11s/it]Running loglikelihood requests:  92%|█████████▏| 369/400 [09:15<00:34,  1.11s/it]Running loglikelihood requests:  92%|█████████▎| 370/400 [09:16<00:33,  1.11s/it]Running loglikelihood requests:  93%|█████████▎| 371/400 [09:18<00:32,  1.11s/it]Running loglikelihood requests:  93%|█████████▎| 372/400 [09:19<00:30,  1.11s/it]Running loglikelihood requests:  93%|█████████▎| 373/400 [09:20<00:29,  1.10s/it]Running loglikelihood requests:  94%|█████████▎| 374/400 [09:21<00:28,  1.10s/it]Running loglikelihood requests:  94%|█████████▍| 375/400 [09:22<00:27,  1.09s/it]Running loglikelihood requests:  94%|█████████▍| 376/400 [09:23<00:26,  1.09s/it]Running loglikelihood requests:  94%|█████████▍| 377/400 [09:24<00:24,  1.08s/it]Running loglikelihood requests:  94%|█████████▍| 378/400 [09:25<00:23,  1.07s/it]Running loglikelihood requests:  95%|█████████▍| 379/400 [09:26<00:22,  1.06s/it]Running loglikelihood requests:  95%|█████████▌| 380/400 [09:27<00:21,  1.05s/it]Running loglikelihood requests:  95%|█████████▌| 381/400 [09:28<00:19,  1.04s/it]Running loglikelihood requests:  96%|█████████▌| 382/400 [09:29<00:18,  1.03s/it]Running loglikelihood requests:  96%|█████████▌| 383/400 [09:30<00:17,  1.03s/it]Running loglikelihood requests:  96%|█████████▌| 384/400 [09:31<00:16,  1.05s/it]Running loglikelihood requests:  96%|█████████▋| 385/400 [09:32<00:15,  1.05s/it]Running loglikelihood requests:  96%|█████████▋| 386/400 [09:33<00:14,  1.03s/it]Running loglikelihood requests:  97%|█████████▋| 387/400 [09:34<00:13,  1.03s/it]Running loglikelihood requests:  97%|█████████▋| 389/400 [09:36<00:09,  1.18it/s]Running loglikelihood requests:  98%|█████████▊| 390/400 [09:37<00:08,  1.14it/s]Running loglikelihood requests:  98%|█████████▊| 391/400 [09:38<00:08,  1.12it/s]Running loglikelihood requests:  98%|█████████▊| 393/400 [09:38<00:04,  1.43it/s]Running loglikelihood requests:  98%|█████████▊| 394/400 [09:40<00:04,  1.20it/s]Running loglikelihood requests:  99%|█████████▉| 395/400 [09:41<00:04,  1.18it/s]Running loglikelihood requests:  99%|█████████▉| 396/400 [09:42<00:03,  1.14it/s]Running loglikelihood requests:  99%|█████████▉| 397/400 [09:42<00:02,  1.13it/s]Running loglikelihood requests: 100%|█████████▉| 398/400 [09:43<00:01,  1.13it/s]Running loglikelihood requests: 100%|█████████▉| 399/400 [09:44<00:00,  1.14it/s]Running loglikelihood requests: 100%|██████████| 400/400 [09:45<00:00,  1.14it/s]Running loglikelihood requests: 100%|██████████| 400/400 [09:45<00:00,  1.46s/it]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:3'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:3'}
full model:
{'logiqa': {'alias': 'logiqa', 'acc,none': 0.29, 'acc_stderr,none': 0.045604802157206865, 'acc_norm,none': 0.33, 'acc_norm_stderr,none': 0.04725815626252609}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9179964803140478
0.7817057225882229
0.8413553272072316
0.9274797474668193
0.8768807463293081
0.9494139907523571
0.8960692461846443
0.9131107283061946
0.6329173647892901
0.8375042173336539
0.8817471801904351
0.8172295355829869
0.7824572665005357
0.9227400642857845
0.9246594853497696
0.8075911590072223
0.6900210787422486
0.599615993999193
0.9308030044211123
0.9504015361511146
0.8866807231108503
0.540104242930401
0.6701728801805507
0.9744992661822648
0.8193037468812308
0.840784693447352
0.9052511591891966
Total groups 70 exceeded the threshold, stopping comparison.
The group tensor is
[3, 6, 7, 1, 5, 2, 4, 0]
tensor([3, 6, 7, 1, 5, 2, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 2, 6, 3, 7, 1, 5, 0]
tensor([4, 2, 6, 3, 7, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 3, 6, 1, 7, 2, 4, 0]
tensor([5, 3, 6, 1, 7, 2, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 4, 6, 1, 7, 2, 3, 0]
tensor([5, 4, 6, 1, 7, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 3, 0, 2, 1, 0, 4, 1]
tensor([5, 3, 0, 2, 1, 0, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 0, 5, 0, 1, 2, 3, 1]
tensor([4, 0, 5, 0, 1, 2, 3, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Normal merging for layer 2
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 4 to 8
done!
Normal merging for layer 9
tensor([2, 5])
tensor(2)
tensor([4, 7])
tensor(4)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 10 to 13
done!
Normal merging for layer 14
tensor([1, 3])
tensor(1)
tensor([4, 7])
tensor(4)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Cross-layer merge completed for layers 15 to 31
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 6 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 11.9458 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 5 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

108
cuda:3
rte
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:58<00:58, 58.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:19<00:00, 36.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:19<00:00, 39.75s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: rte] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: rte] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/rte?recursive=False&expand=False HTTP/1.1" 307 140
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/rte?recursive=False&expand=False HTTP/1.1" 200 354
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:filelock:Attempting to acquire lock 139686163576688 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139686163576688 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139686163576688 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139686163576688 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139706362676816 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139706362676816 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139706362676816 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139706362676816 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of rte from None to 0
INFO:lm_eval.api.task:Building contexts for rte on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 2583.97it/s]
DEBUG:lm_eval.evaluator:Task: rte; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:02<06:55,  2.09s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:03<03:40,  1.12s/it]Running loglikelihood requests:   2%|▎         | 5/200 [00:04<02:51,  1.13it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:06<02:29,  1.29it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:07<02:17,  1.39it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:08<02:08,  1.47it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:09<02:03,  1.52it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:11<01:58,  1.56it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:12<01:57,  1.55it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:13<01:54,  1.58it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:14<01:49,  1.63it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:15<01:46,  1.67it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:17<01:43,  1.68it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:18<01:39,  1.73it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:19<01:36,  1.78it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:20<01:33,  1.81it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:21<01:30,  1.84it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:22<01:28,  1.86it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:23<01:26,  1.88it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:24<01:24,  1.90it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:25<01:22,  1.94it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:26<01:19,  1.98it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:27<01:16,  2.02it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:28<01:14,  2.06it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:29<01:11,  2.11it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:30<01:08,  2.16it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:30<01:06,  2.22it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:31<01:03,  2.27it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:32<01:01,  2.33it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:33<00:59,  2.37it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:34<00:57,  2.41it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:34<00:56,  2.44it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:35<00:54,  2.46it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:36<00:53,  2.48it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:37<00:52,  2.51it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:38<00:51,  2.53it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:38<00:49,  2.54it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:39<00:48,  2.57it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:40<00:47,  2.59it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:41<00:46,  2.61it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:41<00:45,  2.63it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:42<00:44,  2.64it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:43<00:43,  2.67it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:44<00:42,  2.68it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:44<00:41,  2.69it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:45<00:40,  2.70it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:46<00:39,  2.72it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:46<00:38,  2.73it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:47<00:37,  2.74it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:48<00:36,  2.75it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:49<00:35,  2.76it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:49<00:34,  2.78it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:50<00:33,  2.80it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:51<00:33,  2.81it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:52<00:33,  2.68it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:52<00:32,  2.75it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:53<00:30,  2.81it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:54<00:29,  2.84it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:54<00:28,  2.87it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:55<00:27,  2.90it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:56<00:27,  2.92it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:56<00:26,  2.94it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:57<00:25,  2.95it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [00:58<00:24,  2.96it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [00:58<00:23,  2.97it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [00:59<00:23,  2.98it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [01:00<00:22,  3.00it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [01:00<00:21,  3.03it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [01:01<00:20,  3.04it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [01:02<00:19,  3.06it/s]Running loglikelihood requests:  70%|███████   | 141/200 [01:02<00:19,  3.07it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [01:03<00:18,  3.09it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [01:04<00:17,  3.10it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [01:04<00:17,  3.11it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [01:05<00:16,  3.13it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [01:05<00:15,  3.14it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [01:06<00:14,  3.14it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [01:07<00:14,  3.16it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [01:07<00:13,  3.17it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [01:08<00:12,  3.20it/s]Running loglikelihood requests:  80%|████████  | 161/200 [01:09<00:12,  3.22it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [01:09<00:11,  3.23it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [01:10<00:10,  3.24it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [01:10<00:10,  3.25it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [01:11<00:09,  3.27it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [01:12<00:08,  3.30it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [01:12<00:08,  3.31it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [01:13<00:07,  3.33it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [01:13<00:06,  3.35it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [01:14<00:06,  3.36it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [01:15<00:05,  3.37it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [01:15<00:05,  3.38it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [01:16<00:04,  3.39it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [01:16<00:03,  3.40it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [01:17<00:03,  3.42it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [01:17<00:02,  3.44it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [01:18<00:02,  3.46it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:19<00:01,  3.48it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:19<00:00,  3.56it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:20<00:00,  3.63it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:20<00:00,  2.50it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:4'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:4'}
full model:
{'rte': {'alias': 'rte', 'acc,none': 0.5, 'acc_stderr,none': 0.050251890762960605}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.34161229456626735
0.905233410256777
0.5205040718697735
0.4121994254524892
0.7398116665887099
0.6225415196831932
0.7923970242263771
0.7353888240887675
0.6535613357308766
0.7757058271862038
0.734046359122903
0.4471799126982846
0.773619360921301
0.7955347039939479
0.8672068064531693
0.8652880343596522
0.3302235467760883
0.6789268064017625
0.6072221471952108
0.9194446824778495
0.4812004589187253
0.5728915095234594
0.1682455054057436
0.93212414632396
0.9148362604533635
0.8268537756297094
0.7592245907029287
0.7256008379011685
0.7109756105942956
0.34161229456626735
0.905233410256777
0.5205040718697735
0.4121994254524892
0.7398116665887099
0.6225415196831932
0.7923970242263771
0.7353888240887675
0.6535613357308766
0.7757058271862038
0.734046359122903
0.4471799126982846
0.773619360921301
0.7955347039939479
0.8672068064531693
0.8652880343596522
0.3302235467760883
0.6789268064017625
0.6072221471952108
0.9194446824778495
0.4812004589187253
Total groups 73 exceeded the threshold, stopping comparison.
The group tensor is
[5, 2, 7, 1, 6, 4, 3, 0]
tensor([5, 2, 7, 1, 6, 4, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 6, 0, 7, 3, 4, 1]
tensor([5, 2, 6, 0, 7, 3, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 7, 2, 5, 4, 3, 0]
tensor([6, 1, 7, 2, 5, 4, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 7, 2, 4, 1, 5, 0]
tensor([6, 3, 7, 2, 4, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 5, 6, 2, 3, 1, 4, 0]
tensor([7, 5, 6, 2, 3, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 2, 5, 4, 1, 0, 1, 3]
tensor([0, 2, 5, 4, 1, 0, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1.0, 1.0, 0, 1.0, 1]
tensor([0, 1, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
Normal merging for layer 1
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Normal merging for layer 2
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 4
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 5 to 8
done!
Normal merging for layer 9
tensor([0, 5])
tensor(0)
tensor([4, 6])
tensor(4)
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
done!
Cross-layer merge completed for layers 10 to 30
done!
Normal merging for layer 31
tensor([0, 5])
tensor(0)
tensor([1, 2, 3, 4, 6, 7])
tensor(1)
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 5 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.1348 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 4 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

225
cuda:4
coqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:52<00:52, 52.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:09<00:00, 31.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:09<00:00, 34.65s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa HTTP/1.1" 200 857
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/EleutherAI/coqa/EleutherAI/coqa.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa HTTP/1.1" 200 857
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/coqa/resolve/82e11af842af6c1396f5e9a5c7de260107c50cf1/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa/revision/82e11af842af6c1396f5e9a5c7de260107c50cf1 HTTP/1.1" 200 857
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa/tree/82e11af842af6c1396f5e9a5c7de260107c50cf1?recursive=False&expand=False HTTP/1.1" 200 489
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa/tree/82e11af842af6c1396f5e9a5c7de260107c50cf1/data?recursive=False&expand=False HTTP/1.1" 404 79
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa/tree/82e11af842af6c1396f5e9a5c7de260107c50cf1/data?recursive=False&expand=False HTTP/1.1" 404 79
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa/revision/82e11af842af6c1396f5e9a5c7de260107c50cf1 HTTP/1.1" 200 857
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/coqa/resolve/82e11af842af6c1396f5e9a5c7de260107c50cf1/dataset_infos.json HTTP/1.1" 200 0
DEBUG:filelock:Attempting to acquire lock 139703946591456 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___coqa_default_0.0.0_82e11af842af6c1396f5e9a5c7de260107c50cf1.lock
DEBUG:filelock:Lock 139703946591456 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___coqa_default_0.0.0_82e11af842af6c1396f5e9a5c7de260107c50cf1.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1/dataset_info.json
DEBUG:filelock:Attempting to release lock 139703946591456 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___coqa_default_0.0.0_82e11af842af6c1396f5e9a5c7de260107c50cf1.lock
DEBUG:filelock:Lock 139703946591456 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___coqa_default_0.0.0_82e11af842af6c1396f5e9a5c7de260107c50cf1.lock
DEBUG:filelock:Attempting to acquire lock 139682806759008 on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1_builder.lock
DEBUG:filelock:Lock 139682806759008 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1/dataset_info.json
DEBUG:filelock:Attempting to release lock 139682806759008 on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1_builder.lock
DEBUG:filelock:Lock 139682806759008 released on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
DEBUG:lm_eval.api.task:doc_to_target returned a list. Assuming multiple targets.
INFO:lm_eval.evaluator:coqa: Using gen_kwargs: {'until': ['\nQ:']}
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of coqa from None to 0
INFO:lm_eval.api.task:Building contexts for coqa on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 73804.40it/s]
DEBUG:lm_eval.evaluator:Task: coqa; number of requests on this rank: 100
INFO:lm_eval.evaluator:Running generate_until requests
Running generate_until requests:   0%|          | 0/100 [00:00<?, ?it/s]Running generate_until requests:   1%|          | 1/100 [00:06<09:56,  6.03s/it]Running generate_until requests:   2%|▏         | 2/100 [00:11<08:57,  5.48s/it]Running generate_until requests:   3%|▎         | 3/100 [00:17<09:23,  5.81s/it]Running generate_until requests:   4%|▍         | 4/100 [00:22<08:46,  5.48s/it]Running generate_until requests:   5%|▌         | 5/100 [00:27<08:31,  5.38s/it]Running generate_until requests:   6%|▌         | 6/100 [00:32<08:04,  5.15s/it]Running generate_until requests:   7%|▋         | 7/100 [00:37<08:14,  5.31s/it]Running generate_until requests:   8%|▊         | 8/100 [00:42<07:50,  5.11s/it]Running generate_until requests:   9%|▉         | 9/100 [00:47<07:43,  5.09s/it]Running generate_until requests:  10%|█         | 10/100 [00:53<07:50,  5.23s/it]Running generate_until requests:  11%|█         | 11/100 [00:58<07:42,  5.20s/it]Running generate_until requests:  12%|█▏        | 12/100 [01:04<08:05,  5.52s/it]Running generate_until requests:  13%|█▎        | 13/100 [01:08<07:32,  5.20s/it]Running generate_until requests:  14%|█▍        | 14/100 [01:13<07:08,  4.98s/it]Running generate_until requests:  15%|█▌        | 15/100 [01:18<06:56,  4.90s/it]Running generate_until requests:  16%|█▌        | 16/100 [01:22<06:39,  4.75s/it]Running generate_until requests:  17%|█▋        | 17/100 [01:27<06:28,  4.69s/it]Running generate_until requests:  18%|█▊        | 18/100 [01:31<06:13,  4.56s/it]Running generate_until requests:  19%|█▉        | 19/100 [01:35<06:09,  4.56s/it]Running generate_until requests:  20%|██        | 20/100 [01:40<06:00,  4.50s/it]Running generate_until requests:  21%|██        | 21/100 [01:44<05:55,  4.50s/it]Running generate_until requests:  22%|██▏       | 22/100 [01:49<05:47,  4.46s/it]Running generate_until requests:  23%|██▎       | 23/100 [01:54<06:04,  4.74s/it]Running generate_until requests:  24%|██▍       | 24/100 [01:59<06:16,  4.95s/it]Running generate_until requests:  25%|██▌       | 25/100 [02:04<05:55,  4.74s/it]Running generate_until requests:  26%|██▌       | 26/100 [02:08<05:47,  4.70s/it]Running generate_until requests:  27%|██▋       | 27/100 [02:13<05:44,  4.72s/it]Running generate_until requests:  28%|██▊       | 28/100 [02:18<05:36,  4.68s/it]Running generate_until requests:  29%|██▉       | 29/100 [02:22<05:26,  4.60s/it]Running generate_until requests:  30%|███       | 30/100 [02:27<05:22,  4.61s/it]Running generate_until requests:  31%|███       | 31/100 [02:31<05:05,  4.43s/it]Running generate_until requests:  32%|███▏      | 32/100 [02:35<05:05,  4.50s/it]Running generate_until requests:  33%|███▎      | 33/100 [02:40<05:01,  4.50s/it]Running generate_until requests:  34%|███▍      | 34/100 [02:44<04:54,  4.46s/it]Running generate_until requests:  35%|███▌      | 35/100 [02:48<04:40,  4.32s/it]Running generate_until requests:  36%|███▌      | 36/100 [02:54<04:59,  4.68s/it]Running generate_until requests:  37%|███▋      | 37/100 [02:58<04:40,  4.46s/it]Running generate_until requests:  38%|███▊      | 38/100 [03:02<04:26,  4.30s/it]Running generate_until requests:  39%|███▉      | 39/100 [03:06<04:19,  4.26s/it]Running generate_until requests:  40%|████      | 40/100 [03:10<04:08,  4.15s/it]Running generate_until requests:  41%|████      | 41/100 [03:14<04:04,  4.14s/it]Running generate_until requests:  42%|████▏     | 42/100 [03:19<04:20,  4.49s/it]Running generate_until requests:  43%|████▎     | 43/100 [03:23<04:09,  4.37s/it]Running generate_until requests:  44%|████▍     | 44/100 [03:28<04:05,  4.39s/it]Running generate_until requests:  45%|████▌     | 45/100 [03:32<03:58,  4.33s/it]Running generate_until requests:  46%|████▌     | 46/100 [03:36<03:45,  4.18s/it]Running generate_until requests:  47%|████▋     | 47/100 [03:39<03:35,  4.06s/it]Running generate_until requests:  48%|████▊     | 48/100 [03:44<03:37,  4.18s/it]Running generate_until requests:  49%|████▉     | 49/100 [03:49<03:47,  4.47s/it]Running generate_until requests:  50%|█████     | 50/100 [03:53<03:37,  4.35s/it]Running generate_until requests:  51%|█████     | 51/100 [03:58<03:44,  4.58s/it]Running generate_until requests:  52%|█████▏    | 52/100 [04:02<03:28,  4.35s/it]Running generate_until requests:  53%|█████▎    | 53/100 [04:07<03:25,  4.37s/it]Running generate_until requests:  54%|█████▍    | 54/100 [04:10<03:13,  4.20s/it]Running generate_until requests:  55%|█████▌    | 55/100 [04:15<03:09,  4.20s/it]Running generate_until requests:  56%|█████▌    | 56/100 [04:19<03:13,  4.40s/it]Running generate_until requests:  57%|█████▋    | 57/100 [04:24<03:08,  4.38s/it]Running generate_until requests:  58%|█████▊    | 58/100 [04:27<02:56,  4.20s/it]Running generate_until requests:  59%|█████▉    | 59/100 [04:33<03:07,  4.58s/it]Running generate_until requests:  60%|██████    | 60/100 [04:37<02:52,  4.31s/it]Running generate_until requests:  61%|██████    | 61/100 [04:41<02:53,  4.44s/it]Running generate_until requests:  62%|██████▏   | 62/100 [04:46<02:51,  4.51s/it]Running generate_until requests:  63%|██████▎   | 63/100 [04:50<02:36,  4.24s/it]Running generate_until requests:  64%|██████▍   | 64/100 [04:53<02:25,  4.04s/it]Running generate_until requests:  65%|██████▌   | 65/100 [04:57<02:15,  3.88s/it]Running generate_until requests:  66%|██████▌   | 66/100 [05:00<02:08,  3.78s/it]Running generate_until requests:  67%|██████▋   | 67/100 [05:04<02:04,  3.78s/it]Running generate_until requests:  68%|██████▊   | 68/100 [05:08<02:06,  3.95s/it]Running generate_until requests:  69%|██████▉   | 69/100 [05:14<02:17,  4.44s/it]Running generate_until requests:  70%|███████   | 70/100 [05:18<02:09,  4.31s/it]Running generate_until requests:  71%|███████   | 71/100 [05:26<02:39,  5.51s/it]Running generate_until requests:  72%|███████▏  | 72/100 [05:30<02:16,  4.88s/it]Running generate_until requests:  73%|███████▎  | 73/100 [05:33<02:00,  4.47s/it]Running generate_until requests:  74%|███████▍  | 74/100 [05:37<01:51,  4.29s/it]Running generate_until requests:  75%|███████▌  | 75/100 [05:41<01:41,  4.04s/it]Running generate_until requests:  76%|███████▌  | 76/100 [05:44<01:32,  3.86s/it]Running generate_until requests:  77%|███████▋  | 77/100 [05:48<01:32,  4.01s/it]Running generate_until requests:  78%|███████▊  | 78/100 [05:52<01:25,  3.87s/it]Running generate_until requests:  79%|███████▉  | 79/100 [05:55<01:17,  3.68s/it]Running generate_until requests:  80%|████████  | 80/100 [05:59<01:14,  3.71s/it]Running generate_until requests:  81%|████████  | 81/100 [06:05<01:21,  4.27s/it]Running generate_until requests:  82%|████████▏ | 82/100 [06:08<01:11,  3.96s/it]Running generate_until requests:  83%|████████▎ | 83/100 [06:11<01:05,  3.85s/it]Running generate_until requests:  84%|████████▍ | 84/100 [06:15<00:58,  3.64s/it]Running generate_until requests:  85%|████████▌ | 85/100 [06:18<00:52,  3.49s/it]Running generate_until requests:  86%|████████▌ | 86/100 [06:21<00:48,  3.45s/it]Running generate_until requests:  87%|████████▋ | 87/100 [06:25<00:48,  3.70s/it]Running generate_until requests:  88%|████████▊ | 88/100 [06:29<00:43,  3.64s/it]Running generate_until requests:  89%|████████▉ | 89/100 [06:32<00:37,  3.43s/it]Running generate_until requests:  90%|█████████ | 90/100 [06:35<00:32,  3.25s/it]Running generate_until requests:  91%|█████████ | 91/100 [06:37<00:27,  3.08s/it]Running generate_until requests:  92%|█████████▏| 92/100 [06:40<00:23,  2.99s/it]Running generate_until requests:  93%|█████████▎| 93/100 [06:43<00:20,  2.95s/it]Running generate_until requests:  94%|█████████▍| 94/100 [06:46<00:17,  2.95s/it]Running generate_until requests:  95%|█████████▌| 95/100 [06:49<00:15,  3.08s/it]Running generate_until requests:  96%|█████████▌| 96/100 [06:52<00:12,  3.10s/it]Running generate_until requests:  97%|█████████▋| 97/100 [06:55<00:08,  2.98s/it]Running generate_until requests:  98%|█████████▊| 98/100 [06:58<00:05,  2.89s/it]Running generate_until requests:  99%|█████████▉| 99/100 [07:01<00:02,  2.89s/it]Running generate_until requests: 100%|██████████| 100/100 [07:03<00:00,  2.87s/it]Running generate_until requests: 100%|██████████| 100/100 [07:03<00:00,  4.24s/it]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:5'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:5'}
full model:
{'coqa': {'alias': 'coqa', 'em,none': 0.595, 'em_stderr,none': 0.044774970461162564, 'f1,none': 0.7211574141733987, 'f1_stderr,none': 0.037128235455690536}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.6057853926542468
0.4195568875297668
0.5244744113321889
0.5202703028806769
0.6150870974034927
0.5299634576457063
0.9336763524510373
0.23649940737178063
0.388911200696845
0.6478041116722705
0.5517233675449297
0.6723258763091353
0.7175526480521238
0.8411089149883405
0.7404554224148189
0.26376935916880817
0.9373006475493478
0.5360566853939598
0.38729358133282565
0.4541602442018795
0.8623573205888978
0.7318340566806717
0.6643209906079897
0.8122565195147101
0.4707270481319977
0.9785001455445378
0.17075087907531752
0.489625917805058
0.7595051272431785
0.6057853926542468
0.4195568875297668
0.5244744113321889
0.5202703028806769
0.6150870974034927
0.5299634576457063
0.9336763524510373
0.23649940737178063
0.388911200696845
0.6478041116722705
0.5517233675449297
0.6723258763091353
0.7175526480521238
0.8411089149883405
0.7404554224148189
0.26376935916880817
0.9373006475493478
0.5360566853939598
0.38729358133282565
0.4541602442018795
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[5, 4, 3, 2, 0, 1, 7, 6]
tensor([5, 4, 3, 2, 0, 1, 7, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 3, 4, 0, 2, 1, 7, 6]
tensor([5, 3, 4, 0, 2, 1, 7, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 1, 7, 0, 6, 2, 3, 4]
tensor([5, 1, 7, 0, 6, 2, 3, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 3, 6, 0, 5, 2, 4, 1]
tensor([7, 3, 6, 0, 5, 2, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 5, 7, 2, 4, 0, 3, 1]
tensor([6, 5, 7, 2, 4, 0, 3, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 5, 0, 0, 1, 2, 1, 3]
tensor([4, 5, 0, 0, 1, 2, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1, 2, 2, 0, 3, 3]
tensor([0, 1, 1, 2, 2, 0, 3, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([7])
tensor(7)
tensor([6])
tensor(6)
done!
Normal merging for layer 2
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
done!
Normal merging for layer 4
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Cross-layer merge completed for layers 5 to 8
done!
Normal merging for layer 9
tensor([2, 3])
tensor(2)
tensor([4, 6])
tensor(4)
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([1])
tensor(1)
done!
Cross-layer merge completed for layers 10 to 22
done!
Normal merging for layer 23
tensor([0, 5])
tensor(0)
tensor([1, 2])
tensor(1)
tensor([3, 4])
tensor(3)
tensor([6, 7])
tensor(6)
done!
Cross-layer merge completed for layers 24 to 31
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 4 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.3238 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 3 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

81
cuda:5
logiqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:55<00:55, 55.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:13<00:00, 33.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:13<00:00, 36.52s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/logiqa HTTP/1.1" 200 743
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/EleutherAI/logiqa/EleutherAI/logiqa.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): datasets-server.hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://datasets-server.hf-mirror.com:443 "GET /parquet?dataset=EleutherAI/logiqa HTTP/1.1" 302 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET / HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/EleutherAI/logiqa/EleutherAI/logiqa.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/logiqa/resolve/main/logiqa.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/logiqa/resolve/main/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/logiqa/resolve/main/README.md HTTP/1.1" 200 0
DEBUG:filelock:Attempting to acquire lock 139682536720000 on /public/home/zouyifei001/.cache/huggingface/modules/datasets_modules/datasets/EleutherAI--logiqa.lock
DEBUG:filelock:Lock 139682536720000 acquired on /public/home/zouyifei001/.cache/huggingface/modules/datasets_modules/datasets/EleutherAI--logiqa.lock
DEBUG:filelock:Attempting to release lock 139682536720000 on /public/home/zouyifei001/.cache/huggingface/modules/datasets_modules/datasets/EleutherAI--logiqa.lock
DEBUG:filelock:Lock 139682536720000 released on /public/home/zouyifei001/.cache/huggingface/modules/datasets_modules/datasets/EleutherAI--logiqa.lock
DEBUG:filelock:Attempting to acquire lock 139683749080880 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___logiqa_logiqa_0.0.1_5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81.lock
DEBUG:filelock:Lock 139683749080880 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___logiqa_logiqa_0.0.1_5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___logiqa/logiqa/0.0.1/5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81/dataset_info.json
DEBUG:filelock:Attempting to release lock 139683749080880 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___logiqa_logiqa_0.0.1_5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81.lock
DEBUG:filelock:Lock 139683749080880 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___logiqa_logiqa_0.0.1_5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81.lock
DEBUG:filelock:Attempting to acquire lock 139682536731712 on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___logiqa/logiqa/0.0.1/5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81_builder.lock
DEBUG:filelock:Lock 139682536731712 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___logiqa/logiqa/0.0.1/5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___logiqa/logiqa/0.0.1/5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81/dataset_info.json
DEBUG:filelock:Attempting to release lock 139682536731712 on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___logiqa/logiqa/0.0.1/5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81_builder.lock
DEBUG:filelock:Lock 139682536731712 released on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___logiqa/logiqa/0.0.1/5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of logiqa from None to 0
INFO:lm_eval.api.task:Building contexts for logiqa on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 3118.93it/s]
DEBUG:lm_eval.evaluator:Task: logiqa; number of requests on this rank: 400
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/400 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/400 [00:02<19:03,  2.87s/it]Running loglikelihood requests:   0%|          | 2/400 [00:05<16:36,  2.50s/it]Running loglikelihood requests:   1%|          | 3/400 [00:07<15:42,  2.37s/it]Running loglikelihood requests:   1%|          | 4/400 [00:09<15:10,  2.30s/it]Running loglikelihood requests:   1%|▏         | 5/400 [00:11<14:48,  2.25s/it]Running loglikelihood requests:   2%|▏         | 6/400 [00:13<14:34,  2.22s/it]Running loglikelihood requests:   2%|▏         | 7/400 [00:15<14:22,  2.19s/it]Running loglikelihood requests:   2%|▏         | 8/400 [00:18<14:12,  2.17s/it]Running loglikelihood requests:   2%|▏         | 9/400 [00:20<14:02,  2.15s/it]Running loglikelihood requests:   2%|▎         | 10/400 [00:22<13:52,  2.14s/it]Running loglikelihood requests:   3%|▎         | 11/400 [00:24<13:41,  2.11s/it]Running loglikelihood requests:   3%|▎         | 12/400 [00:26<13:28,  2.08s/it]Running loglikelihood requests:   3%|▎         | 13/400 [00:28<13:17,  2.06s/it]Running loglikelihood requests:   4%|▎         | 14/400 [00:30<13:09,  2.04s/it]Running loglikelihood requests:   4%|▍         | 15/400 [00:32<13:03,  2.03s/it]Running loglikelihood requests:   4%|▍         | 16/400 [00:34<12:58,  2.03s/it]Running loglikelihood requests:   4%|▍         | 17/400 [00:36<12:54,  2.02s/it]Running loglikelihood requests:   4%|▍         | 18/400 [00:38<12:49,  2.01s/it]Running loglikelihood requests:   5%|▍         | 19/400 [00:40<12:45,  2.01s/it]Running loglikelihood requests:   5%|▌         | 20/400 [00:42<12:41,  2.00s/it]Running loglikelihood requests:   5%|▌         | 21/400 [00:44<12:35,  1.99s/it]Running loglikelihood requests:   6%|▌         | 22/400 [00:46<12:31,  1.99s/it]Running loglikelihood requests:   6%|▌         | 23/400 [00:48<12:29,  1.99s/it]Running loglikelihood requests:   6%|▌         | 24/400 [00:50<12:23,  1.98s/it]Running loglikelihood requests:   6%|▋         | 25/400 [00:52<12:17,  1.97s/it]Running loglikelihood requests:   6%|▋         | 26/400 [00:54<12:11,  1.95s/it]Running loglikelihood requests:   7%|▋         | 27/400 [00:56<12:04,  1.94s/it]Running loglikelihood requests:   7%|▋         | 28/400 [00:58<12:00,  1.94s/it]Running loglikelihood requests:   7%|▋         | 29/400 [00:59<11:55,  1.93s/it]Running loglikelihood requests:   8%|▊         | 30/400 [01:01<11:55,  1.93s/it]Running loglikelihood requests:   8%|▊         | 31/400 [01:03<11:48,  1.92s/it]Running loglikelihood requests:   8%|▊         | 32/400 [01:05<11:43,  1.91s/it]Running loglikelihood requests:   8%|▊         | 33/400 [01:07<11:41,  1.91s/it]Running loglikelihood requests:   8%|▊         | 34/400 [01:09<11:36,  1.90s/it]Running loglikelihood requests:   9%|▉         | 35/400 [01:11<11:31,  1.90s/it]Running loglikelihood requests:   9%|▉         | 36/400 [01:13<11:28,  1.89s/it]Running loglikelihood requests:   9%|▉         | 37/400 [01:15<11:25,  1.89s/it]Running loglikelihood requests:  10%|▉         | 38/400 [01:16<11:19,  1.88s/it]Running loglikelihood requests:  10%|▉         | 39/400 [01:18<11:12,  1.86s/it]Running loglikelihood requests:  10%|█         | 40/400 [01:20<11:08,  1.86s/it]Running loglikelihood requests:  10%|█         | 41/400 [01:22<11:04,  1.85s/it]Running loglikelihood requests:  10%|█         | 42/400 [01:24<11:01,  1.85s/it]Running loglikelihood requests:  11%|█         | 43/400 [01:26<10:55,  1.84s/it]Running loglikelihood requests:  11%|█         | 44/400 [01:27<10:50,  1.83s/it]Running loglikelihood requests:  11%|█▏        | 45/400 [01:29<10:46,  1.82s/it]Running loglikelihood requests:  12%|█▏        | 46/400 [01:31<11:05,  1.88s/it]Running loglikelihood requests:  12%|█▏        | 47/400 [01:33<10:59,  1.87s/it]Running loglikelihood requests:  12%|█▏        | 48/400 [01:35<10:53,  1.86s/it]Running loglikelihood requests:  12%|█▏        | 49/400 [01:37<10:48,  1.85s/it]Running loglikelihood requests:  12%|█▎        | 50/400 [01:39<11:06,  1.90s/it]Running loglikelihood requests:  13%|█▎        | 51/400 [01:41<11:16,  1.94s/it]Running loglikelihood requests:  13%|█▎        | 52/400 [01:43<11:23,  1.96s/it]Running loglikelihood requests:  13%|█▎        | 53/400 [01:45<11:27,  1.98s/it]Running loglikelihood requests:  14%|█▎        | 54/400 [01:47<11:11,  1.94s/it]Running loglikelihood requests:  14%|█▍        | 55/400 [01:49<10:56,  1.90s/it]Running loglikelihood requests:  14%|█▍        | 56/400 [01:50<10:44,  1.87s/it]Running loglikelihood requests:  14%|█▍        | 57/400 [01:52<10:33,  1.85s/it]Running loglikelihood requests:  14%|█▍        | 58/400 [01:54<10:26,  1.83s/it]Running loglikelihood requests:  15%|█▍        | 59/400 [01:56<10:15,  1.81s/it]Running loglikelihood requests:  15%|█▌        | 60/400 [01:57<10:06,  1.78s/it]Running loglikelihood requests:  15%|█▌        | 61/400 [01:59<09:56,  1.76s/it]Running loglikelihood requests:  16%|█▌        | 62/400 [02:01<09:48,  1.74s/it]Running loglikelihood requests:  16%|█▌        | 63/400 [02:02<09:41,  1.73s/it]Running loglikelihood requests:  16%|█▌        | 64/400 [02:04<09:37,  1.72s/it]Running loglikelihood requests:  16%|█▋        | 65/400 [02:06<09:31,  1.70s/it]Running loglikelihood requests:  16%|█▋        | 66/400 [02:08<09:26,  1.70s/it]Running loglikelihood requests:  17%|█▋        | 67/400 [02:09<09:21,  1.69s/it]Running loglikelihood requests:  17%|█▋        | 68/400 [02:11<09:17,  1.68s/it]Running loglikelihood requests:  17%|█▋        | 69/400 [02:13<09:25,  1.71s/it]Running loglikelihood requests:  18%|█▊        | 70/400 [02:14<09:34,  1.74s/it]Running loglikelihood requests:  18%|█▊        | 71/400 [02:16<09:25,  1.72s/it]Running loglikelihood requests:  18%|█▊        | 72/400 [02:18<09:18,  1.70s/it]Running loglikelihood requests:  18%|█▊        | 73/400 [02:19<09:11,  1.69s/it]Running loglikelihood requests:  18%|█▊        | 74/400 [02:21<09:05,  1.67s/it]Running loglikelihood requests:  19%|█▉        | 75/400 [02:23<08:59,  1.66s/it]Running loglikelihood requests:  19%|█▉        | 76/400 [02:24<08:54,  1.65s/it]Running loglikelihood requests:  19%|█▉        | 77/400 [02:26<08:48,  1.64s/it]Running loglikelihood requests:  20%|█▉        | 78/400 [02:28<08:43,  1.63s/it]Running loglikelihood requests:  20%|█▉        | 79/400 [02:29<08:40,  1.62s/it]Running loglikelihood requests:  20%|██        | 80/400 [02:31<08:36,  1.61s/it]Running loglikelihood requests:  20%|██        | 81/400 [02:32<08:31,  1.60s/it]Running loglikelihood requests:  20%|██        | 82/400 [02:34<08:27,  1.60s/it]Running loglikelihood requests:  21%|██        | 83/400 [02:35<08:23,  1.59s/it]Running loglikelihood requests:  21%|██        | 84/400 [02:37<08:19,  1.58s/it]Running loglikelihood requests:  21%|██▏       | 85/400 [02:39<08:15,  1.57s/it]Running loglikelihood requests:  22%|██▏       | 86/400 [02:40<08:12,  1.57s/it]Running loglikelihood requests:  22%|██▏       | 87/400 [02:42<08:09,  1.56s/it]Running loglikelihood requests:  22%|██▏       | 88/400 [02:43<08:07,  1.56s/it]Running loglikelihood requests:  22%|██▏       | 89/400 [02:45<08:05,  1.56s/it]Running loglikelihood requests:  22%|██▎       | 90/400 [02:46<08:03,  1.56s/it]Running loglikelihood requests:  23%|██▎       | 91/400 [02:48<08:02,  1.56s/it]Running loglikelihood requests:  23%|██▎       | 92/400 [02:49<07:59,  1.56s/it]Running loglikelihood requests:  23%|██▎       | 93/400 [02:51<07:57,  1.56s/it]Running loglikelihood requests:  24%|██▎       | 94/400 [02:53<07:55,  1.55s/it]Running loglikelihood requests:  24%|██▍       | 95/400 [02:54<07:53,  1.55s/it]Running loglikelihood requests:  24%|██▍       | 96/400 [02:56<07:59,  1.58s/it]Running loglikelihood requests:  24%|██▍       | 97/400 [02:57<08:07,  1.61s/it]Running loglikelihood requests:  24%|██▍       | 98/400 [02:59<08:11,  1.63s/it]Running loglikelihood requests:  25%|██▍       | 99/400 [03:01<08:14,  1.64s/it]Running loglikelihood requests:  25%|██▌       | 100/400 [03:02<08:16,  1.65s/it]Running loglikelihood requests:  25%|██▌       | 101/400 [03:04<08:19,  1.67s/it]Running loglikelihood requests:  26%|██▌       | 102/400 [03:06<08:06,  1.63s/it]Running loglikelihood requests:  26%|██▌       | 103/400 [03:07<07:54,  1.60s/it]Running loglikelihood requests:  26%|██▌       | 104/400 [03:09<07:45,  1.57s/it]Running loglikelihood requests:  26%|██▋       | 105/400 [03:10<07:46,  1.58s/it]Running loglikelihood requests:  26%|██▋       | 106/400 [03:12<07:38,  1.56s/it]Running loglikelihood requests:  27%|██▋       | 107/400 [03:13<07:32,  1.54s/it]Running loglikelihood requests:  27%|██▋       | 108/400 [03:15<07:27,  1.53s/it]Running loglikelihood requests:  27%|██▋       | 109/400 [03:16<07:22,  1.52s/it]Running loglikelihood requests:  28%|██▊       | 110/400 [03:18<07:26,  1.54s/it]Running loglikelihood requests:  28%|██▊       | 111/400 [03:19<07:20,  1.52s/it]Running loglikelihood requests:  28%|██▊       | 112/400 [03:21<07:16,  1.51s/it]Running loglikelihood requests:  28%|██▊       | 113/400 [03:22<07:12,  1.51s/it]Running loglikelihood requests:  28%|██▊       | 114/400 [03:24<07:19,  1.54s/it]Running loglikelihood requests:  29%|██▉       | 115/400 [03:26<07:16,  1.53s/it]Running loglikelihood requests:  29%|██▉       | 116/400 [03:27<07:13,  1.53s/it]Running loglikelihood requests:  29%|██▉       | 117/400 [03:29<07:11,  1.52s/it]Running loglikelihood requests:  30%|██▉       | 118/400 [03:30<07:08,  1.52s/it]Running loglikelihood requests:  30%|██▉       | 119/400 [03:32<07:05,  1.51s/it]Running loglikelihood requests:  30%|███       | 120/400 [03:33<07:03,  1.51s/it]Running loglikelihood requests:  30%|███       | 121/400 [03:35<07:01,  1.51s/it]Running loglikelihood requests:  30%|███       | 122/400 [03:36<06:57,  1.50s/it]Running loglikelihood requests:  31%|███       | 123/400 [03:38<06:52,  1.49s/it]Running loglikelihood requests:  31%|███       | 124/400 [03:39<06:48,  1.48s/it]Running loglikelihood requests:  31%|███▏      | 125/400 [03:41<06:59,  1.52s/it]Running loglikelihood requests:  32%|███▏      | 126/400 [03:42<07:07,  1.56s/it]Running loglikelihood requests:  32%|███▏      | 127/400 [03:44<07:09,  1.57s/it]Running loglikelihood requests:  32%|███▏      | 128/400 [03:45<07:02,  1.55s/it]Running loglikelihood requests:  32%|███▏      | 129/400 [03:47<06:53,  1.53s/it]Running loglikelihood requests:  32%|███▎      | 130/400 [03:48<06:48,  1.51s/it]Running loglikelihood requests:  33%|███▎      | 131/400 [03:50<06:42,  1.50s/it]Running loglikelihood requests:  33%|███▎      | 132/400 [03:51<06:40,  1.49s/it]Running loglikelihood requests:  33%|███▎      | 133/400 [03:53<06:36,  1.48s/it]Running loglikelihood requests:  34%|███▎      | 134/400 [03:54<06:33,  1.48s/it]Running loglikelihood requests:  34%|███▍      | 135/400 [03:56<06:30,  1.48s/it]Running loglikelihood requests:  34%|███▍      | 136/400 [03:57<06:27,  1.47s/it]Running loglikelihood requests:  34%|███▍      | 137/400 [03:59<06:25,  1.47s/it]Running loglikelihood requests:  34%|███▍      | 138/400 [04:00<06:23,  1.47s/it]Running loglikelihood requests:  35%|███▍      | 139/400 [04:02<06:22,  1.46s/it]Running loglikelihood requests:  35%|███▌      | 140/400 [04:03<06:31,  1.50s/it]Running loglikelihood requests:  36%|███▌      | 142/400 [04:05<05:04,  1.18s/it]Running loglikelihood requests:  36%|███▌      | 143/400 [04:06<05:29,  1.28s/it]Running loglikelihood requests:  36%|███▌      | 144/400 [04:08<05:49,  1.36s/it]Running loglikelihood requests:  36%|███▋      | 145/400 [04:10<06:03,  1.43s/it]Running loglikelihood requests:  36%|███▋      | 146/400 [04:11<06:13,  1.47s/it]Running loglikelihood requests:  37%|███▋      | 147/400 [04:13<06:21,  1.51s/it]Running loglikelihood requests:  37%|███▋      | 148/400 [04:14<06:25,  1.53s/it]Running loglikelihood requests:  37%|███▋      | 149/400 [04:16<06:30,  1.55s/it]Running loglikelihood requests:  38%|███▊      | 150/400 [04:17<06:28,  1.55s/it]Running loglikelihood requests:  38%|███▊      | 151/400 [04:19<06:19,  1.52s/it]Running loglikelihood requests:  38%|███▊      | 152/400 [04:20<06:12,  1.50s/it]Running loglikelihood requests:  38%|███▊      | 153/400 [04:22<06:07,  1.49s/it]Running loglikelihood requests:  38%|███▊      | 154/400 [04:23<06:03,  1.48s/it]Running loglikelihood requests:  39%|███▉      | 155/400 [04:25<06:00,  1.47s/it]Running loglikelihood requests:  39%|███▉      | 156/400 [04:26<05:57,  1.47s/it]Running loglikelihood requests:  39%|███▉      | 157/400 [04:28<05:55,  1.46s/it]Running loglikelihood requests:  40%|███▉      | 158/400 [04:29<05:58,  1.48s/it]Running loglikelihood requests:  40%|███▉      | 159/400 [04:31<05:52,  1.46s/it]Running loglikelihood requests:  40%|████      | 160/400 [04:32<05:46,  1.45s/it]Running loglikelihood requests:  40%|████      | 161/400 [04:33<05:43,  1.44s/it]Running loglikelihood requests:  40%|████      | 162/400 [04:35<05:47,  1.46s/it]Running loglikelihood requests:  41%|████      | 163/400 [04:37<06:05,  1.54s/it]Running loglikelihood requests:  41%|████      | 164/400 [04:38<06:06,  1.55s/it]Running loglikelihood requests:  41%|████▏     | 165/400 [04:40<05:54,  1.51s/it]Running loglikelihood requests:  42%|████▏     | 166/400 [04:41<05:45,  1.48s/it]Running loglikelihood requests:  42%|████▏     | 167/400 [04:42<05:38,  1.45s/it]Running loglikelihood requests:  42%|████▏     | 168/400 [04:44<05:33,  1.44s/it]Running loglikelihood requests:  42%|████▏     | 169/400 [04:45<05:29,  1.43s/it]Running loglikelihood requests:  42%|████▎     | 170/400 [04:47<05:32,  1.44s/it]Running loglikelihood requests:  43%|████▎     | 171/400 [04:48<05:37,  1.47s/it]Running loglikelihood requests:  43%|████▎     | 172/400 [04:50<05:35,  1.47s/it]Running loglikelihood requests:  43%|████▎     | 173/400 [04:51<05:30,  1.45s/it]Running loglikelihood requests:  44%|████▎     | 174/400 [04:53<05:25,  1.44s/it]Running loglikelihood requests:  44%|████▍     | 175/400 [04:54<05:22,  1.43s/it]Running loglikelihood requests:  44%|████▍     | 176/400 [04:55<05:19,  1.42s/it]Running loglikelihood requests:  44%|████▍     | 177/400 [04:57<05:16,  1.42s/it]Running loglikelihood requests:  44%|████▍     | 178/400 [04:58<05:14,  1.42s/it]Running loglikelihood requests:  45%|████▍     | 179/400 [05:00<05:16,  1.43s/it]Running loglikelihood requests:  45%|████▌     | 180/400 [05:01<05:12,  1.42s/it]Running loglikelihood requests:  45%|████▌     | 181/400 [05:02<05:08,  1.41s/it]Running loglikelihood requests:  46%|████▌     | 182/400 [05:04<05:06,  1.41s/it]Running loglikelihood requests:  46%|████▌     | 183/400 [05:05<05:03,  1.40s/it]Running loglikelihood requests:  46%|████▌     | 184/400 [05:07<05:01,  1.40s/it]Running loglikelihood requests:  46%|████▋     | 185/400 [05:08<04:59,  1.39s/it]Running loglikelihood requests:  46%|████▋     | 186/400 [05:09<04:56,  1.39s/it]Running loglikelihood requests:  47%|████▋     | 187/400 [05:11<04:54,  1.38s/it]Running loglikelihood requests:  47%|████▋     | 188/400 [05:12<04:52,  1.38s/it]Running loglikelihood requests:  47%|████▋     | 189/400 [05:13<04:52,  1.38s/it]Running loglikelihood requests:  48%|████▊     | 190/400 [05:15<04:49,  1.38s/it]Running loglikelihood requests:  48%|████▊     | 191/400 [05:16<04:47,  1.38s/it]Running loglikelihood requests:  48%|████▊     | 192/400 [05:18<04:46,  1.38s/it]Running loglikelihood requests:  48%|████▊     | 193/400 [05:19<04:44,  1.37s/it]Running loglikelihood requests:  48%|████▊     | 194/400 [05:20<04:41,  1.37s/it]Running loglikelihood requests:  49%|████▉     | 195/400 [05:22<04:39,  1.36s/it]Running loglikelihood requests:  49%|████▉     | 196/400 [05:23<04:39,  1.37s/it]Running loglikelihood requests:  49%|████▉     | 197/400 [05:24<04:40,  1.38s/it]Running loglikelihood requests:  50%|████▉     | 198/400 [05:26<04:37,  1.38s/it]Running loglikelihood requests:  50%|████▉     | 199/400 [05:27<04:35,  1.37s/it]Running loglikelihood requests:  50%|█████     | 200/400 [05:29<04:33,  1.37s/it]Running loglikelihood requests:  50%|█████     | 201/400 [05:30<04:31,  1.36s/it]Running loglikelihood requests:  50%|█████     | 202/400 [05:31<04:29,  1.36s/it]Running loglikelihood requests:  51%|█████     | 203/400 [05:33<04:27,  1.36s/it]Running loglikelihood requests:  51%|█████     | 204/400 [05:34<04:25,  1.36s/it]Running loglikelihood requests:  51%|█████▏    | 205/400 [05:35<04:24,  1.36s/it]Running loglikelihood requests:  52%|█████▏    | 206/400 [05:37<04:22,  1.36s/it]Running loglikelihood requests:  52%|█████▏    | 207/400 [05:38<04:21,  1.35s/it]Running loglikelihood requests:  52%|█████▏    | 208/400 [05:39<04:19,  1.35s/it]Running loglikelihood requests:  52%|█████▏    | 209/400 [05:41<04:17,  1.35s/it]Running loglikelihood requests:  52%|█████▎    | 210/400 [05:42<04:16,  1.35s/it]Running loglikelihood requests:  53%|█████▎    | 211/400 [05:43<04:14,  1.35s/it]Running loglikelihood requests:  53%|█████▎    | 212/400 [05:45<04:13,  1.35s/it]Running loglikelihood requests:  53%|█████▎    | 213/400 [05:46<04:11,  1.35s/it]Running loglikelihood requests:  54%|█████▎    | 214/400 [05:47<04:10,  1.35s/it]Running loglikelihood requests:  54%|█████▍    | 215/400 [05:49<04:08,  1.34s/it]Running loglikelihood requests:  54%|█████▍    | 216/400 [05:50<04:06,  1.34s/it]Running loglikelihood requests:  54%|█████▍    | 217/400 [05:51<04:05,  1.34s/it]Running loglikelihood requests:  55%|█████▍    | 218/400 [05:53<04:04,  1.34s/it]Running loglikelihood requests:  55%|█████▍    | 219/400 [05:54<04:03,  1.34s/it]Running loglikelihood requests:  55%|█████▌    | 220/400 [05:55<04:01,  1.34s/it]Running loglikelihood requests:  55%|█████▌    | 221/400 [05:57<03:59,  1.34s/it]Running loglikelihood requests:  56%|█████▌    | 222/400 [05:58<03:58,  1.34s/it]Running loglikelihood requests:  56%|█████▌    | 223/400 [05:59<03:57,  1.34s/it]Running loglikelihood requests:  56%|█████▌    | 224/400 [06:01<03:55,  1.34s/it]Running loglikelihood requests:  56%|█████▋    | 225/400 [06:02<03:53,  1.34s/it]Running loglikelihood requests:  56%|█████▋    | 226/400 [06:03<03:52,  1.33s/it]Running loglikelihood requests:  57%|█████▋    | 227/400 [06:05<03:50,  1.33s/it]Running loglikelihood requests:  57%|█████▋    | 228/400 [06:06<03:49,  1.33s/it]Running loglikelihood requests:  57%|█████▋    | 229/400 [06:07<03:47,  1.33s/it]Running loglikelihood requests:  57%|█████▊    | 230/400 [06:09<03:45,  1.33s/it]Running loglikelihood requests:  58%|█████▊    | 231/400 [06:10<03:44,  1.33s/it]Running loglikelihood requests:  58%|█████▊    | 232/400 [06:11<03:42,  1.33s/it]Running loglikelihood requests:  58%|█████▊    | 233/400 [06:13<03:47,  1.36s/it]Running loglikelihood requests:  58%|█████▊    | 234/400 [06:14<03:50,  1.39s/it]Running loglikelihood requests:  59%|█████▉    | 235/400 [06:16<03:43,  1.36s/it]Running loglikelihood requests:  59%|█████▉    | 236/400 [06:17<03:38,  1.33s/it]Running loglikelihood requests:  59%|█████▉    | 237/400 [06:18<03:34,  1.32s/it]Running loglikelihood requests:  60%|█████▉    | 238/400 [06:19<03:31,  1.31s/it]Running loglikelihood requests:  60%|█████▉    | 239/400 [06:21<03:29,  1.30s/it]Running loglikelihood requests:  60%|██████    | 240/400 [06:22<03:27,  1.29s/it]Running loglikelihood requests:  60%|██████    | 241/400 [06:23<03:25,  1.29s/it]Running loglikelihood requests:  60%|██████    | 242/400 [06:25<03:23,  1.29s/it]Running loglikelihood requests:  61%|██████    | 243/400 [06:26<03:22,  1.29s/it]Running loglikelihood requests:  61%|██████    | 244/400 [06:27<03:20,  1.29s/it]Running loglikelihood requests:  61%|██████▏   | 245/400 [06:28<03:19,  1.29s/it]Running loglikelihood requests:  62%|██████▏   | 246/400 [06:30<03:17,  1.29s/it]Running loglikelihood requests:  62%|██████▏   | 247/400 [06:31<03:16,  1.28s/it]Running loglikelihood requests:  62%|██████▏   | 248/400 [06:32<03:14,  1.28s/it]Running loglikelihood requests:  62%|██████▏   | 249/400 [06:34<03:13,  1.28s/it]Running loglikelihood requests:  62%|██████▎   | 250/400 [06:35<03:11,  1.28s/it]Running loglikelihood requests:  63%|██████▎   | 251/400 [06:36<03:10,  1.28s/it]Running loglikelihood requests:  63%|██████▎   | 252/400 [06:37<03:09,  1.28s/it]Running loglikelihood requests:  63%|██████▎   | 253/400 [06:39<03:07,  1.28s/it]Running loglikelihood requests:  64%|██████▎   | 254/400 [06:40<03:06,  1.28s/it]Running loglikelihood requests:  64%|██████▍   | 255/400 [06:41<03:04,  1.27s/it]Running loglikelihood requests:  64%|██████▍   | 256/400 [06:43<03:03,  1.27s/it]Running loglikelihood requests:  64%|██████▍   | 257/400 [06:44<03:01,  1.27s/it]Running loglikelihood requests:  64%|██████▍   | 258/400 [06:45<03:00,  1.27s/it]Running loglikelihood requests:  65%|██████▍   | 259/400 [06:46<02:59,  1.27s/it]Running loglikelihood requests:  65%|██████▌   | 260/400 [06:48<02:57,  1.27s/it]Running loglikelihood requests:  65%|██████▌   | 261/400 [06:49<02:56,  1.27s/it]Running loglikelihood requests:  66%|██████▌   | 262/400 [06:50<02:54,  1.26s/it]Running loglikelihood requests:  66%|██████▌   | 263/400 [06:51<02:52,  1.26s/it]Running loglikelihood requests:  66%|██████▌   | 264/400 [06:53<02:50,  1.25s/it]Running loglikelihood requests:  66%|██████▋   | 265/400 [06:54<02:49,  1.25s/it]Running loglikelihood requests:  66%|██████▋   | 266/400 [06:55<02:56,  1.31s/it]Running loglikelihood requests:  67%|██████▋   | 267/400 [06:57<02:52,  1.29s/it]Running loglikelihood requests:  67%|██████▋   | 268/400 [06:58<02:49,  1.28s/it]Running loglikelihood requests:  67%|██████▋   | 269/400 [06:59<02:46,  1.27s/it]Running loglikelihood requests:  68%|██████▊   | 270/400 [07:00<02:46,  1.28s/it]Running loglikelihood requests:  68%|██████▊   | 271/400 [07:02<02:48,  1.30s/it]Running loglikelihood requests:  68%|██████▊   | 272/400 [07:03<02:49,  1.33s/it]Running loglikelihood requests:  68%|██████▊   | 273/400 [07:04<02:48,  1.32s/it]Running loglikelihood requests:  68%|██████▊   | 274/400 [07:06<02:44,  1.31s/it]Running loglikelihood requests:  69%|██████▉   | 275/400 [07:07<02:41,  1.29s/it]Running loglikelihood requests:  69%|██████▉   | 276/400 [07:08<02:38,  1.28s/it]Running loglikelihood requests:  69%|██████▉   | 277/400 [07:09<02:35,  1.27s/it]Running loglikelihood requests:  70%|██████▉   | 278/400 [07:11<02:33,  1.26s/it]Running loglikelihood requests:  70%|███████   | 280/400 [07:12<01:55,  1.03it/s]Running loglikelihood requests:  70%|███████   | 281/400 [07:13<02:03,  1.04s/it]Running loglikelihood requests:  70%|███████   | 282/400 [07:14<02:08,  1.09s/it]Running loglikelihood requests:  71%|███████   | 283/400 [07:16<02:12,  1.13s/it]Running loglikelihood requests:  71%|███████   | 284/400 [07:17<02:14,  1.16s/it]Running loglikelihood requests:  71%|███████▏  | 285/400 [07:18<02:15,  1.18s/it]Running loglikelihood requests:  72%|███████▏  | 286/400 [07:19<02:16,  1.19s/it]Running loglikelihood requests:  72%|███████▏  | 287/400 [07:21<02:15,  1.20s/it]Running loglikelihood requests:  72%|███████▏  | 288/400 [07:22<02:15,  1.21s/it]Running loglikelihood requests:  72%|███████▏  | 289/400 [07:23<02:14,  1.21s/it]Running loglikelihood requests:  72%|███████▎  | 290/400 [07:24<02:13,  1.21s/it]Running loglikelihood requests:  73%|███████▎  | 291/400 [07:25<02:11,  1.21s/it]Running loglikelihood requests:  73%|███████▎  | 292/400 [07:27<02:10,  1.20s/it]Running loglikelihood requests:  73%|███████▎  | 293/400 [07:28<02:08,  1.20s/it]Running loglikelihood requests:  74%|███████▎  | 294/400 [07:29<02:07,  1.20s/it]Running loglikelihood requests:  74%|███████▍  | 295/400 [07:30<02:06,  1.20s/it]Running loglikelihood requests:  74%|███████▍  | 296/400 [07:31<02:04,  1.20s/it]Running loglikelihood requests:  74%|███████▍  | 297/400 [07:33<02:03,  1.20s/it]Running loglikelihood requests:  74%|███████▍  | 298/400 [07:34<02:01,  1.19s/it]Running loglikelihood requests:  75%|███████▍  | 299/400 [07:35<02:00,  1.19s/it]Running loglikelihood requests:  75%|███████▌  | 300/400 [07:36<01:58,  1.19s/it]Running loglikelihood requests:  75%|███████▌  | 301/400 [07:37<01:57,  1.19s/it]Running loglikelihood requests:  76%|███████▌  | 302/400 [07:38<01:56,  1.19s/it]Running loglikelihood requests:  76%|███████▌  | 303/400 [07:40<01:54,  1.19s/it]Running loglikelihood requests:  76%|███████▌  | 304/400 [07:41<01:53,  1.18s/it]Running loglikelihood requests:  76%|███████▋  | 305/400 [07:42<01:52,  1.18s/it]Running loglikelihood requests:  76%|███████▋  | 306/400 [07:43<01:51,  1.18s/it]Running loglikelihood requests:  77%|███████▋  | 307/400 [07:44<01:49,  1.18s/it]Running loglikelihood requests:  77%|███████▋  | 308/400 [07:46<01:48,  1.18s/it]Running loglikelihood requests:  77%|███████▋  | 309/400 [07:47<01:47,  1.18s/it]Running loglikelihood requests:  78%|███████▊  | 310/400 [07:48<01:45,  1.17s/it]Running loglikelihood requests:  78%|███████▊  | 311/400 [07:49<01:44,  1.18s/it]Running loglikelihood requests:  78%|███████▊  | 312/400 [07:50<01:43,  1.17s/it]Running loglikelihood requests:  78%|███████▊  | 313/400 [07:51<01:42,  1.18s/it]Running loglikelihood requests:  78%|███████▊  | 314/400 [07:53<01:41,  1.18s/it]Running loglikelihood requests:  79%|███████▉  | 315/400 [07:54<01:39,  1.18s/it]Running loglikelihood requests:  79%|███████▉  | 316/400 [07:55<01:38,  1.17s/it]Running loglikelihood requests:  79%|███████▉  | 317/400 [07:56<01:37,  1.17s/it]Running loglikelihood requests:  80%|███████▉  | 318/400 [07:57<01:35,  1.17s/it]Running loglikelihood requests:  80%|███████▉  | 319/400 [07:58<01:34,  1.17s/it]Running loglikelihood requests:  80%|████████  | 320/400 [08:00<01:33,  1.16s/it]Running loglikelihood requests:  80%|████████  | 321/400 [08:01<01:31,  1.16s/it]Running loglikelihood requests:  80%|████████  | 322/400 [08:02<01:30,  1.16s/it]Running loglikelihood requests:  81%|████████  | 323/400 [08:03<01:29,  1.16s/it]Running loglikelihood requests:  81%|████████  | 324/400 [08:04<01:28,  1.16s/it]Running loglikelihood requests:  81%|████████▏ | 325/400 [08:05<01:26,  1.16s/it]Running loglikelihood requests:  82%|████████▏ | 326/400 [08:07<01:25,  1.15s/it]Running loglikelihood requests:  82%|████████▏ | 327/400 [08:08<01:24,  1.15s/it]Running loglikelihood requests:  82%|████████▏ | 328/400 [08:09<01:22,  1.15s/it]Running loglikelihood requests:  82%|████████▏ | 329/400 [08:10<01:21,  1.15s/it]Running loglikelihood requests:  82%|████████▎ | 330/400 [08:11<01:20,  1.15s/it]Running loglikelihood requests:  83%|████████▎ | 331/400 [08:12<01:19,  1.15s/it]Running loglikelihood requests:  83%|████████▎ | 332/400 [08:13<01:17,  1.15s/it]Running loglikelihood requests:  83%|████████▎ | 333/400 [08:15<01:16,  1.14s/it]Running loglikelihood requests:  84%|████████▎ | 334/400 [08:16<01:15,  1.14s/it]Running loglikelihood requests:  84%|████████▍ | 335/400 [08:17<01:14,  1.14s/it]Running loglikelihood requests:  84%|████████▍ | 336/400 [08:18<01:12,  1.14s/it]Running loglikelihood requests:  84%|████████▍ | 337/400 [08:19<01:11,  1.14s/it]Running loglikelihood requests:  84%|████████▍ | 338/400 [08:20<01:10,  1.13s/it]Running loglikelihood requests:  85%|████████▍ | 339/400 [08:21<01:09,  1.13s/it]Running loglikelihood requests:  85%|████████▌ | 340/400 [08:22<01:07,  1.13s/it]Running loglikelihood requests:  85%|████████▌ | 341/400 [08:24<01:06,  1.13s/it]Running loglikelihood requests:  86%|████████▌ | 342/400 [08:25<01:05,  1.13s/it]Running loglikelihood requests:  86%|████████▌ | 343/400 [08:26<01:03,  1.12s/it]Running loglikelihood requests:  86%|████████▌ | 344/400 [08:27<01:02,  1.12s/it]Running loglikelihood requests:  86%|████████▋ | 345/400 [08:28<01:01,  1.12s/it]Running loglikelihood requests:  86%|████████▋ | 346/400 [08:29<01:00,  1.11s/it]Running loglikelihood requests:  87%|████████▋ | 347/400 [08:30<00:59,  1.11s/it]Running loglikelihood requests:  87%|████████▋ | 348/400 [08:31<00:58,  1.12s/it]Running loglikelihood requests:  87%|████████▋ | 349/400 [08:33<00:56,  1.11s/it]Running loglikelihood requests:  88%|████████▊ | 350/400 [08:34<00:56,  1.12s/it]Running loglikelihood requests:  88%|████████▊ | 351/400 [08:35<00:55,  1.14s/it]Running loglikelihood requests:  88%|████████▊ | 352/400 [08:36<00:55,  1.15s/it]Running loglikelihood requests:  88%|████████▊ | 353/400 [08:37<00:54,  1.16s/it]Running loglikelihood requests:  88%|████████▊ | 354/400 [08:38<00:53,  1.17s/it]Running loglikelihood requests:  89%|████████▉ | 355/400 [08:40<00:52,  1.17s/it]Running loglikelihood requests:  89%|████████▉ | 356/400 [08:41<00:50,  1.14s/it]Running loglikelihood requests:  89%|████████▉ | 357/400 [08:42<00:48,  1.12s/it]Running loglikelihood requests:  90%|████████▉ | 358/400 [08:43<00:47,  1.12s/it]Running loglikelihood requests:  90%|████████▉ | 359/400 [08:44<00:45,  1.11s/it]Running loglikelihood requests:  90%|█████████ | 360/400 [08:45<00:43,  1.10s/it]Running loglikelihood requests:  90%|█████████ | 361/400 [08:46<00:42,  1.09s/it]Running loglikelihood requests:  90%|█████████ | 362/400 [08:47<00:41,  1.09s/it]Running loglikelihood requests:  91%|█████████ | 363/400 [08:48<00:40,  1.08s/it]Running loglikelihood requests:  91%|█████████ | 364/400 [08:49<00:38,  1.08s/it]Running loglikelihood requests:  91%|█████████▏| 365/400 [08:50<00:37,  1.08s/it]Running loglikelihood requests:  92%|█████████▏| 366/400 [08:51<00:36,  1.08s/it]Running loglikelihood requests:  92%|█████████▏| 367/400 [08:53<00:35,  1.08s/it]Running loglikelihood requests:  92%|█████████▏| 368/400 [08:54<00:34,  1.08s/it]Running loglikelihood requests:  92%|█████████▏| 369/400 [08:55<00:33,  1.08s/it]Running loglikelihood requests:  92%|█████████▎| 370/400 [08:56<00:32,  1.07s/it]Running loglikelihood requests:  93%|█████████▎| 371/400 [08:57<00:31,  1.07s/it]Running loglikelihood requests:  93%|█████████▎| 372/400 [08:58<00:29,  1.06s/it]Running loglikelihood requests:  93%|█████████▎| 373/400 [08:59<00:28,  1.06s/it]Running loglikelihood requests:  94%|█████████▎| 374/400 [09:00<00:27,  1.07s/it]Running loglikelihood requests:  94%|█████████▍| 375/400 [09:01<00:26,  1.07s/it]Running loglikelihood requests:  94%|█████████▍| 376/400 [09:02<00:25,  1.06s/it]Running loglikelihood requests:  94%|█████████▍| 377/400 [09:03<00:23,  1.04s/it]Running loglikelihood requests:  94%|█████████▍| 378/400 [09:04<00:22,  1.03s/it]Running loglikelihood requests:  95%|█████████▍| 379/400 [09:05<00:21,  1.02s/it]Running loglikelihood requests:  95%|█████████▌| 380/400 [09:06<00:20,  1.00s/it]Running loglikelihood requests:  95%|█████████▌| 381/400 [09:07<00:18,  1.01it/s]Running loglikelihood requests:  96%|█████████▌| 382/400 [09:08<00:17,  1.02it/s]Running loglikelihood requests:  96%|█████████▌| 383/400 [09:09<00:16,  1.02it/s]Running loglikelihood requests:  96%|█████████▌| 384/400 [09:10<00:15,  1.03it/s]Running loglikelihood requests:  96%|█████████▋| 385/400 [09:11<00:14,  1.04it/s]Running loglikelihood requests:  96%|█████████▋| 386/400 [09:12<00:13,  1.04it/s]Running loglikelihood requests:  97%|█████████▋| 387/400 [09:13<00:12,  1.04it/s]Running loglikelihood requests:  97%|█████████▋| 389/400 [09:14<00:08,  1.37it/s]Running loglikelihood requests:  98%|█████████▊| 390/400 [09:15<00:07,  1.29it/s]Running loglikelihood requests:  98%|█████████▊| 391/400 [09:16<00:07,  1.23it/s]Running loglikelihood requests:  98%|█████████▊| 393/400 [09:16<00:04,  1.55it/s]Running loglikelihood requests:  98%|█████████▊| 394/400 [09:17<00:04,  1.44it/s]Running loglikelihood requests:  99%|█████████▉| 395/400 [09:18<00:03,  1.36it/s]Running loglikelihood requests:  99%|█████████▉| 396/400 [09:19<00:03,  1.31it/s]Running loglikelihood requests:  99%|█████████▉| 397/400 [09:20<00:02,  1.27it/s]Running loglikelihood requests: 100%|█████████▉| 398/400 [09:21<00:01,  1.25it/s]Running loglikelihood requests: 100%|█████████▉| 399/400 [09:21<00:00,  1.23it/s]Running loglikelihood requests: 100%|██████████| 400/400 [09:22<00:00,  1.22it/s]Running loglikelihood requests: 100%|██████████| 400/400 [09:22<00:00,  1.41s/it]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:6'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:6'}
full model:
{'logiqa': {'alias': 'logiqa', 'acc,none': 0.29, 'acc_stderr,none': 0.045604802157206865, 'acc_norm,none': 0.33, 'acc_norm_stderr,none': 0.04725815626252609}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9179964803140478
0.7817057225882229
0.8413553272072316
0.9274797474668193
0.8768807463293081
0.9494139907523571
0.8960692461846443
0.9131107283061946
0.6329173647892901
0.8375042173336539
0.8817471801904351
0.8172295355829869
0.7824572665005357
0.9227400642857845
0.9246594853497696
0.8075911590072223
0.6900210787422486
0.599615993999193
0.9308030044211123
0.9504015361511146
0.8866807231108503
0.540104242930401
0.6701728801805507
0.9744992661822648
0.8193037468812308
0.840784693447352
0.9052511591891966
Total groups 70 exceeded the threshold, stopping comparison.
The group tensor is
[3, 6, 7, 1, 5, 2, 4, 0]
tensor([3, 6, 7, 1, 5, 2, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 2, 6, 3, 7, 1, 5, 0]
tensor([4, 2, 6, 3, 7, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 3, 6, 1, 7, 2, 4, 0]
tensor([5, 3, 6, 1, 7, 2, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 4, 6, 1, 7, 2, 3, 0]
tensor([5, 4, 6, 1, 7, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 3, 0, 2, 1, 0, 4, 1]
tensor([5, 3, 0, 2, 1, 0, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 0, 5, 0, 1, 2, 3, 1]
tensor([4, 0, 5, 0, 1, 2, 3, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Normal merging for layer 2
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 4 to 8
done!
Normal merging for layer 9
tensor([2, 5])
tensor(2)
tensor([4, 7])
tensor(4)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 10 to 13
done!
Normal merging for layer 14
tensor([1, 3])
tensor(1)
tensor([4, 7])
tensor(4)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Cross-layer merge completed for layers 15 to 31
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 3 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 11.9458 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 2 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

110
cuda:6
coqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:57<00:57, 57.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:13<00:00, 33.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:13<00:00, 36.85s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa HTTP/1.1" 200 857
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/EleutherAI/coqa/EleutherAI/coqa.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa HTTP/1.1" 200 857
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/coqa/resolve/82e11af842af6c1396f5e9a5c7de260107c50cf1/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa/tree/82e11af842af6c1396f5e9a5c7de260107c50cf1/data?recursive=False&expand=False HTTP/1.1" 404 79
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa/tree/82e11af842af6c1396f5e9a5c7de260107c50cf1/data?recursive=False&expand=False HTTP/1.1" 404 79
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/coqa/resolve/82e11af842af6c1396f5e9a5c7de260107c50cf1/dataset_infos.json HTTP/1.1" 200 0
DEBUG:filelock:Attempting to acquire lock 139703678132416 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___coqa_default_0.0.0_82e11af842af6c1396f5e9a5c7de260107c50cf1.lock
DEBUG:filelock:Lock 139703678132416 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___coqa_default_0.0.0_82e11af842af6c1396f5e9a5c7de260107c50cf1.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1/dataset_info.json
DEBUG:filelock:Attempting to release lock 139703678132416 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___coqa_default_0.0.0_82e11af842af6c1396f5e9a5c7de260107c50cf1.lock
DEBUG:filelock:Lock 139703678132416 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___coqa_default_0.0.0_82e11af842af6c1396f5e9a5c7de260107c50cf1.lock
DEBUG:filelock:Attempting to acquire lock 139703006987232 on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1_builder.lock
DEBUG:filelock:Lock 139703006987232 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1/dataset_info.json
DEBUG:filelock:Attempting to release lock 139703006987232 on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1_builder.lock
DEBUG:filelock:Lock 139703006987232 released on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
DEBUG:lm_eval.api.task:doc_to_target returned a list. Assuming multiple targets.
INFO:lm_eval.evaluator:coqa: Using gen_kwargs: {'until': ['\nQ:']}
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of coqa from None to 0
INFO:lm_eval.api.task:Building contexts for coqa on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 72402.97it/s]
DEBUG:lm_eval.evaluator:Task: coqa; number of requests on this rank: 100
INFO:lm_eval.evaluator:Running generate_until requests
Running generate_until requests:   0%|          | 0/100 [00:00<?, ?it/s]Running generate_until requests:   1%|          | 1/100 [00:05<09:22,  5.69s/it]Running generate_until requests:   2%|▏         | 2/100 [00:10<08:29,  5.20s/it]Running generate_until requests:   3%|▎         | 3/100 [00:16<08:57,  5.54s/it]Running generate_until requests:   4%|▍         | 4/100 [00:21<08:25,  5.27s/it]Running generate_until requests:   5%|▌         | 5/100 [00:26<08:10,  5.17s/it]Running generate_until requests:   6%|▌         | 6/100 [00:30<07:45,  4.95s/it]Running generate_until requests:   7%|▋         | 7/100 [00:36<07:56,  5.12s/it]Running generate_until requests:   8%|▊         | 8/100 [00:40<07:34,  4.95s/it]Running generate_until requests:   9%|▉         | 9/100 [00:45<07:30,  4.95s/it]Running generate_until requests:  10%|█         | 10/100 [00:51<07:36,  5.07s/it]Running generate_until requests:  11%|█         | 11/100 [00:56<07:32,  5.09s/it]Running generate_until requests:  12%|█▏        | 12/100 [01:03<08:13,  5.61s/it]Running generate_until requests:  13%|█▎        | 13/100 [01:07<07:36,  5.24s/it]Running generate_until requests:  14%|█▍        | 14/100 [01:11<07:06,  4.96s/it]Running generate_until requests:  15%|█▌        | 15/100 [01:16<06:50,  4.83s/it]Running generate_until requests:  16%|█▌        | 16/100 [01:20<06:30,  4.65s/it]Running generate_until requests:  17%|█▋        | 17/100 [01:24<06:18,  4.57s/it]Running generate_until requests:  18%|█▊        | 18/100 [01:29<06:02,  4.42s/it]Running generate_until requests:  19%|█▉        | 19/100 [01:33<05:56,  4.40s/it]Running generate_until requests:  20%|██        | 20/100 [01:37<05:47,  4.34s/it]Running generate_until requests:  21%|██        | 21/100 [01:41<05:42,  4.34s/it]Running generate_until requests:  22%|██▏       | 22/100 [01:46<05:44,  4.42s/it]Running generate_until requests:  23%|██▎       | 23/100 [01:51<06:02,  4.70s/it]Running generate_until requests:  24%|██▍       | 24/100 [01:57<06:07,  4.84s/it]Running generate_until requests:  25%|██▌       | 25/100 [02:01<05:53,  4.71s/it]Running generate_until requests:  26%|██▌       | 26/100 [02:05<05:44,  4.65s/it]Running generate_until requests:  27%|██▋       | 27/100 [02:10<05:36,  4.61s/it]Running generate_until requests:  28%|██▊       | 28/100 [02:15<05:31,  4.60s/it]Running generate_until requests:  29%|██▉       | 29/100 [02:19<05:23,  4.55s/it]Running generate_until requests:  30%|███       | 30/100 [02:24<05:19,  4.56s/it]Running generate_until requests:  31%|███       | 31/100 [02:28<05:03,  4.39s/it]Running generate_until requests:  32%|███▏      | 32/100 [02:32<05:04,  4.47s/it]Running generate_until requests:  33%|███▎      | 33/100 [02:37<05:08,  4.61s/it]Running generate_until requests:  34%|███▍      | 34/100 [02:42<05:02,  4.59s/it]Running generate_until requests:  35%|███▌      | 35/100 [02:46<04:45,  4.39s/it]Running generate_until requests:  36%|███▌      | 36/100 [02:51<05:01,  4.71s/it]Running generate_until requests:  37%|███▋      | 37/100 [02:55<04:41,  4.46s/it]Running generate_until requests:  38%|███▊      | 38/100 [02:59<04:28,  4.32s/it]Running generate_until requests:  39%|███▉      | 39/100 [03:03<04:20,  4.28s/it]Running generate_until requests:  40%|████      | 40/100 [03:07<04:08,  4.14s/it]Running generate_until requests:  41%|████      | 41/100 [03:11<04:05,  4.16s/it]Running generate_until requests:  42%|████▏     | 42/100 [03:17<04:23,  4.54s/it]Running generate_until requests:  43%|████▎     | 43/100 [03:21<04:11,  4.42s/it]Running generate_until requests:  44%|████▍     | 44/100 [03:25<04:06,  4.40s/it]Running generate_until requests:  45%|████▌     | 45/100 [03:29<03:57,  4.31s/it]Running generate_until requests:  46%|████▌     | 46/100 [03:33<03:43,  4.14s/it]Running generate_until requests:  47%|████▋     | 47/100 [03:37<03:32,  4.01s/it]Running generate_until requests:  48%|████▊     | 48/100 [03:41<03:31,  4.07s/it]Running generate_until requests:  49%|████▉     | 49/100 [03:46<03:38,  4.29s/it]Running generate_until requests:  50%|█████     | 50/100 [03:49<03:25,  4.11s/it]Running generate_until requests:  51%|█████     | 51/100 [03:54<03:30,  4.29s/it]Running generate_until requests:  52%|█████▏    | 52/100 [03:58<03:16,  4.09s/it]Running generate_until requests:  53%|█████▎    | 53/100 [04:02<03:15,  4.15s/it]Running generate_until requests:  54%|█████▍    | 54/100 [04:06<03:03,  4.00s/it]Running generate_until requests:  55%|█████▌    | 55/100 [04:10<03:00,  4.01s/it]Running generate_until requests:  56%|█████▌    | 56/100 [04:14<03:02,  4.15s/it]Running generate_until requests:  57%|█████▋    | 57/100 [04:18<03:00,  4.19s/it]Running generate_until requests:  58%|█████▊    | 58/100 [04:23<02:55,  4.18s/it]Running generate_until requests:  59%|█████▉    | 59/100 [04:28<03:07,  4.56s/it]Running generate_until requests:  60%|██████    | 60/100 [04:32<02:51,  4.30s/it]Running generate_until requests:  61%|██████    | 61/100 [04:36<02:51,  4.40s/it]Running generate_until requests:  62%|██████▏   | 62/100 [04:41<02:49,  4.47s/it]Running generate_until requests:  63%|██████▎   | 63/100 [04:45<02:36,  4.22s/it]Running generate_until requests:  64%|██████▍   | 64/100 [04:48<02:25,  4.05s/it]Running generate_until requests:  65%|██████▌   | 65/100 [04:52<02:16,  3.90s/it]Running generate_until requests:  66%|██████▌   | 66/100 [04:55<02:08,  3.79s/it]Running generate_until requests:  67%|██████▋   | 67/100 [04:59<02:02,  3.71s/it]Running generate_until requests:  68%|██████▊   | 68/100 [05:03<02:02,  3.84s/it]Running generate_until requests:  69%|██████▉   | 69/100 [05:09<02:14,  4.35s/it]Running generate_until requests:  70%|███████   | 70/100 [05:13<02:07,  4.25s/it]Running generate_until requests:  71%|███████   | 71/100 [05:21<02:37,  5.44s/it]Running generate_until requests:  72%|███████▏  | 72/100 [05:24<02:17,  4.90s/it]Running generate_until requests:  73%|███████▎  | 73/100 [05:28<02:00,  4.48s/it]Running generate_until requests:  74%|███████▍  | 74/100 [05:32<01:51,  4.29s/it]Running generate_until requests:  75%|███████▌  | 75/100 [05:35<01:41,  4.05s/it]Running generate_until requests:  76%|███████▌  | 76/100 [05:39<01:32,  3.87s/it]Running generate_until requests:  77%|███████▋  | 77/100 [05:43<01:32,  4.01s/it]Running generate_until requests:  78%|███████▊  | 78/100 [05:47<01:25,  3.87s/it]Running generate_until requests:  79%|███████▉  | 79/100 [05:50<01:17,  3.68s/it]Running generate_until requests:  80%|████████  | 80/100 [05:54<01:14,  3.70s/it]Running generate_until requests:  81%|████████  | 81/100 [05:59<01:20,  4.26s/it]Running generate_until requests:  82%|████████▏ | 82/100 [06:02<01:10,  3.94s/it]Running generate_until requests:  83%|████████▎ | 83/100 [06:06<01:05,  3.86s/it]Running generate_until requests:  84%|████████▍ | 84/100 [06:10<01:00,  3.77s/it]Running generate_until requests:  85%|████████▌ | 85/100 [06:13<00:55,  3.69s/it]Running generate_until requests:  86%|████████▌ | 86/100 [06:17<00:52,  3.72s/it]Running generate_until requests:  87%|████████▋ | 87/100 [06:22<00:52,  4.00s/it]Running generate_until requests:  88%|████████▊ | 88/100 [06:25<00:47,  3.92s/it]Running generate_until requests:  89%|████████▉ | 89/100 [06:28<00:40,  3.72s/it]Running generate_until requests:  90%|█████████ | 90/100 [06:32<00:35,  3.54s/it]Running generate_until requests:  91%|█████████ | 91/100 [06:34<00:29,  3.28s/it]Running generate_until requests:  92%|█████████▏| 92/100 [06:37<00:24,  3.12s/it]Running generate_until requests:  93%|█████████▎| 93/100 [06:40<00:21,  3.03s/it]Running generate_until requests:  94%|█████████▍| 94/100 [06:43<00:18,  3.00s/it]Running generate_until requests:  95%|█████████▌| 95/100 [06:46<00:15,  3.05s/it]Running generate_until requests:  96%|█████████▌| 96/100 [06:49<00:12,  3.04s/it]Running generate_until requests:  97%|█████████▋| 97/100 [06:51<00:08,  2.87s/it]Running generate_until requests:  98%|█████████▊| 98/100 [06:54<00:05,  2.74s/it]Running generate_until requests:  99%|█████████▉| 99/100 [06:57<00:02,  2.72s/it]Running generate_until requests: 100%|██████████| 100/100 [06:59<00:00,  2.73s/it]Running generate_until requests: 100%|██████████| 100/100 [06:59<00:00,  4.20s/it]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:7'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:7'}
full model:
{'coqa': {'alias': 'coqa', 'em,none': 0.595, 'em_stderr,none': 0.044774970461162564, 'f1,none': 0.7211574141733987, 'f1_stderr,none': 0.037128235455690536}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.6057853926542468
0.4195568875297668
0.5244744113321889
0.5202703028806769
0.6150870974034927
0.5299634576457063
0.9336763524510373
0.23649940737178063
0.388911200696845
0.6478041116722705
0.5517233675449297
0.6723258763091353
0.7175526480521238
0.8411089149883405
0.7404554224148189
0.26376935916880817
0.9373006475493478
0.5360566853939598
0.38729358133282565
0.4541602442018795
0.8623573205888978
0.7318340566806717
0.6643209906079897
0.8122565195147101
0.4707270481319977
0.9785001455445378
0.17075087907531752
0.489625917805058
0.7595051272431785
0.6057853926542468
0.4195568875297668
0.5244744113321889
0.5202703028806769
0.6150870974034927
0.5299634576457063
0.9336763524510373
0.23649940737178063
0.388911200696845
0.6478041116722705
0.5517233675449297
0.6723258763091353
0.7175526480521238
0.8411089149883405
0.7404554224148189
0.26376935916880817
0.9373006475493478
0.5360566853939598
0.38729358133282565
0.4541602442018795
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[5, 4, 3, 2, 0, 1, 7, 6]
tensor([5, 4, 3, 2, 0, 1, 7, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 3, 4, 0, 2, 1, 7, 6]
tensor([5, 3, 4, 0, 2, 1, 7, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 1, 7, 0, 6, 2, 3, 4]
tensor([5, 1, 7, 0, 6, 2, 3, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 3, 6, 0, 5, 2, 4, 1]
tensor([7, 3, 6, 0, 5, 2, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 5, 7, 2, 4, 0, 3, 1]
tensor([6, 5, 7, 2, 4, 0, 3, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 5, 0, 0, 1, 2, 1, 3]
tensor([4, 5, 0, 0, 1, 2, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1, 2, 2, 0, 3, 3]
tensor([0, 1, 1, 2, 2, 0, 3, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([7])
tensor(7)
tensor([6])
tensor(6)
done!
Normal merging for layer 2
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
done!
Normal merging for layer 4
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Cross-layer merge completed for layers 5 to 8
done!
Normal merging for layer 9
tensor([2, 3])
tensor(2)
tensor([4, 6])
tensor(4)
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([1])
tensor(1)
done!
Cross-layer merge completed for layers 10 to 22
done!
Normal merging for layer 23
tensor([0, 5])
tensor(0)
tensor([1, 2])
tensor(1)
tensor([3, 4])
tensor(3)
tensor([6, 7])
tensor(6)
done!
Cross-layer merge completed for layers 24 to 31
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 2 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.3238 GB

===== 🚀【CUDA 检查开始】[after create model] =====
🔍 找到 1 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

234
cuda:7
rte
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:57<00:57, 57.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:17<00:00, 35.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:17<00:00, 38.97s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: rte] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: rte] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:filelock:Attempting to acquire lock 139681108775216 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139681108775216 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139681108775216 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139681108775216 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139681104137584 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139681104137584 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139681104137584 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139681104137584 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of rte from None to 0
INFO:lm_eval.api.task:Building contexts for rte on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 2612.79it/s]
DEBUG:lm_eval.evaluator:Task: rte; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:02<07:10,  2.16s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:03<03:36,  1.10s/it]Running loglikelihood requests:   2%|▎         | 5/200 [00:04<02:49,  1.15it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:06<02:26,  1.32it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:07<02:14,  1.42it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:08<02:06,  1.49it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:09<02:00,  1.55it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:11<01:59,  1.55it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:12<01:53,  1.61it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:13<01:50,  1.64it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:14<01:46,  1.69it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:15<01:43,  1.71it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:16<01:39,  1.76it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:17<01:35,  1.81it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:18<01:34,  1.82it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:19<01:32,  1.83it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:20<01:29,  1.87it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:22<01:29,  1.84it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:23<01:28,  1.84it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:24<01:24,  1.90it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:25<01:21,  1.95it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:26<01:19,  1.98it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:26<01:16,  2.02it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:27<01:13,  2.07it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:28<01:10,  2.13it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:29<01:07,  2.20it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:30<01:04,  2.26it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:31<01:02,  2.31it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:32<01:00,  2.37it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:32<00:58,  2.43it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:33<00:56,  2.47it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:34<00:54,  2.51it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:35<00:54,  2.47it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:35<00:53,  2.48it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:36<00:52,  2.51it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:37<00:51,  2.52it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:38<00:50,  2.51it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:39<00:49,  2.54it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:39<00:47,  2.61it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:40<00:45,  2.66it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:41<00:43,  2.71it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:41<00:42,  2.75it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:42<00:41,  2.78it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:43<00:40,  2.80it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:44<00:39,  2.82it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:44<00:38,  2.82it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:45<00:38,  2.78it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:46<00:38,  2.75it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:46<00:37,  2.75it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:47<00:37,  2.73it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:48<00:35,  2.78it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:49<00:34,  2.83it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:49<00:34,  2.76it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:50<00:34,  2.67it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:51<00:33,  2.72it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:52<00:33,  2.68it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:52<00:31,  2.77it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:53<00:30,  2.82it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:54<00:29,  2.84it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:54<00:28,  2.86it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:55<00:27,  2.88it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:56<00:26,  2.90it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:56<00:25,  2.92it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [00:57<00:24,  2.97it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [00:58<00:23,  3.01it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [00:58<00:22,  3.04it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [00:59<00:21,  3.08it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [01:00<00:20,  3.11it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [01:00<00:20,  3.11it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [01:01<00:19,  3.15it/s]Running loglikelihood requests:  70%|███████   | 141/200 [01:01<00:18,  3.18it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [01:02<00:17,  3.21it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [01:03<00:17,  3.21it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [01:03<00:16,  3.19it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [01:04<00:16,  3.18it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [01:05<00:15,  3.07it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [01:05<00:15,  3.04it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [01:06<00:14,  3.00it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [01:07<00:14,  3.02it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [01:07<00:13,  3.05it/s]Running loglikelihood requests:  80%|████████  | 161/200 [01:08<00:12,  3.04it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [01:09<00:12,  3.06it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [01:09<00:11,  3.09it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [01:10<00:10,  3.15it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [01:10<00:09,  3.23it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [01:11<00:08,  3.30it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [01:12<00:08,  3.32it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [01:12<00:07,  3.34it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [01:13<00:06,  3.35it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [01:13<00:06,  3.36it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [01:14<00:05,  3.35it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [01:15<00:05,  3.34it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [01:15<00:04,  3.33it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [01:16<00:03,  3.33it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [01:16<00:03,  3.39it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [01:17<00:02,  3.46it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [01:17<00:01,  3.52it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:18<00:01,  3.57it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:19<00:00,  3.67it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:19<00:00,  3.74it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:19<00:00,  2.52it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/task_util.py:69: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
full model:
{'rte': {'alias': 'rte', 'acc,none': 0.5, 'acc_stderr,none': 0.050251890762960605}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.34161229456626735
0.905233410256777
0.5205040718697735
0.4121994254524892
0.7398116665887099
0.6225415196831932
0.7923970242263771
0.7353888240887675
0.6535613357308766
0.7757058271862038
0.734046359122903
0.4471799126982846
0.773619360921301
0.7955347039939479
0.8672068064531693
0.8652880343596522
0.3302235467760883
0.6789268064017625
0.6072221471952108
0.9194446824778495
0.4812004589187253
0.5728915095234594
0.1682455054057436
0.93212414632396
0.9148362604533635
0.8268537756297094
0.7592245907029287
0.7256008379011685
0.7109756105942956
0.34161229456626735
0.905233410256777
0.5205040718697735
0.4121994254524892
0.7398116665887099
0.6225415196831932
0.7923970242263771
0.7353888240887675
0.6535613357308766
0.7757058271862038
0.734046359122903
0.4471799126982846
0.773619360921301
0.7955347039939479
0.8672068064531693
0.8652880343596522
0.3302235467760883
0.6789268064017625
0.6072221471952108
0.9194446824778495
0.4812004589187253
Total groups 73 exceeded the threshold, stopping comparison.
The group tensor is
[5, 2, 7, 1, 6, 4, 3, 0]
tensor([5, 2, 7, 1, 6, 4, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 6, 0, 7, 3, 4, 1]
tensor([5, 2, 6, 0, 7, 3, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 7, 2, 5, 4, 3, 0]
tensor([6, 1, 7, 2, 5, 4, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 7, 2, 4, 1, 5, 0]
tensor([6, 3, 7, 2, 4, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 5, 6, 2, 3, 1, 4, 0]
tensor([7, 5, 6, 2, 3, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 2, 5, 4, 1, 0, 1, 3]
tensor([0, 2, 5, 4, 1, 0, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1.0, 1.0, 0, 1.0, 1]
tensor([0, 1, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
Normal merging for layer 1
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Normal merging for layer 2
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 4
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 5 to 8
done!
Normal merging for layer 9
tensor([0, 5])
tensor(0)
tensor([4, 6])
tensor(4)
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
done!
Cross-layer merge completed for layers 10 to 30
done!
Normal merging for layer 31
tensor([0, 5])
tensor(0)
tensor([1, 2, 3, 4, 6, 7])
tensor(1)
done!
all done!

===== 🚀【CUDA 检查开始】[after model release] =====
🔍 找到 1 个仍驻留在 CUDA 上的张量:
  - 类型: Parameter            | 尺寸: (1, 1) | 显存: 0.00 MB
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after model release] =====

Model size: 12.1348 GB

===== 🚀【CUDA 检查开始】[after create model] =====
✅ 没有发现任何驻留在 CUDA 上的张量，显存清理成功。
🧠 总占用 CUDA 显存（非缓存）: 0.00 MB
===== ✅【CUDA 检查结束】[after create model] =====

Node 183 Flask server is running on port 5183...
Node 53 Flask server is running on port 5053...
Node 148 Flask server is running on port 5148...
Node 40 Flask server is running on port 5040...
Node 157 Flask server is running on port 5157...
Node 101 Flask server is running on port 5101...
Node 30 Flask server is running on port 5030...
Node 218 Flask server is running on port 5218...
Node 73 Flask server is running on port 5073...
Node 19 Flask server is running on port 5019...
Node 202 Flask server is running on port 5202...
Node 108 Flask server is running on port 5108...
 * Serving Flask app 'Node_llama_test'
Node 225 Flask server is running on port 5225...
Node 81 Flask server is running on port 5081...
 * Debug mode: off
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
Node 110 Flask server is running on port 5110...
Node 234 Flask server is running on port 5234...
[183] Inference Step Starting
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5202
 * Running on http://173.0.64.7:5202
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5019
 * Running on http://173.0.64.7:5019
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5183
 * Running on http://173.0.64.7:5183
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5218
 * Running on http://173.0.64.7:5218
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5073
 * Running on http://173.0.64.7:5073
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5110
 * Running on http://173.0.64.7:5110
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5053
 * Running on http://173.0.64.7:5053
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5225
 * Running on http://173.0.64.7:5225
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5108
 * Running on http://173.0.64.7:5108
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5030
 * Running on http://173.0.64.7:5030
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5101
 * Running on http://173.0.64.7:5101
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5148
 * Running on http://173.0.64.7:5148
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5040
 * Running on http://173.0.64.7:5040
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5157
 * Running on http://173.0.64.7:5157
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5234
 * Running on http://173.0.64.7:5234
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5081
 * Running on http://173.0.64.7:5081
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[33mPress CTRL+C to quit[0m
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/revision/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 111
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/revision/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/wnli?recursive=False&expand=False HTTP/1.1" 307 141
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/wnli?recursive=False&expand=False HTTP/1.1" 200 352
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139708039261760 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139708039261760 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139708039261760 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139708039261760 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139705425424944 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139705425424944 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139705425424944 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139705425424944 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2579.88it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:33<1:18:08, 33.25s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:58<41:53, 18.08s/it]  Running loglikelihood requests:   4%|▎         | 5/142 [01:05<23:51, 10.45s/it]Running loglikelihood requests:   5%|▍         | 7/142 [01:27<23:55, 10.63s/it]Running loglikelihood requests:   6%|▋         | 9/142 [02:35<43:10, 19.48s/it]Running loglikelihood requests:   8%|▊         | 11/142 [03:51<56:50, 26.04s/it]Running loglikelihood requests:   9%|▉         | 13/142 [04:09<43:38, 20.30s/it]Running loglikelihood requests:  11%|█         | 15/142 [04:14<30:57, 14.62s/it]Running loglikelihood requests:  12%|█▏        | 17/142 [04:20<22:55, 11.00s/it]Running loglikelihood requests:  13%|█▎        | 19/142 [04:40<21:36, 10.54s/it]Running loglikelihood requests:  15%|█▍        | 21/142 [04:50<17:56,  8.89s/it]Running loglikelihood requests:  16%|█▌        | 23/142 [04:56<14:01,  7.07s/it]Running loglikelihood requests:  18%|█▊        | 25/142 [05:18<16:06,  8.26s/it]Running loglikelihood requests:  19%|█▉        | 27/142 [05:31<14:51,  7.75s/it]Running loglikelihood requests:  20%|██        | 29/142 [05:43<13:41,  7.27s/it]Running loglikelihood requests:  22%|██▏       | 31/142 [06:05<15:21,  8.30s/it]Running loglikelihood requests:  23%|██▎       | 33/142 [06:22<15:14,  8.39s/it]Running loglikelihood requests:  25%|██▍       | 35/142 [06:33<13:33,  7.60s/it]Running loglikelihood requests:  26%|██▌       | 37/142 [06:42<11:36,  6.63s/it]Running loglikelihood requests:  27%|██▋       | 39/142 [06:56<11:32,  6.72s/it]Running loglikelihood requests:  29%|██▉       | 41/142 [07:04<10:01,  5.96s/it]Running loglikelihood requests:  30%|███       | 43/142 [07:13<08:55,  5.41s/it]Running loglikelihood requests:  32%|███▏      | 45/142 [07:18<07:21,  4.56s/it]Running loglikelihood requests:  33%|███▎      | 47/142 [07:31<08:16,  5.23s/it]Running loglikelihood requests:  35%|███▍      | 49/142 [07:38<07:15,  4.68s/it]Running loglikelihood requests:  36%|███▌      | 51/142 [07:49<07:29,  4.94s/it]Running loglikelihood requests:  37%|███▋      | 53/142 [07:55<06:32,  4.41s/it]Running loglikelihood requests:  39%|███▊      | 55/142 [08:01<05:40,  3.92s/it]Running loglikelihood requests:  40%|████      | 57/142 [08:14<06:42,  4.74s/it]Running loglikelihood requests:  42%|████▏     | 59/142 [08:19<05:36,  4.05s/it]Running loglikelihood requests:  43%|████▎     | 61/142 [08:28<05:42,  4.23s/it]Running loglikelihood requests:  44%|████▍     | 63/142 [08:38<05:44,  4.36s/it]Running loglikelihood requests:  46%|████▌     | 65/142 [08:47<05:40,  4.43s/it]Running loglikelihood requests:  47%|████▋     | 67/142 [08:59<06:07,  4.90s/it]Running loglikelihood requests:  49%|████▊     | 69/142 [09:07<05:33,  4.57s/it]Running loglikelihood requests:  50%|█████     | 71/142 [09:12<04:44,  4.00s/it]Running loglikelihood requests:  51%|█████▏    | 73/142 [09:20<04:38,  4.04s/it]Running loglikelihood requests:  53%|█████▎    | 75/142 [09:29<04:33,  4.08s/it]Running loglikelihood requests:  54%|█████▍    | 77/142 [09:38<04:37,  4.26s/it]Running loglikelihood requests:  56%|█████▌    | 79/142 [09:51<05:09,  4.92s/it]Running loglikelihood requests:  57%|█████▋    | 81/142 [10:02<05:11,  5.11s/it]Running loglikelihood requests:  58%|█████▊    | 83/142 [10:21<06:17,  6.39s/it]Running loglikelihood requests:  60%|█████▉    | 85/142 [10:34<06:11,  6.52s/it]Running loglikelihood requests:  61%|██████▏   | 87/142 [10:47<05:53,  6.43s/it]Running loglikelihood requests:  63%|██████▎   | 89/142 [10:49<04:19,  4.90s/it]Running loglikelihood requests:  64%|██████▍   | 91/142 [10:55<03:34,  4.20s/it]Running loglikelihood requests:  65%|██████▌   | 93/142 [11:00<03:04,  3.76s/it]Running loglikelihood requests:  67%|██████▋   | 95/142 [11:11<03:17,  4.21s/it]Running loglikelihood requests:  68%|██████▊   | 97/142 [11:16<02:48,  3.75s/it]Running loglikelihood requests:  70%|██████▉   | 99/142 [11:35<03:57,  5.52s/it]Running loglikelihood requests:  71%|███████   | 101/142 [11:55<04:42,  6.89s/it]Running loglikelihood requests:  73%|███████▎  | 103/142 [12:31<06:38, 10.21s/it]Running loglikelihood requests:  74%|███████▍  | 105/142 [12:41<05:18,  8.61s/it]Running loglikelihood requests:  75%|███████▌  | 107/142 [12:50<04:20,  7.44s/it]Running loglikelihood requests:  77%|███████▋  | 109/142 [13:16<04:58,  9.06s/it]Running loglikelihood requests:  78%|███████▊  | 111/142 [13:45<05:29, 10.62s/it]Running loglikelihood requests:  80%|███████▉  | 113/142 [13:55<04:20,  8.99s/it]Running loglikelihood requests:  81%|████████  | 115/142 [14:39<05:49, 12.95s/it]Running loglikelihood requests:  82%|████████▏ | 117/142 [15:20<06:20, 15.23s/it]Running loglikelihood requests:  84%|████████▍ | 119/142 [15:37<05:00, 13.09s/it]Running loglikelihood requests:  85%|████████▌ | 121/142 [15:48<03:47, 10.82s/it]Running loglikelihood requests:  87%|████████▋ | 123/142 [16:21<03:57, 12.51s/it]Running loglikelihood requests:  88%|████████▊ | 125/142 [16:29<02:51, 10.08s/it]Running loglikelihood requests:  89%|████████▉ | 127/142 [16:35<01:58,  7.91s/it]Running loglikelihood requests:  91%|█████████ | 129/142 [16:38<01:18,  6.00s/it]Running loglikelihood requests:  92%|█████████▏| 131/142 [16:44<00:56,  5.11s/it]Running loglikelihood requests:  94%|█████████▎| 133/142 [17:13<01:11,  7.95s/it]Running loglikelihood requests:  95%|█████████▌| 135/142 [17:29<00:55,  7.95s/it]Running loglikelihood requests:  96%|█████████▋| 137/142 [17:44<00:38,  7.71s/it]Running loglikelihood requests:  98%|█████████▊| 139/142 [18:05<00:25,  8.59s/it]Running loglikelihood requests:  99%|█████████▉| 141/142 [18:15<00:07,  7.50s/it]Running loglikelihood requests: 100%|██████████| 142/142 [18:15<00:00,  7.71s/it]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-4): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-9): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (11-12): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (13): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14-19): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (20-21): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (22-23): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (25-31): 7 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-4): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-9): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (11-12): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (13): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14-19): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (20-21): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (22-23): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (25-31): 7 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
ERROR:save_model:Error processing group 0: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 1: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 2: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 3: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 4: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 5: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 6: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 7: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 8: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 9: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 10: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 11: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 12: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 13: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 14: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 15: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
WARNING:save_model:Expert index -2 is negative, resetting to 0.
ERROR:save_model:Error processing group 16: LlamaMoEModel has no attribute `layers[2]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[2]`
ERROR:save_model:Error processing group 17: LlamaMoEModel has no attribute `layers[5]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[5]`
ERROR:save_model:Error processing group 18: LlamaMoEModel has no attribute `layers[5]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[5]`
ERROR:save_model:Error processing group 19: LlamaMoEModel has no attribute `layers[5]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[5]`
ERROR:save_model:Error processing group 20: LlamaMoEModel has no attribute `layers[5]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[5]`
ERROR:save_model:Error processing group 21: LlamaMoEModel has no attribute `layers[5]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[5]`
ERROR:save_model:Error processing group 22: LlamaMoEModel has no attribute `layers[5]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[5]`
ERROR:save_model:Error processing group 23: LlamaMoEModel has no attribute `layers[5]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[5]`
ERROR:save_model:Error processing group 24: LlamaMoEModel has no attribute `layers[5]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[5]`
WARNING:save_model:Expert index -2 is negative, resetting to 0.
ERROR:save_model:Error processing group 25: LlamaMoEModel has no attribute `layers[6]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[6]`
ERROR:save_model:Error processing group 26: LlamaMoEModel has no attribute `layers[10]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[10]`
ERROR:save_model:Error processing group 27: LlamaMoEModel has no attribute `layers[10]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[10]`
ERROR:save_model:Error processing group 28: LlamaMoEModel has no attribute `layers[10]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[10]`
ERROR:save_model:Error processing group 29: LlamaMoEModel has no attribute `layers[10]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[10]`
ERROR:save_model:Error processing group 30: LlamaMoEModel has no attribute `layers[10]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[10]`
ERROR:save_model:Error processing group 31: LlamaMoEModel has no attribute `layers[10]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[10]`
WARNING:save_model:Expert index -2 is negative, resetting to 0.
ERROR:save_model:Error processing group 32: LlamaMoEModel has no attribute `layers[11]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[11]`
ERROR:save_model:Error processing group 33: LlamaMoEModel has no attribute `layers[13]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[13]`
ERROR:save_model:Error processing group 34: LlamaMoEModel has no attribute `layers[13]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[13]`
ERROR:save_model:Error processing group 35: LlamaMoEModel has no attribute `layers[13]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[13]`
ERROR:save_model:Error processing group 36: LlamaMoEModel has no attribute `layers[13]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[13]`
ERROR:save_model:Error processing group 37: LlamaMoEModel has no attribute `layers[13]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[13]`
ERROR:save_model:Error processing group 38: LlamaMoEModel has no attribute `layers[13]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[13]`
WARNING:save_model:Expert index -2 is negative, resetting to 0.
ERROR:save_model:Error processing group 39: LlamaMoEModel has no attribute `layers[14]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[14]`
ERROR:save_model:Error processing group 40: LlamaMoEModel has no attribute `layers[20]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[20]`
ERROR:save_model:Error processing group 41: LlamaMoEModel has no attribute `layers[20]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[20]`
ERROR:save_model:Error processing group 42: LlamaMoEModel has no attribute `layers[20]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[20]`
ERROR:save_model:Error processing group 43: LlamaMoEModel has no attribute `layers[20]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[20]`
ERROR:save_model:Error processing group 44: LlamaMoEModel has no attribute `layers[21]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[21]`
ERROR:save_model:Error processing group 45: LlamaMoEModel has no attribute `layers[21]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[21]`
ERROR:save_model:Error processing group 46: LlamaMoEModel has no attribute `layers[21]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[21]`
ERROR:save_model:Error processing group 47: LlamaMoEModel has no attribute `layers[21]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[21]`
WARNING:save_model:Expert index -2 is negative, resetting to 0.
ERROR:save_model:Error processing group 48: LlamaMoEModel has no attribute `layers[22]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[22]`
ERROR:save_model:Error processing group 49: LlamaMoEModel has no attribute `layers[24]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[24]`
ERROR:save_model:Error processing group 50: LlamaMoEModel has no attribute `layers[24]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[24]`
WARNING:save_model:Expert index -2 is negative, resetting to 0.
ERROR:save_model:Error processing group 51: LlamaMoEModel has no attribute `layers[25]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[25]`
INFO:save_model:Model saved successfully at saved_models/183.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5040
INFO:werkzeug:127.0.0.1 - - [15/May/2025 14:53:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5040 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 40
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5108
INFO:werkzeug:127.0.0.1 - - [15/May/2025 14:53:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5108 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 108
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5110
INFO:werkzeug:127.0.0.1 - - [15/May/2025 14:53:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5110 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 110
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5157
INFO:werkzeug:127.0.0.1 - - [15/May/2025 14:53:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5157 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 157
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5234
INFO:werkzeug:127.0.0.1 - - [15/May/2025 14:53:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5234 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 234
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5202
INFO:werkzeug:127.0.0.1 - - [15/May/2025 14:53:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5202 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 202
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [15/May/2025 14:53:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5073
INFO:werkzeug:127.0.0.1 - - [15/May/2025 14:53:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5073 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 73
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5225
INFO:werkzeug:127.0.0.1 - - [15/May/2025 14:53:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5225 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 225
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5081
INFO:werkzeug:127.0.0.1 - - [15/May/2025 14:53:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5081 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 81
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5148
INFO:werkzeug:127.0.0.1 - - [15/May/2025 14:53:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5148 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 148
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5218
INFO:werkzeug:127.0.0.1 - - [15/May/2025 14:53:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5218 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 218
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5101
INFO:werkzeug:127.0.0.1 - - [15/May/2025 14:53:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5101 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 101
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5053
INFO:werkzeug:127.0.0.1 - - [15/May/2025 14:53:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5053 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 53
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5019
INFO:werkzeug:127.0.0.1 - - [15/May/2025 14:53:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5019 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 19
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139681108774400 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139681108774400 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139681108774400 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139681108774400 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139705425633664 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139705425633664 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139705425633664 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139705425633664 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[183] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.43661971830985913, 'acc_stderr,none': 0.05927935558412972}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8840011732877091
0.9530187867791682
0.922962504956303
0.7839472459406365
0.8981387177104178
0.9267264969548299
0.5821108615798573
0.2837945650872556
0.6077879555368297
0.40197237439213185
0.8904940347912964
0.7509530386402397
0.901875691813653
0.9122390055224058
0.7316046462179062
0.7968435583929763
0.548007144578676
0.5393492220671232
0.9101317167988644
0.5489553505889563
0.4310648048222707
0.3687557715800523
0.8114931082909914
0.5012706843250611
0.2095243909347347
0.3518983916697559
0.9676050865236582
0.8840253404453832
0.6389046419601837
0.8840011732877091
0.9530187867791682
0.922962504956303
0.7839472459406365
0.8981387177104178
0.9267264969548299
0.5821108615798573
0.2837945650872556
0.6077879555368297
0.40197237439213185
0.8904940347912964
0.7509530386402397
0.901875691813653
0.9122390055224058
0.7316046462179062
0.7968435583929763
0.548007144578676
0.5393492220671232
0.9101317167988644
0.5489553505889563
Total groups 72 exceeded the threshold, stopping comparison.
The group tensor is
[1, 2, 7, 4, 3, 0, 6, 5]
tensor([1, 2, 7, 4, 3, 0, 6, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 5, 4, 1, 0, 7, 2]
tensor([6, 3, 5, 4, 1, 0, 7, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[1, 3, 6, 4, 2, 0, 7, 5]
tensor([1, 3, 6, 4, 2, 0, 7, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 3, 6, 4, 0, 1, 7, 2]
tensor([5, 3, 6, 4, 0, 1, 7, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 4, 6, 5, 3, 0, 7, 1]
tensor([2, 4, 6, 5, 3, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 5, 2, 4, 0, 1, 3]
tensor([0, 1, 5, 2, 4, 0, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/183.pt
[RECEIVE] Queued message from 183
[QUEUE] Processing info from 183
[QUEUE] Stored info from 183
[RECEIVE] Queued message from 183
[QUEUE] Processing info from 183
[QUEUE] Stored info from 183
[RECEIVE] Queued message from 183
[QUEUE] Processing info from 183
[QUEUE] Stored info from 183
[RECEIVE] Queued message from 183
[QUEUE] Processing info from 183
[QUEUE] Stored info from 183
[RECEIVE] Queued message from 183
[QUEUE] Processing info from 183
[QUEUE] Stored info from 183
[RECEIVE] Queued message from 183
[QUEUE] Processing info from 183
[QUEUE] Stored info from 183
[RECEIVE] Queued message from 183
[QUEUE] Processing info from 183
[QUEUE] Stored info from 183
[RECEIVE] Queued message from 183
[QUEUE] Processing info from 183
[QUEUE] Stored info from 183
[RECEIVE] Queued message from 183
[QUEUE] Processing info from 183
[QUEUE] Stored info from 183
[RECEIVE] Queued message from 183
[QUEUE] Processing info from 183
[QUEUE] Stored info from 183
[RECEIVE] Queued message from 183
[QUEUE] Processing info from 183
[QUEUE] Stored info from 183
[RECEIVE] Queued message from 183
[QUEUE] Processing info from 183
[QUEUE] Stored info from 183
[RECEIVE] Queued message from 183
[QUEUE] Processing info from 183
[QUEUE] Stored info from 183
[RECEIVE] Queued message from 183
[QUEUE] Processing info from 183
[QUEUE] Stored info from 183
[RECEIVE] Queued message from 183
[QUEUE] Processing info from 183
[QUEUE] Stored info from 183
[53] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2547.00it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:22<52:10, 22.20s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:52<39:13, 16.93s/it]Running loglikelihood requests:   4%|▎         | 5/142 [01:18<34:12, 14.98s/it]Running loglikelihood requests:   5%|▍         | 7/142 [01:33<26:40, 11.85s/it]Running loglikelihood requests:   6%|▋         | 9/142 [01:49<22:53, 10.33s/it]Running loglikelihood requests:   8%|▊         | 11/142 [02:04<20:15,  9.28s/it]Running loglikelihood requests:   9%|▉         | 13/142 [02:16<17:37,  8.20s/it]Running loglikelihood requests:  11%|█         | 15/142 [02:28<15:48,  7.47s/it]Running loglikelihood requests:  12%|█▏        | 17/142 [02:36<13:16,  6.37s/it]Running loglikelihood requests:  13%|█▎        | 19/142 [03:01<17:10,  8.38s/it]Running loglikelihood requests:  15%|█▍        | 21/142 [03:08<13:44,  6.81s/it]Running loglikelihood requests:  16%|█▌        | 23/142 [03:21<13:22,  6.74s/it]Running loglikelihood requests:  18%|█▊        | 25/142 [03:28<11:13,  5.76s/it]Running loglikelihood requests:  19%|█▉        | 27/142 [03:32<08:51,  4.62s/it]Running loglikelihood requests:  20%|██        | 29/142 [03:39<07:57,  4.22s/it]Running loglikelihood requests:  22%|██▏       | 31/142 [03:46<07:32,  4.08s/it]Running loglikelihood requests:  23%|██▎       | 33/142 [03:49<06:05,  3.35s/it]Running loglikelihood requests:  25%|██▍       | 35/142 [03:54<05:20,  3.00s/it]Running loglikelihood requests:  26%|██▌       | 37/142 [03:57<04:31,  2.58s/it]Running loglikelihood requests:  27%|██▋       | 39/142 [04:00<04:00,  2.33s/it]Running loglikelihood requests:  29%|██▉       | 41/142 [04:03<03:23,  2.01s/it]Running loglikelihood requests:  30%|███       | 43/142 [04:05<02:56,  1.79s/it]Running loglikelihood requests:  32%|███▏      | 45/142 [04:09<02:45,  1.71s/it]Running loglikelihood requests:  33%|███▎      | 47/142 [04:14<03:18,  2.09s/it]Running loglikelihood requests:  35%|███▍      | 49/142 [04:17<02:52,  1.85s/it]Running loglikelihood requests:  36%|███▌      | 51/142 [04:20<02:33,  1.69s/it]Running loglikelihood requests:  37%|███▋      | 53/142 [04:23<02:28,  1.67s/it]Running loglikelihood requests:  39%|███▊      | 55/142 [04:25<02:06,  1.46s/it]Running loglikelihood requests:  40%|████      | 57/142 [04:29<02:15,  1.59s/it]Running loglikelihood requests:  42%|████▏     | 59/142 [04:33<02:28,  1.79s/it]Running loglikelihood requests:  43%|████▎     | 61/142 [04:36<02:14,  1.66s/it]Running loglikelihood requests:  44%|████▍     | 63/142 [04:38<02:01,  1.53s/it]Running loglikelihood requests:  46%|████▌     | 65/142 [04:42<01:59,  1.55s/it]Running loglikelihood requests:  47%|████▋     | 67/142 [04:44<01:51,  1.49s/it]Running loglikelihood requests:  49%|████▊     | 69/142 [04:46<01:38,  1.35s/it]Running loglikelihood requests:  50%|█████     | 71/142 [04:49<01:35,  1.35s/it]Running loglikelihood requests:  51%|█████▏    | 73/142 [04:54<02:01,  1.76s/it]Running loglikelihood requests:  53%|█████▎    | 75/142 [04:57<01:44,  1.56s/it]Running loglikelihood requests:  54%|█████▍    | 77/142 [05:00<01:40,  1.54s/it]Running loglikelihood requests:  56%|█████▌    | 79/142 [05:04<01:47,  1.71s/it]Running loglikelihood requests:  57%|█████▋    | 81/142 [05:06<01:34,  1.55s/it]Running loglikelihood requests:  58%|█████▊    | 83/142 [05:12<01:53,  1.92s/it]Running loglikelihood requests:  60%|█████▉    | 85/142 [05:17<02:05,  2.20s/it]Running loglikelihood requests:  61%|██████▏   | 87/142 [05:24<02:22,  2.59s/it]Running loglikelihood requests:  63%|██████▎   | 89/142 [05:28<02:01,  2.30s/it]Running loglikelihood requests:  64%|██████▍   | 91/142 [05:30<01:42,  2.00s/it]Running loglikelihood requests:  65%|██████▌   | 93/142 [05:37<01:56,  2.37s/it]Running loglikelihood requests:  67%|██████▋   | 95/142 [05:39<01:36,  2.05s/it]Running loglikelihood requests:  68%|██████▊   | 97/142 [05:42<01:20,  1.79s/it]Running loglikelihood requests:  70%|██████▉   | 99/142 [05:45<01:14,  1.73s/it]Running loglikelihood requests:  71%|███████   | 101/142 [05:48<01:06,  1.62s/it]Running loglikelihood requests:  73%|███████▎  | 103/142 [05:50<00:55,  1.44s/it]Running loglikelihood requests:  74%|███████▍  | 105/142 [05:52<00:52,  1.41s/it]Running loglikelihood requests:  75%|███████▌  | 107/142 [05:55<00:47,  1.36s/it]Running loglikelihood requests:  77%|███████▋  | 109/142 [05:57<00:40,  1.24s/it]Running loglikelihood requests:  78%|███████▊  | 111/142 [06:00<00:40,  1.31s/it]Running loglikelihood requests:  80%|███████▉  | 113/142 [06:02<00:37,  1.30s/it]Running loglikelihood requests:  81%|████████  | 115/142 [06:05<00:34,  1.26s/it]Running loglikelihood requests:  82%|████████▏ | 117/142 [06:07<00:29,  1.17s/it]Running loglikelihood requests:  84%|████████▍ | 119/142 [06:09<00:26,  1.14s/it]Running loglikelihood requests:  85%|████████▌ | 121/142 [06:10<00:21,  1.03s/it]Running loglikelihood requests:  87%|████████▋ | 123/142 [06:15<00:26,  1.39s/it]Running loglikelihood requests:  88%|████████▊ | 125/142 [06:17<00:22,  1.35s/it]Running loglikelihood requests:  89%|████████▉ | 127/142 [06:19<00:17,  1.19s/it]Running loglikelihood requests:  91%|█████████ | 129/142 [06:20<00:14,  1.08s/it]Running loglikelihood requests:  92%|█████████▏| 131/142 [06:23<00:12,  1.15s/it]Running loglikelihood requests:  94%|█████████▎| 133/142 [06:25<00:10,  1.15s/it]Running loglikelihood requests:  95%|█████████▌| 135/142 [06:27<00:07,  1.08s/it]Running loglikelihood requests:  96%|█████████▋| 137/142 [06:31<00:06,  1.29s/it]Running loglikelihood requests:  98%|█████████▊| 139/142 [06:33<00:03,  1.18s/it]Running loglikelihood requests:  99%|█████████▉| 141/142 [06:35<00:01,  1.15s/it]Running loglikelihood requests: 100%|██████████| 142/142 [06:35<00:00,  2.78s/it]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-29): 24 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (30-31): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-29): 24 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (30-31): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
ERROR:save_model:Error processing group 0: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 1: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 2: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 3: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 4: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 5: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 6: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 7: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 8: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 9: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 10: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 11: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 12: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 13: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 14: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 15: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 16: LlamaMoEModel has no attribute `layers[2]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[2]`
ERROR:save_model:Error processing group 17: LlamaMoEModel has no attribute `layers[2]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[2]`
ERROR:save_model:Error processing group 18: LlamaMoEModel has no attribute `layers[2]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[2]`
ERROR:save_model:Error processing group 19: LlamaMoEModel has no attribute `layers[2]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[2]`
ERROR:save_model:Error processing group 20: LlamaMoEModel has no attribute `layers[2]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[2]`
ERROR:save_model:Error processing group 21: LlamaMoEModel has no attribute `layers[2]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[2]`
ERROR:save_model:Error processing group 22: LlamaMoEModel has no attribute `layers[2]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[2]`
ERROR:save_model:Error processing group 23: LlamaMoEModel has no attribute `layers[2]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[2]`
ERROR:save_model:Error processing group 24: LlamaMoEModel has no attribute `layers[3]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[3]`
ERROR:save_model:Error processing group 25: LlamaMoEModel has no attribute `layers[3]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[3]`
ERROR:save_model:Error processing group 26: LlamaMoEModel has no attribute `layers[3]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[3]`
ERROR:save_model:Error processing group 27: LlamaMoEModel has no attribute `layers[3]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[3]`
ERROR:save_model:Error processing group 28: LlamaMoEModel has no attribute `layers[3]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[3]`
ERROR:save_model:Error processing group 29: LlamaMoEModel has no attribute `layers[3]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[3]`
ERROR:save_model:Error processing group 30: LlamaMoEModel has no attribute `layers[3]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[3]`
ERROR:save_model:Error processing group 31: LlamaMoEModel has no attribute `layers[3]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[3]`
ERROR:save_model:Error processing group 32: LlamaMoEModel has no attribute `layers[4]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[4]`
ERROR:save_model:Error processing group 33: LlamaMoEModel has no attribute `layers[4]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[4]`
ERROR:save_model:Error processing group 34: LlamaMoEModel has no attribute `layers[4]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[4]`
ERROR:save_model:Error processing group 35: LlamaMoEModel has no attribute `layers[4]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[4]`
ERROR:save_model:Error processing group 36: LlamaMoEModel has no attribute `layers[4]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[4]`
ERROR:save_model:Error processing group 37: LlamaMoEModel has no attribute `layers[4]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[4]`
ERROR:save_model:Error processing group 38: LlamaMoEModel has no attribute `layers[4]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[4]`
ERROR:save_model:Error processing group 39: LlamaMoEModel has no attribute `layers[4]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[4]`
ERROR:save_model:Error processing group 40: LlamaMoEModel has no attribute `layers[5]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[5]`
ERROR:save_model:Error processing group 41: LlamaMoEModel has no attribute `layers[5]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[5]`
ERROR:save_model:Error processing group 42: LlamaMoEModel has no attribute `layers[5]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[5]`
ERROR:save_model:Error processing group 43: LlamaMoEModel has no attribute `layers[5]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[5]`
ERROR:save_model:Error processing group 44: LlamaMoEModel has no attribute `layers[5]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[5]`
ERROR:save_model:Error processing group 45: LlamaMoEModel has no attribute `layers[5]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[5]`
ERROR:save_model:Error processing group 46: LlamaMoEModel has no attribute `layers[5]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[5]`
ERROR:save_model:Error processing group 47: LlamaMoEModel has no attribute `layers[5]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[5]`
WARNING:save_model:Expert index -2 is negative, resetting to 0.
ERROR:save_model:Error processing group 48: LlamaMoEModel has no attribute `layers[6]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[6]`
ERROR:save_model:Error processing group 49: LlamaMoEModel has no attribute `layers[30]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[30]`
ERROR:save_model:Error processing group 50: LlamaMoEModel has no attribute `layers[30]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[30]`
ERROR:save_model:Error processing group 51: LlamaMoEModel has no attribute `layers[31]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[31]`
ERROR:save_model:Error processing group 52: LlamaMoEModel has no attribute `layers[31]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[31]`
INFO:save_model:Model saved successfully at saved_models/53.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5108
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:00:51] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5108 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 108
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:00:51] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5073
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:00:51] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5073 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 73
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5101
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:00:51] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5101 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 101
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5148
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:00:51] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5148 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 148
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5110
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:00:51] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5110 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 110
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5019
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:00:51] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5019 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 19
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5081
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:00:51] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5081 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 81
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5225
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:00:51] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5225 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 225
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5218
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:00:51] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5218 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 218
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5157
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:00:51] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5157 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 157
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5234
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:00:51] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5234 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 234
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5040
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:00:51] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5040 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 40
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5202
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:00:51] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5202 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 202
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5183
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:00:51] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5183 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 183
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139708577128160 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139708577128160 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139708577128160 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139708577128160 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139682534743008 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139682534743008 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139682534743008 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139682534743008 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[53] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4084507042253521, 'acc_stderr,none': 0.058751136942575236}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9179357562486347
0.7304758827874278
0.9028361165350093
0.9177386064031547
0.736264115539795
0.7821589386855158
0.7475448337241333
0.6622221680289488
0.7583296634655016
0.33645990832698236
0.21982307453464583
0.17345324326533693
0.35977004925853934
0.8808900006571698
0.6260065234155616
0.8246960552033293
0.6144641592309815
0.6394144929277611
0.9223063206094516
0.7309208925817541
0.5091734316973643
0.7222829855220914
0.24969394334306674
0.508931879405537
0.8097279042671086
0.5258809052220982
0.4071243454156871
0.9510154626938295
0.3256867622893698
0.9179357562486347
0.7304758827874278
0.9028361165350093
0.9177386064031547
0.736264115539795
0.7821589386855158
0.7475448337241333
0.6622221680289488
0.7583296634655016
0.33645990832698236
0.21982307453464583
0.17345324326533693
0.35977004925853934
0.8808900006571698
0.6260065234155616
0.8246960552033293
0.6144641592309815
0.6394144929277611
0.9223063206094516
0.7309208925817541
0.5091734316973643
0.7222829855220914
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[1, 4, 3, 6, 2, 0, 7, 5]
tensor([1, 4, 3, 6, 2, 0, 7, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 1, 4, 7, 2, 0, 6, 5]
tensor([3, 1, 4, 7, 2, 0, 6, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 6, 7, 0, 3, 2, 4, 1]
tensor([5, 6, 7, 0, 3, 2, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 6, 3, 5, 0, 1, 7, 2]
tensor([4, 6, 3, 5, 0, 1, 7, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 2, 5, 0, 4, 1, 1, 3]
tensor([0, 2, 5, 0, 4, 1, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 2, 3, 0, 2, 3, 1]
tensor([0, 1, 2, 3, 0, 2, 3, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[2, 1, 0, 1, 2, 0, 3, 3]
tensor([2, 1, 0, 1, 2, 0, 3, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 2, 1, 3, 0, 1, 2, 3]
tensor([0, 2, 1, 3, 0, 1, 2, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/53.pt
[RECEIVE] Queued message from 53
[QUEUE] Processing info from 53
[QUEUE] Stored info from 53
[RECEIVE] Queued message from 53
[QUEUE] Processing info from 53
[QUEUE] Stored info from 53
[RECEIVE] Queued message from 53
[QUEUE] Processing info from 53
[QUEUE] Stored info from 53
[RECEIVE] Queued message from 53
[QUEUE] Processing info from 53
[QUEUE] Stored info from 53
[RECEIVE] Queued message from 53
[QUEUE] Processing info from 53
[QUEUE] Stored info from 53
[RECEIVE] Queued message from 53
[QUEUE] Processing info from 53
[QUEUE] Stored info from 53
[RECEIVE] Queued message from 53
[QUEUE] Processing info from 53
[QUEUE] Stored info from 53
[RECEIVE] Queued message from 53
[QUEUE] Processing info from 53
[QUEUE] Stored info from 53
[RECEIVE] Queued message from 53
[QUEUE] Processing info from 53
[QUEUE] Stored info from 53
[RECEIVE] Queued message from 53
[QUEUE] Processing info from 53
[QUEUE] Stored info from 53
[RECEIVE] Queued message from 53
[QUEUE] Processing info from 53
[QUEUE] Stored info from 53
[RECEIVE] Queued message from 53
[QUEUE] Processing info from 53
[QUEUE] Stored info from 53
[RECEIVE] Queued message from 53
[QUEUE] Processing info from 53
[QUEUE] Stored info from 53
[RECEIVE] Queued message from 53
[QUEUE] Processing info from 53
[QUEUE] Stored info from 53
[RECEIVE] Queued message from 53
[QUEUE] Processing info from 53
[QUEUE] Stored info from 53
[148] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2299.05it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:19<46:36, 19.83s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:23<15:16,  6.60s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:27<09:14,  4.05s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:30<06:50,  3.04s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:34<05:51,  2.64s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:37<05:07,  2.35s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:41<04:48,  2.24s/it]Running loglikelihood requests:  11%|█         | 15/142 [00:45<04:19,  2.05s/it]Running loglikelihood requests:  12%|█▏        | 17/142 [00:49<04:09,  2.00s/it]Running loglikelihood requests:  13%|█▎        | 19/142 [00:51<03:39,  1.79s/it]Running loglikelihood requests:  15%|█▍        | 21/142 [00:55<03:36,  1.79s/it]Running loglikelihood requests:  16%|█▌        | 23/142 [00:58<03:22,  1.70s/it]Running loglikelihood requests:  18%|█▊        | 25/142 [01:01<03:07,  1.60s/it]Running loglikelihood requests:  19%|█▉        | 27/142 [01:03<02:56,  1.54s/it]Running loglikelihood requests:  20%|██        | 29/142 [01:06<02:54,  1.54s/it]Running loglikelihood requests:  22%|██▏       | 31/142 [01:10<02:52,  1.56s/it]Running loglikelihood requests:  23%|██▎       | 33/142 [01:14<03:10,  1.75s/it]Running loglikelihood requests:  25%|██▍       | 35/142 [01:21<03:58,  2.22s/it]Running loglikelihood requests:  26%|██▌       | 37/142 [01:26<04:05,  2.34s/it]Running loglikelihood requests:  27%|██▋       | 39/142 [01:30<03:57,  2.31s/it]Running loglikelihood requests:  29%|██▉       | 41/142 [01:33<03:28,  2.07s/it]Running loglikelihood requests:  30%|███       | 43/142 [01:36<03:02,  1.85s/it]Running loglikelihood requests:  32%|███▏      | 45/142 [01:39<02:43,  1.69s/it]Running loglikelihood requests:  33%|███▎      | 47/142 [01:43<02:51,  1.81s/it]Running loglikelihood requests:  35%|███▍      | 49/142 [01:47<02:49,  1.82s/it]Running loglikelihood requests:  36%|███▌      | 51/142 [01:49<02:32,  1.68s/it]Running loglikelihood requests:  37%|███▋      | 53/142 [01:52<02:17,  1.55s/it]Running loglikelihood requests:  39%|███▊      | 55/142 [01:55<02:23,  1.65s/it]Running loglikelihood requests:  40%|████      | 57/142 [02:00<02:30,  1.77s/it]Running loglikelihood requests:  42%|████▏     | 59/142 [02:02<02:09,  1.56s/it]Running loglikelihood requests:  43%|████▎     | 61/142 [02:06<02:16,  1.69s/it]Running loglikelihood requests:  44%|████▍     | 63/142 [02:10<02:26,  1.85s/it]Running loglikelihood requests:  46%|████▌     | 65/142 [02:14<02:27,  1.92s/it]Running loglikelihood requests:  47%|████▋     | 67/142 [02:16<02:04,  1.66s/it]Running loglikelihood requests:  49%|████▊     | 69/142 [02:21<02:14,  1.85s/it]Running loglikelihood requests:  50%|█████     | 71/142 [02:25<02:13,  1.88s/it]Running loglikelihood requests:  51%|█████▏    | 73/142 [02:29<02:12,  1.92s/it]Running loglikelihood requests:  53%|█████▎    | 75/142 [02:33<02:10,  1.95s/it]Running loglikelihood requests:  54%|█████▍    | 77/142 [02:37<02:04,  1.91s/it]Running loglikelihood requests:  56%|█████▌    | 79/142 [02:41<02:05,  1.99s/it]Running loglikelihood requests:  57%|█████▋    | 81/142 [02:45<02:01,  2.00s/it]Running loglikelihood requests:  58%|█████▊    | 83/142 [02:51<02:11,  2.23s/it]Running loglikelihood requests:  60%|█████▉    | 85/142 [02:54<01:56,  2.04s/it]Running loglikelihood requests:  61%|██████▏   | 87/142 [02:56<01:34,  1.71s/it]Running loglikelihood requests:  63%|██████▎   | 89/142 [03:02<01:58,  2.23s/it]Running loglikelihood requests:  64%|██████▍   | 91/142 [03:04<01:32,  1.82s/it]Running loglikelihood requests:  65%|██████▌   | 93/142 [03:09<01:35,  1.96s/it]Running loglikelihood requests:  67%|██████▋   | 95/142 [03:11<01:18,  1.67s/it]Running loglikelihood requests:  68%|██████▊   | 97/142 [03:13<01:04,  1.44s/it]Running loglikelihood requests:  70%|██████▉   | 99/142 [03:14<00:54,  1.27s/it]Running loglikelihood requests:  71%|███████   | 101/142 [03:16<00:48,  1.18s/it]Running loglikelihood requests:  73%|███████▎  | 103/142 [03:20<00:51,  1.33s/it]Running loglikelihood requests:  74%|███████▍  | 105/142 [03:21<00:44,  1.19s/it]Running loglikelihood requests:  75%|███████▌  | 107/142 [03:25<00:49,  1.43s/it]Running loglikelihood requests:  77%|███████▋  | 109/142 [03:32<01:03,  1.93s/it]Running loglikelihood requests:  78%|███████▊  | 111/142 [03:35<00:57,  1.84s/it]Running loglikelihood requests:  80%|███████▉  | 113/142 [03:37<00:45,  1.58s/it]Running loglikelihood requests:  81%|████████  | 115/142 [03:41<00:49,  1.82s/it]Running loglikelihood requests:  82%|████████▏ | 117/142 [03:46<00:48,  1.95s/it]Running loglikelihood requests:  84%|████████▍ | 119/142 [03:48<00:36,  1.60s/it]Running loglikelihood requests:  85%|████████▌ | 121/142 [03:50<00:32,  1.55s/it]Running loglikelihood requests:  87%|████████▋ | 123/142 [03:53<00:28,  1.50s/it]Running loglikelihood requests:  88%|████████▊ | 125/142 [03:55<00:23,  1.37s/it]Running loglikelihood requests:  89%|████████▉ | 127/142 [03:58<00:19,  1.28s/it]Running loglikelihood requests:  91%|█████████ | 129/142 [04:01<00:18,  1.40s/it]Running loglikelihood requests:  92%|█████████▏| 131/142 [04:04<00:16,  1.48s/it]Running loglikelihood requests:  94%|█████████▎| 133/142 [04:07<00:13,  1.51s/it]Running loglikelihood requests:  95%|█████████▌| 135/142 [04:11<00:11,  1.63s/it]Running loglikelihood requests:  96%|█████████▋| 137/142 [04:13<00:07,  1.40s/it]Running loglikelihood requests:  98%|█████████▊| 139/142 [04:15<00:04,  1.34s/it]Running loglikelihood requests:  99%|█████████▉| 141/142 [04:17<00:01,  1.16s/it]Running loglikelihood requests: 100%|██████████| 142/142 [04:17<00:00,  1.81s/it]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-3): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (4-11): 8 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (12): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (13): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14-31): 18 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-3): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (4-11): 8 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (12): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (13): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14-31): 18 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
ERROR:save_model:Error processing group 0: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 1: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 2: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 3: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 4: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 5: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 6: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 7: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 8: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 9: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 10: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 11: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 12: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 13: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 14: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 15: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 16: LlamaMoEModel has no attribute `layers[2]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[2]`
ERROR:save_model:Error processing group 17: LlamaMoEModel has no attribute `layers[2]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[2]`
ERROR:save_model:Error processing group 18: LlamaMoEModel has no attribute `layers[2]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[2]`
ERROR:save_model:Error processing group 19: LlamaMoEModel has no attribute `layers[2]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[2]`
ERROR:save_model:Error processing group 20: LlamaMoEModel has no attribute `layers[2]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[2]`
ERROR:save_model:Error processing group 21: LlamaMoEModel has no attribute `layers[2]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[2]`
ERROR:save_model:Error processing group 22: LlamaMoEModel has no attribute `layers[2]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[2]`
ERROR:save_model:Error processing group 23: LlamaMoEModel has no attribute `layers[2]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[2]`
ERROR:save_model:Error processing group 24: LlamaMoEModel has no attribute `layers[3]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[3]`
ERROR:save_model:Error processing group 25: LlamaMoEModel has no attribute `layers[3]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[3]`
ERROR:save_model:Error processing group 26: LlamaMoEModel has no attribute `layers[3]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[3]`
ERROR:save_model:Error processing group 27: LlamaMoEModel has no attribute `layers[3]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[3]`
ERROR:save_model:Error processing group 28: LlamaMoEModel has no attribute `layers[3]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[3]`
ERROR:save_model:Error processing group 29: LlamaMoEModel has no attribute `layers[3]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[3]`
ERROR:save_model:Error processing group 30: LlamaMoEModel has no attribute `layers[3]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[3]`
ERROR:save_model:Error processing group 31: LlamaMoEModel has no attribute `layers[3]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[3]`
WARNING:save_model:Expert index -2 is negative, resetting to 0.
ERROR:save_model:Error processing group 32: LlamaMoEModel has no attribute `layers[4]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[4]`
ERROR:save_model:Error processing group 33: LlamaMoEModel has no attribute `layers[12]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[12]`
ERROR:save_model:Error processing group 34: LlamaMoEModel has no attribute `layers[12]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[12]`
ERROR:save_model:Error processing group 35: LlamaMoEModel has no attribute `layers[12]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[12]`
ERROR:save_model:Error processing group 36: LlamaMoEModel has no attribute `layers[12]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[12]`
ERROR:save_model:Error processing group 37: LlamaMoEModel has no attribute `layers[12]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[12]`
ERROR:save_model:Error processing group 38: LlamaMoEModel has no attribute `layers[12]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[12]`
ERROR:save_model:Error processing group 39: LlamaMoEModel has no attribute `layers[13]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[13]`
ERROR:save_model:Error processing group 40: LlamaMoEModel has no attribute `layers[13]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[13]`
ERROR:save_model:Error processing group 41: LlamaMoEModel has no attribute `layers[13]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[13]`
ERROR:save_model:Error processing group 42: LlamaMoEModel has no attribute `layers[13]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[13]`
ERROR:save_model:Error processing group 43: LlamaMoEModel has no attribute `layers[13]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[13]`
ERROR:save_model:Error processing group 44: LlamaMoEModel has no attribute `layers[13]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[13]`
WARNING:save_model:Expert index -2 is negative, resetting to 0.
ERROR:save_model:Error processing group 45: LlamaMoEModel has no attribute `layers[14]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[14]`
INFO:save_model:Model saved successfully at saved_models/148.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5081
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:05:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5081 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 81
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5202
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:05:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5202 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 202
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5101
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:05:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5101 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 101
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5234
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:05:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5234 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 234
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5218
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:05:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5218 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 218
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5108
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:05:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5108 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 108
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5225
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:05:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5225 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 225
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5019
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:05:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5019 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 19
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5040
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:05:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5040 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 40
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5183
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:05:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5183 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 183
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5073
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:05:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5073 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 73
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5053
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:05:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5053 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 53
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:05:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5157
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:05:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5157 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 157
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5110
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:05:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5110 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 110
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139682816513168 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139682816513168 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139682816513168 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139682816513168 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139703678132992 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139703678132992 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139703678132992 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139703678132992 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[148] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4788732394366197, 'acc_stderr,none': 0.05970805879899505}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.6890224269714
0.6519987454814186
0.44009979043140846
0.5066155659876163
0.7217003976797293
0.12899593918836094
0.4620116191334168
0.3468065225687064
0.10107939599729882
0.5600103662507451
0.577132167051305
0.6748045019607131
0.4004557650420357
0.700349463047757
0.9095160148001629
0.6131975246160634
0.5678386109581075
0.8437866782628755
0.3536670789186643
0.44960924435079147
0.5862896519346712
0.8246697057441258
0.5484674172302575
0.3288911762125467
0.6478473442183775
0.571596663207821
0.7179565348178579
0.38406312361402845
0.42349247998810474
0.6890224269714
0.6519987454814186
0.44009979043140846
0.5066155659876163
0.7217003976797293
0.12899593918836094
0.4620116191334168
0.3468065225687064
0.10107939599729882
0.5600103662507451
0.577132167051305
0.6748045019607131
0.4004557650420357
0.700349463047757
0.9095160148001629
0.6131975246160634
0.5678386109581075
0.8437866782628755
0.3536670789186643
0.44960924435079147
0.5862896519346712
0.8246697057441258
0.5484674172302575
0.3288911762125467
0.6478473442183775
0.571596663207821
Total groups 70 exceeded the threshold, stopping comparison.
The group tensor is
[5, 3, 7, 6, 2, 1, 4, 0]
tensor([5, 3, 7, 6, 2, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 5, 1, 3, 4, 0, 6, 2]
tensor([7, 5, 1, 3, 4, 0, 6, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 7, 2, 1, 0, 4, 5]
tensor([6, 3, 7, 2, 1, 0, 4, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 7, 5, 2, 1, 4, 0]
tensor([6, 3, 7, 5, 2, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 3, 2, 5, 1, 0, 4, 6]
tensor([7, 3, 2, 5, 1, 0, 4, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 2, 3, 0, 3, 2, 1]
tensor([0, 1, 2, 3, 0, 3, 2, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/148.pt
[RECEIVE] Queued message from 148
[QUEUE] Processing info from 148
[QUEUE] Stored info from 148
[RECEIVE] Queued message from 148
[QUEUE] Processing info from 148
[QUEUE] Stored info from 148
[RECEIVE] Queued message from 148
[QUEUE] Processing info from 148
[QUEUE] Stored info from 148
[RECEIVE] Queued message from 148
[QUEUE] Processing info from 148
[QUEUE] Stored info from 148
[RECEIVE] Queued message from 148
[QUEUE] Processing info from 148
[QUEUE] Stored info from 148
[RECEIVE] Queued message from 148
[QUEUE] Processing info from 148
[QUEUE] Stored info from 148
[RECEIVE] Queued message from 148
[QUEUE] Processing info from 148
[QUEUE] Stored info from 148
[RECEIVE] Queued message from 148
[QUEUE] Processing info from 148
[QUEUE] Stored info from 148
[RECEIVE] Queued message from 148
[QUEUE] Processing info from 148
[QUEUE] Stored info from 148
[RECEIVE] Queued message from 148
[QUEUE] Processing info from 148
[QUEUE] Stored info from 148
[RECEIVE] Queued message from 148
[QUEUE] Processing info from 148
[QUEUE] Stored info from 148
[RECEIVE] Queued message from 148
[QUEUE] Processing info from 148
[QUEUE] Stored info from 148
[RECEIVE] Queued message from 148
[QUEUE] Processing info from 148
[QUEUE] Stored info from 148
[RECEIVE] Queued message from 148
[QUEUE] Processing info from 148
[QUEUE] Stored info from 148
[RECEIVE] Queued message from 148
[QUEUE] Processing info from 148
[QUEUE] Stored info from 148
[40] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2553.34it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:05<14:02,  5.97s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:09<06:47,  2.93s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:14<06:09,  2.70s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:19<05:46,  2.57s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:23<05:04,  2.29s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:27<05:00,  2.30s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:31<04:40,  2.17s/it]Running loglikelihood requests:  11%|█         | 15/142 [00:34<04:13,  2.00s/it]Running loglikelihood requests:  12%|█▏        | 17/142 [00:37<03:49,  1.84s/it]Running loglikelihood requests:  13%|█▎        | 19/142 [00:40<03:26,  1.68s/it]Running loglikelihood requests:  15%|█▍        | 21/142 [00:43<03:15,  1.61s/it]Running loglikelihood requests:  16%|█▌        | 23/142 [00:46<03:11,  1.61s/it]Running loglikelihood requests:  18%|█▊        | 25/142 [00:49<02:58,  1.53s/it]Running loglikelihood requests:  19%|█▉        | 27/142 [00:51<02:39,  1.39s/it]Running loglikelihood requests:  20%|██        | 29/142 [00:56<03:20,  1.77s/it]Running loglikelihood requests:  22%|██▏       | 31/142 [00:59<02:57,  1.60s/it]Running loglikelihood requests:  23%|██▎       | 33/142 [01:02<02:57,  1.63s/it]Running loglikelihood requests:  25%|██▍       | 35/142 [01:06<03:02,  1.70s/it]Running loglikelihood requests:  26%|██▌       | 37/142 [01:11<03:23,  1.94s/it]Running loglikelihood requests:  27%|██▋       | 39/142 [01:14<03:15,  1.90s/it]Running loglikelihood requests:  29%|██▉       | 41/142 [01:19<03:22,  2.00s/it]Running loglikelihood requests:  30%|███       | 43/142 [01:27<04:14,  2.57s/it]Running loglikelihood requests:  32%|███▏      | 45/142 [01:31<04:03,  2.51s/it]Running loglikelihood requests:  33%|███▎      | 47/142 [01:36<03:47,  2.39s/it]Running loglikelihood requests:  35%|███▍      | 49/142 [01:45<04:42,  3.04s/it]Running loglikelihood requests:  36%|███▌      | 51/142 [01:48<04:02,  2.66s/it]Running loglikelihood requests:  37%|███▋      | 53/142 [01:52<03:29,  2.36s/it]Running loglikelihood requests:  39%|███▊      | 55/142 [01:55<03:08,  2.17s/it]Running loglikelihood requests:  40%|████      | 57/142 [02:01<03:22,  2.38s/it]Running loglikelihood requests:  42%|████▏     | 59/142 [02:04<02:53,  2.10s/it]Running loglikelihood requests:  43%|████▎     | 61/142 [02:09<03:09,  2.34s/it]Running loglikelihood requests:  44%|████▍     | 63/142 [02:13<02:57,  2.25s/it]Running loglikelihood requests:  46%|████▌     | 65/142 [02:17<02:43,  2.12s/it]Running loglikelihood requests:  47%|████▋     | 67/142 [02:20<02:21,  1.88s/it]Running loglikelihood requests:  49%|████▊     | 69/142 [02:28<03:03,  2.51s/it]Running loglikelihood requests:  50%|█████     | 71/142 [02:35<03:18,  2.79s/it]Running loglikelihood requests:  51%|█████▏    | 73/142 [02:42<03:33,  3.10s/it]Running loglikelihood requests:  53%|█████▎    | 75/142 [02:44<02:44,  2.46s/it]Running loglikelihood requests:  54%|█████▍    | 77/142 [02:53<03:13,  2.98s/it]Running loglikelihood requests:  56%|█████▌    | 79/142 [02:57<02:57,  2.81s/it]Running loglikelihood requests:  57%|█████▋    | 81/142 [03:01<02:32,  2.50s/it]Running loglikelihood requests:  58%|█████▊    | 83/142 [03:04<02:10,  2.22s/it]Running loglikelihood requests:  60%|█████▉    | 85/142 [03:07<01:56,  2.05s/it]Running loglikelihood requests:  61%|██████▏   | 87/142 [03:11<01:51,  2.02s/it]Running loglikelihood requests:  63%|██████▎   | 89/142 [03:19<02:12,  2.50s/it]Running loglikelihood requests:  64%|██████▍   | 91/142 [03:24<02:12,  2.61s/it]Running loglikelihood requests:  65%|██████▌   | 93/142 [03:36<02:52,  3.53s/it]Running loglikelihood requests:  67%|██████▋   | 95/142 [03:43<02:48,  3.59s/it]Running loglikelihood requests:  68%|██████▊   | 97/142 [03:51<02:47,  3.72s/it]Running loglikelihood requests:  70%|██████▉   | 99/142 [03:56<02:21,  3.30s/it]Running loglikelihood requests:  71%|███████   | 101/142 [04:00<01:58,  2.88s/it]Running loglikelihood requests:  73%|███████▎  | 103/142 [04:04<01:42,  2.63s/it]Running loglikelihood requests:  74%|███████▍  | 105/142 [04:05<01:17,  2.09s/it]Running loglikelihood requests:  75%|███████▌  | 107/142 [04:08<01:05,  1.88s/it]Running loglikelihood requests:  77%|███████▋  | 109/142 [04:12<01:01,  1.87s/it]Running loglikelihood requests:  78%|███████▊  | 111/142 [04:22<01:28,  2.84s/it]Running loglikelihood requests:  80%|███████▉  | 113/142 [04:26<01:17,  2.66s/it]Running loglikelihood requests:  81%|████████  | 115/142 [04:32<01:13,  2.72s/it]Running loglikelihood requests:  82%|████████▏ | 117/142 [04:35<00:58,  2.33s/it]Running loglikelihood requests:  84%|████████▍ | 119/142 [04:40<00:53,  2.34s/it]Running loglikelihood requests:  85%|████████▌ | 121/142 [04:43<00:45,  2.18s/it]Running loglikelihood requests:  87%|████████▋ | 123/142 [04:46<00:35,  1.88s/it]Running loglikelihood requests:  88%|████████▊ | 125/142 [04:49<00:29,  1.75s/it]Running loglikelihood requests:  89%|████████▉ | 127/142 [04:52<00:25,  1.71s/it]Running loglikelihood requests:  91%|█████████ | 129/142 [04:59<00:30,  2.34s/it]Running loglikelihood requests:  92%|█████████▏| 131/142 [05:01<00:20,  1.90s/it]Running loglikelihood requests:  94%|█████████▎| 133/142 [05:04<00:15,  1.70s/it]Running loglikelihood requests:  95%|█████████▌| 135/142 [05:12<00:17,  2.49s/it]Running loglikelihood requests:  96%|█████████▋| 137/142 [05:19<00:13,  2.69s/it]Running loglikelihood requests:  98%|█████████▊| 139/142 [05:23<00:07,  2.58s/it]Running loglikelihood requests:  99%|█████████▉| 141/142 [05:32<00:03,  3.06s/it]Running loglikelihood requests: 100%|██████████| 142/142 [05:32<00:00,  2.34s/it]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-3): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (4-8): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10-13): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (15-31): 17 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-3): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (4-8): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10-13): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (15-31): 17 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
ERROR:save_model:Error processing group 0: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 1: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 2: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 3: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 4: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 5: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 6: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 7: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 8: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 9: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 10: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 11: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 12: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 13: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 14: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 15: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 16: LlamaMoEModel has no attribute `layers[2]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[2]`
ERROR:save_model:Error processing group 17: LlamaMoEModel has no attribute `layers[2]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[2]`
ERROR:save_model:Error processing group 18: LlamaMoEModel has no attribute `layers[2]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[2]`
ERROR:save_model:Error processing group 19: LlamaMoEModel has no attribute `layers[2]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[2]`
ERROR:save_model:Error processing group 20: LlamaMoEModel has no attribute `layers[2]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[2]`
ERROR:save_model:Error processing group 21: LlamaMoEModel has no attribute `layers[2]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[2]`
ERROR:save_model:Error processing group 22: LlamaMoEModel has no attribute `layers[2]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[2]`
ERROR:save_model:Error processing group 23: LlamaMoEModel has no attribute `layers[2]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[2]`
ERROR:save_model:Error processing group 24: LlamaMoEModel has no attribute `layers[3]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[3]`
ERROR:save_model:Error processing group 25: LlamaMoEModel has no attribute `layers[3]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[3]`
ERROR:save_model:Error processing group 26: LlamaMoEModel has no attribute `layers[3]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[3]`
ERROR:save_model:Error processing group 27: LlamaMoEModel has no attribute `layers[3]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[3]`
ERROR:save_model:Error processing group 28: LlamaMoEModel has no attribute `layers[3]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[3]`
ERROR:save_model:Error processing group 29: LlamaMoEModel has no attribute `layers[3]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[3]`
ERROR:save_model:Error processing group 30: LlamaMoEModel has no attribute `layers[3]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[3]`
ERROR:save_model:Error processing group 31: LlamaMoEModel has no attribute `layers[3]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[3]`
WARNING:save_model:Expert index -2 is negative, resetting to 0.
ERROR:save_model:Error processing group 32: LlamaMoEModel has no attribute `layers[4]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[4]`
ERROR:save_model:Error processing group 33: LlamaMoEModel has no attribute `layers[9]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[9]`
ERROR:save_model:Error processing group 34: LlamaMoEModel has no attribute `layers[9]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[9]`
ERROR:save_model:Error processing group 35: LlamaMoEModel has no attribute `layers[9]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[9]`
ERROR:save_model:Error processing group 36: LlamaMoEModel has no attribute `layers[9]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[9]`
ERROR:save_model:Error processing group 37: LlamaMoEModel has no attribute `layers[9]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[9]`
ERROR:save_model:Error processing group 38: LlamaMoEModel has no attribute `layers[9]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[9]`
WARNING:save_model:Expert index -2 is negative, resetting to 0.
ERROR:save_model:Error processing group 39: LlamaMoEModel has no attribute `layers[10]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[10]`
ERROR:save_model:Error processing group 40: LlamaMoEModel has no attribute `layers[14]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[14]`
ERROR:save_model:Error processing group 41: LlamaMoEModel has no attribute `layers[14]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[14]`
ERROR:save_model:Error processing group 42: LlamaMoEModel has no attribute `layers[14]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[14]`
ERROR:save_model:Error processing group 43: LlamaMoEModel has no attribute `layers[14]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[14]`
ERROR:save_model:Error processing group 44: LlamaMoEModel has no attribute `layers[14]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[14]`
ERROR:save_model:Error processing group 45: LlamaMoEModel has no attribute `layers[14]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[14]`
WARNING:save_model:Expert index -2 is negative, resetting to 0.
ERROR:save_model:Error processing group 46: LlamaMoEModel has no attribute `layers[15]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[15]`
INFO:save_model:Model saved successfully at saved_models/40.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5110
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:11:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5110 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 110
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5202
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:11:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5202 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 202
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5019
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:11:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5019 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 19
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5148
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:11:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5148 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 148
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5218
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:11:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5218 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 218
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5183
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:11:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5183 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 183
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5108
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:11:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5108 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 108
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5225
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:11:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5225 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 225
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:11:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5053
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:11:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5053 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 53
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5081
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:11:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5081 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 81
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5234
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:11:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5234 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 234
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5157
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:11:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5157 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 157
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5101
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:11:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5101 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 101
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5073
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:11:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5073 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 73
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139681102693152 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139681102693152 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139681102693152 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139681102693152 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139706362681136 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139706362681136 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139706362681136 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139706362681136 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[40] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4507042253521127, 'acc_stderr,none': 0.05947027187738001}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.36326485003451675
0.9393611658494853
0.5347697273308267
0.4619639883096971
0.26830156279453604
0.8380027464731019
0.8263233574501603
0.6320977880109986
0.7843146415103402
0.2072713135482749
0.3805984042723936
0.43289830555723763
0.19273781754260347
0.8181624071033468
0.5320194969946469
0.7203219641552613
0.7789354624632999
0.3567665334531696
0.2604208944916411
0.942273921845013
0.8798126471295904
0.8327076147848976
0.5471221204152548
0.8016285641373796
0.8787721123612405
0.7314094662215913
0.733830137407364
0.7399689895148621
0.8815844426907766
0.36326485003451675
0.9393611658494853
0.5347697273308267
0.4619639883096971
0.26830156279453604
0.8380027464731019
0.8263233574501603
0.6320977880109986
0.7843146415103402
0.2072713135482749
0.3805984042723936
0.43289830555723763
0.19273781754260347
0.8181624071033468
0.5320194969946469
0.7203219641552613
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[1, 2, 5, 4, 3, 0, 7, 6]
tensor([1, 2, 5, 4, 3, 0, 7, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 3, 2, 6, 0, 1, 4, 7]
tensor([5, 3, 2, 6, 0, 1, 4, 7], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[1, 2, 6, 7, 4, 0, 3, 5]
tensor([1, 2, 6, 7, 4, 0, 3, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[1, 4, 5, 6, 2, 0, 7, 3]
tensor([1, 4, 5, 6, 2, 0, 7, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 5, 1, 0, 0, 2, 1, 3]
tensor([4, 5, 1, 0, 0, 2, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[1, 5, 0, 3, 4, 0, 1, 2]
tensor([1, 5, 0, 3, 4, 0, 1, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 1, 2, 0, 1, 3, 2]
tensor([0, 3, 1, 2, 0, 1, 3, 2], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1.0, 1, 0, 1.0, 1.0]
tensor([0, 1, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
Model saved locally at saved_models/40.pt
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[157] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2487.37it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:13<31:32, 13.42s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:25<18:42,  8.07s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:33<13:30,  5.91s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:40<11:12,  4.98s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:46<09:08,  4.12s/it]Running loglikelihood requests:   8%|▊         | 11/142 [01:23<19:59,  9.15s/it]Running loglikelihood requests:   9%|▉         | 13/142 [02:58<47:05, 21.90s/it]Running loglikelihood requests:  11%|█         | 15/142 [04:17<58:38, 27.70s/it]Running loglikelihood requests:  12%|█▏        | 17/142 [05:52<1:10:38, 33.91s/it]Running loglikelihood requests:  13%|█▎        | 19/142 [07:32<1:19:40, 38.87s/it]Running loglikelihood requests:  15%|█▍        | 21/142 [08:59<1:21:11, 40.26s/it]Running loglikelihood requests:  16%|█▌        | 23/142 [09:58<1:13:24, 37.01s/it]Running loglikelihood requests:  18%|█▊        | 25/142 [10:17<55:50, 28.63s/it]  Running loglikelihood requests:  19%|█▉        | 27/142 [11:12<54:21, 28.36s/it]Running loglikelihood requests:  20%|██        | 29/142 [12:09<53:17, 28.30s/it]Running loglikelihood requests:  22%|██▏       | 31/142 [12:43<46:13, 24.99s/it]Running loglikelihood requests:  23%|██▎       | 33/142 [13:11<39:18, 21.64s/it]Running loglikelihood requests:  25%|██▍       | 35/142 [13:49<37:11, 20.85s/it]Running loglikelihood requests:  26%|██▌       | 37/142 [14:20<33:34, 19.19s/it]Running loglikelihood requests:  27%|██▋       | 39/142 [14:59<33:16, 19.38s/it]Running loglikelihood requests:  29%|██▉       | 41/142 [15:47<34:46, 20.66s/it]Running loglikelihood requests:  30%|███       | 43/142 [16:39<36:46, 22.29s/it]Running loglikelihood requests:  32%|███▏      | 45/142 [16:45<26:40, 16.50s/it]Running loglikelihood requests:  33%|███▎      | 47/142 [17:10<24:11, 15.28s/it]Running loglikelihood requests:  35%|███▍      | 49/142 [17:46<25:01, 16.15s/it]Running loglikelihood requests:  36%|███▌      | 51/142 [18:08<22:13, 14.65s/it]Running loglikelihood requests:  37%|███▋      | 53/142 [18:26<19:04, 12.86s/it]Running loglikelihood requests:  39%|███▊      | 55/142 [18:43<16:45, 11.56s/it]Running loglikelihood requests:  40%|████      | 57/142 [18:54<13:54,  9.81s/it]Running loglikelihood requests:  42%|████▏     | 59/142 [18:59<10:35,  7.66s/it]Running loglikelihood requests:  43%|████▎     | 61/142 [19:07<08:49,  6.54s/it]Running loglikelihood requests:  44%|████▍     | 63/142 [19:12<06:55,  5.27s/it]Running loglikelihood requests:  46%|████▌     | 65/142 [19:25<07:16,  5.67s/it]Running loglikelihood requests:  47%|████▋     | 67/142 [19:29<05:43,  4.59s/it]Running loglikelihood requests:  49%|████▊     | 69/142 [19:37<05:25,  4.45s/it]Running loglikelihood requests:  50%|█████     | 71/142 [19:42<04:28,  3.78s/it]Running loglikelihood requests:  51%|█████▏    | 73/142 [19:47<03:52,  3.37s/it]Running loglikelihood requests:  53%|█████▎    | 75/142 [19:53<03:42,  3.32s/it]Running loglikelihood requests:  54%|█████▍    | 77/142 [19:58<03:15,  3.00s/it]Running loglikelihood requests:  56%|█████▌    | 79/142 [20:02<02:57,  2.81s/it]Running loglikelihood requests:  57%|█████▋    | 81/142 [20:10<03:07,  3.08s/it]Running loglikelihood requests:  58%|█████▊    | 83/142 [20:22<03:55,  4.00s/it]Running loglikelihood requests:  60%|█████▉    | 85/142 [20:34<04:17,  4.52s/it]Running loglikelihood requests:  61%|██████▏   | 87/142 [20:41<03:53,  4.24s/it]Running loglikelihood requests:  63%|██████▎   | 89/142 [20:48<03:31,  3.99s/it]Running loglikelihood requests:  64%|██████▍   | 91/142 [20:57<03:33,  4.18s/it]Running loglikelihood requests:  65%|██████▌   | 93/142 [21:04<03:16,  4.00s/it]Running loglikelihood requests:  67%|██████▋   | 95/142 [21:07<02:35,  3.32s/it]Running loglikelihood requests:  68%|██████▊   | 97/142 [21:15<02:38,  3.52s/it]Running loglikelihood requests:  70%|██████▉   | 99/142 [21:22<02:27,  3.44s/it]Running loglikelihood requests:  71%|███████   | 101/142 [21:28<02:18,  3.39s/it]Running loglikelihood requests:  73%|███████▎  | 103/142 [21:42<02:51,  4.40s/it]Running loglikelihood requests:  74%|███████▍  | 105/142 [21:45<02:09,  3.49s/it]Running loglikelihood requests:  75%|███████▌  | 107/142 [22:00<02:44,  4.71s/it]Running loglikelihood requests:  77%|███████▋  | 109/142 [22:05<02:14,  4.07s/it]Running loglikelihood requests:  78%|███████▊  | 111/142 [22:18<02:31,  4.88s/it]Running loglikelihood requests:  80%|███████▉  | 113/142 [22:30<02:28,  5.13s/it]Running loglikelihood requests:  81%|████████  | 115/142 [22:34<01:53,  4.22s/it]Running loglikelihood requests:  82%|████████▏ | 117/142 [22:38<01:26,  3.48s/it]Running loglikelihood requests:  84%|████████▍ | 119/142 [22:44<01:17,  3.36s/it]Running loglikelihood requests:  85%|████████▌ | 121/142 [22:49<01:07,  3.21s/it]Running loglikelihood requests:  87%|████████▋ | 123/142 [22:59<01:10,  3.69s/it]Running loglikelihood requests:  88%|████████▊ | 125/142 [23:10<01:12,  4.26s/it]Running loglikelihood requests:  89%|████████▉ | 127/142 [23:14<00:54,  3.61s/it]Running loglikelihood requests:  91%|█████████ | 129/142 [23:24<00:51,  3.93s/it]Running loglikelihood requests:  92%|█████████▏| 131/142 [23:28<00:37,  3.38s/it]Running loglikelihood requests:  94%|█████████▎| 133/142 [23:30<00:23,  2.62s/it]Running loglikelihood requests:  95%|█████████▌| 135/142 [23:35<00:18,  2.63s/it]Running loglikelihood requests:  96%|█████████▋| 137/142 [23:41<00:13,  2.67s/it]Running loglikelihood requests:  98%|█████████▊| 139/142 [23:47<00:08,  2.84s/it]Running loglikelihood requests:  99%|█████████▉| 141/142 [23:50<00:02,  2.43s/it]Running loglikelihood requests: 100%|██████████| 142/142 [23:50<00:00, 10.07s/it]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-5): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (7-18): 12 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (19): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (20): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (21): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (22): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (23): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24-27): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (28): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (29-31): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-5): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (7-18): 12 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (19): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (20): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (21): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (22): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (23): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24-27): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (28): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (29-31): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1]
                  (2): Parameter containing: [torch.float32 of size 1x1]
                  (3): Parameter containing: [torch.float32 of size 1x1]
                  (4): Parameter containing: [torch.float32 of size 1x1]
                  (5): Parameter containing: [torch.float32 of size 1x1]
                  (6): Parameter containing: [torch.float32 of size 1x1]
                  (7): Parameter containing: [torch.float32 of size 1x1]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
ERROR:save_model:Error processing group 0: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 1: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 2: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 3: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 4: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 5: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 6: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 7: LlamaMoEModel has no attribute `layers[0]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[0]`
ERROR:save_model:Error processing group 8: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 9: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 10: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 11: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 12: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 13: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 14: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
ERROR:save_model:Error processing group 15: LlamaMoEModel has no attribute `layers[1]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[1]`
WARNING:save_model:Expert index -2 is negative, resetting to 0.
ERROR:save_model:Error processing group 16: LlamaMoEModel has no attribute `layers[2]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[2]`
ERROR:save_model:Error processing group 17: LlamaMoEModel has no attribute `layers[6]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[6]`
ERROR:save_model:Error processing group 18: LlamaMoEModel has no attribute `layers[6]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[6]`
ERROR:save_model:Error processing group 19: LlamaMoEModel has no attribute `layers[6]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[6]`
ERROR:save_model:Error processing group 20: LlamaMoEModel has no attribute `layers[6]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[6]`
ERROR:save_model:Error processing group 21: LlamaMoEModel has no attribute `layers[6]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[6]`
ERROR:save_model:Error processing group 22: LlamaMoEModel has no attribute `layers[6]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[6]`
ERROR:save_model:Error processing group 23: LlamaMoEModel has no attribute `layers[6]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[6]`
ERROR:save_model:Error processing group 24: LlamaMoEModel has no attribute `layers[6]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[6]`
WARNING:save_model:Expert index -2 is negative, resetting to 0.
ERROR:save_model:Error processing group 25: LlamaMoEModel has no attribute `layers[7]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[7]`
ERROR:save_model:Error processing group 26: LlamaMoEModel has no attribute `layers[19]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[19]`
ERROR:save_model:Error processing group 27: LlamaMoEModel has no attribute `layers[19]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[19]`
ERROR:save_model:Error processing group 28: LlamaMoEModel has no attribute `layers[19]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[19]`
ERROR:save_model:Error processing group 29: LlamaMoEModel has no attribute `layers[19]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[19]`
ERROR:save_model:Error processing group 30: LlamaMoEModel has no attribute `layers[20]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[20]`
ERROR:save_model:Error processing group 31: LlamaMoEModel has no attribute `layers[20]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[20]`
ERROR:save_model:Error processing group 32: LlamaMoEModel has no attribute `layers[20]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[20]`
ERROR:save_model:Error processing group 33: LlamaMoEModel has no attribute `layers[20]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[20]`
ERROR:save_model:Error processing group 34: LlamaMoEModel has no attribute `layers[21]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[21]`
ERROR:save_model:Error processing group 35: LlamaMoEModel has no attribute `layers[21]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[21]`
ERROR:save_model:Error processing group 36: LlamaMoEModel has no attribute `layers[21]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[21]`
ERROR:save_model:Error processing group 37: LlamaMoEModel has no attribute `layers[21]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[21]`
ERROR:save_model:Error processing group 38: LlamaMoEModel has no attribute `layers[22]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[22]`
ERROR:save_model:Error processing group 39: LlamaMoEModel has no attribute `layers[22]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[22]`
ERROR:save_model:Error processing group 40: LlamaMoEModel has no attribute `layers[22]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[22]`
ERROR:save_model:Error processing group 41: LlamaMoEModel has no attribute `layers[22]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[22]`
ERROR:save_model:Error processing group 42: LlamaMoEModel has no attribute `layers[23]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[23]`
ERROR:save_model:Error processing group 43: LlamaMoEModel has no attribute `layers[23]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[23]`
ERROR:save_model:Error processing group 44: LlamaMoEModel has no attribute `layers[23]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[23]`
ERROR:save_model:Error processing group 45: LlamaMoEModel has no attribute `layers[23]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[23]`
WARNING:save_model:Expert index -2 is negative, resetting to 0.
ERROR:save_model:Error processing group 46: LlamaMoEModel has no attribute `layers[24]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[24]`
ERROR:save_model:Error processing group 47: LlamaMoEModel has no attribute `layers[28]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[28]`
ERROR:save_model:Error processing group 48: LlamaMoEModel has no attribute `layers[28]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[28]`
WARNING:save_model:Expert index -2 is negative, resetting to 0.
ERROR:save_model:Error processing group 49: LlamaMoEModel has no attribute `layers[29]`
Traceback (most recent call last):
  File "/public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/Node_llama_test.py", line 1146, in save_model
    param_list = getattr(self.local_model._model.get_submodule(base_path), param_type, None)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/public/home/zouyifei001/perl5/miniconda3/envs/MoEUpdate/lib/python3.12/site-packages/torch/nn/modules/module.py", line 710, in get_submodule
    raise AttributeError(
AttributeError: LlamaMoEModel has no attribute `layers[29]`
INFO:save_model:Model saved successfully at saved_models/157.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5183
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:36:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5183 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 183
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5019
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:36:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5019 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 19
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5218
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:36:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5218 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 218
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5081
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:36:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5081 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 81
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:36:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5110
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:36:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5110 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 110
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5073
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:36:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5073 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 73
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5108
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:36:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5108 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 108
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5148
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:36:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5148 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 148
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5101
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:36:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5101 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 101
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5234
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:36:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5234 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 234
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5225
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:36:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5225 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 225
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5053
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:36:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5053 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 53
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5202
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:36:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5202 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 202
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5040
INFO:werkzeug:127.0.0.1 - - [15/May/2025 15:36:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5040 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 40
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139681102707600 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139681102707600 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139681102707600 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139681102707600 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139706363818352 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139706363818352 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139706363818352 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139706363818352 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[157] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.43661971830985913, 'acc_stderr,none': 0.05927935558412972}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8579940969956122
0.9172414698319051
0.5383905049167778
0.7154451748054276
0.547671504517951
0.8833126318549385
0.815742382492854
0.6517871119418787
0.320270438500039
0.20847052823122236
0.9142272844016534
0.8979022224289909
0.8081306275049516
0.5991072724268783
0.8920856671099552
0.8548931916511182
0.9545918502043321
0.9270787839270334
0.4466502436196787
0.892147307459623
0.7319083135729072
0.8321772812735796
0.9605666801588856
0.3242808765028886
0.884060616512067
0.5116280105615226
0.22259676802614164
0.8272877996431262
Total groups 68 exceeded the threshold, stopping comparison.
The group tensor is
[3, 2, 7, 4, 5, 0, 6, 1]
tensor([3, 2, 7, 4, 5, 0, 6, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[1, 6, 5, 4, 2, 0, 7, 3]
tensor([1, 6, 5, 4, 2, 0, 7, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 3, 5, 6, 1, 2, 7, 0]
tensor([4, 3, 5, 6, 1, 2, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[2, 5, 3, 7, 0, 1, 6, 4]
tensor([2, 5, 3, 7, 0, 1, 6, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 2, 1, 1, 3, 2, 3]
tensor([0, 0, 2, 1, 1, 3, 2, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[3, 0, 2, 1, 1, 0, 2, 3]
tensor([3, 0, 2, 1, 1, 0, 2, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 1, 1.0, 1, 1.0, 1.0, 1.0]
tensor([0, 0, 1, 1, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[1, 0, 1, 1.0, 1.0, 0, 1.0, 1.0]
tensor([1, 0, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/157.pt
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[101] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2581.24it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:15<35:56, 15.29s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:24<16:43,  7.22s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:36<15:17,  6.69s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:41<10:59,  4.88s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:52<11:24,  5.14s/it]Running loglikelihood requests:   8%|▊         | 11/142 [01:02<11:03,  5.07s/it]Running loglikelihood requests:   9%|▉         | 13/142 [01:10<10:09,  4.72s/it]Running loglikelihood requests:  11%|█         | 15/142 [01:18<09:38,  4.55s/it]Running loglikelihood requests:  12%|█▏        | 17/142 [01:29<10:03,  4.83s/it]Running loglikelihood requests:  13%|█▎        | 19/142 [01:35<08:44,  4.26s/it]Running loglikelihood requests:  15%|█▍        | 21/142 [01:43<08:23,  4.16s/it]Running loglikelihood requests:  16%|█▌        | 23/142 [01:49<07:36,  3.84s/it]Running loglikelihood requests:  18%|█▊        | 25/142 [01:55<06:54,  3.55s/it]Running loglikelihood requests:  19%|█▉        | 27/142 [02:05<07:46,  4.06s/it]Running loglikelihood requests:  20%|██        | 29/142 [02:27<11:27,  6.08s/it]Running loglikelihood requests:  22%|██▏       | 31/142 [03:37<27:21, 14.79s/it]