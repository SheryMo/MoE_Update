nohup: ignoring input
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:0'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}
网络架构：{'109': ['205', '29', '87', '161', '206', '243', '141', '80', '82', '4', '64', '45', '26', '163', '242', '171', '11', '94', '104', '44', '6', '178', '133', '30', '236', '196', '230', '55', '60', '27', '13'], '141': ['206', '230', '64', '13', '6', '44', '133', '161', '82', '196', '104', '26', '109', '4', '163', '178', '205', '27', '242', '243', '55', '30', '87', '29', '80', '60', '11', '236', '45', '94', '171'], '163': ['109', '45', '11', '196', '4', '94', '178', '30', '133', '55', '60', '29', '6', '243', '205', '206', '26', '27', '80', '82', '64', '161', '171', '141', '242', '44', '230', '87', '13', '104', '236'], '196': ['30', '29', '87', '45', '94', '163', '55', '26', '206', '60', '11', '230', '141', '243', '171', '80', '236', '104', '133', '6', '13', '44', '64', '27', '109', '161', '82', '4', '178', '242', '205'], '55': ['13', '242', '161', '205', '26', '178', '11', '44', '82', '141', '196', '104', '87', '60', '171', '80', '64', '4', '27', '30', '163', '109', '133', '29', '236', '206', '243', '94', '230', '6', '45'], '26': ['205', '161', '87', '243', '242', '6', '44', '80', '4', '60', '55', '13', '94', '109', '178', '206', '133', '64', '171', '30', '230', '163', '11', '196', '104', '236', '141', '45', '82', '27', '29'], '206': ['171', '6', '163', '87', '196', '26', '64', '178', '82', '205', '161', '30', '4', '11', '94', '141', '44', '60', '242', '55', '27', '109', '133', '243', '45', '80', '104', '230', '29', '13', '236'], '87': ['206', '27', '11', '109', '44', '64', '243', '26', '6', '141', '4', '55', '230', '196', '82', '13', '80', '236', '30', '242', '29', '60', '133', '171', '45', '161', '104', '94', '163', '178', '205'], '44': ['55', '230', '13', '104', '11', '87', '60', '206', '6', '109', '30', '242', '26', '133', '80', '27', '141', '236', '64', '205', '171', '29', '45', '4', '161', '82', '243', '196', '163', '94', '178'], '30': ['109', '243', '206', '6', '133', '11', '236', '104', '141', '60', '171', '80', '242', '87', '13', '29', '163', '4', '82', '27', '45', '230', '205', '26', '64', '161', '196', '44', '178', '94', '55'], '82': ['60', '178', '80', '13', '171', '109', '87', '133', '243', '94', '230', '104', '26', '206', '4', '205', '55', '141', '163', '45', '161', '242', '29', '44', '6', '236', '11', '30', '196', '27', '64'], '45': ['55', '94', '26', '82', '242', '161', '27', '30', '4', '171', '141', '196', '80', '6', '64', '243', '206', '230', '13', '104', '11', '133', '60', '236', '29', '44', '163', '87', '178', '205', '109'], '6': ['205', '4', '29', '133', '161', '163', '30', '55', '27', '11', '104', '60', '45', '141', '26', '87', '44', '94', '64', '80', '13', '242', '243', '171', '178', '236', '230', '206', '109', '82', '196'], '133': ['13', '178', '242', '4', '82', '206', '87', '27', '60', '29', '104', '171', '243', '109', '45', '94', '80', '26', '6', '196', '205', '236', '161', '30', '64', '163', '44', '11', '55', '230', '141'], '104': ['171', '82', '178', '161', '45', '205', '13', '109', '6', '87', '196', '242', '4', '55', '163', '94', '141', '236', '30', '206', '11', '29', '230', '64', '26', '80', '27', '44', '133', '243', '60'], '80': ['109', '171', '141', '44', '104', '230', '163', '13', '236', '11', '45', '196', '64', '30', '178', '6', '82', '27', '87', '242', '133', '60', '161', '243', '206', '205', '55', '29', '94', '26', '4'], '178': ['196', '133', '26', '109', '104', '4', '141', '55', '206', '30', '236', '171', '230', '64', '6', '82', '29', '205', '87', '161', '60', '80', '243', '13', '94', '45', '44', '163', '242', '27', '11'], '236': ['205', '45', '26', '242', '163', '206', '82', '243', '171', '30', '27', '64', '29', '44', '6', '87', '230', '133', '196', '80', '104', '141', '109', '60', '178', '55', '94', '161', '4', '11', '13'], '242': ['196', '104', '230', '26', '109', '30', '6', '94', '205', '44', '133', '141', '4', '29', '161', '171', '45', '163', '60', '82', '64', '27', '55', '13', '206', '243', '87', '80', '236', '11', '178'], '13': ['141', '236', '242', '82', '55', '171', '44', '29', '104', '133', '64', '80', '178', '4', '94', '30', '6', '87', '60', '27', '45', '243', '26', '163', '230', '205', '11', '196', '161', '109', '206'], '29': ['87', '206', '230', '133', '55', '27', '80', '26', '45', '178', '196', '243', '171', '30', '11', '205', '4', '6', '242', '141', '13', '161', '44', '64', '109', '94', '104', '60', '82', '236', '163'], '11': ['196', '13', '60', '29', '109', '80', '87', '243', '178', '206', '242', '44', '45', '64', '104', '205', '161', '26', '230', '27', '30', '133', '171', '82', '94', '6', '163', '55', '4', '236', '141'], '205': ['6', '82', '206', '26', '236', '29', '243', '87', '242', '109', '30', '4', '141', '44', '94', '161', '11', '60', '80', '196', '45', '133', '104', '230', '27', '13', '55', '171', '64', '163', '178'], '243': ['60', '205', '163', '30', '196', '6', '55', '236', '94', '133', '230', '141', '29', '13', '80', '11', '104', '171', '206', '242', '87', '27', '4', '64', '161', '44', '109', '45', '26', '178', '82'], '171': ['30', '13', '44', '242', '64', '4', '80', '205', '60', '6', '163', '87', '178', '29', '206', '27', '26', '94', '230', '11', '109', '236', '243', '82', '161', '45', '55', '133', '196', '104', '141'], '94': ['171', '178', '236', '243', '55', '6', '27', '242', '29', '230', '205', '4', '60', '82', '87', '163', '133', '196', '141', '11', '26', '45', '13', '64', '44', '30', '104', '206', '161', '109', '80'], '4': ['171', '243', '109', '60', '27', '230', '29', '64', '206', '104', '87', '236', '55', '30', '242', '26', '133', '94', '161', '45', '196', '6', '82', '11', '44', '163', '178', '80', '205', '141', '13'], '161': ['196', '109', '55', '64', '178', '29', '13', '133', '163', '80', '242', '60', '94', '6', '230', '236', '104', '30', '141', '206', '45', '243', '87', '26', '11', '27', '205', '171', '44', '4', '82'], '230': ['55', '30', '26', '206', '44', '45', '242', '161', '60', '205', '80', '104', '243', '171', '163', '94', '11', '27', '141', '64', '29', '13', '196', '4', '6', '178', '82', '109', '87', '236', '133'], '64': ['196', '6', '178', '60', '30', '133', '243', '13', '236', '104', '141', '26', '55', '44', '242', '163', '80', '94', '45', '206', '171', '82', '109', '29', '4', '11', '205', '87', '161', '27', '230'], '27': ['4', '26', '94', '55', '82', '29', '196', '141', '60', '109', '87', '243', '30', '64', '45', '206', '13', '163', '6', '104', '236', '11', '242', '171', '80', '44', '205', '178', '230', '133', '161'], '60': ['178', '11', '109', '141', '64', '82', '44', '29', '205', '4', '243', '236', '45', '161', '87', '230', '104', '94', '80', '163', '171', '6', '30', '27', '13', '242', '206', '55', '26', '133', '196']}
109
cuda:0
wsc
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:57<00:57, 57.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:14<00:00, 33.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:14<00:00, 37.20s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wsc] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wsc] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/super_glue/super_glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue/revision/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue/revision/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue/tree/3de24cf8022e94f4ee4b9d55a6f539891524d646?recursive=False&expand=False HTTP/1.1" 307 138
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue/tree/3de24cf8022e94f4ee4b9d55a6f539891524d646?recursive=False&expand=False HTTP/1.1" 200 501
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue/tree/3de24cf8022e94f4ee4b9d55a6f539891524d646/axb?recursive=False&expand=False HTTP/1.1" 307 142
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue/tree/3de24cf8022e94f4ee4b9d55a6f539891524d646/axb?recursive=False&expand=False HTTP/1.1" 200 232
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue/revision/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue/revision/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 241
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue/tree/3de24cf8022e94f4ee4b9d55a6f539891524d646/wsc.fixed?recursive=False&expand=False HTTP/1.1" 307 148
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue/tree/3de24cf8022e94f4ee4b9d55a6f539891524d646/wsc.fixed?recursive=False&expand=False HTTP/1.1" 200 356
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 241
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 241
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 241
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 241
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 241
DEBUG:filelock:Attempting to acquire lock 139752465180016 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_wsc.fixed_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 139752465180016 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_wsc.fixed_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wsc.fixed/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 139752465180016 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_wsc.fixed_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 139752465180016 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_wsc.fixed_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Attempting to acquire lock 139749986930704 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wsc.fixed/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 139749986930704 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wsc.fixed/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wsc.fixed/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 139749986930704 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wsc.fixed/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 139749986930704 released on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wsc.fixed/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wsc from None to 0
INFO:lm_eval.api.task:Building contexts for wsc on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 78545.02it/s]
DEBUG:lm_eval.evaluator:Task: wsc; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:03<10:26,  3.15s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:04<03:43,  1.13s/it]Running loglikelihood requests:   4%|▎         | 7/200 [00:04<01:37,  1.97it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:05<01:31,  2.09it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:06<01:27,  2.15it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:07<01:24,  2.20it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:08<01:22,  2.25it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:09<01:20,  2.28it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:09<01:17,  2.32it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:10<01:16,  2.35it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:11<01:14,  2.37it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:12<01:13,  2.39it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:13<01:12,  2.40it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:14<01:10,  2.44it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:14<01:07,  2.49it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:15<01:06,  2.52it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:16<01:05,  2.54it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:17<01:03,  2.56it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:17<01:03,  2.52it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:18<01:03,  2.51it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:19<01:02,  2.50it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:20<01:01,  2.50it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:21<01:00,  2.51it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:21<01:00,  2.50it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:22<00:58,  2.55it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:23<00:56,  2.59it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:24<00:55,  2.62it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:24<00:54,  2.64it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:25<00:53,  2.66it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:26<00:53,  2.60it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:27<00:51,  2.63it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:27<00:50,  2.69it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:28<00:48,  2.73it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:29<00:47,  2.75it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:30<00:46,  2.77it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:30<00:45,  2.80it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:31<00:44,  2.81it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:32<00:44,  2.75it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:32<00:44,  2.72it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:33<00:44,  2.70it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:34<00:43,  2.72it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:35<00:41,  2.76it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:35<00:40,  2.81it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:36<00:39,  2.82it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:37<00:38,  2.80it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:37<00:38,  2.75it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:38<00:38,  2.75it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:39<00:36,  2.82it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:40<00:35,  2.85it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:40<00:34,  2.90it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:41<00:33,  2.93it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:42<00:32,  2.93it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:42<00:31,  2.92it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:43<00:31,  2.89it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:44<00:30,  2.92it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:44<00:29,  2.98it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:45<00:21,  3.94it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:46<00:16,  4.65it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:46<00:18,  4.21it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:47<00:19,  3.91it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [00:47<00:19,  3.71it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [00:48<00:19,  3.57it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [00:49<00:19,  3.48it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [00:49<00:19,  3.42it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [00:50<00:19,  3.31it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [00:51<00:19,  3.31it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [00:51<00:18,  3.31it/s]Running loglikelihood requests:  70%|███████   | 141/200 [00:52<00:17,  3.31it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [00:52<00:17,  3.32it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [00:53<00:16,  3.29it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [00:54<00:16,  3.29it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [00:54<00:15,  3.33it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [00:55<00:14,  3.27it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [00:55<00:14,  3.27it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [00:56<00:13,  3.32it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [00:57<00:12,  3.35it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [00:57<00:12,  3.35it/s]Running loglikelihood requests:  80%|████████  | 161/200 [00:58<00:11,  3.35it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [00:58<00:10,  3.39it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [00:59<00:10,  3.41it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [00:59<00:09,  3.43it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [01:00<00:09,  3.44it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [01:01<00:08,  3.44it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [01:01<00:07,  3.46it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [01:02<00:07,  3.45it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [01:02<00:06,  3.42it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [01:03<00:06,  3.43it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [01:04<00:05,  3.45it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [01:04<00:04,  3.46it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [01:05<00:04,  3.40it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [01:05<00:03,  3.47it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [01:06<00:03,  3.49it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [01:06<00:02,  3.57it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [01:07<00:01,  3.62it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:07<00:01,  3.67it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:08<00:00,  3.71it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:08<00:00,  3.74it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:08<00:00,  2.90it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:1'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:1'}
full model:
{'wsc': {'alias': 'wsc', 'acc,none': 0.39, 'acc_stderr,none': 0.04902071300001973}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8279363410631274
0.19299873358047231
0.24697427628971416
0.9498246079459217
0.9208790959024347
0.5433529265767616
0.7541489406957872
0.8642404861438043
0.9451768410410958
0.6364904470004392
0.8605038470072015
0.8806563523485148
0.7320941418431636
0.7167995199876819
0.9558598958577776
0.7974395317006763
0.8001507378395173
0.8689133172877098
0.6142386786363212
0.6039861720637983
0.8068446902119512
0.6154342295548068
0.8415314242927469
0.42042589459680124
0.7443787948515065
0.7081725962998161
0.7223774755032815
0.9338202429729527
0.7700364698774241
0.8279363410631274
0.19299873358047231
0.24697427628971416
0.9498246079459217
0.9208790959024347
0.5433529265767616
0.7541489406957872
0.8642404861438043
0.9451768410410958
0.6364904470004392
0.8605038470072015
0.8806563523485148
0.7320941418431636
0.7167995199876819
0.9558598958577776
0.7974395317006763
0.8001507378395173
0.8689133172877098
0.6142386786363212
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[6, 7, 2, 4, 5, 1, 3, 0]
tensor([6, 7, 2, 4, 5, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[1, 7, 3, 6, 2, 5, 4, 0]
tensor([1, 7, 3, 6, 2, 5, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[1, 5, 6, 3, 7, 4, 2, 0]
tensor([1, 5, 6, 3, 7, 4, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[1, 5, 3, 6, 7, 4, 2, 0]
tensor([1, 5, 3, 6, 7, 4, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 7, 5, 6, 1, 2, 3, 0]
tensor([4, 7, 5, 6, 1, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 7, 1, 5, 6, 3, 2, 0]
tensor([4, 7, 1, 5, 6, 3, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1.0, 1, 1.0, 0, 1.0]
tensor([0, 1, 1, 1, 1, 1, 0, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
done!
Normal merging for layer 2
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 3 to 4
done!
Normal merging for layer 5
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
tensor([2])
tensor(2)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
done!
Normal merging for layer 6
tensor([7])
tensor(7)
tensor([4])
tensor(4)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
done!
Normal merging for layer 7
tensor([7])
tensor(7)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([1])
tensor(1)
done!
Cross-layer merge completed for layers 8 to 28
done!
Normal merging for layer 29
tensor([0, 6])
tensor(0)
tensor([1, 2, 3, 4, 5, 7])
tensor(1)
done!
Cross-layer merge completed for layers 30 to 31
done!
all done!
Model size: 12.3238 GB
141
cuda:1
wikitext
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:55<00:55, 55.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:13<00:00, 33.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:13<00:00, 36.55s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
WARNING:lm_eval.api.task:[Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
WARNING:lm_eval.api.task:[Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
WARNING:lm_eval.api.task:[Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
WARNING:lm_eval.api.task:[Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
WARNING:lm_eval.api.task:[Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/wikitext_document_level HTTP/1.1" 200 1012
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/EleutherAI/wikitext_document_level/EleutherAI/wikitext_document_level.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/wikitext_document_level HTTP/1.1" 200 1012
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/wikitext_document_level/resolve/647234772b9554e208af6c826f23b99e3cac88c8/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/wikitext_document_level/revision/647234772b9554e208af6c826f23b99e3cac88c8 HTTP/1.1" 200 1012
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/wikitext_document_level/tree/647234772b9554e208af6c826f23b99e3cac88c8?recursive=False&expand=False HTTP/1.1" 200 357
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/EleutherAI/wikitext_document_level/paths-info/647234772b9554e208af6c826f23b99e3cac88c8 HTTP/1.1" 200 299
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/wikitext_document_level/tree/647234772b9554e208af6c826f23b99e3cac88c8/wikitext-103-raw-v1?recursive=False&expand=False HTTP/1.1" 200 488
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/EleutherAI/wikitext_document_level/paths-info/647234772b9554e208af6c826f23b99e3cac88c8 HTTP/1.1" 200 299
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/wikitext_document_level/revision/647234772b9554e208af6c826f23b99e3cac88c8 HTTP/1.1" 200 1012
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/EleutherAI/wikitext_document_level/paths-info/647234772b9554e208af6c826f23b99e3cac88c8 HTTP/1.1" 200 299
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/EleutherAI/wikitext_document_level/paths-info/647234772b9554e208af6c826f23b99e3cac88c8 HTTP/1.1" 200 299
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/EleutherAI/wikitext_document_level/paths-info/647234772b9554e208af6c826f23b99e3cac88c8 HTTP/1.1" 200 299
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/EleutherAI/wikitext_document_level/paths-info/647234772b9554e208af6c826f23b99e3cac88c8 HTTP/1.1" 200 299
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/wikitext_document_level/resolve/647234772b9554e208af6c826f23b99e3cac88c8/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/EleutherAI/wikitext_document_level/paths-info/647234772b9554e208af6c826f23b99e3cac88c8 HTTP/1.1" 200 293
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/wikitext_document_level/tree/647234772b9554e208af6c826f23b99e3cac88c8/wikitext-2-raw-v1?recursive=False&expand=False HTTP/1.1" 200 487
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/EleutherAI/wikitext_document_level/paths-info/647234772b9554e208af6c826f23b99e3cac88c8 HTTP/1.1" 200 293
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/EleutherAI/wikitext_document_level/paths-info/647234772b9554e208af6c826f23b99e3cac88c8 HTTP/1.1" 200 293
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/EleutherAI/wikitext_document_level/paths-info/647234772b9554e208af6c826f23b99e3cac88c8 HTTP/1.1" 200 293
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/EleutherAI/wikitext_document_level/paths-info/647234772b9554e208af6c826f23b99e3cac88c8 HTTP/1.1" 200 293
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/EleutherAI/wikitext_document_level/paths-info/647234772b9554e208af6c826f23b99e3cac88c8 HTTP/1.1" 200 293
DEBUG:filelock:Attempting to acquire lock 139751466187088 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___wikitext_document_level_wikitext-2-raw-v1_0.0.0_647234772b9554e208af6c826f23b99e3cac88c8.lock
DEBUG:filelock:Lock 139751466187088 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___wikitext_document_level_wikitext-2-raw-v1_0.0.0_647234772b9554e208af6c826f23b99e3cac88c8.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___wikitext_document_level/wikitext-2-raw-v1/0.0.0/647234772b9554e208af6c826f23b99e3cac88c8/dataset_info.json
DEBUG:filelock:Attempting to release lock 139751466187088 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___wikitext_document_level_wikitext-2-raw-v1_0.0.0_647234772b9554e208af6c826f23b99e3cac88c8.lock
DEBUG:filelock:Lock 139751466187088 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___wikitext_document_level_wikitext-2-raw-v1_0.0.0_647234772b9554e208af6c826f23b99e3cac88c8.lock
DEBUG:filelock:Attempting to acquire lock 139750523789840 on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___wikitext_document_level/wikitext-2-raw-v1/0.0.0/647234772b9554e208af6c826f23b99e3cac88c8_builder.lock
DEBUG:filelock:Lock 139750523789840 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___wikitext_document_level/wikitext-2-raw-v1/0.0.0/647234772b9554e208af6c826f23b99e3cac88c8_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___wikitext_document_level/wikitext-2-raw-v1/0.0.0/647234772b9554e208af6c826f23b99e3cac88c8/dataset_info.json
DEBUG:filelock:Attempting to release lock 139750523789840 on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___wikitext_document_level/wikitext-2-raw-v1/0.0.0/647234772b9554e208af6c826f23b99e3cac88c8_builder.lock
DEBUG:filelock:Lock 139750523789840 released on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___wikitext_document_level/wikitext-2-raw-v1/0.0.0/647234772b9554e208af6c826f23b99e3cac88c8_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wikitext from None to 0
INFO:lm_eval.api.task:Building contexts for wikitext on rank 0...
  0%|          | 0/62 [00:00<?, ?it/s]100%|██████████| 62/62 [00:00<00:00, 726.39it/s]
DEBUG:lm_eval.evaluator:Task: wikitext; number of requests on this rank: 62
INFO:lm_eval.evaluator:Running loglikelihood_rolling requests
  0%|          | 0/62 [00:00<?, ?it/s] 15%|█▍        | 9/62 [00:00<00:00, 88.95it/s] 39%|███▊      | 24/62 [00:00<00:00, 111.91it/s] 58%|█████▊    | 36/62 [00:00<00:00, 109.47it/s] 76%|███████▌  | 47/62 [00:00<00:00, 99.81it/s] 100%|██████████| 62/62 [00:00<00:00, 112.27it/s]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:07<00:00,  7.72s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:07<00:00,  7.72s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.86s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.86s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.20s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.20s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:14<00:00, 14.29s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:14<00:00, 14.29s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.10s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.10s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.22s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.22s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.07s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.07s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:12<00:00, 12.45s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:12<00:00, 12.45s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:14<00:00, 14.35s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:14<00:00, 14.35s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.14s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.14s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.03s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.03s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.08s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.08s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.14s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.14s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:13<00:00, 13.82s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:13<00:00, 13.82s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.10s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.10s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.80s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.80s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.89s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.89s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.92s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.92s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:09<00:00,  9.41s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:09<00:00,  9.41s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:16<00:00, 16.62s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:16<00:00, 16.62s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.83s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.83s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.91s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.91s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.91s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.91s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:05<00:00,  5.68s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:05<00:00,  5.68s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:12<00:00, 12.62s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:12<00:00, 12.62s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:03<00:00,  3.18s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:03<00:00,  3.18s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:09<00:00,  9.87s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:09<00:00,  9.87s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.80s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.80s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.88s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.88s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.95s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.95s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:06<00:00,  6.20s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:06<00:00,  6.20s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.84s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.84s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.45s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.45s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.32s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.32s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.49s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.49s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.28s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.28s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.31s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.31s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:07<00:00,  7.04s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:07<00:00,  7.04s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.33s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.33s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.75s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.75s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:19<00:00, 19.73s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:19<00:00, 19.73s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.70s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.70s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.76s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.76s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.78s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.79s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:13<00:00, 13.77s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:13<00:00, 13.77s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.76s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.76s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.76s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.76s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.82s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.82s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.72s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.72s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.88s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.88s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.73s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.73s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.71s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.71s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:06<00:00,  6.48s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:06<00:00,  6.48s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  1.93it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  1.93it/s]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.88s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.88s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.79s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.79s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:08<00:00,  8.86s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:08<00:00,  8.86s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.77s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.77s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.78s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.78s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:09<00:00,  9.60s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:09<00:00,  9.60s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.91s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.91s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.78s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.78s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.74s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.74s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.89s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.89s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.74s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.74s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.79s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.80s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:09<00:00,  9.01s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:09<00:00,  9.01s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.80s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.81s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.79s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.79s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.10s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.10s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.21s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.21s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.09s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.09s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.19s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.19s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.12s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.12s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.91s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.91s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.88s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.88s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.68s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.68s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.58s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.58s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.57s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.57s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.56s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.56s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.56s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.56s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.57s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.57s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:13<00:00, 13.55s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:13<00:00, 13.55s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:06<00:00,  6.13s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:06<00:00,  6.13s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.57s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.57s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.57s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.57s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:12<00:00, 12.18s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:12<00:00, 12.18s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:06<00:00,  6.23s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:06<00:00,  6.23s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:07<00:00,  7.01s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:07<00:00,  7.01s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.54s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.54s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.56s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.56s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.56s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.56s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:07<00:00,  7.64s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:07<00:00,  7.64s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:08<00:00,  8.29s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:08<00:00,  8.29s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:15<00:00, 15.91s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:15<00:00, 15.91s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:15<00:00, 15.53s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:15<00:00, 15.53s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:06<00:00,  6.19s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:06<00:00,  6.19s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:06<00:00,  6.10s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:06<00:00,  6.10s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:05<00:00,  5.55s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:05<00:00,  5.56s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:05<00:00,  5.40s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:05<00:00,  5.40s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.57s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.57s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.21s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.21s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.41s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.41s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:03<00:00,  3.13s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:03<00:00,  3.13s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.37s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.37s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.37s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.38s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.38s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.38s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.37s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.37s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.37s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.37s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.36s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.36s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.39s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.39s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.38s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.38s/it]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:2'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:2'}
full model:
{'wikitext': {'alias': 'wikitext', 'word_perplexity,none': 10.41810626477151, 'word_perplexity_stderr,none': 'N/A', 'byte_perplexity,none': 1.5499996141598633, 'byte_perplexity_stderr,none': 'N/A', 'bits_per_byte,none': 0.6322678563706606, 'bits_per_byte_stderr,none': 'N/A'}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.45530714642366393
0.6593661321025917
0.45166835110772663
0.3470526807104175
0.3369212652555373
0.5686768652815603
0.5380667106744194
0.1994061645434335
0.7857081855506413
0.7236392518096334
0.6975091963753621
0.7192457446547811
0.6820752222558486
0.2553530000000423
0.9092011229700152
0.8474392887638426
0.29700403366343364
0.3112335629956447
0.316268174131358
0.5041948206367306
0.3067038688170426
0.21198641237235732
0.23379101174921613
0.4411951857077822
0.3636022184812837
0.22411151956337602
0.0659668585894146
0.5103891010860186
0.5291148039479469
0.45530714642366393
0.6593661321025917
0.45166835110772663
0.3470526807104175
0.3369212652555373
0.5686768652815603
0.5380667106744194
0.1994061645434335
0.7857081855506413
0.7236392518096334
0.6975091963753621
0.7192457446547811
0.6820752222558486
0.2553530000000423
0.9092011229700152
0.8474392887638426
0.29700403366343364
0.3112335629956447
0.316268174131358
0.5041948206367306
0.3067038688170426
0.21198641237235732
0.23379101174921613
0.4411951857077822
0.3636022184812837
0.22411151956337602
0.0659668585894146
0.5103891010860186
0.5291148039479469
0.45530714642366393
0.6593661321025917
0.45166835110772663
0.3470526807104175
0.3369212652555373
0.5686768652815603
0.5380667106744194
0.1994061645434335
0.7857081855506413
0.7236392518096334
0.6975091963753621
0.7192457446547811
0.6820752222558486
0.2553530000000423
0.9092011229700152
0.8474392887638426
0.29700403366343364
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[6, 3, 7, 0, 5, 1, 4, 2]
tensor([6, 3, 7, 0, 5, 1, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 5, 0, 4, 3, 6, 7, 1]
tensor([2, 5, 0, 4, 3, 6, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[6, 7, 5, 2, 0, 3, 1, 4]
tensor([6, 7, 5, 2, 0, 3, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 1, 0, 7, 2, 3, 5, 6]
tensor([4, 1, 0, 7, 2, 3, 5, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 3, 2, 4, 0, 1, 1, 0]
tensor([5, 3, 2, 4, 0, 1, 1, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[3, 2, 0, 1, 5, 0, 4, 1]
tensor([3, 2, 0, 1, 5, 0, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[1, 0, 1, 5, 2, 0, 4, 3]
tensor([1, 0, 1, 5, 2, 0, 4, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([2])
tensor(2)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 2 to 4
done!
Normal merging for layer 5
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([1])
tensor(1)
done!
Normal merging for layer 6
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
done!
Cross-layer merge completed for layers 7 to 8
done!
Normal merging for layer 9
tensor([4, 7])
tensor(4)
tensor([5, 6])
tensor(5)
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([0])
tensor(0)
done!
Normal merging for layer 10
tensor([2, 5])
tensor(2)
tensor([3, 7])
tensor(3)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 11 to 12
done!
Normal merging for layer 13
tensor([1, 5])
tensor(1)
tensor([0, 2])
tensor(0)
tensor([4])
tensor(4)
tensor([7])
tensor(7)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
done!
Cross-layer merge completed for layers 14 to 31
done!
all done!
Model size: 12.3867 GB
163
cuda:2
mastermind_35_easy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:48<00:48, 48.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:02<00:00, 28.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:02<00:00, 31.30s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_35_mcq_random HTTP/1.1" 200 772
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/flair/mastermind_35_mcq_random/flair/mastermind_35_mcq_random.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_35_mcq_random HTTP/1.1" 200 780
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/flair/mastermind_35_mcq_random/resolve/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_35_mcq_random/revision/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 780
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_35_mcq_random/tree/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1?recursive=False&expand=False HTTP/1.1" 200 290
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_35_mcq_random/tree/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1/data?recursive=False&expand=False HTTP/1.1" 200 359
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_35_mcq_random/revision/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 780
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/flair/mastermind_35_mcq_random/resolve/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:filelock:Attempting to acquire lock 139750519391296 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_35_mcq_random_default_0.0.0_15dd5105771e9c8d2d3ea71c8d44fffda374a7a1.lock
DEBUG:filelock:Lock 139750519391296 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_35_mcq_random_default_0.0.0_15dd5105771e9c8d2d3ea71c8d44fffda374a7a1.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1/dataset_info.json
DEBUG:filelock:Attempting to release lock 139750519391296 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_35_mcq_random_default_0.0.0_15dd5105771e9c8d2d3ea71c8d44fffda374a7a1.lock
DEBUG:filelock:Lock 139750519391296 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_35_mcq_random_default_0.0.0_15dd5105771e9c8d2d3ea71c8d44fffda374a7a1.lock
DEBUG:filelock:Attempting to acquire lock 139751460236816 on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1_builder.lock
DEBUG:filelock:Lock 139751460236816 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1/dataset_info.json
DEBUG:filelock:Attempting to release lock 139751460236816 on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1_builder.lock
DEBUG:filelock:Lock 139751460236816 released on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mastermind_35_easy from None to 0
INFO:lm_eval.api.task:Building contexts for mastermind_35_easy on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1514.15it/s]
DEBUG:lm_eval.evaluator:Task: mastermind_35_easy; number of requests on this rank: 400
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/400 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/400 [00:04<29:07,  4.38s/it]Running loglikelihood requests:   0%|          | 2/400 [00:05<17:00,  2.56s/it]Running loglikelihood requests:   1%|          | 3/400 [00:06<13:01,  1.97s/it]Running loglikelihood requests:   1%|          | 4/400 [00:08<11:07,  1.69s/it]Running loglikelihood requests:   1%|▏         | 5/400 [00:09<10:03,  1.53s/it]Running loglikelihood requests:   2%|▏         | 6/400 [00:10<09:23,  1.43s/it]Running loglikelihood requests:   2%|▏         | 7/400 [00:11<08:57,  1.37s/it]Running loglikelihood requests:   2%|▏         | 8/400 [00:13<08:42,  1.33s/it]Running loglikelihood requests:   2%|▏         | 9/400 [00:14<08:28,  1.30s/it]Running loglikelihood requests:   2%|▎         | 10/400 [00:15<08:16,  1.27s/it]Running loglikelihood requests:   3%|▎         | 11/400 [00:16<08:09,  1.26s/it]Running loglikelihood requests:   3%|▎         | 12/400 [00:18<08:08,  1.26s/it]Running loglikelihood requests:   3%|▎         | 13/400 [00:19<08:01,  1.24s/it]Running loglikelihood requests:   4%|▎         | 14/400 [00:20<07:56,  1.23s/it]Running loglikelihood requests:   4%|▍         | 15/400 [00:21<07:52,  1.23s/it]Running loglikelihood requests:   4%|▍         | 16/400 [00:22<07:49,  1.22s/it]Running loglikelihood requests:   4%|▍         | 17/400 [00:24<07:46,  1.22s/it]Running loglikelihood requests:   4%|▍         | 18/400 [00:25<07:43,  1.21s/it]Running loglikelihood requests:   5%|▍         | 19/400 [00:26<07:40,  1.21s/it]Running loglikelihood requests:   5%|▌         | 20/400 [00:27<07:35,  1.20s/it]Running loglikelihood requests:   5%|▌         | 21/400 [00:28<07:36,  1.20s/it]Running loglikelihood requests:   6%|▌         | 23/400 [00:30<05:49,  1.08it/s]Running loglikelihood requests:   6%|▌         | 24/400 [00:31<06:13,  1.01it/s]Running loglikelihood requests:   6%|▋         | 25/400 [00:32<06:33,  1.05s/it]Running loglikelihood requests:   6%|▋         | 26/400 [00:33<06:47,  1.09s/it]Running loglikelihood requests:   7%|▋         | 27/400 [00:34<06:57,  1.12s/it]Running loglikelihood requests:   7%|▋         | 28/400 [00:36<07:04,  1.14s/it]Running loglikelihood requests:   7%|▋         | 29/400 [00:37<07:09,  1.16s/it]Running loglikelihood requests:   8%|▊         | 30/400 [00:38<07:13,  1.17s/it]Running loglikelihood requests:   8%|▊         | 31/400 [00:39<07:13,  1.18s/it]Running loglikelihood requests:   8%|▊         | 32/400 [00:40<07:13,  1.18s/it]Running loglikelihood requests:   8%|▊         | 33/400 [00:42<07:16,  1.19s/it]Running loglikelihood requests:   8%|▊         | 34/400 [00:43<07:15,  1.19s/it]Running loglikelihood requests:   9%|▉         | 35/400 [00:44<07:15,  1.19s/it]Running loglikelihood requests:   9%|▉         | 36/400 [00:45<07:13,  1.19s/it]Running loglikelihood requests:   9%|▉         | 37/400 [00:46<07:12,  1.19s/it]Running loglikelihood requests:  10%|▉         | 38/400 [00:48<07:11,  1.19s/it]Running loglikelihood requests:  10%|▉         | 39/400 [00:49<07:14,  1.20s/it]Running loglikelihood requests:  10%|█         | 40/400 [00:50<07:11,  1.20s/it]Running loglikelihood requests:  10%|█         | 41/400 [00:51<07:08,  1.19s/it]Running loglikelihood requests:  10%|█         | 42/400 [00:52<07:06,  1.19s/it]Running loglikelihood requests:  11%|█         | 43/400 [00:54<07:04,  1.19s/it]Running loglikelihood requests:  11%|█         | 44/400 [00:55<07:02,  1.19s/it]Running loglikelihood requests:  11%|█▏        | 45/400 [00:56<07:01,  1.19s/it]Running loglikelihood requests:  12%|█▏        | 46/400 [00:57<07:00,  1.19s/it]Running loglikelihood requests:  12%|█▏        | 47/400 [00:58<06:58,  1.19s/it]Running loglikelihood requests:  12%|█▏        | 48/400 [00:59<06:57,  1.19s/it]Running loglikelihood requests:  12%|█▏        | 49/400 [01:01<06:57,  1.19s/it]Running loglikelihood requests:  12%|█▎        | 50/400 [01:02<06:55,  1.19s/it]Running loglikelihood requests:  13%|█▎        | 51/400 [01:03<06:52,  1.18s/it]Running loglikelihood requests:  13%|█▎        | 52/400 [01:04<06:50,  1.18s/it]Running loglikelihood requests:  13%|█▎        | 53/400 [01:05<06:48,  1.18s/it]Running loglikelihood requests:  14%|█▎        | 54/400 [01:07<06:46,  1.18s/it]Running loglikelihood requests:  14%|█▍        | 55/400 [01:08<06:45,  1.17s/it]Running loglikelihood requests:  14%|█▍        | 56/400 [01:09<06:43,  1.17s/it]Running loglikelihood requests:  14%|█▍        | 57/400 [01:10<06:42,  1.17s/it]Running loglikelihood requests:  14%|█▍        | 58/400 [01:11<06:41,  1.17s/it]Running loglikelihood requests:  15%|█▍        | 59/400 [01:12<06:40,  1.17s/it]Running loglikelihood requests:  15%|█▌        | 60/400 [01:14<06:39,  1.17s/it]Running loglikelihood requests:  15%|█▌        | 61/400 [01:15<06:38,  1.17s/it]Running loglikelihood requests:  16%|█▌        | 62/400 [01:16<06:36,  1.17s/it]Running loglikelihood requests:  16%|█▌        | 63/400 [01:17<06:35,  1.17s/it]Running loglikelihood requests:  16%|█▌        | 64/400 [01:18<06:35,  1.18s/it]Running loglikelihood requests:  16%|█▋        | 65/400 [01:20<06:41,  1.20s/it]Running loglikelihood requests:  16%|█▋        | 66/400 [01:21<06:39,  1.20s/it]Running loglikelihood requests:  17%|█▋        | 67/400 [01:22<06:42,  1.21s/it]Running loglikelihood requests:  17%|█▋        | 68/400 [01:23<06:42,  1.21s/it]Running loglikelihood requests:  17%|█▋        | 69/400 [01:24<06:41,  1.21s/it]Running loglikelihood requests:  18%|█▊        | 70/400 [01:26<06:40,  1.21s/it]Running loglikelihood requests:  18%|█▊        | 71/400 [01:27<06:39,  1.21s/it]Running loglikelihood requests:  18%|█▊        | 72/400 [01:28<06:38,  1.22s/it]Running loglikelihood requests:  18%|█▊        | 73/400 [01:29<06:42,  1.23s/it]Running loglikelihood requests:  18%|█▊        | 74/400 [01:31<06:42,  1.23s/it]Running loglikelihood requests:  19%|█▉        | 75/400 [01:32<06:38,  1.22s/it]Running loglikelihood requests:  19%|█▉        | 76/400 [01:33<06:32,  1.21s/it]Running loglikelihood requests:  19%|█▉        | 77/400 [01:34<06:28,  1.20s/it]Running loglikelihood requests:  20%|█▉        | 78/400 [01:35<06:24,  1.19s/it]Running loglikelihood requests:  20%|█▉        | 79/400 [01:37<06:30,  1.22s/it]Running loglikelihood requests:  20%|██        | 80/400 [01:38<06:32,  1.23s/it]Running loglikelihood requests:  20%|██        | 81/400 [01:39<06:26,  1.21s/it]Running loglikelihood requests:  20%|██        | 82/400 [01:40<06:20,  1.20s/it]Running loglikelihood requests:  21%|██        | 83/400 [01:41<06:12,  1.17s/it]Running loglikelihood requests:  21%|██        | 84/400 [01:42<06:06,  1.16s/it]Running loglikelihood requests:  21%|██▏       | 85/400 [01:44<06:02,  1.15s/it]Running loglikelihood requests:  22%|██▏       | 86/400 [01:45<06:03,  1.16s/it]Running loglikelihood requests:  22%|██▏       | 87/400 [01:46<05:59,  1.15s/it]Running loglikelihood requests:  22%|██▏       | 88/400 [01:47<05:56,  1.14s/it]Running loglikelihood requests:  22%|██▏       | 89/400 [01:48<05:53,  1.14s/it]Running loglikelihood requests:  22%|██▎       | 90/400 [01:49<05:50,  1.13s/it]Running loglikelihood requests:  23%|██▎       | 91/400 [01:50<05:47,  1.13s/it]Running loglikelihood requests:  23%|██▎       | 92/400 [01:51<05:45,  1.12s/it]Running loglikelihood requests:  23%|██▎       | 93/400 [01:53<05:44,  1.12s/it]Running loglikelihood requests:  24%|██▎       | 94/400 [01:54<05:48,  1.14s/it]Running loglikelihood requests:  24%|██▍       | 95/400 [01:55<05:46,  1.14s/it]Running loglikelihood requests:  24%|██▍       | 96/400 [01:56<05:44,  1.13s/it]Running loglikelihood requests:  24%|██▍       | 97/400 [01:57<05:43,  1.13s/it]Running loglikelihood requests:  24%|██▍       | 98/400 [01:58<05:49,  1.16s/it]Running loglikelihood requests:  25%|██▍       | 99/400 [02:00<05:57,  1.19s/it]Running loglikelihood requests:  25%|██▌       | 100/400 [02:01<06:01,  1.21s/it]Running loglikelihood requests:  25%|██▌       | 101/400 [02:02<06:04,  1.22s/it]Running loglikelihood requests:  26%|██▌       | 102/400 [02:03<06:06,  1.23s/it]Running loglikelihood requests:  26%|██▌       | 103/400 [02:05<06:07,  1.24s/it]Running loglikelihood requests:  26%|██▌       | 104/400 [02:06<06:06,  1.24s/it]Running loglikelihood requests:  26%|██▋       | 105/400 [02:07<06:06,  1.24s/it]Running loglikelihood requests:  26%|██▋       | 106/400 [02:08<06:05,  1.24s/it]Running loglikelihood requests:  27%|██▋       | 107/400 [02:10<06:04,  1.24s/it]Running loglikelihood requests:  27%|██▋       | 108/400 [02:11<05:53,  1.21s/it]Running loglikelihood requests:  27%|██▋       | 109/400 [02:12<05:43,  1.18s/it]Running loglikelihood requests:  28%|██▊       | 110/400 [02:13<05:36,  1.16s/it]Running loglikelihood requests:  28%|██▊       | 112/400 [02:14<04:13,  1.14it/s]Running loglikelihood requests:  28%|██▊       | 113/400 [02:15<04:28,  1.07it/s]Running loglikelihood requests:  28%|██▊       | 114/400 [02:16<04:40,  1.02it/s]Running loglikelihood requests:  29%|██▉       | 115/400 [02:17<04:50,  1.02s/it]Running loglikelihood requests:  29%|██▉       | 116/400 [02:18<04:56,  1.04s/it]Running loglikelihood requests:  29%|██▉       | 117/400 [02:20<05:00,  1.06s/it]Running loglikelihood requests:  30%|██▉       | 118/400 [02:21<05:02,  1.07s/it]Running loglikelihood requests:  30%|██▉       | 119/400 [02:22<05:04,  1.08s/it]Running loglikelihood requests:  30%|███       | 120/400 [02:23<05:05,  1.09s/it]Running loglikelihood requests:  30%|███       | 121/400 [02:24<05:06,  1.10s/it]Running loglikelihood requests:  30%|███       | 122/400 [02:25<05:06,  1.10s/it]Running loglikelihood requests:  31%|███       | 123/400 [02:26<05:05,  1.10s/it]Running loglikelihood requests:  31%|███       | 124/400 [02:27<05:04,  1.10s/it]Running loglikelihood requests:  31%|███▏      | 125/400 [02:28<05:03,  1.10s/it]Running loglikelihood requests:  32%|███▏      | 126/400 [02:30<05:02,  1.10s/it]Running loglikelihood requests:  32%|███▏      | 127/400 [02:31<05:01,  1.10s/it]Running loglikelihood requests:  32%|███▏      | 128/400 [02:32<05:00,  1.10s/it]Running loglikelihood requests:  32%|███▏      | 129/400 [02:33<04:59,  1.10s/it]Running loglikelihood requests:  32%|███▎      | 130/400 [02:34<04:57,  1.10s/it]Running loglikelihood requests:  33%|███▎      | 131/400 [02:35<04:56,  1.10s/it]Running loglikelihood requests:  33%|███▎      | 132/400 [02:36<04:55,  1.10s/it]Running loglikelihood requests:  33%|███▎      | 133/400 [02:37<04:54,  1.10s/it]Running loglikelihood requests:  34%|███▎      | 134/400 [02:38<04:53,  1.10s/it]Running loglikelihood requests:  34%|███▍      | 135/400 [02:39<04:51,  1.10s/it]Running loglikelihood requests:  34%|███▍      | 136/400 [02:41<04:50,  1.10s/it]Running loglikelihood requests:  34%|███▍      | 137/400 [02:42<04:48,  1.10s/it]Running loglikelihood requests:  34%|███▍      | 138/400 [02:43<04:47,  1.10s/it]Running loglikelihood requests:  35%|███▍      | 139/400 [02:44<04:46,  1.10s/it]Running loglikelihood requests:  35%|███▌      | 140/400 [02:45<04:45,  1.10s/it]Running loglikelihood requests:  35%|███▌      | 141/400 [02:46<04:44,  1.10s/it]Running loglikelihood requests:  36%|███▌      | 142/400 [02:47<04:42,  1.10s/it]Running loglikelihood requests:  36%|███▌      | 143/400 [02:48<04:42,  1.10s/it]Running loglikelihood requests:  36%|███▌      | 144/400 [02:49<04:40,  1.10s/it]Running loglikelihood requests:  36%|███▋      | 145/400 [02:50<04:39,  1.10s/it]Running loglikelihood requests:  36%|███▋      | 146/400 [02:52<04:38,  1.10s/it]Running loglikelihood requests:  37%|███▋      | 147/400 [02:53<04:37,  1.10s/it]Running loglikelihood requests:  37%|███▋      | 148/400 [02:54<04:36,  1.10s/it]Running loglikelihood requests:  37%|███▋      | 149/400 [02:55<04:34,  1.10s/it]Running loglikelihood requests:  38%|███▊      | 150/400 [02:56<04:33,  1.09s/it]Running loglikelihood requests:  38%|███▊      | 151/400 [02:57<04:32,  1.10s/it]Running loglikelihood requests:  38%|███▊      | 152/400 [02:58<04:31,  1.10s/it]Running loglikelihood requests:  38%|███▊      | 153/400 [02:59<04:29,  1.09s/it]Running loglikelihood requests:  38%|███▊      | 154/400 [03:00<04:28,  1.09s/it]Running loglikelihood requests:  39%|███▉      | 155/400 [03:01<04:27,  1.09s/it]Running loglikelihood requests:  39%|███▉      | 156/400 [03:02<04:26,  1.09s/it]Running loglikelihood requests:  39%|███▉      | 157/400 [03:04<04:24,  1.09s/it]Running loglikelihood requests:  40%|███▉      | 158/400 [03:05<04:23,  1.09s/it]Running loglikelihood requests:  40%|███▉      | 159/400 [03:06<04:22,  1.09s/it]Running loglikelihood requests:  40%|████      | 160/400 [03:07<04:21,  1.09s/it]Running loglikelihood requests:  40%|████      | 161/400 [03:08<04:19,  1.09s/it]Running loglikelihood requests:  40%|████      | 162/400 [03:09<04:18,  1.09s/it]Running loglikelihood requests:  41%|████      | 163/400 [03:10<04:17,  1.09s/it]Running loglikelihood requests:  41%|████      | 164/400 [03:11<04:16,  1.09s/it]Running loglikelihood requests:  41%|████▏     | 165/400 [03:12<04:15,  1.09s/it]Running loglikelihood requests:  42%|████▏     | 166/400 [03:13<04:14,  1.09s/it]Running loglikelihood requests:  42%|████▏     | 167/400 [03:14<04:13,  1.09s/it]Running loglikelihood requests:  42%|████▏     | 168/400 [03:16<04:12,  1.09s/it]Running loglikelihood requests:  42%|████▏     | 169/400 [03:17<04:10,  1.08s/it]Running loglikelihood requests:  42%|████▎     | 170/400 [03:18<04:09,  1.08s/it]Running loglikelihood requests:  43%|████▎     | 171/400 [03:19<04:07,  1.08s/it]Running loglikelihood requests:  43%|████▎     | 172/400 [03:20<04:06,  1.08s/it]Running loglikelihood requests:  43%|████▎     | 173/400 [03:21<04:05,  1.08s/it]Running loglikelihood requests:  44%|████▎     | 174/400 [03:22<04:04,  1.08s/it]Running loglikelihood requests:  44%|████▍     | 175/400 [03:23<04:03,  1.08s/it]Running loglikelihood requests:  44%|████▍     | 177/400 [03:24<03:05,  1.20it/s]Running loglikelihood requests:  44%|████▍     | 178/400 [03:25<03:18,  1.12it/s]Running loglikelihood requests:  45%|████▍     | 179/400 [03:26<03:28,  1.06it/s]Running loglikelihood requests:  45%|████▌     | 180/400 [03:27<03:35,  1.02it/s]Running loglikelihood requests:  45%|████▌     | 181/400 [03:28<03:40,  1.01s/it]Running loglikelihood requests:  46%|████▌     | 182/400 [03:30<03:44,  1.03s/it]Running loglikelihood requests:  46%|████▌     | 183/400 [03:31<03:46,  1.04s/it]Running loglikelihood requests:  46%|████▌     | 184/400 [03:32<03:47,  1.05s/it]Running loglikelihood requests:  46%|████▋     | 185/400 [03:33<03:48,  1.06s/it]Running loglikelihood requests:  46%|████▋     | 186/400 [03:34<03:48,  1.07s/it]Running loglikelihood requests:  47%|████▋     | 187/400 [03:35<03:48,  1.07s/it]Running loglikelihood requests:  47%|████▋     | 188/400 [03:36<03:47,  1.07s/it]Running loglikelihood requests:  47%|████▋     | 189/400 [03:37<03:46,  1.07s/it]Running loglikelihood requests:  48%|████▊     | 190/400 [03:38<03:45,  1.08s/it]Running loglikelihood requests:  48%|████▊     | 191/400 [03:39<03:44,  1.08s/it]Running loglikelihood requests:  48%|████▊     | 192/400 [03:40<03:43,  1.07s/it]Running loglikelihood requests:  48%|████▊     | 193/400 [03:41<03:42,  1.07s/it]Running loglikelihood requests:  48%|████▊     | 194/400 [03:42<03:41,  1.07s/it]Running loglikelihood requests:  49%|████▉     | 195/400 [03:44<03:40,  1.08s/it]Running loglikelihood requests:  49%|████▉     | 196/400 [03:45<03:39,  1.08s/it]Running loglikelihood requests:  49%|████▉     | 197/400 [03:46<03:38,  1.08s/it]Running loglikelihood requests:  50%|████▉     | 198/400 [03:47<03:37,  1.07s/it]Running loglikelihood requests:  50%|████▉     | 199/400 [03:48<03:35,  1.07s/it]Running loglikelihood requests:  50%|█████     | 200/400 [03:49<03:34,  1.07s/it]Running loglikelihood requests:  50%|█████     | 201/400 [03:50<03:33,  1.07s/it]Running loglikelihood requests:  50%|█████     | 202/400 [03:51<03:32,  1.07s/it]Running loglikelihood requests:  51%|█████     | 203/400 [03:52<03:31,  1.07s/it]Running loglikelihood requests:  51%|█████▏    | 205/400 [03:53<02:40,  1.21it/s]Running loglikelihood requests:  52%|█████▏    | 206/400 [03:54<02:52,  1.13it/s]Running loglikelihood requests:  52%|█████▏    | 207/400 [03:55<03:00,  1.07it/s]Running loglikelihood requests:  52%|█████▏    | 208/400 [03:56<03:06,  1.03it/s]Running loglikelihood requests:  52%|█████▏    | 209/400 [03:58<03:11,  1.00s/it]Running loglikelihood requests:  52%|█████▎    | 210/400 [03:59<03:14,  1.02s/it]Running loglikelihood requests:  53%|█████▎    | 211/400 [04:00<03:15,  1.04s/it]Running loglikelihood requests:  53%|█████▎    | 212/400 [04:01<03:16,  1.05s/it]Running loglikelihood requests:  53%|█████▎    | 213/400 [04:02<03:16,  1.05s/it]Running loglikelihood requests:  54%|█████▎    | 214/400 [04:03<03:16,  1.06s/it]Running loglikelihood requests:  54%|█████▍    | 215/400 [04:04<03:16,  1.06s/it]Running loglikelihood requests:  54%|█████▍    | 216/400 [04:05<03:15,  1.06s/it]Running loglikelihood requests:  54%|█████▍    | 217/400 [04:06<03:14,  1.06s/it]Running loglikelihood requests:  55%|█████▍    | 218/400 [04:07<03:13,  1.07s/it]Running loglikelihood requests:  55%|█████▍    | 219/400 [04:08<03:13,  1.07s/it]Running loglikelihood requests:  55%|█████▌    | 220/400 [04:09<03:12,  1.07s/it]Running loglikelihood requests:  55%|█████▌    | 221/400 [04:10<03:11,  1.07s/it]Running loglikelihood requests:  56%|█████▌    | 222/400 [04:11<03:09,  1.07s/it]Running loglikelihood requests:  56%|█████▌    | 223/400 [04:12<03:08,  1.07s/it]Running loglikelihood requests:  56%|█████▌    | 224/400 [04:14<03:07,  1.07s/it]Running loglikelihood requests:  56%|█████▋    | 225/400 [04:15<03:06,  1.07s/it]Running loglikelihood requests:  56%|█████▋    | 226/400 [04:16<03:05,  1.07s/it]Running loglikelihood requests:  57%|█████▋    | 227/400 [04:17<03:04,  1.07s/it]Running loglikelihood requests:  57%|█████▋    | 228/400 [04:18<03:03,  1.07s/it]Running loglikelihood requests:  57%|█████▋    | 229/400 [04:19<03:02,  1.07s/it]Running loglikelihood requests:  57%|█████▊    | 230/400 [04:20<03:01,  1.07s/it]Running loglikelihood requests:  58%|█████▊    | 231/400 [04:21<03:00,  1.07s/it]Running loglikelihood requests:  58%|█████▊    | 232/400 [04:22<02:58,  1.07s/it]Running loglikelihood requests:  58%|█████▊    | 233/400 [04:23<02:57,  1.07s/it]Running loglikelihood requests:  58%|█████▊    | 234/400 [04:24<02:56,  1.06s/it]Running loglikelihood requests:  59%|█████▉    | 235/400 [04:25<02:55,  1.06s/it]Running loglikelihood requests:  59%|█████▉    | 236/400 [04:26<02:54,  1.06s/it]Running loglikelihood requests:  59%|█████▉    | 237/400 [04:27<02:53,  1.06s/it]Running loglikelihood requests:  60%|█████▉    | 238/400 [04:28<02:52,  1.06s/it]Running loglikelihood requests:  60%|█████▉    | 239/400 [04:30<02:51,  1.06s/it]Running loglikelihood requests:  60%|██████    | 241/400 [04:31<02:10,  1.22it/s]Running loglikelihood requests:  60%|██████    | 242/400 [04:32<02:18,  1.14it/s]Running loglikelihood requests:  61%|██████    | 243/400 [04:33<02:25,  1.08it/s]Running loglikelihood requests:  61%|██████    | 244/400 [04:34<02:30,  1.04it/s]Running loglikelihood requests:  61%|██████▏   | 245/400 [04:35<02:33,  1.01it/s]Running loglikelihood requests:  62%|██████▏   | 246/400 [04:36<02:35,  1.01s/it]Running loglikelihood requests:  62%|██████▏   | 247/400 [04:37<02:36,  1.02s/it]Running loglikelihood requests:  62%|██████▏   | 248/400 [04:38<02:37,  1.04s/it]Running loglikelihood requests:  62%|██████▏   | 249/400 [04:39<02:37,  1.04s/it]Running loglikelihood requests:  62%|██████▎   | 250/400 [04:40<02:37,  1.05s/it]Running loglikelihood requests:  63%|██████▎   | 251/400 [04:41<02:36,  1.05s/it]Running loglikelihood requests:  63%|██████▎   | 252/400 [04:42<02:35,  1.05s/it]Running loglikelihood requests:  63%|██████▎   | 253/400 [04:43<02:35,  1.06s/it]Running loglikelihood requests:  64%|██████▍   | 255/400 [04:44<01:57,  1.23it/s]Running loglikelihood requests:  64%|██████▍   | 256/400 [04:45<02:05,  1.14it/s]Running loglikelihood requests:  64%|██████▍   | 257/400 [04:46<02:11,  1.08it/s]Running loglikelihood requests:  64%|██████▍   | 258/400 [04:48<02:16,  1.04it/s]Running loglikelihood requests:  65%|██████▍   | 259/400 [04:49<02:19,  1.01it/s]Running loglikelihood requests:  65%|██████▌   | 260/400 [04:50<02:20,  1.01s/it]Running loglikelihood requests:  65%|██████▌   | 261/400 [04:51<02:21,  1.02s/it]Running loglikelihood requests:  66%|██████▌   | 262/400 [04:52<02:22,  1.03s/it]Running loglikelihood requests:  66%|██████▌   | 263/400 [04:53<02:22,  1.04s/it]Running loglikelihood requests:  66%|██████▌   | 264/400 [04:54<02:21,  1.04s/it]Running loglikelihood requests:  66%|██████▋   | 265/400 [04:55<02:21,  1.05s/it]Running loglikelihood requests:  66%|██████▋   | 266/400 [04:56<02:20,  1.05s/it]Running loglikelihood requests:  67%|██████▋   | 267/400 [04:57<02:19,  1.05s/it]Running loglikelihood requests:  67%|██████▋   | 268/400 [04:58<02:19,  1.05s/it]Running loglikelihood requests:  68%|██████▊   | 270/400 [04:59<01:45,  1.23it/s]Running loglikelihood requests:  68%|██████▊   | 271/400 [05:00<01:52,  1.15it/s]Running loglikelihood requests:  68%|██████▊   | 272/400 [05:01<01:57,  1.09it/s]Running loglikelihood requests:  68%|██████▊   | 273/400 [05:02<02:01,  1.05it/s]Running loglikelihood requests:  68%|██████▊   | 274/400 [05:03<02:03,  1.02it/s]Running loglikelihood requests:  69%|██████▉   | 275/400 [05:04<02:04,  1.00it/s]Running loglikelihood requests:  69%|██████▉   | 276/400 [05:05<02:05,  1.01s/it]Running loglikelihood requests:  69%|██████▉   | 277/400 [05:06<02:05,  1.02s/it]Running loglikelihood requests:  70%|██████▉   | 278/400 [05:08<02:05,  1.03s/it]Running loglikelihood requests:  70%|██████▉   | 279/400 [05:09<02:04,  1.03s/it]Running loglikelihood requests:  70%|███████   | 280/400 [05:10<02:04,  1.03s/it]Running loglikelihood requests:  70%|███████   | 281/400 [05:11<02:03,  1.04s/it]Running loglikelihood requests:  70%|███████   | 282/400 [05:12<02:02,  1.04s/it]Running loglikelihood requests:  71%|███████   | 283/400 [05:13<02:01,  1.04s/it]Running loglikelihood requests:  71%|███████   | 284/400 [05:14<02:00,  1.04s/it]Running loglikelihood requests:  71%|███████▏  | 285/400 [05:15<01:59,  1.04s/it]Running loglikelihood requests:  72%|███████▏  | 286/400 [05:16<01:58,  1.04s/it]Running loglikelihood requests:  72%|███████▏  | 287/400 [05:17<01:57,  1.04s/it]Running loglikelihood requests:  72%|███████▏  | 288/400 [05:18<01:56,  1.04s/it]Running loglikelihood requests:  72%|███████▏  | 289/400 [05:19<01:55,  1.04s/it]Running loglikelihood requests:  72%|███████▎  | 290/400 [05:20<01:54,  1.04s/it]Running loglikelihood requests:  73%|███████▎  | 291/400 [05:21<01:53,  1.04s/it]Running loglikelihood requests:  73%|███████▎  | 292/400 [05:22<01:52,  1.04s/it]Running loglikelihood requests:  73%|███████▎  | 293/400 [05:23<01:51,  1.04s/it]Running loglikelihood requests:  74%|███████▎  | 294/400 [05:24<01:50,  1.04s/it]Running loglikelihood requests:  74%|███████▍  | 295/400 [05:25<01:49,  1.04s/it]Running loglikelihood requests:  74%|███████▍  | 296/400 [05:26<01:47,  1.04s/it]Running loglikelihood requests:  74%|███████▍  | 297/400 [05:27<01:46,  1.04s/it]Running loglikelihood requests:  74%|███████▍  | 298/400 [05:28<01:45,  1.04s/it]Running loglikelihood requests:  75%|███████▍  | 299/400 [05:29<01:44,  1.03s/it]Running loglikelihood requests:  75%|███████▌  | 300/400 [05:30<01:43,  1.03s/it]Running loglikelihood requests:  75%|███████▌  | 301/400 [05:31<01:42,  1.03s/it]Running loglikelihood requests:  76%|███████▌  | 302/400 [05:32<01:41,  1.03s/it]Running loglikelihood requests:  76%|███████▌  | 304/400 [05:33<01:16,  1.26it/s]Running loglikelihood requests:  76%|███████▋  | 305/400 [05:35<01:20,  1.17it/s]Running loglikelihood requests:  76%|███████▋  | 306/400 [05:36<01:24,  1.11it/s]Running loglikelihood requests:  77%|███████▋  | 307/400 [05:37<01:26,  1.07it/s]Running loglikelihood requests:  77%|███████▋  | 308/400 [05:38<01:28,  1.04it/s]Running loglikelihood requests:  77%|███████▋  | 309/400 [05:39<01:29,  1.02it/s]Running loglikelihood requests:  78%|███████▊  | 310/400 [05:40<01:29,  1.01it/s]Running loglikelihood requests:  78%|███████▊  | 311/400 [05:41<01:29,  1.00s/it]Running loglikelihood requests:  78%|███████▊  | 312/400 [05:42<01:28,  1.01s/it]Running loglikelihood requests:  78%|███████▊  | 313/400 [05:43<01:28,  1.01s/it]Running loglikelihood requests:  78%|███████▊  | 314/400 [05:44<01:27,  1.02s/it]Running loglikelihood requests:  79%|███████▉  | 315/400 [05:45<01:26,  1.02s/it]Running loglikelihood requests:  79%|███████▉  | 316/400 [05:46<01:25,  1.02s/it]Running loglikelihood requests:  79%|███████▉  | 317/400 [05:47<01:24,  1.02s/it]Running loglikelihood requests:  80%|███████▉  | 318/400 [05:48<01:23,  1.02s/it]Running loglikelihood requests:  80%|███████▉  | 319/400 [05:49<01:22,  1.02s/it]Running loglikelihood requests:  80%|████████  | 320/400 [05:50<01:21,  1.02s/it]Running loglikelihood requests:  80%|████████  | 321/400 [05:51<01:20,  1.02s/it]Running loglikelihood requests:  80%|████████  | 322/400 [05:52<01:19,  1.02s/it]Running loglikelihood requests:  81%|████████  | 323/400 [05:53<01:18,  1.02s/it]Running loglikelihood requests:  81%|████████  | 324/400 [05:54<01:17,  1.02s/it]Running loglikelihood requests:  81%|████████▏ | 325/400 [05:55<01:16,  1.02s/it]Running loglikelihood requests:  82%|████████▏ | 326/400 [05:56<01:15,  1.02s/it]Running loglikelihood requests:  82%|████████▏ | 327/400 [05:57<01:14,  1.02s/it]Running loglikelihood requests:  82%|████████▏ | 328/400 [05:58<01:13,  1.02s/it]Running loglikelihood requests:  82%|████████▎ | 330/400 [05:59<00:54,  1.28it/s]Running loglikelihood requests:  83%|████████▎ | 331/400 [06:00<00:58,  1.19it/s]Running loglikelihood requests:  83%|████████▎ | 332/400 [06:01<01:00,  1.13it/s]Running loglikelihood requests:  83%|████████▎ | 333/400 [06:02<01:01,  1.09it/s]Running loglikelihood requests:  84%|████████▎ | 334/400 [06:03<01:02,  1.05it/s]Running loglikelihood requests:  84%|████████▍ | 335/400 [06:04<01:02,  1.04it/s]Running loglikelihood requests:  84%|████████▍ | 336/400 [06:05<01:02,  1.02it/s]Running loglikelihood requests:  84%|████████▍ | 337/400 [06:06<01:02,  1.01it/s]Running loglikelihood requests:  84%|████████▍ | 338/400 [06:07<01:01,  1.01it/s]Running loglikelihood requests:  85%|████████▍ | 339/400 [06:08<01:00,  1.00it/s]Running loglikelihood requests:  85%|████████▌ | 340/400 [06:09<01:00,  1.00s/it]Running loglikelihood requests:  85%|████████▌ | 341/400 [06:10<00:59,  1.00s/it]Running loglikelihood requests:  86%|████████▌ | 342/400 [06:11<00:58,  1.00s/it]Running loglikelihood requests:  86%|████████▌ | 343/400 [06:12<00:57,  1.00s/it]Running loglikelihood requests:  86%|████████▌ | 344/400 [06:13<00:56,  1.00s/it]Running loglikelihood requests:  86%|████████▋ | 345/400 [06:14<00:55,  1.01s/it]Running loglikelihood requests:  86%|████████▋ | 346/400 [06:15<00:54,  1.01s/it]Running loglikelihood requests:  87%|████████▋ | 347/400 [06:16<00:53,  1.01s/it]Running loglikelihood requests:  87%|████████▋ | 348/400 [06:17<00:52,  1.00s/it]Running loglikelihood requests:  87%|████████▋ | 349/400 [06:18<00:51,  1.00s/it]Running loglikelihood requests:  88%|████████▊ | 350/400 [06:19<00:49,  1.00it/s]Running loglikelihood requests:  88%|████████▊ | 351/400 [06:20<00:48,  1.00it/s]Running loglikelihood requests:  88%|████████▊ | 352/400 [06:21<00:47,  1.01it/s]Running loglikelihood requests:  88%|████████▊ | 353/400 [06:22<00:46,  1.01it/s]Running loglikelihood requests:  88%|████████▊ | 354/400 [06:23<00:45,  1.01it/s]Running loglikelihood requests:  89%|████████▉ | 355/400 [06:24<00:44,  1.01it/s]Running loglikelihood requests:  89%|████████▉ | 356/400 [06:25<00:43,  1.01it/s]Running loglikelihood requests:  89%|████████▉ | 357/400 [06:26<00:42,  1.01it/s]Running loglikelihood requests:  90%|████████▉ | 358/400 [06:27<00:41,  1.01it/s]Running loglikelihood requests:  90%|████████▉ | 359/400 [06:28<00:40,  1.01it/s]Running loglikelihood requests:  90%|█████████ | 360/400 [06:29<00:39,  1.02it/s]Running loglikelihood requests:  90%|█████████ | 361/400 [06:30<00:38,  1.02it/s]Running loglikelihood requests:  90%|█████████ | 362/400 [06:31<00:37,  1.02it/s]Running loglikelihood requests:  91%|█████████ | 363/400 [06:32<00:36,  1.02it/s]Running loglikelihood requests:  91%|█████████ | 364/400 [06:33<00:35,  1.02it/s]Running loglikelihood requests:  91%|█████████▏| 365/400 [06:34<00:34,  1.03it/s]Running loglikelihood requests:  92%|█████████▏| 366/400 [06:35<00:33,  1.03it/s]Running loglikelihood requests:  92%|█████████▏| 367/400 [06:36<00:32,  1.03it/s]Running loglikelihood requests:  92%|█████████▏| 368/400 [06:37<00:31,  1.03it/s]Running loglikelihood requests:  92%|█████████▏| 369/400 [06:38<00:30,  1.03it/s]Running loglikelihood requests:  92%|█████████▎| 370/400 [06:39<00:29,  1.03it/s]Running loglikelihood requests:  93%|█████████▎| 371/400 [06:40<00:28,  1.03it/s]Running loglikelihood requests:  93%|█████████▎| 372/400 [06:41<00:27,  1.03it/s]Running loglikelihood requests:  93%|█████████▎| 373/400 [06:42<00:26,  1.03it/s]Running loglikelihood requests:  94%|█████████▎| 374/400 [06:43<00:25,  1.03it/s]Running loglikelihood requests:  94%|█████████▍| 375/400 [06:44<00:24,  1.04it/s]Running loglikelihood requests:  94%|█████████▍| 376/400 [06:45<00:23,  1.04it/s]Running loglikelihood requests:  94%|█████████▍| 377/400 [06:45<00:22,  1.04it/s]Running loglikelihood requests:  94%|█████████▍| 378/400 [06:46<00:21,  1.04it/s]Running loglikelihood requests:  95%|█████████▍| 379/400 [06:47<00:20,  1.05it/s]Running loglikelihood requests:  95%|█████████▌| 380/400 [06:48<00:19,  1.05it/s]Running loglikelihood requests:  95%|█████████▌| 381/400 [06:49<00:18,  1.05it/s]Running loglikelihood requests:  96%|█████████▌| 382/400 [06:50<00:17,  1.05it/s]Running loglikelihood requests:  96%|█████████▌| 383/400 [06:51<00:16,  1.05it/s]Running loglikelihood requests:  96%|█████████▌| 384/400 [06:52<00:15,  1.05it/s]Running loglikelihood requests:  96%|█████████▋| 385/400 [06:53<00:14,  1.05it/s]Running loglikelihood requests:  96%|█████████▋| 386/400 [06:54<00:13,  1.05it/s]Running loglikelihood requests:  97%|█████████▋| 387/400 [06:55<00:12,  1.05it/s]Running loglikelihood requests:  97%|█████████▋| 388/400 [06:56<00:11,  1.06it/s]Running loglikelihood requests:  97%|█████████▋| 389/400 [06:57<00:10,  1.06it/s]Running loglikelihood requests:  98%|█████████▊| 390/400 [06:58<00:09,  1.06it/s]Running loglikelihood requests:  98%|█████████▊| 391/400 [06:59<00:08,  1.06it/s]Running loglikelihood requests:  98%|█████████▊| 392/400 [07:00<00:07,  1.06it/s]Running loglikelihood requests:  98%|█████████▊| 393/400 [07:01<00:06,  1.06it/s]Running loglikelihood requests:  98%|█████████▊| 394/400 [07:02<00:05,  1.06it/s]Running loglikelihood requests:  99%|█████████▉| 395/400 [07:03<00:04,  1.06it/s]Running loglikelihood requests:  99%|█████████▉| 396/400 [07:03<00:03,  1.06it/s]Running loglikelihood requests:  99%|█████████▉| 397/400 [07:04<00:02,  1.07it/s]Running loglikelihood requests: 100%|█████████▉| 398/400 [07:05<00:01,  1.07it/s]Running loglikelihood requests: 100%|█████████▉| 399/400 [07:06<00:00,  1.08it/s]Running loglikelihood requests: 100%|██████████| 400/400 [07:07<00:00,  1.08it/s]Running loglikelihood requests: 100%|██████████| 400/400 [07:07<00:00,  1.07s/it]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:3'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:3'}
full model:
{'mastermind_35_easy': {'alias': 'mastermind_35_easy', 'acc,none': 0.51, 'acc_stderr,none': 0.05024183937956913}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9685093904417202
0.9837389482734848
0.9887891422859466
0.9728424941793791
0.9273096247071001
0.9956884174036557
0.9936991917224709
0.990637728847171
0.984416562505352
0.9357041463019401
0.957486187236088
0.9794440444506461
0.9854000882321717
0.989321120949945
0.9948124947717892
0.9950699411775289
0.9589145403056732
0.9488498047330014
0.979093344902028
0.9861615563222426
0.9944647439314634
0.9974738465425171
0.9932459641322177
0.9612113452387381
0.9566187588663586
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[5, 1, 0, 3, 7, 6, 2, 4]
tensor([5, 1, 0, 3, 7, 6, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 0, 3, 7, 5, 2, 4]
tensor([6, 1, 0, 3, 7, 5, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 1, 0, 3, 7, 6, 2, 4]
tensor([5, 1, 0, 3, 7, 6, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 0, 3, 7, 5, 2, 4]
tensor([6, 1, 0, 3, 7, 5, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 1, 0, 3, 7, 6, 2, 4]
tensor([5, 1, 0, 3, 7, 6, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 0, 3, 7, 5, 2, 4]
tensor([6, 1, 0, 3, 7, 5, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Normal merging for layer 2
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Normal merging for layer 3
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Normal merging for layer 4
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Normal merging for layer 5
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 6 to 31
done!
all done!
Model size: 12.0718 GB
196
cuda:3
wic
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:46<00:46, 46.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:59<00:00, 26.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:59<00:00, 29.86s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wic] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wic] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/super_glue/super_glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue/revision/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue/revision/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue/tree/3de24cf8022e94f4ee4b9d55a6f539891524d646/wic?recursive=False&expand=False HTTP/1.1" 307 142
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue/tree/3de24cf8022e94f4ee4b9d55a6f539891524d646/wic?recursive=False&expand=False HTTP/1.1" 200 356
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 235
DEBUG:filelock:Attempting to acquire lock 139752655283616 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_wic_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 139752655283616 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_wic_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wic/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 139752655283616 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_wic_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 139752655283616 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_wic_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Attempting to acquire lock 139750525739680 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wic/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 139750525739680 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wic/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wic/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 139750525739680 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wic/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 139750525739680 released on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wic/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wic from None to 0
INFO:lm_eval.api.task:Building contexts for wic on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1570.10it/s]
DEBUG:lm_eval.evaluator:Task: wic; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:01<04:45,  1.44s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:02<02:05,  1.57it/s]Running loglikelihood requests:   2%|▎         | 5/200 [00:02<01:36,  2.02it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:03<01:24,  2.28it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:04<01:16,  2.50it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:04<01:11,  2.64it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:05<01:07,  2.77it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:06<01:04,  2.85it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:06<01:02,  2.92it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:07<01:01,  2.97it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:08<00:59,  3.00it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:08<00:58,  3.03it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:09<00:57,  3.05it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:10<00:56,  3.06it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:10<00:55,  3.07it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:11<00:54,  3.09it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:12<00:53,  3.10it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:12<00:52,  3.12it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:13<00:52,  3.13it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:13<00:51,  3.14it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:14<00:50,  3.15it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:15<00:49,  3.16it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:15<00:48,  3.17it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:16<00:48,  3.17it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:17<00:47,  3.18it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:17<00:46,  3.18it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:18<00:46,  3.18it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:18<00:45,  3.19it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:19<00:44,  3.19it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:20<00:44,  3.19it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:20<00:43,  3.19it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:21<00:42,  3.19it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:22<00:42,  3.19it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:22<00:41,  3.19it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:23<00:40,  3.20it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:23<00:40,  3.21it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:24<00:39,  3.22it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:25<00:38,  3.22it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:25<00:38,  3.23it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:26<00:37,  3.24it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:27<00:36,  3.25it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:27<00:35,  3.26it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:28<00:35,  3.26it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:28<00:34,  3.27it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:29<00:33,  3.27it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:30<00:33,  3.27it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:30<00:32,  3.27it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:31<00:32,  3.27it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:31<00:31,  3.28it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:32<00:30,  3.27it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:33<00:30,  3.27it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:33<00:29,  3.27it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:34<00:28,  3.28it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:34<00:28,  3.29it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:35<00:27,  3.29it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:36<00:27,  3.29it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:36<00:26,  3.29it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:37<00:25,  3.29it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:38<00:25,  3.29it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:38<00:24,  3.29it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:39<00:23,  3.30it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:39<00:23,  3.30it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:40<00:22,  3.30it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [00:41<00:22,  3.30it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [00:41<00:21,  3.30it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [00:42<00:20,  3.31it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [00:42<00:20,  3.31it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [00:43<00:19,  3.31it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [00:44<00:19,  3.31it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [00:44<00:18,  3.33it/s]Running loglikelihood requests:  70%|███████   | 141/200 [00:45<00:17,  3.34it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [00:45<00:17,  3.34it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [00:46<00:16,  3.35it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [00:47<00:15,  3.36it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [00:47<00:15,  3.36it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [00:48<00:14,  3.37it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [00:48<00:13,  3.37it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [00:49<00:13,  3.37it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [00:50<00:12,  3.38it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [00:50<00:12,  3.39it/s]Running loglikelihood requests:  80%|████████  | 161/200 [00:51<00:11,  3.39it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [00:51<00:10,  3.40it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [00:52<00:10,  3.40it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [00:52<00:09,  3.41it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [00:53<00:09,  3.41it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [00:54<00:08,  3.42it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [00:54<00:07,  3.43it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [00:55<00:07,  3.44it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [00:55<00:06,  3.45it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [00:56<00:06,  3.46it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [00:56<00:05,  3.47it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [00:57<00:04,  3.47it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [00:58<00:04,  3.47it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [00:58<00:03,  3.48it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [00:59<00:03,  3.49it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [00:59<00:02,  3.51it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [01:00<00:01,  3.51it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:00<00:01,  3.52it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:01<00:00,  3.53it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:02<00:00,  3.55it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:02<00:00,  3.22it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:4'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:4'}
full model:
{'wic': {'alias': 'wic', 'acc,none': 0.47, 'acc_stderr,none': 0.05016135580465919}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.7015569150227223
0.5302361010977743
0.6131123609930033
0.8131827739550247
0.5456264918897312
0.5653128506125247
0.9024119585362896
0.8122852497904204
0.9072724946141106
0.866764102055741
0.8260299199157425
0.7472915500213457
0.8874866998217976
0.7441602305581367
0.22948143665096393
0.6763976434023368
0.5909756859477309
0.6775915070630182
0.8311737665735953
0.5882947608660276
0.7888779075700829
0.9530393862783458
0.7563942945196994
0.7021129984434293
0.9133573687405422
0.8864659884483975
0.43949477197814607
0.49530015739760547
0.9835705252160515
0.7015569150227223
0.5302361010977743
0.6131123609930033
0.8131827739550247
0.5456264918897312
0.5653128506125247
0.9024119585362896
0.8122852497904204
0.9072724946141106
0.866764102055741
0.8260299199157425
0.7472915500213457
0.8874866998217976
0.7441602305581367
Total groups 76 exceeded the threshold, stopping comparison.
The group tensor is
[6, 5, 2, 3, 7, 0, 4, 1]
tensor([6, 5, 2, 3, 7, 0, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 6, 1, 5, 4, 2, 3, 0]
tensor([7, 6, 1, 5, 4, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[7, 6, 2, 4, 5, 0, 3, 1]
tensor([7, 6, 2, 4, 5, 0, 3, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 0, 0, 5, 1, 1, 3, 2]
tensor([4, 0, 0, 5, 1, 1, 3, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 0, 2, 5, 3, 4, 1]
tensor([0, 1, 0, 2, 5, 3, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 0, 1, 4, 1, 2, 3, 0]
tensor([5, 0, 1, 4, 1, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 1, 1, 3, 4, 2, 5, 0]
tensor([0, 1, 1, 3, 4, 2, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 1, 0, 2, 3, 1, 2, 3]
tensor([0, 1, 0, 2, 3, 1, 2, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([2])
tensor(2)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 2 to 3
done!
Normal merging for layer 4
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 5 to 7
done!
Normal merging for layer 8
tensor([1, 2])
tensor(1)
tensor([4, 5])
tensor(4)
tensor([7])
tensor(7)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([3])
tensor(3)
done!
Cross-layer merge completed for layers 9 to 10
done!
Normal merging for layer 11
tensor([0, 2])
tensor(0)
tensor([1, 7])
tensor(1)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 12 to 13
done!
Normal merging for layer 14
tensor([1, 7])
tensor(1)
tensor([2, 4])
tensor(2)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([0])
tensor(0)
done!
Normal merging for layer 15
tensor([0, 7])
tensor(0)
tensor([1, 2])
tensor(1)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
done!
Normal merging for layer 16
tensor([0, 2])
tensor(0)
tensor([1, 5])
tensor(1)
tensor([3, 6])
tensor(3)
tensor([4, 7])
tensor(4)
done!
Cross-layer merge completed for layers 17 to 31
done!
all done!
Model size: 12.5757 GB
55
cuda:4
qqp
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:43<00:43, 43.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:57<00:00, 25.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:57<00:00, 28.60s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: qqp] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: qqp] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
WARNING:lm_eval.api.task:[Task: qqp] metric f1 is defined, but aggregation is not. using default aggregation=f1
WARNING:lm_eval.api.task:[Task: qqp] metric f1 is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/revision/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 111
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/revision/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c?recursive=False&expand=False HTTP/1.1" 307 136
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c?recursive=False&expand=False HTTP/1.1" 200 530
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/ax?recursive=False&expand=False HTTP/1.1" 307 139
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/ax?recursive=False&expand=False HTTP/1.1" 200 231
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/revision/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 111
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/revision/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 502 0
Using the latest cached version of the dataset since glue couldn't be found on the Hugging Face Hub
WARNING:datasets.load:Using the latest cached version of the dataset since glue couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'qqp' at /public/home/zouyifei001/.cache/huggingface/datasets/glue/qqp/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c (last modified on Wed Apr 30 15:05:20 2025).
WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'qqp' at /public/home/zouyifei001/.cache/huggingface/datasets/glue/qqp/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c (last modified on Wed Apr 30 15:05:20 2025).
DEBUG:filelock:Attempting to acquire lock 139750525697440 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_qqp_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139750525697440 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_qqp_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/qqp/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139750525697440 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_qqp_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139750525697440 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_qqp_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of qqp from None to 0
INFO:lm_eval.api.task:Building contexts for qqp on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 2374.20it/s]
DEBUG:lm_eval.evaluator:Task: qqp; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:01<05:32,  1.67s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:02<02:31,  1.30it/s]Running loglikelihood requests:   2%|▎         | 5/200 [00:03<01:53,  1.73it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:04<01:36,  1.99it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:04<01:26,  2.20it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:05<01:20,  2.35it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:06<01:16,  2.45it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:07<01:13,  2.53it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:07<01:10,  2.59it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:08<01:08,  2.64it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:09<01:06,  2.70it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:10<01:04,  2.74it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:10<01:03,  2.77it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:11<01:01,  2.81it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:12<01:00,  2.83it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:12<00:59,  2.84it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:13<00:58,  2.88it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:14<00:56,  2.91it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:14<00:55,  2.93it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:15<00:54,  2.95it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:16<00:53,  2.97it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:16<00:52,  2.97it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:17<00:51,  2.99it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:18<00:50,  3.01it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:18<00:50,  3.02it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:19<00:49,  3.04it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:20<00:48,  3.05it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:20<00:47,  3.06it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:21<00:46,  3.07it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:22<00:45,  3.09it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:22<00:44,  3.11it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:23<00:43,  3.11it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:23<00:43,  3.13it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:24<00:42,  3.14it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:25<00:41,  3.14it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:25<00:40,  3.15it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:26<00:40,  3.15it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:27<00:39,  3.15it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:27<00:38,  3.16it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:28<00:38,  3.18it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:28<00:37,  3.19it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:29<00:36,  3.20it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:30<00:35,  3.21it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:30<00:35,  3.21it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:31<00:34,  3.22it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:32<00:33,  3.22it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:32<00:33,  3.24it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:33<00:32,  3.25it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:33<00:31,  3.26it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:34<00:30,  3.27it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:35<00:30,  3.28it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:35<00:29,  3.29it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:36<00:28,  3.30it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:36<00:28,  3.31it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:37<00:27,  3.31it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:38<00:26,  3.33it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:38<00:25,  3.35it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:39<00:25,  3.36it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:39<00:24,  3.37it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:40<00:23,  3.38it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:41<00:23,  3.38it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:41<00:22,  3.39it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:42<00:22,  3.39it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [00:42<00:21,  3.40it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [00:43<00:20,  3.41it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [00:43<00:20,  3.43it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [00:44<00:19,  3.44it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [00:45<00:18,  3.44it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [00:45<00:18,  3.45it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [00:46<00:17,  3.45it/s]Running loglikelihood requests:  70%|███████   | 141/200 [00:46<00:17,  3.46it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [00:47<00:16,  3.47it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [00:48<00:15,  3.48it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [00:48<00:15,  3.49it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [00:49<00:14,  3.50it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [00:49<00:13,  3.51it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [00:50<00:13,  3.52it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [00:50<00:12,  3.52it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [00:51<00:12,  3.54it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [00:51<00:11,  3.55it/s]Running loglikelihood requests:  80%|████████  | 161/200 [00:52<00:10,  3.56it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [00:53<00:10,  3.56it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [00:53<00:09,  3.57it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [00:54<00:09,  3.58it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [00:54<00:08,  3.59it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [00:55<00:08,  3.60it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [00:55<00:07,  3.61it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [00:56<00:06,  3.62it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [00:56<00:06,  3.63it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [00:57<00:05,  3.63it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [00:58<00:05,  3.64it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [00:58<00:04,  3.64it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [00:59<00:04,  3.64it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [00:59<00:03,  3.65it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [01:00<00:03,  3.66it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [01:00<00:02,  3.68it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [01:01<00:01,  3.70it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:01<00:01,  3.72it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:02<00:00,  3.75it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:02<00:00,  3.79it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:02<00:00,  3.18it/s]
bootstrapping for stddev (sequential): f1_score
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:01<01:58,  1.20s/it]  2%|▏         | 2/100 [00:02<01:57,  1.20s/it]  3%|▎         | 3/100 [00:03<01:56,  1.20s/it]  4%|▍         | 4/100 [00:04<01:55,  1.20s/it]  5%|▌         | 5/100 [00:06<01:54,  1.20s/it]  6%|▌         | 6/100 [00:07<01:52,  1.20s/it]  7%|▋         | 7/100 [00:08<01:51,  1.20s/it]  8%|▊         | 8/100 [00:09<01:50,  1.20s/it]  9%|▉         | 9/100 [00:10<01:49,  1.20s/it] 10%|█         | 10/100 [00:12<01:48,  1.20s/it] 11%|█         | 11/100 [00:13<01:46,  1.20s/it] 12%|█▏        | 12/100 [00:14<01:45,  1.20s/it] 13%|█▎        | 13/100 [00:15<01:44,  1.20s/it] 14%|█▍        | 14/100 [00:16<01:43,  1.20s/it] 15%|█▌        | 15/100 [00:18<01:42,  1.20s/it] 16%|█▌        | 16/100 [00:19<01:40,  1.20s/it] 17%|█▋        | 17/100 [00:20<01:39,  1.20s/it] 18%|█▊        | 18/100 [00:21<01:38,  1.20s/it] 19%|█▉        | 19/100 [00:22<01:37,  1.20s/it] 20%|██        | 20/100 [00:24<01:36,  1.20s/it] 21%|██        | 21/100 [00:25<01:34,  1.20s/it] 22%|██▏       | 22/100 [00:26<01:33,  1.20s/it] 23%|██▎       | 23/100 [00:27<01:32,  1.20s/it] 24%|██▍       | 24/100 [00:28<01:31,  1.20s/it] 25%|██▌       | 25/100 [00:30<01:30,  1.20s/it] 26%|██▌       | 26/100 [00:31<01:28,  1.20s/it] 27%|██▋       | 27/100 [00:32<01:27,  1.20s/it] 28%|██▊       | 28/100 [00:33<01:26,  1.20s/it] 29%|██▉       | 29/100 [00:34<01:25,  1.20s/it] 30%|███       | 30/100 [00:36<01:24,  1.20s/it] 31%|███       | 31/100 [00:37<01:22,  1.20s/it] 32%|███▏      | 32/100 [00:38<01:21,  1.20s/it] 33%|███▎      | 33/100 [00:39<01:20,  1.20s/it] 34%|███▍      | 34/100 [00:40<01:19,  1.20s/it] 35%|███▌      | 35/100 [00:42<01:18,  1.20s/it] 36%|███▌      | 36/100 [00:43<01:17,  1.21s/it] 37%|███▋      | 37/100 [00:44<01:16,  1.21s/it] 38%|███▊      | 38/100 [00:45<01:14,  1.21s/it] 39%|███▉      | 39/100 [00:46<01:13,  1.21s/it] 40%|████      | 40/100 [00:48<01:12,  1.21s/it] 41%|████      | 41/100 [00:49<01:11,  1.21s/it] 42%|████▏     | 42/100 [00:50<01:09,  1.20s/it] 43%|████▎     | 43/100 [00:51<01:08,  1.21s/it] 44%|████▍     | 44/100 [00:52<01:07,  1.21s/it] 45%|████▌     | 45/100 [00:54<01:06,  1.21s/it] 46%|████▌     | 46/100 [00:55<01:05,  1.21s/it] 47%|████▋     | 47/100 [00:56<01:03,  1.21s/it] 48%|████▊     | 48/100 [00:57<01:02,  1.20s/it] 49%|████▉     | 49/100 [00:58<01:01,  1.21s/it] 50%|█████     | 50/100 [01:00<01:00,  1.21s/it] 51%|█████     | 51/100 [01:01<00:59,  1.21s/it] 52%|█████▏    | 52/100 [01:02<00:57,  1.20s/it] 53%|█████▎    | 53/100 [01:03<00:56,  1.20s/it] 54%|█████▍    | 54/100 [01:04<00:55,  1.20s/it] 55%|█████▌    | 55/100 [01:06<00:54,  1.20s/it] 56%|█████▌    | 56/100 [01:07<00:52,  1.20s/it] 57%|█████▋    | 57/100 [01:08<00:51,  1.20s/it] 58%|█████▊    | 58/100 [01:09<00:50,  1.20s/it] 59%|█████▉    | 59/100 [01:10<00:49,  1.20s/it] 60%|██████    | 60/100 [01:12<00:48,  1.20s/it] 61%|██████    | 61/100 [01:13<00:46,  1.20s/it] 62%|██████▏   | 62/100 [01:14<00:45,  1.20s/it] 63%|██████▎   | 63/100 [01:15<00:44,  1.20s/it] 64%|██████▍   | 64/100 [01:17<00:43,  1.20s/it] 65%|██████▌   | 65/100 [01:18<00:42,  1.20s/it] 66%|██████▌   | 66/100 [01:19<00:41,  1.21s/it] 67%|██████▋   | 67/100 [01:20<00:40,  1.22s/it] 68%|██████▊   | 68/100 [01:21<00:38,  1.21s/it] 69%|██████▉   | 69/100 [01:23<00:37,  1.21s/it] 70%|███████   | 70/100 [01:24<00:36,  1.21s/it] 71%|███████   | 71/100 [01:25<00:34,  1.21s/it] 72%|███████▏  | 72/100 [01:26<00:33,  1.20s/it] 73%|███████▎  | 73/100 [01:27<00:32,  1.20s/it] 74%|███████▍  | 74/100 [01:29<00:31,  1.20s/it] 75%|███████▌  | 75/100 [01:30<00:30,  1.20s/it] 76%|███████▌  | 76/100 [01:31<00:28,  1.20s/it] 77%|███████▋  | 77/100 [01:32<00:27,  1.20s/it] 78%|███████▊  | 78/100 [01:33<00:26,  1.20s/it] 79%|███████▉  | 79/100 [01:35<00:25,  1.20s/it] 80%|████████  | 80/100 [01:36<00:24,  1.20s/it] 81%|████████  | 81/100 [01:37<00:22,  1.20s/it] 82%|████████▏ | 82/100 [01:38<00:21,  1.20s/it] 83%|████████▎ | 83/100 [01:39<00:20,  1.20s/it] 84%|████████▍ | 84/100 [01:41<00:19,  1.20s/it] 85%|████████▌ | 85/100 [01:42<00:18,  1.20s/it] 86%|████████▌ | 86/100 [01:43<00:16,  1.20s/it] 87%|████████▋ | 87/100 [01:44<00:15,  1.20s/it] 88%|████████▊ | 88/100 [01:45<00:14,  1.20s/it] 89%|████████▉ | 89/100 [01:47<00:13,  1.20s/it] 90%|█████████ | 90/100 [01:48<00:12,  1.20s/it] 91%|█████████ | 91/100 [01:49<00:10,  1.20s/it] 92%|█████████▏| 92/100 [01:50<00:09,  1.20s/it] 93%|█████████▎| 93/100 [01:51<00:08,  1.20s/it] 94%|█████████▍| 94/100 [01:53<00:07,  1.20s/it] 95%|█████████▌| 95/100 [01:54<00:06,  1.20s/it] 96%|█████████▌| 96/100 [01:55<00:04,  1.20s/it] 97%|█████████▋| 97/100 [01:56<00:03,  1.20s/it] 98%|█████████▊| 98/100 [01:57<00:02,  1.20s/it] 99%|█████████▉| 99/100 [01:59<00:01,  1.20s/it]100%|██████████| 100/100 [02:00<00:00,  1.20s/it]100%|██████████| 100/100 [02:00<00:00,  1.20s/it]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:5'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:5'}
full model:
{'qqp': {'alias': 'qqp', 'acc,none': 0.3, 'acc_stderr,none': 0.04605661864718382, 'f1,none': np.float64(0.46153846153846156), 'f1_stderr,none': 0.05409397997448054}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.7956670939612598
0.9434665619842647
0.7711450328862919
0.8003111158987146
0.8660685706927677
0.6448594355779524
0.8450704433196731
0.7858702319299253
0.44571740342828275
0.8279983705061201
0.5649013775668057
0.5764430622159564
0.7600312367627909
0.4667905570890965
0.6441885742762831
0.5956490746171949
0.7561037067659027
0.6832036593513438
0.703034342774608
0.741950763385666
0.9094352412525417
0.3828457019607829
0.592762753179094
0.5983336442242687
0.5414593978662989
0.3299447012562784
0.4799857918750434
0.8524920468933548
0.713165518996795
0.7956670939612598
0.9434665619842647
0.7711450328862919
0.8003111158987146
0.8660685706927677
0.6448594355779524
0.8450704433196731
0.7858702319299253
0.44571740342828275
0.8279983705061201
0.5649013775668057
0.5764430622159564
0.7600312367627909
0.4667905570890965
0.6441885742762831
0.5956490746171949
0.7561037067659027
0.6832036593513438
0.703034342774608
0.741950763385666
0.9094352412525417
0.3828457019607829
0.592762753179094
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[5, 4, 6, 2, 7, 1, 3, 0]
tensor([5, 4, 6, 2, 7, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 4, 5, 2, 6, 1, 3, 0]
tensor([7, 4, 5, 2, 6, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 4, 6, 2, 7, 1, 3, 0]
tensor([5, 4, 6, 2, 7, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[6, 4, 5, 2, 7, 3, 0, 1]
tensor([6, 4, 5, 2, 7, 3, 0, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 7, 4, 2, 5, 0, 1, 3]
tensor([6, 7, 4, 2, 5, 0, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 6, 4, 3, 7, 1, 0, 2]
tensor([5, 6, 4, 3, 7, 1, 0, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
done!
Normal merging for layer 2
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 3 to 4
done!
Normal merging for layer 5
tensor([6])
tensor(6)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Normal merging for layer 6
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
tensor([1])
tensor(1)
done!
Normal merging for layer 7
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 8 to 31
done!
all done!
Model size: 12.1348 GB
26
cuda:5
cola
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:43<00:43, 43.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:56<00:00, 25.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:56<00:00, 28.27s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: cola] metric mcc is defined, but aggregation is not. using default aggregation=matthews_corrcoef
WARNING:lm_eval.api.task:[Task: cola] metric mcc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cola?recursive=False&expand=False HTTP/1.1" 307 141
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cola?recursive=False&expand=False HTTP/1.1" 200 358
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139750522627056 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_cola_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139750522627056 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_cola_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139750522627056 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_cola_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139750522627056 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_cola_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139750519402000 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139750519402000 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139750519402000 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139750519402000 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of cola from None to 0
INFO:lm_eval.api.task:Building contexts for cola on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 3183.15it/s]
DEBUG:lm_eval.evaluator:Task: cola; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:01<04:22,  1.32s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:01<01:47,  1.83it/s]Running loglikelihood requests:   2%|▎         | 5/200 [00:02<01:18,  2.50it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:02<01:06,  2.92it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:03<00:59,  3.23it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:03<00:55,  3.43it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:04<00:52,  3.58it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:04<00:50,  3.68it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:05<00:50,  3.64it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:06<00:48,  3.74it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:06<00:46,  3.81it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:07<00:45,  3.86it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:07<00:44,  3.90it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:08<00:43,  3.94it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:08<00:43,  3.97it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:09<00:42,  3.99it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:09<00:41,  4.01it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:10<00:40,  4.04it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:10<00:40,  4.06it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:10<00:39,  4.07it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:11<00:39,  4.07it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:11<00:38,  4.08it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:12<00:37,  4.10it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:12<00:37,  4.11it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:13<00:36,  4.12it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:13<00:35,  4.14it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:14<00:35,  4.16it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:14<00:34,  4.16it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:15<00:34,  4.17it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:15<00:33,  4.17it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:16<00:33,  4.19it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:16<00:32,  4.20it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:17<00:32,  4.21it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:17<00:31,  4.21it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:18<00:30,  4.23it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:18<00:30,  4.24it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:19<00:29,  4.25it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:19<00:29,  4.25it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:20<00:28,  4.26it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:20<00:28,  4.26it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:20<00:27,  4.26it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:21<00:27,  4.26it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:21<00:26,  4.27it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:22<00:26,  4.28it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:22<00:25,  4.29it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:23<00:25,  4.30it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:23<00:24,  4.29it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:24<00:24,  4.30it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:24<00:23,  4.29it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:25<00:23,  4.30it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:25<00:22,  4.32it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:26<00:22,  4.32it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:26<00:21,  4.33it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:26<00:21,  4.34it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:27<00:20,  4.35it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:27<00:20,  4.35it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:28<00:19,  4.35it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:28<00:19,  4.36it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:29<00:19,  4.37it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:29<00:18,  4.38it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:30<00:18,  4.39it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:30<00:17,  4.39it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:31<00:17,  4.39it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [00:31<00:16,  4.40it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [00:32<00:16,  4.40it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [00:32<00:15,  4.42it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [00:32<00:15,  4.42it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [00:33<00:14,  4.43it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [00:33<00:14,  4.43it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [00:34<00:13,  4.44it/s]Running loglikelihood requests:  70%|███████   | 141/200 [00:34<00:13,  4.46it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [00:35<00:12,  4.47it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [00:35<00:12,  4.47it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [00:36<00:11,  4.48it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [00:36<00:11,  4.49it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [00:36<00:10,  4.50it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [00:37<00:10,  4.50it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [00:37<00:09,  4.50it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [00:38<00:09,  4.52it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [00:38<00:09,  4.54it/s]Running loglikelihood requests:  80%|████████  | 161/200 [00:39<00:08,  4.54it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [00:39<00:08,  4.56it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [00:40<00:07,  4.56it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [00:40<00:07,  4.56it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [00:40<00:06,  4.57it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [00:41<00:06,  4.58it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [00:41<00:05,  4.59it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [00:42<00:05,  4.60it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [00:42<00:04,  4.61it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [00:43<00:04,  4.61it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [00:43<00:04,  4.61it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [00:43<00:03,  4.62it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [00:44<00:03,  4.62it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [00:44<00:02,  4.63it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [00:45<00:02,  4.64it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [00:45<00:01,  4.65it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [00:46<00:01,  4.67it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [00:46<00:01,  4.69it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [00:46<00:00,  4.70it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [00:47<00:00,  4.73it/s]Running loglikelihood requests: 100%|██████████| 200/200 [00:47<00:00,  4.23it/s]
bootstrapping for stddev (sequential): matthews_corrcoef
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<01:34,  1.05it/s]  2%|▏         | 2/100 [00:01<01:32,  1.06it/s]  3%|▎         | 3/100 [00:02<01:30,  1.07it/s]  4%|▍         | 4/100 [00:03<01:28,  1.08it/s]  5%|▌         | 5/100 [00:04<01:27,  1.08it/s]  6%|▌         | 6/100 [00:05<01:26,  1.08it/s]  7%|▋         | 7/100 [00:06<01:26,  1.08it/s]  8%|▊         | 8/100 [00:07<01:25,  1.08it/s]  9%|▉         | 9/100 [00:08<01:24,  1.08it/s] 10%|█         | 10/100 [00:09<01:23,  1.08it/s] 11%|█         | 11/100 [00:10<01:22,  1.08it/s] 12%|█▏        | 12/100 [00:11<01:21,  1.08it/s] 13%|█▎        | 13/100 [00:12<01:20,  1.08it/s] 14%|█▍        | 14/100 [00:12<01:19,  1.08it/s] 15%|█▌        | 15/100 [00:13<01:18,  1.08it/s] 16%|█▌        | 16/100 [00:14<01:17,  1.08it/s] 17%|█▋        | 17/100 [00:15<01:17,  1.08it/s] 18%|█▊        | 18/100 [00:16<01:16,  1.07it/s] 19%|█▉        | 19/100 [00:17<01:15,  1.07it/s] 20%|██        | 20/100 [00:18<01:14,  1.08it/s] 21%|██        | 21/100 [00:19<01:13,  1.08it/s] 22%|██▏       | 22/100 [00:20<01:12,  1.08it/s] 23%|██▎       | 23/100 [00:21<01:11,  1.07it/s] 24%|██▍       | 24/100 [00:22<01:10,  1.07it/s] 25%|██▌       | 25/100 [00:23<01:09,  1.08it/s] 26%|██▌       | 26/100 [00:24<01:08,  1.08it/s] 27%|██▋       | 27/100 [00:25<01:07,  1.08it/s] 28%|██▊       | 28/100 [00:25<01:06,  1.07it/s] 29%|██▉       | 29/100 [00:26<01:06,  1.07it/s] 30%|███       | 30/100 [00:27<01:05,  1.07it/s] 31%|███       | 31/100 [00:28<01:03,  1.08it/s] 32%|███▏      | 32/100 [00:29<01:02,  1.08it/s] 33%|███▎      | 33/100 [00:30<01:02,  1.08it/s] 34%|███▍      | 34/100 [00:31<01:01,  1.08it/s] 35%|███▌      | 35/100 [00:32<01:00,  1.08it/s] 36%|███▌      | 36/100 [00:33<00:59,  1.08it/s] 37%|███▋      | 37/100 [00:34<00:58,  1.08it/s] 38%|███▊      | 38/100 [00:35<00:57,  1.09it/s] 39%|███▉      | 39/100 [00:36<00:56,  1.07it/s] 40%|████      | 40/100 [00:37<00:55,  1.07it/s] 41%|████      | 41/100 [00:38<00:54,  1.08it/s] 42%|████▏     | 42/100 [00:38<00:53,  1.08it/s] 43%|████▎     | 43/100 [00:39<00:52,  1.08it/s] 44%|████▍     | 44/100 [00:40<00:51,  1.08it/s] 45%|████▌     | 45/100 [00:41<00:51,  1.07it/s] 46%|████▌     | 46/100 [00:42<00:50,  1.07it/s] 47%|████▋     | 47/100 [00:43<00:49,  1.07it/s] 48%|████▊     | 48/100 [00:44<00:48,  1.07it/s] 49%|████▉     | 49/100 [00:45<00:47,  1.07it/s] 50%|█████     | 50/100 [00:46<00:46,  1.07it/s] 51%|█████     | 51/100 [00:47<00:45,  1.07it/s] 52%|█████▏    | 52/100 [00:48<00:44,  1.07it/s] 53%|█████▎    | 53/100 [00:49<00:43,  1.08it/s] 54%|█████▍    | 54/100 [00:50<00:42,  1.08it/s] 55%|█████▌    | 55/100 [00:51<00:41,  1.08it/s] 56%|█████▌    | 56/100 [00:51<00:40,  1.08it/s] 57%|█████▋    | 57/100 [00:52<00:40,  1.07it/s] 58%|█████▊    | 58/100 [00:53<00:39,  1.07it/s] 59%|█████▉    | 59/100 [00:54<00:38,  1.07it/s] 60%|██████    | 60/100 [00:55<00:37,  1.07it/s] 61%|██████    | 61/100 [00:56<00:36,  1.07it/s] 62%|██████▏   | 62/100 [00:57<00:35,  1.07it/s] 63%|██████▎   | 63/100 [00:58<00:34,  1.07it/s] 64%|██████▍   | 64/100 [00:59<00:33,  1.07it/s] 65%|██████▌   | 65/100 [01:00<00:32,  1.07it/s] 66%|██████▌   | 66/100 [01:01<00:31,  1.07it/s] 67%|██████▋   | 67/100 [01:02<00:30,  1.07it/s] 68%|██████▊   | 68/100 [01:03<00:29,  1.07it/s] 69%|██████▉   | 69/100 [01:04<00:29,  1.07it/s] 70%|███████   | 70/100 [01:05<00:28,  1.07it/s] 71%|███████   | 71/100 [01:06<00:27,  1.07it/s] 72%|███████▏  | 72/100 [01:06<00:26,  1.07it/s] 73%|███████▎  | 73/100 [01:07<00:25,  1.07it/s] 74%|███████▍  | 74/100 [01:08<00:24,  1.07it/s] 75%|███████▌  | 75/100 [01:09<00:23,  1.08it/s] 76%|███████▌  | 76/100 [01:10<00:22,  1.07it/s] 77%|███████▋  | 77/100 [01:11<00:21,  1.07it/s] 78%|███████▊  | 78/100 [01:12<00:20,  1.07it/s] 79%|███████▉  | 79/100 [01:13<00:19,  1.08it/s] 80%|████████  | 80/100 [01:14<00:18,  1.07it/s] 81%|████████  | 81/100 [01:15<00:17,  1.07it/s] 82%|████████▏ | 82/100 [01:16<00:16,  1.07it/s] 83%|████████▎ | 83/100 [01:17<00:15,  1.07it/s] 84%|████████▍ | 84/100 [01:18<00:14,  1.07it/s] 85%|████████▌ | 85/100 [01:19<00:13,  1.07it/s] 86%|████████▌ | 86/100 [01:19<00:13,  1.08it/s] 87%|████████▋ | 87/100 [01:20<00:12,  1.08it/s] 88%|████████▊ | 88/100 [01:21<00:11,  1.07it/s] 89%|████████▉ | 89/100 [01:22<00:10,  1.07it/s] 90%|█████████ | 90/100 [01:23<00:09,  1.07it/s] 91%|█████████ | 91/100 [01:24<00:08,  1.08it/s] 92%|█████████▏| 92/100 [01:25<00:07,  1.08it/s] 93%|█████████▎| 93/100 [01:26<00:06,  1.07it/s] 94%|█████████▍| 94/100 [01:27<00:05,  1.08it/s] 95%|█████████▌| 95/100 [01:28<00:04,  1.08it/s] 96%|█████████▌| 96/100 [01:29<00:03,  1.08it/s] 97%|█████████▋| 97/100 [01:30<00:02,  1.08it/s] 98%|█████████▊| 98/100 [01:31<00:01,  1.08it/s] 99%|█████████▉| 99/100 [01:32<00:00,  1.07it/s]100%|██████████| 100/100 [01:33<00:00,  1.07it/s]100%|██████████| 100/100 [01:33<00:00,  1.07it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:6'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:6'}
full model:
{'cola': {'alias': 'cola', 'mcc,none': np.float64(-0.0234083603222329), 'mcc_stderr,none': 0.10027612985654218}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9827615088085355
0.9302188892609604
0.7011961870018854
0.5626926521241726
0.8487059565524276
0.8497526414658526
0.9054485200458864
0.7394951536076
0.6615723249956142
0.3790091735780837
0.7669438266452424
0.6500882643740805
0.6039759750877352
0.8611545876684488
0.9595791152744535
0.7624866897939796
0.8585278638499474
0.9654871578633694
0.8537985077125277
0.9276026122967783
0.938072418626947
0.8815459403167786
0.6241194219560614
0.901256729143793
0.7007049393842223
0.6541093728101413
0.9141945519271818
0.7667764647672246
0.8091089193013563
Total groups 69 exceeded the threshold, stopping comparison.
The group tensor is
[3, 2, 6, 7, 5, 1, 4, 0]
tensor([3, 2, 6, 7, 5, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 3, 6, 7, 5, 1, 4, 0]
tensor([2, 3, 6, 7, 5, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 3, 5, 7, 6, 1, 2, 0]
tensor([4, 3, 5, 7, 6, 1, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[2, 3, 0, 1, 2, 1, 3, 0]
tensor([2, 3, 0, 1, 2, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[1, 0, 1, 2, 3, 2, 3, 0]
tensor([1, 0, 1, 2, 3, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 2, 1, 2, 3, 1, 3, 0]
tensor([0, 2, 1, 2, 3, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[1, 0, 0, 1, 2, 3, 3, 2]
tensor([1, 0, 0, 1, 2, 3, 3, 2], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[3, 1, 0, 1, 2, 2, 3, 0]
tensor([3, 1, 0, 1, 2, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1.0, 1.0, 1, 1.0, 0]
tensor([0, 1, 1, 1, 1, 1, 1, 0], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
done!
Cross-layer merge completed for layers 2 to 5
done!
Normal merging for layer 6
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
tensor([3])
tensor(3)
done!
Cross-layer merge completed for layers 7 to 18
done!
Normal merging for layer 19
tensor([2, 7])
tensor(2)
tensor([3, 5])
tensor(3)
tensor([0, 4])
tensor(0)
tensor([1, 6])
tensor(1)
done!
Normal merging for layer 20
tensor([1, 7])
tensor(1)
tensor([0, 2])
tensor(0)
tensor([3, 5])
tensor(3)
tensor([4, 6])
tensor(4)
done!
Normal merging for layer 21
tensor([0, 7])
tensor(0)
tensor([2, 5])
tensor(2)
tensor([1, 3])
tensor(1)
tensor([4, 6])
tensor(4)
done!
Normal merging for layer 22
tensor([1, 2])
tensor(1)
tensor([0, 3])
tensor(0)
tensor([4, 7])
tensor(4)
tensor([5, 6])
tensor(5)
done!
Normal merging for layer 23
tensor([2, 7])
tensor(2)
tensor([1, 3])
tensor(1)
tensor([4, 5])
tensor(4)
tensor([0, 6])
tensor(0)
done!
Cross-layer merge completed for layers 24 to 27
done!
Normal merging for layer 28
tensor([0, 7])
tensor(0)
tensor([1, 2, 3, 4, 5, 6])
tensor(1)
done!
Cross-layer merge completed for layers 29 to 31
done!
all done!
Model size: 12.1348 GB
206
cuda:6
multirc
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:44<00:44, 44.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:57<00:00, 25.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:57<00:00, 28.63s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: multirc] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: multirc] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/super_glue/super_glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 239
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue/tree/3de24cf8022e94f4ee4b9d55a6f539891524d646/multirc?recursive=False&expand=False HTTP/1.1" 307 146
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue/tree/3de24cf8022e94f4ee4b9d55a6f539891524d646/multirc?recursive=False&expand=False HTTP/1.1" 200 365
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 239
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 239
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 239
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 239
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 239
DEBUG:filelock:Attempting to acquire lock 139722718251248 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_multirc_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 139722718251248 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_multirc_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/multirc/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 139722718251248 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_multirc_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 139722718251248 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_multirc_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Attempting to acquire lock 139752600926832 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/multirc/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 139752600926832 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/multirc/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/multirc/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 139752600926832 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/multirc/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 139752600926832 released on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/multirc/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of multirc from None to 0
INFO:lm_eval.api.task:Building contexts for multirc on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1276.75it/s]
DEBUG:lm_eval.evaluator:Task: multirc; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:03<11:24,  3.44s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:06<06:06,  1.86s/it]Running loglikelihood requests:   2%|▎         | 5/200 [00:08<05:07,  1.58s/it]Running loglikelihood requests:   4%|▎         | 7/200 [00:11<04:41,  1.46s/it]Running loglikelihood requests:   4%|▍         | 9/200 [00:13<04:27,  1.40s/it]Running loglikelihood requests:   6%|▌         | 11/200 [00:16<04:19,  1.37s/it]Running loglikelihood requests:   6%|▋         | 13/200 [00:19<04:11,  1.34s/it]Running loglikelihood requests:   8%|▊         | 15/200 [00:21<04:05,  1.33s/it]Running loglikelihood requests:   8%|▊         | 17/200 [00:24<04:00,  1.32s/it]Running loglikelihood requests:  10%|▉         | 19/200 [00:26<03:56,  1.31s/it]Running loglikelihood requests:  10%|█         | 21/200 [00:29<03:53,  1.30s/it]Running loglikelihood requests:  12%|█▏        | 23/200 [00:32<03:50,  1.30s/it]Running loglikelihood requests:  12%|█▎        | 25/200 [00:34<03:46,  1.30s/it]Running loglikelihood requests:  14%|█▎        | 27/200 [00:37<03:44,  1.29s/it]Running loglikelihood requests:  14%|█▍        | 29/200 [00:39<03:41,  1.29s/it]Running loglikelihood requests:  16%|█▌        | 31/200 [00:42<03:38,  1.29s/it]Running loglikelihood requests:  16%|█▋        | 33/200 [00:44<03:35,  1.29s/it]Running loglikelihood requests:  18%|█▊        | 35/200 [00:47<03:32,  1.29s/it]Running loglikelihood requests:  18%|█▊        | 37/200 [00:50<03:30,  1.29s/it]Running loglikelihood requests:  20%|█▉        | 39/200 [00:52<03:27,  1.29s/it]Running loglikelihood requests:  20%|██        | 41/200 [00:55<03:24,  1.29s/it]Running loglikelihood requests:  22%|██▏       | 43/200 [00:57<03:21,  1.29s/it]Running loglikelihood requests:  22%|██▎       | 45/200 [01:00<03:18,  1.28s/it]Running loglikelihood requests:  24%|██▎       | 47/200 [01:02<03:16,  1.28s/it]Running loglikelihood requests:  24%|██▍       | 49/200 [01:05<03:13,  1.28s/it]Running loglikelihood requests:  26%|██▌       | 51/200 [01:08<03:11,  1.28s/it]Running loglikelihood requests:  26%|██▋       | 53/200 [01:10<03:08,  1.28s/it]Running loglikelihood requests:  28%|██▊       | 55/200 [01:13<03:05,  1.28s/it]Running loglikelihood requests:  28%|██▊       | 57/200 [01:15<03:03,  1.28s/it]Running loglikelihood requests:  30%|██▉       | 59/200 [01:18<03:00,  1.28s/it]Running loglikelihood requests:  30%|███       | 61/200 [01:20<02:57,  1.28s/it]Running loglikelihood requests:  32%|███▏      | 63/200 [01:23<02:55,  1.28s/it]Running loglikelihood requests:  32%|███▎      | 65/200 [01:25<02:52,  1.28s/it]Running loglikelihood requests:  34%|███▎      | 67/200 [01:28<02:49,  1.28s/it]Running loglikelihood requests:  34%|███▍      | 69/200 [01:30<02:47,  1.28s/it]Running loglikelihood requests:  36%|███▌      | 71/200 [01:33<02:44,  1.27s/it]Running loglikelihood requests:  36%|███▋      | 73/200 [01:36<02:41,  1.27s/it]Running loglikelihood requests:  38%|███▊      | 75/200 [01:38<02:39,  1.27s/it]Running loglikelihood requests:  38%|███▊      | 77/200 [01:41<02:36,  1.27s/it]Running loglikelihood requests:  40%|███▉      | 79/200 [01:43<02:34,  1.27s/it]Running loglikelihood requests:  40%|████      | 81/200 [01:46<02:30,  1.27s/it]Running loglikelihood requests:  42%|████▏     | 83/200 [01:48<02:27,  1.26s/it]Running loglikelihood requests:  42%|████▎     | 85/200 [01:51<02:24,  1.26s/it]Running loglikelihood requests:  44%|████▎     | 87/200 [01:53<02:22,  1.26s/it]Running loglikelihood requests:  44%|████▍     | 89/200 [01:56<02:19,  1.26s/it]Running loglikelihood requests:  46%|████▌     | 91/200 [01:58<02:16,  1.25s/it]Running loglikelihood requests:  46%|████▋     | 93/200 [02:01<02:14,  1.25s/it]Running loglikelihood requests:  48%|████▊     | 95/200 [02:03<02:11,  1.25s/it]Running loglikelihood requests:  48%|████▊     | 97/200 [02:06<02:09,  1.25s/it]Running loglikelihood requests:  50%|████▉     | 99/200 [02:08<02:06,  1.25s/it]Running loglikelihood requests:  50%|█████     | 101/200 [02:11<02:03,  1.25s/it]Running loglikelihood requests:  52%|█████▏    | 103/200 [02:13<02:01,  1.25s/it]Running loglikelihood requests:  52%|█████▎    | 105/200 [02:16<01:58,  1.25s/it]Running loglikelihood requests:  54%|█████▎    | 107/200 [02:18<01:56,  1.25s/it]Running loglikelihood requests:  55%|█████▍    | 109/200 [02:21<01:53,  1.25s/it]Running loglikelihood requests:  56%|█████▌    | 111/200 [02:23<01:50,  1.25s/it]Running loglikelihood requests:  56%|█████▋    | 113/200 [02:26<01:48,  1.24s/it]Running loglikelihood requests:  57%|█████▊    | 115/200 [02:28<01:45,  1.24s/it]Running loglikelihood requests:  58%|█████▊    | 117/200 [02:31<01:42,  1.24s/it]Running loglikelihood requests:  60%|█████▉    | 119/200 [02:33<01:40,  1.24s/it]Running loglikelihood requests:  60%|██████    | 121/200 [02:36<01:37,  1.24s/it]Running loglikelihood requests:  62%|██████▏   | 123/200 [02:38<01:35,  1.24s/it]Running loglikelihood requests:  62%|██████▎   | 125/200 [02:41<01:32,  1.24s/it]Running loglikelihood requests:  64%|██████▎   | 127/200 [02:43<01:30,  1.24s/it]Running loglikelihood requests:  64%|██████▍   | 129/200 [02:46<01:28,  1.24s/it]Running loglikelihood requests:  66%|██████▌   | 131/200 [02:48<01:25,  1.24s/it]Running loglikelihood requests:  66%|██████▋   | 133/200 [02:50<01:23,  1.24s/it]Running loglikelihood requests:  68%|██████▊   | 135/200 [02:52<01:12,  1.12s/it]Running loglikelihood requests:  68%|██████▊   | 137/200 [02:54<01:04,  1.02s/it]Running loglikelihood requests:  70%|██████▉   | 139/200 [02:55<00:58,  1.05it/s]Running loglikelihood requests:  70%|███████   | 141/200 [02:57<00:53,  1.11it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [02:58<00:49,  1.15it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [03:00<00:46,  1.19it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [03:02<00:43,  1.22it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [03:03<00:41,  1.24it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [03:05<00:38,  1.26it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [03:06<00:36,  1.28it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [03:08<00:34,  1.29it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [03:09<00:33,  1.30it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [03:11<00:31,  1.31it/s]Running loglikelihood requests:  80%|████████  | 161/200 [03:12<00:29,  1.32it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [03:14<00:27,  1.35it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [03:15<00:25,  1.38it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [03:16<00:23,  1.40it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [03:18<00:22,  1.40it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [03:19<00:20,  1.42it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [03:20<00:18,  1.44it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [03:22<00:17,  1.46it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [03:23<00:15,  1.47it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [03:24<00:14,  1.48it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [03:26<00:12,  1.48it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [03:27<00:11,  1.50it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [03:28<00:09,  1.51it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [03:30<00:08,  1.51it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [03:31<00:07,  1.52it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [03:32<00:05,  1.52it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [03:34<00:04,  1.52it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [03:35<00:03,  1.52it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [03:36<00:01,  1.53it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [03:38<00:00,  1.53it/s]Running loglikelihood requests: 100%|██████████| 200/200 [03:38<00:00,  1.09s/it]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:7'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:7'}
full model:
{'multirc': {'alias': 'multirc', 'acc,none': 0.54, 'acc_stderr,none': 0.05009082659620331}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.6089030413152259
0.13723554564825818
0.32639298774801107
0.39554004962513223
0.17838079452737773
0.18172395498612623
0.4458149326815675
0.2599923469162762
0.44953845901781375
0.264228421159195
0.28453253935496087
0.5178234519727917
0.18549509579986273
0.3164231435223059
0.47622435667997154
0.5789910219470605
0.38414027299756903
0.6648306636715198
0.2288657593104162
0.30014630918632723
0.28954340172694804
0.7956189982678256
0.789982900191189
0.3644425339397572
0.37373995160413354
0.19965826892219962
0.3752330861186013
0.6279352732581062
0.3474029418882723
0.6089030413152259
0.13723554564825818
0.32639298774801107
0.39554004962513223
0.17838079452737773
0.18172395498612623
0.4458149326815675
0.2599923469162762
0.44953845901781375
0.264228421159195
0.28453253935496087
0.5178234519727917
0.18549509579986273
0.3164231435223059
0.47622435667997154
0.5789910219470605
0.38414027299756903
0.6648306636715198
0.2288657593104162
0.30014630918632723
0.28954340172694804
0.7956189982678256
0.789982900191189
0.3644425339397572
0.37373995160413354
0.19965826892219962
0.3752330861186013
0.6279352732581062
0.3474029418882723
0.6089030413152259
0.13723554564825818
0.32639298774801107
0.39554004962513223
0.17838079452737773
0.18172395498612623
0.4458149326815675
0.2599923469162762
0.44953845901781375
0.264228421159195
0.28453253935496087
0.5178234519727917
0.18549509579986273
0.3164231435223059
0.47622435667997154
0.5789910219470605
0.38414027299756903
0.6648306636715198
0.2288657593104162
0.30014630918632723
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[5, 3, 7, 0, 6, 2, 4, 1]
tensor([5, 3, 7, 0, 6, 2, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 7, 4, 2, 1, 3, 6, 0]
tensor([5, 7, 4, 2, 1, 3, 6, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 1, 3, 6, 0, 5, 7, 4]
tensor([2, 1, 3, 6, 0, 5, 7, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[7, 4, 1, 6, 0, 2, 3, 5]
tensor([7, 4, 1, 6, 0, 2, 3, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 6, 3, 2, 5, 1, 7, 0]
tensor([4, 6, 3, 2, 5, 1, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 0, 2, 1, 4, 7, 3, 6]
tensor([5, 0, 2, 1, 4, 7, 3, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 0, 1, 1.0, 1.0, 1.0]
tensor([0, 1, 1, 0, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([4])
tensor(4)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
done!
Normal merging for layer 2
tensor([4])
tensor(4)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 3 to 4
done!
Normal merging for layer 5
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([0])
tensor(0)
done!
Normal merging for layer 6
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
done!
Normal merging for layer 7
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
done!
Cross-layer merge completed for layers 8 to 25
done!
Normal merging for layer 26
tensor([0, 3])
tensor(0)
tensor([1, 2, 4, 5, 6, 7])
tensor(1)
done!
Cross-layer merge completed for layers 27 to 31
done!
all done!
Model size: 12.3238 GB
87
cuda:7
winogrande
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:45<00:45, 45.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:59<00:00, 26.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:59<00:00, 29.64s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/winogrande HTTP/1.1" 307 67
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/winogrande HTTP/1.1" 200 1036
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/winogrande/winogrande.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): datasets-server.hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://datasets-server.hf-mirror.com:443 "GET /parquet?dataset=winogrande HTTP/1.1" 302 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET / HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/winogrande/winogrande.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/winogrande/resolve/main/winogrande.py HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/allenai/winogrande/resolve/main/winogrande.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/winogrande/resolve/main/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/allenai/winogrande/resolve/main/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/winogrande/resolve/main/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/allenai/winogrande/resolve/main/README.md HTTP/1.1" 200 0
DEBUG:filelock:Attempting to acquire lock 139750525856336 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_winogrande_winogrande_xl_1.1.0_a826c3d3506aefe0e9e9390dcb53271070536586bab95849876b2c1743df56e2.lock
DEBUG:filelock:Lock 139750525856336 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_winogrande_winogrande_xl_1.1.0_a826c3d3506aefe0e9e9390dcb53271070536586bab95849876b2c1743df56e2.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/winogrande/winogrande_xl/1.1.0/a826c3d3506aefe0e9e9390dcb53271070536586bab95849876b2c1743df56e2/dataset_info.json
DEBUG:filelock:Attempting to release lock 139750525856336 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_winogrande_winogrande_xl_1.1.0_a826c3d3506aefe0e9e9390dcb53271070536586bab95849876b2c1743df56e2.lock
DEBUG:filelock:Lock 139750525856336 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_winogrande_winogrande_xl_1.1.0_a826c3d3506aefe0e9e9390dcb53271070536586bab95849876b2c1743df56e2.lock
DEBUG:filelock:Attempting to acquire lock 139748506884944 on /public/home/zouyifei001/.cache/huggingface/datasets/winogrande/winogrande_xl/1.1.0/a826c3d3506aefe0e9e9390dcb53271070536586bab95849876b2c1743df56e2_builder.lock
DEBUG:filelock:Lock 139748506884944 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/winogrande/winogrande_xl/1.1.0/a826c3d3506aefe0e9e9390dcb53271070536586bab95849876b2c1743df56e2_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/winogrande/winogrande_xl/1.1.0/a826c3d3506aefe0e9e9390dcb53271070536586bab95849876b2c1743df56e2/dataset_info.json
DEBUG:filelock:Attempting to release lock 139748506884944 on /public/home/zouyifei001/.cache/huggingface/datasets/winogrande/winogrande_xl/1.1.0/a826c3d3506aefe0e9e9390dcb53271070536586bab95849876b2c1743df56e2_builder.lock
DEBUG:filelock:Lock 139748506884944 released on /public/home/zouyifei001/.cache/huggingface/datasets/winogrande/winogrande_xl/1.1.0/a826c3d3506aefe0e9e9390dcb53271070536586bab95849876b2c1743df56e2_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
DEBUG:lm_eval.api.task:doc_to_text returned an int. Assuming multiple inputs.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of winogrande from None to 0
INFO:lm_eval.api.task:Building contexts for winogrande on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 141891.20it/s]
DEBUG:lm_eval.evaluator:Task: winogrande; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:01<03:44,  1.13s/it]Running loglikelihood requests:   1%|          | 2/200 [00:01<02:38,  1.25it/s]Running loglikelihood requests:   2%|▏         | 3/200 [00:02<02:18,  1.43it/s]Running loglikelihood requests:   2%|▏         | 4/200 [00:02<02:03,  1.58it/s]Running loglikelihood requests:   2%|▎         | 5/200 [00:03<01:55,  1.69it/s]Running loglikelihood requests:   3%|▎         | 6/200 [00:03<01:50,  1.76it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:04<01:46,  1.81it/s]Running loglikelihood requests:   4%|▍         | 8/200 [00:04<01:43,  1.85it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:05<01:41,  1.88it/s]Running loglikelihood requests:   5%|▌         | 10/200 [00:05<01:39,  1.90it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:06<01:38,  1.92it/s]Running loglikelihood requests:   6%|▌         | 12/200 [00:06<01:37,  1.93it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:07<01:36,  1.94it/s]Running loglikelihood requests:   7%|▋         | 14/200 [00:07<01:35,  1.95it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:08<01:34,  1.96it/s]Running loglikelihood requests:   8%|▊         | 16/200 [00:08<01:33,  1.96it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:09<01:33,  1.96it/s]Running loglikelihood requests:   9%|▉         | 18/200 [00:09<01:32,  1.96it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:10<01:31,  1.97it/s]Running loglikelihood requests:  10%|█         | 20/200 [00:10<01:31,  1.97it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:11<01:30,  1.97it/s]Running loglikelihood requests:  11%|█         | 22/200 [00:12<01:30,  1.98it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:12<01:29,  1.98it/s]Running loglikelihood requests:  12%|█▏        | 24/200 [00:13<01:28,  1.98it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:13<01:28,  1.98it/s]Running loglikelihood requests:  13%|█▎        | 26/200 [00:13<01:26,  2.01it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:14<01:24,  2.04it/s]Running loglikelihood requests:  14%|█▍        | 28/200 [00:14<01:23,  2.06it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:15<01:22,  2.07it/s]Running loglikelihood requests:  15%|█▌        | 30/200 [00:15<01:21,  2.09it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:16<01:20,  2.10it/s]Running loglikelihood requests:  16%|█▌        | 32/200 [00:16<01:19,  2.11it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:17<01:19,  2.11it/s]Running loglikelihood requests:  17%|█▋        | 34/200 [00:17<01:18,  2.11it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:18<01:17,  2.12it/s]Running loglikelihood requests:  18%|█▊        | 36/200 [00:18<01:17,  2.12it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:19<01:16,  2.13it/s]Running loglikelihood requests:  19%|█▉        | 38/200 [00:19<01:18,  2.07it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:20<01:18,  2.06it/s]Running loglikelihood requests:  20%|██        | 40/200 [00:20<01:17,  2.06it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:21<01:17,  2.06it/s]Running loglikelihood requests:  21%|██        | 42/200 [00:21<01:16,  2.07it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:22<01:15,  2.07it/s]Running loglikelihood requests:  22%|██▏       | 44/200 [00:22<01:15,  2.07it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:23<01:14,  2.07it/s]Running loglikelihood requests:  23%|██▎       | 46/200 [00:23<01:14,  2.07it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:24<01:14,  2.07it/s]Running loglikelihood requests:  24%|██▍       | 48/200 [00:24<01:13,  2.07it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:25<01:13,  2.07it/s]Running loglikelihood requests:  25%|██▌       | 50/200 [00:25<01:12,  2.07it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:25<01:12,  2.07it/s]Running loglikelihood requests:  26%|██▌       | 52/200 [00:26<01:11,  2.07it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:26<01:10,  2.07it/s]Running loglikelihood requests:  27%|██▋       | 54/200 [00:27<01:10,  2.07it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:27<01:09,  2.07it/s]Running loglikelihood requests:  28%|██▊       | 56/200 [00:28<01:09,  2.07it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:28<01:08,  2.08it/s]Running loglikelihood requests:  29%|██▉       | 58/200 [00:29<01:08,  2.08it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:29<01:07,  2.08it/s]Running loglikelihood requests:  30%|███       | 60/200 [00:30<01:07,  2.09it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:30<01:06,  2.09it/s]Running loglikelihood requests:  31%|███       | 62/200 [00:31<01:06,  2.09it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:31<01:05,  2.09it/s]Running loglikelihood requests:  32%|███▏      | 64/200 [00:32<01:05,  2.09it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:32<01:04,  2.09it/s]Running loglikelihood requests:  33%|███▎      | 66/200 [00:33<01:04,  2.09it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:33<01:03,  2.09it/s]Running loglikelihood requests:  34%|███▍      | 68/200 [00:34<01:03,  2.09it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:34<01:02,  2.09it/s]Running loglikelihood requests:  35%|███▌      | 70/200 [00:35<01:02,  2.09it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:35<01:01,  2.09it/s]Running loglikelihood requests:  36%|███▌      | 72/200 [00:36<01:01,  2.09it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:36<01:00,  2.09it/s]Running loglikelihood requests:  37%|███▋      | 74/200 [00:37<01:00,  2.10it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:37<00:59,  2.10it/s]Running loglikelihood requests:  38%|███▊      | 76/200 [00:37<00:58,  2.10it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:38<00:58,  2.11it/s]Running loglikelihood requests:  39%|███▉      | 78/200 [00:38<00:57,  2.11it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:39<00:57,  2.11it/s]Running loglikelihood requests:  40%|████      | 80/200 [00:39<00:56,  2.11it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:40<00:56,  2.11it/s]Running loglikelihood requests:  41%|████      | 82/200 [00:40<00:55,  2.11it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:41<00:55,  2.11it/s]Running loglikelihood requests:  42%|████▏     | 84/200 [00:41<00:54,  2.12it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:42<00:54,  2.12it/s]Running loglikelihood requests:  43%|████▎     | 86/200 [00:42<00:53,  2.13it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:43<00:53,  2.13it/s]Running loglikelihood requests:  44%|████▍     | 88/200 [00:43<00:52,  2.13it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:44<00:52,  2.13it/s]Running loglikelihood requests:  45%|████▌     | 90/200 [00:44<00:51,  2.13it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:45<00:51,  2.13it/s]Running loglikelihood requests:  46%|████▌     | 92/200 [00:45<00:50,  2.12it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:45<00:50,  2.12it/s]Running loglikelihood requests:  47%|████▋     | 94/200 [00:46<00:49,  2.13it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:46<00:49,  2.13it/s]Running loglikelihood requests:  48%|████▊     | 96/200 [00:47<00:48,  2.13it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:47<00:48,  2.14it/s]Running loglikelihood requests:  49%|████▉     | 98/200 [00:48<00:47,  2.13it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:48<00:47,  2.13it/s]Running loglikelihood requests:  50%|█████     | 100/200 [00:49<00:46,  2.13it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:49<00:46,  2.14it/s]Running loglikelihood requests:  51%|█████     | 102/200 [00:50<00:45,  2.14it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:50<00:45,  2.15it/s]Running loglikelihood requests:  52%|█████▏    | 104/200 [00:51<00:44,  2.15it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:51<00:44,  2.16it/s]Running loglikelihood requests:  53%|█████▎    | 106/200 [00:52<00:43,  2.16it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:52<00:43,  2.16it/s]Running loglikelihood requests:  54%|█████▍    | 108/200 [00:52<00:42,  2.16it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:53<00:42,  2.16it/s]Running loglikelihood requests:  55%|█████▌    | 110/200 [00:53<00:41,  2.16it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:54<00:41,  2.16it/s]Running loglikelihood requests:  56%|█████▌    | 112/200 [00:54<00:40,  2.15it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:55<00:40,  2.16it/s]Running loglikelihood requests:  57%|█████▋    | 114/200 [00:55<00:39,  2.16it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:56<00:39,  2.17it/s]Running loglikelihood requests:  58%|█████▊    | 116/200 [00:56<00:38,  2.17it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:57<00:38,  2.17it/s]Running loglikelihood requests:  59%|█████▉    | 118/200 [00:57<00:37,  2.17it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:58<00:37,  2.18it/s]Running loglikelihood requests:  60%|██████    | 120/200 [00:58<00:36,  2.18it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:58<00:36,  2.18it/s]Running loglikelihood requests:  61%|██████    | 122/200 [00:59<00:35,  2.17it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:59<00:35,  2.17it/s]Running loglikelihood requests:  62%|██████▏   | 124/200 [01:00<00:35,  2.17it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [01:00<00:34,  2.17it/s]Running loglikelihood requests:  63%|██████▎   | 126/200 [01:01<00:34,  2.17it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [01:01<00:33,  2.17it/s]Running loglikelihood requests:  64%|██████▍   | 128/200 [01:02<00:33,  2.18it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [01:02<00:32,  2.18it/s]Running loglikelihood requests:  65%|██████▌   | 130/200 [01:03<00:32,  2.17it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [01:03<00:31,  2.18it/s]Running loglikelihood requests:  66%|██████▌   | 132/200 [01:03<00:31,  2.19it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [01:04<00:30,  2.20it/s]Running loglikelihood requests:  67%|██████▋   | 134/200 [01:04<00:30,  2.20it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [01:05<00:29,  2.20it/s]Running loglikelihood requests:  68%|██████▊   | 136/200 [01:05<00:29,  2.20it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [01:06<00:28,  2.20it/s]Running loglikelihood requests:  69%|██████▉   | 138/200 [01:06<00:28,  2.20it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [01:07<00:27,  2.20it/s]Running loglikelihood requests:  70%|███████   | 140/200 [01:07<00:27,  2.20it/s]Running loglikelihood requests:  70%|███████   | 141/200 [01:08<00:26,  2.20it/s]Running loglikelihood requests:  71%|███████   | 142/200 [01:08<00:26,  2.20it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [01:08<00:25,  2.20it/s]Running loglikelihood requests:  72%|███████▏  | 144/200 [01:09<00:25,  2.20it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [01:09<00:24,  2.21it/s]Running loglikelihood requests:  73%|███████▎  | 146/200 [01:10<00:24,  2.20it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [01:10<00:24,  2.20it/s]Running loglikelihood requests:  74%|███████▍  | 148/200 [01:11<00:23,  2.21it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [01:11<00:22,  2.22it/s]Running loglikelihood requests:  75%|███████▌  | 150/200 [01:12<00:22,  2.22it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [01:12<00:22,  2.23it/s]Running loglikelihood requests:  76%|███████▌  | 152/200 [01:13<00:21,  2.23it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [01:13<00:21,  2.23it/s]Running loglikelihood requests:  77%|███████▋  | 154/200 [01:13<00:20,  2.23it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [01:14<00:20,  2.23it/s]Running loglikelihood requests:  78%|███████▊  | 156/200 [01:14<00:19,  2.23it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [01:15<00:19,  2.23it/s]Running loglikelihood requests:  79%|███████▉  | 158/200 [01:15<00:18,  2.23it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [01:16<00:18,  2.23it/s]Running loglikelihood requests:  80%|████████  | 160/200 [01:16<00:17,  2.23it/s]Running loglikelihood requests:  80%|████████  | 161/200 [01:17<00:17,  2.22it/s]Running loglikelihood requests:  81%|████████  | 162/200 [01:17<00:17,  2.22it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [01:17<00:16,  2.22it/s]Running loglikelihood requests:  82%|████████▏ | 164/200 [01:18<00:16,  2.23it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [01:18<00:15,  2.24it/s]Running loglikelihood requests:  83%|████████▎ | 166/200 [01:19<00:15,  2.25it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [01:19<00:14,  2.25it/s]Running loglikelihood requests:  84%|████████▍ | 168/200 [01:20<00:14,  2.24it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [01:20<00:13,  2.24it/s]Running loglikelihood requests:  85%|████████▌ | 170/200 [01:21<00:13,  2.24it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [01:21<00:12,  2.25it/s]Running loglikelihood requests:  86%|████████▌ | 172/200 [01:21<00:12,  2.26it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [01:22<00:11,  2.27it/s]Running loglikelihood requests:  87%|████████▋ | 174/200 [01:22<00:11,  2.27it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [01:23<00:11,  2.27it/s]Running loglikelihood requests:  88%|████████▊ | 176/200 [01:23<00:10,  2.27it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [01:24<00:10,  2.27it/s]Running loglikelihood requests:  89%|████████▉ | 178/200 [01:24<00:09,  2.27it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [01:25<00:09,  2.28it/s]Running loglikelihood requests:  90%|█████████ | 180/200 [01:25<00:08,  2.29it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [01:25<00:08,  2.30it/s]Running loglikelihood requests:  91%|█████████ | 182/200 [01:26<00:07,  2.31it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [01:26<00:07,  2.31it/s]Running loglikelihood requests:  92%|█████████▏| 184/200 [01:27<00:06,  2.31it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [01:27<00:06,  2.31it/s]Running loglikelihood requests:  93%|█████████▎| 186/200 [01:28<00:06,  2.31it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [01:28<00:05,  2.31it/s]Running loglikelihood requests:  94%|█████████▍| 188/200 [01:28<00:05,  2.31it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [01:29<00:04,  2.31it/s]Running loglikelihood requests:  95%|█████████▌| 190/200 [01:29<00:04,  2.33it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [01:30<00:03,  2.35it/s]Running loglikelihood requests:  96%|█████████▌| 192/200 [01:30<00:03,  2.35it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [01:31<00:02,  2.36it/s]Running loglikelihood requests:  97%|█████████▋| 194/200 [01:31<00:02,  2.36it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:31<00:02,  2.36it/s]Running loglikelihood requests:  98%|█████████▊| 196/200 [01:32<00:01,  2.36it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:32<00:01,  2.36it/s]Running loglikelihood requests:  99%|█████████▉| 198/200 [01:33<00:00,  2.36it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:33<00:00,  2.36it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:34<00:00,  2.36it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:34<00:00,  2.13it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:0'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}
full model:
{'winogrande': {'alias': 'winogrande', 'acc,none': 0.69, 'acc_stderr,none': 0.046482319871173176}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9565474555896152
0.9256436871263655
0.919777800952949
0.8502516827829548
0.9788217808920475
0.7842184683361061
0.5847175538207384
0.7741211354638314
0.8734705119073022
0.9731317123565076
0.9046875380381674
0.8858535931048256
0.9314298098713261
0.8442403312485581
0.7166029053748131
0.7061450250233585
0.7563059483803782
0.6877563559653158
0.8738989590810852
0.784285727893607
0.8409178900131131
0.8425380927376759
0.6782655591765769
0.7228968829640015
0.8418686487797186
0.9141168065903919
0.8562481461255738
0.6139553840231665
0.934088538459943
Total groups 66 exceeded the threshold, stopping comparison.
The group tensor is
[6, 2, 4, 3, 5, 1, 7, 0]
tensor([6, 2, 4, 3, 5, 1, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 2, 3, 1, 5, 4, 7, 0]
tensor([6, 2, 3, 1, 5, 4, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 4, 1, 0, 3, 0, 1, 2]
tensor([5, 4, 1, 0, 3, 0, 1, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 2, 3, 1, 4, 5, 1, 0]
tensor([0, 2, 3, 1, 4, 5, 1, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[5, 1, 2, 3, 4, 0, 1, 0]
tensor([5, 1, 2, 3, 4, 0, 1, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 2, 1, 1, 2, 3, 3, 0]
tensor([0, 2, 1, 1, 2, 3, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1, 1.0, 1.0, 1.0, 1.0, 0]
tensor([0, 1, 1, 1, 1, 1, 1, 0], dtype=torch.int32)
[0, 1]
The group tensor is
[0, 1, 1.0, 0, 1.0, 1.0, 1.0, 1]
tensor([0, 1, 1, 0, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 2 to 7
done!
Normal merging for layer 8
tensor([3, 5])
tensor(3)
tensor([2, 6])
tensor(2)
tensor([7])
tensor(7)
tensor([4])
tensor(4)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 9 to 13
done!
Normal merging for layer 14
tensor([0, 7])
tensor(0)
tensor([3, 6])
tensor(3)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
tensor([5])
tensor(5)
done!
Normal merging for layer 15
tensor([5, 7])
tensor(5)
tensor([1, 6])
tensor(1)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
done!
Normal merging for layer 16
tensor([0, 7])
tensor(0)
tensor([2, 3])
tensor(2)
tensor([1, 4])
tensor(1)
tensor([5, 6])
tensor(5)
done!
Cross-layer merge completed for layers 17 to 23
done!
Normal merging for layer 24
tensor([0, 7])
tensor(0)
tensor([1, 2, 3, 4, 5, 6])
tensor(1)
done!
Normal merging for layer 25
tensor([0, 3])
tensor(0)
tensor([1, 2, 4, 5, 6, 7])
tensor(1)
done!
Cross-layer merge completed for layers 26 to 31
done!
all done!
Model size: 11.8828 GB
44
cuda:0
mastermind_35_easy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:43<00:43, 43.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:57<00:00, 25.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:57<00:00, 28.55s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_35_mcq_random HTTP/1.1" 200 780
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/flair/mastermind_35_mcq_random/flair/mastermind_35_mcq_random.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_35_mcq_random HTTP/1.1" 200 780
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/flair/mastermind_35_mcq_random/resolve/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/flair/mastermind_35_mcq_random/resolve/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:filelock:Attempting to acquire lock 139750924133696 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_35_mcq_random_default_0.0.0_15dd5105771e9c8d2d3ea71c8d44fffda374a7a1.lock
DEBUG:filelock:Lock 139750924133696 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_35_mcq_random_default_0.0.0_15dd5105771e9c8d2d3ea71c8d44fffda374a7a1.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1/dataset_info.json
DEBUG:filelock:Attempting to release lock 139750924133696 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_35_mcq_random_default_0.0.0_15dd5105771e9c8d2d3ea71c8d44fffda374a7a1.lock
DEBUG:filelock:Lock 139750924133696 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_35_mcq_random_default_0.0.0_15dd5105771e9c8d2d3ea71c8d44fffda374a7a1.lock
DEBUG:filelock:Attempting to acquire lock 139750523785952 on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1_builder.lock
DEBUG:filelock:Lock 139750523785952 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1/dataset_info.json
DEBUG:filelock:Attempting to release lock 139750523785952 on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1_builder.lock
DEBUG:filelock:Lock 139750523785952 released on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mastermind_35_easy from None to 0
INFO:lm_eval.api.task:Building contexts for mastermind_35_easy on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1492.79it/s]
DEBUG:lm_eval.evaluator:Task: mastermind_35_easy; number of requests on this rank: 400
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/400 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/400 [00:01<11:45,  1.77s/it]Running loglikelihood requests:   0%|          | 2/400 [00:02<09:22,  1.41s/it]Running loglikelihood requests:   1%|          | 3/400 [00:04<08:36,  1.30s/it]Running loglikelihood requests:   1%|          | 4/400 [00:05<08:12,  1.24s/it]Running loglikelihood requests:   1%|▏         | 5/400 [00:06<07:58,  1.21s/it]Running loglikelihood requests:   2%|▏         | 6/400 [00:07<07:48,  1.19s/it]Running loglikelihood requests:   2%|▏         | 7/400 [00:08<07:43,  1.18s/it]Running loglikelihood requests:   2%|▏         | 8/400 [00:09<07:38,  1.17s/it]Running loglikelihood requests:   2%|▏         | 9/400 [00:11<07:34,  1.16s/it]Running loglikelihood requests:   2%|▎         | 10/400 [00:12<07:30,  1.16s/it]Running loglikelihood requests:   3%|▎         | 11/400 [00:13<07:28,  1.15s/it]Running loglikelihood requests:   3%|▎         | 12/400 [00:14<07:27,  1.15s/it]Running loglikelihood requests:   3%|▎         | 13/400 [00:15<07:24,  1.15s/it]Running loglikelihood requests:   4%|▎         | 14/400 [00:16<07:22,  1.15s/it]Running loglikelihood requests:   4%|▍         | 15/400 [00:17<07:20,  1.14s/it]Running loglikelihood requests:   4%|▍         | 16/400 [00:19<07:18,  1.14s/it]Running loglikelihood requests:   4%|▍         | 17/400 [00:20<07:16,  1.14s/it]Running loglikelihood requests:   4%|▍         | 18/400 [00:21<07:15,  1.14s/it]Running loglikelihood requests:   5%|▍         | 19/400 [00:22<07:13,  1.14s/it]Running loglikelihood requests:   5%|▌         | 20/400 [00:23<07:12,  1.14s/it]Running loglikelihood requests:   5%|▌         | 21/400 [00:24<07:11,  1.14s/it]Running loglikelihood requests:   6%|▌         | 23/400 [00:25<05:29,  1.14it/s]Running loglikelihood requests:   6%|▌         | 24/400 [00:26<05:52,  1.07it/s]Running loglikelihood requests:   6%|▋         | 25/400 [00:28<06:10,  1.01it/s]Running loglikelihood requests:   6%|▋         | 26/400 [00:29<06:23,  1.03s/it]Running loglikelihood requests:   7%|▋         | 27/400 [00:30<06:32,  1.05s/it]Running loglikelihood requests:   7%|▋         | 28/400 [00:31<06:39,  1.07s/it]Running loglikelihood requests:   7%|▋         | 29/400 [00:32<06:43,  1.09s/it]Running loglikelihood requests:   8%|▊         | 30/400 [00:33<06:45,  1.10s/it]Running loglikelihood requests:   8%|▊         | 31/400 [00:34<06:47,  1.10s/it]Running loglikelihood requests:   8%|▊         | 32/400 [00:35<06:50,  1.12s/it]Running loglikelihood requests:   8%|▊         | 33/400 [00:37<06:50,  1.12s/it]Running loglikelihood requests:   8%|▊         | 34/400 [00:38<06:49,  1.12s/it]Running loglikelihood requests:   9%|▉         | 35/400 [00:39<06:48,  1.12s/it]Running loglikelihood requests:   9%|▉         | 36/400 [00:40<06:47,  1.12s/it]Running loglikelihood requests:   9%|▉         | 37/400 [00:41<06:46,  1.12s/it]Running loglikelihood requests:  10%|▉         | 38/400 [00:42<06:45,  1.12s/it]Running loglikelihood requests:  10%|▉         | 39/400 [00:43<06:44,  1.12s/it]Running loglikelihood requests:  10%|█         | 40/400 [00:44<06:43,  1.12s/it]Running loglikelihood requests:  10%|█         | 41/400 [00:46<06:42,  1.12s/it]Running loglikelihood requests:  10%|█         | 42/400 [00:47<06:41,  1.12s/it]Running loglikelihood requests:  11%|█         | 43/400 [00:48<06:39,  1.12s/it]Running loglikelihood requests:  11%|█         | 44/400 [00:49<06:38,  1.12s/it]Running loglikelihood requests:  11%|█▏        | 45/400 [00:50<06:37,  1.12s/it]Running loglikelihood requests:  12%|█▏        | 46/400 [00:51<06:36,  1.12s/it]Running loglikelihood requests:  12%|█▏        | 47/400 [00:52<06:35,  1.12s/it]Running loglikelihood requests:  12%|█▏        | 48/400 [00:53<06:33,  1.12s/it]Running loglikelihood requests:  12%|█▏        | 49/400 [00:55<06:32,  1.12s/it]Running loglikelihood requests:  12%|█▎        | 50/400 [00:56<06:31,  1.12s/it]Running loglikelihood requests:  13%|█▎        | 51/400 [00:57<06:30,  1.12s/it]Running loglikelihood requests:  13%|█▎        | 52/400 [00:58<06:29,  1.12s/it]Running loglikelihood requests:  13%|█▎        | 53/400 [00:59<06:28,  1.12s/it]Running loglikelihood requests:  14%|█▎        | 54/400 [01:00<06:27,  1.12s/it]Running loglikelihood requests:  14%|█▍        | 55/400 [01:01<06:25,  1.12s/it]Running loglikelihood requests:  14%|█▍        | 56/400 [01:02<06:25,  1.12s/it]Running loglikelihood requests:  14%|█▍        | 57/400 [01:03<06:24,  1.12s/it]Running loglikelihood requests:  14%|█▍        | 58/400 [01:05<06:23,  1.12s/it]Running loglikelihood requests:  15%|█▍        | 59/400 [01:06<06:22,  1.12s/it]Running loglikelihood requests:  15%|█▌        | 60/400 [01:07<06:21,  1.12s/it]Running loglikelihood requests:  15%|█▌        | 61/400 [01:08<06:19,  1.12s/it]Running loglikelihood requests:  16%|█▌        | 62/400 [01:09<06:18,  1.12s/it]Running loglikelihood requests:  16%|█▌        | 63/400 [01:10<06:17,  1.12s/it]Running loglikelihood requests:  16%|█▌        | 64/400 [01:11<06:16,  1.12s/it]Running loglikelihood requests:  16%|█▋        | 65/400 [01:12<06:14,  1.12s/it]Running loglikelihood requests:  16%|█▋        | 66/400 [01:14<06:13,  1.12s/it]Running loglikelihood requests:  17%|█▋        | 67/400 [01:15<06:12,  1.12s/it]Running loglikelihood requests:  17%|█▋        | 68/400 [01:16<06:11,  1.12s/it]Running loglikelihood requests:  17%|█▋        | 69/400 [01:17<06:10,  1.12s/it]Running loglikelihood requests:  18%|█▊        | 70/400 [01:18<06:09,  1.12s/it]Running loglikelihood requests:  18%|█▊        | 71/400 [01:19<06:08,  1.12s/it]Running loglikelihood requests:  18%|█▊        | 72/400 [01:20<06:07,  1.12s/it]Running loglikelihood requests:  18%|█▊        | 73/400 [01:21<06:05,  1.12s/it]Running loglikelihood requests:  18%|█▊        | 74/400 [01:22<06:04,  1.12s/it]Running loglikelihood requests:  19%|█▉        | 75/400 [01:24<06:03,  1.12s/it]Running loglikelihood requests:  19%|█▉        | 76/400 [01:25<06:01,  1.12s/it]Running loglikelihood requests:  19%|█▉        | 77/400 [01:26<06:00,  1.12s/it]Running loglikelihood requests:  20%|█▉        | 78/400 [01:27<05:59,  1.12s/it]Running loglikelihood requests:  20%|█▉        | 79/400 [01:28<05:58,  1.12s/it]Running loglikelihood requests:  20%|██        | 80/400 [01:29<05:57,  1.12s/it]Running loglikelihood requests:  20%|██        | 81/400 [01:30<05:55,  1.12s/it]Running loglikelihood requests:  20%|██        | 82/400 [01:31<05:54,  1.12s/it]Running loglikelihood requests:  21%|██        | 83/400 [01:33<05:53,  1.11s/it]Running loglikelihood requests:  21%|██        | 84/400 [01:34<05:52,  1.11s/it]Running loglikelihood requests:  21%|██▏       | 85/400 [01:35<05:50,  1.11s/it]Running loglikelihood requests:  22%|██▏       | 86/400 [01:36<05:49,  1.11s/it]Running loglikelihood requests:  22%|██▏       | 87/400 [01:37<05:48,  1.11s/it]Running loglikelihood requests:  22%|██▏       | 88/400 [01:38<05:47,  1.11s/it]Running loglikelihood requests:  22%|██▏       | 89/400 [01:39<05:46,  1.11s/it]Running loglikelihood requests:  22%|██▎       | 90/400 [01:40<05:45,  1.11s/it]Running loglikelihood requests:  23%|██▎       | 91/400 [01:41<05:44,  1.11s/it]Running loglikelihood requests:  23%|██▎       | 92/400 [01:43<05:43,  1.11s/it]Running loglikelihood requests:  23%|██▎       | 93/400 [01:44<05:42,  1.11s/it]Running loglikelihood requests:  24%|██▎       | 94/400 [01:45<05:41,  1.11s/it]Running loglikelihood requests:  24%|██▍       | 95/400 [01:46<05:40,  1.11s/it]Running loglikelihood requests:  24%|██▍       | 96/400 [01:47<05:39,  1.12s/it]Running loglikelihood requests:  24%|██▍       | 97/400 [01:48<05:38,  1.12s/it]Running loglikelihood requests:  24%|██▍       | 98/400 [01:49<05:37,  1.12s/it]Running loglikelihood requests:  25%|██▍       | 99/400 [01:50<05:35,  1.12s/it]Running loglikelihood requests:  25%|██▌       | 100/400 [01:51<05:34,  1.12s/it]Running loglikelihood requests:  25%|██▌       | 101/400 [01:53<05:33,  1.11s/it]Running loglikelihood requests:  26%|██▌       | 102/400 [01:54<05:31,  1.11s/it]Running loglikelihood requests:  26%|██▌       | 103/400 [01:55<05:30,  1.11s/it]Running loglikelihood requests:  26%|██▌       | 104/400 [01:56<05:29,  1.11s/it]Running loglikelihood requests:  26%|██▋       | 105/400 [01:57<05:27,  1.11s/it]Running loglikelihood requests:  26%|██▋       | 106/400 [01:58<05:26,  1.11s/it]Running loglikelihood requests:  27%|██▋       | 107/400 [01:59<05:33,  1.14s/it]Running loglikelihood requests:  27%|██▋       | 108/400 [02:01<05:40,  1.17s/it]Running loglikelihood requests:  27%|██▋       | 109/400 [02:02<05:45,  1.19s/it]Running loglikelihood requests:  28%|██▊       | 110/400 [02:03<05:48,  1.20s/it]Running loglikelihood requests:  28%|██▊       | 112/400 [02:04<04:29,  1.07it/s]Running loglikelihood requests:  28%|██▊       | 113/400 [02:06<04:50,  1.01s/it]Running loglikelihood requests:  28%|██▊       | 114/400 [02:07<05:07,  1.07s/it]Running loglikelihood requests:  29%|██▉       | 115/400 [02:08<05:09,  1.08s/it]Running loglikelihood requests:  29%|██▉       | 116/400 [02:09<05:10,  1.09s/it]Running loglikelihood requests:  29%|██▉       | 117/400 [02:10<05:11,  1.10s/it]Running loglikelihood requests:  30%|██▉       | 118/400 [02:11<05:11,  1.10s/it]Running loglikelihood requests:  30%|██▉       | 119/400 [02:12<05:10,  1.11s/it]Running loglikelihood requests:  30%|███       | 120/400 [02:13<05:10,  1.11s/it]Running loglikelihood requests:  30%|███       | 121/400 [02:15<05:09,  1.11s/it]Running loglikelihood requests:  30%|███       | 122/400 [02:16<05:08,  1.11s/it]Running loglikelihood requests:  31%|███       | 123/400 [02:17<05:07,  1.11s/it]Running loglikelihood requests:  31%|███       | 124/400 [02:18<05:06,  1.11s/it]Running loglikelihood requests:  31%|███▏      | 125/400 [02:19<05:06,  1.11s/it]Running loglikelihood requests:  32%|███▏      | 126/400 [02:20<05:05,  1.11s/it]Running loglikelihood requests:  32%|███▏      | 127/400 [02:21<05:03,  1.11s/it]Running loglikelihood requests:  32%|███▏      | 128/400 [02:22<05:02,  1.11s/it]Running loglikelihood requests:  32%|███▏      | 129/400 [02:23<05:00,  1.11s/it]Running loglikelihood requests:  32%|███▎      | 130/400 [02:25<04:59,  1.11s/it]Running loglikelihood requests:  33%|███▎      | 131/400 [02:26<04:59,  1.11s/it]Running loglikelihood requests:  33%|███▎      | 132/400 [02:27<04:57,  1.11s/it]Running loglikelihood requests:  33%|███▎      | 133/400 [02:28<04:57,  1.11s/it]Running loglikelihood requests:  34%|███▎      | 134/400 [02:29<04:55,  1.11s/it]Running loglikelihood requests:  34%|███▍      | 135/400 [02:30<04:54,  1.11s/it]Running loglikelihood requests:  34%|███▍      | 136/400 [02:31<04:53,  1.11s/it]Running loglikelihood requests:  34%|███▍      | 137/400 [02:32<04:52,  1.11s/it]Running loglikelihood requests:  34%|███▍      | 138/400 [02:33<04:50,  1.11s/it]Running loglikelihood requests:  35%|███▍      | 139/400 [02:35<04:48,  1.11s/it]Running loglikelihood requests:  35%|███▌      | 140/400 [02:36<04:47,  1.11s/it]Running loglikelihood requests:  35%|███▌      | 141/400 [02:37<04:46,  1.11s/it]Running loglikelihood requests:  36%|███▌      | 142/400 [02:38<04:45,  1.11s/it]Running loglikelihood requests:  36%|███▌      | 143/400 [02:39<04:43,  1.10s/it]Running loglikelihood requests:  36%|███▌      | 144/400 [02:40<04:42,  1.10s/it]Running loglikelihood requests:  36%|███▋      | 145/400 [02:41<04:41,  1.10s/it]Running loglikelihood requests:  36%|███▋      | 146/400 [02:42<04:39,  1.10s/it]Running loglikelihood requests:  37%|███▋      | 147/400 [02:43<04:38,  1.10s/it]Running loglikelihood requests:  37%|███▋      | 148/400 [02:45<04:37,  1.10s/it]Running loglikelihood requests:  37%|███▋      | 149/400 [02:46<04:36,  1.10s/it]Running loglikelihood requests:  38%|███▊      | 150/400 [02:47<04:35,  1.10s/it]Running loglikelihood requests:  38%|███▊      | 151/400 [02:48<04:34,  1.10s/it]Running loglikelihood requests:  38%|███▊      | 152/400 [02:49<04:33,  1.10s/it]Running loglikelihood requests:  38%|███▊      | 153/400 [02:50<04:31,  1.10s/it]Running loglikelihood requests:  38%|███▊      | 154/400 [02:51<04:30,  1.10s/it]Running loglikelihood requests:  39%|███▉      | 155/400 [02:52<04:29,  1.10s/it]Running loglikelihood requests:  39%|███▉      | 156/400 [02:53<04:28,  1.10s/it]Running loglikelihood requests:  39%|███▉      | 157/400 [02:54<04:26,  1.10s/it]Running loglikelihood requests:  40%|███▉      | 158/400 [02:56<04:25,  1.10s/it]Running loglikelihood requests:  40%|███▉      | 159/400 [02:57<04:24,  1.10s/it]Running loglikelihood requests:  40%|████      | 160/400 [02:58<04:22,  1.09s/it]Running loglikelihood requests:  40%|████      | 161/400 [02:59<04:21,  1.10s/it]Running loglikelihood requests:  40%|████      | 162/400 [03:00<04:20,  1.09s/it]Running loglikelihood requests:  41%|████      | 163/400 [03:01<04:18,  1.09s/it]Running loglikelihood requests:  41%|████      | 164/400 [03:02<04:17,  1.09s/it]Running loglikelihood requests:  41%|████▏     | 165/400 [03:03<04:16,  1.09s/it]Running loglikelihood requests:  42%|████▏     | 166/400 [03:04<04:15,  1.09s/it]Running loglikelihood requests:  42%|████▏     | 167/400 [03:05<04:14,  1.09s/it]Running loglikelihood requests:  42%|████▏     | 168/400 [03:06<04:13,  1.09s/it]Running loglikelihood requests:  42%|████▏     | 169/400 [03:08<04:12,  1.09s/it]Running loglikelihood requests:  42%|████▎     | 170/400 [03:09<04:10,  1.09s/it]Running loglikelihood requests:  43%|████▎     | 171/400 [03:10<04:09,  1.09s/it]Running loglikelihood requests:  43%|████▎     | 172/400 [03:11<04:08,  1.09s/it]Running loglikelihood requests:  43%|████▎     | 173/400 [03:12<04:07,  1.09s/it]Running loglikelihood requests:  44%|████▎     | 174/400 [03:13<04:05,  1.09s/it]Running loglikelihood requests:  44%|████▍     | 175/400 [03:14<04:04,  1.09s/it]Running loglikelihood requests:  44%|████▍     | 177/400 [03:15<03:06,  1.20it/s]Running loglikelihood requests:  44%|████▍     | 178/400 [03:16<03:19,  1.11it/s]Running loglikelihood requests:  45%|████▍     | 179/400 [03:17<03:29,  1.06it/s]Running loglikelihood requests:  45%|████▌     | 180/400 [03:18<03:36,  1.02it/s]Running loglikelihood requests:  45%|████▌     | 181/400 [03:19<03:41,  1.01s/it]Running loglikelihood requests:  46%|████▌     | 182/400 [03:21<03:45,  1.03s/it]Running loglikelihood requests:  46%|████▌     | 183/400 [03:22<03:47,  1.05s/it]Running loglikelihood requests:  46%|████▌     | 184/400 [03:23<03:49,  1.06s/it]Running loglikelihood requests:  46%|████▋     | 185/400 [03:24<03:49,  1.07s/it]Running loglikelihood requests:  46%|████▋     | 186/400 [03:25<03:49,  1.07s/it]Running loglikelihood requests:  47%|████▋     | 187/400 [03:26<03:49,  1.08s/it]Running loglikelihood requests:  47%|████▋     | 188/400 [03:27<03:48,  1.08s/it]Running loglikelihood requests:  47%|████▋     | 189/400 [03:28<03:48,  1.08s/it]Running loglikelihood requests:  48%|████▊     | 190/400 [03:29<03:47,  1.08s/it]Running loglikelihood requests:  48%|████▊     | 191/400 [03:30<03:46,  1.08s/it]Running loglikelihood requests:  48%|████▊     | 192/400 [03:31<03:45,  1.08s/it]Running loglikelihood requests:  48%|████▊     | 193/400 [03:32<03:44,  1.08s/it]Running loglikelihood requests:  48%|████▊     | 194/400 [03:34<03:43,  1.08s/it]Running loglikelihood requests:  49%|████▉     | 195/400 [03:35<03:42,  1.08s/it]Running loglikelihood requests:  49%|████▉     | 196/400 [03:36<03:40,  1.08s/it]Running loglikelihood requests:  49%|████▉     | 197/400 [03:37<03:39,  1.08s/it]Running loglikelihood requests:  50%|████▉     | 198/400 [03:38<03:38,  1.08s/it]Running loglikelihood requests:  50%|████▉     | 199/400 [03:39<03:37,  1.08s/it]Running loglikelihood requests:  50%|█████     | 200/400 [03:40<03:35,  1.08s/it]Running loglikelihood requests:  50%|█████     | 201/400 [03:41<03:34,  1.08s/it]Running loglikelihood requests:  50%|█████     | 202/400 [03:42<03:33,  1.08s/it]Running loglikelihood requests:  51%|█████     | 203/400 [03:43<03:32,  1.08s/it]Running loglikelihood requests:  51%|█████▏    | 205/400 [03:44<02:41,  1.21it/s]Running loglikelihood requests:  52%|█████▏    | 206/400 [03:45<02:52,  1.12it/s]Running loglikelihood requests:  52%|█████▏    | 207/400 [03:47<03:01,  1.06it/s]Running loglikelihood requests:  52%|█████▏    | 208/400 [03:48<03:07,  1.02it/s]Running loglikelihood requests:  52%|█████▏    | 209/400 [03:49<03:12,  1.01s/it]Running loglikelihood requests:  52%|█████▎    | 210/400 [03:50<03:15,  1.03s/it]Running loglikelihood requests:  53%|█████▎    | 211/400 [03:51<03:17,  1.04s/it]Running loglikelihood requests:  53%|█████▎    | 212/400 [03:52<03:17,  1.05s/it]Running loglikelihood requests:  53%|█████▎    | 213/400 [03:53<03:18,  1.06s/it]Running loglikelihood requests:  54%|█████▎    | 214/400 [03:54<03:18,  1.07s/it]Running loglikelihood requests:  54%|█████▍    | 215/400 [03:55<03:17,  1.07s/it]Running loglikelihood requests:  54%|█████▍    | 216/400 [03:56<03:16,  1.07s/it]Running loglikelihood requests:  54%|█████▍    | 217/400 [03:57<03:16,  1.07s/it]Running loglikelihood requests:  55%|█████▍    | 218/400 [03:58<03:15,  1.07s/it]Running loglikelihood requests:  55%|█████▍    | 219/400 [04:00<03:17,  1.09s/it]Running loglikelihood requests:  55%|█████▌    | 220/400 [04:01<03:15,  1.09s/it]Running loglikelihood requests:  55%|█████▌    | 221/400 [04:02<03:14,  1.08s/it]Running loglikelihood requests:  56%|█████▌    | 222/400 [04:03<03:12,  1.08s/it]Running loglikelihood requests:  56%|█████▌    | 223/400 [04:04<03:11,  1.08s/it]Running loglikelihood requests:  56%|█████▌    | 224/400 [04:05<03:10,  1.08s/it]Running loglikelihood requests:  56%|█████▋    | 225/400 [04:06<03:08,  1.08s/it]Running loglikelihood requests:  56%|█████▋    | 226/400 [04:07<03:07,  1.08s/it]Running loglikelihood requests:  57%|█████▋    | 227/400 [04:08<03:06,  1.08s/it]Running loglikelihood requests:  57%|█████▋    | 228/400 [04:09<03:05,  1.08s/it]Running loglikelihood requests:  57%|█████▋    | 229/400 [04:10<03:04,  1.08s/it]Running loglikelihood requests:  57%|█████▊    | 230/400 [04:11<03:02,  1.08s/it]Running loglikelihood requests:  58%|█████▊    | 231/400 [04:12<03:01,  1.07s/it]Running loglikelihood requests:  58%|█████▊    | 232/400 [04:14<03:00,  1.07s/it]Running loglikelihood requests:  58%|█████▊    | 233/400 [04:15<02:59,  1.07s/it]Running loglikelihood requests:  58%|█████▊    | 234/400 [04:16<02:57,  1.07s/it]Running loglikelihood requests:  59%|█████▉    | 235/400 [04:17<02:56,  1.07s/it]Running loglikelihood requests:  59%|█████▉    | 236/400 [04:18<02:55,  1.07s/it]Running loglikelihood requests:  59%|█████▉    | 237/400 [04:19<02:54,  1.07s/it]Running loglikelihood requests:  60%|█████▉    | 238/400 [04:20<02:53,  1.07s/it]Running loglikelihood requests:  60%|█████▉    | 239/400 [04:21<02:52,  1.07s/it]Running loglikelihood requests:  60%|██████    | 241/400 [04:22<02:10,  1.22it/s]Running loglikelihood requests:  60%|██████    | 242/400 [04:23<02:19,  1.13it/s]Running loglikelihood requests:  61%|██████    | 243/400 [04:24<02:26,  1.07it/s]Running loglikelihood requests:  61%|██████    | 244/400 [04:25<02:31,  1.03it/s]Running loglikelihood requests:  61%|██████▏   | 245/400 [04:26<02:34,  1.00it/s]Running loglikelihood requests:  62%|██████▏   | 246/400 [04:27<02:36,  1.02s/it]Running loglikelihood requests:  62%|██████▏   | 247/400 [04:28<02:38,  1.03s/it]Running loglikelihood requests:  62%|██████▏   | 248/400 [04:30<02:38,  1.04s/it]Running loglikelihood requests:  62%|██████▏   | 249/400 [04:31<02:38,  1.05s/it]Running loglikelihood requests:  62%|██████▎   | 250/400 [04:32<02:38,  1.05s/it]Running loglikelihood requests:  63%|██████▎   | 251/400 [04:33<02:37,  1.06s/it]Running loglikelihood requests:  63%|██████▎   | 252/400 [04:34<02:37,  1.06s/it]Running loglikelihood requests:  63%|██████▎   | 253/400 [04:35<02:36,  1.06s/it]Running loglikelihood requests:  64%|██████▍   | 255/400 [04:36<01:58,  1.22it/s]Running loglikelihood requests:  64%|██████▍   | 256/400 [04:37<02:06,  1.14it/s]Running loglikelihood requests:  64%|██████▍   | 257/400 [04:38<02:12,  1.08it/s]Running loglikelihood requests:  64%|██████▍   | 258/400 [04:39<02:17,  1.04it/s]Running loglikelihood requests:  65%|██████▍   | 259/400 [04:40<02:19,  1.01it/s]Running loglikelihood requests:  65%|██████▌   | 260/400 [04:41<02:21,  1.01s/it]Running loglikelihood requests:  65%|██████▌   | 261/400 [04:42<02:22,  1.03s/it]Running loglikelihood requests:  66%|██████▌   | 262/400 [04:43<02:23,  1.04s/it]Running loglikelihood requests:  66%|██████▌   | 263/400 [04:44<02:23,  1.04s/it]Running loglikelihood requests:  66%|██████▌   | 264/400 [04:46<02:22,  1.05s/it]Running loglikelihood requests:  66%|██████▋   | 265/400 [04:47<02:22,  1.05s/it]Running loglikelihood requests:  66%|██████▋   | 266/400 [04:48<02:21,  1.06s/it]Running loglikelihood requests:  67%|██████▋   | 267/400 [04:49<02:20,  1.06s/it]Running loglikelihood requests:  67%|██████▋   | 268/400 [04:50<02:19,  1.06s/it]Running loglikelihood requests:  68%|██████▊   | 270/400 [04:51<01:46,  1.23it/s]Running loglikelihood requests:  68%|██████▊   | 271/400 [04:52<01:52,  1.14it/s]Running loglikelihood requests:  68%|██████▊   | 272/400 [04:53<01:58,  1.08it/s]Running loglikelihood requests:  68%|██████▊   | 273/400 [04:54<02:01,  1.04it/s]Running loglikelihood requests:  68%|██████▊   | 274/400 [04:55<02:04,  1.01it/s]Running loglikelihood requests:  69%|██████▉   | 275/400 [04:56<02:05,  1.00s/it]Running loglikelihood requests:  69%|██████▉   | 276/400 [04:57<02:06,  1.02s/it]Running loglikelihood requests:  69%|██████▉   | 277/400 [04:58<02:06,  1.03s/it]Running loglikelihood requests:  70%|██████▉   | 278/400 [04:59<02:07,  1.05s/it]Running loglikelihood requests:  70%|██████▉   | 279/400 [05:00<02:06,  1.05s/it]Running loglikelihood requests:  70%|███████   | 280/400 [05:01<02:06,  1.05s/it]Running loglikelihood requests:  70%|███████   | 281/400 [05:02<02:05,  1.05s/it]Running loglikelihood requests:  70%|███████   | 282/400 [05:04<02:04,  1.05s/it]Running loglikelihood requests:  71%|███████   | 283/400 [05:05<02:03,  1.05s/it]Running loglikelihood requests:  71%|███████   | 284/400 [05:06<02:02,  1.06s/it]Running loglikelihood requests:  71%|███████▏  | 285/400 [05:07<02:01,  1.05s/it]Running loglikelihood requests:  72%|███████▏  | 286/400 [05:08<02:00,  1.05s/it]Running loglikelihood requests:  72%|███████▏  | 287/400 [05:09<02:00,  1.07s/it]Running loglikelihood requests:  72%|███████▏  | 288/400 [05:10<01:58,  1.06s/it]Running loglikelihood requests:  72%|███████▏  | 289/400 [05:11<01:56,  1.05s/it]Running loglikelihood requests:  72%|███████▎  | 290/400 [05:12<01:55,  1.05s/it]Running loglikelihood requests:  73%|███████▎  | 291/400 [05:13<01:53,  1.04s/it]Running loglikelihood requests:  73%|███████▎  | 292/400 [05:14<01:52,  1.04s/it]Running loglikelihood requests:  73%|███████▎  | 293/400 [05:15<01:51,  1.04s/it]Running loglikelihood requests:  74%|███████▎  | 294/400 [05:16<01:50,  1.04s/it]Running loglikelihood requests:  74%|███████▍  | 295/400 [05:17<01:49,  1.04s/it]Running loglikelihood requests:  74%|███████▍  | 296/400 [05:18<01:47,  1.04s/it]Running loglikelihood requests:  74%|███████▍  | 297/400 [05:19<01:46,  1.03s/it]Running loglikelihood requests:  74%|███████▍  | 298/400 [05:20<01:45,  1.03s/it]Running loglikelihood requests:  75%|███████▍  | 299/400 [05:21<01:44,  1.03s/it]Running loglikelihood requests:  75%|███████▌  | 300/400 [05:22<01:43,  1.03s/it]Running loglikelihood requests:  75%|███████▌  | 301/400 [05:23<01:42,  1.03s/it]Running loglikelihood requests:  76%|███████▌  | 302/400 [05:24<01:40,  1.03s/it]Running loglikelihood requests:  76%|███████▌  | 304/400 [05:25<01:16,  1.26it/s]Running loglikelihood requests:  76%|███████▋  | 305/400 [05:26<01:20,  1.17it/s]Running loglikelihood requests:  76%|███████▋  | 306/400 [05:27<01:24,  1.11it/s]Running loglikelihood requests:  77%|███████▋  | 307/400 [05:28<01:26,  1.07it/s]Running loglikelihood requests:  77%|███████▋  | 308/400 [05:29<01:28,  1.04it/s]Running loglikelihood requests:  77%|███████▋  | 309/400 [05:30<01:28,  1.02it/s]Running loglikelihood requests:  78%|███████▊  | 310/400 [05:32<01:29,  1.01it/s]Running loglikelihood requests:  78%|███████▊  | 311/400 [05:33<01:28,  1.00it/s]Running loglikelihood requests:  78%|███████▊  | 312/400 [05:34<01:28,  1.00s/it]Running loglikelihood requests:  78%|███████▊  | 313/400 [05:35<01:27,  1.01s/it]Running loglikelihood requests:  78%|███████▊  | 314/400 [05:36<01:26,  1.01s/it]Running loglikelihood requests:  79%|███████▉  | 315/400 [05:37<01:26,  1.01s/it]Running loglikelihood requests:  79%|███████▉  | 316/400 [05:38<01:25,  1.02s/it]Running loglikelihood requests:  79%|███████▉  | 317/400 [05:39<01:24,  1.02s/it]Running loglikelihood requests:  80%|███████▉  | 318/400 [05:40<01:23,  1.02s/it]Running loglikelihood requests:  80%|███████▉  | 319/400 [05:41<01:22,  1.02s/it]Running loglikelihood requests:  80%|████████  | 320/400 [05:42<01:21,  1.02s/it]Running loglikelihood requests:  80%|████████  | 321/400 [05:43<01:20,  1.02s/it]Running loglikelihood requests:  80%|████████  | 322/400 [05:44<01:19,  1.02s/it]Running loglikelihood requests:  81%|████████  | 323/400 [05:45<01:18,  1.02s/it]Running loglikelihood requests:  81%|████████  | 324/400 [05:46<01:17,  1.02s/it]Running loglikelihood requests:  81%|████████▏ | 325/400 [05:47<01:16,  1.02s/it]Running loglikelihood requests:  82%|████████▏ | 326/400 [05:48<01:15,  1.02s/it]Running loglikelihood requests:  82%|████████▏ | 327/400 [05:49<01:14,  1.02s/it]Running loglikelihood requests:  82%|████████▏ | 328/400 [05:50<01:13,  1.01s/it]Running loglikelihood requests:  82%|████████▎ | 330/400 [05:51<00:54,  1.28it/s]Running loglikelihood requests:  83%|████████▎ | 331/400 [05:52<00:57,  1.20it/s]Running loglikelihood requests:  83%|████████▎ | 332/400 [05:53<00:59,  1.13it/s]Running loglikelihood requests:  83%|████████▎ | 333/400 [05:54<01:01,  1.09it/s]Running loglikelihood requests:  84%|████████▎ | 334/400 [05:55<01:02,  1.06it/s]Running loglikelihood requests:  84%|████████▍ | 335/400 [05:56<01:02,  1.04it/s]Running loglikelihood requests:  84%|████████▍ | 336/400 [05:57<01:02,  1.03it/s]Running loglikelihood requests:  84%|████████▍ | 337/400 [05:58<01:01,  1.02it/s]Running loglikelihood requests:  84%|████████▍ | 338/400 [05:59<01:01,  1.01it/s]Running loglikelihood requests:  85%|████████▍ | 339/400 [06:00<01:00,  1.00it/s]Running loglikelihood requests:  85%|████████▌ | 340/400 [06:01<00:59,  1.00it/s]Running loglikelihood requests:  85%|████████▌ | 341/400 [06:02<00:58,  1.00it/s]Running loglikelihood requests:  86%|████████▌ | 342/400 [06:03<00:58,  1.00s/it]Running loglikelihood requests:  86%|████████▌ | 343/400 [06:04<00:57,  1.00s/it]Running loglikelihood requests:  86%|████████▌ | 344/400 [06:05<00:56,  1.00s/it]Running loglikelihood requests:  86%|████████▋ | 345/400 [06:06<00:55,  1.00s/it]Running loglikelihood requests:  86%|████████▋ | 346/400 [06:07<00:54,  1.00s/it]Running loglikelihood requests:  87%|████████▋ | 347/400 [06:08<00:53,  1.00s/it]Running loglikelihood requests:  87%|████████▋ | 348/400 [06:09<00:52,  1.00s/it]Running loglikelihood requests:  87%|████████▋ | 349/400 [06:10<00:51,  1.02s/it]Running loglikelihood requests:  88%|████████▊ | 350/400 [06:11<00:52,  1.04s/it]Running loglikelihood requests:  88%|████████▊ | 351/400 [06:12<00:51,  1.05s/it]Running loglikelihood requests:  88%|████████▊ | 352/400 [06:13<00:49,  1.03s/it]Running loglikelihood requests:  88%|████████▊ | 353/400 [06:14<00:47,  1.02s/it]Running loglikelihood requests:  88%|████████▊ | 354/400 [06:15<00:46,  1.01s/it]Running loglikelihood requests:  89%|████████▉ | 355/400 [06:16<00:45,  1.00s/it]Running loglikelihood requests:  89%|████████▉ | 356/400 [06:17<00:43,  1.00it/s]Running loglikelihood requests:  89%|████████▉ | 357/400 [06:18<00:42,  1.00it/s]Running loglikelihood requests:  90%|████████▉ | 358/400 [06:19<00:41,  1.01it/s]Running loglikelihood requests:  90%|████████▉ | 359/400 [06:20<00:40,  1.01it/s]Running loglikelihood requests:  90%|█████████ | 360/400 [06:21<00:39,  1.01it/s]Running loglikelihood requests:  90%|█████████ | 361/400 [06:22<00:38,  1.02it/s]Running loglikelihood requests:  90%|█████████ | 362/400 [06:23<00:37,  1.02it/s]Running loglikelihood requests:  91%|█████████ | 363/400 [06:24<00:36,  1.02it/s]Running loglikelihood requests:  91%|█████████ | 364/400 [06:25<00:35,  1.02it/s]Running loglikelihood requests:  91%|█████████▏| 365/400 [06:26<00:34,  1.02it/s]Running loglikelihood requests:  92%|█████████▏| 366/400 [06:27<00:33,  1.03it/s]Running loglikelihood requests:  92%|█████████▏| 367/400 [06:28<00:32,  1.03it/s]Running loglikelihood requests:  92%|█████████▏| 368/400 [06:29<00:31,  1.03it/s]Running loglikelihood requests:  92%|█████████▏| 369/400 [06:30<00:30,  1.03it/s]Running loglikelihood requests:  92%|█████████▎| 370/400 [06:31<00:29,  1.03it/s]Running loglikelihood requests:  93%|█████████▎| 371/400 [06:32<00:28,  1.03it/s]Running loglikelihood requests:  93%|█████████▎| 372/400 [06:33<00:27,  1.03it/s]Running loglikelihood requests:  93%|█████████▎| 373/400 [06:34<00:26,  1.03it/s]Running loglikelihood requests:  94%|█████████▎| 374/400 [06:35<00:25,  1.04it/s]Running loglikelihood requests:  94%|█████████▍| 375/400 [06:36<00:24,  1.04it/s]Running loglikelihood requests:  94%|█████████▍| 376/400 [06:37<00:23,  1.04it/s]Running loglikelihood requests:  94%|█████████▍| 377/400 [06:37<00:22,  1.04it/s]Running loglikelihood requests:  94%|█████████▍| 378/400 [06:38<00:21,  1.05it/s]Running loglikelihood requests:  95%|█████████▍| 379/400 [06:39<00:20,  1.05it/s]Running loglikelihood requests:  95%|█████████▌| 380/400 [06:40<00:19,  1.05it/s]Running loglikelihood requests:  95%|█████████▌| 381/400 [06:41<00:18,  1.05it/s]Running loglikelihood requests:  96%|█████████▌| 382/400 [06:42<00:17,  1.05it/s]Running loglikelihood requests:  96%|█████████▌| 383/400 [06:43<00:16,  1.05it/s]Running loglikelihood requests:  96%|█████████▌| 384/400 [06:44<00:15,  1.05it/s]Running loglikelihood requests:  96%|█████████▋| 385/400 [06:45<00:14,  1.05it/s]Running loglikelihood requests:  96%|█████████▋| 386/400 [06:46<00:13,  1.05it/s]Running loglikelihood requests:  97%|█████████▋| 387/400 [06:47<00:12,  1.05it/s]Running loglikelihood requests:  97%|█████████▋| 388/400 [06:48<00:11,  1.05it/s]Running loglikelihood requests:  97%|█████████▋| 389/400 [06:49<00:10,  1.05it/s]Running loglikelihood requests:  98%|█████████▊| 390/400 [06:50<00:09,  1.05it/s]Running loglikelihood requests:  98%|█████████▊| 391/400 [06:51<00:08,  1.06it/s]Running loglikelihood requests:  98%|█████████▊| 392/400 [06:52<00:07,  1.06it/s]Running loglikelihood requests:  98%|█████████▊| 393/400 [06:53<00:06,  1.06it/s]Running loglikelihood requests:  98%|█████████▊| 394/400 [06:54<00:05,  1.06it/s]Running loglikelihood requests:  99%|█████████▉| 395/400 [06:55<00:04,  1.06it/s]Running loglikelihood requests:  99%|█████████▉| 396/400 [06:55<00:03,  1.06it/s]Running loglikelihood requests:  99%|█████████▉| 397/400 [06:56<00:02,  1.07it/s]Running loglikelihood requests: 100%|█████████▉| 398/400 [06:57<00:01,  1.08it/s]Running loglikelihood requests: 100%|█████████▉| 399/400 [06:58<00:00,  1.08it/s]Running loglikelihood requests: 100%|██████████| 400/400 [06:59<00:00,  1.05it/s]Running loglikelihood requests: 100%|██████████| 400/400 [06:59<00:00,  1.05s/it]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:1'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:1'}
full model:
{'mastermind_35_easy': {'alias': 'mastermind_35_easy', 'acc,none': 0.51, 'acc_stderr,none': 0.05024183937956913}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9685093904417202
0.9837389482734848
0.9887891422859466
0.9728424941793791
0.9273096247071001
0.9956884174036557
0.9936991917224709
0.990637728847171
0.984416562505352
0.9357041463019401
0.957486187236088
0.9794440444506461
0.9854000882321717
0.989321120949945
0.9948124947717892
0.9950699411775289
0.9589145403056732
0.9488498047330014
0.979093344902028
0.9861615563222426
0.9944647439314634
0.9974738465425171
0.9932459641322177
0.9612113452387381
0.9566187588663586
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[5, 1, 0, 3, 7, 6, 2, 4]
tensor([5, 1, 0, 3, 7, 6, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 0, 3, 7, 5, 2, 4]
tensor([6, 1, 0, 3, 7, 5, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 1, 0, 3, 7, 6, 2, 4]
tensor([5, 1, 0, 3, 7, 6, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 0, 3, 7, 5, 2, 4]
tensor([6, 1, 0, 3, 7, 5, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 1, 0, 3, 7, 6, 2, 4]
tensor([5, 1, 0, 3, 7, 6, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 0, 3, 7, 5, 2, 4]
tensor([6, 1, 0, 3, 7, 5, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Normal merging for layer 2
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Normal merging for layer 3
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Normal merging for layer 4
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Normal merging for layer 5
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 6 to 31
done!
all done!
Model size: 12.0718 GB
30
cuda:1
cola
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:44<00:44, 44.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:57<00:00, 26.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:57<00:00, 28.73s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: cola] metric mcc is defined, but aggregation is not. using default aggregation=matthews_corrcoef
WARNING:lm_eval.api.task:[Task: cola] metric mcc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139748506715008 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_cola_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139748506715008 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_cola_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139748506715008 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_cola_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139748506715008 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_cola_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139722780430784 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139722780430784 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139722780430784 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139722780430784 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of cola from None to 0
INFO:lm_eval.api.task:Building contexts for cola on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 3255.51it/s]
DEBUG:lm_eval.evaluator:Task: cola; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:01<03:39,  1.11s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:01<01:34,  2.08it/s]Running loglikelihood requests:   2%|▎         | 5/200 [00:02<01:11,  2.73it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:02<01:02,  3.11it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:03<00:56,  3.39it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:03<00:52,  3.58it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:04<00:50,  3.71it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:04<00:48,  3.80it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:05<00:47,  3.87it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:05<00:46,  3.93it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:06<00:45,  3.97it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:06<00:44,  3.99it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:07<00:43,  4.02it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:07<00:42,  4.04it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:08<00:42,  4.07it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:08<00:41,  4.09it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:09<00:40,  4.10it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:09<00:40,  4.12it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:10<00:39,  4.13it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:10<00:38,  4.13it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:11<00:38,  4.14it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:11<00:37,  4.14it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:11<00:37,  4.16it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:12<00:36,  4.18it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:12<00:36,  4.19it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:13<00:35,  4.21it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:13<00:34,  4.22it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:14<00:34,  4.22it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:14<00:33,  4.24it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:15<00:33,  4.24it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:15<00:32,  4.27it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:16<00:31,  4.28it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:16<00:31,  4.29it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:17<00:30,  4.30it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:17<00:30,  4.32it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:18<00:29,  4.33it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:18<00:29,  4.33it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:18<00:28,  4.33it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:19<00:28,  4.33it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:19<00:27,  4.33it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:20<00:27,  4.33it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:20<00:26,  4.34it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:21<00:26,  4.35it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:21<00:25,  4.36it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:22<00:25,  4.37it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:22<00:24,  4.37it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:23<00:24,  4.38it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:23<00:23,  4.39it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:23<00:23,  4.40it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:24<00:22,  4.41it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:24<00:22,  4.43it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:25<00:21,  4.43it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:25<00:21,  4.44it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:26<00:20,  4.44it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:26<00:20,  4.44it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:27<00:20,  4.44it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:27<00:19,  4.44it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:28<00:19,  4.45it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:28<00:18,  4.46it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:28<00:18,  4.48it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:29<00:17,  4.49it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:29<00:17,  4.49it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:30<00:16,  4.48it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [00:30<00:16,  4.49it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [00:31<00:15,  4.49it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [00:31<00:15,  4.51it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [00:32<00:14,  4.53it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [00:32<00:14,  4.53it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [00:32<00:13,  4.53it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [00:33<00:13,  4.54it/s]Running loglikelihood requests:  70%|███████   | 141/200 [00:33<00:12,  4.55it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [00:34<00:12,  4.56it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [00:34<00:12,  4.57it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [00:35<00:11,  4.57it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [00:35<00:11,  4.58it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [00:35<00:10,  4.59it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [00:36<00:10,  4.59it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [00:36<00:09,  4.59it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [00:37<00:09,  4.61it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [00:37<00:08,  4.62it/s]Running loglikelihood requests:  80%|████████  | 161/200 [00:38<00:08,  4.62it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [00:38<00:07,  4.63it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [00:38<00:07,  4.63it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [00:39<00:07,  4.64it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [00:39<00:06,  4.64it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [00:40<00:06,  4.65it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [00:40<00:05,  4.67it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [00:41<00:05,  4.67it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [00:41<00:04,  4.68it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [00:41<00:04,  4.68it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [00:42<00:04,  4.70it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [00:42<00:03,  4.71it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [00:43<00:03,  4.71it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [00:43<00:02,  4.73it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [00:44<00:02,  4.75it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [00:44<00:01,  4.76it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [00:44<00:01,  4.79it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [00:45<00:01,  4.79it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [00:45<00:00,  4.79it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [00:46<00:00,  4.82it/s]Running loglikelihood requests: 100%|██████████| 200/200 [00:46<00:00,  4.33it/s]
bootstrapping for stddev (sequential): matthews_corrcoef
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<01:33,  1.06it/s]  2%|▏         | 2/100 [00:01<01:31,  1.07it/s]  3%|▎         | 3/100 [00:02<01:30,  1.08it/s]  4%|▍         | 4/100 [00:03<01:29,  1.08it/s]  5%|▌         | 5/100 [00:04<01:28,  1.08it/s]  6%|▌         | 6/100 [00:05<01:27,  1.08it/s]  7%|▋         | 7/100 [00:06<01:26,  1.08it/s]  8%|▊         | 8/100 [00:07<01:25,  1.08it/s]  9%|▉         | 9/100 [00:08<01:24,  1.08it/s] 10%|█         | 10/100 [00:09<01:23,  1.08it/s] 11%|█         | 11/100 [00:10<01:23,  1.07it/s] 12%|█▏        | 12/100 [00:11<01:22,  1.07it/s] 13%|█▎        | 13/100 [00:12<01:21,  1.07it/s] 14%|█▍        | 14/100 [00:13<01:19,  1.08it/s] 15%|█▌        | 15/100 [00:13<01:19,  1.06it/s] 16%|█▌        | 16/100 [00:14<01:18,  1.07it/s] 17%|█▋        | 17/100 [00:15<01:17,  1.07it/s] 18%|█▊        | 18/100 [00:16<01:16,  1.08it/s] 19%|█▉        | 19/100 [00:17<01:14,  1.08it/s] 20%|██        | 20/100 [00:18<01:13,  1.08it/s] 21%|██        | 21/100 [00:19<01:13,  1.08it/s] 22%|██▏       | 22/100 [00:20<01:12,  1.08it/s] 23%|██▎       | 23/100 [00:21<01:11,  1.08it/s] 24%|██▍       | 24/100 [00:22<01:10,  1.08it/s] 25%|██▌       | 25/100 [00:23<01:09,  1.08it/s] 26%|██▌       | 26/100 [00:24<01:08,  1.08it/s] 27%|██▋       | 27/100 [00:25<01:07,  1.08it/s] 28%|██▊       | 28/100 [00:26<01:07,  1.07it/s] 29%|██▉       | 29/100 [00:26<01:06,  1.07it/s] 30%|███       | 30/100 [00:27<01:05,  1.07it/s] 31%|███       | 31/100 [00:28<01:04,  1.07it/s] 32%|███▏      | 32/100 [00:29<01:03,  1.06it/s] 33%|███▎      | 33/100 [00:30<01:02,  1.07it/s] 34%|███▍      | 34/100 [00:31<01:01,  1.07it/s] 35%|███▌      | 35/100 [00:32<01:00,  1.08it/s] 36%|███▌      | 36/100 [00:33<00:59,  1.08it/s] 37%|███▋      | 37/100 [00:34<00:58,  1.08it/s] 38%|███▊      | 38/100 [00:35<00:57,  1.08it/s] 39%|███▉      | 39/100 [00:36<00:56,  1.08it/s] 40%|████      | 40/100 [00:37<00:55,  1.08it/s] 41%|████      | 41/100 [00:38<00:54,  1.08it/s] 42%|████▏     | 42/100 [00:39<00:53,  1.08it/s] 43%|████▎     | 43/100 [00:39<00:52,  1.08it/s] 44%|████▍     | 44/100 [00:40<00:51,  1.08it/s] 45%|████▌     | 45/100 [00:41<00:50,  1.08it/s] 46%|████▌     | 46/100 [00:42<00:49,  1.08it/s] 47%|████▋     | 47/100 [00:43<00:48,  1.08it/s] 48%|████▊     | 48/100 [00:44<00:48,  1.08it/s] 49%|████▉     | 49/100 [00:45<00:47,  1.08it/s] 50%|█████     | 50/100 [00:46<00:46,  1.08it/s] 51%|█████     | 51/100 [00:47<00:45,  1.08it/s] 52%|█████▏    | 52/100 [00:48<00:44,  1.08it/s] 53%|█████▎    | 53/100 [00:49<00:43,  1.08it/s] 54%|█████▍    | 54/100 [00:50<00:42,  1.08it/s] 55%|█████▌    | 55/100 [00:51<00:41,  1.08it/s] 56%|█████▌    | 56/100 [00:51<00:40,  1.08it/s] 57%|█████▋    | 57/100 [00:52<00:39,  1.08it/s] 58%|█████▊    | 58/100 [00:53<00:38,  1.08it/s] 59%|█████▉    | 59/100 [00:54<00:38,  1.08it/s] 60%|██████    | 60/100 [00:55<00:37,  1.08it/s] 61%|██████    | 61/100 [00:56<00:36,  1.08it/s] 62%|██████▏   | 62/100 [00:57<00:35,  1.08it/s] 63%|██████▎   | 63/100 [00:58<00:34,  1.08it/s] 64%|██████▍   | 64/100 [00:59<00:33,  1.08it/s] 65%|██████▌   | 65/100 [01:00<00:32,  1.08it/s] 66%|██████▌   | 66/100 [01:01<00:31,  1.08it/s] 67%|██████▋   | 67/100 [01:02<00:30,  1.08it/s] 68%|██████▊   | 68/100 [01:03<00:29,  1.08it/s] 69%|██████▉   | 69/100 [01:04<00:28,  1.08it/s] 70%|███████   | 70/100 [01:04<00:27,  1.08it/s] 71%|███████   | 71/100 [01:05<00:26,  1.08it/s] 72%|███████▏  | 72/100 [01:06<00:26,  1.08it/s] 73%|███████▎  | 73/100 [01:07<00:25,  1.08it/s] 74%|███████▍  | 74/100 [01:08<00:24,  1.08it/s] 75%|███████▌  | 75/100 [01:09<00:23,  1.07it/s] 76%|███████▌  | 76/100 [01:10<00:22,  1.07it/s] 77%|███████▋  | 77/100 [01:11<00:21,  1.08it/s] 78%|███████▊  | 78/100 [01:12<00:20,  1.08it/s] 79%|███████▉  | 79/100 [01:13<00:19,  1.08it/s] 80%|████████  | 80/100 [01:14<00:18,  1.08it/s] 81%|████████  | 81/100 [01:15<00:17,  1.08it/s] 82%|████████▏ | 82/100 [01:16<00:16,  1.08it/s] 83%|████████▎ | 83/100 [01:16<00:15,  1.08it/s] 84%|████████▍ | 84/100 [01:17<00:14,  1.08it/s] 85%|████████▌ | 85/100 [01:18<00:13,  1.08it/s] 86%|████████▌ | 86/100 [01:19<00:13,  1.07it/s] 87%|████████▋ | 87/100 [01:20<00:12,  1.08it/s] 88%|████████▊ | 88/100 [01:21<00:11,  1.08it/s] 89%|████████▉ | 89/100 [01:22<00:10,  1.08it/s] 90%|█████████ | 90/100 [01:23<00:09,  1.08it/s] 91%|█████████ | 91/100 [01:24<00:08,  1.07it/s] 92%|█████████▏| 92/100 [01:25<00:07,  1.07it/s] 93%|█████████▎| 93/100 [01:26<00:06,  1.08it/s] 94%|█████████▍| 94/100 [01:27<00:05,  1.08it/s] 95%|█████████▌| 95/100 [01:28<00:04,  1.08it/s] 96%|█████████▌| 96/100 [01:29<00:03,  1.08it/s] 97%|█████████▋| 97/100 [01:29<00:02,  1.08it/s] 98%|█████████▊| 98/100 [01:30<00:01,  1.08it/s] 99%|█████████▉| 99/100 [01:31<00:00,  1.08it/s]100%|██████████| 100/100 [01:32<00:00,  1.08it/s]100%|██████████| 100/100 [01:32<00:00,  1.08it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:2'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:2'}
full model:
{'cola': {'alias': 'cola', 'mcc,none': np.float64(-0.0234083603222329), 'mcc_stderr,none': 0.10027612985654218}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9827615088085355
0.9302188892609604
0.7011961870018854
0.5626926521241726
0.8487059565524276
0.8497526414658526
0.9054485200458864
0.7394951536076
0.6615723249956142
0.3790091735780837
0.7669438266452424
0.6500882643740805
0.6039759750877352
0.8611545876684488
0.9595791152744535
0.7624866897939796
0.8585278638499474
0.9654871578633694
0.8537985077125277
0.9276026122967783
0.938072418626947
0.8815459403167786
0.6241194219560614
0.901256729143793
0.7007049393842223
0.6541093728101413
0.9141945519271818
0.7667764647672246
0.8091089193013563
Total groups 69 exceeded the threshold, stopping comparison.
The group tensor is
[3, 2, 6, 7, 5, 1, 4, 0]
tensor([3, 2, 6, 7, 5, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 3, 6, 7, 5, 1, 4, 0]
tensor([2, 3, 6, 7, 5, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 3, 5, 7, 6, 1, 2, 0]
tensor([4, 3, 5, 7, 6, 1, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[2, 3, 0, 1, 2, 1, 3, 0]
tensor([2, 3, 0, 1, 2, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[1, 0, 1, 2, 3, 2, 3, 0]
tensor([1, 0, 1, 2, 3, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 2, 1, 2, 3, 1, 3, 0]
tensor([0, 2, 1, 2, 3, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[1, 0, 0, 1, 2, 3, 3, 2]
tensor([1, 0, 0, 1, 2, 3, 3, 2], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[3, 1, 0, 1, 2, 2, 3, 0]
tensor([3, 1, 0, 1, 2, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1.0, 1.0, 1, 1.0, 0]
tensor([0, 1, 1, 1, 1, 1, 1, 0], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
done!
Cross-layer merge completed for layers 2 to 5
done!
Normal merging for layer 6
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
tensor([3])
tensor(3)
done!
Cross-layer merge completed for layers 7 to 18
done!
Normal merging for layer 19
tensor([2, 7])
tensor(2)
tensor([3, 5])
tensor(3)
tensor([0, 4])
tensor(0)
tensor([1, 6])
tensor(1)
done!
Normal merging for layer 20
tensor([1, 7])
tensor(1)
tensor([0, 2])
tensor(0)
tensor([3, 5])
tensor(3)
tensor([4, 6])
tensor(4)
done!
Normal merging for layer 21
tensor([0, 7])
tensor(0)
tensor([2, 5])
tensor(2)
tensor([1, 3])
tensor(1)
tensor([4, 6])
tensor(4)
done!
Normal merging for layer 22
tensor([1, 2])
tensor(1)
tensor([0, 3])
tensor(0)
tensor([4, 7])
tensor(4)
tensor([5, 6])
tensor(5)
done!
Normal merging for layer 23
tensor([2, 7])
tensor(2)
tensor([1, 3])
tensor(1)
tensor([4, 5])
tensor(4)
tensor([0, 6])
tensor(0)
done!
Cross-layer merge completed for layers 24 to 27
done!
Normal merging for layer 28
tensor([0, 7])
tensor(0)
tensor([1, 2, 3, 4, 5, 6])
tensor(1)
done!
Cross-layer merge completed for layers 29 to 31
done!
all done!
Model size: 12.1348 GB
82
cuda:2
openbookqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:43<00:43, 43.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:57<00:00, 25.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:57<00:00, 28.51s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/openbookqa HTTP/1.1" 307 67
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/openbookqa HTTP/1.1" 200 1408
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/openbookqa/openbookqa.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/openbookqa HTTP/1.1" 307 67
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/openbookqa HTTP/1.1" 200 1408
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/openbookqa/resolve/388097ea7776314e93a529163e0fea805b8a6454/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/allenai/openbookqa/resolve/388097ea7776314e93a529163e0fea805b8a6454/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/openbookqa/revision/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 117
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/openbookqa/revision/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 1408
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/openbookqa/tree/388097ea7776314e93a529163e0fea805b8a6454?recursive=False&expand=False HTTP/1.1" 307 142
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/openbookqa/tree/388097ea7776314e93a529163e0fea805b8a6454?recursive=False&expand=False HTTP/1.1" 200 390
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 119
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 241
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/openbookqa/tree/388097ea7776314e93a529163e0fea805b8a6454/additional?recursive=False&expand=False HTTP/1.1" 307 153
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/openbookqa/tree/388097ea7776314e93a529163e0fea805b8a6454/additional?recursive=False&expand=False HTTP/1.1" 200 363
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 119
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 241
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/openbookqa/revision/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 117
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/openbookqa/revision/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 1408
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 119
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 241
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 119
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 241
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 119
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 241
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 119
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 241
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/openbookqa/resolve/388097ea7776314e93a529163e0fea805b8a6454/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/allenai/openbookqa/resolve/388097ea7776314e93a529163e0fea805b8a6454/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 119
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/openbookqa/tree/388097ea7776314e93a529163e0fea805b8a6454/main?recursive=False&expand=False HTTP/1.1" 307 147
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/openbookqa/tree/388097ea7776314e93a529163e0fea805b8a6454/main?recursive=False&expand=False HTTP/1.1" 200 359
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 119
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 119
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 119
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 119
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 307 119
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/openbookqa/paths-info/388097ea7776314e93a529163e0fea805b8a6454 HTTP/1.1" 200 235
DEBUG:filelock:Attempting to acquire lock 139749987797904 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_openbookqa_main_0.0.0_388097ea7776314e93a529163e0fea805b8a6454.lock
DEBUG:filelock:Lock 139749987797904 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_openbookqa_main_0.0.0_388097ea7776314e93a529163e0fea805b8a6454.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/openbookqa/main/0.0.0/388097ea7776314e93a529163e0fea805b8a6454/dataset_info.json
DEBUG:filelock:Attempting to release lock 139749987797904 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_openbookqa_main_0.0.0_388097ea7776314e93a529163e0fea805b8a6454.lock
DEBUG:filelock:Lock 139749987797904 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_openbookqa_main_0.0.0_388097ea7776314e93a529163e0fea805b8a6454.lock
DEBUG:filelock:Attempting to acquire lock 139750522621296 on /public/home/zouyifei001/.cache/huggingface/datasets/openbookqa/main/0.0.0/388097ea7776314e93a529163e0fea805b8a6454_builder.lock
DEBUG:filelock:Lock 139750522621296 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/openbookqa/main/0.0.0/388097ea7776314e93a529163e0fea805b8a6454_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/openbookqa/main/0.0.0/388097ea7776314e93a529163e0fea805b8a6454/dataset_info.json
DEBUG:filelock:Attempting to release lock 139750522621296 on /public/home/zouyifei001/.cache/huggingface/datasets/openbookqa/main/0.0.0/388097ea7776314e93a529163e0fea805b8a6454_builder.lock
DEBUG:filelock:Lock 139750522621296 released on /public/home/zouyifei001/.cache/huggingface/datasets/openbookqa/main/0.0.0/388097ea7776314e93a529163e0fea805b8a6454_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of openbookqa from None to 0
INFO:lm_eval.api.task:Building contexts for openbookqa on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 2753.50it/s]
DEBUG:lm_eval.evaluator:Task: openbookqa; number of requests on this rank: 400
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/400 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/400 [00:01<08:28,  1.27s/it]Running loglikelihood requests:   0%|          | 2/400 [00:02<06:22,  1.04it/s]Running loglikelihood requests:   1%|          | 3/400 [00:02<05:38,  1.17it/s]Running loglikelihood requests:   1%|          | 4/400 [00:03<05:16,  1.25it/s]Running loglikelihood requests:   1%|▏         | 5/400 [00:04<04:45,  1.38it/s]Running loglikelihood requests:   2%|▏         | 6/400 [00:04<04:26,  1.48it/s]Running loglikelihood requests:   2%|▏         | 7/400 [00:05<04:13,  1.55it/s]Running loglikelihood requests:   2%|▏         | 8/400 [00:05<04:03,  1.61it/s]Running loglikelihood requests:   2%|▏         | 9/400 [00:06<03:55,  1.66it/s]Running loglikelihood requests:   2%|▎         | 10/400 [00:06<03:50,  1.69it/s]Running loglikelihood requests:   3%|▎         | 11/400 [00:07<03:46,  1.72it/s]Running loglikelihood requests:   3%|▎         | 12/400 [00:08<03:43,  1.74it/s]Running loglikelihood requests:   3%|▎         | 13/400 [00:08<03:40,  1.76it/s]Running loglikelihood requests:   4%|▍         | 15/400 [00:09<02:47,  2.30it/s]Running loglikelihood requests:   4%|▍         | 16/400 [00:09<02:58,  2.15it/s]Running loglikelihood requests:   4%|▍         | 17/400 [00:10<03:06,  2.05it/s]Running loglikelihood requests:   4%|▍         | 18/400 [00:10<03:11,  1.99it/s]Running loglikelihood requests:   5%|▍         | 19/400 [00:11<03:15,  1.95it/s]Running loglikelihood requests:   5%|▌         | 20/400 [00:11<03:17,  1.92it/s]Running loglikelihood requests:   5%|▌         | 21/400 [00:12<03:18,  1.91it/s]Running loglikelihood requests:   6%|▌         | 22/400 [00:14<06:26,  1.02s/it]Running loglikelihood requests:   6%|▌         | 23/400 [00:15<05:30,  1.14it/s]Running loglikelihood requests:   6%|▌         | 24/400 [00:15<04:50,  1.29it/s]Running loglikelihood requests:   6%|▋         | 25/400 [00:16<04:22,  1.43it/s]Running loglikelihood requests:   6%|▋         | 26/400 [00:16<04:02,  1.54it/s]Running loglikelihood requests:   7%|▋         | 27/400 [00:17<03:47,  1.64it/s]Running loglikelihood requests:   7%|▋         | 28/400 [00:17<03:36,  1.72it/s]Running loglikelihood requests:   7%|▋         | 29/400 [00:18<03:28,  1.78it/s]Running loglikelihood requests:   8%|▊         | 33/400 [00:18<01:45,  3.48it/s]Running loglikelihood requests:   8%|▊         | 34/400 [00:19<01:59,  3.07it/s]Running loglikelihood requests:   9%|▉         | 35/400 [00:19<02:11,  2.78it/s]Running loglikelihood requests:   9%|▉         | 36/400 [00:20<02:21,  2.57it/s]Running loglikelihood requests:   9%|▉         | 37/400 [00:20<02:30,  2.41it/s]Running loglikelihood requests:  10%|▉         | 38/400 [00:21<02:37,  2.31it/s]Running loglikelihood requests:  10%|▉         | 39/400 [00:21<02:41,  2.24it/s]Running loglikelihood requests:  10%|█         | 40/400 [00:22<02:44,  2.19it/s]Running loglikelihood requests:  10%|█         | 41/400 [00:22<02:46,  2.16it/s]Running loglikelihood requests:  10%|█         | 42/400 [00:23<02:47,  2.14it/s]Running loglikelihood requests:  11%|█         | 43/400 [00:23<02:47,  2.13it/s]Running loglikelihood requests:  11%|█         | 44/400 [00:24<02:47,  2.12it/s]Running loglikelihood requests:  11%|█▏        | 45/400 [00:24<02:47,  2.12it/s]Running loglikelihood requests:  12%|█▏        | 46/400 [00:25<02:47,  2.11it/s]Running loglikelihood requests:  12%|█▏        | 47/400 [00:25<02:46,  2.12it/s]Running loglikelihood requests:  12%|█▏        | 48/400 [00:26<02:46,  2.12it/s]Running loglikelihood requests:  12%|█▏        | 49/400 [00:26<02:45,  2.12it/s]Running loglikelihood requests:  12%|█▎        | 50/400 [00:26<02:44,  2.12it/s]Running loglikelihood requests:  13%|█▎        | 51/400 [00:27<02:44,  2.13it/s]Running loglikelihood requests:  13%|█▎        | 52/400 [00:27<02:43,  2.13it/s]Running loglikelihood requests:  13%|█▎        | 53/400 [00:28<02:42,  2.13it/s]Running loglikelihood requests:  14%|█▎        | 54/400 [00:28<02:41,  2.14it/s]Running loglikelihood requests:  14%|█▍        | 55/400 [00:29<02:40,  2.14it/s]Running loglikelihood requests:  14%|█▍        | 57/400 [00:29<02:02,  2.79it/s]Running loglikelihood requests:  15%|█▌        | 60/400 [00:30<01:27,  3.89it/s]Running loglikelihood requests:  15%|█▌        | 61/400 [00:30<01:40,  3.38it/s]Running loglikelihood requests:  16%|█▌        | 62/400 [00:31<01:52,  3.02it/s]Running loglikelihood requests:  16%|█▌        | 63/400 [00:31<02:01,  2.76it/s]Running loglikelihood requests:  16%|█▌        | 64/400 [00:32<02:09,  2.59it/s]Running loglikelihood requests:  16%|█▋        | 65/400 [00:32<02:15,  2.46it/s]Running loglikelihood requests:  16%|█▋        | 66/400 [00:32<02:20,  2.38it/s]Running loglikelihood requests:  17%|█▋        | 67/400 [00:33<02:23,  2.32it/s]Running loglikelihood requests:  17%|█▋        | 68/400 [00:33<02:25,  2.28it/s]Running loglikelihood requests:  17%|█▋        | 69/400 [00:34<02:26,  2.26it/s]Running loglikelihood requests:  18%|█▊        | 70/400 [00:34<02:27,  2.24it/s]Running loglikelihood requests:  18%|█▊        | 71/400 [00:35<02:27,  2.23it/s]Running loglikelihood requests:  18%|█▊        | 72/400 [00:35<02:27,  2.22it/s]Running loglikelihood requests:  18%|█▊        | 73/400 [00:36<02:27,  2.21it/s]Running loglikelihood requests:  18%|█▊        | 74/400 [00:36<02:27,  2.21it/s]Running loglikelihood requests:  19%|█▉        | 75/400 [00:37<02:27,  2.21it/s]Running loglikelihood requests:  19%|█▉        | 76/400 [00:37<02:27,  2.20it/s]Running loglikelihood requests:  19%|█▉        | 77/400 [00:37<02:26,  2.20it/s]Running loglikelihood requests:  20%|█▉        | 78/400 [00:38<02:26,  2.20it/s]Running loglikelihood requests:  20%|█▉        | 79/400 [00:38<02:25,  2.20it/s]Running loglikelihood requests:  20%|██        | 81/400 [00:39<01:51,  2.87it/s]Running loglikelihood requests:  20%|██        | 82/400 [00:39<01:59,  2.67it/s]Running loglikelihood requests:  21%|██        | 83/400 [00:40<02:05,  2.53it/s]Running loglikelihood requests:  21%|██        | 84/400 [00:40<02:09,  2.44it/s]Running loglikelihood requests:  22%|██▏       | 86/400 [00:41<01:44,  3.01it/s]Running loglikelihood requests:  22%|██▏       | 87/400 [00:41<01:51,  2.80it/s]Running loglikelihood requests:  22%|██▏       | 88/400 [00:42<01:57,  2.65it/s]Running loglikelihood requests:  22%|██▏       | 89/400 [00:42<02:02,  2.54it/s]Running loglikelihood requests:  22%|██▎       | 90/400 [00:42<02:05,  2.47it/s]Running loglikelihood requests:  23%|██▎       | 91/400 [00:43<02:07,  2.42it/s]Running loglikelihood requests:  23%|██▎       | 92/400 [00:43<02:08,  2.39it/s]Running loglikelihood requests:  23%|██▎       | 93/400 [00:44<02:09,  2.37it/s]Running loglikelihood requests:  24%|██▎       | 94/400 [00:44<02:10,  2.35it/s]Running loglikelihood requests:  24%|██▍       | 95/400 [00:45<02:10,  2.33it/s]Running loglikelihood requests:  24%|██▍       | 96/400 [00:45<02:10,  2.32it/s]Running loglikelihood requests:  24%|██▍       | 97/400 [00:45<02:11,  2.31it/s]Running loglikelihood requests:  24%|██▍       | 98/400 [00:46<02:10,  2.31it/s]Running loglikelihood requests:  25%|██▍       | 99/400 [00:46<02:10,  2.31it/s]Running loglikelihood requests:  25%|██▌       | 100/400 [00:47<02:10,  2.30it/s]Running loglikelihood requests:  25%|██▌       | 101/400 [00:47<02:09,  2.31it/s]Running loglikelihood requests:  26%|██▌       | 102/400 [00:48<02:08,  2.31it/s]Running loglikelihood requests:  26%|██▌       | 103/400 [00:48<02:07,  2.32it/s]Running loglikelihood requests:  26%|██▋       | 106/400 [00:48<01:18,  3.73it/s]Running loglikelihood requests:  27%|██▋       | 107/400 [00:49<01:28,  3.31it/s]Running loglikelihood requests:  27%|██▋       | 108/400 [00:49<01:36,  3.02it/s]Running loglikelihood requests:  27%|██▋       | 109/400 [00:50<01:43,  2.81it/s]Running loglikelihood requests:  28%|██▊       | 110/400 [00:50<01:48,  2.66it/s]Running loglikelihood requests:  28%|██▊       | 111/400 [00:51<01:52,  2.56it/s]Running loglikelihood requests:  28%|██▊       | 112/400 [00:51<01:55,  2.49it/s]Running loglikelihood requests:  28%|██▊       | 113/400 [00:51<01:57,  2.44it/s]Running loglikelihood requests:  28%|██▊       | 114/400 [00:52<01:59,  2.40it/s]Running loglikelihood requests:  29%|██▉       | 115/400 [00:52<01:59,  2.39it/s]Running loglikelihood requests:  29%|██▉       | 116/400 [00:53<01:58,  2.39it/s]Running loglikelihood requests:  29%|██▉       | 117/400 [00:53<01:58,  2.39it/s]Running loglikelihood requests:  30%|██▉       | 118/400 [00:54<01:58,  2.38it/s]Running loglikelihood requests:  30%|██▉       | 119/400 [00:54<01:57,  2.38it/s]Running loglikelihood requests:  30%|███       | 120/400 [00:54<01:58,  2.37it/s]Running loglikelihood requests:  30%|███       | 121/400 [00:55<01:57,  2.37it/s]Running loglikelihood requests:  30%|███       | 122/400 [00:55<01:57,  2.37it/s]Running loglikelihood requests:  31%|███       | 123/400 [00:56<01:57,  2.36it/s]Running loglikelihood requests:  31%|███       | 124/400 [00:56<01:56,  2.36it/s]Running loglikelihood requests:  31%|███▏      | 125/400 [00:57<01:56,  2.36it/s]Running loglikelihood requests:  32%|███▏      | 126/400 [00:57<01:59,  2.30it/s]Running loglikelihood requests:  32%|███▏      | 127/400 [00:57<01:58,  2.31it/s]Running loglikelihood requests:  32%|███▏      | 128/400 [00:58<01:59,  2.27it/s]Running loglikelihood requests:  32%|███▏      | 129/400 [00:58<01:58,  2.28it/s]Running loglikelihood requests:  32%|███▎      | 130/400 [00:59<01:57,  2.31it/s]Running loglikelihood requests:  33%|███▎      | 131/400 [00:59<01:55,  2.32it/s]Running loglikelihood requests:  33%|███▎      | 132/400 [01:00<01:57,  2.29it/s]Running loglikelihood requests:  33%|███▎      | 133/400 [01:00<01:56,  2.30it/s]Running loglikelihood requests:  34%|███▎      | 134/400 [01:00<01:55,  2.31it/s]Running loglikelihood requests:  34%|███▍      | 138/400 [01:01<00:59,  4.38it/s]Running loglikelihood requests:  35%|███▍      | 139/400 [01:01<01:09,  3.76it/s]Running loglikelihood requests:  35%|███▌      | 140/400 [01:02<01:19,  3.27it/s]Running loglikelihood requests:  35%|███▌      | 141/400 [01:02<01:26,  2.98it/s]Running loglikelihood requests:  36%|███▌      | 142/400 [01:03<01:36,  2.67it/s]Running loglikelihood requests:  36%|███▌      | 143/400 [01:03<01:39,  2.57it/s]Running loglikelihood requests:  36%|███▌      | 144/400 [01:04<01:42,  2.50it/s]Running loglikelihood requests:  36%|███▋      | 145/400 [01:04<01:44,  2.44it/s]Running loglikelihood requests:  37%|███▋      | 147/400 [01:04<01:21,  3.09it/s]Running loglikelihood requests:  37%|███▋      | 148/400 [01:05<01:27,  2.87it/s]Running loglikelihood requests:  37%|███▋      | 149/400 [01:05<01:32,  2.71it/s]Running loglikelihood requests:  38%|███▊      | 151/400 [01:06<01:15,  3.30it/s]Running loglikelihood requests:  38%|███▊      | 152/400 [01:06<01:22,  3.01it/s]Running loglikelihood requests:  38%|███▊      | 153/400 [01:07<01:27,  2.81it/s]Running loglikelihood requests:  38%|███▊      | 154/400 [01:07<01:32,  2.67it/s]Running loglikelihood requests:  39%|███▉      | 155/400 [01:07<01:35,  2.57it/s]Running loglikelihood requests:  39%|███▉      | 156/400 [01:08<01:37,  2.51it/s]Running loglikelihood requests:  39%|███▉      | 157/400 [01:08<01:38,  2.46it/s]Running loglikelihood requests:  40%|███▉      | 158/400 [01:09<01:39,  2.43it/s]Running loglikelihood requests:  40%|███▉      | 159/400 [01:09<01:40,  2.41it/s]Running loglikelihood requests:  40%|████      | 160/400 [01:10<01:41,  2.35it/s]Running loglikelihood requests:  40%|████      | 161/400 [01:10<01:41,  2.36it/s]Running loglikelihood requests:  40%|████      | 162/400 [01:10<01:40,  2.36it/s]Running loglikelihood requests:  41%|████      | 163/400 [01:11<01:39,  2.37it/s]Running loglikelihood requests:  42%|████▏     | 166/400 [01:11<01:01,  3.79it/s]Running loglikelihood requests:  42%|████▏     | 167/400 [01:12<01:08,  3.38it/s]Running loglikelihood requests:  43%|████▎     | 171/400 [01:12<00:43,  5.24it/s]Running loglikelihood requests:  43%|████▎     | 172/400 [01:13<00:52,  4.34it/s]Running loglikelihood requests:  43%|████▎     | 173/400 [01:13<01:00,  3.73it/s]Running loglikelihood requests:  44%|████▎     | 174/400 [01:13<01:08,  3.31it/s]Running loglikelihood requests:  44%|████▍     | 175/400 [01:14<01:14,  3.03it/s]Running loglikelihood requests:  44%|████▍     | 176/400 [01:14<01:19,  2.83it/s]Running loglikelihood requests:  44%|████▍     | 177/400 [01:15<01:22,  2.69it/s]Running loglikelihood requests:  44%|████▍     | 178/400 [01:15<01:25,  2.60it/s]Running loglikelihood requests:  45%|████▍     | 179/400 [01:16<01:27,  2.51it/s]Running loglikelihood requests:  45%|████▌     | 180/400 [01:16<01:29,  2.47it/s]Running loglikelihood requests:  45%|████▌     | 181/400 [01:16<01:30,  2.43it/s]Running loglikelihood requests:  46%|████▌     | 182/400 [01:17<01:30,  2.40it/s]Running loglikelihood requests:  46%|████▌     | 183/400 [01:17<01:31,  2.38it/s]Running loglikelihood requests:  46%|████▌     | 184/400 [01:18<01:30,  2.39it/s]Running loglikelihood requests:  46%|████▋     | 185/400 [01:18<01:30,  2.38it/s]Running loglikelihood requests:  46%|████▋     | 186/400 [01:18<01:29,  2.38it/s]Running loglikelihood requests:  47%|████▋     | 187/400 [01:19<01:29,  2.38it/s]Running loglikelihood requests:  47%|████▋     | 188/400 [01:19<01:29,  2.38it/s]Running loglikelihood requests:  48%|████▊     | 190/400 [01:20<01:07,  3.10it/s]Running loglikelihood requests:  48%|████▊     | 192/400 [01:20<00:57,  3.60it/s]Running loglikelihood requests:  48%|████▊     | 193/400 [01:21<01:04,  3.23it/s]Running loglikelihood requests:  48%|████▊     | 194/400 [01:21<01:09,  2.97it/s]Running loglikelihood requests:  49%|████▉     | 195/400 [01:21<01:13,  2.80it/s]Running loglikelihood requests:  49%|████▉     | 196/400 [01:22<01:16,  2.67it/s]Running loglikelihood requests:  49%|████▉     | 197/400 [01:22<01:18,  2.58it/s]Running loglikelihood requests:  50%|████▉     | 198/400 [01:23<01:20,  2.51it/s]Running loglikelihood requests:  50%|█████     | 202/400 [01:23<00:42,  4.63it/s]Running loglikelihood requests:  51%|█████     | 203/400 [01:24<00:49,  3.97it/s]Running loglikelihood requests:  51%|█████     | 204/400 [01:24<00:55,  3.53it/s]Running loglikelihood requests:  51%|█████▏    | 205/400 [01:24<01:00,  3.22it/s]Running loglikelihood requests:  52%|█████▏    | 206/400 [01:25<01:05,  2.98it/s]Running loglikelihood requests:  52%|█████▏    | 207/400 [01:25<01:08,  2.81it/s]Running loglikelihood requests:  52%|█████▏    | 209/400 [01:26<00:55,  3.44it/s]Running loglikelihood requests:  52%|█████▎    | 210/400 [01:26<01:00,  3.14it/s]Running loglikelihood requests:  53%|█████▎    | 211/400 [01:26<01:04,  2.92it/s]Running loglikelihood requests:  53%|█████▎    | 212/400 [01:27<01:08,  2.76it/s]Running loglikelihood requests:  53%|█████▎    | 213/400 [01:27<01:10,  2.65it/s]Running loglikelihood requests:  54%|█████▎    | 214/400 [01:28<01:12,  2.58it/s]Running loglikelihood requests:  54%|█████▍    | 215/400 [01:28<01:13,  2.52it/s]Running loglikelihood requests:  54%|█████▍    | 216/400 [01:28<01:13,  2.50it/s]Running loglikelihood requests:  54%|█████▍    | 217/400 [01:29<01:13,  2.49it/s]Running loglikelihood requests:  55%|█████▍    | 218/400 [01:29<01:13,  2.47it/s]Running loglikelihood requests:  55%|█████▍    | 219/400 [01:30<01:13,  2.46it/s]Running loglikelihood requests:  55%|█████▌    | 220/400 [01:30<01:13,  2.44it/s]Running loglikelihood requests:  55%|█████▌    | 221/400 [01:31<01:13,  2.44it/s]Running loglikelihood requests:  56%|█████▌    | 222/400 [01:31<01:12,  2.44it/s]Running loglikelihood requests:  56%|█████▌    | 223/400 [01:31<01:12,  2.44it/s]Running loglikelihood requests:  56%|█████▌    | 224/400 [01:32<01:11,  2.46it/s]Running loglikelihood requests:  56%|█████▋    | 225/400 [01:32<01:11,  2.46it/s]Running loglikelihood requests:  56%|█████▋    | 226/400 [01:33<01:10,  2.46it/s]Running loglikelihood requests:  57%|█████▋    | 227/400 [01:33<01:10,  2.46it/s]Running loglikelihood requests:  57%|█████▋    | 228/400 [01:33<01:09,  2.48it/s]Running loglikelihood requests:  57%|█████▋    | 229/400 [01:34<01:08,  2.49it/s]Running loglikelihood requests:  57%|█████▊    | 230/400 [01:34<01:08,  2.48it/s]Running loglikelihood requests:  58%|█████▊    | 231/400 [01:35<01:08,  2.47it/s]Running loglikelihood requests:  58%|█████▊    | 232/400 [01:35<01:07,  2.48it/s]Running loglikelihood requests:  58%|█████▊    | 233/400 [01:35<01:07,  2.48it/s]Running loglikelihood requests:  58%|█████▊    | 234/400 [01:36<01:07,  2.48it/s]Running loglikelihood requests:  59%|█████▉    | 235/400 [01:36<01:06,  2.48it/s]Running loglikelihood requests:  59%|█████▉    | 237/400 [01:37<00:50,  3.23it/s]Running loglikelihood requests:  60%|█████▉    | 239/400 [01:37<00:42,  3.77it/s]Running loglikelihood requests:  60%|██████    | 240/400 [01:37<00:48,  3.33it/s]Running loglikelihood requests:  60%|██████    | 241/400 [01:38<00:52,  3.03it/s]Running loglikelihood requests:  60%|██████    | 242/400 [01:38<00:54,  2.87it/s]Running loglikelihood requests:  61%|██████    | 243/400 [01:39<00:57,  2.73it/s]Running loglikelihood requests:  61%|██████    | 244/400 [01:39<00:58,  2.68it/s]Running loglikelihood requests:  61%|██████▏   | 245/400 [01:39<00:58,  2.65it/s]Running loglikelihood requests:  62%|██████▏   | 246/400 [01:40<00:58,  2.61it/s]Running loglikelihood requests:  62%|██████▏   | 247/400 [01:40<00:59,  2.59it/s]Running loglikelihood requests:  62%|██████▏   | 248/400 [01:41<00:58,  2.58it/s]Running loglikelihood requests:  62%|██████▏   | 249/400 [01:41<00:58,  2.59it/s]Running loglikelihood requests:  62%|██████▎   | 250/400 [01:41<00:57,  2.59it/s]Running loglikelihood requests:  63%|██████▎   | 251/400 [01:42<00:59,  2.53it/s]Running loglikelihood requests:  63%|██████▎   | 252/400 [01:42<00:58,  2.51it/s]Running loglikelihood requests:  63%|██████▎   | 253/400 [01:43<00:58,  2.50it/s]Running loglikelihood requests:  64%|██████▎   | 254/400 [01:43<00:58,  2.51it/s]Running loglikelihood requests:  64%|██████▍   | 255/400 [01:43<00:57,  2.51it/s]Running loglikelihood requests:  64%|██████▍   | 256/400 [01:44<00:56,  2.54it/s]Running loglikelihood requests:  64%|██████▍   | 257/400 [01:44<00:56,  2.53it/s]Running loglikelihood requests:  64%|██████▍   | 258/400 [01:45<00:56,  2.53it/s]Running loglikelihood requests:  65%|██████▍   | 259/400 [01:45<00:55,  2.53it/s]Running loglikelihood requests:  65%|██████▌   | 260/400 [01:45<00:55,  2.52it/s]Running loglikelihood requests:  65%|██████▌   | 261/400 [01:46<00:55,  2.52it/s]Running loglikelihood requests:  66%|██████▌   | 262/400 [01:46<00:54,  2.52it/s]Running loglikelihood requests:  66%|██████▌   | 263/400 [01:47<00:53,  2.54it/s]Running loglikelihood requests:  66%|██████▋   | 265/400 [01:47<00:40,  3.32it/s]Running loglikelihood requests:  66%|██████▋   | 266/400 [01:47<00:43,  3.10it/s]Running loglikelihood requests:  67%|██████▋   | 267/400 [01:48<00:45,  2.92it/s]Running loglikelihood requests:  67%|██████▋   | 268/400 [01:48<00:47,  2.79it/s]Running loglikelihood requests:  67%|██████▋   | 269/400 [01:49<00:48,  2.71it/s]Running loglikelihood requests:  68%|██████▊   | 270/400 [01:49<00:48,  2.69it/s]Running loglikelihood requests:  68%|██████▊   | 271/400 [01:49<00:48,  2.64it/s]Running loglikelihood requests:  68%|██████▊   | 272/400 [01:50<00:49,  2.61it/s]Running loglikelihood requests:  68%|██████▊   | 273/400 [01:50<00:48,  2.62it/s]Running loglikelihood requests:  68%|██████▊   | 274/400 [01:50<00:48,  2.58it/s]Running loglikelihood requests:  69%|██████▉   | 275/400 [01:51<00:48,  2.56it/s]Running loglikelihood requests:  69%|██████▉   | 276/400 [01:51<00:48,  2.56it/s]Running loglikelihood requests:  69%|██████▉   | 277/400 [01:52<00:48,  2.55it/s]Running loglikelihood requests:  70%|██████▉   | 278/400 [01:52<00:47,  2.56it/s]Running loglikelihood requests:  70%|██████▉   | 279/400 [01:52<00:47,  2.55it/s]Running loglikelihood requests:  70%|███████   | 280/400 [01:53<00:47,  2.55it/s]Running loglikelihood requests:  70%|███████   | 281/400 [01:53<00:46,  2.57it/s]Running loglikelihood requests:  70%|███████   | 282/400 [01:54<00:45,  2.57it/s]Running loglikelihood requests:  71%|███████   | 283/400 [01:54<00:45,  2.59it/s]Running loglikelihood requests:  71%|███████   | 284/400 [01:54<00:44,  2.60it/s]Running loglikelihood requests:  71%|███████▏  | 285/400 [01:55<00:44,  2.60it/s]Running loglikelihood requests:  72%|███████▏  | 286/400 [01:55<00:43,  2.61it/s]Running loglikelihood requests:  72%|███████▏  | 287/400 [01:56<00:43,  2.60it/s]Running loglikelihood requests:  72%|███████▏  | 288/400 [01:56<00:42,  2.61it/s]Running loglikelihood requests:  72%|███████▏  | 289/400 [01:56<00:42,  2.62it/s]Running loglikelihood requests:  72%|███████▎  | 290/400 [01:57<00:41,  2.64it/s]Running loglikelihood requests:  73%|███████▎  | 291/400 [01:57<00:41,  2.65it/s]Running loglikelihood requests:  73%|███████▎  | 292/400 [01:57<00:40,  2.64it/s]Running loglikelihood requests:  73%|███████▎  | 293/400 [01:58<00:40,  2.63it/s]Running loglikelihood requests:  74%|███████▎  | 294/400 [01:58<00:40,  2.62it/s]Running loglikelihood requests:  74%|███████▍  | 297/400 [01:59<00:24,  4.23it/s]Running loglikelihood requests:  74%|███████▍  | 298/400 [01:59<00:27,  3.71it/s]Running loglikelihood requests:  75%|███████▍  | 299/400 [01:59<00:30,  3.36it/s]Running loglikelihood requests:  75%|███████▌  | 300/400 [02:00<00:31,  3.14it/s]Running loglikelihood requests:  75%|███████▌  | 301/400 [02:00<00:33,  2.98it/s]Running loglikelihood requests:  76%|███████▌  | 302/400 [02:00<00:34,  2.86it/s]Running loglikelihood requests:  76%|███████▌  | 303/400 [02:01<00:35,  2.76it/s]Running loglikelihood requests:  77%|███████▋  | 307/400 [02:01<00:18,  5.03it/s]Running loglikelihood requests:  77%|███████▋  | 308/400 [02:02<00:21,  4.31it/s]Running loglikelihood requests:  77%|███████▋  | 309/400 [02:02<00:23,  3.82it/s]Running loglikelihood requests:  78%|███████▊  | 310/400 [02:02<00:26,  3.46it/s]Running loglikelihood requests:  78%|███████▊  | 311/400 [02:03<00:27,  3.21it/s]Running loglikelihood requests:  78%|███████▊  | 312/400 [02:03<00:29,  3.02it/s]Running loglikelihood requests:  78%|███████▊  | 313/400 [02:04<00:30,  2.88it/s]Running loglikelihood requests:  78%|███████▊  | 314/400 [02:04<00:30,  2.80it/s]Running loglikelihood requests:  79%|███████▉  | 315/400 [02:04<00:30,  2.75it/s]Running loglikelihood requests:  79%|███████▉  | 316/400 [02:05<00:30,  2.74it/s]Running loglikelihood requests:  79%|███████▉  | 317/400 [02:05<00:30,  2.72it/s]Running loglikelihood requests:  80%|███████▉  | 318/400 [02:05<00:30,  2.69it/s]Running loglikelihood requests:  80%|████████  | 321/400 [02:06<00:18,  4.29it/s]Running loglikelihood requests:  80%|████████  | 322/400 [02:06<00:20,  3.80it/s]Running loglikelihood requests:  81%|████████  | 323/400 [02:07<00:22,  3.47it/s]Running loglikelihood requests:  81%|████████  | 324/400 [02:07<00:23,  3.25it/s]Running loglikelihood requests:  81%|████████▏ | 325/400 [02:07<00:24,  3.07it/s]Running loglikelihood requests:  82%|████████▏ | 326/400 [02:08<00:25,  2.95it/s]Running loglikelihood requests:  82%|████████▏ | 327/400 [02:08<00:25,  2.86it/s]Running loglikelihood requests:  82%|████████▏ | 328/400 [02:08<00:25,  2.82it/s]Running loglikelihood requests:  82%|████████▏ | 329/400 [02:09<00:25,  2.77it/s]Running loglikelihood requests:  82%|████████▎ | 330/400 [02:09<00:25,  2.72it/s]Running loglikelihood requests:  83%|████████▎ | 331/400 [02:10<00:25,  2.73it/s]Running loglikelihood requests:  83%|████████▎ | 332/400 [02:10<00:25,  2.70it/s]Running loglikelihood requests:  83%|████████▎ | 333/400 [02:10<00:24,  2.75it/s]Running loglikelihood requests:  84%|████████▎ | 334/400 [02:11<00:24,  2.66it/s]Running loglikelihood requests:  84%|████████▍ | 336/400 [02:11<00:18,  3.50it/s]Running loglikelihood requests:  84%|████████▍ | 337/400 [02:11<00:19,  3.28it/s]Running loglikelihood requests:  84%|████████▍ | 338/400 [02:12<00:19,  3.14it/s]Running loglikelihood requests:  85%|████████▍ | 339/400 [02:12<00:20,  3.01it/s]Running loglikelihood requests:  85%|████████▌ | 340/400 [02:12<00:20,  2.93it/s]Running loglikelihood requests:  85%|████████▌ | 341/400 [02:13<00:20,  2.87it/s]Running loglikelihood requests:  86%|████████▌ | 342/400 [02:13<00:20,  2.82it/s]Running loglikelihood requests:  86%|████████▌ | 343/400 [02:14<00:20,  2.77it/s]Running loglikelihood requests:  86%|████████▌ | 344/400 [02:14<00:20,  2.76it/s]Running loglikelihood requests:  86%|████████▋ | 345/400 [02:14<00:19,  2.77it/s]Running loglikelihood requests:  86%|████████▋ | 346/400 [02:15<00:18,  2.85it/s]Running loglikelihood requests:  87%|████████▋ | 347/400 [02:15<00:18,  2.82it/s]Running loglikelihood requests:  87%|████████▋ | 348/400 [02:15<00:18,  2.79it/s]Running loglikelihood requests:  87%|████████▋ | 349/400 [02:16<00:18,  2.80it/s]Running loglikelihood requests:  88%|████████▊ | 350/400 [02:16<00:17,  2.79it/s]Running loglikelihood requests:  88%|████████▊ | 351/400 [02:16<00:17,  2.79it/s]Running loglikelihood requests:  88%|████████▊ | 352/400 [02:17<00:16,  2.84it/s]Running loglikelihood requests:  88%|████████▊ | 353/400 [02:17<00:16,  2.88it/s]Running loglikelihood requests:  88%|████████▊ | 354/400 [02:17<00:16,  2.85it/s]Running loglikelihood requests:  89%|████████▉ | 355/400 [02:18<00:15,  2.82it/s]Running loglikelihood requests:  89%|████████▉ | 356/400 [02:18<00:15,  2.85it/s]Running loglikelihood requests:  89%|████████▉ | 357/400 [02:19<00:15,  2.83it/s]Running loglikelihood requests:  90%|████████▉ | 358/400 [02:19<00:14,  2.83it/s]Running loglikelihood requests:  90%|████████▉ | 359/400 [02:19<00:14,  2.84it/s]Running loglikelihood requests:  90%|█████████ | 360/400 [02:20<00:13,  2.87it/s]Running loglikelihood requests:  91%|█████████ | 363/400 [02:20<00:08,  4.59it/s]Running loglikelihood requests:  91%|█████████ | 364/400 [02:20<00:08,  4.05it/s]Running loglikelihood requests:  91%|█████████▏| 365/400 [02:21<00:09,  3.72it/s]Running loglikelihood requests:  92%|█████████▏| 366/400 [02:21<00:09,  3.50it/s]Running loglikelihood requests:  92%|█████████▏| 367/400 [02:21<00:09,  3.35it/s]Running loglikelihood requests:  92%|█████████▏| 368/400 [02:22<00:10,  3.11it/s]Running loglikelihood requests:  92%|█████████▏| 369/400 [02:22<00:10,  3.00it/s]Running loglikelihood requests:  92%|█████████▎| 370/400 [02:22<00:10,  2.95it/s]Running loglikelihood requests:  93%|█████████▎| 371/400 [02:23<00:09,  2.94it/s]Running loglikelihood requests:  93%|█████████▎| 372/400 [02:23<00:09,  2.96it/s]Running loglikelihood requests:  93%|█████████▎| 373/400 [02:23<00:09,  2.96it/s]Running loglikelihood requests:  94%|█████████▎| 374/400 [02:24<00:08,  2.93it/s]Running loglikelihood requests:  94%|█████████▍| 377/400 [02:24<00:04,  4.74it/s]Running loglikelihood requests:  94%|█████████▍| 378/400 [02:24<00:05,  4.22it/s]Running loglikelihood requests:  95%|█████████▍| 379/400 [02:25<00:05,  3.83it/s]Running loglikelihood requests:  95%|█████████▌| 380/400 [02:25<00:05,  3.60it/s]Running loglikelihood requests:  95%|█████████▌| 381/400 [02:25<00:05,  3.45it/s]Running loglikelihood requests:  96%|█████████▌| 382/400 [02:26<00:05,  3.33it/s]Running loglikelihood requests:  96%|█████████▌| 383/400 [02:26<00:05,  3.23it/s]Running loglikelihood requests:  96%|█████████▌| 384/400 [02:26<00:05,  3.16it/s]Running loglikelihood requests:  97%|█████████▋| 387/400 [02:27<00:02,  4.93it/s]Running loglikelihood requests:  97%|█████████▋| 388/400 [02:27<00:02,  4.37it/s]Running loglikelihood requests:  98%|█████████▊| 390/400 [02:27<00:02,  4.82it/s]Running loglikelihood requests:  98%|█████████▊| 391/400 [02:28<00:02,  4.34it/s]Running loglikelihood requests:  98%|█████████▊| 392/400 [02:28<00:02,  3.99it/s]Running loglikelihood requests:  98%|█████████▊| 393/400 [02:28<00:01,  3.83it/s]Running loglikelihood requests:  98%|█████████▊| 394/400 [02:29<00:01,  3.59it/s]Running loglikelihood requests:  99%|█████████▉| 395/400 [02:29<00:01,  3.32it/s]Running loglikelihood requests:  99%|█████████▉| 396/400 [02:29<00:01,  3.31it/s]Running loglikelihood requests: 100%|█████████▉| 398/400 [02:30<00:00,  4.28it/s]Running loglikelihood requests: 100%|█████████▉| 399/400 [02:30<00:00,  4.22it/s]Running loglikelihood requests: 100%|██████████| 400/400 [02:30<00:00,  2.66it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:3'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:3'}
full model:
{'openbookqa': {'alias': 'openbookqa', 'acc,none': 0.25, 'acc_stderr,none': 0.04351941398892446, 'acc_norm,none': 0.39, 'acc_norm_stderr,none': 0.04902071300001973}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.7187319796021299
0.7542307644255121
0.9218102409329888
0.9507846064925026
0.9244473932111009
0.9697851265705995
0.9088369054586506
0.9555908644563589
0.6065244449438403
0.8380982140772407
0.9227293008726757
0.940339967265193
0.8763319017557598
0.8956221731459367
0.8537768995934096
0.9486125995141542
0.9673324054839537
0.9137514724447725
0.9379677722073356
0.9822722776537973
0.9198472199854921
0.886666948473494
0.9000260607563779
0.9759633945879138
0.9869744580755335
Total groups 76 exceeded the threshold, stopping comparison.
The group tensor is
[6, 2, 3, 1, 5, 4, 7, 0]
tensor([6, 2, 3, 1, 5, 4, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 2, 3, 1, 4, 5, 7, 0]
tensor([6, 2, 3, 1, 4, 5, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 2, 3, 1, 4, 5, 7, 0]
tensor([6, 2, 3, 1, 4, 5, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 5, 2, 4, 3, 7, 0]
tensor([6, 1, 5, 2, 4, 3, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 1, 3, 2, 5, 4, 6, 0]
tensor([7, 1, 3, 2, 5, 4, 6, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 2, 3, 1, 5, 4, 7, 0]
tensor([6, 2, 3, 1, 5, 4, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1, 1.0, 1.0, 1.0, 1.0, 0]
tensor([0, 1, 1, 1, 1, 1, 1, 0], dtype=torch.int32)
[0, 1]
The group tensor is
[0, 1, 1.0, 1, 1.0, 1.0, 1.0, 0]
tensor([0, 1, 1, 1, 1, 1, 1, 0], dtype=torch.int32)
[0, 1]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
done!
Normal merging for layer 2
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
done!
Normal merging for layer 4
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
done!
Normal merging for layer 5
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 6 to 29
done!
Normal merging for layer 30
tensor([0, 7])
tensor(0)
tensor([1, 2, 3, 4, 5, 6])
tensor(1)
done!
Normal merging for layer 31
tensor([0, 7])
tensor(0)
tensor([1, 2, 3, 4, 5, 6])
tensor(1)
done!
all done!
Model size: 12.3238 GB
45
cuda:3
rte
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:42<00:42, 42.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:55<00:00, 24.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:55<00:00, 27.56s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: rte] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: rte] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/rte?recursive=False&expand=False HTTP/1.1" 307 140
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/rte?recursive=False&expand=False HTTP/1.1" 200 354
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:filelock:Attempting to acquire lock 139722756033328 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139722756033328 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139722756033328 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139722756033328 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139752062375104 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139752062375104 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139752062375104 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139752062375104 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of rte from None to 0
INFO:lm_eval.api.task:Building contexts for rte on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 2570.20it/s]
DEBUG:lm_eval.evaluator:Task: rte; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:01<06:32,  1.97s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:03<03:28,  1.06s/it]Running loglikelihood requests:   2%|▎         | 5/200 [00:04<02:44,  1.19it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:05<02:25,  1.33it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:07<02:14,  1.42it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:08<02:06,  1.49it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:09<02:01,  1.54it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:10<01:56,  1.59it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:11<01:51,  1.63it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:13<01:49,  1.66it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:14<01:45,  1.70it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:15<01:43,  1.72it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:16<01:40,  1.74it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:17<01:36,  1.80it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:18<01:32,  1.84it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:19<01:29,  1.88it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:20<01:27,  1.92it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:21<01:25,  1.94it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:22<01:24,  1.93it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:23<01:22,  1.94it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:24<01:21,  1.96it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:25<01:18,  2.00it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:26<01:15,  2.05it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:27<01:13,  2.08it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:28<01:10,  2.14it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:29<01:07,  2.20it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:30<01:05,  2.26it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:30<01:02,  2.32it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:31<01:00,  2.38it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:32<00:58,  2.42it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:33<00:56,  2.46it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:33<00:54,  2.49it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:34<00:53,  2.52it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:35<00:52,  2.55it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:36<00:50,  2.57it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:37<00:49,  2.59it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:37<00:48,  2.61it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:38<00:47,  2.63it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:39<00:46,  2.66it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:39<00:45,  2.68it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:40<00:44,  2.70it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:41<00:42,  2.72it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:42<00:41,  2.74it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:42<00:41,  2.75it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:43<00:39,  2.78it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:44<00:38,  2.80it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:44<00:37,  2.82it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:45<00:37,  2.83it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:46<00:36,  2.85it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:47<00:35,  2.86it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:47<00:34,  2.87it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:48<00:33,  2.89it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:49<00:32,  2.90it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:49<00:31,  2.92it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:50<00:31,  2.93it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:51<00:30,  2.95it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:51<00:29,  2.96it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:52<00:28,  2.96it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:53<00:28,  2.96it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:53<00:27,  2.95it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:54<00:26,  2.94it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:55<00:25,  2.97it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:55<00:25,  2.97it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [00:56<00:24,  2.97it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [00:57<00:23,  2.98it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [00:57<00:23,  3.00it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [00:58<00:22,  3.02it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [00:59<00:21,  3.06it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [00:59<00:20,  3.08it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [01:00<00:19,  3.10it/s]Running loglikelihood requests:  70%|███████   | 141/200 [01:01<00:18,  3.11it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [01:01<00:18,  3.13it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [01:02<00:17,  3.15it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [01:02<00:16,  3.16it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [01:03<00:16,  3.17it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [01:04<00:15,  3.18it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [01:04<00:14,  3.19it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [01:05<00:14,  3.20it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [01:06<00:13,  3.22it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [01:06<00:12,  3.25it/s]Running loglikelihood requests:  80%|████████  | 161/200 [01:07<00:11,  3.27it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [01:07<00:11,  3.28it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [01:08<00:10,  3.28it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [01:09<00:10,  3.27it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [01:09<00:09,  3.29it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [01:10<00:08,  3.31it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [01:10<00:08,  3.32it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [01:11<00:07,  3.33it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [01:12<00:06,  3.34it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [01:12<00:06,  3.35it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [01:13<00:05,  3.36it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [01:13<00:05,  3.37it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [01:14<00:04,  3.38it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [01:14<00:03,  3.41it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [01:15<00:03,  3.42it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [01:16<00:02,  3.43it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [01:16<00:02,  3.43it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:17<00:01,  3.49it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:17<00:00,  3.58it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:18<00:00,  3.67it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:18<00:00,  2.55it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:4'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:4'}
full model:
{'rte': {'alias': 'rte', 'acc,none': 0.5, 'acc_stderr,none': 0.050251890762960605}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.34161229456626735
0.905233410256777
0.5205040718697735
0.4121994254524892
0.7398116665887099
0.6225415196831932
0.7923970242263771
0.7353888240887675
0.6535613357308766
0.7757058271862038
0.734046359122903
0.4471799126982846
0.773619360921301
0.7955347039939479
0.8672068064531693
0.8652880343596522
0.3302235467760883
0.6789268064017625
0.6072221471952108
0.9194446824778495
0.4812004589187253
0.5728915095234594
0.1682455054057436
0.93212414632396
0.9148362604533635
0.8268537756297094
0.7592245907029287
0.7256008379011685
0.7109756105942956
0.34161229456626735
0.905233410256777
0.5205040718697735
0.4121994254524892
0.7398116665887099
0.6225415196831932
0.7923970242263771
0.7353888240887675
0.6535613357308766
0.7757058271862038
0.734046359122903
0.4471799126982846
0.773619360921301
0.7955347039939479
0.8672068064531693
0.8652880343596522
0.3302235467760883
0.6789268064017625
0.6072221471952108
0.9194446824778495
0.4812004589187253
Total groups 73 exceeded the threshold, stopping comparison.
The group tensor is
[5, 2, 7, 1, 6, 4, 3, 0]
tensor([5, 2, 7, 1, 6, 4, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 6, 0, 7, 3, 4, 1]
tensor([5, 2, 6, 0, 7, 3, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 7, 2, 5, 4, 3, 0]
tensor([6, 1, 7, 2, 5, 4, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 7, 2, 4, 1, 5, 0]
tensor([6, 3, 7, 2, 4, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 5, 6, 2, 3, 1, 4, 0]
tensor([7, 5, 6, 2, 3, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 2, 5, 4, 1, 0, 1, 3]
tensor([0, 2, 5, 4, 1, 0, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1.0, 1.0, 0, 1.0, 1]
tensor([0, 1, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
Normal merging for layer 1
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Normal merging for layer 2
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 4
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 5 to 8
done!
Normal merging for layer 9
tensor([0, 5])
tensor(0)
tensor([4, 6])
tensor(4)
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
done!
Cross-layer merge completed for layers 10 to 30
done!
Normal merging for layer 31
tensor([0, 5])
tensor(0)
tensor([1, 2, 3, 4, 6, 7])
tensor(1)
done!
all done!
Model size: 12.1348 GB
6
cuda:4
mastermind_24_easy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:43<00:43, 43.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:57<00:00, 26.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:57<00:00, 28.83s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_24_mcq_random HTTP/1.1" 200 772
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/flair/mastermind_24_mcq_random/flair/mastermind_24_mcq_random.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_24_mcq_random HTTP/1.1" 200 779
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/flair/mastermind_24_mcq_random/resolve/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_24_mcq_random/revision/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 779
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_24_mcq_random/tree/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5?recursive=False&expand=False HTTP/1.1" 200 290
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_24_mcq_random/tree/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5/data?recursive=False&expand=False HTTP/1.1" 200 358
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_24_mcq_random/revision/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 779
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/flair/mastermind_24_mcq_random/resolve/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:filelock:Attempting to acquire lock 139722742983152 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_24_mcq_random_default_0.0.0_cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5.lock
DEBUG:filelock:Lock 139722742983152 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_24_mcq_random_default_0.0.0_cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_24_mcq_random/default/0.0.0/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5/dataset_info.json
DEBUG:filelock:Attempting to release lock 139722742983152 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_24_mcq_random_default_0.0.0_cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5.lock
DEBUG:filelock:Lock 139722742983152 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_24_mcq_random_default_0.0.0_cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5.lock
DEBUG:filelock:Attempting to acquire lock 139749987800064 on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_24_mcq_random/default/0.0.0/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5_builder.lock
DEBUG:filelock:Lock 139749987800064 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_24_mcq_random/default/0.0.0/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_24_mcq_random/default/0.0.0/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5/dataset_info.json
DEBUG:filelock:Attempting to release lock 139749987800064 on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_24_mcq_random/default/0.0.0/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5_builder.lock
DEBUG:filelock:Lock 139749987800064 released on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_24_mcq_random/default/0.0.0/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mastermind_24_easy from None to 0
INFO:lm_eval.api.task:Building contexts for mastermind_24_easy on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1489.49it/s]
DEBUG:lm_eval.evaluator:Task: mastermind_24_easy; number of requests on this rank: 400
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/400 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/400 [00:01<10:22,  1.56s/it]Running loglikelihood requests:   0%|          | 2/400 [00:02<08:28,  1.28s/it]Running loglikelihood requests:   1%|          | 3/400 [00:03<07:57,  1.20s/it]Running loglikelihood requests:   1%|          | 4/400 [00:04<07:28,  1.13s/it]Running loglikelihood requests:   1%|▏         | 5/400 [00:05<07:11,  1.09s/it]Running loglikelihood requests:   2%|▏         | 6/400 [00:06<07:00,  1.07s/it]Running loglikelihood requests:   2%|▏         | 7/400 [00:07<07:00,  1.07s/it]Running loglikelihood requests:   2%|▏         | 8/400 [00:08<06:58,  1.07s/it]Running loglikelihood requests:   2%|▏         | 9/400 [00:09<06:51,  1.05s/it]Running loglikelihood requests:   2%|▎         | 10/400 [00:11<06:47,  1.04s/it]Running loglikelihood requests:   3%|▎         | 12/400 [00:12<05:13,  1.24it/s]Running loglikelihood requests:   3%|▎         | 13/400 [00:13<05:33,  1.16it/s]Running loglikelihood requests:   4%|▎         | 14/400 [00:14<05:48,  1.11it/s]Running loglikelihood requests:   4%|▍         | 16/400 [00:15<04:46,  1.34it/s]Running loglikelihood requests:   4%|▍         | 17/400 [00:16<05:13,  1.22it/s]Running loglikelihood requests:   4%|▍         | 18/400 [00:17<05:30,  1.16it/s]Running loglikelihood requests:   5%|▍         | 19/400 [00:18<05:42,  1.11it/s]Running loglikelihood requests:   5%|▌         | 20/400 [00:19<05:52,  1.08it/s]Running loglikelihood requests:   5%|▌         | 21/400 [00:20<06:00,  1.05it/s]Running loglikelihood requests:   6%|▌         | 22/400 [00:21<06:04,  1.04it/s]Running loglikelihood requests:   6%|▌         | 23/400 [00:22<06:07,  1.03it/s]Running loglikelihood requests:   6%|▋         | 25/400 [00:23<04:44,  1.32it/s]Running loglikelihood requests:   6%|▋         | 26/400 [00:24<05:05,  1.22it/s]Running loglikelihood requests:   7%|▋         | 27/400 [00:25<05:22,  1.16it/s]Running loglikelihood requests:   7%|▋         | 29/400 [00:26<04:23,  1.41it/s]Running loglikelihood requests:   8%|▊         | 30/400 [00:27<04:46,  1.29it/s]Running loglikelihood requests:   8%|▊         | 31/400 [00:28<05:05,  1.21it/s]Running loglikelihood requests:   8%|▊         | 32/400 [00:29<05:20,  1.15it/s]Running loglikelihood requests:   8%|▊         | 34/400 [00:30<04:24,  1.38it/s]Running loglikelihood requests:   9%|▉         | 35/400 [00:31<04:48,  1.27it/s]Running loglikelihood requests:  10%|▉         | 38/400 [00:32<03:22,  1.78it/s]Running loglikelihood requests:  10%|▉         | 39/400 [00:33<03:52,  1.55it/s]Running loglikelihood requests:  10%|█         | 40/400 [00:34<04:18,  1.39it/s]Running loglikelihood requests:  10%|█         | 41/400 [00:35<04:41,  1.27it/s]Running loglikelihood requests:  10%|█         | 42/400 [00:36<05:00,  1.19it/s]Running loglikelihood requests:  11%|█         | 43/400 [00:37<05:14,  1.14it/s]Running loglikelihood requests:  11%|█         | 44/400 [00:38<05:32,  1.07it/s]Running loglikelihood requests:  11%|█▏        | 45/400 [00:39<05:49,  1.02it/s]Running loglikelihood requests:  12%|█▏        | 47/400 [00:40<04:35,  1.28it/s]Running loglikelihood requests:  12%|█▏        | 48/400 [00:41<04:53,  1.20it/s]Running loglikelihood requests:  12%|█▏        | 49/400 [00:42<05:07,  1.14it/s]Running loglikelihood requests:  12%|█▎        | 50/400 [00:43<05:26,  1.07it/s]Running loglikelihood requests:  13%|█▎        | 52/400 [00:44<04:27,  1.30it/s]Running loglikelihood requests:  13%|█▎        | 53/400 [00:45<04:53,  1.18it/s]Running loglikelihood requests:  14%|█▎        | 54/400 [00:46<05:14,  1.10it/s]Running loglikelihood requests:  14%|█▍        | 56/400 [00:47<04:15,  1.35it/s]Running loglikelihood requests:  14%|█▍        | 57/400 [00:48<04:33,  1.25it/s]Running loglikelihood requests:  14%|█▍        | 58/400 [00:49<04:47,  1.19it/s]Running loglikelihood requests:  15%|█▍        | 59/400 [00:50<04:59,  1.14it/s]Running loglikelihood requests:  15%|█▌        | 60/400 [00:51<05:07,  1.11it/s]Running loglikelihood requests:  15%|█▌        | 61/400 [00:52<05:13,  1.08it/s]Running loglikelihood requests:  16%|█▌        | 62/400 [00:53<05:17,  1.06it/s]Running loglikelihood requests:  16%|█▌        | 63/400 [00:54<05:20,  1.05it/s]Running loglikelihood requests:  16%|█▌        | 64/400 [00:55<05:21,  1.05it/s]Running loglikelihood requests:  16%|█▋        | 65/400 [00:56<05:22,  1.04it/s]Running loglikelihood requests:  16%|█▋        | 66/400 [00:57<05:22,  1.04it/s]Running loglikelihood requests:  17%|█▋        | 67/400 [00:58<05:22,  1.03it/s]Running loglikelihood requests:  17%|█▋        | 68/400 [00:59<05:22,  1.03it/s]Running loglikelihood requests:  17%|█▋        | 69/400 [01:00<05:21,  1.03it/s]Running loglikelihood requests:  18%|█▊        | 70/400 [01:01<05:20,  1.03it/s]Running loglikelihood requests:  18%|█▊        | 71/400 [01:02<05:19,  1.03it/s]Running loglikelihood requests:  18%|█▊        | 72/400 [01:03<05:18,  1.03it/s]Running loglikelihood requests:  18%|█▊        | 73/400 [01:04<05:17,  1.03it/s]Running loglikelihood requests:  18%|█▊        | 74/400 [01:05<05:16,  1.03it/s]Running loglikelihood requests:  19%|█▉        | 76/400 [01:06<04:01,  1.34it/s]Running loglikelihood requests:  19%|█▉        | 77/400 [01:07<04:18,  1.25it/s]Running loglikelihood requests:  20%|█▉        | 78/400 [01:08<04:31,  1.18it/s]Running loglikelihood requests:  20%|█▉        | 79/400 [01:09<04:41,  1.14it/s]Running loglikelihood requests:  20%|██        | 80/400 [01:10<04:49,  1.11it/s]Running loglikelihood requests:  20%|██        | 81/400 [01:11<04:53,  1.09it/s]Running loglikelihood requests:  20%|██        | 82/400 [01:12<04:56,  1.07it/s]Running loglikelihood requests:  21%|██        | 83/400 [01:13<04:58,  1.06it/s]Running loglikelihood requests:  21%|██        | 84/400 [01:14<05:03,  1.04it/s]Running loglikelihood requests:  21%|██▏       | 85/400 [01:15<05:08,  1.02it/s]Running loglikelihood requests:  22%|██▏       | 87/400 [01:16<04:02,  1.29it/s]Running loglikelihood requests:  22%|██▏       | 88/400 [01:17<04:24,  1.18it/s]Running loglikelihood requests:  22%|██▏       | 89/400 [01:18<04:40,  1.11it/s]Running loglikelihood requests:  22%|██▎       | 90/400 [01:19<04:52,  1.06it/s]Running loglikelihood requests:  23%|██▎       | 91/400 [01:20<05:01,  1.03it/s]Running loglikelihood requests:  23%|██▎       | 92/400 [01:21<05:07,  1.00it/s]Running loglikelihood requests:  24%|██▎       | 94/400 [01:22<03:56,  1.30it/s]Running loglikelihood requests:  24%|██▍       | 95/400 [01:23<04:10,  1.22it/s]Running loglikelihood requests:  24%|██▍       | 96/400 [01:24<04:21,  1.16it/s]Running loglikelihood requests:  24%|██▍       | 98/400 [01:25<03:32,  1.42it/s]Running loglikelihood requests:  25%|██▌       | 100/400 [01:26<03:06,  1.61it/s]Running loglikelihood requests:  26%|██▌       | 102/400 [01:27<02:51,  1.74it/s]Running loglikelihood requests:  26%|██▌       | 103/400 [01:28<03:14,  1.53it/s]Running loglikelihood requests:  26%|██▌       | 104/400 [01:29<03:34,  1.38it/s]Running loglikelihood requests:  27%|██▋       | 107/400 [01:30<02:34,  1.89it/s]Running loglikelihood requests:  27%|██▋       | 108/400 [01:31<02:58,  1.63it/s]Running loglikelihood requests:  27%|██▋       | 109/400 [01:32<03:20,  1.45it/s]Running loglikelihood requests:  28%|██▊       | 110/400 [01:33<03:38,  1.33it/s]Running loglikelihood requests:  28%|██▊       | 111/400 [01:34<03:53,  1.24it/s]Running loglikelihood requests:  28%|██▊       | 112/400 [01:35<04:04,  1.18it/s]Running loglikelihood requests:  28%|██▊       | 113/400 [01:36<04:16,  1.12it/s]Running loglikelihood requests:  28%|██▊       | 114/400 [01:37<04:20,  1.10it/s]Running loglikelihood requests:  29%|██▉       | 116/400 [01:38<03:24,  1.39it/s]Running loglikelihood requests:  29%|██▉       | 117/400 [01:39<03:39,  1.29it/s]Running loglikelihood requests:  30%|██▉       | 118/400 [01:40<03:52,  1.22it/s]Running loglikelihood requests:  30%|███       | 121/400 [01:40<02:35,  1.79it/s]Running loglikelihood requests:  30%|███       | 122/400 [01:41<02:57,  1.57it/s]Running loglikelihood requests:  31%|███       | 123/400 [01:42<03:16,  1.41it/s]Running loglikelihood requests:  31%|███       | 124/400 [01:43<03:34,  1.29it/s]Running loglikelihood requests:  31%|███▏      | 125/400 [01:44<03:43,  1.23it/s]Running loglikelihood requests:  32%|███▏      | 126/400 [01:45<03:50,  1.19it/s]Running loglikelihood requests:  32%|███▏      | 127/400 [01:46<03:55,  1.16it/s]Running loglikelihood requests:  32%|███▏      | 128/400 [01:47<04:07,  1.10it/s]Running loglikelihood requests:  32%|███▎      | 130/400 [01:48<03:15,  1.38it/s]Running loglikelihood requests:  33%|███▎      | 132/400 [01:49<02:46,  1.61it/s]Running loglikelihood requests:  33%|███▎      | 133/400 [01:50<03:07,  1.42it/s]Running loglikelihood requests:  34%|███▎      | 134/400 [01:51<03:20,  1.33it/s]Running loglikelihood requests:  34%|███▍      | 135/400 [01:52<03:30,  1.26it/s]Running loglikelihood requests:  34%|███▍      | 136/400 [01:53<03:38,  1.21it/s]Running loglikelihood requests:  34%|███▍      | 137/400 [01:54<03:43,  1.17it/s]Running loglikelihood requests:  34%|███▍      | 138/400 [01:55<03:48,  1.15it/s]Running loglikelihood requests:  35%|███▍      | 139/400 [01:56<03:50,  1.13it/s]Running loglikelihood requests:  35%|███▌      | 140/400 [01:57<03:52,  1.12it/s]Running loglikelihood requests:  35%|███▌      | 141/400 [01:57<03:52,  1.11it/s]Running loglikelihood requests:  36%|███▌      | 142/400 [01:58<03:52,  1.11it/s]Running loglikelihood requests:  36%|███▌      | 143/400 [01:59<03:56,  1.08it/s]Running loglikelihood requests:  36%|███▋      | 145/400 [02:00<03:04,  1.38it/s]Running loglikelihood requests:  36%|███▋      | 146/400 [02:01<03:18,  1.28it/s]Running loglikelihood requests:  37%|███▋      | 147/400 [02:02<03:26,  1.22it/s]Running loglikelihood requests:  37%|███▋      | 148/400 [02:03<03:37,  1.16it/s]Running loglikelihood requests:  37%|███▋      | 149/400 [02:04<03:41,  1.13it/s]Running loglikelihood requests:  38%|███▊      | 150/400 [02:05<03:43,  1.12it/s]Running loglikelihood requests:  38%|███▊      | 152/400 [02:06<02:55,  1.42it/s]Running loglikelihood requests:  38%|███▊      | 153/400 [02:07<03:09,  1.30it/s]Running loglikelihood requests:  38%|███▊      | 154/400 [02:08<03:17,  1.24it/s]Running loglikelihood requests:  39%|███▉      | 155/400 [02:09<03:24,  1.20it/s]Running loglikelihood requests:  39%|███▉      | 157/400 [02:10<02:42,  1.49it/s]Running loglikelihood requests:  40%|███▉      | 158/400 [02:11<02:55,  1.38it/s]Running loglikelihood requests:  40%|████      | 160/400 [02:12<02:34,  1.56it/s]Running loglikelihood requests:  40%|████      | 161/400 [02:13<02:51,  1.39it/s]Running loglikelihood requests:  40%|████      | 162/400 [02:13<03:02,  1.31it/s]Running loglikelihood requests:  41%|████      | 163/400 [02:14<03:10,  1.25it/s]Running loglikelihood requests:  41%|████▏     | 165/400 [02:15<02:33,  1.53it/s]Running loglikelihood requests:  42%|████▏     | 166/400 [02:16<02:47,  1.40it/s]Running loglikelihood requests:  42%|████▏     | 167/400 [02:17<02:57,  1.31it/s]Running loglikelihood requests:  42%|████▏     | 168/400 [02:18<03:08,  1.23it/s]Running loglikelihood requests:  42%|████▎     | 170/400 [02:19<02:34,  1.49it/s]Running loglikelihood requests:  43%|████▎     | 171/400 [02:20<02:46,  1.37it/s]Running loglikelihood requests:  43%|████▎     | 172/400 [02:21<02:56,  1.29it/s]Running loglikelihood requests:  43%|████▎     | 173/400 [02:22<03:03,  1.23it/s]Running loglikelihood requests:  44%|████▎     | 174/400 [02:23<03:09,  1.19it/s]Running loglikelihood requests:  44%|████▍     | 175/400 [02:24<03:13,  1.16it/s]Running loglikelihood requests:  44%|████▍     | 176/400 [02:25<03:15,  1.14it/s]Running loglikelihood requests:  44%|████▍     | 178/400 [02:25<02:32,  1.46it/s]Running loglikelihood requests:  45%|████▍     | 179/400 [02:26<02:43,  1.35it/s]Running loglikelihood requests:  45%|████▌     | 180/400 [02:27<02:52,  1.28it/s]Running loglikelihood requests:  45%|████▌     | 181/400 [02:28<02:58,  1.22it/s]Running loglikelihood requests:  46%|████▌     | 183/400 [02:29<02:23,  1.52it/s]Running loglikelihood requests:  46%|████▌     | 184/400 [02:30<02:35,  1.39it/s]Running loglikelihood requests:  47%|████▋     | 187/400 [02:31<01:48,  1.97it/s]Running loglikelihood requests:  47%|████▋     | 188/400 [02:32<02:03,  1.71it/s]Running loglikelihood requests:  47%|████▋     | 189/400 [02:33<02:17,  1.53it/s]Running loglikelihood requests:  48%|████▊     | 190/400 [02:34<02:29,  1.40it/s]Running loglikelihood requests:  48%|████▊     | 191/400 [02:34<02:38,  1.31it/s]Running loglikelihood requests:  48%|████▊     | 192/400 [02:35<02:52,  1.21it/s]Running loglikelihood requests:  48%|████▊     | 193/400 [02:36<02:55,  1.18it/s]Running loglikelihood requests:  48%|████▊     | 194/400 [02:37<02:57,  1.16it/s]Running loglikelihood requests:  49%|████▉     | 196/400 [02:38<02:18,  1.47it/s]Running loglikelihood requests:  49%|████▉     | 197/400 [02:39<02:28,  1.37it/s]Running loglikelihood requests:  50%|████▉     | 198/400 [02:40<02:36,  1.29it/s]Running loglikelihood requests:  50%|████▉     | 199/400 [02:41<02:42,  1.24it/s]Running loglikelihood requests:  50%|█████     | 200/400 [02:42<02:46,  1.20it/s]Running loglikelihood requests:  50%|█████     | 202/400 [02:43<02:11,  1.51it/s]Running loglikelihood requests:  51%|█████     | 203/400 [02:44<02:27,  1.34it/s]Running loglikelihood requests:  51%|█████     | 204/400 [02:45<02:39,  1.23it/s]Running loglikelihood requests:  51%|█████▏    | 205/400 [02:46<02:48,  1.16it/s]Running loglikelihood requests:  52%|█████▏    | 206/400 [02:47<02:54,  1.11it/s]Running loglikelihood requests:  52%|█████▏    | 207/400 [02:48<02:59,  1.08it/s]Running loglikelihood requests:  52%|█████▎    | 210/400 [02:49<01:54,  1.66it/s]Running loglikelihood requests:  53%|█████▎    | 212/400 [02:50<01:45,  1.77it/s]Running loglikelihood requests:  53%|█████▎    | 213/400 [02:51<01:58,  1.58it/s]Running loglikelihood requests:  54%|█████▍    | 215/400 [02:52<01:45,  1.76it/s]Running loglikelihood requests:  54%|█████▍    | 216/400 [02:52<01:57,  1.57it/s]Running loglikelihood requests:  54%|█████▍    | 217/400 [02:53<02:07,  1.43it/s]Running loglikelihood requests:  55%|█████▍    | 219/400 [02:54<01:49,  1.66it/s]Running loglikelihood requests:  55%|█████▌    | 220/400 [02:55<02:00,  1.49it/s]Running loglikelihood requests:  55%|█████▌    | 221/400 [02:56<02:10,  1.37it/s]Running loglikelihood requests:  56%|█████▌    | 222/400 [02:57<02:17,  1.29it/s]Running loglikelihood requests:  56%|█████▌    | 223/400 [02:58<02:23,  1.24it/s]Running loglikelihood requests:  56%|█████▌    | 224/400 [02:59<02:27,  1.20it/s]Running loglikelihood requests:  56%|█████▋    | 225/400 [03:00<02:29,  1.17it/s]Running loglikelihood requests:  56%|█████▋    | 226/400 [03:01<02:31,  1.15it/s]Running loglikelihood requests:  57%|█████▋    | 227/400 [03:02<02:32,  1.13it/s]Running loglikelihood requests:  57%|█████▋    | 228/400 [03:02<02:32,  1.12it/s]Running loglikelihood requests:  57%|█████▋    | 229/400 [03:03<02:36,  1.09it/s]Running loglikelihood requests:  57%|█████▊    | 230/400 [03:04<02:39,  1.06it/s]Running loglikelihood requests:  58%|█████▊    | 231/400 [03:05<02:41,  1.05it/s]Running loglikelihood requests:  58%|█████▊    | 232/400 [03:06<02:42,  1.03it/s]Running loglikelihood requests:  58%|█████▊    | 233/400 [03:07<02:43,  1.02it/s]Running loglikelihood requests:  59%|█████▉    | 235/400 [03:08<02:06,  1.30it/s]Running loglikelihood requests:  59%|█████▉    | 236/400 [03:09<02:16,  1.20it/s]Running loglikelihood requests:  59%|█████▉    | 237/400 [03:10<02:24,  1.13it/s]Running loglikelihood requests:  60%|█████▉    | 238/400 [03:12<02:29,  1.08it/s]Running loglikelihood requests:  60%|█████▉    | 239/400 [03:12<02:27,  1.09it/s]Running loglikelihood requests:  60%|██████    | 240/400 [03:13<02:26,  1.09it/s]Running loglikelihood requests:  60%|██████    | 242/400 [03:14<01:51,  1.42it/s]Running loglikelihood requests:  61%|██████    | 243/400 [03:15<01:58,  1.33it/s]Running loglikelihood requests:  61%|██████    | 244/400 [03:16<02:03,  1.26it/s]Running loglikelihood requests:  61%|██████▏   | 245/400 [03:17<02:07,  1.22it/s]Running loglikelihood requests:  62%|██████▏   | 246/400 [03:18<02:10,  1.18it/s]Running loglikelihood requests:  62%|██████▏   | 247/400 [03:19<02:11,  1.16it/s]Running loglikelihood requests:  62%|██████▏   | 249/400 [03:20<01:42,  1.48it/s]Running loglikelihood requests:  62%|██████▎   | 250/400 [03:21<01:49,  1.37it/s]Running loglikelihood requests:  63%|██████▎   | 251/400 [03:21<01:55,  1.29it/s]Running loglikelihood requests:  63%|██████▎   | 252/400 [03:22<01:59,  1.24it/s]Running loglikelihood requests:  63%|██████▎   | 253/400 [03:23<02:02,  1.20it/s]Running loglikelihood requests:  64%|██████▎   | 254/400 [03:24<02:04,  1.17it/s]Running loglikelihood requests:  64%|██████▍   | 255/400 [03:25<02:05,  1.15it/s]Running loglikelihood requests:  64%|██████▍   | 256/400 [03:26<02:06,  1.14it/s]Running loglikelihood requests:  64%|██████▍   | 257/400 [03:27<02:06,  1.13it/s]Running loglikelihood requests:  64%|██████▍   | 258/400 [03:28<02:06,  1.13it/s]Running loglikelihood requests:  65%|██████▌   | 260/400 [03:29<01:36,  1.45it/s]Running loglikelihood requests:  65%|██████▌   | 261/400 [03:30<01:43,  1.35it/s]Running loglikelihood requests:  66%|██████▌   | 264/400 [03:30<01:09,  1.94it/s]Running loglikelihood requests:  66%|██████▋   | 265/400 [03:31<01:19,  1.69it/s]Running loglikelihood requests:  66%|██████▋   | 266/400 [03:32<01:29,  1.50it/s]Running loglikelihood requests:  67%|██████▋   | 267/400 [03:33<01:37,  1.36it/s]Running loglikelihood requests:  67%|██████▋   | 268/400 [03:34<01:42,  1.29it/s]Running loglikelihood requests:  67%|██████▋   | 269/400 [03:35<01:46,  1.23it/s]Running loglikelihood requests:  68%|██████▊   | 270/400 [03:36<01:48,  1.20it/s]Running loglikelihood requests:  68%|██████▊   | 271/400 [03:37<01:53,  1.14it/s]Running loglikelihood requests:  68%|██████▊   | 272/400 [03:38<01:56,  1.10it/s]Running loglikelihood requests:  68%|██████▊   | 273/400 [03:39<01:58,  1.08it/s]Running loglikelihood requests:  68%|██████▊   | 274/400 [03:40<01:56,  1.08it/s]Running loglikelihood requests:  69%|██████▉   | 277/400 [03:41<01:10,  1.74it/s]Running loglikelihood requests:  70%|██████▉   | 279/400 [03:42<01:04,  1.88it/s]Running loglikelihood requests:  70%|███████   | 281/400 [03:42<01:00,  1.98it/s]Running loglikelihood requests:  71%|███████   | 284/400 [03:43<00:48,  2.38it/s]Running loglikelihood requests:  71%|███████▏  | 285/400 [03:44<00:57,  2.00it/s]Running loglikelihood requests:  72%|███████▏  | 286/400 [03:45<01:05,  1.74it/s]Running loglikelihood requests:  72%|███████▏  | 287/400 [03:46<01:12,  1.55it/s]Running loglikelihood requests:  72%|███████▏  | 288/400 [03:47<01:18,  1.42it/s]Running loglikelihood requests:  72%|███████▏  | 289/400 [03:48<01:23,  1.33it/s]Running loglikelihood requests:  72%|███████▎  | 290/400 [03:49<01:29,  1.23it/s]Running loglikelihood requests:  73%|███████▎  | 291/400 [03:50<01:30,  1.20it/s]Running loglikelihood requests:  73%|███████▎  | 293/400 [03:51<01:12,  1.48it/s]Running loglikelihood requests:  74%|███████▎  | 294/400 [03:52<01:19,  1.34it/s]Running loglikelihood requests:  74%|███████▍  | 295/400 [03:53<01:23,  1.26it/s]Running loglikelihood requests:  74%|███████▍  | 296/400 [03:53<01:25,  1.22it/s]Running loglikelihood requests:  74%|███████▍  | 297/400 [03:54<01:26,  1.19it/s]Running loglikelihood requests:  75%|███████▍  | 299/400 [03:55<01:07,  1.51it/s]Running loglikelihood requests:  75%|███████▌  | 300/400 [03:56<01:11,  1.39it/s]Running loglikelihood requests:  75%|███████▌  | 301/400 [03:57<01:15,  1.32it/s]Running loglikelihood requests:  76%|███████▌  | 302/400 [03:58<01:17,  1.26it/s]Running loglikelihood requests:  76%|███████▌  | 304/400 [03:59<01:01,  1.56it/s]Running loglikelihood requests:  76%|███████▋  | 305/400 [04:00<01:07,  1.41it/s]Running loglikelihood requests:  77%|███████▋  | 307/400 [04:01<00:57,  1.62it/s]Running loglikelihood requests:  77%|███████▋  | 309/400 [04:02<00:51,  1.76it/s]Running loglikelihood requests:  78%|███████▊  | 310/400 [04:03<00:58,  1.53it/s]Running loglikelihood requests:  78%|███████▊  | 311/400 [04:04<01:03,  1.41it/s]Running loglikelihood requests:  78%|███████▊  | 312/400 [04:04<01:06,  1.33it/s]Running loglikelihood requests:  78%|███████▊  | 313/400 [04:05<01:08,  1.27it/s]Running loglikelihood requests:  79%|███████▉  | 315/400 [04:06<00:54,  1.55it/s]Running loglikelihood requests:  79%|███████▉  | 317/400 [04:07<00:47,  1.76it/s]Running loglikelihood requests:  80%|███████▉  | 318/400 [04:08<00:52,  1.57it/s]Running loglikelihood requests:  80%|███████▉  | 319/400 [04:09<00:56,  1.43it/s]Running loglikelihood requests:  80%|████████  | 321/400 [04:10<00:47,  1.67it/s]Running loglikelihood requests:  81%|████████  | 323/400 [04:11<00:41,  1.84it/s]Running loglikelihood requests:  82%|████████▏ | 326/400 [04:12<00:32,  2.29it/s]Running loglikelihood requests:  82%|████████▏ | 327/400 [04:12<00:37,  1.94it/s]Running loglikelihood requests:  82%|████████▏ | 328/400 [04:13<00:42,  1.70it/s]Running loglikelihood requests:  82%|████████▏ | 329/400 [04:14<00:46,  1.52it/s]Running loglikelihood requests:  82%|████████▎ | 330/400 [04:15<00:51,  1.36it/s]Running loglikelihood requests:  83%|████████▎ | 332/400 [04:16<00:42,  1.59it/s]Running loglikelihood requests:  83%|████████▎ | 333/400 [04:17<00:47,  1.42it/s]Running loglikelihood requests:  84%|████████▎ | 334/400 [04:18<00:50,  1.30it/s]Running loglikelihood requests:  84%|████████▍ | 335/400 [04:19<00:53,  1.22it/s]Running loglikelihood requests:  84%|████████▍ | 336/400 [04:20<00:54,  1.17it/s]Running loglikelihood requests:  84%|████████▍ | 337/400 [04:21<00:55,  1.13it/s]Running loglikelihood requests:  84%|████████▍ | 338/400 [04:22<00:54,  1.13it/s]Running loglikelihood requests:  85%|████████▍ | 339/400 [04:23<00:53,  1.14it/s]Running loglikelihood requests:  85%|████████▌ | 340/400 [04:24<00:52,  1.14it/s]Running loglikelihood requests:  85%|████████▌ | 341/400 [04:24<00:50,  1.17it/s]Running loglikelihood requests:  86%|████████▌ | 342/400 [04:25<00:48,  1.19it/s]Running loglikelihood requests:  86%|████████▌ | 343/400 [04:26<00:47,  1.21it/s]Running loglikelihood requests:  86%|████████▋ | 346/400 [04:27<00:27,  1.94it/s]Running loglikelihood requests:  87%|████████▋ | 348/400 [04:28<00:25,  2.08it/s]Running loglikelihood requests:  87%|████████▋ | 349/400 [04:29<00:28,  1.78it/s]Running loglikelihood requests:  88%|████████▊ | 350/400 [04:29<00:31,  1.58it/s]Running loglikelihood requests:  88%|████████▊ | 351/400 [04:30<00:33,  1.45it/s]Running loglikelihood requests:  88%|████████▊ | 352/400 [04:31<00:35,  1.35it/s]Running loglikelihood requests:  88%|████████▊ | 353/400 [04:32<00:35,  1.31it/s]Running loglikelihood requests:  88%|████████▊ | 354/400 [04:33<00:35,  1.30it/s]Running loglikelihood requests:  89%|████████▉ | 355/400 [04:34<00:35,  1.26it/s]Running loglikelihood requests:  89%|████████▉ | 356/400 [04:35<00:36,  1.22it/s]Running loglikelihood requests:  90%|████████▉ | 358/400 [04:35<00:27,  1.55it/s]Running loglikelihood requests:  90%|████████▉ | 359/400 [04:36<00:28,  1.42it/s]Running loglikelihood requests:  90%|█████████ | 360/400 [04:37<00:30,  1.32it/s]Running loglikelihood requests:  90%|█████████ | 361/400 [04:38<00:30,  1.27it/s]Running loglikelihood requests:  90%|█████████ | 362/400 [04:39<00:30,  1.23it/s]Running loglikelihood requests:  91%|█████████ | 364/400 [04:40<00:23,  1.54it/s]Running loglikelihood requests:  91%|█████████▏| 365/400 [04:41<00:24,  1.42it/s]Running loglikelihood requests:  92%|█████████▏| 367/400 [04:42<00:19,  1.68it/s]Running loglikelihood requests:  92%|█████████▏| 368/400 [04:42<00:21,  1.52it/s]Running loglikelihood requests:  92%|█████████▏| 369/400 [04:43<00:21,  1.41it/s]Running loglikelihood requests:  92%|█████████▎| 370/400 [04:44<00:22,  1.34it/s]Running loglikelihood requests:  93%|█████████▎| 371/400 [04:45<00:22,  1.28it/s]Running loglikelihood requests:  93%|█████████▎| 373/400 [04:46<00:16,  1.59it/s]Running loglikelihood requests:  94%|█████████▍| 375/400 [04:47<00:13,  1.80it/s]Running loglikelihood requests:  94%|█████████▍| 376/400 [04:48<00:14,  1.61it/s]Running loglikelihood requests:  95%|█████████▍| 379/400 [04:49<00:09,  2.17it/s]Running loglikelihood requests:  95%|█████████▌| 381/400 [04:49<00:08,  2.22it/s]Running loglikelihood requests:  96%|█████████▌| 382/400 [04:50<00:09,  1.94it/s]Running loglikelihood requests:  96%|█████████▌| 384/400 [04:51<00:07,  2.09it/s]Running loglikelihood requests:  96%|█████████▋| 386/400 [04:52<00:06,  2.20it/s]Running loglikelihood requests:  97%|█████████▋| 387/400 [04:53<00:06,  1.91it/s]Running loglikelihood requests:  97%|█████████▋| 389/400 [04:53<00:05,  2.07it/s]Running loglikelihood requests:  98%|█████████▊| 391/400 [04:54<00:04,  2.19it/s]Running loglikelihood requests:  98%|█████████▊| 393/400 [04:55<00:03,  2.28it/s]Running loglikelihood requests:  99%|█████████▉| 395/400 [04:56<00:02,  2.34it/s]Running loglikelihood requests:  99%|█████████▉| 397/400 [04:57<00:01,  2.38it/s]Running loglikelihood requests: 100%|█████████▉| 398/400 [04:57<00:00,  2.04it/s]Running loglikelihood requests: 100%|██████████| 400/400 [04:58<00:00,  2.18it/s]Running loglikelihood requests: 100%|██████████| 400/400 [04:58<00:00,  1.34it/s]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:5'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:5'}
full model:
{'mastermind_24_easy': {'alias': 'mastermind_24_easy', 'acc,none': 0.33, 'acc_stderr,none': 0.04725815626252609}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9705388716727775
0.9880227828623074
0.982119607496995
0.9941469535767887
0.984917378949356
0.9883609317461776
0.9752442385272352
0.9858149677985593
0.9966001900863091
0.9954965780195978
0.9982374916142641
0.987839947084121
0.9740425263242771
0.9802324544963317
0.9965978314947238
0.9890806289155061
0.971808392501808
0.9767123038440666
0.9820534501654181
0.9672299205809463
0.9753579231968917
0.9973837437819523
0.9951994747100236
0.9465102818948206
0.9757933184251313
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[7, 0, 1, 3, 6, 5, 4, 2]
tensor([7, 0, 1, 3, 6, 5, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 0, 1, 3, 7, 5, 4, 2]
tensor([6, 0, 1, 3, 7, 5, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 0, 1, 3, 6, 5, 4, 2]
tensor([7, 0, 1, 3, 6, 5, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 0, 1, 3, 7, 5, 4, 2]
tensor([6, 0, 1, 3, 7, 5, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 0, 1, 3, 6, 5, 4, 2]
tensor([7, 0, 1, 3, 6, 5, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 0, 2, 3, 6, 5, 4, 1]
tensor([7, 0, 2, 3, 6, 5, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Normal merging for layer 2
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
done!
Normal merging for layer 3
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Normal merging for layer 4
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
done!
Normal merging for layer 5
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 6 to 31
done!
all done!
Model size: 12.0718 GB
133
cuda:5
coqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:43<00:43, 43.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:56<00:00, 25.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:56<00:00, 28.47s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa HTTP/1.1" 200 857
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/EleutherAI/coqa/EleutherAI/coqa.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa HTTP/1.1" 200 857
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/coqa/resolve/82e11af842af6c1396f5e9a5c7de260107c50cf1/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa/revision/82e11af842af6c1396f5e9a5c7de260107c50cf1 HTTP/1.1" 200 857
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa/tree/82e11af842af6c1396f5e9a5c7de260107c50cf1?recursive=False&expand=False HTTP/1.1" 200 489
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa/tree/82e11af842af6c1396f5e9a5c7de260107c50cf1/data?recursive=False&expand=False HTTP/1.1" 404 79
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa/tree/82e11af842af6c1396f5e9a5c7de260107c50cf1/data?recursive=False&expand=False HTTP/1.1" 404 79
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa/revision/82e11af842af6c1396f5e9a5c7de260107c50cf1 HTTP/1.1" 200 857
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/coqa/resolve/82e11af842af6c1396f5e9a5c7de260107c50cf1/dataset_infos.json HTTP/1.1" 200 0
DEBUG:filelock:Attempting to acquire lock 139722779364576 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___coqa_default_0.0.0_82e11af842af6c1396f5e9a5c7de260107c50cf1.lock
DEBUG:filelock:Lock 139722779364576 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___coqa_default_0.0.0_82e11af842af6c1396f5e9a5c7de260107c50cf1.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1/dataset_info.json
DEBUG:filelock:Attempting to release lock 139722779364576 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___coqa_default_0.0.0_82e11af842af6c1396f5e9a5c7de260107c50cf1.lock
DEBUG:filelock:Lock 139722779364576 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___coqa_default_0.0.0_82e11af842af6c1396f5e9a5c7de260107c50cf1.lock
DEBUG:filelock:Attempting to acquire lock 139750522782976 on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1_builder.lock
DEBUG:filelock:Lock 139750522782976 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1/dataset_info.json
DEBUG:filelock:Attempting to release lock 139750522782976 on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1_builder.lock
DEBUG:filelock:Lock 139750522782976 released on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
DEBUG:lm_eval.api.task:doc_to_target returned a list. Assuming multiple targets.
INFO:lm_eval.evaluator:coqa: Using gen_kwargs: {'until': ['\nQ:']}
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of coqa from None to 0
INFO:lm_eval.api.task:Building contexts for coqa on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 72377.98it/s]
DEBUG:lm_eval.evaluator:Task: coqa; number of requests on this rank: 100
INFO:lm_eval.evaluator:Running generate_until requests
Running generate_until requests:   0%|          | 0/100 [00:00<?, ?it/s]Running generate_until requests:   1%|          | 1/100 [00:05<09:37,  5.84s/it]Running generate_until requests:   2%|▏         | 2/100 [00:10<08:42,  5.33s/it]Running generate_until requests:   3%|▎         | 3/100 [00:16<09:04,  5.62s/it]Running generate_until requests:   4%|▍         | 4/100 [00:21<08:23,  5.25s/it]Running generate_until requests:   5%|▌         | 5/100 [00:26<08:11,  5.17s/it]Running generate_until requests:   6%|▌         | 6/100 [00:31<07:54,  5.05s/it]Running generate_until requests:   7%|▋         | 7/100 [00:36<08:01,  5.18s/it]Running generate_until requests:   8%|▊         | 8/100 [00:41<07:37,  4.97s/it]Running generate_until requests:   9%|▉         | 9/100 [00:46<07:37,  5.03s/it]Running generate_until requests:  10%|█         | 10/100 [00:51<07:40,  5.11s/it]Running generate_until requests:  11%|█         | 11/100 [00:56<07:29,  5.05s/it]Running generate_until requests:  12%|█▏        | 12/100 [01:02<07:57,  5.43s/it]Running generate_until requests:  13%|█▎        | 13/100 [01:07<07:30,  5.17s/it]Running generate_until requests:  14%|█▍        | 14/100 [01:12<07:18,  5.10s/it]Running generate_until requests:  15%|█▌        | 15/100 [01:17<07:09,  5.05s/it]Running generate_until requests:  16%|█▌        | 16/100 [01:21<06:43,  4.81s/it]Running generate_until requests:  17%|█▋        | 17/100 [01:26<06:43,  4.86s/it]Running generate_until requests:  18%|█▊        | 18/100 [01:30<06:18,  4.62s/it]Running generate_until requests:  19%|█▉        | 19/100 [01:35<06:07,  4.53s/it]Running generate_until requests:  20%|██        | 20/100 [01:39<05:58,  4.48s/it]Running generate_until requests:  21%|██        | 21/100 [01:44<06:00,  4.56s/it]Running generate_until requests:  22%|██▏       | 22/100 [01:48<05:47,  4.46s/it]Running generate_until requests:  23%|██▎       | 23/100 [01:53<06:00,  4.69s/it]Running generate_until requests:  24%|██▍       | 24/100 [01:58<06:07,  4.84s/it]Running generate_until requests:  25%|██▌       | 25/100 [02:02<05:47,  4.63s/it]Running generate_until requests:  26%|██▌       | 26/100 [02:07<05:39,  4.59s/it]Running generate_until requests:  27%|██▋       | 27/100 [02:12<05:36,  4.61s/it]Running generate_until requests:  28%|██▊       | 28/100 [02:16<05:26,  4.54s/it]Running generate_until requests:  29%|██▉       | 29/100 [02:20<05:18,  4.48s/it]Running generate_until requests:  30%|███       | 30/100 [02:25<05:13,  4.48s/it]Running generate_until requests:  31%|███       | 31/100 [02:29<04:58,  4.32s/it]Running generate_until requests:  32%|███▏      | 32/100 [02:33<04:59,  4.40s/it]Running generate_until requests:  33%|███▎      | 33/100 [02:38<04:58,  4.45s/it]Running generate_until requests:  34%|███▍      | 34/100 [02:42<04:50,  4.40s/it]Running generate_until requests:  35%|███▌      | 35/100 [02:46<04:36,  4.25s/it]Running generate_until requests:  36%|███▌      | 36/100 [02:52<05:06,  4.79s/it]Running generate_until requests:  37%|███▋      | 37/100 [02:57<04:54,  4.68s/it]Running generate_until requests:  38%|███▊      | 38/100 [03:01<04:40,  4.53s/it]Running generate_until requests:  39%|███▉      | 39/100 [03:05<04:28,  4.41s/it]Running generate_until requests:  40%|████      | 40/100 [03:09<04:14,  4.24s/it]Running generate_until requests:  41%|████      | 41/100 [03:13<04:07,  4.20s/it]Running generate_until requests:  42%|████▏     | 42/100 [03:18<04:22,  4.52s/it]Running generate_until requests:  43%|████▎     | 43/100 [03:22<04:09,  4.38s/it]Running generate_until requests:  44%|████▍     | 44/100 [03:27<04:05,  4.39s/it]Running generate_until requests:  45%|████▌     | 45/100 [03:31<04:06,  4.48s/it]Running generate_until requests:  46%|████▌     | 46/100 [03:35<03:49,  4.26s/it]Running generate_until requests:  47%|████▋     | 47/100 [03:39<03:36,  4.09s/it]Running generate_until requests:  48%|████▊     | 48/100 [03:43<03:34,  4.13s/it]Running generate_until requests:  49%|████▉     | 49/100 [03:48<03:39,  4.31s/it]Running generate_until requests:  50%|█████     | 50/100 [03:51<03:26,  4.13s/it]Running generate_until requests:  51%|█████     | 51/100 [03:56<03:30,  4.30s/it]Running generate_until requests:  52%|█████▏    | 52/100 [04:00<03:17,  4.11s/it]Running generate_until requests:  53%|█████▎    | 53/100 [04:04<03:15,  4.17s/it]Running generate_until requests:  54%|█████▍    | 54/100 [04:08<03:04,  4.01s/it]Running generate_until requests:  55%|█████▌    | 55/100 [04:12<03:02,  4.05s/it]Running generate_until requests:  56%|█████▌    | 56/100 [04:16<03:03,  4.18s/it]Running generate_until requests:  57%|█████▋    | 57/100 [04:20<03:00,  4.20s/it]Running generate_until requests:  58%|█████▊    | 58/100 [04:24<02:49,  4.04s/it]Running generate_until requests:  59%|█████▉    | 59/100 [04:29<02:56,  4.31s/it]Running generate_until requests:  60%|██████    | 60/100 [04:33<02:48,  4.21s/it]Running generate_until requests:  61%|██████    | 61/100 [04:38<02:52,  4.41s/it]Running generate_until requests:  62%|██████▏   | 62/100 [04:43<02:49,  4.47s/it]Running generate_until requests:  63%|██████▎   | 63/100 [04:46<02:35,  4.20s/it]Running generate_until requests:  64%|██████▍   | 64/100 [04:50<02:24,  4.00s/it]Running generate_until requests:  65%|██████▌   | 65/100 [04:53<02:14,  3.85s/it]Running generate_until requests:  66%|██████▌   | 66/100 [04:57<02:07,  3.75s/it]Running generate_until requests:  67%|██████▋   | 67/100 [05:01<02:05,  3.79s/it]Running generate_until requests:  68%|██████▊   | 68/100 [05:05<02:09,  4.04s/it]Running generate_until requests:  69%|██████▉   | 69/100 [05:11<02:20,  4.55s/it]Running generate_until requests:  70%|███████   | 70/100 [05:15<02:11,  4.38s/it]Running generate_until requests:  71%|███████   | 71/100 [05:23<02:39,  5.51s/it]Running generate_until requests:  72%|███████▏  | 72/100 [05:26<02:16,  4.88s/it]Running generate_until requests:  73%|███████▎  | 73/100 [05:30<02:00,  4.47s/it]Running generate_until requests:  74%|███████▍  | 74/100 [05:34<01:51,  4.29s/it]Running generate_until requests:  75%|███████▌  | 75/100 [05:38<01:43,  4.16s/it]Running generate_until requests:  76%|███████▌  | 76/100 [05:41<01:37,  4.05s/it]Running generate_until requests:  77%|███████▋  | 77/100 [05:46<01:37,  4.25s/it]Running generate_until requests:  78%|███████▊  | 78/100 [05:50<01:29,  4.07s/it]Running generate_until requests:  79%|███████▉  | 79/100 [05:53<01:19,  3.81s/it]Running generate_until requests:  80%|████████  | 80/100 [05:57<01:15,  3.78s/it]Running generate_until requests:  81%|████████  | 81/100 [06:02<01:21,  4.28s/it]Running generate_until requests:  82%|████████▏ | 82/100 [06:05<01:11,  3.95s/it]Running generate_until requests:  83%|████████▎ | 83/100 [06:09<01:05,  3.83s/it]Running generate_until requests:  84%|████████▍ | 84/100 [06:12<00:57,  3.62s/it]Running generate_until requests:  85%|████████▌ | 85/100 [06:15<00:51,  3.45s/it]Running generate_until requests:  86%|████████▌ | 86/100 [06:19<00:48,  3.45s/it]Running generate_until requests:  87%|████████▋ | 87/100 [06:23<00:47,  3.67s/it]Running generate_until requests:  88%|████████▊ | 88/100 [06:26<00:42,  3.58s/it]Running generate_until requests:  89%|████████▉ | 89/100 [06:29<00:37,  3.37s/it]Running generate_until requests:  90%|█████████ | 90/100 [06:32<00:32,  3.25s/it]Running generate_until requests:  91%|█████████ | 91/100 [06:35<00:28,  3.12s/it]Running generate_until requests:  92%|█████████▏| 92/100 [06:38<00:24,  3.02s/it]Running generate_until requests:  93%|█████████▎| 93/100 [06:41<00:20,  2.99s/it]Running generate_until requests:  94%|█████████▍| 94/100 [06:43<00:17,  2.99s/it]Running generate_until requests:  95%|█████████▌| 95/100 [06:47<00:15,  3.05s/it]Running generate_until requests:  96%|█████████▌| 96/100 [06:50<00:12,  3.04s/it]Running generate_until requests:  97%|█████████▋| 97/100 [06:52<00:08,  2.86s/it]Running generate_until requests:  98%|█████████▊| 98/100 [06:55<00:05,  2.73s/it]Running generate_until requests:  99%|█████████▉| 99/100 [06:57<00:02,  2.70s/it]Running generate_until requests: 100%|██████████| 100/100 [07:00<00:00,  2.71s/it]Running generate_until requests: 100%|██████████| 100/100 [07:00<00:00,  4.20s/it]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:6'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:6'}
full model:
{'coqa': {'alias': 'coqa', 'em,none': 0.595, 'em_stderr,none': 0.044774970461162564, 'f1,none': 0.7211574141733987, 'f1_stderr,none': 0.037128235455690536}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.6057853926542468
0.4195568875297668
0.5244744113321889
0.5202703028806769
0.6150870974034927
0.5299634576457063
0.9336763524510373
0.23649940737178063
0.388911200696845
0.6478041116722705
0.5517233675449297
0.6723258763091353
0.7175526480521238
0.8411089149883405
0.7404554224148189
0.26376935916880817
0.9373006475493478
0.5360566853939598
0.38729358133282565
0.4541602442018795
0.8623573205888978
0.7318340566806717
0.6643209906079897
0.8122565195147101
0.4707270481319977
0.9785001455445378
0.17075087907531752
0.489625917805058
0.7595051272431785
0.6057853926542468
0.4195568875297668
0.5244744113321889
0.5202703028806769
0.6150870974034927
0.5299634576457063
0.9336763524510373
0.23649940737178063
0.388911200696845
0.6478041116722705
0.5517233675449297
0.6723258763091353
0.7175526480521238
0.8411089149883405
0.7404554224148189
0.26376935916880817
0.9373006475493478
0.5360566853939598
0.38729358133282565
0.4541602442018795
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[5, 4, 3, 2, 0, 1, 7, 6]
tensor([5, 4, 3, 2, 0, 1, 7, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 3, 4, 0, 2, 1, 7, 6]
tensor([5, 3, 4, 0, 2, 1, 7, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 1, 7, 0, 6, 2, 3, 4]
tensor([5, 1, 7, 0, 6, 2, 3, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 3, 6, 0, 5, 2, 4, 1]
tensor([7, 3, 6, 0, 5, 2, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 5, 7, 2, 4, 0, 3, 1]
tensor([6, 5, 7, 2, 4, 0, 3, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 5, 0, 0, 1, 2, 1, 3]
tensor([4, 5, 0, 0, 1, 2, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1, 2, 2, 0, 3, 3]
tensor([0, 1, 1, 2, 2, 0, 3, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([7])
tensor(7)
tensor([6])
tensor(6)
done!
Normal merging for layer 2
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
done!
Normal merging for layer 4
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Cross-layer merge completed for layers 5 to 8
done!
Normal merging for layer 9
tensor([2, 3])
tensor(2)
tensor([4, 6])
tensor(4)
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([1])
tensor(1)
done!
Cross-layer merge completed for layers 10 to 22
done!
Normal merging for layer 23
tensor([0, 5])
tensor(0)
tensor([1, 2])
tensor(1)
tensor([3, 4])
tensor(3)
tensor([6, 7])
tensor(6)
done!
Cross-layer merge completed for layers 24 to 31
done!
all done!
Model size: 12.3238 GB
104
cuda:6
rte
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:41<00:41, 41.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 24.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 27.29s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: rte] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: rte] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:filelock:Attempting to acquire lock 139720624966448 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139720624966448 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139720624966448 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139720624966448 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139720625735872 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139720625735872 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139720625735872 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139720625735872 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of rte from None to 0
INFO:lm_eval.api.task:Building contexts for rte on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 2601.17it/s]
DEBUG:lm_eval.evaluator:Task: rte; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:01<05:54,  1.78s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:03<03:11,  1.03it/s]Running loglikelihood requests:   2%|▎         | 5/200 [00:04<02:34,  1.26it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:05<02:16,  1.41it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:06<02:07,  1.50it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:07<01:59,  1.58it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:09<01:55,  1.63it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:10<01:54,  1.62it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:11<01:52,  1.62it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:12<01:49,  1.65it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:13<01:44,  1.72it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:14<01:40,  1.77it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:15<01:36,  1.81it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:16<01:32,  1.87it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:17<01:29,  1.91it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:18<01:27,  1.94it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:19<01:24,  1.97it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:20<01:22,  1.99it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:21<01:21,  2.01it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:22<01:19,  2.03it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:23<01:17,  2.06it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:24<01:14,  2.10it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:25<01:12,  2.13it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:26<01:10,  2.17it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:27<01:08,  2.21it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:28<01:05,  2.27it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:28<01:03,  2.32it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:29<01:01,  2.37it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:30<00:58,  2.43it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:31<00:57,  2.47it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:32<00:55,  2.50it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:32<00:53,  2.54it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:33<00:52,  2.57it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:34<00:51,  2.59it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:35<00:50,  2.62it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:35<00:48,  2.64it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:36<00:47,  2.66it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:37<00:46,  2.69it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:37<00:45,  2.72it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:38<00:44,  2.74it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:39<00:42,  2.77it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:40<00:41,  2.79it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:40<00:40,  2.82it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:41<00:39,  2.83it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:42<00:39,  2.80it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:42<00:39,  2.76it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:43<00:38,  2.80it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:44<00:37,  2.83it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:45<00:36,  2.86it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:45<00:35,  2.89it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:46<00:34,  2.90it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:47<00:33,  2.92it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:47<00:32,  2.94it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:48<00:31,  2.96it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:49<00:30,  2.98it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:49<00:29,  2.99it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:50<00:28,  3.00it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:51<00:28,  3.01it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:51<00:27,  3.02it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:52<00:26,  3.03it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:53<00:26,  3.04it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:53<00:25,  3.05it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:54<00:24,  3.05it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [00:54<00:23,  3.06it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [00:55<00:23,  3.06it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [00:56<00:22,  3.07it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [00:56<00:21,  3.08it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [00:57<00:20,  3.11it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [00:58<00:20,  3.13it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [00:58<00:19,  3.14it/s]Running loglikelihood requests:  70%|███████   | 141/200 [00:59<00:18,  3.16it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [01:00<00:17,  3.19it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [01:00<00:17,  3.20it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [01:01<00:16,  3.15it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [01:01<00:16,  3.11it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [01:02<00:15,  3.08it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [01:03<00:15,  3.08it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [01:03<00:14,  3.16it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [01:04<00:13,  3.21it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [01:05<00:12,  3.27it/s]Running loglikelihood requests:  80%|████████  | 161/200 [01:05<00:11,  3.31it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [01:06<00:11,  3.26it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [01:06<00:10,  3.22it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [01:07<00:10,  3.23it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [01:08<00:09,  3.28it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [01:08<00:08,  3.34it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [01:09<00:07,  3.38it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [01:09<00:07,  3.41it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [01:10<00:06,  3.43it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [01:10<00:06,  3.45it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [01:11<00:05,  3.47it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [01:12<00:04,  3.49it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [01:12<00:04,  3.51it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [01:13<00:03,  3.52it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [01:13<00:03,  3.54it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [01:14<00:02,  3.55it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [01:14<00:01,  3.58it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:15<00:01,  3.60it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:15<00:00,  3.68it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:16<00:00,  3.75it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:16<00:00,  2.61it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:7'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:7'}
full model:
{'rte': {'alias': 'rte', 'acc,none': 0.5, 'acc_stderr,none': 0.050251890762960605}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.34161229456626735
0.905233410256777
0.5205040718697735
0.4121994254524892
0.7398116665887099
0.6225415196831932
0.7923970242263771
0.7353888240887675
0.6535613357308766
0.7757058271862038
0.734046359122903
0.4471799126982846
0.773619360921301
0.7955347039939479
0.8672068064531693
0.8652880343596522
0.3302235467760883
0.6789268064017625
0.6072221471952108
0.9194446824778495
0.4812004589187253
0.5728915095234594
0.1682455054057436
0.93212414632396
0.9148362604533635
0.8268537756297094
0.7592245907029287
0.7256008379011685
0.7109756105942956
0.34161229456626735
0.905233410256777
0.5205040718697735
0.4121994254524892
0.7398116665887099
0.6225415196831932
0.7923970242263771
0.7353888240887675
0.6535613357308766
0.7757058271862038
0.734046359122903
0.4471799126982846
0.773619360921301
0.7955347039939479
0.8672068064531693
0.8652880343596522
0.3302235467760883
0.6789268064017625
0.6072221471952108
0.9194446824778495
0.4812004589187253
Total groups 73 exceeded the threshold, stopping comparison.
The group tensor is
[5, 2, 7, 1, 6, 4, 3, 0]
tensor([5, 2, 7, 1, 6, 4, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 6, 0, 7, 3, 4, 1]
tensor([5, 2, 6, 0, 7, 3, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 7, 2, 5, 4, 3, 0]
tensor([6, 1, 7, 2, 5, 4, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 7, 2, 4, 1, 5, 0]
tensor([6, 3, 7, 2, 4, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 5, 6, 2, 3, 1, 4, 0]
tensor([7, 5, 6, 2, 3, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 2, 5, 4, 1, 0, 1, 3]
tensor([0, 2, 5, 4, 1, 0, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1.0, 1.0, 0, 1.0, 1]
tensor([0, 1, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
Normal merging for layer 1
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Normal merging for layer 2
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 4
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 5 to 8
done!
Normal merging for layer 9
tensor([0, 5])
tensor(0)
tensor([4, 6])
tensor(4)
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
done!
Cross-layer merge completed for layers 10 to 30
done!
Normal merging for layer 31
tensor([0, 5])
tensor(0)
tensor([1, 2, 3, 4, 6, 7])
tensor(1)
done!
all done!
Model size: 12.1348 GB
80
cuda:7
mastermind_46_easy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:41<00:41, 41.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 24.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 27.02s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_46_mcq_random HTTP/1.1" 200 778
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/flair/mastermind_46_mcq_random/flair/mastermind_46_mcq_random.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_46_mcq_random HTTP/1.1" 200 786
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/flair/mastermind_46_mcq_random/resolve/544d077942975b1664c0bc4fd54df026050329a4/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_46_mcq_random/revision/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 786
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_46_mcq_random/tree/544d077942975b1664c0bc4fd54df026050329a4?recursive=False&expand=False HTTP/1.1" 200 290
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_46_mcq_random/tree/544d077942975b1664c0bc4fd54df026050329a4/data?recursive=False&expand=False HTTP/1.1" 200 361
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_46_mcq_random/revision/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 786
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/flair/mastermind_46_mcq_random/resolve/544d077942975b1664c0bc4fd54df026050329a4/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:filelock:Attempting to acquire lock 139748103666048 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_46_mcq_random_default_0.0.0_544d077942975b1664c0bc4fd54df026050329a4.lock
DEBUG:filelock:Lock 139748103666048 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_46_mcq_random_default_0.0.0_544d077942975b1664c0bc4fd54df026050329a4.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_46_mcq_random/default/0.0.0/544d077942975b1664c0bc4fd54df026050329a4/dataset_info.json
DEBUG:filelock:Attempting to release lock 139748103666048 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_46_mcq_random_default_0.0.0_544d077942975b1664c0bc4fd54df026050329a4.lock
DEBUG:filelock:Lock 139748103666048 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_46_mcq_random_default_0.0.0_544d077942975b1664c0bc4fd54df026050329a4.lock
DEBUG:filelock:Attempting to acquire lock 139750523789888 on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_46_mcq_random/default/0.0.0/544d077942975b1664c0bc4fd54df026050329a4_builder.lock
DEBUG:filelock:Lock 139750523789888 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_46_mcq_random/default/0.0.0/544d077942975b1664c0bc4fd54df026050329a4_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_46_mcq_random/default/0.0.0/544d077942975b1664c0bc4fd54df026050329a4/dataset_info.json
DEBUG:filelock:Attempting to release lock 139750523789888 on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_46_mcq_random/default/0.0.0/544d077942975b1664c0bc4fd54df026050329a4_builder.lock
DEBUG:filelock:Lock 139750523789888 released on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_46_mcq_random/default/0.0.0/544d077942975b1664c0bc4fd54df026050329a4_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mastermind_46_easy from None to 0
INFO:lm_eval.api.task:Building contexts for mastermind_46_easy on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1451.23it/s]
DEBUG:lm_eval.evaluator:Task: mastermind_46_easy; number of requests on this rank: 400
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/400 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/400 [00:02<13:29,  2.03s/it]Running loglikelihood requests:   0%|          | 2/400 [00:03<11:16,  1.70s/it]Running loglikelihood requests:   1%|          | 3/400 [00:04<10:29,  1.59s/it]Running loglikelihood requests:   1%|          | 4/400 [00:06<10:07,  1.53s/it]Running loglikelihood requests:   1%|▏         | 5/400 [00:07<09:53,  1.50s/it]Running loglikelihood requests:   2%|▏         | 6/400 [00:09<09:55,  1.51s/it]Running loglikelihood requests:   2%|▏         | 7/400 [00:10<09:45,  1.49s/it]Running loglikelihood requests:   2%|▏         | 8/400 [00:12<09:37,  1.47s/it]Running loglikelihood requests:   2%|▏         | 9/400 [00:13<09:40,  1.48s/it]Running loglikelihood requests:   2%|▎         | 10/400 [00:15<09:34,  1.47s/it]Running loglikelihood requests:   3%|▎         | 11/400 [00:16<09:29,  1.46s/it]Running loglikelihood requests:   3%|▎         | 12/400 [00:18<09:25,  1.46s/it]Running loglikelihood requests:   3%|▎         | 13/400 [00:19<09:22,  1.45s/it]Running loglikelihood requests:   4%|▎         | 14/400 [00:20<09:20,  1.45s/it]Running loglikelihood requests:   4%|▍         | 15/400 [00:22<09:18,  1.45s/it]Running loglikelihood requests:   4%|▍         | 16/400 [00:23<09:23,  1.47s/it]Running loglikelihood requests:   4%|▍         | 17/400 [00:25<09:30,  1.49s/it]Running loglikelihood requests:   4%|▍         | 18/400 [00:26<09:19,  1.47s/it]Running loglikelihood requests:   5%|▍         | 19/400 [00:28<09:11,  1.45s/it]Running loglikelihood requests:   5%|▌         | 20/400 [00:29<09:03,  1.43s/it]Running loglikelihood requests:   5%|▌         | 21/400 [00:31<08:58,  1.42s/it]Running loglikelihood requests:   6%|▌         | 22/400 [00:32<08:52,  1.41s/it]Running loglikelihood requests:   6%|▌         | 23/400 [00:33<08:48,  1.40s/it]Running loglikelihood requests:   6%|▌         | 24/400 [00:35<08:45,  1.40s/it]Running loglikelihood requests:   6%|▋         | 25/400 [00:36<08:43,  1.40s/it]Running loglikelihood requests:   6%|▋         | 26/400 [00:38<08:40,  1.39s/it]Running loglikelihood requests:   7%|▋         | 27/400 [00:39<08:39,  1.39s/it]Running loglikelihood requests:   7%|▋         | 28/400 [00:40<08:37,  1.39s/it]Running loglikelihood requests:   7%|▋         | 29/400 [00:42<08:35,  1.39s/it]Running loglikelihood requests:   8%|▊         | 30/400 [00:43<08:34,  1.39s/it]Running loglikelihood requests:   8%|▊         | 31/400 [00:45<08:42,  1.42s/it]Running loglikelihood requests:   8%|▊         | 32/400 [00:46<08:48,  1.44s/it]Running loglikelihood requests:   8%|▊         | 33/400 [00:47<08:43,  1.43s/it]Running loglikelihood requests:   8%|▊         | 34/400 [00:49<08:39,  1.42s/it]Running loglikelihood requests:   9%|▉         | 35/400 [00:50<08:36,  1.42s/it]Running loglikelihood requests:   9%|▉         | 36/400 [00:52<08:34,  1.41s/it]Running loglikelihood requests:   9%|▉         | 37/400 [00:53<08:32,  1.41s/it]Running loglikelihood requests:  10%|▉         | 38/400 [00:54<08:30,  1.41s/it]Running loglikelihood requests:  10%|▉         | 39/400 [00:56<08:27,  1.41s/it]Running loglikelihood requests:  10%|█         | 40/400 [00:57<08:26,  1.41s/it]Running loglikelihood requests:  10%|█         | 41/400 [00:59<08:25,  1.41s/it]Running loglikelihood requests:  10%|█         | 42/400 [01:00<08:22,  1.40s/it]Running loglikelihood requests:  11%|█         | 43/400 [01:01<08:20,  1.40s/it]Running loglikelihood requests:  11%|█         | 44/400 [01:03<08:18,  1.40s/it]Running loglikelihood requests:  11%|█▏        | 45/400 [01:04<08:17,  1.40s/it]Running loglikelihood requests:  12%|█▏        | 46/400 [01:06<08:16,  1.40s/it]Running loglikelihood requests:  12%|█▏        | 47/400 [01:07<08:14,  1.40s/it]Running loglikelihood requests:  12%|█▏        | 48/400 [01:09<08:14,  1.40s/it]Running loglikelihood requests:  12%|█▏        | 49/400 [01:10<08:12,  1.40s/it]Running loglikelihood requests:  12%|█▎        | 50/400 [01:11<08:11,  1.40s/it]Running loglikelihood requests:  13%|█▎        | 51/400 [01:13<08:09,  1.40s/it]Running loglikelihood requests:  13%|█▎        | 52/400 [01:14<08:07,  1.40s/it]Running loglikelihood requests:  13%|█▎        | 53/400 [01:15<08:05,  1.40s/it]Running loglikelihood requests:  14%|█▎        | 54/400 [01:17<08:04,  1.40s/it]Running loglikelihood requests:  14%|█▍        | 55/400 [01:18<08:02,  1.40s/it]Running loglikelihood requests:  14%|█▍        | 56/400 [01:20<08:02,  1.40s/it]Running loglikelihood requests:  14%|█▍        | 57/400 [01:21<08:00,  1.40s/it]Running loglikelihood requests:  14%|█▍        | 58/400 [01:22<07:58,  1.40s/it]Running loglikelihood requests:  15%|█▍        | 59/400 [01:24<08:00,  1.41s/it]Running loglikelihood requests:  15%|█▌        | 60/400 [01:25<07:59,  1.41s/it]Running loglikelihood requests:  15%|█▌        | 61/400 [01:27<07:56,  1.40s/it]Running loglikelihood requests:  16%|█▌        | 62/400 [01:28<07:52,  1.40s/it]Running loglikelihood requests:  16%|█▌        | 63/400 [01:30<07:50,  1.40s/it]Running loglikelihood requests:  16%|█▌        | 64/400 [01:31<07:48,  1.39s/it]Running loglikelihood requests:  16%|█▋        | 65/400 [01:32<07:48,  1.40s/it]Running loglikelihood requests:  16%|█▋        | 66/400 [01:34<07:43,  1.39s/it]Running loglikelihood requests:  17%|█▋        | 67/400 [01:35<07:40,  1.38s/it]Running loglikelihood requests:  17%|█▋        | 68/400 [01:36<07:38,  1.38s/it]Running loglikelihood requests:  17%|█▋        | 69/400 [01:38<07:51,  1.42s/it]Running loglikelihood requests:  18%|█▊        | 71/400 [01:39<05:56,  1.08s/it]Running loglikelihood requests:  18%|█▊        | 72/400 [01:41<06:17,  1.15s/it]Running loglikelihood requests:  18%|█▊        | 73/400 [01:42<06:34,  1.21s/it]Running loglikelihood requests:  18%|█▊        | 74/400 [01:43<06:46,  1.25s/it]Running loglikelihood requests:  19%|█▉        | 75/400 [01:45<06:55,  1.28s/it]Running loglikelihood requests:  19%|█▉        | 76/400 [01:46<07:01,  1.30s/it]Running loglikelihood requests:  19%|█▉        | 77/400 [01:47<07:05,  1.32s/it]Running loglikelihood requests:  20%|█▉        | 78/400 [01:49<07:07,  1.33s/it]Running loglikelihood requests:  20%|█▉        | 79/400 [01:50<07:07,  1.33s/it]Running loglikelihood requests:  20%|██        | 80/400 [01:52<07:07,  1.34s/it]Running loglikelihood requests:  20%|██        | 81/400 [01:53<07:07,  1.34s/it]Running loglikelihood requests:  20%|██        | 82/400 [01:54<07:06,  1.34s/it]Running loglikelihood requests:  21%|██        | 83/400 [01:56<07:06,  1.34s/it]Running loglikelihood requests:  21%|██        | 84/400 [01:57<07:04,  1.34s/it]Running loglikelihood requests:  21%|██▏       | 85/400 [01:58<07:03,  1.35s/it]Running loglikelihood requests:  22%|██▏       | 86/400 [02:00<07:03,  1.35s/it]Running loglikelihood requests:  22%|██▏       | 87/400 [02:01<07:02,  1.35s/it]Running loglikelihood requests:  22%|██▏       | 88/400 [02:02<07:01,  1.35s/it]Running loglikelihood requests:  22%|██▏       | 89/400 [02:04<07:00,  1.35s/it]Running loglikelihood requests:  22%|██▎       | 90/400 [02:05<06:58,  1.35s/it]Running loglikelihood requests:  23%|██▎       | 91/400 [02:06<06:56,  1.35s/it]Running loglikelihood requests:  23%|██▎       | 92/400 [02:08<06:54,  1.35s/it]Running loglikelihood requests:  23%|██▎       | 93/400 [02:09<06:53,  1.35s/it]Running loglikelihood requests:  24%|██▎       | 94/400 [02:10<06:51,  1.34s/it]Running loglikelihood requests:  24%|██▍       | 95/400 [02:12<06:49,  1.34s/it]Running loglikelihood requests:  24%|██▍       | 96/400 [02:13<06:47,  1.34s/it]Running loglikelihood requests:  24%|██▍       | 97/400 [02:14<06:46,  1.34s/it]Running loglikelihood requests:  24%|██▍       | 98/400 [02:16<06:44,  1.34s/it]Running loglikelihood requests:  25%|██▍       | 99/400 [02:17<06:43,  1.34s/it]Running loglikelihood requests:  25%|██▌       | 100/400 [02:18<06:42,  1.34s/it]Running loglikelihood requests:  25%|██▌       | 101/400 [02:20<06:41,  1.34s/it]Running loglikelihood requests:  26%|██▌       | 102/400 [02:21<06:40,  1.34s/it]Running loglikelihood requests:  26%|██▌       | 103/400 [02:22<06:38,  1.34s/it]Running loglikelihood requests:  26%|██▌       | 104/400 [02:24<06:37,  1.34s/it]Running loglikelihood requests:  26%|██▋       | 105/400 [02:25<06:35,  1.34s/it]Running loglikelihood requests:  26%|██▋       | 106/400 [02:26<06:34,  1.34s/it]Running loglikelihood requests:  27%|██▋       | 107/400 [02:28<06:32,  1.34s/it]Running loglikelihood requests:  27%|██▋       | 108/400 [02:29<06:31,  1.34s/it]Running loglikelihood requests:  27%|██▋       | 109/400 [02:30<06:30,  1.34s/it]Running loglikelihood requests:  28%|██▊       | 110/400 [02:32<06:29,  1.34s/it]Running loglikelihood requests:  28%|██▊       | 111/400 [02:33<06:27,  1.34s/it]Running loglikelihood requests:  28%|██▊       | 112/400 [02:34<06:25,  1.34s/it]Running loglikelihood requests:  28%|██▊       | 113/400 [02:36<06:37,  1.38s/it]Running loglikelihood requests:  28%|██▊       | 114/400 [02:37<06:39,  1.40s/it]Running loglikelihood requests:  29%|██▉       | 115/400 [02:39<06:35,  1.39s/it]Running loglikelihood requests:  29%|██▉       | 116/400 [02:40<06:31,  1.38s/it]Running loglikelihood requests:  29%|██▉       | 117/400 [02:41<06:28,  1.37s/it]Running loglikelihood requests:  30%|██▉       | 118/400 [02:43<06:26,  1.37s/it]Running loglikelihood requests:  30%|██▉       | 119/400 [02:44<06:24,  1.37s/it]Running loglikelihood requests:  30%|███       | 120/400 [02:46<06:22,  1.36s/it]Running loglikelihood requests:  30%|███       | 121/400 [02:47<06:20,  1.36s/it]Running loglikelihood requests:  30%|███       | 122/400 [02:48<06:18,  1.36s/it]Running loglikelihood requests:  31%|███       | 123/400 [02:50<06:16,  1.36s/it]Running loglikelihood requests:  31%|███       | 124/400 [02:51<06:15,  1.36s/it]Running loglikelihood requests:  31%|███▏      | 125/400 [02:52<06:13,  1.36s/it]Running loglikelihood requests:  32%|███▏      | 126/400 [02:54<06:12,  1.36s/it]Running loglikelihood requests:  32%|███▏      | 127/400 [02:55<06:14,  1.37s/it]Running loglikelihood requests:  32%|███▏      | 128/400 [02:57<06:24,  1.41s/it]Running loglikelihood requests:  32%|███▏      | 129/400 [02:58<06:15,  1.39s/it]Running loglikelihood requests:  32%|███▎      | 130/400 [02:59<06:10,  1.37s/it]Running loglikelihood requests:  33%|███▎      | 131/400 [03:01<06:05,  1.36s/it]Running loglikelihood requests:  33%|███▎      | 132/400 [03:02<06:01,  1.35s/it]Running loglikelihood requests:  33%|███▎      | 133/400 [03:03<05:58,  1.34s/it]Running loglikelihood requests:  34%|███▎      | 134/400 [03:05<05:56,  1.34s/it]Running loglikelihood requests:  34%|███▍      | 135/400 [03:06<05:53,  1.33s/it]Running loglikelihood requests:  34%|███▍      | 136/400 [03:07<05:52,  1.33s/it]Running loglikelihood requests:  34%|███▍      | 137/400 [03:09<05:50,  1.33s/it]Running loglikelihood requests:  34%|███▍      | 138/400 [03:10<05:48,  1.33s/it]Running loglikelihood requests:  35%|███▍      | 139/400 [03:11<05:57,  1.37s/it]Running loglikelihood requests:  35%|███▌      | 140/400 [03:13<05:53,  1.36s/it]Running loglikelihood requests:  35%|███▌      | 141/400 [03:14<05:49,  1.35s/it]Running loglikelihood requests:  36%|███▌      | 142/400 [03:15<05:45,  1.34s/it]Running loglikelihood requests:  36%|███▌      | 143/400 [03:17<05:43,  1.34s/it]Running loglikelihood requests:  36%|███▌      | 144/400 [03:18<05:40,  1.33s/it]Running loglikelihood requests:  36%|███▋      | 145/400 [03:19<05:40,  1.34s/it]Running loglikelihood requests:  36%|███▋      | 146/400 [03:21<05:37,  1.33s/it]Running loglikelihood requests:  37%|███▋      | 147/400 [03:22<05:35,  1.33s/it]Running loglikelihood requests:  37%|███▋      | 148/400 [03:23<05:39,  1.35s/it]Running loglikelihood requests:  37%|███▋      | 149/400 [03:25<05:47,  1.39s/it]Running loglikelihood requests:  38%|███▊      | 150/400 [03:26<05:53,  1.41s/it]Running loglikelihood requests:  38%|███▊      | 151/400 [03:28<05:56,  1.43s/it]Running loglikelihood requests:  38%|███▊      | 152/400 [03:29<05:55,  1.43s/it]Running loglikelihood requests:  38%|███▊      | 153/400 [03:31<05:57,  1.45s/it]Running loglikelihood requests:  38%|███▊      | 154/400 [03:32<05:52,  1.43s/it]Running loglikelihood requests:  39%|███▉      | 155/400 [03:33<05:43,  1.40s/it]Running loglikelihood requests:  39%|███▉      | 156/400 [03:35<05:37,  1.38s/it]Running loglikelihood requests:  39%|███▉      | 157/400 [03:36<05:32,  1.37s/it]Running loglikelihood requests:  40%|███▉      | 158/400 [03:37<05:28,  1.36s/it]Running loglikelihood requests:  40%|███▉      | 159/400 [03:39<05:25,  1.35s/it]Running loglikelihood requests:  40%|████      | 160/400 [03:40<05:23,  1.35s/it]Running loglikelihood requests:  40%|████      | 161/400 [03:41<05:20,  1.34s/it]Running loglikelihood requests:  40%|████      | 162/400 [03:43<05:18,  1.34s/it]Running loglikelihood requests:  41%|████      | 163/400 [03:44<05:16,  1.34s/it]Running loglikelihood requests:  41%|████      | 164/400 [03:45<05:14,  1.33s/it]Running loglikelihood requests:  41%|████▏     | 165/400 [03:47<05:13,  1.33s/it]Running loglikelihood requests:  42%|████▏     | 166/400 [03:48<05:11,  1.33s/it]Running loglikelihood requests:  42%|████▏     | 167/400 [03:49<05:10,  1.33s/it]Running loglikelihood requests:  42%|████▏     | 168/400 [03:51<05:13,  1.35s/it]Running loglikelihood requests:  42%|████▏     | 169/400 [03:52<05:21,  1.39s/it]Running loglikelihood requests:  42%|████▎     | 170/400 [03:54<05:25,  1.42s/it]Running loglikelihood requests:  43%|████▎     | 171/400 [03:55<05:32,  1.45s/it]Running loglikelihood requests:  43%|████▎     | 172/400 [03:57<05:34,  1.47s/it]Running loglikelihood requests:  43%|████▎     | 173/400 [03:58<05:34,  1.48s/it]Running loglikelihood requests:  44%|████▎     | 174/400 [04:00<05:34,  1.48s/it]Running loglikelihood requests:  44%|████▍     | 175/400 [04:01<05:32,  1.48s/it]Running loglikelihood requests:  44%|████▍     | 176/400 [04:03<05:30,  1.48s/it]Running loglikelihood requests:  44%|████▍     | 177/400 [04:04<05:27,  1.47s/it]Running loglikelihood requests:  44%|████▍     | 178/400 [04:06<05:16,  1.42s/it]Running loglikelihood requests:  45%|████▍     | 179/400 [04:07<05:07,  1.39s/it]Running loglikelihood requests:  45%|████▌     | 180/400 [04:08<05:01,  1.37s/it]Running loglikelihood requests:  45%|████▌     | 181/400 [04:10<04:56,  1.36s/it]Running loglikelihood requests:  46%|████▌     | 182/400 [04:11<04:53,  1.34s/it]Running loglikelihood requests:  46%|████▌     | 183/400 [04:12<04:50,  1.34s/it]Running loglikelihood requests:  46%|████▌     | 184/400 [04:13<04:47,  1.33s/it]Running loglikelihood requests:  46%|████▋     | 185/400 [04:15<04:45,  1.33s/it]Running loglikelihood requests:  46%|████▋     | 186/400 [04:16<04:43,  1.32s/it]Running loglikelihood requests:  47%|████▋     | 187/400 [04:17<04:41,  1.32s/it]Running loglikelihood requests:  47%|████▋     | 188/400 [04:19<04:39,  1.32s/it]Running loglikelihood requests:  47%|████▋     | 189/400 [04:20<04:38,  1.32s/it]Running loglikelihood requests:  48%|████▊     | 190/400 [04:21<04:36,  1.32s/it]Running loglikelihood requests:  48%|████▊     | 191/400 [04:23<04:35,  1.32s/it]Running loglikelihood requests:  48%|████▊     | 192/400 [04:24<04:34,  1.32s/it]Running loglikelihood requests:  48%|████▊     | 193/400 [04:25<04:32,  1.32s/it]Running loglikelihood requests:  48%|████▊     | 194/400 [04:27<04:31,  1.32s/it]Running loglikelihood requests:  49%|████▉     | 195/400 [04:28<04:36,  1.35s/it]Running loglikelihood requests:  49%|████▉     | 196/400 [04:30<04:43,  1.39s/it]Running loglikelihood requests:  49%|████▉     | 197/400 [04:31<04:47,  1.42s/it]Running loglikelihood requests:  50%|████▉     | 198/400 [04:32<04:45,  1.41s/it]Running loglikelihood requests:  50%|████▉     | 199/400 [04:34<04:37,  1.38s/it]Running loglikelihood requests:  50%|█████     | 200/400 [04:35<04:31,  1.36s/it]Running loglikelihood requests:  50%|█████     | 201/400 [04:36<04:27,  1.34s/it]Running loglikelihood requests:  50%|█████     | 202/400 [04:38<04:23,  1.33s/it]Running loglikelihood requests:  51%|█████     | 203/400 [04:39<04:23,  1.34s/it]Running loglikelihood requests:  51%|█████     | 204/400 [04:40<04:24,  1.35s/it]Running loglikelihood requests:  51%|█████▏    | 205/400 [04:42<04:21,  1.34s/it]Running loglikelihood requests:  52%|█████▏    | 206/400 [04:43<04:18,  1.33s/it]Running loglikelihood requests:  52%|█████▏    | 207/400 [04:44<04:16,  1.33s/it]Running loglikelihood requests:  52%|█████▏    | 208/400 [04:46<04:15,  1.33s/it]Running loglikelihood requests:  52%|█████▏    | 209/400 [04:47<04:20,  1.36s/it]Running loglikelihood requests:  52%|█████▎    | 210/400 [04:49<04:23,  1.38s/it]Running loglikelihood requests:  53%|█████▎    | 211/400 [04:50<04:24,  1.40s/it]Running loglikelihood requests:  53%|█████▎    | 212/400 [04:51<04:26,  1.42s/it]Running loglikelihood requests:  53%|█████▎    | 213/400 [04:53<04:19,  1.39s/it]Running loglikelihood requests:  54%|█████▎    | 214/400 [04:54<04:13,  1.36s/it]Running loglikelihood requests:  54%|█████▍    | 215/400 [04:55<04:07,  1.34s/it]Running loglikelihood requests:  54%|█████▍    | 216/400 [04:57<04:03,  1.32s/it]Running loglikelihood requests:  54%|█████▍    | 217/400 [04:58<03:59,  1.31s/it]Running loglikelihood requests:  55%|█████▍    | 218/400 [04:59<03:56,  1.30s/it]Running loglikelihood requests:  55%|█████▍    | 219/400 [05:00<03:54,  1.30s/it]Running loglikelihood requests:  55%|█████▌    | 220/400 [05:02<03:52,  1.29s/it]Running loglikelihood requests:  55%|█████▌    | 221/400 [05:03<03:50,  1.29s/it]Running loglikelihood requests:  56%|█████▌    | 222/400 [05:04<03:48,  1.28s/it]Running loglikelihood requests:  56%|█████▌    | 223/400 [05:06<03:46,  1.28s/it]Running loglikelihood requests:  56%|█████▌    | 224/400 [05:07<03:45,  1.28s/it]Running loglikelihood requests:  56%|█████▋    | 225/400 [05:08<03:43,  1.28s/it]Running loglikelihood requests:  56%|█████▋    | 226/400 [05:09<03:42,  1.28s/it]Running loglikelihood requests:  57%|█████▋    | 227/400 [05:11<03:40,  1.28s/it]Running loglikelihood requests:  57%|█████▋    | 228/400 [05:12<03:39,  1.28s/it]Running loglikelihood requests:  57%|█████▋    | 229/400 [05:13<03:37,  1.27s/it]Running loglikelihood requests:  57%|█████▊    | 230/400 [05:15<03:36,  1.27s/it]Running loglikelihood requests:  58%|█████▊    | 231/400 [05:16<03:35,  1.28s/it]Running loglikelihood requests:  58%|█████▊    | 232/400 [05:17<03:34,  1.27s/it]Running loglikelihood requests:  58%|█████▊    | 233/400 [05:18<03:32,  1.27s/it]Running loglikelihood requests:  58%|█████▊    | 234/400 [05:20<03:30,  1.27s/it]Running loglikelihood requests:  59%|█████▉    | 235/400 [05:21<03:31,  1.28s/it]Running loglikelihood requests:  59%|█████▉    | 236/400 [05:22<03:30,  1.28s/it]Running loglikelihood requests:  59%|█████▉    | 237/400 [05:23<03:28,  1.28s/it]Running loglikelihood requests:  60%|█████▉    | 238/400 [05:25<03:26,  1.27s/it]Running loglikelihood requests:  60%|█████▉    | 239/400 [05:26<03:24,  1.27s/it]Running loglikelihood requests:  60%|██████    | 240/400 [05:27<03:23,  1.27s/it]Running loglikelihood requests:  60%|██████    | 241/400 [05:28<03:20,  1.26s/it]Running loglikelihood requests:  60%|██████    | 242/400 [05:30<03:18,  1.25s/it]Running loglikelihood requests:  61%|██████    | 243/400 [05:31<03:16,  1.25s/it]Running loglikelihood requests:  61%|██████    | 244/400 [05:32<03:14,  1.25s/it]Running loglikelihood requests:  61%|██████▏   | 245/400 [05:33<03:12,  1.24s/it]Running loglikelihood requests:  62%|██████▏   | 246/400 [05:35<03:10,  1.24s/it]Running loglikelihood requests:  62%|██████▏   | 247/400 [05:36<03:09,  1.24s/it]Running loglikelihood requests:  62%|██████▏   | 248/400 [05:37<03:09,  1.25s/it]Running loglikelihood requests:  62%|██████▏   | 249/400 [05:38<03:08,  1.25s/it]Running loglikelihood requests:  62%|██████▎   | 250/400 [05:40<03:06,  1.24s/it]Running loglikelihood requests:  63%|██████▎   | 251/400 [05:41<03:05,  1.24s/it]Running loglikelihood requests:  63%|██████▎   | 252/400 [05:42<03:03,  1.24s/it]Running loglikelihood requests:  63%|██████▎   | 253/400 [05:43<03:02,  1.24s/it]Running loglikelihood requests:  64%|██████▎   | 254/400 [05:45<03:01,  1.24s/it]Running loglikelihood requests:  64%|██████▍   | 255/400 [05:46<02:59,  1.24s/it]Running loglikelihood requests:  64%|██████▍   | 256/400 [05:47<03:00,  1.26s/it]Running loglikelihood requests:  64%|██████▍   | 257/400 [05:48<02:58,  1.25s/it]Running loglikelihood requests:  64%|██████▍   | 258/400 [05:50<02:56,  1.25s/it]Running loglikelihood requests:  65%|██████▍   | 259/400 [05:51<02:54,  1.24s/it]Running loglikelihood requests:  65%|██████▌   | 260/400 [05:52<02:52,  1.24s/it]Running loglikelihood requests:  65%|██████▌   | 261/400 [05:53<02:51,  1.23s/it]Running loglikelihood requests:  66%|██████▌   | 262/400 [05:55<02:49,  1.23s/it]Running loglikelihood requests:  66%|██████▌   | 263/400 [05:56<02:48,  1.23s/it]Running loglikelihood requests:  66%|██████▌   | 264/400 [05:57<02:47,  1.23s/it]Running loglikelihood requests:  66%|██████▋   | 265/400 [05:58<02:45,  1.23s/it]Running loglikelihood requests:  66%|██████▋   | 266/400 [05:59<02:44,  1.23s/it]Running loglikelihood requests:  67%|██████▋   | 267/400 [06:01<02:42,  1.22s/it]Running loglikelihood requests:  67%|██████▋   | 268/400 [06:02<02:43,  1.24s/it]Running loglikelihood requests:  67%|██████▋   | 269/400 [06:03<02:46,  1.27s/it]Running loglikelihood requests:  68%|██████▊   | 270/400 [06:05<02:48,  1.30s/it]Running loglikelihood requests:  68%|██████▊   | 271/400 [06:06<02:49,  1.31s/it]Running loglikelihood requests:  68%|██████▊   | 272/400 [06:07<02:49,  1.32s/it]Running loglikelihood requests:  68%|██████▊   | 273/400 [06:09<02:49,  1.33s/it]Running loglikelihood requests:  68%|██████▊   | 274/400 [06:10<02:47,  1.33s/it]Running loglikelihood requests:  69%|██████▉   | 275/400 [06:11<02:41,  1.29s/it]Running loglikelihood requests:  69%|██████▉   | 276/400 [06:12<02:37,  1.27s/it]Running loglikelihood requests:  69%|██████▉   | 277/400 [06:14<02:34,  1.25s/it]Running loglikelihood requests:  70%|██████▉   | 278/400 [06:15<02:31,  1.24s/it]Running loglikelihood requests:  70%|██████▉   | 279/400 [06:16<02:29,  1.23s/it]Running loglikelihood requests:  70%|███████   | 280/400 [06:17<02:27,  1.23s/it]Running loglikelihood requests:  70%|███████   | 281/400 [06:18<02:25,  1.22s/it]Running loglikelihood requests:  70%|███████   | 282/400 [06:20<02:23,  1.22s/it]Running loglikelihood requests:  71%|███████   | 283/400 [06:21<02:22,  1.22s/it]Running loglikelihood requests:  71%|███████   | 284/400 [06:22<02:20,  1.21s/it]Running loglikelihood requests:  71%|███████▏  | 285/400 [06:23<02:19,  1.21s/it]Running loglikelihood requests:  72%|███████▏  | 286/400 [06:25<02:18,  1.21s/it]Running loglikelihood requests:  72%|███████▏  | 287/400 [06:26<02:17,  1.22s/it]Running loglikelihood requests:  72%|███████▏  | 288/400 [06:27<02:19,  1.25s/it]Running loglikelihood requests:  72%|███████▏  | 289/400 [06:28<02:16,  1.23s/it]Running loglikelihood requests:  72%|███████▎  | 290/400 [06:29<02:14,  1.22s/it]Running loglikelihood requests:  73%|███████▎  | 291/400 [06:31<02:12,  1.22s/it]Running loglikelihood requests:  73%|███████▎  | 292/400 [06:32<02:10,  1.21s/it]Running loglikelihood requests:  73%|███████▎  | 293/400 [06:33<02:09,  1.21s/it]Running loglikelihood requests:  74%|███████▎  | 294/400 [06:34<02:07,  1.20s/it]Running loglikelihood requests:  74%|███████▍  | 295/400 [06:35<02:06,  1.20s/it]Running loglikelihood requests:  74%|███████▍  | 296/400 [06:37<02:04,  1.20s/it]Running loglikelihood requests:  74%|███████▍  | 297/400 [06:38<02:03,  1.20s/it]Running loglikelihood requests:  74%|███████▍  | 298/400 [06:39<02:01,  1.19s/it]Running loglikelihood requests:  75%|███████▍  | 299/400 [06:40<02:00,  1.19s/it]Running loglikelihood requests:  75%|███████▌  | 300/400 [06:41<01:59,  1.19s/it]Running loglikelihood requests:  75%|███████▌  | 301/400 [06:43<01:57,  1.19s/it]Running loglikelihood requests:  76%|███████▌  | 302/400 [06:44<01:56,  1.19s/it]Running loglikelihood requests:  76%|███████▌  | 303/400 [06:45<01:55,  1.19s/it]Running loglikelihood requests:  76%|███████▌  | 304/400 [06:46<01:53,  1.19s/it]Running loglikelihood requests:  76%|███████▋  | 305/400 [06:47<01:52,  1.18s/it]Running loglikelihood requests:  76%|███████▋  | 306/400 [06:49<01:51,  1.18s/it]Running loglikelihood requests:  77%|███████▋  | 307/400 [06:50<01:50,  1.18s/it]Running loglikelihood requests:  77%|███████▋  | 308/400 [06:51<01:48,  1.18s/it]Running loglikelihood requests:  77%|███████▋  | 309/400 [06:52<01:52,  1.23s/it]Running loglikelihood requests:  78%|███████▊  | 310/400 [06:54<01:53,  1.26s/it]Running loglikelihood requests:  78%|███████▊  | 311/400 [06:55<01:50,  1.24s/it]Running loglikelihood requests:  78%|███████▊  | 312/400 [06:56<01:47,  1.22s/it]Running loglikelihood requests:  78%|███████▊  | 313/400 [06:57<01:45,  1.21s/it]Running loglikelihood requests:  78%|███████▊  | 314/400 [06:58<01:42,  1.20s/it]Running loglikelihood requests:  79%|███████▉  | 315/400 [06:59<01:41,  1.19s/it]Running loglikelihood requests:  79%|███████▉  | 316/400 [07:01<01:41,  1.21s/it]Running loglikelihood requests:  79%|███████▉  | 317/400 [07:02<01:40,  1.21s/it]Running loglikelihood requests:  80%|███████▉  | 318/400 [07:03<01:38,  1.21s/it]Running loglikelihood requests:  80%|███████▉  | 319/400 [07:04<01:37,  1.20s/it]Running loglikelihood requests:  80%|████████  | 320/400 [07:06<01:37,  1.22s/it]Running loglikelihood requests:  80%|████████  | 321/400 [07:07<01:35,  1.21s/it]Running loglikelihood requests:  80%|████████  | 322/400 [07:08<01:33,  1.20s/it]Running loglikelihood requests:  81%|████████  | 323/400 [07:09<01:31,  1.19s/it]Running loglikelihood requests:  81%|████████  | 324/400 [07:10<01:30,  1.19s/it]Running loglikelihood requests:  81%|████████▏ | 325/400 [07:11<01:28,  1.18s/it]Running loglikelihood requests:  82%|████████▏ | 326/400 [07:13<01:27,  1.18s/it]Running loglikelihood requests:  82%|████████▏ | 327/400 [07:14<01:25,  1.18s/it]Running loglikelihood requests:  82%|████████▏ | 328/400 [07:15<01:24,  1.18s/it]Running loglikelihood requests:  82%|████████▏ | 329/400 [07:16<01:23,  1.17s/it]Running loglikelihood requests:  82%|████████▎ | 330/400 [07:17<01:22,  1.17s/it]Running loglikelihood requests:  83%|████████▎ | 331/400 [07:18<01:20,  1.17s/it]Running loglikelihood requests:  83%|████████▎ | 332/400 [07:20<01:19,  1.17s/it]Running loglikelihood requests:  83%|████████▎ | 333/400 [07:21<01:18,  1.17s/it]Running loglikelihood requests:  84%|████████▎ | 334/400 [07:22<01:17,  1.17s/it]Running loglikelihood requests:  84%|████████▍ | 335/400 [07:23<01:16,  1.17s/it]Running loglikelihood requests:  84%|████████▍ | 336/400 [07:24<01:14,  1.17s/it]Running loglikelihood requests:  84%|████████▍ | 337/400 [07:26<01:13,  1.17s/it]Running loglikelihood requests:  84%|████████▍ | 338/400 [07:27<01:12,  1.17s/it]Running loglikelihood requests:  85%|████████▍ | 339/400 [07:28<01:11,  1.17s/it]Running loglikelihood requests:  85%|████████▌ | 340/400 [07:29<01:10,  1.17s/it]Running loglikelihood requests:  85%|████████▌ | 341/400 [07:30<01:09,  1.17s/it]Running loglikelihood requests:  86%|████████▌ | 342/400 [07:31<01:07,  1.17s/it]Running loglikelihood requests:  86%|████████▌ | 343/400 [07:33<01:06,  1.17s/it]Running loglikelihood requests:  86%|████████▌ | 344/400 [07:34<01:05,  1.17s/it]Running loglikelihood requests:  86%|████████▋ | 345/400 [07:35<01:04,  1.17s/it]Running loglikelihood requests:  86%|████████▋ | 346/400 [07:36<01:03,  1.17s/it]Running loglikelihood requests:  87%|████████▋ | 347/400 [07:37<01:02,  1.17s/it]Running loglikelihood requests:  87%|████████▋ | 348/400 [07:38<01:00,  1.17s/it]Running loglikelihood requests:  87%|████████▋ | 349/400 [07:40<00:59,  1.17s/it]Running loglikelihood requests:  88%|████████▊ | 350/400 [07:41<00:58,  1.17s/it]Running loglikelihood requests:  88%|████████▊ | 351/400 [07:42<00:57,  1.17s/it]Running loglikelihood requests:  88%|████████▊ | 352/400 [07:43<00:55,  1.17s/it]Running loglikelihood requests:  88%|████████▊ | 353/400 [07:44<00:54,  1.17s/it]Running loglikelihood requests:  88%|████████▊ | 354/400 [07:45<00:53,  1.17s/it]Running loglikelihood requests:  89%|████████▉ | 355/400 [07:47<00:52,  1.17s/it]Running loglikelihood requests:  89%|████████▉ | 356/400 [07:48<00:51,  1.17s/it]Running loglikelihood requests:  89%|████████▉ | 357/400 [07:49<00:50,  1.16s/it]Running loglikelihood requests:  90%|████████▉ | 358/400 [07:50<00:48,  1.17s/it]Running loglikelihood requests:  90%|████████▉ | 359/400 [07:51<00:47,  1.16s/it]Running loglikelihood requests:  90%|█████████ | 360/400 [07:52<00:47,  1.19s/it]Running loglikelihood requests:  90%|█████████ | 361/400 [07:54<00:46,  1.19s/it]Running loglikelihood requests:  90%|█████████ | 362/400 [07:55<00:45,  1.19s/it]Running loglikelihood requests:  91%|█████████ | 363/400 [07:56<00:44,  1.20s/it]Running loglikelihood requests:  91%|█████████ | 364/400 [07:57<00:43,  1.22s/it]Running loglikelihood requests:  91%|█████████▏| 365/400 [07:58<00:41,  1.20s/it]Running loglikelihood requests:  92%|█████████▏| 366/400 [08:00<00:41,  1.22s/it]Running loglikelihood requests:  92%|█████████▏| 367/400 [08:01<00:40,  1.24s/it]Running loglikelihood requests:  92%|█████████▏| 368/400 [08:02<00:39,  1.25s/it]Running loglikelihood requests:  92%|█████████▏| 369/400 [08:04<00:38,  1.26s/it]Running loglikelihood requests:  92%|█████████▎| 370/400 [08:05<00:37,  1.26s/it]Running loglikelihood requests:  93%|█████████▎| 371/400 [08:06<00:36,  1.25s/it]Running loglikelihood requests:  93%|█████████▎| 372/400 [08:07<00:34,  1.23s/it]Running loglikelihood requests:  93%|█████████▎| 373/400 [08:08<00:32,  1.21s/it]Running loglikelihood requests:  94%|█████████▎| 374/400 [08:10<00:30,  1.19s/it]Running loglikelihood requests:  94%|█████████▍| 375/400 [08:11<00:29,  1.18s/it]Running loglikelihood requests:  94%|█████████▍| 376/400 [08:12<00:28,  1.17s/it]Running loglikelihood requests:  94%|█████████▍| 377/400 [08:13<00:26,  1.16s/it]Running loglikelihood requests:  94%|█████████▍| 378/400 [08:14<00:25,  1.16s/it]Running loglikelihood requests:  95%|█████████▍| 379/400 [08:15<00:24,  1.15s/it]Running loglikelihood requests:  95%|█████████▌| 380/400 [08:16<00:22,  1.15s/it]Running loglikelihood requests:  95%|█████████▌| 381/400 [08:18<00:21,  1.15s/it]Running loglikelihood requests:  96%|█████████▌| 382/400 [08:19<00:20,  1.14s/it]Running loglikelihood requests:  96%|█████████▌| 383/400 [08:20<00:19,  1.14s/it]Running loglikelihood requests:  96%|█████████▌| 384/400 [08:21<00:18,  1.16s/it]Running loglikelihood requests:  96%|█████████▋| 385/400 [08:22<00:17,  1.17s/it]Running loglikelihood requests:  96%|█████████▋| 386/400 [08:23<00:16,  1.14s/it]Running loglikelihood requests:  97%|█████████▋| 387/400 [08:24<00:14,  1.13s/it]Running loglikelihood requests:  97%|█████████▋| 388/400 [08:25<00:13,  1.11s/it]Running loglikelihood requests:  97%|█████████▋| 389/400 [08:27<00:11,  1.08s/it]Running loglikelihood requests:  98%|█████████▊| 390/400 [08:28<00:10,  1.06s/it]Running loglikelihood requests:  98%|█████████▊| 391/400 [08:29<00:09,  1.05s/it]Running loglikelihood requests:  98%|█████████▊| 392/400 [08:30<00:08,  1.03s/it]Running loglikelihood requests:  98%|█████████▊| 393/400 [08:31<00:07,  1.02s/it]Running loglikelihood requests:  98%|█████████▊| 394/400 [08:32<00:06,  1.01s/it]Running loglikelihood requests:  99%|█████████▉| 395/400 [08:33<00:05,  1.01s/it]Running loglikelihood requests:  99%|█████████▉| 396/400 [08:34<00:04,  1.00s/it]Running loglikelihood requests:  99%|█████████▉| 397/400 [08:34<00:02,  1.02it/s]Running loglikelihood requests: 100%|█████████▉| 398/400 [08:35<00:01,  1.03it/s]Running loglikelihood requests: 100%|█████████▉| 399/400 [08:36<00:00,  1.04it/s]Running loglikelihood requests: 100%|██████████| 400/400 [08:37<00:00,  1.05it/s]Running loglikelihood requests: 100%|██████████| 400/400 [08:37<00:00,  1.29s/it]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:0'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}
full model:
{'mastermind_46_easy': {'alias': 'mastermind_46_easy', 'acc,none': 0.75, 'acc_stderr,none': 0.04351941398892446}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9900730655060652
0.9975621416797388
0.9971758007187725
0.9980230222224056
0.9889479987910904
0.9764864248764976
0.9903944102306983
0.9944743493554844
0.9959595842537624
0.9872350810596702
0.9630442697748985
0.9836939129473328
0.9680042833072414
0.9739989664157891
0.9945965755000291
0.9874567967365809
0.9910190996776087
0.9888895436517939
0.9820307305549418
0.9881803990776891
0.9859944271811626
0.9931460182904469
0.984259193892523
0.99673879588459
0.9800909214289261
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[5, 2, 0, 3, 7, 6, 1, 4]
tensor([5, 2, 0, 3, 7, 6, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 0, 3, 7, 6, 1, 4]
tensor([5, 2, 0, 3, 7, 6, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 0, 3, 7, 6, 1, 4]
tensor([5, 2, 0, 3, 7, 6, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 0, 3, 7, 6, 1, 4]
tensor([5, 2, 0, 3, 7, 6, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 0, 3, 7, 6, 1, 4]
tensor([5, 2, 0, 3, 7, 6, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 0, 3, 7, 6, 1, 4]
tensor([5, 2, 0, 3, 7, 6, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Normal merging for layer 2
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Normal merging for layer 3
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Normal merging for layer 4
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Normal merging for layer 5
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 6 to 31
done!
all done!
Model size: 12.0718 GB
178
cuda:0
wnli
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:44<00:44, 44.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:57<00:00, 26.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:57<00:00, 28.83s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/wnli?recursive=False&expand=False HTTP/1.1" 307 141
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/wnli?recursive=False&expand=False HTTP/1.1" 200 352
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139750522786768 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139750522786768 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139750522786768 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139750522786768 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139748506891232 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139748506891232 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139748506891232 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139748506891232 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2569.80it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:01<03:24,  1.45s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:02<01:32,  1.51it/s]Running loglikelihood requests:   4%|▎         | 5/142 [00:03<01:14,  1.84it/s]Running loglikelihood requests:   5%|▍         | 7/142 [00:03<01:05,  2.08it/s]Running loglikelihood requests:   6%|▋         | 9/142 [00:04<00:59,  2.24it/s]Running loglikelihood requests:   8%|▊         | 11/142 [00:05<00:55,  2.38it/s]Running loglikelihood requests:   9%|▉         | 13/142 [00:06<00:52,  2.47it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:06<00:49,  2.58it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:07<00:46,  2.66it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:08<00:44,  2.77it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:08<00:42,  2.84it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:09<00:40,  2.93it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:10<00:39,  2.99it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:10<00:37,  3.05it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:11<00:36,  3.10it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:12<00:35,  3.13it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:12<00:34,  3.16it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:13<00:33,  3.18it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:13<00:32,  3.19it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:14<00:32,  3.21it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:15<00:31,  3.22it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:15<00:30,  3.24it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:16<00:29,  3.27it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:16<00:28,  3.31it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:17<00:27,  3.34it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:18<00:26,  3.39it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:18<00:26,  3.42it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:19<00:25,  3.45it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:19<00:24,  3.48it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:20<00:23,  3.50it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:20<00:23,  3.51it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:21<00:22,  3.52it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:22<00:21,  3.53it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:22<00:21,  3.54it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:23<00:20,  3.56it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:23<00:19,  3.57it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:24<00:19,  3.58it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [00:24<00:18,  3.59it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [00:25<00:18,  3.60it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [00:25<00:17,  3.62it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [00:26<00:16,  3.63it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [00:26<00:16,  3.64it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [00:27<00:15,  3.64it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [00:28<00:15,  3.66it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [00:28<00:14,  3.67it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [00:29<00:13,  3.67it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [00:29<00:13,  3.69it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [00:30<00:12,  3.70it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [00:30<00:12,  3.71it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [00:31<00:11,  3.72it/s]Running loglikelihood requests:  71%|███████   | 101/142 [00:31<00:10,  3.74it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [00:32<00:10,  3.75it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [00:32<00:09,  3.76it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [00:33<00:09,  3.77it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [00:33<00:08,  3.78it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [00:34<00:08,  3.79it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [00:34<00:07,  3.81it/s]Running loglikelihood requests:  81%|████████  | 115/142 [00:35<00:07,  3.81it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [00:36<00:06,  3.81it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [00:36<00:06,  3.82it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [00:37<00:05,  3.82it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [00:37<00:04,  3.84it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [00:38<00:04,  3.86it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [00:38<00:03,  3.87it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [00:39<00:03,  3.89it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [00:39<00:02,  3.90it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [00:40<00:02,  3.92it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [00:40<00:01,  3.93it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [00:41<00:01,  3.97it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [00:41<00:00,  4.00it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [00:42<00:00,  4.05it/s]Running loglikelihood requests: 100%|██████████| 142/142 [00:42<00:00,  3.37it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:1'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:1'}
full model:
{'wnli': {'alias': 'wnli', 'acc,none': 0.5352112676056338, 'acc_stderr,none': 0.0596130578497224}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.31190044950254875
0.7306280553786256
0.6985925052465822
0.5843516732063875
0.8124235844589114
0.820438203921003
0.6253838264581936
0.7600037006947045
0.8225872978677496
0.708398461303215
0.8646089269479391
0.8239362351853257
0.7608099850331435
0.6657423857513638
0.7943257460202938
0.7511476003698512
0.9073696655228775
0.8741838353767599
0.7945799099309127
0.9323691001541556
0.865243808509542
0.8176606226311932
0.6785099625983169
0.9579534328203848
0.788928884938056
0.9833718962298513
0.5933012307657521
0.7829988799240639
0.7823073743206628
0.31190044950254875
0.7306280553786256
0.6985925052465822
0.5843516732063875
0.8124235844589114
0.820438203921003
0.6253838264581936
0.7600037006947045
0.8225872978677496
0.708398461303215
0.8646089269479391
0.8239362351853257
0.7608099850331435
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[7, 4, 5, 1, 6, 3, 2, 0]
tensor([7, 4, 5, 1, 6, 3, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 2, 4, 5, 6, 1, 0, 3]
tensor([7, 2, 4, 5, 6, 1, 0, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 7, 5, 4, 1, 2, 0]
tensor([6, 3, 7, 5, 4, 1, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 3, 6, 4, 7, 1, 2, 0]
tensor([5, 3, 6, 4, 7, 1, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 3, 6, 5, 7, 2, 1, 0]
tensor([4, 3, 6, 5, 7, 2, 1, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1, 2, 3, 2, 3, 0]
tensor([0, 1, 1, 2, 3, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 1, 2, 2, 3, 0, 3, 1]
tensor([0, 1, 2, 2, 3, 0, 3, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 1, 1, 1.0, 1.0, 1.0, 1.0]
tensor([0, 0, 1, 1, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
Normal merging for layer 1
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
done!
Normal merging for layer 2
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
tensor([3])
tensor(3)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Normal merging for layer 4
tensor([7])
tensor(7)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 5 to 15
done!
Normal merging for layer 16
tensor([0, 7])
tensor(0)
tensor([1, 2])
tensor(1)
tensor([3, 5])
tensor(3)
tensor([4, 6])
tensor(4)
done!
Normal merging for layer 17
tensor([0, 5])
tensor(0)
tensor([1, 7])
tensor(1)
tensor([2, 3])
tensor(2)
tensor([4, 6])
tensor(4)
done!
Cross-layer merge completed for layers 18 to 30
done!
Normal merging for layer 31
tensor([0, 1])
tensor(0)
tensor([2, 3, 4, 5, 6, 7])
tensor(2)
done!
all done!
Model size: 12.2608 GB
236
cuda:1
cola
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:41<00:41, 41.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 24.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 27.02s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: cola] metric mcc is defined, but aggregation is not. using default aggregation=matthews_corrcoef
WARNING:lm_eval.api.task:[Task: cola] metric mcc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139718425351984 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_cola_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139718425351984 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_cola_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139718425351984 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_cola_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139718425351984 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_cola_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139722779010656 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139722779010656 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139722779010656 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139722779010656 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of cola from None to 0
INFO:lm_eval.api.task:Building contexts for cola on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 3208.99it/s]
DEBUG:lm_eval.evaluator:Task: cola; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:01<03:31,  1.06s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:01<01:36,  2.05it/s]Running loglikelihood requests:   2%|▎         | 5/200 [00:02<01:13,  2.66it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:02<01:04,  3.00it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:03<00:58,  3.28it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:03<00:54,  3.47it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:04<00:51,  3.61it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:04<00:49,  3.71it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:05<00:48,  3.79it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:05<00:47,  3.84it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:06<00:46,  3.88it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:06<00:45,  3.91it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:07<00:44,  3.94it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:07<00:43,  3.97it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:08<00:42,  3.99it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:08<00:42,  4.01it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:09<00:41,  4.01it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:09<00:40,  4.04it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:10<00:40,  4.05it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:10<00:39,  4.07it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:11<00:39,  4.07it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:11<00:38,  4.07it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:12<00:37,  4.09it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:12<00:37,  4.10it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:13<00:36,  4.11it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:13<00:36,  4.13it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:14<00:35,  4.14it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:14<00:34,  4.15it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:15<00:34,  4.16it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:15<00:33,  4.17it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:16<00:33,  4.19it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:16<00:32,  4.20it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:16<00:32,  4.20it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:17<00:31,  4.20it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:17<00:31,  4.23it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:18<00:30,  4.24it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:18<00:29,  4.25it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:19<00:29,  4.19it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:19<00:29,  4.23it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:20<00:28,  4.17it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:20<00:28,  4.23it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:21<00:27,  4.27it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:21<00:26,  4.32it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:22<00:26,  4.32it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:22<00:25,  4.30it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:23<00:25,  4.25it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:23<00:24,  4.29it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:24<00:24,  4.33it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:24<00:23,  4.35it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:24<00:23,  4.38it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:25<00:22,  4.41it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:25<00:21,  4.42it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:26<00:21,  4.37it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:26<00:21,  4.37it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:27<00:20,  4.36it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:27<00:20,  4.36it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:28<00:19,  4.36it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:28<00:19,  4.36it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:29<00:18,  4.37it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:29<00:18,  4.38it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:29<00:17,  4.39it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:30<00:17,  4.40it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:30<00:17,  4.40it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [00:31<00:16,  4.41it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [00:31<00:16,  4.41it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [00:32<00:15,  4.43it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [00:32<00:15,  4.45it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [00:33<00:14,  4.44it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [00:33<00:14,  4.45it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [00:33<00:13,  4.46it/s]Running loglikelihood requests:  70%|███████   | 141/200 [00:34<00:13,  4.47it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [00:34<00:12,  4.48it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [00:35<00:12,  4.49it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [00:35<00:11,  4.50it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [00:36<00:11,  4.51it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [00:36<00:10,  4.51it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [00:37<00:10,  4.52it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [00:37<00:09,  4.51it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [00:37<00:09,  4.53it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [00:38<00:09,  4.55it/s]Running loglikelihood requests:  80%|████████  | 161/200 [00:38<00:08,  4.56it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [00:39<00:08,  4.56it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [00:39<00:07,  4.57it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [00:40<00:07,  4.57it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [00:40<00:06,  4.58it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [00:41<00:06,  4.60it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [00:41<00:05,  4.56it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [00:41<00:05,  4.60it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [00:42<00:04,  4.64it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [00:42<00:04,  4.66it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [00:43<00:04,  4.64it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [00:43<00:03,  4.62it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [00:44<00:03,  4.61it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [00:44<00:02,  4.61it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [00:44<00:02,  4.62it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [00:45<00:01,  4.64it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [00:45<00:01,  4.66it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [00:46<00:01,  4.67it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [00:46<00:00,  4.67it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [00:47<00:00,  4.69it/s]Running loglikelihood requests: 100%|██████████| 200/200 [00:47<00:00,  4.25it/s]
bootstrapping for stddev (sequential): matthews_corrcoef
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<01:33,  1.06it/s]  2%|▏         | 2/100 [00:01<01:30,  1.08it/s]  3%|▎         | 3/100 [00:02<01:29,  1.08it/s]  4%|▍         | 4/100 [00:03<01:28,  1.08it/s]  5%|▌         | 5/100 [00:04<01:27,  1.09it/s]  6%|▌         | 6/100 [00:05<01:26,  1.09it/s]  7%|▋         | 7/100 [00:06<01:25,  1.09it/s]  8%|▊         | 8/100 [00:07<01:24,  1.08it/s]  9%|▉         | 9/100 [00:08<01:23,  1.09it/s] 10%|█         | 10/100 [00:09<01:22,  1.09it/s] 11%|█         | 11/100 [00:10<01:21,  1.09it/s] 12%|█▏        | 12/100 [00:11<01:20,  1.09it/s] 13%|█▎        | 13/100 [00:11<01:19,  1.09it/s] 14%|█▍        | 14/100 [00:12<01:18,  1.09it/s] 15%|█▌        | 15/100 [00:13<01:17,  1.09it/s] 16%|█▌        | 16/100 [00:14<01:16,  1.09it/s] 17%|█▋        | 17/100 [00:15<01:15,  1.09it/s] 18%|█▊        | 18/100 [00:16<01:15,  1.09it/s] 19%|█▉        | 19/100 [00:17<01:14,  1.09it/s] 20%|██        | 20/100 [00:18<01:13,  1.09it/s] 21%|██        | 21/100 [00:19<01:12,  1.09it/s] 22%|██▏       | 22/100 [00:20<01:11,  1.09it/s] 23%|██▎       | 23/100 [00:21<01:10,  1.09it/s] 24%|██▍       | 24/100 [00:22<01:09,  1.09it/s] 25%|██▌       | 25/100 [00:22<01:08,  1.09it/s] 26%|██▌       | 26/100 [00:23<01:07,  1.09it/s] 27%|██▋       | 27/100 [00:24<01:06,  1.09it/s] 28%|██▊       | 28/100 [00:25<01:05,  1.09it/s] 29%|██▉       | 29/100 [00:26<01:05,  1.09it/s] 30%|███       | 30/100 [00:27<01:04,  1.09it/s] 31%|███       | 31/100 [00:28<01:03,  1.09it/s] 32%|███▏      | 32/100 [00:29<01:02,  1.09it/s] 33%|███▎      | 33/100 [00:30<01:01,  1.09it/s] 34%|███▍      | 34/100 [00:31<01:00,  1.09it/s] 35%|███▌      | 35/100 [00:32<00:59,  1.09it/s] 36%|███▌      | 36/100 [00:33<00:58,  1.09it/s] 37%|███▋      | 37/100 [00:33<00:57,  1.09it/s] 38%|███▊      | 38/100 [00:34<00:56,  1.09it/s] 39%|███▉      | 39/100 [00:35<00:56,  1.09it/s] 40%|████      | 40/100 [00:36<00:55,  1.09it/s] 41%|████      | 41/100 [00:37<00:55,  1.07it/s] 42%|████▏     | 42/100 [00:38<00:54,  1.07it/s] 43%|████▎     | 43/100 [00:39<00:52,  1.08it/s] 44%|████▍     | 44/100 [00:40<00:51,  1.08it/s] 45%|████▌     | 45/100 [00:41<00:50,  1.08it/s] 46%|████▌     | 46/100 [00:42<00:50,  1.08it/s] 47%|████▋     | 47/100 [00:43<00:49,  1.08it/s] 48%|████▊     | 48/100 [00:44<00:48,  1.08it/s] 49%|████▉     | 49/100 [00:45<00:47,  1.08it/s] 50%|█████     | 50/100 [00:46<00:46,  1.08it/s] 51%|█████     | 51/100 [00:46<00:45,  1.08it/s] 52%|█████▏    | 52/100 [00:47<00:44,  1.08it/s] 53%|█████▎    | 53/100 [00:48<00:43,  1.08it/s] 54%|█████▍    | 54/100 [00:49<00:42,  1.08it/s] 55%|█████▌    | 55/100 [00:50<00:41,  1.08it/s] 56%|█████▌    | 56/100 [00:51<00:40,  1.08it/s] 57%|█████▋    | 57/100 [00:52<00:39,  1.08it/s] 58%|█████▊    | 58/100 [00:53<00:38,  1.08it/s] 59%|█████▉    | 59/100 [00:54<00:37,  1.08it/s] 60%|██████    | 60/100 [00:55<00:36,  1.08it/s] 61%|██████    | 61/100 [00:56<00:36,  1.08it/s] 62%|██████▏   | 62/100 [00:57<00:35,  1.08it/s] 63%|██████▎   | 63/100 [00:58<00:34,  1.08it/s] 64%|██████▍   | 64/100 [00:58<00:33,  1.08it/s] 65%|██████▌   | 65/100 [00:59<00:32,  1.08it/s] 66%|██████▌   | 66/100 [01:00<00:31,  1.08it/s] 67%|██████▋   | 67/100 [01:01<00:30,  1.08it/s] 68%|██████▊   | 68/100 [01:02<00:29,  1.08it/s] 69%|██████▉   | 69/100 [01:03<00:28,  1.08it/s] 70%|███████   | 70/100 [01:04<00:27,  1.08it/s] 71%|███████   | 71/100 [01:05<00:26,  1.08it/s] 72%|███████▏  | 72/100 [01:06<00:25,  1.08it/s] 73%|███████▎  | 73/100 [01:07<00:25,  1.08it/s] 74%|███████▍  | 74/100 [01:08<00:24,  1.08it/s] 75%|███████▌  | 75/100 [01:09<00:23,  1.08it/s] 76%|███████▌  | 76/100 [01:10<00:22,  1.08it/s] 77%|███████▋  | 77/100 [01:11<00:21,  1.08it/s] 78%|███████▊  | 78/100 [01:11<00:20,  1.08it/s] 79%|███████▉  | 79/100 [01:12<00:19,  1.08it/s] 80%|████████  | 80/100 [01:13<00:18,  1.08it/s] 81%|████████  | 81/100 [01:14<00:17,  1.08it/s] 82%|████████▏ | 82/100 [01:15<00:16,  1.08it/s] 83%|████████▎ | 83/100 [01:16<00:15,  1.08it/s] 84%|████████▍ | 84/100 [01:17<00:14,  1.08it/s] 85%|████████▌ | 85/100 [01:18<00:13,  1.08it/s] 86%|████████▌ | 86/100 [01:19<00:13,  1.07it/s] 87%|████████▋ | 87/100 [01:20<00:12,  1.08it/s] 88%|████████▊ | 88/100 [01:21<00:11,  1.07it/s] 89%|████████▉ | 89/100 [01:22<00:10,  1.06it/s] 90%|█████████ | 90/100 [01:23<00:09,  1.07it/s] 91%|█████████ | 91/100 [01:24<00:08,  1.07it/s] 92%|█████████▏| 92/100 [01:24<00:07,  1.07it/s] 93%|█████████▎| 93/100 [01:25<00:06,  1.07it/s] 94%|█████████▍| 94/100 [01:26<00:05,  1.06it/s] 95%|█████████▌| 95/100 [01:27<00:04,  1.07it/s] 96%|█████████▌| 96/100 [01:28<00:03,  1.07it/s] 97%|█████████▋| 97/100 [01:29<00:02,  1.07it/s] 98%|█████████▊| 98/100 [01:30<00:01,  1.07it/s] 99%|█████████▉| 99/100 [01:31<00:00,  1.08it/s]100%|██████████| 100/100 [01:32<00:00,  1.08it/s]100%|██████████| 100/100 [01:32<00:00,  1.08it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:2'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:2'}
full model:
{'cola': {'alias': 'cola', 'mcc,none': np.float64(-0.0234083603222329), 'mcc_stderr,none': 0.10027612985654218}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9827615088085355
0.9302188892609604
0.7011961870018854
0.5626926521241726
0.8487059565524276
0.8497526414658526
0.9054485200458864
0.7394951536076
0.6615723249956142
0.3790091735780837
0.7669438266452424
0.6500882643740805
0.6039759750877352
0.8611545876684488
0.9595791152744535
0.7624866897939796
0.8585278638499474
0.9654871578633694
0.8537985077125277
0.9276026122967783
0.938072418626947
0.8815459403167786
0.6241194219560614
0.901256729143793
0.7007049393842223
0.6541093728101413
0.9141945519271818
0.7667764647672246
0.8091089193013563
Total groups 69 exceeded the threshold, stopping comparison.
The group tensor is
[3, 2, 6, 7, 5, 1, 4, 0]
tensor([3, 2, 6, 7, 5, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 3, 6, 7, 5, 1, 4, 0]
tensor([2, 3, 6, 7, 5, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 3, 5, 7, 6, 1, 2, 0]
tensor([4, 3, 5, 7, 6, 1, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[2, 3, 0, 1, 2, 1, 3, 0]
tensor([2, 3, 0, 1, 2, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[1, 0, 1, 2, 3, 2, 3, 0]
tensor([1, 0, 1, 2, 3, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 2, 1, 2, 3, 1, 3, 0]
tensor([0, 2, 1, 2, 3, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[1, 0, 0, 1, 2, 3, 3, 2]
tensor([1, 0, 0, 1, 2, 3, 3, 2], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[3, 1, 0, 1, 2, 2, 3, 0]
tensor([3, 1, 0, 1, 2, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1.0, 1.0, 1, 1.0, 0]
tensor([0, 1, 1, 1, 1, 1, 1, 0], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
done!
Cross-layer merge completed for layers 2 to 5
done!
Normal merging for layer 6
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
tensor([3])
tensor(3)
done!
Cross-layer merge completed for layers 7 to 18
done!
Normal merging for layer 19
tensor([2, 7])
tensor(2)
tensor([3, 5])
tensor(3)
tensor([0, 4])
tensor(0)
tensor([1, 6])
tensor(1)
done!
Normal merging for layer 20
tensor([1, 7])
tensor(1)
tensor([0, 2])
tensor(0)
tensor([3, 5])
tensor(3)
tensor([4, 6])
tensor(4)
done!
Normal merging for layer 21
tensor([0, 7])
tensor(0)
tensor([2, 5])
tensor(2)
tensor([1, 3])
tensor(1)
tensor([4, 6])
tensor(4)
done!
Normal merging for layer 22
tensor([1, 2])
tensor(1)
tensor([0, 3])
tensor(0)
tensor([4, 7])
tensor(4)
tensor([5, 6])
tensor(5)
done!
Normal merging for layer 23
tensor([2, 7])
tensor(2)
tensor([1, 3])
tensor(1)
tensor([4, 5])
tensor(4)
tensor([0, 6])
tensor(0)
done!
Cross-layer merge completed for layers 24 to 27
done!
Normal merging for layer 28
tensor([0, 7])
tensor(0)
tensor([1, 2, 3, 4, 5, 6])
tensor(1)
done!
Cross-layer merge completed for layers 29 to 31
done!
all done!
Model size: 12.1348 GB
242
cuda:2
mastermind_24_easy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:42<00:42, 42.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 24.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 27.49s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_24_mcq_random HTTP/1.1" 200 779
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/flair/mastermind_24_mcq_random/flair/mastermind_24_mcq_random.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_24_mcq_random HTTP/1.1" 200 779
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/flair/mastermind_24_mcq_random/resolve/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/flair/mastermind_24_mcq_random/resolve/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:filelock:Attempting to acquire lock 139722787922112 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_24_mcq_random_default_0.0.0_cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5.lock
DEBUG:filelock:Lock 139722787922112 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_24_mcq_random_default_0.0.0_cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_24_mcq_random/default/0.0.0/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5/dataset_info.json
DEBUG:filelock:Attempting to release lock 139722787922112 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_24_mcq_random_default_0.0.0_cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5.lock
DEBUG:filelock:Lock 139722787922112 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_24_mcq_random_default_0.0.0_cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5.lock
DEBUG:filelock:Attempting to acquire lock 139722755389344 on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_24_mcq_random/default/0.0.0/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5_builder.lock
DEBUG:filelock:Lock 139722755389344 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_24_mcq_random/default/0.0.0/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_24_mcq_random/default/0.0.0/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5/dataset_info.json
DEBUG:filelock:Attempting to release lock 139722755389344 on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_24_mcq_random/default/0.0.0/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5_builder.lock
DEBUG:filelock:Lock 139722755389344 released on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_24_mcq_random/default/0.0.0/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mastermind_24_easy from None to 0
INFO:lm_eval.api.task:Building contexts for mastermind_24_easy on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1526.39it/s]
DEBUG:lm_eval.evaluator:Task: mastermind_24_easy; number of requests on this rank: 400
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/400 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/400 [00:01<10:25,  1.57s/it]Running loglikelihood requests:   0%|          | 2/400 [00:02<08:29,  1.28s/it]Running loglikelihood requests:   1%|          | 3/400 [00:03<07:52,  1.19s/it]Running loglikelihood requests:   1%|          | 4/400 [00:04<07:33,  1.15s/it]Running loglikelihood requests:   1%|▏         | 5/400 [00:05<07:21,  1.12s/it]Running loglikelihood requests:   2%|▏         | 6/400 [00:06<07:13,  1.10s/it]Running loglikelihood requests:   2%|▏         | 7/400 [00:08<07:07,  1.09s/it]Running loglikelihood requests:   2%|▏         | 8/400 [00:09<07:04,  1.08s/it]Running loglikelihood requests:   2%|▏         | 9/400 [00:10<07:01,  1.08s/it]Running loglikelihood requests:   2%|▎         | 10/400 [00:11<06:58,  1.07s/it]Running loglikelihood requests:   3%|▎         | 12/400 [00:12<05:17,  1.22it/s]Running loglikelihood requests:   3%|▎         | 13/400 [00:13<05:40,  1.14it/s]Running loglikelihood requests:   4%|▎         | 14/400 [00:14<05:57,  1.08it/s]Running loglikelihood requests:   4%|▍         | 16/400 [00:15<04:50,  1.32it/s]Running loglikelihood requests:   4%|▍         | 17/400 [00:16<05:17,  1.21it/s]Running loglikelihood requests:   4%|▍         | 18/400 [00:17<05:38,  1.13it/s]Running loglikelihood requests:   5%|▍         | 19/400 [00:18<05:55,  1.07it/s]Running loglikelihood requests:   5%|▌         | 20/400 [00:19<06:07,  1.03it/s]Running loglikelihood requests:   5%|▌         | 21/400 [00:20<06:16,  1.01it/s]Running loglikelihood requests:   6%|▌         | 22/400 [00:21<06:22,  1.01s/it]Running loglikelihood requests:   6%|▌         | 23/400 [00:22<06:26,  1.03s/it]Running loglikelihood requests:   6%|▋         | 25/400 [00:23<04:59,  1.25it/s]Running loglikelihood requests:   6%|▋         | 26/400 [00:24<05:22,  1.16it/s]Running loglikelihood requests:   7%|▋         | 27/400 [00:26<05:40,  1.09it/s]Running loglikelihood requests:   7%|▋         | 29/400 [00:27<04:38,  1.33it/s]Running loglikelihood requests:   8%|▊         | 30/400 [00:28<05:04,  1.22it/s]Running loglikelihood requests:   8%|▊         | 31/400 [00:29<05:24,  1.14it/s]Running loglikelihood requests:   8%|▊         | 32/400 [00:30<05:41,  1.08it/s]Running loglikelihood requests:   8%|▊         | 34/400 [00:31<04:35,  1.33it/s]Running loglikelihood requests:   9%|▉         | 35/400 [00:32<04:59,  1.22it/s]Running loglikelihood requests:  10%|▉         | 38/400 [00:33<03:32,  1.71it/s]Running loglikelihood requests:  10%|▉         | 39/400 [00:34<04:04,  1.48it/s]Running loglikelihood requests:  10%|█         | 40/400 [00:35<04:32,  1.32it/s]Running loglikelihood requests:  10%|█         | 41/400 [00:36<04:56,  1.21it/s]Running loglikelihood requests:  10%|█         | 42/400 [00:37<05:16,  1.13it/s]Running loglikelihood requests:  11%|█         | 43/400 [00:38<05:31,  1.08it/s]Running loglikelihood requests:  11%|█         | 44/400 [00:39<05:42,  1.04it/s]Running loglikelihood requests:  11%|█▏        | 45/400 [00:40<05:50,  1.01it/s]Running loglikelihood requests:  12%|█▏        | 47/400 [00:41<04:35,  1.28it/s]Running loglikelihood requests:  12%|█▏        | 48/400 [00:42<04:56,  1.19it/s]Running loglikelihood requests:  12%|█▏        | 49/400 [00:43<05:13,  1.12it/s]Running loglikelihood requests:  12%|█▎        | 50/400 [00:44<05:26,  1.07it/s]Running loglikelihood requests:  13%|█▎        | 52/400 [00:45<04:22,  1.33it/s]Running loglikelihood requests:  13%|█▎        | 53/400 [00:47<04:44,  1.22it/s]Running loglikelihood requests:  14%|█▎        | 54/400 [00:48<05:02,  1.14it/s]Running loglikelihood requests:  14%|█▍        | 56/400 [00:49<04:09,  1.38it/s]Running loglikelihood requests:  14%|█▍        | 57/400 [00:50<04:36,  1.24it/s]Running loglikelihood requests:  14%|█▍        | 58/400 [00:51<04:55,  1.16it/s]Running loglikelihood requests:  15%|█▍        | 59/400 [00:52<05:10,  1.10it/s]Running loglikelihood requests:  15%|█▌        | 60/400 [00:53<05:21,  1.06it/s]Running loglikelihood requests:  15%|█▌        | 61/400 [00:54<05:29,  1.03it/s]Running loglikelihood requests:  16%|█▌        | 62/400 [00:55<05:37,  1.00it/s]Running loglikelihood requests:  16%|█▌        | 63/400 [00:56<05:38,  1.01s/it]Running loglikelihood requests:  16%|█▌        | 64/400 [00:57<05:38,  1.01s/it]Running loglikelihood requests:  16%|█▋        | 65/400 [00:58<05:38,  1.01s/it]Running loglikelihood requests:  16%|█▋        | 66/400 [00:59<05:42,  1.02s/it]Running loglikelihood requests:  17%|█▋        | 67/400 [01:00<05:41,  1.03s/it]Running loglikelihood requests:  17%|█▋        | 68/400 [01:01<05:42,  1.03s/it]Running loglikelihood requests:  17%|█▋        | 69/400 [01:02<05:41,  1.03s/it]Running loglikelihood requests:  18%|█▊        | 70/400 [01:03<05:41,  1.04s/it]Running loglikelihood requests:  18%|█▊        | 71/400 [01:04<05:40,  1.04s/it]Running loglikelihood requests:  18%|█▊        | 72/400 [01:05<05:40,  1.04s/it]Running loglikelihood requests:  18%|█▊        | 73/400 [01:06<05:37,  1.03s/it]Running loglikelihood requests:  18%|█▊        | 74/400 [01:07<05:34,  1.03s/it]Running loglikelihood requests:  19%|█▉        | 76/400 [01:08<04:14,  1.27it/s]Running loglikelihood requests:  19%|█▉        | 77/400 [01:09<04:31,  1.19it/s]Running loglikelihood requests:  20%|█▉        | 78/400 [01:10<04:49,  1.11it/s]Running loglikelihood requests:  20%|█▉        | 79/400 [01:11<05:00,  1.07it/s]Running loglikelihood requests:  20%|██        | 80/400 [01:12<05:08,  1.04it/s]Running loglikelihood requests:  20%|██        | 81/400 [01:13<05:13,  1.02it/s]Running loglikelihood requests:  20%|██        | 82/400 [01:14<05:17,  1.00it/s]Running loglikelihood requests:  21%|██        | 83/400 [01:16<05:19,  1.01s/it]Running loglikelihood requests:  21%|██        | 84/400 [01:17<05:20,  1.01s/it]Running loglikelihood requests:  21%|██▏       | 85/400 [01:18<05:21,  1.02s/it]Running loglikelihood requests:  22%|██▏       | 87/400 [01:19<04:09,  1.26it/s]Running loglikelihood requests:  22%|██▏       | 88/400 [01:20<04:26,  1.17it/s]Running loglikelihood requests:  22%|██▏       | 89/400 [01:21<04:40,  1.11it/s]Running loglikelihood requests:  22%|██▎       | 90/400 [01:22<04:49,  1.07it/s]Running loglikelihood requests:  23%|██▎       | 91/400 [01:23<04:56,  1.04it/s]Running loglikelihood requests:  23%|██▎       | 92/400 [01:24<05:01,  1.02it/s]Running loglikelihood requests:  24%|██▎       | 94/400 [01:25<03:55,  1.30it/s]Running loglikelihood requests:  24%|██▍       | 95/400 [01:26<04:14,  1.20it/s]Running loglikelihood requests:  24%|██▍       | 96/400 [01:27<04:29,  1.13it/s]Running loglikelihood requests:  24%|██▍       | 98/400 [01:28<03:39,  1.37it/s]Running loglikelihood requests:  25%|██▌       | 100/400 [01:29<03:14,  1.55it/s]Running loglikelihood requests:  26%|██▌       | 102/400 [01:30<02:58,  1.67it/s]Running loglikelihood requests:  26%|██▌       | 103/400 [01:31<03:24,  1.46it/s]Running loglikelihood requests:  26%|██▌       | 104/400 [01:32<03:45,  1.31it/s]Running loglikelihood requests:  27%|██▋       | 107/400 [01:33<02:42,  1.80it/s]Running loglikelihood requests:  27%|██▋       | 108/400 [01:34<03:08,  1.55it/s]Running loglikelihood requests:  27%|██▋       | 109/400 [01:35<03:28,  1.39it/s]Running loglikelihood requests:  28%|██▊       | 110/400 [01:36<03:49,  1.27it/s]Running loglikelihood requests:  28%|██▊       | 111/400 [01:37<04:03,  1.18it/s]Running loglikelihood requests:  28%|██▊       | 112/400 [01:38<04:15,  1.13it/s]Running loglikelihood requests:  28%|██▊       | 113/400 [01:39<04:24,  1.09it/s]Running loglikelihood requests:  28%|██▊       | 114/400 [01:40<04:29,  1.06it/s]Running loglikelihood requests:  29%|██▉       | 116/400 [01:41<03:32,  1.34it/s]Running loglikelihood requests:  29%|██▉       | 117/400 [01:42<03:48,  1.24it/s]Running loglikelihood requests:  30%|██▉       | 118/400 [01:43<04:01,  1.17it/s]Running loglikelihood requests:  30%|███       | 121/400 [01:44<02:42,  1.71it/s]Running loglikelihood requests:  30%|███       | 122/400 [01:45<03:05,  1.50it/s]Running loglikelihood requests:  31%|███       | 123/400 [01:46<03:24,  1.35it/s]Running loglikelihood requests:  31%|███       | 124/400 [01:47<03:41,  1.25it/s]Running loglikelihood requests:  31%|███▏      | 125/400 [01:48<03:53,  1.18it/s]Running loglikelihood requests:  32%|███▏      | 126/400 [01:49<04:01,  1.13it/s]Running loglikelihood requests:  32%|███▏      | 127/400 [01:50<04:07,  1.10it/s]Running loglikelihood requests:  32%|███▏      | 128/400 [01:51<04:11,  1.08it/s]Running loglikelihood requests:  32%|███▎      | 130/400 [01:52<03:16,  1.37it/s]Running loglikelihood requests:  33%|███▎      | 132/400 [01:53<02:50,  1.58it/s]Running loglikelihood requests:  33%|███▎      | 133/400 [01:54<03:09,  1.41it/s]Running loglikelihood requests:  34%|███▎      | 134/400 [01:55<03:24,  1.30it/s]Running loglikelihood requests:  34%|███▍      | 135/400 [01:56<03:37,  1.22it/s]Running loglikelihood requests:  34%|███▍      | 136/400 [01:57<03:46,  1.16it/s]Running loglikelihood requests:  34%|███▍      | 137/400 [01:58<03:53,  1.13it/s]Running loglikelihood requests:  34%|███▍      | 138/400 [01:59<03:58,  1.10it/s]Running loglikelihood requests:  35%|███▍      | 139/400 [02:00<04:01,  1.08it/s]Running loglikelihood requests:  35%|███▌      | 140/400 [02:01<04:03,  1.07it/s]Running loglikelihood requests:  35%|███▌      | 141/400 [02:02<04:04,  1.06it/s]Running loglikelihood requests:  36%|███▌      | 142/400 [02:03<04:05,  1.05it/s]Running loglikelihood requests:  36%|███▌      | 143/400 [02:04<04:04,  1.05it/s]Running loglikelihood requests:  36%|███▋      | 145/400 [02:05<03:07,  1.36it/s]Running loglikelihood requests:  36%|███▋      | 146/400 [02:06<03:21,  1.26it/s]Running loglikelihood requests:  37%|███▋      | 147/400 [02:06<03:31,  1.20it/s]Running loglikelihood requests:  37%|███▋      | 148/400 [02:07<03:39,  1.15it/s]Running loglikelihood requests:  37%|███▋      | 149/400 [02:08<03:44,  1.12it/s]Running loglikelihood requests:  38%|███▊      | 150/400 [02:09<03:48,  1.09it/s]Running loglikelihood requests:  38%|███▊      | 152/400 [02:10<02:58,  1.39it/s]Running loglikelihood requests:  38%|███▊      | 153/400 [02:11<03:12,  1.28it/s]Running loglikelihood requests:  38%|███▊      | 154/400 [02:12<03:23,  1.21it/s]Running loglikelihood requests:  39%|███▉      | 155/400 [02:13<03:31,  1.16it/s]Running loglikelihood requests:  39%|███▉      | 157/400 [02:14<02:49,  1.43it/s]Running loglikelihood requests:  40%|███▉      | 158/400 [02:15<03:03,  1.32it/s]Running loglikelihood requests:  40%|████      | 160/400 [02:16<02:35,  1.55it/s]Running loglikelihood requests:  40%|████      | 161/400 [02:17<02:51,  1.40it/s]Running loglikelihood requests:  40%|████      | 162/400 [02:18<03:04,  1.29it/s]Running loglikelihood requests:  41%|████      | 163/400 [02:19<03:15,  1.21it/s]Running loglikelihood requests:  41%|████▏     | 165/400 [02:20<02:39,  1.47it/s]Running loglikelihood requests:  42%|████▏     | 166/400 [02:21<02:53,  1.35it/s]Running loglikelihood requests:  42%|████▏     | 167/400 [02:22<03:06,  1.25it/s]Running loglikelihood requests:  42%|████▏     | 168/400 [02:23<03:15,  1.19it/s]Running loglikelihood requests:  42%|████▎     | 170/400 [02:24<02:38,  1.45it/s]Running loglikelihood requests:  43%|████▎     | 171/400 [02:25<02:52,  1.32it/s]Running loglikelihood requests:  43%|████▎     | 172/400 [02:26<03:04,  1.24it/s]Running loglikelihood requests:  43%|████▎     | 173/400 [02:27<03:13,  1.17it/s]Running loglikelihood requests:  44%|████▎     | 174/400 [02:28<03:19,  1.13it/s]Running loglikelihood requests:  44%|████▍     | 175/400 [02:29<03:24,  1.10it/s]Running loglikelihood requests:  44%|████▍     | 176/400 [02:30<03:27,  1.08it/s]Running loglikelihood requests:  44%|████▍     | 178/400 [02:31<02:41,  1.38it/s]Running loglikelihood requests:  45%|████▍     | 179/400 [02:32<02:53,  1.27it/s]Running loglikelihood requests:  45%|████▌     | 180/400 [02:33<03:03,  1.20it/s]Running loglikelihood requests:  45%|████▌     | 181/400 [02:33<03:10,  1.15it/s]Running loglikelihood requests:  46%|████▌     | 183/400 [02:34<02:32,  1.42it/s]Running loglikelihood requests:  46%|████▌     | 184/400 [02:35<02:45,  1.31it/s]Running loglikelihood requests:  47%|████▋     | 187/400 [02:36<01:55,  1.84it/s]Running loglikelihood requests:  47%|████▋     | 188/400 [02:37<02:12,  1.60it/s]Running loglikelihood requests:  47%|████▋     | 189/400 [02:38<02:27,  1.43it/s]Running loglikelihood requests:  48%|████▊     | 190/400 [02:39<02:39,  1.31it/s]Running loglikelihood requests:  48%|████▊     | 191/400 [02:40<02:50,  1.23it/s]Running loglikelihood requests:  48%|████▊     | 192/400 [02:41<02:57,  1.17it/s]Running loglikelihood requests:  48%|████▊     | 193/400 [02:42<03:02,  1.13it/s]Running loglikelihood requests:  48%|████▊     | 194/400 [02:43<03:06,  1.10it/s]Running loglikelihood requests:  49%|████▉     | 196/400 [02:44<02:26,  1.39it/s]Running loglikelihood requests:  49%|████▉     | 197/400 [02:45<02:38,  1.28it/s]Running loglikelihood requests:  50%|████▉     | 198/400 [02:46<02:46,  1.21it/s]Running loglikelihood requests:  50%|████▉     | 199/400 [02:47<02:53,  1.16it/s]Running loglikelihood requests:  50%|█████     | 200/400 [02:48<02:57,  1.13it/s]Running loglikelihood requests:  50%|█████     | 202/400 [02:49<02:19,  1.42it/s]Running loglikelihood requests:  51%|█████     | 203/400 [02:50<02:30,  1.30it/s]Running loglikelihood requests:  51%|█████     | 204/400 [02:51<02:39,  1.23it/s]Running loglikelihood requests:  51%|█████▏    | 205/400 [02:52<02:46,  1.17it/s]Running loglikelihood requests:  52%|█████▏    | 206/400 [02:53<02:51,  1.13it/s]Running loglikelihood requests:  52%|█████▏    | 207/400 [02:54<02:54,  1.10it/s]Running loglikelihood requests:  52%|█████▎    | 210/400 [02:55<01:50,  1.71it/s]Running loglikelihood requests:  53%|█████▎    | 212/400 [02:56<01:42,  1.83it/s]Running loglikelihood requests:  53%|█████▎    | 213/400 [02:57<01:57,  1.59it/s]Running loglikelihood requests:  54%|█████▍    | 215/400 [02:58<01:46,  1.74it/s]Running loglikelihood requests:  54%|█████▍    | 216/400 [02:58<02:00,  1.53it/s]Running loglikelihood requests:  54%|█████▍    | 217/400 [02:59<02:11,  1.39it/s]Running loglikelihood requests:  55%|█████▍    | 219/400 [03:00<01:53,  1.60it/s]Running loglikelihood requests:  55%|█████▌    | 220/400 [03:01<02:05,  1.43it/s]Running loglikelihood requests:  55%|█████▌    | 221/400 [03:02<02:15,  1.32it/s]Running loglikelihood requests:  56%|█████▌    | 222/400 [03:03<02:23,  1.24it/s]Running loglikelihood requests:  56%|█████▌    | 223/400 [03:04<02:29,  1.18it/s]Running loglikelihood requests:  56%|█████▌    | 224/400 [03:05<02:34,  1.14it/s]Running loglikelihood requests:  56%|█████▋    | 225/400 [03:06<02:37,  1.11it/s]Running loglikelihood requests:  56%|█████▋    | 226/400 [03:07<02:39,  1.09it/s]Running loglikelihood requests:  57%|█████▋    | 227/400 [03:08<02:40,  1.08it/s]Running loglikelihood requests:  57%|█████▋    | 228/400 [03:09<02:40,  1.07it/s]Running loglikelihood requests:  57%|█████▋    | 229/400 [03:10<02:40,  1.06it/s]Running loglikelihood requests:  57%|█████▊    | 230/400 [03:11<02:40,  1.06it/s]Running loglikelihood requests:  58%|█████▊    | 231/400 [03:12<02:40,  1.06it/s]Running loglikelihood requests:  58%|█████▊    | 232/400 [03:13<02:39,  1.05it/s]Running loglikelihood requests:  58%|█████▊    | 233/400 [03:14<02:38,  1.05it/s]Running loglikelihood requests:  59%|█████▉    | 235/400 [03:15<02:00,  1.37it/s]Running loglikelihood requests:  59%|█████▉    | 236/400 [03:16<02:08,  1.27it/s]Running loglikelihood requests:  59%|█████▉    | 237/400 [03:17<02:15,  1.21it/s]Running loglikelihood requests:  60%|█████▉    | 238/400 [03:18<02:19,  1.16it/s]Running loglikelihood requests:  60%|█████▉    | 239/400 [03:19<02:22,  1.13it/s]Running loglikelihood requests:  60%|██████    | 240/400 [03:19<02:25,  1.10it/s]Running loglikelihood requests:  60%|██████    | 242/400 [03:20<01:52,  1.40it/s]Running loglikelihood requests:  61%|██████    | 243/400 [03:21<02:01,  1.30it/s]Running loglikelihood requests:  61%|██████    | 244/400 [03:22<02:07,  1.22it/s]Running loglikelihood requests:  61%|██████▏   | 245/400 [03:23<02:12,  1.17it/s]Running loglikelihood requests:  62%|██████▏   | 246/400 [03:24<02:15,  1.14it/s]Running loglikelihood requests:  62%|██████▏   | 247/400 [03:25<02:17,  1.11it/s]Running loglikelihood requests:  62%|██████▏   | 249/400 [03:26<01:47,  1.41it/s]Running loglikelihood requests:  62%|██████▎   | 250/400 [03:27<01:55,  1.30it/s]Running loglikelihood requests:  63%|██████▎   | 251/400 [03:28<02:01,  1.23it/s]Running loglikelihood requests:  63%|██████▎   | 252/400 [03:29<02:05,  1.18it/s]Running loglikelihood requests:  63%|██████▎   | 253/400 [03:30<02:08,  1.14it/s]Running loglikelihood requests:  64%|██████▎   | 254/400 [03:31<02:11,  1.11it/s]Running loglikelihood requests:  64%|██████▍   | 255/400 [03:32<02:12,  1.10it/s]Running loglikelihood requests:  64%|██████▍   | 256/400 [03:33<02:12,  1.08it/s]Running loglikelihood requests:  64%|██████▍   | 257/400 [03:34<02:12,  1.08it/s]Running loglikelihood requests:  64%|██████▍   | 258/400 [03:35<02:12,  1.07it/s]Running loglikelihood requests:  65%|██████▌   | 260/400 [03:36<01:41,  1.38it/s]Running loglikelihood requests:  65%|██████▌   | 261/400 [03:37<01:48,  1.28it/s]Running loglikelihood requests:  66%|██████▌   | 264/400 [03:38<01:13,  1.85it/s]Running loglikelihood requests:  66%|██████▋   | 265/400 [03:38<01:23,  1.61it/s]Running loglikelihood requests:  66%|██████▋   | 266/400 [03:39<01:32,  1.44it/s]Running loglikelihood requests:  67%|██████▋   | 267/400 [03:40<01:40,  1.33it/s]Running loglikelihood requests:  67%|██████▋   | 268/400 [03:41<01:45,  1.25it/s]Running loglikelihood requests:  67%|██████▋   | 269/400 [03:42<01:49,  1.19it/s]Running loglikelihood requests:  68%|██████▊   | 270/400 [03:43<01:52,  1.15it/s]Running loglikelihood requests:  68%|██████▊   | 271/400 [03:44<01:54,  1.12it/s]Running loglikelihood requests:  68%|██████▊   | 272/400 [03:45<01:55,  1.11it/s]Running loglikelihood requests:  68%|██████▊   | 273/400 [03:46<01:56,  1.09it/s]Running loglikelihood requests:  68%|██████▊   | 274/400 [03:47<01:56,  1.08it/s]Running loglikelihood requests:  69%|██████▉   | 277/400 [03:48<01:11,  1.71it/s]Running loglikelihood requests:  70%|██████▉   | 279/400 [03:49<01:05,  1.84it/s]Running loglikelihood requests:  70%|███████   | 281/400 [03:50<01:01,  1.93it/s]Running loglikelihood requests:  71%|███████   | 284/400 [03:51<00:50,  2.31it/s]Running loglikelihood requests:  71%|███████▏  | 285/400 [03:52<00:59,  1.94it/s]Running loglikelihood requests:  72%|███████▏  | 286/400 [03:53<01:08,  1.67it/s]Running loglikelihood requests:  72%|███████▏  | 287/400 [03:54<01:15,  1.49it/s]Running loglikelihood requests:  72%|███████▏  | 288/400 [03:54<01:22,  1.36it/s]Running loglikelihood requests:  72%|███████▏  | 289/400 [03:55<01:26,  1.28it/s]Running loglikelihood requests:  72%|███████▎  | 290/400 [03:56<01:30,  1.22it/s]Running loglikelihood requests:  73%|███████▎  | 291/400 [03:57<01:33,  1.17it/s]Running loglikelihood requests:  73%|███████▎  | 293/400 [03:58<01:13,  1.46it/s]Running loglikelihood requests:  74%|███████▎  | 294/400 [03:59<01:18,  1.34it/s]Running loglikelihood requests:  74%|███████▍  | 295/400 [04:00<01:23,  1.26it/s]Running loglikelihood requests:  74%|███████▍  | 296/400 [04:01<01:26,  1.20it/s]Running loglikelihood requests:  74%|███████▍  | 297/400 [04:02<01:28,  1.16it/s]Running loglikelihood requests:  75%|███████▍  | 299/400 [04:03<01:09,  1.45it/s]Running loglikelihood requests:  75%|███████▌  | 300/400 [04:04<01:15,  1.33it/s]Running loglikelihood requests:  75%|███████▌  | 301/400 [04:05<01:20,  1.23it/s]Running loglikelihood requests:  76%|███████▌  | 302/400 [04:06<01:23,  1.18it/s]Running loglikelihood requests:  76%|███████▌  | 304/400 [04:07<01:05,  1.46it/s]Running loglikelihood requests:  76%|███████▋  | 305/400 [04:08<01:10,  1.34it/s]Running loglikelihood requests:  77%|███████▋  | 307/400 [04:09<00:59,  1.58it/s]Running loglikelihood requests:  77%|███████▋  | 309/400 [04:10<00:52,  1.74it/s]Running loglikelihood requests:  78%|███████▊  | 310/400 [04:10<00:58,  1.54it/s]Running loglikelihood requests:  78%|███████▊  | 311/400 [04:11<01:03,  1.40it/s]Running loglikelihood requests:  78%|███████▊  | 312/400 [04:12<01:07,  1.30it/s]Running loglikelihood requests:  78%|███████▊  | 313/400 [04:13<01:10,  1.23it/s]Running loglikelihood requests:  79%|███████▉  | 315/400 [04:14<00:56,  1.50it/s]Running loglikelihood requests:  79%|███████▉  | 317/400 [04:15<00:49,  1.69it/s]Running loglikelihood requests:  80%|███████▉  | 318/400 [04:16<00:54,  1.50it/s]Running loglikelihood requests:  80%|███████▉  | 319/400 [04:17<00:59,  1.37it/s]Running loglikelihood requests:  80%|████████  | 321/400 [04:18<00:49,  1.60it/s]Running loglikelihood requests:  81%|████████  | 323/400 [04:19<00:43,  1.76it/s]Running loglikelihood requests:  82%|████████▏ | 326/400 [04:20<00:33,  2.19it/s]Running loglikelihood requests:  82%|████████▏ | 327/400 [04:21<00:39,  1.85it/s]Running loglikelihood requests:  82%|████████▏ | 328/400 [04:22<00:44,  1.61it/s]Running loglikelihood requests:  82%|████████▏ | 329/400 [04:23<00:48,  1.45it/s]Running loglikelihood requests:  82%|████████▎ | 330/400 [04:24<00:52,  1.34it/s]Running loglikelihood requests:  83%|████████▎ | 332/400 [04:25<00:43,  1.58it/s]Running loglikelihood requests:  83%|████████▎ | 333/400 [04:25<00:46,  1.44it/s]Running loglikelihood requests:  84%|████████▎ | 334/400 [04:26<00:49,  1.32it/s]Running loglikelihood requests:  84%|████████▍ | 335/400 [04:27<00:52,  1.25it/s]Running loglikelihood requests:  84%|████████▍ | 336/400 [04:28<00:53,  1.20it/s]Running loglikelihood requests:  84%|████████▍ | 337/400 [04:29<00:54,  1.16it/s]Running loglikelihood requests:  84%|████████▍ | 338/400 [04:30<00:54,  1.13it/s]Running loglikelihood requests:  85%|████████▍ | 339/400 [04:31<00:54,  1.11it/s]Running loglikelihood requests:  85%|████████▌ | 340/400 [04:32<00:54,  1.10it/s]Running loglikelihood requests:  85%|████████▌ | 341/400 [04:33<00:52,  1.12it/s]Running loglikelihood requests:  86%|████████▌ | 342/400 [04:34<00:51,  1.14it/s]Running loglikelihood requests:  86%|████████▌ | 343/400 [04:35<00:49,  1.15it/s]Running loglikelihood requests:  86%|████████▋ | 346/400 [04:35<00:29,  1.85it/s]Running loglikelihood requests:  87%|████████▋ | 348/400 [04:36<00:26,  1.99it/s]Running loglikelihood requests:  87%|████████▋ | 349/400 [04:37<00:29,  1.75it/s]Running loglikelihood requests:  88%|████████▊ | 350/400 [04:38<00:31,  1.58it/s]Running loglikelihood requests:  88%|████████▊ | 351/400 [04:39<00:33,  1.46it/s]Running loglikelihood requests:  88%|████████▊ | 352/400 [04:40<00:34,  1.38it/s]Running loglikelihood requests:  88%|████████▊ | 353/400 [04:41<00:35,  1.31it/s]Running loglikelihood requests:  88%|████████▊ | 354/400 [04:41<00:36,  1.27it/s]Running loglikelihood requests:  89%|████████▉ | 355/400 [04:42<00:36,  1.25it/s]Running loglikelihood requests:  89%|████████▉ | 356/400 [04:43<00:35,  1.23it/s]Running loglikelihood requests:  90%|████████▉ | 358/400 [04:44<00:26,  1.58it/s]Running loglikelihood requests:  90%|████████▉ | 359/400 [04:45<00:28,  1.46it/s]Running loglikelihood requests:  90%|█████████ | 360/400 [04:46<00:28,  1.38it/s]Running loglikelihood requests:  90%|█████████ | 361/400 [04:46<00:29,  1.32it/s]Running loglikelihood requests:  90%|█████████ | 362/400 [04:47<00:29,  1.28it/s]Running loglikelihood requests:  91%|█████████ | 364/400 [04:48<00:22,  1.61it/s]Running loglikelihood requests:  91%|█████████▏| 365/400 [04:49<00:23,  1.49it/s]Running loglikelihood requests:  92%|█████████▏| 367/400 [04:50<00:18,  1.76it/s]Running loglikelihood requests:  92%|█████████▏| 368/400 [04:51<00:20,  1.59it/s]Running loglikelihood requests:  92%|█████████▏| 369/400 [04:51<00:21,  1.47it/s]Running loglikelihood requests:  92%|█████████▎| 370/400 [04:52<00:21,  1.39it/s]Running loglikelihood requests:  93%|█████████▎| 371/400 [04:53<00:21,  1.33it/s]Running loglikelihood requests:  93%|█████████▎| 373/400 [04:54<00:16,  1.64it/s]Running loglikelihood requests:  94%|█████████▍| 375/400 [04:55<00:13,  1.86it/s]Running loglikelihood requests:  94%|█████████▍| 376/400 [04:56<00:14,  1.66it/s]Running loglikelihood requests:  95%|█████████▍| 379/400 [04:56<00:09,  2.24it/s]Running loglikelihood requests:  95%|█████████▌| 381/400 [04:57<00:08,  2.29it/s]Running loglikelihood requests:  96%|█████████▌| 382/400 [04:58<00:09,  1.96it/s]Running loglikelihood requests:  96%|█████████▌| 384/400 [04:59<00:07,  2.09it/s]Running loglikelihood requests:  96%|█████████▋| 386/400 [05:00<00:06,  2.17it/s]Running loglikelihood requests:  97%|█████████▋| 387/400 [05:01<00:06,  1.86it/s]Running loglikelihood requests:  97%|█████████▋| 389/400 [05:02<00:05,  2.01it/s]Running loglikelihood requests:  98%|█████████▊| 391/400 [05:02<00:04,  2.12it/s]Running loglikelihood requests:  98%|█████████▊| 393/400 [05:03<00:03,  2.20it/s]Running loglikelihood requests:  99%|█████████▉| 395/400 [05:04<00:02,  2.25it/s]Running loglikelihood requests:  99%|█████████▉| 397/400 [05:05<00:01,  2.29it/s]Running loglikelihood requests: 100%|█████████▉| 398/400 [05:06<00:01,  1.96it/s]Running loglikelihood requests: 100%|██████████| 400/400 [05:07<00:00,  2.09it/s]Running loglikelihood requests: 100%|██████████| 400/400 [05:07<00:00,  1.30it/s]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:3'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:3'}
full model:
{'mastermind_24_easy': {'alias': 'mastermind_24_easy', 'acc,none': 0.33, 'acc_stderr,none': 0.04725815626252609}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9705388716727775
0.9880227828623074
0.982119607496995
0.9941469535767887
0.984917378949356
0.9883609317461776
0.9752442385272352
0.9858149677985593
0.9966001900863091
0.9954965780195978
0.9982374916142641
0.987839947084121
0.9740425263242771
0.9802324544963317
0.9965978314947238
0.9890806289155061
0.971808392501808
0.9767123038440666
0.9820534501654181
0.9672299205809463
0.9753579231968917
0.9973837437819523
0.9951994747100236
0.9465102818948206
0.9757933184251313
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[7, 0, 1, 3, 6, 5, 4, 2]
tensor([7, 0, 1, 3, 6, 5, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 0, 1, 3, 7, 5, 4, 2]
tensor([6, 0, 1, 3, 7, 5, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 0, 1, 3, 6, 5, 4, 2]
tensor([7, 0, 1, 3, 6, 5, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 0, 1, 3, 7, 5, 4, 2]
tensor([6, 0, 1, 3, 7, 5, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 0, 1, 3, 6, 5, 4, 2]
tensor([7, 0, 1, 3, 6, 5, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 0, 2, 3, 6, 5, 4, 1]
tensor([7, 0, 2, 3, 6, 5, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Normal merging for layer 2
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
done!
Normal merging for layer 3
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Normal merging for layer 4
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
done!
Normal merging for layer 5
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 6 to 31
done!
all done!
Model size: 12.0718 GB
13
cuda:3
sciq
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:43<00:43, 43.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:57<00:00, 25.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:57<00:00, 28.54s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq HTTP/1.1" 200 1237
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/sciq/sciq.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq HTTP/1.1" 200 1237
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/allenai/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq/revision/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 111
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq/revision/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 1237
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq/tree/2c94ad3e1aafab77146f384e23536f97a4849815?recursive=False&expand=False HTTP/1.1" 307 136
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq/tree/2c94ad3e1aafab77146f384e23536f97a4849815?recursive=False&expand=False HTTP/1.1" 200 291
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq/tree/2c94ad3e1aafab77146f384e23536f97a4849815/data?recursive=False&expand=False HTTP/1.1" 307 141
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq/tree/2c94ad3e1aafab77146f384e23536f97a4849815/data?recursive=False&expand=False HTTP/1.1" 200 358
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq/revision/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 111
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq/revision/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 1237
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/allenai/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:filelock:Attempting to acquire lock 139722742978160 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:filelock:Lock 139722742978160 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_info.json
DEBUG:filelock:Attempting to release lock 139722742978160 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:filelock:Lock 139722742978160 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:filelock:Attempting to acquire lock 139748103659328 on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:filelock:Lock 139748103659328 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_info.json
DEBUG:filelock:Attempting to release lock 139748103659328 on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:filelock:Lock 139748103659328 released on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of sciq from None to 0
INFO:lm_eval.api.task:Building contexts for sciq on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1023.56it/s]
DEBUG:lm_eval.evaluator:Task: sciq; number of requests on this rank: 400
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/400 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/400 [00:03<25:52,  3.89s/it]Running loglikelihood requests:   0%|          | 2/400 [00:07<23:43,  3.58s/it]Running loglikelihood requests:   1%|          | 3/400 [00:10<22:56,  3.47s/it]Running loglikelihood requests:   1%|          | 4/400 [00:13<22:33,  3.42s/it]Running loglikelihood requests:   1%|▏         | 5/400 [00:17<21:52,  3.32s/it]Running loglikelihood requests:   2%|▏         | 6/400 [00:20<21:33,  3.28s/it]Running loglikelihood requests:   2%|▏         | 7/400 [00:23<21:13,  3.24s/it]Running loglikelihood requests:   2%|▏         | 8/400 [00:26<20:57,  3.21s/it]Running loglikelihood requests:   2%|▏         | 9/400 [00:29<20:06,  3.08s/it]Running loglikelihood requests:   2%|▎         | 10/400 [00:32<19:29,  3.00s/it]Running loglikelihood requests:   3%|▎         | 11/400 [00:34<19:02,  2.94s/it]Running loglikelihood requests:   3%|▎         | 12/400 [00:37<18:42,  2.89s/it]Running loglikelihood requests:   3%|▎         | 13/400 [00:40<18:03,  2.80s/it]Running loglikelihood requests:   4%|▎         | 14/400 [00:42<17:34,  2.73s/it]Running loglikelihood requests:   4%|▍         | 15/400 [00:45<17:14,  2.69s/it]Running loglikelihood requests:   4%|▍         | 16/400 [00:48<16:58,  2.65s/it]Running loglikelihood requests:   4%|▍         | 17/400 [00:50<16:38,  2.61s/it]Running loglikelihood requests:   4%|▍         | 18/400 [00:53<16:22,  2.57s/it]Running loglikelihood requests:   5%|▍         | 19/400 [00:55<16:10,  2.55s/it]Running loglikelihood requests:   5%|▌         | 20/400 [00:58<16:00,  2.53s/it]Running loglikelihood requests:   5%|▌         | 21/400 [01:00<15:49,  2.51s/it]Running loglikelihood requests:   6%|▌         | 22/400 [01:02<15:42,  2.49s/it]Running loglikelihood requests:   6%|▌         | 23/400 [01:05<15:35,  2.48s/it]Running loglikelihood requests:   6%|▌         | 24/400 [01:07<15:30,  2.47s/it]Running loglikelihood requests:   6%|▋         | 25/400 [01:10<15:07,  2.42s/it]Running loglikelihood requests:   6%|▋         | 26/400 [01:12<14:51,  2.38s/it]Running loglikelihood requests:   7%|▋         | 27/400 [01:14<14:39,  2.36s/it]Running loglikelihood requests:   7%|▋         | 28/400 [01:17<14:29,  2.34s/it]Running loglikelihood requests:   7%|▋         | 29/400 [01:19<13:59,  2.26s/it]Running loglikelihood requests:   8%|▊         | 30/400 [01:21<13:37,  2.21s/it]Running loglikelihood requests:   8%|▊         | 31/400 [01:23<13:21,  2.17s/it]Running loglikelihood requests:   8%|▊         | 32/400 [01:25<13:09,  2.15s/it]Running loglikelihood requests:   8%|▊         | 33/400 [01:27<12:46,  2.09s/it]Running loglikelihood requests:   8%|▊         | 34/400 [01:29<12:30,  2.05s/it]Running loglikelihood requests:   9%|▉         | 35/400 [01:31<12:16,  2.02s/it]Running loglikelihood requests:   9%|▉         | 36/400 [01:33<12:06,  2.00s/it]Running loglikelihood requests:   9%|▉         | 37/400 [01:35<11:59,  1.98s/it]Running loglikelihood requests:  10%|▉         | 38/400 [01:37<11:53,  1.97s/it]Running loglikelihood requests:  10%|█         | 40/400 [01:39<09:03,  1.51s/it]Running loglikelihood requests:  10%|█         | 41/400 [01:40<09:26,  1.58s/it]Running loglikelihood requests:  10%|█         | 42/400 [01:42<09:43,  1.63s/it]Running loglikelihood requests:  11%|█         | 43/400 [01:44<09:56,  1.67s/it]Running loglikelihood requests:  11%|█         | 44/400 [01:46<10:04,  1.70s/it]Running loglikelihood requests:  11%|█▏        | 45/400 [01:47<10:03,  1.70s/it]Running loglikelihood requests:  12%|█▏        | 46/400 [01:49<10:01,  1.70s/it]Running loglikelihood requests:  12%|█▏        | 47/400 [01:51<09:59,  1.70s/it]Running loglikelihood requests:  12%|█▏        | 48/400 [01:52<09:57,  1.70s/it]Running loglikelihood requests:  12%|█▏        | 49/400 [01:54<09:55,  1.70s/it]Running loglikelihood requests:  12%|█▎        | 50/400 [01:56<09:53,  1.69s/it]Running loglikelihood requests:  13%|█▎        | 51/400 [01:58<09:51,  1.69s/it]Running loglikelihood requests:  13%|█▎        | 52/400 [01:59<09:48,  1.69s/it]Running loglikelihood requests:  13%|█▎        | 53/400 [02:01<09:29,  1.64s/it]Running loglikelihood requests:  14%|█▎        | 54/400 [02:02<09:14,  1.60s/it]Running loglikelihood requests:  14%|█▍        | 55/400 [02:04<09:03,  1.58s/it]Running loglikelihood requests:  14%|█▍        | 57/400 [02:05<06:46,  1.19s/it]Running loglikelihood requests:  14%|█▍        | 58/400 [02:07<07:07,  1.25s/it]Running loglikelihood requests:  15%|█▍        | 59/400 [02:08<07:23,  1.30s/it]Running loglikelihood requests:  16%|█▌        | 62/400 [02:10<04:53,  1.15it/s]Running loglikelihood requests:  16%|█▌        | 63/400 [02:11<05:30,  1.02it/s]Running loglikelihood requests:  16%|█▌        | 64/400 [02:12<06:04,  1.08s/it]Running loglikelihood requests:  16%|█▋        | 65/400 [02:14<06:28,  1.16s/it]Running loglikelihood requests:  16%|█▋        | 66/400 [02:15<06:46,  1.22s/it]Running loglikelihood requests:  17%|█▋        | 67/400 [02:17<07:00,  1.26s/it]Running loglikelihood requests:  17%|█▋        | 68/400 [02:18<07:10,  1.30s/it]Running loglikelihood requests:  17%|█▋        | 69/400 [02:19<07:15,  1.32s/it]Running loglikelihood requests:  18%|█▊        | 70/400 [02:21<07:18,  1.33s/it]Running loglikelihood requests:  18%|█▊        | 71/400 [02:22<07:20,  1.34s/it]Running loglikelihood requests:  18%|█▊        | 72/400 [02:23<07:20,  1.34s/it]Running loglikelihood requests:  18%|█▊        | 73/400 [02:25<07:20,  1.35s/it]Running loglikelihood requests:  18%|█▊        | 74/400 [02:26<07:18,  1.35s/it]Running loglikelihood requests:  19%|█▉        | 77/400 [02:27<04:30,  1.19it/s]Running loglikelihood requests:  20%|█▉        | 78/400 [02:29<05:01,  1.07it/s]Running loglikelihood requests:  20%|█▉        | 79/400 [02:30<05:28,  1.02s/it]Running loglikelihood requests:  20%|██        | 81/400 [02:31<04:32,  1.17it/s]Running loglikelihood requests:  20%|██        | 82/400 [02:32<04:55,  1.08it/s]Running loglikelihood requests:  21%|██        | 83/400 [02:34<05:13,  1.01it/s]Running loglikelihood requests:  21%|██        | 84/400 [02:35<05:29,  1.04s/it]Running loglikelihood requests:  21%|██▏       | 85/400 [02:36<05:39,  1.08s/it]Running loglikelihood requests:  22%|██▏       | 86/400 [02:37<05:46,  1.10s/it]Running loglikelihood requests:  22%|██▏       | 89/400 [02:38<03:42,  1.39it/s]Running loglikelihood requests:  22%|██▎       | 90/400 [02:40<04:10,  1.24it/s]Running loglikelihood requests:  23%|██▎       | 91/400 [02:41<04:34,  1.12it/s]Running loglikelihood requests:  23%|██▎       | 92/400 [02:42<04:54,  1.05it/s]Running loglikelihood requests:  23%|██▎       | 93/400 [02:43<05:09,  1.01s/it]Running loglikelihood requests:  24%|██▍       | 97/400 [02:44<02:55,  1.73it/s]Running loglikelihood requests:  24%|██▍       | 98/400 [02:45<03:24,  1.48it/s]Running loglikelihood requests:  25%|██▍       | 99/400 [02:46<03:51,  1.30it/s]Running loglikelihood requests:  25%|██▌       | 100/400 [02:48<04:16,  1.17it/s]Running loglikelihood requests:  25%|██▌       | 101/400 [02:49<04:35,  1.09it/s]Running loglikelihood requests:  26%|██▌       | 102/400 [02:50<04:49,  1.03it/s]Running loglikelihood requests:  26%|██▌       | 103/400 [02:51<05:01,  1.01s/it]Running loglikelihood requests:  26%|██▌       | 104/400 [02:52<05:09,  1.05s/it]Running loglikelihood requests:  26%|██▋       | 105/400 [02:53<05:14,  1.07s/it]Running loglikelihood requests:  26%|██▋       | 106/400 [02:54<05:17,  1.08s/it]Running loglikelihood requests:  27%|██▋       | 107/400 [02:55<05:18,  1.09s/it]Running loglikelihood requests:  27%|██▋       | 108/400 [02:57<05:19,  1.09s/it]Running loglikelihood requests:  27%|██▋       | 109/400 [02:58<05:18,  1.09s/it]Running loglikelihood requests:  28%|██▊       | 110/400 [02:59<05:16,  1.09s/it]Running loglikelihood requests:  28%|██▊       | 111/400 [03:00<05:15,  1.09s/it]Running loglikelihood requests:  28%|██▊       | 112/400 [03:01<05:13,  1.09s/it]Running loglikelihood requests:  28%|██▊       | 113/400 [03:02<05:11,  1.09s/it]Running loglikelihood requests:  28%|██▊       | 114/400 [03:03<05:10,  1.08s/it]Running loglikelihood requests:  29%|██▉       | 115/400 [03:04<05:07,  1.08s/it]Running loglikelihood requests:  29%|██▉       | 116/400 [03:05<05:05,  1.08s/it]Running loglikelihood requests:  29%|██▉       | 117/400 [03:06<05:02,  1.07s/it]Running loglikelihood requests:  30%|██▉       | 118/400 [03:07<04:59,  1.06s/it]Running loglikelihood requests:  30%|██▉       | 119/400 [03:08<04:56,  1.06s/it]Running loglikelihood requests:  30%|███       | 120/400 [03:09<04:54,  1.05s/it]Running loglikelihood requests:  30%|███       | 121/400 [03:10<04:52,  1.05s/it]Running loglikelihood requests:  30%|███       | 122/400 [03:11<04:50,  1.05s/it]Running loglikelihood requests:  31%|███       | 123/400 [03:12<04:49,  1.05s/it]Running loglikelihood requests:  31%|███       | 124/400 [03:14<04:48,  1.05s/it]Running loglikelihood requests:  31%|███▏      | 125/400 [03:15<04:45,  1.04s/it]Running loglikelihood requests:  32%|███▏      | 126/400 [03:16<04:42,  1.03s/it]Running loglikelihood requests:  32%|███▏      | 127/400 [03:17<04:40,  1.03s/it]Running loglikelihood requests:  32%|███▏      | 128/400 [03:18<04:38,  1.02s/it]Running loglikelihood requests:  32%|███▏      | 129/400 [03:19<04:36,  1.02s/it]Running loglikelihood requests:  32%|███▎      | 130/400 [03:20<04:34,  1.02s/it]Running loglikelihood requests:  33%|███▎      | 131/400 [03:21<04:32,  1.01s/it]Running loglikelihood requests:  34%|███▎      | 134/400 [03:22<02:47,  1.58it/s]Running loglikelihood requests:  34%|███▍      | 135/400 [03:23<03:07,  1.41it/s]Running loglikelihood requests:  34%|███▍      | 136/400 [03:24<03:24,  1.29it/s]Running loglikelihood requests:  34%|███▍      | 137/400 [03:25<03:38,  1.20it/s]Running loglikelihood requests:  34%|███▍      | 138/400 [03:26<03:49,  1.14it/s]Running loglikelihood requests:  35%|███▍      | 139/400 [03:27<03:56,  1.10it/s]Running loglikelihood requests:  36%|███▌      | 142/400 [03:28<02:33,  1.68it/s]Running loglikelihood requests:  36%|███▌      | 143/400 [03:29<02:53,  1.48it/s]Running loglikelihood requests:  36%|███▌      | 144/400 [03:30<03:11,  1.34it/s]Running loglikelihood requests:  36%|███▋      | 145/400 [03:31<03:25,  1.24it/s]Running loglikelihood requests:  36%|███▋      | 146/400 [03:32<03:36,  1.17it/s]Running loglikelihood requests:  37%|███▋      | 147/400 [03:33<03:44,  1.13it/s]Running loglikelihood requests:  37%|███▋      | 148/400 [03:34<03:50,  1.09it/s]Running loglikelihood requests:  37%|███▋      | 149/400 [03:35<03:53,  1.07it/s]Running loglikelihood requests:  38%|███▊      | 150/400 [03:35<03:55,  1.06it/s]Running loglikelihood requests:  38%|███▊      | 151/400 [03:36<03:56,  1.05it/s]Running loglikelihood requests:  38%|███▊      | 152/400 [03:37<03:56,  1.05it/s]Running loglikelihood requests:  38%|███▊      | 153/400 [03:38<03:56,  1.04it/s]Running loglikelihood requests:  38%|███▊      | 154/400 [03:39<03:56,  1.04it/s]Running loglikelihood requests:  39%|███▉      | 155/400 [03:40<03:55,  1.04it/s]Running loglikelihood requests:  39%|███▉      | 156/400 [03:41<03:54,  1.04it/s]Running loglikelihood requests:  39%|███▉      | 157/400 [03:42<03:53,  1.04it/s]Running loglikelihood requests:  40%|███▉      | 158/400 [03:43<03:52,  1.04it/s]Running loglikelihood requests:  40%|███▉      | 159/400 [03:44<03:51,  1.04it/s]Running loglikelihood requests:  40%|████      | 160/400 [03:45<03:50,  1.04it/s]Running loglikelihood requests:  40%|████      | 161/400 [03:46<03:49,  1.04it/s]Running loglikelihood requests:  40%|████      | 162/400 [03:47<03:47,  1.04it/s]Running loglikelihood requests:  41%|████      | 163/400 [03:48<03:46,  1.05it/s]Running loglikelihood requests:  41%|████      | 164/400 [03:49<03:45,  1.05it/s]Running loglikelihood requests:  41%|████▏     | 165/400 [03:50<03:43,  1.05it/s]Running loglikelihood requests:  42%|████▏     | 166/400 [03:51<03:41,  1.06it/s]Running loglikelihood requests:  42%|████▏     | 167/400 [03:52<03:39,  1.06it/s]Running loglikelihood requests:  42%|████▏     | 168/400 [03:53<03:38,  1.06it/s]Running loglikelihood requests:  42%|████▏     | 169/400 [03:54<03:37,  1.06it/s]Running loglikelihood requests:  42%|████▎     | 170/400 [03:55<03:35,  1.07it/s]Running loglikelihood requests:  43%|████▎     | 172/400 [03:55<02:43,  1.39it/s]Running loglikelihood requests:  43%|████▎     | 173/400 [03:56<02:53,  1.31it/s]Running loglikelihood requests:  44%|████▎     | 174/400 [03:57<03:00,  1.25it/s]Running loglikelihood requests:  44%|████▍     | 177/400 [03:58<01:59,  1.87it/s]Running loglikelihood requests:  44%|████▍     | 178/400 [03:59<02:15,  1.64it/s]Running loglikelihood requests:  45%|████▍     | 179/400 [04:00<02:28,  1.49it/s]Running loglikelihood requests:  45%|████▌     | 180/400 [04:01<02:39,  1.38it/s]Running loglikelihood requests:  45%|████▌     | 181/400 [04:02<02:47,  1.31it/s]Running loglikelihood requests:  46%|████▌     | 182/400 [04:03<02:53,  1.25it/s]Running loglikelihood requests:  46%|████▌     | 183/400 [04:04<02:57,  1.22it/s]Running loglikelihood requests:  46%|████▌     | 184/400 [04:04<03:00,  1.20it/s]Running loglikelihood requests:  46%|████▋     | 185/400 [04:05<03:01,  1.18it/s]Running loglikelihood requests:  46%|████▋     | 186/400 [04:06<03:02,  1.17it/s]Running loglikelihood requests:  47%|████▋     | 187/400 [04:07<03:02,  1.17it/s]Running loglikelihood requests:  47%|████▋     | 188/400 [04:08<03:02,  1.16it/s]Running loglikelihood requests:  47%|████▋     | 189/400 [04:09<03:01,  1.16it/s]Running loglikelihood requests:  48%|████▊     | 190/400 [04:10<03:00,  1.16it/s]Running loglikelihood requests:  48%|████▊     | 191/400 [04:10<02:59,  1.16it/s]Running loglikelihood requests:  48%|████▊     | 192/400 [04:11<02:58,  1.17it/s]Running loglikelihood requests:  48%|████▊     | 193/400 [04:12<02:56,  1.17it/s]Running loglikelihood requests:  48%|████▊     | 194/400 [04:13<02:54,  1.18it/s]Running loglikelihood requests:  49%|████▉     | 195/400 [04:14<02:53,  1.18it/s]Running loglikelihood requests:  49%|████▉     | 196/400 [04:15<02:52,  1.19it/s]Running loglikelihood requests:  49%|████▉     | 197/400 [04:15<02:50,  1.19it/s]Running loglikelihood requests:  50%|████▉     | 198/400 [04:16<02:48,  1.20it/s]Running loglikelihood requests:  50%|████▉     | 199/400 [04:17<02:47,  1.20it/s]Running loglikelihood requests:  50%|█████     | 200/400 [04:18<02:45,  1.21it/s]Running loglikelihood requests:  50%|█████     | 201/400 [04:19<02:44,  1.21it/s]Running loglikelihood requests:  50%|█████     | 202/400 [04:20<02:43,  1.21it/s]Running loglikelihood requests:  51%|█████     | 203/400 [04:20<02:42,  1.21it/s]Running loglikelihood requests:  51%|█████     | 204/400 [04:21<02:41,  1.21it/s]Running loglikelihood requests:  51%|█████▏    | 205/400 [04:22<02:40,  1.22it/s]Running loglikelihood requests:  52%|█████▏    | 206/400 [04:23<02:39,  1.22it/s]Running loglikelihood requests:  52%|█████▏    | 207/400 [04:24<02:38,  1.22it/s]Running loglikelihood requests:  52%|█████▏    | 208/400 [04:25<02:37,  1.22it/s]Running loglikelihood requests:  52%|█████▏    | 209/400 [04:25<02:36,  1.22it/s]Running loglikelihood requests:  53%|█████▎    | 212/400 [04:26<01:36,  1.95it/s]Running loglikelihood requests:  53%|█████▎    | 213/400 [04:27<01:47,  1.74it/s]Running loglikelihood requests:  54%|█████▎    | 214/400 [04:28<01:56,  1.60it/s]Running loglikelihood requests:  54%|█████▍    | 215/400 [04:29<02:03,  1.50it/s]Running loglikelihood requests:  54%|█████▍    | 216/400 [04:29<02:09,  1.42it/s]Running loglikelihood requests:  54%|█████▍    | 217/400 [04:30<02:13,  1.38it/s]Running loglikelihood requests:  55%|█████▍    | 218/400 [04:31<02:15,  1.34it/s]Running loglikelihood requests:  55%|█████▍    | 219/400 [04:32<02:17,  1.31it/s]Running loglikelihood requests:  55%|█████▌    | 220/400 [04:33<02:19,  1.29it/s]Running loglikelihood requests:  55%|█████▌    | 221/400 [04:33<02:19,  1.29it/s]Running loglikelihood requests:  56%|█████▌    | 222/400 [04:34<02:18,  1.28it/s]Running loglikelihood requests:  56%|█████▌    | 223/400 [04:35<02:18,  1.28it/s]Running loglikelihood requests:  56%|█████▌    | 224/400 [04:36<02:17,  1.28it/s]Running loglikelihood requests:  56%|█████▋    | 225/400 [04:36<02:17,  1.28it/s]Running loglikelihood requests:  56%|█████▋    | 226/400 [04:37<02:16,  1.28it/s]Running loglikelihood requests:  57%|█████▋    | 227/400 [04:38<02:15,  1.28it/s]Running loglikelihood requests:  57%|█████▋    | 228/400 [04:39<02:14,  1.28it/s]Running loglikelihood requests:  57%|█████▋    | 229/400 [04:40<02:13,  1.28it/s]Running loglikelihood requests:  57%|█████▊    | 230/400 [04:40<02:13,  1.28it/s]Running loglikelihood requests:  58%|█████▊    | 231/400 [04:41<02:12,  1.28it/s]Running loglikelihood requests:  58%|█████▊    | 232/400 [04:42<02:11,  1.28it/s]Running loglikelihood requests:  58%|█████▊    | 233/400 [04:43<02:10,  1.28it/s]Running loglikelihood requests:  58%|█████▊    | 234/400 [04:44<02:09,  1.28it/s]Running loglikelihood requests:  59%|█████▉    | 235/400 [04:44<02:08,  1.29it/s]Running loglikelihood requests:  59%|█████▉    | 236/400 [04:45<02:07,  1.29it/s]Running loglikelihood requests:  59%|█████▉    | 237/400 [04:46<02:06,  1.29it/s]Running loglikelihood requests:  60%|██████    | 240/400 [04:47<01:17,  2.07it/s]Running loglikelihood requests:  60%|██████    | 241/400 [04:47<01:26,  1.85it/s]Running loglikelihood requests:  60%|██████    | 242/400 [04:48<01:33,  1.69it/s]Running loglikelihood requests:  61%|██████    | 243/400 [04:49<01:38,  1.59it/s]Running loglikelihood requests:  61%|██████    | 244/400 [04:50<01:43,  1.51it/s]Running loglikelihood requests:  61%|██████▏   | 245/400 [04:50<01:46,  1.46it/s]Running loglikelihood requests:  62%|██████▏   | 246/400 [04:51<01:48,  1.43it/s]Running loglikelihood requests:  62%|██████▏   | 247/400 [04:52<01:49,  1.40it/s]Running loglikelihood requests:  62%|██████▏   | 248/400 [04:53<01:49,  1.39it/s]Running loglikelihood requests:  62%|██████▏   | 249/400 [04:53<01:49,  1.37it/s]Running loglikelihood requests:  62%|██████▎   | 250/400 [04:54<01:49,  1.37it/s]Running loglikelihood requests:  63%|██████▎   | 251/400 [04:55<01:49,  1.37it/s]Running loglikelihood requests:  63%|██████▎   | 252/400 [04:56<01:48,  1.36it/s]Running loglikelihood requests:  63%|██████▎   | 253/400 [04:56<01:47,  1.36it/s]Running loglikelihood requests:  64%|██████▎   | 254/400 [04:57<01:47,  1.36it/s]Running loglikelihood requests:  64%|██████▍   | 255/400 [04:58<01:46,  1.36it/s]Running loglikelihood requests:  64%|██████▍   | 256/400 [04:58<01:45,  1.36it/s]Running loglikelihood requests:  64%|██████▍   | 257/400 [04:59<01:44,  1.37it/s]Running loglikelihood requests:  64%|██████▍   | 258/400 [05:00<01:43,  1.37it/s]Running loglikelihood requests:  65%|██████▍   | 259/400 [05:01<01:42,  1.37it/s]Running loglikelihood requests:  65%|██████▌   | 260/400 [05:01<01:41,  1.38it/s]Running loglikelihood requests:  65%|██████▌   | 261/400 [05:02<01:39,  1.40it/s]Running loglikelihood requests:  66%|██████▌   | 262/400 [05:03<01:37,  1.42it/s]Running loglikelihood requests:  66%|██████▌   | 263/400 [05:03<01:35,  1.43it/s]Running loglikelihood requests:  66%|██████▌   | 264/400 [05:04<01:34,  1.44it/s]Running loglikelihood requests:  66%|██████▋   | 265/400 [05:05<01:31,  1.47it/s]Running loglikelihood requests:  66%|██████▋   | 266/400 [05:05<01:29,  1.50it/s]Running loglikelihood requests:  67%|██████▋   | 267/400 [05:06<01:27,  1.51it/s]Running loglikelihood requests:  67%|██████▋   | 268/400 [05:07<01:26,  1.53it/s]Running loglikelihood requests:  67%|██████▋   | 269/400 [05:07<01:24,  1.54it/s]Running loglikelihood requests:  68%|██████▊   | 270/400 [05:08<01:23,  1.56it/s]Running loglikelihood requests:  68%|██████▊   | 271/400 [05:09<01:22,  1.57it/s]Running loglikelihood requests:  68%|██████▊   | 272/400 [05:09<01:21,  1.58it/s]Running loglikelihood requests:  68%|██████▊   | 273/400 [05:10<01:19,  1.61it/s]Running loglikelihood requests:  68%|██████▊   | 274/400 [05:10<01:17,  1.64it/s]Running loglikelihood requests:  69%|██████▉   | 275/400 [05:11<01:15,  1.66it/s]Running loglikelihood requests:  69%|██████▉   | 276/400 [05:12<01:14,  1.67it/s]Running loglikelihood requests:  69%|██████▉   | 277/400 [05:12<01:13,  1.68it/s]Running loglikelihood requests:  70%|██████▉   | 278/400 [05:13<01:12,  1.69it/s]Running loglikelihood requests:  70%|██████▉   | 279/400 [05:13<01:11,  1.70it/s]Running loglikelihood requests:  70%|███████   | 280/400 [05:14<01:10,  1.71it/s]Running loglikelihood requests:  70%|███████   | 281/400 [05:14<01:09,  1.72it/s]Running loglikelihood requests:  70%|███████   | 282/400 [05:15<01:08,  1.73it/s]Running loglikelihood requests:  71%|███████   | 283/400 [05:16<01:07,  1.73it/s]Running loglikelihood requests:  71%|███████   | 284/400 [05:16<01:06,  1.74it/s]Running loglikelihood requests:  71%|███████▏  | 285/400 [05:17<01:06,  1.74it/s]Running loglikelihood requests:  72%|███████▏  | 286/400 [05:17<01:05,  1.74it/s]Running loglikelihood requests:  72%|███████▏  | 287/400 [05:18<01:04,  1.75it/s]Running loglikelihood requests:  72%|███████▏  | 288/400 [05:18<01:03,  1.75it/s]Running loglikelihood requests:  72%|███████▏  | 289/400 [05:19<01:03,  1.75it/s]Running loglikelihood requests:  72%|███████▎  | 290/400 [05:20<01:02,  1.76it/s]Running loglikelihood requests:  73%|███████▎  | 291/400 [05:20<01:02,  1.76it/s]Running loglikelihood requests:  73%|███████▎  | 292/400 [05:21<01:01,  1.76it/s]Running loglikelihood requests:  73%|███████▎  | 293/400 [05:21<01:00,  1.76it/s]Running loglikelihood requests:  74%|███████▎  | 294/400 [05:22<01:00,  1.76it/s]Running loglikelihood requests:  74%|███████▍  | 295/400 [05:22<00:59,  1.77it/s]Running loglikelihood requests:  74%|███████▍  | 296/400 [05:23<00:58,  1.78it/s]Running loglikelihood requests:  74%|███████▍  | 297/400 [05:24<00:57,  1.78it/s]Running loglikelihood requests:  74%|███████▍  | 298/400 [05:24<00:57,  1.78it/s]Running loglikelihood requests:  75%|███████▍  | 299/400 [05:25<00:56,  1.78it/s]Running loglikelihood requests:  75%|███████▌  | 300/400 [05:25<00:55,  1.79it/s]Running loglikelihood requests:  75%|███████▌  | 301/400 [05:26<00:55,  1.79it/s]Running loglikelihood requests:  76%|███████▌  | 302/400 [05:26<00:54,  1.79it/s]Running loglikelihood requests:  76%|███████▌  | 303/400 [05:27<00:54,  1.79it/s]Running loglikelihood requests:  76%|███████▌  | 304/400 [05:27<00:53,  1.79it/s]Running loglikelihood requests:  76%|███████▋  | 305/400 [05:28<00:52,  1.80it/s]Running loglikelihood requests:  76%|███████▋  | 306/400 [05:29<00:52,  1.80it/s]Running loglikelihood requests:  77%|███████▋  | 307/400 [05:29<00:51,  1.80it/s]Running loglikelihood requests:  78%|███████▊  | 310/400 [05:30<00:31,  2.89it/s]Running loglikelihood requests:  78%|███████▊  | 311/400 [05:30<00:34,  2.57it/s]Running loglikelihood requests:  78%|███████▊  | 312/400 [05:31<00:37,  2.34it/s]Running loglikelihood requests:  78%|███████▊  | 313/400 [05:31<00:39,  2.19it/s]Running loglikelihood requests:  78%|███████▊  | 314/400 [05:32<00:41,  2.08it/s]Running loglikelihood requests:  79%|███████▉  | 315/400 [05:32<00:42,  2.00it/s]Running loglikelihood requests:  79%|███████▉  | 316/400 [05:33<00:43,  1.95it/s]Running loglikelihood requests:  79%|███████▉  | 317/400 [05:33<00:43,  1.92it/s]Running loglikelihood requests:  80%|███████▉  | 318/400 [05:34<00:43,  1.90it/s]Running loglikelihood requests:  80%|███████▉  | 319/400 [05:35<00:42,  1.90it/s]Running loglikelihood requests:  80%|████████  | 321/400 [05:35<00:32,  2.45it/s]Running loglikelihood requests:  80%|████████  | 322/400 [05:36<00:33,  2.29it/s]Running loglikelihood requests:  81%|████████  | 323/400 [05:36<00:35,  2.18it/s]Running loglikelihood requests:  81%|████████  | 324/400 [05:37<00:36,  2.10it/s]Running loglikelihood requests:  81%|████████▏ | 325/400 [05:37<00:36,  2.04it/s]Running loglikelihood requests:  82%|████████▏ | 326/400 [05:38<00:36,  2.01it/s]Running loglikelihood requests:  82%|████████▏ | 327/400 [05:38<00:36,  1.99it/s]Running loglikelihood requests:  82%|████████▏ | 328/400 [05:39<00:36,  1.98it/s]Running loglikelihood requests:  82%|████████▏ | 329/400 [05:39<00:36,  1.97it/s]Running loglikelihood requests:  82%|████████▎ | 330/400 [05:40<00:35,  1.96it/s]Running loglikelihood requests:  83%|████████▎ | 331/400 [05:40<00:35,  1.95it/s]Running loglikelihood requests:  83%|████████▎ | 332/400 [05:41<00:34,  1.95it/s]Running loglikelihood requests:  83%|████████▎ | 333/400 [05:41<00:34,  1.96it/s]Running loglikelihood requests:  84%|████████▎ | 334/400 [05:42<00:33,  1.98it/s]Running loglikelihood requests:  84%|████████▍ | 335/400 [05:42<00:32,  1.98it/s]Running loglikelihood requests:  84%|████████▍ | 336/400 [05:43<00:32,  1.99it/s]Running loglikelihood requests:  84%|████████▍ | 337/400 [05:43<00:31,  1.99it/s]Running loglikelihood requests:  84%|████████▍ | 338/400 [05:44<00:31,  1.96it/s]Running loglikelihood requests:  85%|████████▍ | 339/400 [05:44<00:31,  1.96it/s]Running loglikelihood requests:  85%|████████▌ | 340/400 [05:45<00:30,  1.98it/s]Running loglikelihood requests:  85%|████████▌ | 341/400 [05:45<00:29,  1.99it/s]Running loglikelihood requests:  86%|████████▌ | 342/400 [05:46<00:28,  2.00it/s]Running loglikelihood requests:  86%|████████▌ | 343/400 [05:46<00:28,  1.98it/s]Running loglikelihood requests:  86%|████████▌ | 344/400 [05:47<00:28,  1.98it/s]Running loglikelihood requests:  86%|████████▋ | 345/400 [05:47<00:27,  1.99it/s]Running loglikelihood requests:  86%|████████▋ | 346/400 [05:48<00:27,  1.99it/s]Running loglikelihood requests:  87%|████████▋ | 347/400 [05:48<00:26,  1.99it/s]Running loglikelihood requests:  87%|████████▋ | 348/400 [05:49<00:26,  1.99it/s]Running loglikelihood requests:  87%|████████▋ | 349/400 [05:49<00:25,  1.99it/s]Running loglikelihood requests:  88%|████████▊ | 350/400 [05:50<00:25,  1.99it/s]Running loglikelihood requests:  88%|████████▊ | 351/400 [05:50<00:24,  2.00it/s]Running loglikelihood requests:  88%|████████▊ | 352/400 [05:51<00:24,  1.98it/s]Running loglikelihood requests:  88%|████████▊ | 353/400 [05:51<00:23,  2.00it/s]Running loglikelihood requests:  88%|████████▊ | 354/400 [05:52<00:22,  2.01it/s]Running loglikelihood requests:  89%|████████▉ | 355/400 [05:52<00:22,  2.02it/s]Running loglikelihood requests:  89%|████████▉ | 356/400 [05:53<00:21,  2.04it/s]Running loglikelihood requests:  89%|████████▉ | 357/400 [05:53<00:21,  2.05it/s]Running loglikelihood requests:  90%|████████▉ | 358/400 [05:54<00:20,  2.05it/s]Running loglikelihood requests:  90%|████████▉ | 359/400 [05:54<00:19,  2.06it/s]Running loglikelihood requests:  90%|█████████ | 360/400 [05:55<00:19,  2.06it/s]Running loglikelihood requests:  90%|█████████ | 361/400 [05:55<00:18,  2.07it/s]Running loglikelihood requests:  90%|█████████ | 362/400 [05:56<00:18,  2.07it/s]Running loglikelihood requests:  91%|█████████ | 363/400 [05:56<00:17,  2.08it/s]Running loglikelihood requests:  91%|█████████ | 364/400 [05:57<00:17,  2.08it/s]Running loglikelihood requests:  91%|█████████▏| 365/400 [05:57<00:16,  2.09it/s]Running loglikelihood requests:  92%|█████████▏| 366/400 [05:58<00:16,  2.09it/s]Running loglikelihood requests:  92%|█████████▏| 368/400 [05:58<00:11,  2.72it/s]Running loglikelihood requests:  92%|█████████▏| 369/400 [05:59<00:12,  2.53it/s]Running loglikelihood requests:  92%|█████████▎| 370/400 [05:59<00:12,  2.40it/s]Running loglikelihood requests:  93%|█████████▎| 371/400 [06:00<00:12,  2.31it/s]Running loglikelihood requests:  93%|█████████▎| 373/400 [06:00<00:09,  2.87it/s]Running loglikelihood requests:  94%|█████████▎| 374/400 [06:00<00:09,  2.64it/s]Running loglikelihood requests:  94%|█████████▍| 375/400 [06:01<00:10,  2.44it/s]Running loglikelihood requests:  94%|█████████▍| 376/400 [06:01<00:10,  2.33it/s]Running loglikelihood requests:  94%|█████████▍| 377/400 [06:02<00:10,  2.26it/s]Running loglikelihood requests:  94%|█████████▍| 378/400 [06:02<00:10,  2.20it/s]Running loglikelihood requests:  95%|█████████▍| 379/400 [06:03<00:09,  2.19it/s]Running loglikelihood requests:  95%|█████████▌| 380/400 [06:03<00:09,  2.19it/s]Running loglikelihood requests:  95%|█████████▌| 381/400 [06:04<00:08,  2.19it/s]Running loglikelihood requests:  96%|█████████▌| 382/400 [06:04<00:08,  2.19it/s]Running loglikelihood requests:  96%|█████████▌| 383/400 [06:05<00:07,  2.19it/s]Running loglikelihood requests:  96%|█████████▌| 384/400 [06:05<00:07,  2.20it/s]Running loglikelihood requests:  96%|█████████▋| 385/400 [06:06<00:06,  2.21it/s]Running loglikelihood requests:  96%|█████████▋| 386/400 [06:06<00:06,  2.21it/s]Running loglikelihood requests:  97%|█████████▋| 387/400 [06:06<00:05,  2.22it/s]Running loglikelihood requests:  97%|█████████▋| 388/400 [06:07<00:05,  2.23it/s]Running loglikelihood requests:  97%|█████████▋| 389/400 [06:07<00:04,  2.23it/s]Running loglikelihood requests:  98%|█████████▊| 390/400 [06:08<00:04,  2.24it/s]Running loglikelihood requests:  98%|█████████▊| 391/400 [06:08<00:04,  2.24it/s]Running loglikelihood requests:  98%|█████████▊| 392/400 [06:09<00:03,  2.25it/s]Running loglikelihood requests:  98%|█████████▊| 393/400 [06:09<00:03,  2.25it/s]Running loglikelihood requests:  98%|█████████▊| 394/400 [06:10<00:02,  2.26it/s]Running loglikelihood requests:  99%|█████████▉| 395/400 [06:10<00:02,  2.26it/s]Running loglikelihood requests:  99%|█████████▉| 396/400 [06:10<00:01,  2.27it/s]Running loglikelihood requests:  99%|█████████▉| 397/400 [06:11<00:01,  2.27it/s]Running loglikelihood requests: 100%|█████████▉| 398/400 [06:11<00:00,  2.28it/s]Running loglikelihood requests: 100%|█████████▉| 399/400 [06:12<00:00,  2.28it/s]Running loglikelihood requests: 100%|██████████| 400/400 [06:12<00:00,  2.29it/s]Running loglikelihood requests: 100%|██████████| 400/400 [06:12<00:00,  1.07it/s]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:4'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:4'}
full model:
{'sciq': {'alias': 'sciq', 'acc,none': 0.94, 'acc_stderr,none': 0.023868325657594204, 'acc_norm,none': 0.91, 'acc_norm_stderr,none': 0.028762349126466136}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.969062788859705
0.9024924890572922
0.7706109127217512
0.8221264026535647
0.9190490061886575
0.9866654579796295
0.6586322754204971
0.7962110384246164
0.8195614021629236
0.7124178311176441
0.787697814339696
0.7034455022322618
0.8136386046534271
0.8174990104652458
0.6784276389594894
0.8698440245672888
0.8886492811850213
0.6541737276411673
0.6560861559753316
0.8139845219953913
0.6714741870309046
0.6164364868717988
0.8331581872497299
0.9065420049234512
0.9246185715568276
0.7477515960551026
0.574165362968651
0.8586446364199891
0.8889771415746612
Total groups 70 exceeded the threshold, stopping comparison.
The group tensor is
[7, 3, 4, 2, 6, 1, 5, 0]
tensor([7, 3, 4, 2, 6, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 2, 5, 3, 4, 0, 7, 1]
tensor([6, 2, 5, 3, 4, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 3, 6, 2, 7, 1, 4, 0]
tensor([5, 3, 6, 2, 7, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 4, 2, 1, 3, 5, 1]
tensor([0, 0, 4, 2, 1, 3, 5, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 2, 3, 4, 5, 0, 1, 1]
tensor([0, 2, 3, 4, 5, 0, 1, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 1, 0, 2, 2, 3, 1]
tensor([0, 3, 1, 0, 2, 2, 3, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 3, 1, 1, 2, 2, 3, 0]
tensor([0, 3, 1, 1, 2, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 1, 1.0, 1.0, 1.0, 1.0, 1]
tensor([0, 0, 1, 1, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 2 to 4
done!
Normal merging for layer 5
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 6 to 9
done!
Normal merging for layer 10
tensor([0, 1])
tensor(0)
tensor([4, 7])
tensor(4)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 11 to 12
done!
Normal merging for layer 13
tensor([0, 5])
tensor(0)
tensor([6, 7])
tensor(6)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 14 to 19
done!
Normal merging for layer 20
tensor([0, 3])
tensor(0)
tensor([2, 7])
tensor(2)
tensor([4, 5])
tensor(4)
tensor([1, 6])
tensor(1)
done!
Normal merging for layer 21
tensor([0, 7])
tensor(0)
tensor([2, 3])
tensor(2)
tensor([4, 5])
tensor(4)
tensor([1, 6])
tensor(1)
done!
Cross-layer merge completed for layers 22 to 23
done!
Normal merging for layer 24
tensor([0, 1])
tensor(0)
tensor([2, 3, 4, 5, 6, 7])
tensor(2)
done!
Cross-layer merge completed for layers 25 to 31
done!
all done!
Model size: 12.2608 GB
29
cuda:4
wic
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:44<00:44, 44.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:57<00:00, 26.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:57<00:00, 28.91s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wic] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wic] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/super_glue/super_glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 235
DEBUG:filelock:Attempting to acquire lock 139720631453504 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_wic_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 139720631453504 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_wic_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wic/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 139720631453504 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_wic_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 139720631453504 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_wic_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Attempting to acquire lock 139722779002112 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wic/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 139722779002112 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wic/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wic/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 139722779002112 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wic/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 139722779002112 released on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wic/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wic from None to 0
INFO:lm_eval.api.task:Building contexts for wic on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1558.91it/s]
DEBUG:lm_eval.evaluator:Task: wic; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:01<04:06,  1.24s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:01<01:52,  1.74it/s]Running loglikelihood requests:   2%|▎         | 5/200 [00:02<01:27,  2.22it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:03<01:17,  2.50it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:03<01:11,  2.69it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:04<01:07,  2.81it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:05<01:04,  2.90it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:05<01:02,  2.97it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:06<01:00,  3.02it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:07<00:59,  3.06it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:07<00:58,  3.08it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:08<00:57,  3.10it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:09<00:56,  3.12it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:09<00:55,  3.13it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:10<00:54,  3.14it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:10<00:53,  3.16it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:11<00:52,  3.17it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:12<00:51,  3.18it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:12<00:50,  3.20it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:13<00:50,  3.21it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:14<00:49,  3.23it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:14<00:48,  3.24it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:15<00:47,  3.25it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:15<00:47,  3.25it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:16<00:46,  3.25it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:17<00:45,  3.25it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:17<00:45,  3.26it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:18<00:44,  3.27it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:18<00:43,  3.27it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:19<00:43,  3.27it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:20<00:42,  3.28it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:20<00:41,  3.28it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:21<00:41,  3.28it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:21<00:40,  3.28it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:22<00:39,  3.28it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:23<00:39,  3.29it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:23<00:38,  3.30it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:24<00:37,  3.31it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:24<00:37,  3.32it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:25<00:36,  3.32it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:26<00:35,  3.33it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:26<00:35,  3.34it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:27<00:34,  3.35it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:27<00:33,  3.35it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:28<00:33,  3.35it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:29<00:32,  3.35it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:29<00:31,  3.35it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:30<00:31,  3.36it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:30<00:30,  3.36it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:31<00:30,  3.36it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:32<00:29,  3.36it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:32<00:28,  3.36it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:33<00:28,  3.36it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:33<00:27,  3.37it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:34<00:26,  3.37it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:35<00:26,  3.38it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:35<00:25,  3.38it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:36<00:25,  3.38it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:36<00:24,  3.38it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:37<00:23,  3.39it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:38<00:23,  3.38it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:38<00:22,  3.38it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:39<00:22,  3.39it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [00:39<00:21,  3.39it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [00:40<00:20,  3.39it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [00:40<00:20,  3.40it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [00:41<00:19,  3.40it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [00:42<00:19,  3.40it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [00:42<00:18,  3.41it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [00:43<00:17,  3.42it/s]Running loglikelihood requests:  70%|███████   | 141/200 [00:43<00:17,  3.42it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [00:44<00:16,  3.43it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [00:45<00:15,  3.44it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [00:45<00:15,  3.45it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [00:46<00:14,  3.45it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [00:46<00:14,  3.45it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [00:47<00:13,  3.46it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [00:47<00:13,  3.46it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [00:48<00:12,  3.47it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [00:49<00:11,  3.48it/s]Running loglikelihood requests:  80%|████████  | 161/200 [00:49<00:11,  3.48it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [00:50<00:10,  3.49it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [00:50<00:10,  3.49it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [00:51<00:09,  3.50it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [00:51<00:08,  3.50it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [00:52<00:08,  3.51it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [00:53<00:07,  3.52it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [00:53<00:07,  3.53it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [00:54<00:06,  3.54it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [00:54<00:05,  3.55it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [00:55<00:05,  3.56it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [00:55<00:04,  3.56it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [00:56<00:04,  3.57it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [00:56<00:03,  3.58it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [00:57<00:03,  3.58it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [00:58<00:02,  3.60it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [00:58<00:01,  3.61it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [00:59<00:01,  3.61it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [00:59<00:00,  3.63it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:00<00:00,  3.64it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:00<00:00,  3.32it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:5'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:5'}
full model:
{'wic': {'alias': 'wic', 'acc,none': 0.47, 'acc_stderr,none': 0.05016135580465919}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.7015569150227223
0.5302361010977743
0.6131123609930033
0.8131827739550247
0.5456264918897312
0.5653128506125247
0.9024119585362896
0.8122852497904204
0.9072724946141106
0.866764102055741
0.8260299199157425
0.7472915500213457
0.8874866998217976
0.7441602305581367
0.22948143665096393
0.6763976434023368
0.5909756859477309
0.6775915070630182
0.8311737665735953
0.5882947608660276
0.7888779075700829
0.9530393862783458
0.7563942945196994
0.7021129984434293
0.9133573687405422
0.8864659884483975
0.43949477197814607
0.49530015739760547
0.9835705252160515
0.7015569150227223
0.5302361010977743
0.6131123609930033
0.8131827739550247
0.5456264918897312
0.5653128506125247
0.9024119585362896
0.8122852497904204
0.9072724946141106
0.866764102055741
0.8260299199157425
0.7472915500213457
0.8874866998217976
0.7441602305581367
Total groups 76 exceeded the threshold, stopping comparison.
The group tensor is
[6, 5, 2, 3, 7, 0, 4, 1]
tensor([6, 5, 2, 3, 7, 0, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 6, 1, 5, 4, 2, 3, 0]
tensor([7, 6, 1, 5, 4, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[7, 6, 2, 4, 5, 0, 3, 1]
tensor([7, 6, 2, 4, 5, 0, 3, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 0, 0, 5, 1, 1, 3, 2]
tensor([4, 0, 0, 5, 1, 1, 3, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 0, 2, 5, 3, 4, 1]
tensor([0, 1, 0, 2, 5, 3, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 0, 1, 4, 1, 2, 3, 0]
tensor([5, 0, 1, 4, 1, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 1, 1, 3, 4, 2, 5, 0]
tensor([0, 1, 1, 3, 4, 2, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 1, 0, 2, 3, 1, 2, 3]
tensor([0, 1, 0, 2, 3, 1, 2, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([2])
tensor(2)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 2 to 3
done!
Normal merging for layer 4
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 5 to 7
done!
Normal merging for layer 8
tensor([1, 2])
tensor(1)
tensor([4, 5])
tensor(4)
tensor([7])
tensor(7)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([3])
tensor(3)
done!
Cross-layer merge completed for layers 9 to 10
done!
Normal merging for layer 11
tensor([0, 2])
tensor(0)
tensor([1, 7])
tensor(1)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 12 to 13
done!
Normal merging for layer 14
tensor([1, 7])
tensor(1)
tensor([2, 4])
tensor(2)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([0])
tensor(0)
done!
Normal merging for layer 15
tensor([0, 7])
tensor(0)
tensor([1, 2])
tensor(1)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
done!
Normal merging for layer 16
tensor([0, 2])
tensor(0)
tensor([1, 5])
tensor(1)
tensor([3, 6])
tensor(3)
tensor([4, 7])
tensor(4)
done!
Cross-layer merge completed for layers 17 to 31
done!
all done!
Model size: 12.5757 GB
11
cuda:5
mastermind_35_easy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:41<00:41, 41.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:53<00:00, 24.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:53<00:00, 26.88s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_35_mcq_random HTTP/1.1" 200 772
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/flair/mastermind_35_mcq_random/flair/mastermind_35_mcq_random.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_35_mcq_random HTTP/1.1" 200 780
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/flair/mastermind_35_mcq_random/resolve/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/flair/mastermind_35_mcq_random/resolve/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:filelock:Attempting to acquire lock 139720653497856 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_35_mcq_random_default_0.0.0_15dd5105771e9c8d2d3ea71c8d44fffda374a7a1.lock
DEBUG:filelock:Lock 139720653497856 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_35_mcq_random_default_0.0.0_15dd5105771e9c8d2d3ea71c8d44fffda374a7a1.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1/dataset_info.json
DEBUG:filelock:Attempting to release lock 139720653497856 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_35_mcq_random_default_0.0.0_15dd5105771e9c8d2d3ea71c8d44fffda374a7a1.lock
DEBUG:filelock:Lock 139720653497856 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_35_mcq_random_default_0.0.0_15dd5105771e9c8d2d3ea71c8d44fffda374a7a1.lock
DEBUG:filelock:Attempting to acquire lock 139722742976768 on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1_builder.lock
DEBUG:filelock:Lock 139722742976768 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1/dataset_info.json
DEBUG:filelock:Attempting to release lock 139722742976768 on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1_builder.lock
DEBUG:filelock:Lock 139722742976768 released on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mastermind_35_easy from None to 0
INFO:lm_eval.api.task:Building contexts for mastermind_35_easy on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1514.12it/s]
DEBUG:lm_eval.evaluator:Task: mastermind_35_easy; number of requests on this rank: 400
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/400 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/400 [00:01<10:41,  1.61s/it]Running loglikelihood requests:   0%|          | 2/400 [00:02<08:59,  1.36s/it]Running loglikelihood requests:   1%|          | 3/400 [00:03<08:25,  1.27s/it]Running loglikelihood requests:   1%|          | 4/400 [00:05<08:08,  1.23s/it]Running loglikelihood requests:   1%|▏         | 5/400 [00:06<07:58,  1.21s/it]Running loglikelihood requests:   2%|▏         | 6/400 [00:07<07:51,  1.20s/it]Running loglikelihood requests:   2%|▏         | 7/400 [00:08<07:46,  1.19s/it]Running loglikelihood requests:   2%|▏         | 8/400 [00:09<07:43,  1.18s/it]Running loglikelihood requests:   2%|▏         | 9/400 [00:10<07:40,  1.18s/it]Running loglikelihood requests:   2%|▎         | 10/400 [00:12<07:37,  1.17s/it]Running loglikelihood requests:   3%|▎         | 11/400 [00:13<07:35,  1.17s/it]Running loglikelihood requests:   3%|▎         | 12/400 [00:14<07:33,  1.17s/it]Running loglikelihood requests:   3%|▎         | 13/400 [00:15<07:30,  1.16s/it]Running loglikelihood requests:   4%|▎         | 14/400 [00:16<07:28,  1.16s/it]Running loglikelihood requests:   4%|▍         | 15/400 [00:17<07:26,  1.16s/it]Running loglikelihood requests:   4%|▍         | 16/400 [00:19<07:25,  1.16s/it]Running loglikelihood requests:   4%|▍         | 17/400 [00:20<07:23,  1.16s/it]Running loglikelihood requests:   4%|▍         | 18/400 [00:21<07:22,  1.16s/it]Running loglikelihood requests:   5%|▍         | 19/400 [00:22<07:19,  1.15s/it]Running loglikelihood requests:   5%|▌         | 20/400 [00:23<07:17,  1.15s/it]Running loglikelihood requests:   5%|▌         | 21/400 [00:24<07:16,  1.15s/it]Running loglikelihood requests:   6%|▌         | 23/400 [00:26<05:34,  1.13it/s]Running loglikelihood requests:   6%|▌         | 24/400 [00:27<05:57,  1.05it/s]Running loglikelihood requests:   6%|▋         | 25/400 [00:28<06:15,  1.00s/it]Running loglikelihood requests:   6%|▋         | 26/400 [00:29<06:28,  1.04s/it]Running loglikelihood requests:   7%|▋         | 27/400 [00:30<06:37,  1.07s/it]Running loglikelihood requests:   7%|▋         | 28/400 [00:31<06:44,  1.09s/it]Running loglikelihood requests:   7%|▋         | 29/400 [00:32<06:49,  1.10s/it]Running loglikelihood requests:   8%|▊         | 30/400 [00:33<06:52,  1.11s/it]Running loglikelihood requests:   8%|▊         | 31/400 [00:35<06:53,  1.12s/it]Running loglikelihood requests:   8%|▊         | 32/400 [00:36<06:54,  1.13s/it]Running loglikelihood requests:   8%|▊         | 33/400 [00:37<06:55,  1.13s/it]Running loglikelihood requests:   8%|▊         | 34/400 [00:38<06:54,  1.13s/it]Running loglikelihood requests:   9%|▉         | 35/400 [00:39<06:54,  1.13s/it]Running loglikelihood requests:   9%|▉         | 36/400 [00:40<06:53,  1.14s/it]Running loglikelihood requests:   9%|▉         | 37/400 [00:41<06:52,  1.14s/it]Running loglikelihood requests:  10%|▉         | 38/400 [00:43<06:51,  1.14s/it]Running loglikelihood requests:  10%|▉         | 39/400 [00:44<06:50,  1.14s/it]Running loglikelihood requests:  10%|█         | 40/400 [00:45<06:48,  1.14s/it]Running loglikelihood requests:  10%|█         | 41/400 [00:46<06:47,  1.14s/it]Running loglikelihood requests:  10%|█         | 42/400 [00:47<06:46,  1.14s/it]Running loglikelihood requests:  11%|█         | 43/400 [00:48<06:45,  1.14s/it]Running loglikelihood requests:  11%|█         | 44/400 [00:49<06:44,  1.14s/it]Running loglikelihood requests:  11%|█▏        | 45/400 [00:51<06:42,  1.14s/it]Running loglikelihood requests:  12%|█▏        | 46/400 [00:52<06:41,  1.13s/it]Running loglikelihood requests:  12%|█▏        | 47/400 [00:53<06:40,  1.14s/it]Running loglikelihood requests:  12%|█▏        | 48/400 [00:54<06:39,  1.14s/it]Running loglikelihood requests:  12%|█▏        | 49/400 [00:55<06:38,  1.13s/it]Running loglikelihood requests:  12%|█▎        | 50/400 [00:56<06:37,  1.13s/it]Running loglikelihood requests:  13%|█▎        | 51/400 [00:57<06:36,  1.13s/it]Running loglikelihood requests:  13%|█▎        | 52/400 [00:58<06:35,  1.14s/it]Running loglikelihood requests:  13%|█▎        | 53/400 [01:00<06:33,  1.14s/it]Running loglikelihood requests:  14%|█▎        | 54/400 [01:01<06:32,  1.13s/it]Running loglikelihood requests:  14%|█▍        | 55/400 [01:02<06:31,  1.13s/it]Running loglikelihood requests:  14%|█▍        | 56/400 [01:03<06:30,  1.14s/it]Running loglikelihood requests:  14%|█▍        | 57/400 [01:04<06:29,  1.14s/it]Running loglikelihood requests:  14%|█▍        | 58/400 [01:05<06:28,  1.14s/it]Running loglikelihood requests:  15%|█▍        | 59/400 [01:06<06:27,  1.14s/it]Running loglikelihood requests:  15%|█▌        | 60/400 [01:08<06:26,  1.14s/it]Running loglikelihood requests:  15%|█▌        | 61/400 [01:09<06:26,  1.14s/it]Running loglikelihood requests:  16%|█▌        | 62/400 [01:10<06:24,  1.14s/it]Running loglikelihood requests:  16%|█▌        | 63/400 [01:11<06:23,  1.14s/it]Running loglikelihood requests:  16%|█▌        | 64/400 [01:12<06:22,  1.14s/it]Running loglikelihood requests:  16%|█▋        | 65/400 [01:13<06:21,  1.14s/it]Running loglikelihood requests:  16%|█▋        | 66/400 [01:14<06:20,  1.14s/it]Running loglikelihood requests:  17%|█▋        | 67/400 [01:16<06:19,  1.14s/it]Running loglikelihood requests:  17%|█▋        | 68/400 [01:17<06:18,  1.14s/it]Running loglikelihood requests:  17%|█▋        | 69/400 [01:18<06:16,  1.14s/it]Running loglikelihood requests:  18%|█▊        | 70/400 [01:19<06:15,  1.14s/it]Running loglikelihood requests:  18%|█▊        | 71/400 [01:20<06:14,  1.14s/it]Running loglikelihood requests:  18%|█▊        | 72/400 [01:21<06:13,  1.14s/it]Running loglikelihood requests:  18%|█▊        | 73/400 [01:22<06:11,  1.14s/it]Running loglikelihood requests:  18%|█▊        | 74/400 [01:24<06:10,  1.14s/it]Running loglikelihood requests:  19%|█▉        | 75/400 [01:25<06:08,  1.13s/it]Running loglikelihood requests:  19%|█▉        | 76/400 [01:26<06:07,  1.13s/it]Running loglikelihood requests:  19%|█▉        | 77/400 [01:27<06:06,  1.13s/it]Running loglikelihood requests:  20%|█▉        | 78/400 [01:28<06:04,  1.13s/it]Running loglikelihood requests:  20%|█▉        | 79/400 [01:29<06:03,  1.13s/it]Running loglikelihood requests:  20%|██        | 80/400 [01:30<06:02,  1.13s/it]Running loglikelihood requests:  20%|██        | 81/400 [01:31<06:01,  1.13s/it]Running loglikelihood requests:  20%|██        | 82/400 [01:33<05:59,  1.13s/it]Running loglikelihood requests:  21%|██        | 83/400 [01:34<05:58,  1.13s/it]Running loglikelihood requests:  21%|██        | 84/400 [01:35<05:57,  1.13s/it]Running loglikelihood requests:  21%|██▏       | 85/400 [01:36<05:56,  1.13s/it]Running loglikelihood requests:  22%|██▏       | 86/400 [01:37<05:55,  1.13s/it]Running loglikelihood requests:  22%|██▏       | 87/400 [01:38<05:54,  1.13s/it]Running loglikelihood requests:  22%|██▏       | 88/400 [01:39<05:53,  1.13s/it]Running loglikelihood requests:  22%|██▏       | 89/400 [01:40<05:51,  1.13s/it]Running loglikelihood requests:  22%|██▎       | 90/400 [01:42<05:51,  1.13s/it]Running loglikelihood requests:  23%|██▎       | 91/400 [01:43<05:50,  1.13s/it]Running loglikelihood requests:  23%|██▎       | 92/400 [01:44<05:49,  1.13s/it]Running loglikelihood requests:  23%|██▎       | 93/400 [01:45<05:48,  1.14s/it]Running loglikelihood requests:  24%|██▎       | 94/400 [01:46<05:47,  1.14s/it]Running loglikelihood requests:  24%|██▍       | 95/400 [01:47<05:46,  1.14s/it]Running loglikelihood requests:  24%|██▍       | 96/400 [01:48<05:45,  1.14s/it]Running loglikelihood requests:  24%|██▍       | 97/400 [01:50<05:43,  1.13s/it]Running loglikelihood requests:  24%|██▍       | 98/400 [01:51<05:42,  1.14s/it]Running loglikelihood requests:  25%|██▍       | 99/400 [01:52<05:41,  1.13s/it]Running loglikelihood requests:  25%|██▌       | 100/400 [01:53<05:40,  1.13s/it]Running loglikelihood requests:  25%|██▌       | 101/400 [01:54<05:38,  1.13s/it]Running loglikelihood requests:  26%|██▌       | 102/400 [01:55<05:37,  1.13s/it]Running loglikelihood requests:  26%|██▌       | 103/400 [01:56<05:35,  1.13s/it]Running loglikelihood requests:  26%|██▌       | 104/400 [01:57<05:34,  1.13s/it]Running loglikelihood requests:  26%|██▋       | 105/400 [01:59<05:33,  1.13s/it]Running loglikelihood requests:  26%|██▋       | 106/400 [02:00<05:32,  1.13s/it]Running loglikelihood requests:  27%|██▋       | 107/400 [02:01<05:30,  1.13s/it]Running loglikelihood requests:  27%|██▋       | 108/400 [02:02<05:29,  1.13s/it]Running loglikelihood requests:  27%|██▋       | 109/400 [02:03<05:28,  1.13s/it]Running loglikelihood requests:  28%|██▊       | 110/400 [02:04<05:27,  1.13s/it]Running loglikelihood requests:  28%|██▊       | 112/400 [02:05<04:10,  1.15it/s]Running loglikelihood requests:  28%|██▊       | 113/400 [02:07<04:27,  1.07it/s]Running loglikelihood requests:  28%|██▊       | 114/400 [02:08<04:41,  1.02it/s]Running loglikelihood requests:  29%|██▉       | 115/400 [02:09<04:51,  1.02s/it]Running loglikelihood requests:  29%|██▉       | 116/400 [02:10<04:58,  1.05s/it]Running loglikelihood requests:  29%|██▉       | 117/400 [02:11<05:03,  1.07s/it]Running loglikelihood requests:  30%|██▉       | 118/400 [02:12<05:06,  1.09s/it]Running loglikelihood requests:  30%|██▉       | 119/400 [02:13<05:09,  1.10s/it]Running loglikelihood requests:  30%|███       | 120/400 [02:14<05:10,  1.11s/it]Running loglikelihood requests:  30%|███       | 121/400 [02:16<05:11,  1.12s/it]Running loglikelihood requests:  30%|███       | 122/400 [02:17<05:11,  1.12s/it]Running loglikelihood requests:  31%|███       | 123/400 [02:18<05:10,  1.12s/it]Running loglikelihood requests:  31%|███       | 124/400 [02:19<05:09,  1.12s/it]Running loglikelihood requests:  31%|███▏      | 125/400 [02:20<05:09,  1.13s/it]Running loglikelihood requests:  32%|███▏      | 126/400 [02:21<05:08,  1.13s/it]Running loglikelihood requests:  32%|███▏      | 127/400 [02:22<05:07,  1.13s/it]Running loglikelihood requests:  32%|███▏      | 128/400 [02:23<05:06,  1.13s/it]Running loglikelihood requests:  32%|███▏      | 129/400 [02:25<05:05,  1.13s/it]Running loglikelihood requests:  32%|███▎      | 130/400 [02:26<05:04,  1.13s/it]Running loglikelihood requests:  33%|███▎      | 131/400 [02:27<05:03,  1.13s/it]Running loglikelihood requests:  33%|███▎      | 132/400 [02:28<05:01,  1.13s/it]Running loglikelihood requests:  33%|███▎      | 133/400 [02:29<05:00,  1.13s/it]Running loglikelihood requests:  34%|███▎      | 134/400 [02:30<04:59,  1.13s/it]Running loglikelihood requests:  34%|███▍      | 135/400 [02:31<04:58,  1.13s/it]Running loglikelihood requests:  34%|███▍      | 136/400 [02:32<04:56,  1.12s/it]Running loglikelihood requests:  34%|███▍      | 137/400 [02:34<04:55,  1.12s/it]Running loglikelihood requests:  34%|███▍      | 138/400 [02:35<04:53,  1.12s/it]Running loglikelihood requests:  35%|███▍      | 139/400 [02:36<04:52,  1.12s/it]Running loglikelihood requests:  35%|███▌      | 140/400 [02:37<04:51,  1.12s/it]Running loglikelihood requests:  35%|███▌      | 141/400 [02:38<04:50,  1.12s/it]Running loglikelihood requests:  36%|███▌      | 142/400 [02:39<04:49,  1.12s/it]Running loglikelihood requests:  36%|███▌      | 143/400 [02:40<04:47,  1.12s/it]Running loglikelihood requests:  36%|███▌      | 144/400 [02:41<04:46,  1.12s/it]Running loglikelihood requests:  36%|███▋      | 145/400 [02:43<04:45,  1.12s/it]Running loglikelihood requests:  36%|███▋      | 146/400 [02:44<04:43,  1.12s/it]Running loglikelihood requests:  37%|███▋      | 147/400 [02:45<04:42,  1.12s/it]Running loglikelihood requests:  37%|███▋      | 148/400 [02:46<04:41,  1.12s/it]Running loglikelihood requests:  37%|███▋      | 149/400 [02:47<04:40,  1.12s/it]Running loglikelihood requests:  38%|███▊      | 150/400 [02:48<04:38,  1.12s/it]Running loglikelihood requests:  38%|███▊      | 151/400 [02:49<04:37,  1.12s/it]Running loglikelihood requests:  38%|███▊      | 152/400 [02:50<04:36,  1.11s/it]Running loglikelihood requests:  38%|███▊      | 153/400 [02:51<04:34,  1.11s/it]Running loglikelihood requests:  38%|███▊      | 154/400 [02:53<04:33,  1.11s/it]Running loglikelihood requests:  39%|███▉      | 155/400 [02:54<04:32,  1.11s/it]Running loglikelihood requests:  39%|███▉      | 156/400 [02:55<04:31,  1.11s/it]Running loglikelihood requests:  39%|███▉      | 157/400 [02:56<04:30,  1.11s/it]Running loglikelihood requests:  40%|███▉      | 158/400 [02:57<04:28,  1.11s/it]Running loglikelihood requests:  40%|███▉      | 159/400 [02:58<04:27,  1.11s/it]Running loglikelihood requests:  40%|████      | 160/400 [02:59<04:26,  1.11s/it]Running loglikelihood requests:  40%|████      | 161/400 [03:00<04:24,  1.11s/it]Running loglikelihood requests:  40%|████      | 162/400 [03:01<04:23,  1.11s/it]Running loglikelihood requests:  41%|████      | 163/400 [03:03<04:22,  1.11s/it]Running loglikelihood requests:  41%|████      | 164/400 [03:04<04:21,  1.11s/it]Running loglikelihood requests:  41%|████▏     | 165/400 [03:05<04:20,  1.11s/it]Running loglikelihood requests:  42%|████▏     | 166/400 [03:06<04:19,  1.11s/it]Running loglikelihood requests:  42%|████▏     | 167/400 [03:07<04:18,  1.11s/it]Running loglikelihood requests:  42%|████▏     | 168/400 [03:08<04:16,  1.11s/it]Running loglikelihood requests:  42%|████▏     | 169/400 [03:09<04:17,  1.12s/it]Running loglikelihood requests:  42%|████▎     | 170/400 [03:10<04:16,  1.11s/it]Running loglikelihood requests:  43%|████▎     | 171/400 [03:11<04:14,  1.11s/it]Running loglikelihood requests:  43%|████▎     | 172/400 [03:13<04:13,  1.11s/it]Running loglikelihood requests:  43%|████▎     | 173/400 [03:14<04:11,  1.11s/it]Running loglikelihood requests:  44%|████▎     | 174/400 [03:15<04:10,  1.11s/it]Running loglikelihood requests:  44%|████▍     | 175/400 [03:16<04:09,  1.11s/it]Running loglikelihood requests:  44%|████▍     | 177/400 [03:17<03:10,  1.17it/s]Running loglikelihood requests:  44%|████▍     | 178/400 [03:18<03:23,  1.09it/s]Running loglikelihood requests:  45%|████▍     | 179/400 [03:19<03:33,  1.04it/s]Running loglikelihood requests:  45%|████▌     | 180/400 [03:20<03:41,  1.00s/it]Running loglikelihood requests:  45%|████▌     | 181/400 [03:21<03:46,  1.03s/it]Running loglikelihood requests:  46%|████▌     | 182/400 [03:22<03:49,  1.05s/it]Running loglikelihood requests:  46%|████▌     | 183/400 [03:24<03:52,  1.07s/it]Running loglikelihood requests:  46%|████▌     | 184/400 [03:25<03:53,  1.08s/it]Running loglikelihood requests:  46%|████▋     | 185/400 [03:26<03:54,  1.09s/it]Running loglikelihood requests:  46%|████▋     | 186/400 [03:27<03:54,  1.09s/it]Running loglikelihood requests:  47%|████▋     | 187/400 [03:28<03:53,  1.10s/it]Running loglikelihood requests:  47%|████▋     | 188/400 [03:29<03:52,  1.10s/it]Running loglikelihood requests:  47%|████▋     | 189/400 [03:30<03:52,  1.10s/it]Running loglikelihood requests:  48%|████▊     | 190/400 [03:31<03:51,  1.10s/it]Running loglikelihood requests:  48%|████▊     | 191/400 [03:32<03:50,  1.10s/it]Running loglikelihood requests:  48%|████▊     | 192/400 [03:34<03:49,  1.10s/it]Running loglikelihood requests:  48%|████▊     | 193/400 [03:35<03:48,  1.10s/it]Running loglikelihood requests:  48%|████▊     | 194/400 [03:36<03:46,  1.10s/it]Running loglikelihood requests:  49%|████▉     | 195/400 [03:37<03:46,  1.10s/it]Running loglikelihood requests:  49%|████▉     | 196/400 [03:38<03:44,  1.10s/it]Running loglikelihood requests:  49%|████▉     | 197/400 [03:39<03:44,  1.10s/it]Running loglikelihood requests:  50%|████▉     | 198/400 [03:40<03:43,  1.10s/it]Running loglikelihood requests:  50%|████▉     | 199/400 [03:41<03:41,  1.10s/it]Running loglikelihood requests:  50%|█████     | 200/400 [03:42<03:40,  1.10s/it]Running loglikelihood requests:  50%|█████     | 201/400 [03:43<03:39,  1.10s/it]Running loglikelihood requests:  50%|█████     | 202/400 [03:45<03:38,  1.10s/it]Running loglikelihood requests:  51%|█████     | 203/400 [03:46<03:37,  1.10s/it]Running loglikelihood requests:  51%|█████▏    | 205/400 [03:47<02:45,  1.18it/s]Running loglikelihood requests:  52%|█████▏    | 206/400 [03:48<02:56,  1.10it/s]Running loglikelihood requests:  52%|█████▏    | 207/400 [03:49<03:05,  1.04it/s]Running loglikelihood requests:  52%|█████▏    | 208/400 [03:50<03:11,  1.00it/s]Running loglikelihood requests:  52%|█████▏    | 209/400 [03:51<03:15,  1.03s/it]Running loglikelihood requests:  52%|█████▎    | 210/400 [03:52<03:18,  1.05s/it]Running loglikelihood requests:  53%|█████▎    | 211/400 [03:53<03:20,  1.06s/it]Running loglikelihood requests:  53%|█████▎    | 212/400 [03:54<03:21,  1.07s/it]Running loglikelihood requests:  53%|█████▎    | 213/400 [03:56<03:22,  1.08s/it]Running loglikelihood requests:  54%|█████▎    | 214/400 [03:57<03:21,  1.08s/it]Running loglikelihood requests:  54%|█████▍    | 215/400 [03:58<03:21,  1.09s/it]Running loglikelihood requests:  54%|█████▍    | 216/400 [03:59<03:20,  1.09s/it]Running loglikelihood requests:  54%|█████▍    | 217/400 [04:00<03:19,  1.09s/it]Running loglikelihood requests:  55%|█████▍    | 218/400 [04:01<03:18,  1.09s/it]Running loglikelihood requests:  55%|█████▍    | 219/400 [04:02<03:17,  1.09s/it]Running loglikelihood requests:  55%|█████▌    | 220/400 [04:03<03:17,  1.09s/it]Running loglikelihood requests:  55%|█████▌    | 221/400 [04:04<03:16,  1.10s/it]Running loglikelihood requests:  56%|█████▌    | 222/400 [04:05<03:14,  1.09s/it]Running loglikelihood requests:  56%|█████▌    | 223/400 [04:07<03:13,  1.09s/it]Running loglikelihood requests:  56%|█████▌    | 224/400 [04:08<03:12,  1.09s/it]Running loglikelihood requests:  56%|█████▋    | 225/400 [04:09<03:11,  1.09s/it]Running loglikelihood requests:  56%|█████▋    | 226/400 [04:10<03:10,  1.09s/it]Running loglikelihood requests:  57%|█████▋    | 227/400 [04:11<03:09,  1.09s/it]Running loglikelihood requests:  57%|█████▋    | 228/400 [04:12<03:08,  1.09s/it]Running loglikelihood requests:  57%|█████▋    | 229/400 [04:13<03:06,  1.09s/it]Running loglikelihood requests:  57%|█████▊    | 230/400 [04:14<03:05,  1.09s/it]Running loglikelihood requests:  58%|█████▊    | 231/400 [04:15<03:04,  1.09s/it]Running loglikelihood requests:  58%|█████▊    | 232/400 [04:16<03:03,  1.09s/it]Running loglikelihood requests:  58%|█████▊    | 233/400 [04:17<03:02,  1.09s/it]Running loglikelihood requests:  58%|█████▊    | 234/400 [04:19<03:01,  1.09s/it]Running loglikelihood requests:  59%|█████▉    | 235/400 [04:20<03:00,  1.09s/it]Running loglikelihood requests:  59%|█████▉    | 236/400 [04:21<02:59,  1.09s/it]Running loglikelihood requests:  59%|█████▉    | 237/400 [04:22<02:58,  1.09s/it]Running loglikelihood requests:  60%|█████▉    | 238/400 [04:23<02:57,  1.09s/it]Running loglikelihood requests:  60%|█████▉    | 239/400 [04:24<02:56,  1.09s/it]Running loglikelihood requests:  60%|██████    | 241/400 [04:25<02:13,  1.19it/s]Running loglikelihood requests:  60%|██████    | 242/400 [04:26<02:22,  1.11it/s]Running loglikelihood requests:  61%|██████    | 243/400 [04:27<02:29,  1.05it/s]Running loglikelihood requests:  61%|██████    | 244/400 [04:28<02:34,  1.01it/s]Running loglikelihood requests:  61%|██████▏   | 245/400 [04:29<02:37,  1.02s/it]Running loglikelihood requests:  62%|██████▏   | 246/400 [04:31<02:39,  1.04s/it]Running loglikelihood requests:  62%|██████▏   | 247/400 [04:32<02:40,  1.05s/it]Running loglikelihood requests:  62%|██████▏   | 248/400 [04:33<02:41,  1.06s/it]Running loglikelihood requests:  62%|██████▏   | 249/400 [04:34<02:41,  1.07s/it]Running loglikelihood requests:  62%|██████▎   | 250/400 [04:35<02:41,  1.07s/it]Running loglikelihood requests:  63%|██████▎   | 251/400 [04:36<02:40,  1.08s/it]Running loglikelihood requests:  63%|██████▎   | 252/400 [04:37<02:40,  1.08s/it]Running loglikelihood requests:  63%|██████▎   | 253/400 [04:38<02:39,  1.08s/it]Running loglikelihood requests:  64%|██████▍   | 255/400 [04:39<02:01,  1.20it/s]Running loglikelihood requests:  64%|██████▍   | 256/400 [04:40<02:09,  1.11it/s]Running loglikelihood requests:  64%|██████▍   | 257/400 [04:41<02:15,  1.06it/s]Running loglikelihood requests:  64%|██████▍   | 258/400 [04:43<02:19,  1.02it/s]Running loglikelihood requests:  65%|██████▍   | 259/400 [04:44<02:22,  1.01s/it]Running loglikelihood requests:  65%|██████▌   | 260/400 [04:45<02:24,  1.03s/it]Running loglikelihood requests:  65%|██████▌   | 261/400 [04:46<02:25,  1.05s/it]Running loglikelihood requests:  66%|██████▌   | 262/400 [04:47<02:25,  1.06s/it]Running loglikelihood requests:  66%|██████▌   | 263/400 [04:48<02:25,  1.07s/it]Running loglikelihood requests:  66%|██████▌   | 264/400 [04:49<02:25,  1.07s/it]Running loglikelihood requests:  66%|██████▋   | 265/400 [04:50<02:25,  1.07s/it]Running loglikelihood requests:  66%|██████▋   | 266/400 [04:51<02:24,  1.08s/it]Running loglikelihood requests:  67%|██████▋   | 267/400 [04:52<02:23,  1.08s/it]Running loglikelihood requests:  67%|██████▋   | 268/400 [04:53<02:22,  1.08s/it]Running loglikelihood requests:  68%|██████▊   | 270/400 [04:54<01:47,  1.20it/s]Running loglikelihood requests:  68%|██████▊   | 271/400 [04:55<01:55,  1.12it/s]Running loglikelihood requests:  68%|██████▊   | 272/400 [04:57<02:00,  1.06it/s]Running loglikelihood requests:  68%|██████▊   | 273/400 [04:58<02:04,  1.02it/s]Running loglikelihood requests:  68%|██████▊   | 274/400 [04:59<02:06,  1.01s/it]Running loglikelihood requests:  69%|██████▉   | 275/400 [05:00<02:08,  1.03s/it]Running loglikelihood requests:  69%|██████▉   | 276/400 [05:01<02:08,  1.04s/it]Running loglikelihood requests:  69%|██████▉   | 277/400 [05:02<02:09,  1.05s/it]Running loglikelihood requests:  70%|██████▉   | 278/400 [05:03<02:08,  1.05s/it]Running loglikelihood requests:  70%|██████▉   | 279/400 [05:04<02:08,  1.06s/it]Running loglikelihood requests:  70%|███████   | 280/400 [05:05<02:07,  1.06s/it]Running loglikelihood requests:  70%|███████   | 281/400 [05:06<02:06,  1.07s/it]Running loglikelihood requests:  70%|███████   | 282/400 [05:07<02:05,  1.07s/it]Running loglikelihood requests:  71%|███████   | 283/400 [05:08<02:04,  1.07s/it]Running loglikelihood requests:  71%|███████   | 284/400 [05:09<02:03,  1.07s/it]Running loglikelihood requests:  71%|███████▏  | 285/400 [05:11<02:02,  1.07s/it]Running loglikelihood requests:  72%|███████▏  | 286/400 [05:12<02:01,  1.07s/it]Running loglikelihood requests:  72%|███████▏  | 287/400 [05:13<02:00,  1.07s/it]Running loglikelihood requests:  72%|███████▏  | 288/400 [05:14<01:59,  1.07s/it]Running loglikelihood requests:  72%|███████▏  | 289/400 [05:15<01:58,  1.07s/it]Running loglikelihood requests:  72%|███████▎  | 290/400 [05:16<01:57,  1.07s/it]Running loglikelihood requests:  73%|███████▎  | 291/400 [05:17<01:56,  1.07s/it]Running loglikelihood requests:  73%|███████▎  | 292/400 [05:18<01:55,  1.06s/it]Running loglikelihood requests:  73%|███████▎  | 293/400 [05:19<01:53,  1.06s/it]Running loglikelihood requests:  74%|███████▎  | 294/400 [05:20<01:52,  1.07s/it]Running loglikelihood requests:  74%|███████▍  | 295/400 [05:21<01:51,  1.07s/it]Running loglikelihood requests:  74%|███████▍  | 296/400 [05:22<01:50,  1.06s/it]Running loglikelihood requests:  74%|███████▍  | 297/400 [05:23<01:49,  1.06s/it]Running loglikelihood requests:  74%|███████▍  | 298/400 [05:24<01:48,  1.06s/it]Running loglikelihood requests:  75%|███████▍  | 299/400 [05:25<01:47,  1.06s/it]Running loglikelihood requests:  75%|███████▌  | 300/400 [05:26<01:45,  1.06s/it]Running loglikelihood requests:  75%|███████▌  | 301/400 [05:28<01:44,  1.06s/it]Running loglikelihood requests:  76%|███████▌  | 302/400 [05:29<01:43,  1.06s/it]Running loglikelihood requests:  76%|███████▌  | 304/400 [05:30<01:18,  1.23it/s]Running loglikelihood requests:  76%|███████▋  | 305/400 [05:31<01:22,  1.15it/s]Running loglikelihood requests:  76%|███████▋  | 306/400 [05:32<01:26,  1.09it/s]Running loglikelihood requests:  77%|███████▋  | 307/400 [05:33<01:29,  1.04it/s]Running loglikelihood requests:  77%|███████▋  | 308/400 [05:34<01:30,  1.02it/s]Running loglikelihood requests:  77%|███████▋  | 309/400 [05:35<01:31,  1.00s/it]Running loglikelihood requests:  78%|███████▊  | 310/400 [05:36<01:31,  1.02s/it]Running loglikelihood requests:  78%|███████▊  | 311/400 [05:37<01:31,  1.03s/it]Running loglikelihood requests:  78%|███████▊  | 312/400 [05:38<01:31,  1.03s/it]Running loglikelihood requests:  78%|███████▊  | 313/400 [05:39<01:30,  1.04s/it]Running loglikelihood requests:  78%|███████▊  | 314/400 [05:40<01:29,  1.04s/it]Running loglikelihood requests:  79%|███████▉  | 315/400 [05:41<01:28,  1.04s/it]Running loglikelihood requests:  79%|███████▉  | 316/400 [05:42<01:27,  1.05s/it]Running loglikelihood requests:  79%|███████▉  | 317/400 [05:43<01:26,  1.05s/it]Running loglikelihood requests:  80%|███████▉  | 318/400 [05:44<01:25,  1.05s/it]Running loglikelihood requests:  80%|███████▉  | 319/400 [05:45<01:24,  1.04s/it]Running loglikelihood requests:  80%|████████  | 320/400 [05:46<01:23,  1.04s/it]Running loglikelihood requests:  80%|████████  | 321/400 [05:47<01:22,  1.04s/it]Running loglikelihood requests:  80%|████████  | 322/400 [05:49<01:21,  1.04s/it]Running loglikelihood requests:  81%|████████  | 323/400 [05:50<01:20,  1.04s/it]Running loglikelihood requests:  81%|████████  | 324/400 [05:51<01:19,  1.04s/it]Running loglikelihood requests:  81%|████████▏ | 325/400 [05:52<01:18,  1.04s/it]Running loglikelihood requests:  82%|████████▏ | 326/400 [05:53<01:17,  1.04s/it]Running loglikelihood requests:  82%|████████▏ | 327/400 [05:54<01:16,  1.04s/it]Running loglikelihood requests:  82%|████████▏ | 328/400 [05:55<01:15,  1.04s/it]Running loglikelihood requests:  82%|████████▎ | 330/400 [05:56<00:56,  1.25it/s]Running loglikelihood requests:  83%|████████▎ | 331/400 [05:57<00:59,  1.16it/s]Running loglikelihood requests:  83%|████████▎ | 332/400 [05:58<01:01,  1.10it/s]Running loglikelihood requests:  83%|████████▎ | 333/400 [05:59<01:03,  1.06it/s]Running loglikelihood requests:  84%|████████▎ | 334/400 [06:00<01:03,  1.03it/s]Running loglikelihood requests:  84%|████████▍ | 335/400 [06:01<01:04,  1.01it/s]Running loglikelihood requests:  84%|████████▍ | 336/400 [06:02<01:04,  1.00s/it]Running loglikelihood requests:  84%|████████▍ | 337/400 [06:03<01:03,  1.01s/it]Running loglikelihood requests:  84%|████████▍ | 338/400 [06:04<01:03,  1.02s/it]Running loglikelihood requests:  85%|████████▍ | 339/400 [06:05<01:02,  1.02s/it]Running loglikelihood requests:  85%|████████▌ | 340/400 [06:06<01:01,  1.03s/it]Running loglikelihood requests:  85%|████████▌ | 341/400 [06:07<01:00,  1.03s/it]Running loglikelihood requests:  86%|████████▌ | 342/400 [06:08<00:59,  1.03s/it]Running loglikelihood requests:  86%|████████▌ | 343/400 [06:09<00:58,  1.03s/it]Running loglikelihood requests:  86%|████████▌ | 344/400 [06:10<00:57,  1.03s/it]Running loglikelihood requests:  86%|████████▋ | 345/400 [06:11<00:56,  1.03s/it]Running loglikelihood requests:  86%|████████▋ | 346/400 [06:12<00:55,  1.03s/it]Running loglikelihood requests:  87%|████████▋ | 347/400 [06:13<00:54,  1.03s/it]Running loglikelihood requests:  87%|████████▋ | 348/400 [06:14<00:53,  1.03s/it]Running loglikelihood requests:  87%|████████▋ | 349/400 [06:15<00:52,  1.03s/it]Running loglikelihood requests:  88%|████████▊ | 350/400 [06:16<00:51,  1.02s/it]Running loglikelihood requests:  88%|████████▊ | 351/400 [06:17<00:50,  1.02s/it]Running loglikelihood requests:  88%|████████▊ | 352/400 [06:18<00:49,  1.02s/it]Running loglikelihood requests:  88%|████████▊ | 353/400 [06:19<00:47,  1.02s/it]Running loglikelihood requests:  88%|████████▊ | 354/400 [06:20<00:46,  1.02s/it]Running loglikelihood requests:  89%|████████▉ | 355/400 [06:22<00:45,  1.02s/it]Running loglikelihood requests:  89%|████████▉ | 356/400 [06:23<00:44,  1.02s/it]Running loglikelihood requests:  89%|████████▉ | 357/400 [06:24<00:43,  1.01s/it]Running loglikelihood requests:  90%|████████▉ | 358/400 [06:25<00:42,  1.01s/it]Running loglikelihood requests:  90%|████████▉ | 359/400 [06:26<00:41,  1.01s/it]Running loglikelihood requests:  90%|█████████ | 360/400 [06:27<00:40,  1.01s/it]Running loglikelihood requests:  90%|█████████ | 361/400 [06:28<00:39,  1.01s/it]Running loglikelihood requests:  90%|█████████ | 362/400 [06:29<00:38,  1.00s/it]Running loglikelihood requests:  91%|█████████ | 363/400 [06:30<00:37,  1.00s/it]Running loglikelihood requests:  91%|█████████ | 364/400 [06:31<00:35,  1.00it/s]Running loglikelihood requests:  91%|█████████▏| 365/400 [06:32<00:34,  1.00it/s]Running loglikelihood requests:  92%|█████████▏| 366/400 [06:33<00:33,  1.00it/s]Running loglikelihood requests:  92%|█████████▏| 367/400 [06:34<00:32,  1.00it/s]Running loglikelihood requests:  92%|█████████▏| 368/400 [06:35<00:31,  1.00it/s]Running loglikelihood requests:  92%|█████████▏| 369/400 [06:36<00:30,  1.01it/s]Running loglikelihood requests:  92%|█████████▎| 370/400 [06:37<00:29,  1.01it/s]Running loglikelihood requests:  93%|█████████▎| 371/400 [06:38<00:28,  1.01it/s]Running loglikelihood requests:  93%|█████████▎| 372/400 [06:38<00:27,  1.01it/s]Running loglikelihood requests:  93%|█████████▎| 373/400 [06:39<00:26,  1.01it/s]Running loglikelihood requests:  94%|█████████▎| 374/400 [06:40<00:25,  1.01it/s]Running loglikelihood requests:  94%|█████████▍| 375/400 [06:41<00:24,  1.01it/s]Running loglikelihood requests:  94%|█████████▍| 376/400 [06:42<00:23,  1.01it/s]Running loglikelihood requests:  94%|█████████▍| 377/400 [06:43<00:22,  1.02it/s]Running loglikelihood requests:  94%|█████████▍| 378/400 [06:44<00:21,  1.02it/s]Running loglikelihood requests:  95%|█████████▍| 379/400 [06:45<00:20,  1.02it/s]Running loglikelihood requests:  95%|█████████▌| 380/400 [06:46<00:19,  1.02it/s]Running loglikelihood requests:  95%|█████████▌| 381/400 [06:47<00:18,  1.02it/s]Running loglikelihood requests:  96%|█████████▌| 382/400 [06:48<00:17,  1.02it/s]Running loglikelihood requests:  96%|█████████▌| 383/400 [06:49<00:16,  1.03it/s]Running loglikelihood requests:  96%|█████████▌| 384/400 [06:50<00:15,  1.03it/s]Running loglikelihood requests:  96%|█████████▋| 385/400 [06:51<00:14,  1.03it/s]Running loglikelihood requests:  96%|█████████▋| 386/400 [06:52<00:13,  1.03it/s]Running loglikelihood requests:  97%|█████████▋| 387/400 [06:53<00:12,  1.03it/s]Running loglikelihood requests:  97%|█████████▋| 388/400 [06:54<00:11,  1.03it/s]Running loglikelihood requests:  97%|█████████▋| 389/400 [06:55<00:10,  1.03it/s]Running loglikelihood requests:  98%|█████████▊| 390/400 [06:56<00:09,  1.03it/s]Running loglikelihood requests:  98%|█████████▊| 391/400 [06:57<00:08,  1.03it/s]Running loglikelihood requests:  98%|█████████▊| 392/400 [06:58<00:07,  1.03it/s]Running loglikelihood requests:  98%|█████████▊| 393/400 [06:59<00:06,  1.03it/s]Running loglikelihood requests:  98%|█████████▊| 394/400 [07:00<00:05,  1.03it/s]Running loglikelihood requests:  99%|█████████▉| 395/400 [07:01<00:04,  1.03it/s]Running loglikelihood requests:  99%|█████████▉| 396/400 [07:02<00:03,  1.04it/s]Running loglikelihood requests:  99%|█████████▉| 397/400 [07:03<00:02,  1.04it/s]Running loglikelihood requests: 100%|█████████▉| 398/400 [07:04<00:01,  1.05it/s]Running loglikelihood requests: 100%|█████████▉| 399/400 [07:05<00:00,  1.05it/s]Running loglikelihood requests: 100%|██████████| 400/400 [07:06<00:00,  1.06it/s]Running loglikelihood requests: 100%|██████████| 400/400 [07:06<00:00,  1.07s/it]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:6'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:6'}
full model:
{'mastermind_35_easy': {'alias': 'mastermind_35_easy', 'acc,none': 0.51, 'acc_stderr,none': 0.05024183937956913}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9685093904417202
0.9837389482734848
0.9887891422859466
0.9728424941793791
0.9273096247071001
0.9956884174036557
0.9936991917224709
0.990637728847171
0.984416562505352
0.9357041463019401
0.957486187236088
0.9794440444506461
0.9854000882321717
0.989321120949945
0.9948124947717892
0.9950699411775289
0.9589145403056732
0.9488498047330014
0.979093344902028
0.9861615563222426
0.9944647439314634
0.9974738465425171
0.9932459641322177
0.9612113452387381
0.9566187588663586
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[5, 1, 0, 3, 7, 6, 2, 4]
tensor([5, 1, 0, 3, 7, 6, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 0, 3, 7, 5, 2, 4]
tensor([6, 1, 0, 3, 7, 5, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 1, 0, 3, 7, 6, 2, 4]
tensor([5, 1, 0, 3, 7, 6, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 0, 3, 7, 5, 2, 4]
tensor([6, 1, 0, 3, 7, 5, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 1, 0, 3, 7, 6, 2, 4]
tensor([5, 1, 0, 3, 7, 6, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 0, 3, 7, 5, 2, 4]
tensor([6, 1, 0, 3, 7, 5, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Normal merging for layer 2
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Normal merging for layer 3
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Normal merging for layer 4
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Normal merging for layer 5
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 6 to 31
done!
all done!
Model size: 12.0718 GB
205
cuda:6
wnli
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:43<00:43, 43.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:55<00:00, 25.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:55<00:00, 27.89s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139722751227760 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139722751227760 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139722751227760 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139722751227760 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139748506614912 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139748506614912 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139748506614912 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139748506614912 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2511.56it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:01<03:19,  1.42s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:02<01:32,  1.50it/s]Running loglikelihood requests:   4%|▎         | 5/142 [00:03<01:13,  1.88it/s]Running loglikelihood requests:   5%|▍         | 7/142 [00:03<01:04,  2.09it/s]Running loglikelihood requests:   6%|▋         | 9/142 [00:04<00:59,  2.23it/s]Running loglikelihood requests:   8%|▊         | 11/142 [00:05<00:55,  2.36it/s]Running loglikelihood requests:   9%|▉         | 13/142 [00:06<00:52,  2.43it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:06<00:50,  2.53it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:07<00:48,  2.60it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:08<00:45,  2.72it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:08<00:43,  2.81it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:09<00:41,  2.90it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:10<00:39,  2.96it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:10<00:37,  3.03it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:11<00:36,  3.07it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:12<00:35,  3.11it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:12<00:34,  3.14it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:13<00:33,  3.17it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:13<00:32,  3.18it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:14<00:32,  3.20it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:15<00:31,  3.22it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:15<00:30,  3.23it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:16<00:29,  3.27it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:16<00:28,  3.30it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:17<00:27,  3.34it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:18<00:26,  3.39it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:18<00:26,  3.42it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:19<00:25,  3.46it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:19<00:24,  3.48it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:20<00:23,  3.50it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:20<00:23,  3.51it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:21<00:22,  3.52it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:22<00:21,  3.53it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:22<00:21,  3.54it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:23<00:20,  3.56it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:23<00:20,  3.52it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:24<00:19,  3.58it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [00:24<00:18,  3.62it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [00:25<00:17,  3.65it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [00:25<00:17,  3.68it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [00:26<00:16,  3.70it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [00:27<00:15,  3.72it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [00:27<00:15,  3.72it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [00:28<00:14,  3.74it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [00:28<00:14,  3.76it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [00:29<00:13,  3.77it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [00:29<00:12,  3.78it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [00:30<00:12,  3.80it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [00:30<00:11,  3.80it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [00:31<00:11,  3.82it/s]Running loglikelihood requests:  71%|███████   | 101/142 [00:31<00:10,  3.83it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [00:32<00:10,  3.85it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [00:32<00:09,  3.85it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [00:33<00:09,  3.87it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [00:33<00:08,  3.88it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [00:34<00:07,  3.89it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [00:34<00:07,  3.91it/s]Running loglikelihood requests:  81%|████████  | 115/142 [00:35<00:06,  3.91it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [00:35<00:06,  3.92it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [00:36<00:05,  3.93it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [00:36<00:05,  3.94it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [00:37<00:04,  3.96it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [00:37<00:04,  3.97it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [00:38<00:03,  3.98it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [00:38<00:03,  4.00it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [00:39<00:02,  4.02it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [00:39<00:02,  4.04it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [00:40<00:01,  4.07it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [00:40<00:01,  4.10it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [00:41<00:00,  4.12it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [00:41<00:00,  4.17it/s]Running loglikelihood requests: 100%|██████████| 142/142 [00:41<00:00,  3.40it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:7'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:7'}
full model:
{'wnli': {'alias': 'wnli', 'acc,none': 0.5352112676056338, 'acc_stderr,none': 0.0596130578497224}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.31190044950254875
0.7306280553786256
0.6985925052465822
0.5843516732063875
0.8124235844589114
0.820438203921003
0.6253838264581936
0.7600037006947045
0.8225872978677496
0.708398461303215
0.8646089269479391
0.8239362351853257
0.7608099850331435
0.6657423857513638
0.7943257460202938
0.7511476003698512
0.9073696655228775
0.8741838353767599
0.7945799099309127
0.9323691001541556
0.865243808509542
0.8176606226311932
0.6785099625983169
0.9579534328203848
0.788928884938056
0.9833718962298513
0.5933012307657521
0.7829988799240639
0.7823073743206628
0.31190044950254875
0.7306280553786256
0.6985925052465822
0.5843516732063875
0.8124235844589114
0.820438203921003
0.6253838264581936
0.7600037006947045
0.8225872978677496
0.708398461303215
0.8646089269479391
0.8239362351853257
0.7608099850331435
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[7, 4, 5, 1, 6, 3, 2, 0]
tensor([7, 4, 5, 1, 6, 3, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 2, 4, 5, 6, 1, 0, 3]
tensor([7, 2, 4, 5, 6, 1, 0, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 7, 5, 4, 1, 2, 0]
tensor([6, 3, 7, 5, 4, 1, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 3, 6, 4, 7, 1, 2, 0]
tensor([5, 3, 6, 4, 7, 1, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 3, 6, 5, 7, 2, 1, 0]
tensor([4, 3, 6, 5, 7, 2, 1, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1, 2, 3, 2, 3, 0]
tensor([0, 1, 1, 2, 3, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 1, 2, 2, 3, 0, 3, 1]
tensor([0, 1, 2, 2, 3, 0, 3, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 1, 1, 1.0, 1.0, 1.0, 1.0]
tensor([0, 0, 1, 1, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
Normal merging for layer 1
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
done!
Normal merging for layer 2
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
tensor([3])
tensor(3)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Normal merging for layer 4
tensor([7])
tensor(7)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 5 to 15
done!
Normal merging for layer 16
tensor([0, 7])
tensor(0)
tensor([1, 2])
tensor(1)
tensor([3, 5])
tensor(3)
tensor([4, 6])
tensor(4)
done!
Normal merging for layer 17
tensor([0, 5])
tensor(0)
tensor([1, 7])
tensor(1)
tensor([2, 3])
tensor(2)
tensor([4, 6])
tensor(4)
done!
Cross-layer merge completed for layers 18 to 30
done!
Normal merging for layer 31
tensor([0, 1])
tensor(0)
tensor([2, 3, 4, 5, 6, 7])
tensor(2)
done!
all done!
Model size: 12.2608 GB
243
cuda:7
wikitext
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:43<00:43, 43.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:56<00:00, 25.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:56<00:00, 28.09s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
WARNING:lm_eval.api.task:[Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
WARNING:lm_eval.api.task:[Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
WARNING:lm_eval.api.task:[Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
WARNING:lm_eval.api.task:[Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
WARNING:lm_eval.api.task:[Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/wikitext_document_level HTTP/1.1" 200 1012
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/EleutherAI/wikitext_document_level/EleutherAI/wikitext_document_level.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/wikitext_document_level HTTP/1.1" 200 1012
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/wikitext_document_level/resolve/647234772b9554e208af6c826f23b99e3cac88c8/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/EleutherAI/wikitext_document_level/paths-info/647234772b9554e208af6c826f23b99e3cac88c8 HTTP/1.1" 200 299
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/EleutherAI/wikitext_document_level/paths-info/647234772b9554e208af6c826f23b99e3cac88c8 HTTP/1.1" 200 299
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/EleutherAI/wikitext_document_level/paths-info/647234772b9554e208af6c826f23b99e3cac88c8 HTTP/1.1" 200 299
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/EleutherAI/wikitext_document_level/paths-info/647234772b9554e208af6c826f23b99e3cac88c8 HTTP/1.1" 200 299
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/EleutherAI/wikitext_document_level/paths-info/647234772b9554e208af6c826f23b99e3cac88c8 HTTP/1.1" 200 299
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/EleutherAI/wikitext_document_level/paths-info/647234772b9554e208af6c826f23b99e3cac88c8 HTTP/1.1" 200 299
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/wikitext_document_level/resolve/647234772b9554e208af6c826f23b99e3cac88c8/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/EleutherAI/wikitext_document_level/paths-info/647234772b9554e208af6c826f23b99e3cac88c8 HTTP/1.1" 200 293
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/EleutherAI/wikitext_document_level/paths-info/647234772b9554e208af6c826f23b99e3cac88c8 HTTP/1.1" 200 293
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/EleutherAI/wikitext_document_level/paths-info/647234772b9554e208af6c826f23b99e3cac88c8 HTTP/1.1" 200 293
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/EleutherAI/wikitext_document_level/paths-info/647234772b9554e208af6c826f23b99e3cac88c8 HTTP/1.1" 200 293
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/EleutherAI/wikitext_document_level/paths-info/647234772b9554e208af6c826f23b99e3cac88c8 HTTP/1.1" 200 293
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/EleutherAI/wikitext_document_level/paths-info/647234772b9554e208af6c826f23b99e3cac88c8 HTTP/1.1" 200 293
DEBUG:filelock:Attempting to acquire lock 139722756033328 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___wikitext_document_level_wikitext-2-raw-v1_0.0.0_647234772b9554e208af6c826f23b99e3cac88c8.lock
DEBUG:filelock:Lock 139722756033328 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___wikitext_document_level_wikitext-2-raw-v1_0.0.0_647234772b9554e208af6c826f23b99e3cac88c8.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___wikitext_document_level/wikitext-2-raw-v1/0.0.0/647234772b9554e208af6c826f23b99e3cac88c8/dataset_info.json
DEBUG:filelock:Attempting to release lock 139722756033328 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___wikitext_document_level_wikitext-2-raw-v1_0.0.0_647234772b9554e208af6c826f23b99e3cac88c8.lock
DEBUG:filelock:Lock 139722756033328 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___wikitext_document_level_wikitext-2-raw-v1_0.0.0_647234772b9554e208af6c826f23b99e3cac88c8.lock
DEBUG:filelock:Attempting to acquire lock 139722706369808 on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___wikitext_document_level/wikitext-2-raw-v1/0.0.0/647234772b9554e208af6c826f23b99e3cac88c8_builder.lock
DEBUG:filelock:Lock 139722706369808 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___wikitext_document_level/wikitext-2-raw-v1/0.0.0/647234772b9554e208af6c826f23b99e3cac88c8_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___wikitext_document_level/wikitext-2-raw-v1/0.0.0/647234772b9554e208af6c826f23b99e3cac88c8/dataset_info.json
DEBUG:filelock:Attempting to release lock 139722706369808 on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___wikitext_document_level/wikitext-2-raw-v1/0.0.0/647234772b9554e208af6c826f23b99e3cac88c8_builder.lock
DEBUG:filelock:Lock 139722706369808 released on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___wikitext_document_level/wikitext-2-raw-v1/0.0.0/647234772b9554e208af6c826f23b99e3cac88c8_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wikitext from None to 0
INFO:lm_eval.api.task:Building contexts for wikitext on rank 0...
  0%|          | 0/62 [00:00<?, ?it/s]100%|██████████| 62/62 [00:00<00:00, 731.57it/s]
DEBUG:lm_eval.evaluator:Task: wikitext; number of requests on this rank: 62
INFO:lm_eval.evaluator:Running loglikelihood_rolling requests
  0%|          | 0/62 [00:00<?, ?it/s] 15%|█▍        | 9/62 [00:00<00:00, 77.48it/s] 39%|███▊      | 24/62 [00:00<00:00, 108.78it/s] 58%|█████▊    | 36/62 [00:00<00:00, 109.94it/s] 77%|███████▋  | 48/62 [00:00<00:00, 101.73it/s]100%|██████████| 62/62 [00:00<00:00, 114.01it/s]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:07<00:00,  7.32s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:07<00:00,  7.32s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.46s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.46s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.41s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.41s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:13<00:00, 13.70s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:13<00:00, 13.70s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.42s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.42s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.43s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.43s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.39s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.39s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:11<00:00, 11.48s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:11<00:00, 11.48s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:13<00:00, 13.82s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:13<00:00, 13.82s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.37s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.37s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.37s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.37s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.36s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.36s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.38s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.38s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:13<00:00, 13.49s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:13<00:00, 13.49s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.61s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.61s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.61s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.61s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.63s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.63s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.63s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.63s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:09<00:00,  9.27s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:09<00:00,  9.27s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:16<00:00, 16.37s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:16<00:00, 16.37s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.89s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.89s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.60s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.60s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.43s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.43s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:05<00:00,  5.59s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:05<00:00,  5.59s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:12<00:00, 12.34s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:12<00:00, 12.34s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:03<00:00,  3.11s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:03<00:00,  3.11s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:10<00:00, 10.69s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:10<00:00, 10.69s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.09s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.09s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.67s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.67s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.61s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.62s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:06<00:00,  6.09s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:06<00:00,  6.09s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.61s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.61s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.54s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.54s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.94s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.94s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.75s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.75s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.96s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.96s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.99s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.99s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:07<00:00,  7.13s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:07<00:00,  7.13s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.59s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.59s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.39s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.39s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.25s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.25s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.25s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.25s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:19<00:00, 19.93s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:19<00:00, 19.93s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.51s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.51s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:13<00:00, 13.43s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:13<00:00, 13.43s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.37s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.37s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.93s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.93s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.61s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.61s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.63s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.63s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.75s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.75s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.49s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.49s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.28s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.28s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:06<00:00,  6.38s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:06<00:00,  6.38s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  2.03it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:00<00:00,  2.03it/s]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:01<00:00,  1.58s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:01<00:00,  1.58s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.30s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.30s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.30s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.30s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:08<00:00,  8.57s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:08<00:00,  8.57s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.30s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.30s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.35s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.35s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:09<00:00,  9.28s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:09<00:00,  9.28s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.32s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.32s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.31s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.31s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.30s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.30s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.82s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.82s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.51s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.51s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.92s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.92s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:09<00:00,  9.03s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:09<00:00,  9.03s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.91s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.91s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.39s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:18<00:00, 18.39s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.78s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.78s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.51s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.51s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.49s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.49s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.49s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.49s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.42s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.42s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.36s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.36s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.38s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.38s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.37s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.37s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.39s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.39s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.36s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.36s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.38s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.38s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.36s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.36s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.37s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.37s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:13<00:00, 13.42s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:13<00:00, 13.42s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:06<00:00,  6.12s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:06<00:00,  6.12s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.37s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.37s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.40s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.40s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:12<00:00, 12.07s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:12<00:00, 12.07s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:06<00:00,  6.23s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:06<00:00,  6.23s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:07<00:00,  7.00s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:07<00:00,  7.00s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.38s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.38s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.37s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.37s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.37s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.37s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:07<00:00,  7.63s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:07<00:00,  7.63s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:08<00:00,  8.25s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:08<00:00,  8.25s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:15<00:00, 15.78s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:15<00:00, 15.78s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:15<00:00, 15.45s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:15<00:00, 15.45s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:06<00:00,  6.18s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:06<00:00,  6.18s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:06<00:00,  6.09s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:06<00:00,  6.09s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:05<00:00,  5.55s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:05<00:00,  5.55s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:05<00:00,  5.39s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:05<00:00,  5.39s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.38s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.38s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.37s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.37s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.38s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.38s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:03<00:00,  3.13s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:03<00:00,  3.13s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.42s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.42s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.36s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.36s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.37s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.37s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.38s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.38s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.37s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.37s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.38s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.38s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.39s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.39s/it]
Running loglikelihood requests:   0%|          | 0/1 [00:00<?, ?it/s]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.38s/it]Running loglikelihood requests: 100%|██████████| 1/1 [00:17<00:00, 17.38s/it]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:0'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}
full model:
{'wikitext': {'alias': 'wikitext', 'word_perplexity,none': 10.41810626477151, 'word_perplexity_stderr,none': 'N/A', 'byte_perplexity,none': 1.5499996141598633, 'byte_perplexity_stderr,none': 'N/A', 'bits_per_byte,none': 0.6322678563706606, 'bits_per_byte_stderr,none': 'N/A'}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.45530714642366393
0.6593661321025917
0.45166835110772663
0.3470526807104175
0.3369212652555373
0.5686768652815603
0.5380667106744194
0.1994061645434335
0.7857081855506413
0.7236392518096334
0.6975091963753621
0.7192457446547811
0.6820752222558486
0.2553530000000423
0.9092011229700152
0.8474392887638426
0.29700403366343364
0.3112335629956447
0.316268174131358
0.5041948206367306
0.3067038688170426
0.21198641237235732
0.23379101174921613
0.4411951857077822
0.3636022184812837
0.22411151956337602
0.0659668585894146
0.5103891010860186
0.5291148039479469
0.45530714642366393
0.6593661321025917
0.45166835110772663
0.3470526807104175
0.3369212652555373
0.5686768652815603
0.5380667106744194
0.1994061645434335
0.7857081855506413
0.7236392518096334
0.6975091963753621
0.7192457446547811
0.6820752222558486
0.2553530000000423
0.9092011229700152
0.8474392887638426
0.29700403366343364
0.3112335629956447
0.316268174131358
0.5041948206367306
0.3067038688170426
0.21198641237235732
0.23379101174921613
0.4411951857077822
0.3636022184812837
0.22411151956337602
0.0659668585894146
0.5103891010860186
0.5291148039479469
0.45530714642366393
0.6593661321025917
0.45166835110772663
0.3470526807104175
0.3369212652555373
0.5686768652815603
0.5380667106744194
0.1994061645434335
0.7857081855506413
0.7236392518096334
0.6975091963753621
0.7192457446547811
0.6820752222558486
0.2553530000000423
0.9092011229700152
0.8474392887638426
0.29700403366343364
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[6, 3, 7, 0, 5, 1, 4, 2]
tensor([6, 3, 7, 0, 5, 1, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 5, 0, 4, 3, 6, 7, 1]
tensor([2, 5, 0, 4, 3, 6, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[6, 7, 5, 2, 0, 3, 1, 4]
tensor([6, 7, 5, 2, 0, 3, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 1, 0, 7, 2, 3, 5, 6]
tensor([4, 1, 0, 7, 2, 3, 5, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 3, 2, 4, 0, 1, 1, 0]
tensor([5, 3, 2, 4, 0, 1, 1, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[3, 2, 0, 1, 5, 0, 4, 1]
tensor([3, 2, 0, 1, 5, 0, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[1, 0, 1, 5, 2, 0, 4, 3]
tensor([1, 0, 1, 5, 2, 0, 4, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([2])
tensor(2)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 2 to 4
done!
Normal merging for layer 5
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([1])
tensor(1)
done!
Normal merging for layer 6
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
done!
Cross-layer merge completed for layers 7 to 8
done!
Normal merging for layer 9
tensor([4, 7])
tensor(4)
tensor([5, 6])
tensor(5)
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([0])
tensor(0)
done!
Normal merging for layer 10
tensor([2, 5])
tensor(2)
tensor([3, 7])
tensor(3)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 11 to 12
done!
Normal merging for layer 13
tensor([1, 5])
tensor(1)
tensor([0, 2])
tensor(0)
tensor([4])
tensor(4)
tensor([7])
tensor(7)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
done!
Cross-layer merge completed for layers 14 to 31
done!
all done!
Model size: 12.3867 GB
171
cuda:0
rte
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:46<00:46, 46.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:00<00:00, 27.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:00<00:00, 30.28s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: rte] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: rte] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:filelock:Attempting to acquire lock 139722755388624 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139722755388624 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139722755388624 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139722755388624 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139721436547072 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139721436547072 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139721436547072 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139721436547072 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of rte from None to 0
INFO:lm_eval.api.task:Building contexts for rte on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 2571.47it/s]
DEBUG:lm_eval.evaluator:Task: rte; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:01<06:28,  1.95s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:03<03:25,  1.04s/it]Running loglikelihood requests:   2%|▎         | 5/200 [00:04<02:46,  1.17it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:05<02:25,  1.32it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:07<02:14,  1.42it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:08<02:07,  1.49it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:09<02:02,  1.53it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:10<01:57,  1.57it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:12<01:54,  1.60it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:13<01:51,  1.63it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:14<01:47,  1.67it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:15<01:44,  1.69it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:16<01:41,  1.72it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:17<01:38,  1.75it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:18<01:35,  1.79it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:19<01:33,  1.81it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:20<01:31,  1.83it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:22<01:29,  1.85it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:23<01:27,  1.86it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:24<01:25,  1.89it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:25<01:22,  1.92it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:26<01:20,  1.95it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:27<01:17,  1.99it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:27<01:15,  2.03it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:28<01:12,  2.07it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:29<01:10,  2.13it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:30<01:07,  2.18it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:31<01:04,  2.23it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:32<01:02,  2.29it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:33<01:00,  2.33it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:33<00:58,  2.37it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:34<00:57,  2.40it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:35<00:55,  2.43it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:36<00:54,  2.45it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:37<00:52,  2.48it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:37<00:51,  2.50it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:38<00:50,  2.52it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:39<00:49,  2.54it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:40<00:47,  2.57it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:40<00:46,  2.60it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:41<00:45,  2.62it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:42<00:44,  2.64it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:43<00:43,  2.66it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:43<00:42,  2.67it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:44<00:41,  2.70it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:45<00:40,  2.72it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:46<00:39,  2.74it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:46<00:38,  2.75it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:47<00:37,  2.77it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:48<00:36,  2.78it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:48<00:35,  2.79it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:49<00:34,  2.81it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:50<00:33,  2.82it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:51<00:32,  2.84it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:51<00:31,  2.85it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:52<00:31,  2.87it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:53<00:30,  2.88it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:53<00:29,  2.88it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:54<00:28,  2.89it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:55<00:27,  2.90it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:55<00:27,  2.91it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:56<00:26,  2.92it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:57<00:25,  2.93it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [00:57<00:24,  2.93it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [00:58<00:24,  2.93it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [00:59<00:23,  2.94it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [00:59<00:22,  2.96it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [01:00<00:21,  2.99it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [01:01<00:20,  3.01it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [01:01<00:20,  3.02it/s]Running loglikelihood requests:  70%|███████   | 141/200 [01:02<00:19,  3.04it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [01:03<00:18,  3.05it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [01:03<00:17,  3.07it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [01:04<00:17,  3.07it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [01:05<00:16,  3.09it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [01:05<00:15,  3.10it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [01:06<00:15,  3.11it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [01:07<00:14,  3.12it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [01:07<00:13,  3.13it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [01:08<00:12,  3.16it/s]Running loglikelihood requests:  80%|████████  | 161/200 [01:08<00:12,  3.18it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [01:09<00:11,  3.19it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [01:10<00:10,  3.20it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [01:10<00:10,  3.22it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [01:11<00:09,  3.24it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [01:11<00:08,  3.27it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [01:12<00:08,  3.28it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [01:13<00:07,  3.30it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [01:13<00:06,  3.31it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [01:14<00:06,  3.32it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [01:14<00:05,  3.33it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [01:15<00:05,  3.35it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [01:16<00:04,  3.35it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [01:16<00:03,  3.37it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [01:17<00:03,  3.38it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [01:17<00:02,  3.40it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [01:18<00:02,  3.42it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:19<00:01,  3.44it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:19<00:00,  3.52it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:20<00:00,  3.58it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:20<00:00,  2.50it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:1'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:1'}
full model:
{'rte': {'alias': 'rte', 'acc,none': 0.5, 'acc_stderr,none': 0.050251890762960605}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.34161229456626735
0.905233410256777
0.5205040718697735
0.4121994254524892
0.7398116665887099
0.6225415196831932
0.7923970242263771
0.7353888240887675
0.6535613357308766
0.7757058271862038
0.734046359122903
0.4471799126982846
0.773619360921301
0.7955347039939479
0.8672068064531693
0.8652880343596522
0.3302235467760883
0.6789268064017625
0.6072221471952108
0.9194446824778495
0.4812004589187253
0.5728915095234594
0.1682455054057436
0.93212414632396
0.9148362604533635
0.8268537756297094
0.7592245907029287
0.7256008379011685
0.7109756105942956
0.34161229456626735
0.905233410256777
0.5205040718697735
0.4121994254524892
0.7398116665887099
0.6225415196831932
0.7923970242263771
0.7353888240887675
0.6535613357308766
0.7757058271862038
0.734046359122903
0.4471799126982846
0.773619360921301
0.7955347039939479
0.8672068064531693
0.8652880343596522
0.3302235467760883
0.6789268064017625
0.6072221471952108
0.9194446824778495
0.4812004589187253
Total groups 73 exceeded the threshold, stopping comparison.
The group tensor is
[5, 2, 7, 1, 6, 4, 3, 0]
tensor([5, 2, 7, 1, 6, 4, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 6, 0, 7, 3, 4, 1]
tensor([5, 2, 6, 0, 7, 3, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 7, 2, 5, 4, 3, 0]
tensor([6, 1, 7, 2, 5, 4, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 7, 2, 4, 1, 5, 0]
tensor([6, 3, 7, 2, 4, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 5, 6, 2, 3, 1, 4, 0]
tensor([7, 5, 6, 2, 3, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 2, 5, 4, 1, 0, 1, 3]
tensor([0, 2, 5, 4, 1, 0, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1.0, 1.0, 0, 1.0, 1]
tensor([0, 1, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
Normal merging for layer 1
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Normal merging for layer 2
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 4
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 5 to 8
done!
Normal merging for layer 9
tensor([0, 5])
tensor(0)
tensor([4, 6])
tensor(4)
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
done!
Cross-layer merge completed for layers 10 to 30
done!
Normal merging for layer 31
tensor([0, 5])
tensor(0)
tensor([1, 2, 3, 4, 6, 7])
tensor(1)
done!
all done!
Model size: 12.1348 GB
94
cuda:1
logiqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:42<00:42, 42.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:55<00:00, 25.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:55<00:00, 27.94s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/logiqa HTTP/1.1" 200 741
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/EleutherAI/logiqa/EleutherAI/logiqa.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): datasets-server.hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://datasets-server.hf-mirror.com:443 "GET /parquet?dataset=EleutherAI/logiqa HTTP/1.1" 302 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET / HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/EleutherAI/logiqa/EleutherAI/logiqa.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/logiqa/resolve/main/logiqa.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/logiqa/resolve/main/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/logiqa/resolve/main/README.md HTTP/1.1" 200 0
DEBUG:filelock:Attempting to acquire lock 139720625554592 on /public/home/zouyifei001/.cache/huggingface/modules/datasets_modules/datasets/EleutherAI--logiqa.lock
DEBUG:filelock:Lock 139720625554592 acquired on /public/home/zouyifei001/.cache/huggingface/modules/datasets_modules/datasets/EleutherAI--logiqa.lock
DEBUG:filelock:Attempting to release lock 139720625554592 on /public/home/zouyifei001/.cache/huggingface/modules/datasets_modules/datasets/EleutherAI--logiqa.lock
DEBUG:filelock:Lock 139720625554592 released on /public/home/zouyifei001/.cache/huggingface/modules/datasets_modules/datasets/EleutherAI--logiqa.lock
DEBUG:filelock:Attempting to acquire lock 139722744349856 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___logiqa_logiqa_0.0.1_5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81.lock
DEBUG:filelock:Lock 139722744349856 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___logiqa_logiqa_0.0.1_5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___logiqa/logiqa/0.0.1/5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81/dataset_info.json
DEBUG:filelock:Attempting to release lock 139722744349856 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___logiqa_logiqa_0.0.1_5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81.lock
DEBUG:filelock:Lock 139722744349856 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___logiqa_logiqa_0.0.1_5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81.lock
DEBUG:filelock:Attempting to acquire lock 139750522790944 on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___logiqa/logiqa/0.0.1/5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81_builder.lock
DEBUG:filelock:Lock 139750522790944 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___logiqa/logiqa/0.0.1/5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___logiqa/logiqa/0.0.1/5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81/dataset_info.json
DEBUG:filelock:Attempting to release lock 139750522790944 on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___logiqa/logiqa/0.0.1/5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81_builder.lock
DEBUG:filelock:Lock 139750522790944 released on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___logiqa/logiqa/0.0.1/5f02e925d138de34af1cba698b682982c58753f9d7e741715d6b5171f60ede81_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of logiqa from None to 0
INFO:lm_eval.api.task:Building contexts for logiqa on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 3123.76it/s]
DEBUG:lm_eval.evaluator:Task: logiqa; number of requests on this rank: 400
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/400 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/400 [00:02<19:27,  2.93s/it]Running loglikelihood requests:   0%|          | 2/400 [00:05<17:19,  2.61s/it]Running loglikelihood requests:   1%|          | 3/400 [00:07<16:31,  2.50s/it]Running loglikelihood requests:   1%|          | 4/400 [00:10<16:02,  2.43s/it]Running loglikelihood requests:   1%|▏         | 5/400 [00:12<15:40,  2.38s/it]Running loglikelihood requests:   2%|▏         | 6/400 [00:14<15:24,  2.35s/it]Running loglikelihood requests:   2%|▏         | 7/400 [00:16<15:13,  2.33s/it]Running loglikelihood requests:   2%|▏         | 8/400 [00:19<15:04,  2.31s/it]Running loglikelihood requests:   2%|▏         | 9/400 [00:21<14:54,  2.29s/it]Running loglikelihood requests:   2%|▎         | 10/400 [00:23<14:45,  2.27s/it]Running loglikelihood requests:   3%|▎         | 11/400 [00:25<14:34,  2.25s/it]Running loglikelihood requests:   3%|▎         | 12/400 [00:27<14:21,  2.22s/it]Running loglikelihood requests:   3%|▎         | 13/400 [00:30<14:10,  2.20s/it]Running loglikelihood requests:   4%|▎         | 14/400 [00:32<14:01,  2.18s/it]Running loglikelihood requests:   4%|▍         | 15/400 [00:34<13:53,  2.17s/it]Running loglikelihood requests:   4%|▍         | 16/400 [00:36<13:48,  2.16s/it]Running loglikelihood requests:   4%|▍         | 17/400 [00:38<13:43,  2.15s/it]Running loglikelihood requests:   4%|▍         | 18/400 [00:40<13:38,  2.14s/it]Running loglikelihood requests:   5%|▍         | 19/400 [00:42<13:32,  2.13s/it]Running loglikelihood requests:   5%|▌         | 20/400 [00:44<13:27,  2.12s/it]Running loglikelihood requests:   5%|▌         | 21/400 [00:47<13:20,  2.11s/it]Running loglikelihood requests:   6%|▌         | 22/400 [00:49<13:16,  2.11s/it]Running loglikelihood requests:   6%|▌         | 23/400 [00:51<13:10,  2.10s/it]Running loglikelihood requests:   6%|▌         | 24/400 [00:53<13:05,  2.09s/it]Running loglikelihood requests:   6%|▋         | 25/400 [00:55<13:00,  2.08s/it]Running loglikelihood requests:   6%|▋         | 26/400 [00:57<12:54,  2.07s/it]Running loglikelihood requests:   7%|▋         | 27/400 [00:59<12:48,  2.06s/it]Running loglikelihood requests:   7%|▋         | 28/400 [01:01<12:43,  2.05s/it]Running loglikelihood requests:   7%|▋         | 29/400 [01:03<12:37,  2.04s/it]Running loglikelihood requests:   8%|▊         | 30/400 [01:05<12:32,  2.03s/it]Running loglikelihood requests:   8%|▊         | 31/400 [01:07<12:27,  2.03s/it]Running loglikelihood requests:   8%|▊         | 32/400 [01:09<12:23,  2.02s/it]Running loglikelihood requests:   8%|▊         | 33/400 [01:11<12:18,  2.01s/it]Running loglikelihood requests:   8%|▊         | 34/400 [01:13<12:14,  2.01s/it]Running loglikelihood requests:   9%|▉         | 35/400 [01:15<12:10,  2.00s/it]Running loglikelihood requests:   9%|▉         | 36/400 [01:17<12:07,  2.00s/it]Running loglikelihood requests:   9%|▉         | 37/400 [01:19<12:01,  1.99s/it]Running loglikelihood requests:  10%|▉         | 38/400 [01:21<11:56,  1.98s/it]Running loglikelihood requests:  10%|▉         | 39/400 [01:23<11:51,  1.97s/it]Running loglikelihood requests:  10%|█         | 40/400 [01:25<11:46,  1.96s/it]Running loglikelihood requests:  10%|█         | 41/400 [01:27<11:42,  1.96s/it]Running loglikelihood requests:  10%|█         | 42/400 [01:29<11:37,  1.95s/it]Running loglikelihood requests:  11%|█         | 43/400 [01:31<11:34,  1.94s/it]Running loglikelihood requests:  11%|█         | 44/400 [01:33<11:30,  1.94s/it]Running loglikelihood requests:  11%|█▏        | 45/400 [01:34<11:27,  1.94s/it]Running loglikelihood requests:  12%|█▏        | 46/400 [01:36<11:23,  1.93s/it]Running loglikelihood requests:  12%|█▏        | 47/400 [01:38<11:18,  1.92s/it]Running loglikelihood requests:  12%|█▏        | 48/400 [01:40<11:15,  1.92s/it]Running loglikelihood requests:  12%|█▏        | 49/400 [01:42<11:11,  1.91s/it]Running loglikelihood requests:  12%|█▎        | 50/400 [01:44<11:08,  1.91s/it]Running loglikelihood requests:  13%|█▎        | 51/400 [01:46<11:06,  1.91s/it]Running loglikelihood requests:  13%|█▎        | 52/400 [01:48<11:03,  1.91s/it]Running loglikelihood requests:  13%|█▎        | 53/400 [01:50<11:01,  1.91s/it]Running loglikelihood requests:  14%|█▎        | 54/400 [01:52<10:58,  1.90s/it]Running loglikelihood requests:  14%|█▍        | 55/400 [01:54<10:54,  1.90s/it]Running loglikelihood requests:  14%|█▍        | 56/400 [01:55<10:49,  1.89s/it]Running loglikelihood requests:  14%|█▍        | 57/400 [01:57<10:44,  1.88s/it]Running loglikelihood requests:  14%|█▍        | 58/400 [01:59<10:38,  1.87s/it]Running loglikelihood requests:  15%|█▍        | 59/400 [02:01<10:35,  1.86s/it]Running loglikelihood requests:  15%|█▌        | 60/400 [02:03<10:30,  1.85s/it]Running loglikelihood requests:  15%|█▌        | 61/400 [02:05<10:23,  1.84s/it]Running loglikelihood requests:  16%|█▌        | 62/400 [02:06<10:18,  1.83s/it]Running loglikelihood requests:  16%|█▌        | 63/400 [02:08<10:13,  1.82s/it]Running loglikelihood requests:  16%|█▌        | 64/400 [02:10<10:09,  1.81s/it]Running loglikelihood requests:  16%|█▋        | 65/400 [02:12<10:03,  1.80s/it]Running loglikelihood requests:  16%|█▋        | 66/400 [02:14<09:58,  1.79s/it]Running loglikelihood requests:  17%|█▋        | 67/400 [02:15<09:53,  1.78s/it]Running loglikelihood requests:  17%|█▋        | 68/400 [02:17<09:49,  1.77s/it]Running loglikelihood requests:  17%|█▋        | 69/400 [02:19<09:44,  1.77s/it]Running loglikelihood requests:  18%|█▊        | 70/400 [02:21<09:41,  1.76s/it]Running loglikelihood requests:  18%|█▊        | 71/400 [02:22<09:38,  1.76s/it]Running loglikelihood requests:  18%|█▊        | 72/400 [02:24<09:34,  1.75s/it]Running loglikelihood requests:  18%|█▊        | 73/400 [02:26<09:29,  1.74s/it]Running loglikelihood requests:  18%|█▊        | 74/400 [02:27<09:24,  1.73s/it]Running loglikelihood requests:  19%|█▉        | 75/400 [02:29<09:19,  1.72s/it]Running loglikelihood requests:  19%|█▉        | 76/400 [02:31<09:15,  1.71s/it]Running loglikelihood requests:  19%|█▉        | 77/400 [02:33<09:10,  1.70s/it]Running loglikelihood requests:  20%|█▉        | 78/400 [02:34<09:05,  1.69s/it]Running loglikelihood requests:  20%|█▉        | 79/400 [02:36<09:00,  1.68s/it]Running loglikelihood requests:  20%|██        | 80/400 [02:38<08:56,  1.68s/it]Running loglikelihood requests:  20%|██        | 81/400 [02:39<08:52,  1.67s/it]Running loglikelihood requests:  20%|██        | 82/400 [02:41<08:48,  1.66s/it]Running loglikelihood requests:  21%|██        | 83/400 [02:42<08:43,  1.65s/it]Running loglikelihood requests:  21%|██        | 84/400 [02:44<08:40,  1.65s/it]Running loglikelihood requests:  21%|██▏       | 85/400 [02:46<08:36,  1.64s/it]Running loglikelihood requests:  22%|██▏       | 86/400 [02:47<08:33,  1.63s/it]Running loglikelihood requests:  22%|██▏       | 87/400 [02:49<08:30,  1.63s/it]Running loglikelihood requests:  22%|██▏       | 88/400 [02:51<08:28,  1.63s/it]Running loglikelihood requests:  22%|██▏       | 89/400 [02:52<08:26,  1.63s/it]Running loglikelihood requests:  22%|██▎       | 90/400 [02:54<08:24,  1.63s/it]Running loglikelihood requests:  23%|██▎       | 91/400 [02:55<08:21,  1.62s/it]Running loglikelihood requests:  23%|██▎       | 92/400 [02:57<08:19,  1.62s/it]Running loglikelihood requests:  23%|██▎       | 93/400 [02:59<08:17,  1.62s/it]Running loglikelihood requests:  24%|██▎       | 94/400 [03:00<08:14,  1.62s/it]Running loglikelihood requests:  24%|██▍       | 95/400 [03:02<08:12,  1.61s/it]Running loglikelihood requests:  24%|██▍       | 96/400 [03:03<08:09,  1.61s/it]Running loglikelihood requests:  24%|██▍       | 97/400 [03:05<08:07,  1.61s/it]Running loglikelihood requests:  24%|██▍       | 98/400 [03:07<08:05,  1.61s/it]Running loglikelihood requests:  25%|██▍       | 99/400 [03:08<08:03,  1.61s/it]Running loglikelihood requests:  25%|██▌       | 100/400 [03:10<08:02,  1.61s/it]Running loglikelihood requests:  25%|██▌       | 101/400 [03:12<08:00,  1.61s/it]Running loglikelihood requests:  26%|██▌       | 102/400 [03:13<07:57,  1.60s/it]Running loglikelihood requests:  26%|██▌       | 103/400 [03:15<07:55,  1.60s/it]Running loglikelihood requests:  26%|██▌       | 104/400 [03:16<07:53,  1.60s/it]Running loglikelihood requests:  26%|██▋       | 105/400 [03:18<07:51,  1.60s/it]Running loglikelihood requests:  26%|██▋       | 106/400 [03:19<07:49,  1.60s/it]Running loglikelihood requests:  27%|██▋       | 107/400 [03:21<07:47,  1.60s/it]Running loglikelihood requests:  27%|██▋       | 108/400 [03:23<07:44,  1.59s/it]Running loglikelihood requests:  27%|██▋       | 109/400 [03:24<07:41,  1.59s/it]Running loglikelihood requests:  28%|██▊       | 110/400 [03:26<07:39,  1.58s/it]Running loglikelihood requests:  28%|██▊       | 111/400 [03:27<07:37,  1.58s/it]Running loglikelihood requests:  28%|██▊       | 112/400 [03:29<07:34,  1.58s/it]Running loglikelihood requests:  28%|██▊       | 113/400 [03:31<07:32,  1.58s/it]Running loglikelihood requests:  28%|██▊       | 114/400 [03:32<07:29,  1.57s/it]Running loglikelihood requests:  29%|██▉       | 115/400 [03:34<07:26,  1.57s/it]Running loglikelihood requests:  29%|██▉       | 116/400 [03:35<07:25,  1.57s/it]Running loglikelihood requests:  29%|██▉       | 117/400 [03:37<07:23,  1.57s/it]Running loglikelihood requests:  30%|██▉       | 118/400 [03:38<07:20,  1.56s/it]Running loglikelihood requests:  30%|██▉       | 119/400 [03:40<07:17,  1.56s/it]Running loglikelihood requests:  30%|███       | 120/400 [03:41<07:15,  1.55s/it]Running loglikelihood requests:  30%|███       | 121/400 [03:43<07:13,  1.55s/it]Running loglikelihood requests:  30%|███       | 122/400 [03:45<07:10,  1.55s/it]Running loglikelihood requests:  31%|███       | 123/400 [03:46<07:08,  1.55s/it]Running loglikelihood requests:  31%|███       | 124/400 [03:48<07:06,  1.54s/it]Running loglikelihood requests:  31%|███▏      | 125/400 [03:49<07:03,  1.54s/it]Running loglikelihood requests:  32%|███▏      | 126/400 [03:51<07:02,  1.54s/it]Running loglikelihood requests:  32%|███▏      | 127/400 [03:52<06:59,  1.54s/it]Running loglikelihood requests:  32%|███▏      | 128/400 [03:54<06:57,  1.54s/it]Running loglikelihood requests:  32%|███▏      | 129/400 [03:55<06:55,  1.53s/it]Running loglikelihood requests:  32%|███▎      | 130/400 [03:57<06:53,  1.53s/it]Running loglikelihood requests:  33%|███▎      | 131/400 [03:58<06:51,  1.53s/it]Running loglikelihood requests:  33%|███▎      | 132/400 [04:00<06:49,  1.53s/it]Running loglikelihood requests:  33%|███▎      | 133/400 [04:01<06:47,  1.53s/it]Running loglikelihood requests:  34%|███▎      | 134/400 [04:03<06:45,  1.52s/it]Running loglikelihood requests:  34%|███▍      | 135/400 [04:04<06:43,  1.52s/it]Running loglikelihood requests:  34%|███▍      | 136/400 [04:06<06:42,  1.52s/it]Running loglikelihood requests:  34%|███▍      | 137/400 [04:07<06:40,  1.52s/it]Running loglikelihood requests:  34%|███▍      | 138/400 [04:09<06:38,  1.52s/it]Running loglikelihood requests:  35%|███▍      | 139/400 [04:11<06:36,  1.52s/it]Running loglikelihood requests:  35%|███▌      | 140/400 [04:12<06:35,  1.52s/it]Running loglikelihood requests:  36%|███▌      | 142/400 [04:14<05:01,  1.17s/it]Running loglikelihood requests:  36%|███▌      | 143/400 [04:15<05:22,  1.25s/it]Running loglikelihood requests:  36%|███▌      | 144/400 [04:17<05:38,  1.32s/it]Running loglikelihood requests:  36%|███▋      | 145/400 [04:18<05:49,  1.37s/it]Running loglikelihood requests:  36%|███▋      | 146/400 [04:20<05:57,  1.41s/it]Running loglikelihood requests:  37%|███▋      | 147/400 [04:21<06:03,  1.44s/it]Running loglikelihood requests:  37%|███▋      | 148/400 [04:23<06:06,  1.46s/it]Running loglikelihood requests:  37%|███▋      | 149/400 [04:24<06:08,  1.47s/it]Running loglikelihood requests:  38%|███▊      | 150/400 [04:26<06:09,  1.48s/it]Running loglikelihood requests:  38%|███▊      | 151/400 [04:27<06:09,  1.48s/it]Running loglikelihood requests:  38%|███▊      | 152/400 [04:29<06:08,  1.49s/it]Running loglikelihood requests:  38%|███▊      | 153/400 [04:30<06:08,  1.49s/it]Running loglikelihood requests:  38%|███▊      | 154/400 [04:32<06:07,  1.49s/it]Running loglikelihood requests:  39%|███▉      | 155/400 [04:33<06:06,  1.49s/it]Running loglikelihood requests:  39%|███▉      | 156/400 [04:35<06:04,  1.49s/it]Running loglikelihood requests:  39%|███▉      | 157/400 [04:36<06:03,  1.49s/it]Running loglikelihood requests:  40%|███▉      | 158/400 [04:38<06:01,  1.49s/it]Running loglikelihood requests:  40%|███▉      | 159/400 [04:39<05:59,  1.49s/it]Running loglikelihood requests:  40%|████      | 160/400 [04:41<05:58,  1.49s/it]Running loglikelihood requests:  40%|████      | 161/400 [04:42<05:56,  1.49s/it]Running loglikelihood requests:  40%|████      | 162/400 [04:44<05:55,  1.49s/it]Running loglikelihood requests:  41%|████      | 163/400 [04:45<05:53,  1.49s/it]Running loglikelihood requests:  41%|████      | 164/400 [04:46<05:51,  1.49s/it]Running loglikelihood requests:  41%|████▏     | 165/400 [04:48<05:49,  1.49s/it]Running loglikelihood requests:  42%|████▏     | 166/400 [04:49<05:47,  1.49s/it]Running loglikelihood requests:  42%|████▏     | 167/400 [04:51<05:45,  1.48s/it]Running loglikelihood requests:  42%|████▏     | 168/400 [04:52<05:43,  1.48s/it]Running loglikelihood requests:  42%|████▏     | 169/400 [04:54<05:41,  1.48s/it]Running loglikelihood requests:  42%|████▎     | 170/400 [04:55<05:40,  1.48s/it]Running loglikelihood requests:  43%|████▎     | 171/400 [04:57<05:38,  1.48s/it]Running loglikelihood requests:  43%|████▎     | 172/400 [04:58<05:36,  1.48s/it]Running loglikelihood requests:  43%|████▎     | 173/400 [05:00<05:34,  1.47s/it]Running loglikelihood requests:  44%|████▎     | 174/400 [05:01<05:32,  1.47s/it]Running loglikelihood requests:  44%|████▍     | 175/400 [05:03<05:30,  1.47s/it]Running loglikelihood requests:  44%|████▍     | 176/400 [05:04<05:28,  1.47s/it]Running loglikelihood requests:  44%|████▍     | 177/400 [05:06<05:27,  1.47s/it]Running loglikelihood requests:  44%|████▍     | 178/400 [05:07<05:24,  1.46s/it]Running loglikelihood requests:  45%|████▍     | 179/400 [05:09<05:22,  1.46s/it]Running loglikelihood requests:  45%|████▌     | 180/400 [05:10<05:20,  1.46s/it]Running loglikelihood requests:  45%|████▌     | 181/400 [05:11<05:18,  1.45s/it]Running loglikelihood requests:  46%|████▌     | 182/400 [05:13<05:16,  1.45s/it]Running loglikelihood requests:  46%|████▌     | 183/400 [05:14<05:14,  1.45s/it]Running loglikelihood requests:  46%|████▌     | 184/400 [05:16<05:12,  1.45s/it]Running loglikelihood requests:  46%|████▋     | 185/400 [05:17<05:10,  1.44s/it]Running loglikelihood requests:  46%|████▋     | 186/400 [05:19<05:08,  1.44s/it]Running loglikelihood requests:  47%|████▋     | 187/400 [05:20<05:06,  1.44s/it]Running loglikelihood requests:  47%|████▋     | 188/400 [05:22<05:04,  1.44s/it]Running loglikelihood requests:  47%|████▋     | 189/400 [05:23<05:02,  1.44s/it]Running loglikelihood requests:  48%|████▊     | 190/400 [05:24<05:01,  1.43s/it]Running loglikelihood requests:  48%|████▊     | 191/400 [05:26<04:59,  1.43s/it]Running loglikelihood requests:  48%|████▊     | 192/400 [05:27<04:57,  1.43s/it]Running loglikelihood requests:  48%|████▊     | 193/400 [05:29<04:55,  1.43s/it]Running loglikelihood requests:  48%|████▊     | 194/400 [05:30<04:53,  1.43s/it]Running loglikelihood requests:  49%|████▉     | 195/400 [05:32<04:52,  1.42s/it]Running loglikelihood requests:  49%|████▉     | 196/400 [05:33<04:49,  1.42s/it]Running loglikelihood requests:  49%|████▉     | 197/400 [05:34<04:47,  1.42s/it]Running loglikelihood requests:  50%|████▉     | 198/400 [05:36<04:46,  1.42s/it]Running loglikelihood requests:  50%|████▉     | 199/400 [05:37<04:44,  1.41s/it]Running loglikelihood requests:  50%|█████     | 200/400 [05:39<04:42,  1.41s/it]Running loglikelihood requests:  50%|█████     | 201/400 [05:40<04:40,  1.41s/it]Running loglikelihood requests:  50%|█████     | 202/400 [05:41<04:38,  1.41s/it]Running loglikelihood requests:  51%|█████     | 203/400 [05:43<04:36,  1.40s/it]Running loglikelihood requests:  51%|█████     | 204/400 [05:44<04:35,  1.40s/it]Running loglikelihood requests:  51%|█████▏    | 205/400 [05:46<04:33,  1.40s/it]Running loglikelihood requests:  52%|█████▏    | 206/400 [05:47<04:31,  1.40s/it]Running loglikelihood requests:  52%|█████▏    | 207/400 [05:48<04:30,  1.40s/it]Running loglikelihood requests:  52%|█████▏    | 208/400 [05:50<04:28,  1.40s/it]Running loglikelihood requests:  52%|█████▏    | 209/400 [05:51<04:26,  1.40s/it]Running loglikelihood requests:  52%|█████▎    | 210/400 [05:53<04:25,  1.40s/it]Running loglikelihood requests:  53%|█████▎    | 211/400 [05:54<04:23,  1.40s/it]Running loglikelihood requests:  53%|█████▎    | 212/400 [05:55<04:22,  1.40s/it]Running loglikelihood requests:  53%|█████▎    | 213/400 [05:57<04:20,  1.39s/it]Running loglikelihood requests:  54%|█████▎    | 214/400 [05:58<04:19,  1.39s/it]Running loglikelihood requests:  54%|█████▍    | 215/400 [06:00<04:17,  1.39s/it]Running loglikelihood requests:  54%|█████▍    | 216/400 [06:01<04:15,  1.39s/it]Running loglikelihood requests:  54%|█████▍    | 217/400 [06:02<04:14,  1.39s/it]Running loglikelihood requests:  55%|█████▍    | 218/400 [06:04<04:13,  1.39s/it]Running loglikelihood requests:  55%|█████▍    | 219/400 [06:05<04:11,  1.39s/it]Running loglikelihood requests:  55%|█████▌    | 220/400 [06:06<04:09,  1.39s/it]Running loglikelihood requests:  55%|█████▌    | 221/400 [06:08<04:07,  1.39s/it]Running loglikelihood requests:  56%|█████▌    | 222/400 [06:09<04:06,  1.38s/it]Running loglikelihood requests:  56%|█████▌    | 223/400 [06:11<04:04,  1.38s/it]Running loglikelihood requests:  56%|█████▌    | 224/400 [06:12<04:03,  1.38s/it]Running loglikelihood requests:  56%|█████▋    | 225/400 [06:13<04:01,  1.38s/it]Running loglikelihood requests:  56%|█████▋    | 226/400 [06:15<04:00,  1.38s/it]Running loglikelihood requests:  57%|█████▋    | 227/400 [06:16<03:58,  1.38s/it]Running loglikelihood requests:  57%|█████▋    | 228/400 [06:17<03:57,  1.38s/it]Running loglikelihood requests:  57%|█████▋    | 229/400 [06:19<03:55,  1.38s/it]Running loglikelihood requests:  57%|█████▊    | 230/400 [06:20<03:53,  1.38s/it]Running loglikelihood requests:  58%|█████▊    | 231/400 [06:22<03:52,  1.38s/it]Running loglikelihood requests:  58%|█████▊    | 232/400 [06:23<03:50,  1.37s/it]Running loglikelihood requests:  58%|█████▊    | 233/400 [06:24<03:49,  1.37s/it]Running loglikelihood requests:  58%|█████▊    | 234/400 [06:26<03:47,  1.37s/it]Running loglikelihood requests:  59%|█████▉    | 235/400 [06:27<03:45,  1.37s/it]Running loglikelihood requests:  59%|█████▉    | 236/400 [06:28<03:43,  1.36s/it]Running loglikelihood requests:  59%|█████▉    | 237/400 [06:30<03:42,  1.36s/it]Running loglikelihood requests:  60%|█████▉    | 238/400 [06:31<03:40,  1.36s/it]Running loglikelihood requests:  60%|█████▉    | 239/400 [06:33<03:38,  1.36s/it]Running loglikelihood requests:  60%|██████    | 240/400 [06:34<03:37,  1.36s/it]Running loglikelihood requests:  60%|██████    | 241/400 [06:35<03:36,  1.36s/it]Running loglikelihood requests:  60%|██████    | 242/400 [06:37<03:34,  1.36s/it]Running loglikelihood requests:  61%|██████    | 243/400 [06:38<03:33,  1.36s/it]Running loglikelihood requests:  61%|██████    | 244/400 [06:39<03:31,  1.36s/it]Running loglikelihood requests:  61%|██████▏   | 245/400 [06:41<03:30,  1.36s/it]Running loglikelihood requests:  62%|██████▏   | 246/400 [06:42<03:29,  1.36s/it]Running loglikelihood requests:  62%|██████▏   | 247/400 [06:43<03:27,  1.36s/it]Running loglikelihood requests:  62%|██████▏   | 248/400 [06:45<03:26,  1.36s/it]Running loglikelihood requests:  62%|██████▏   | 249/400 [06:46<03:24,  1.35s/it]Running loglikelihood requests:  62%|██████▎   | 250/400 [06:47<03:22,  1.35s/it]Running loglikelihood requests:  63%|██████▎   | 251/400 [06:49<03:21,  1.35s/it]Running loglikelihood requests:  63%|██████▎   | 252/400 [06:50<03:19,  1.35s/it]Running loglikelihood requests:  63%|██████▎   | 253/400 [06:51<03:18,  1.35s/it]Running loglikelihood requests:  64%|██████▎   | 254/400 [06:53<03:16,  1.35s/it]Running loglikelihood requests:  64%|██████▍   | 255/400 [06:54<03:14,  1.34s/it]Running loglikelihood requests:  64%|██████▍   | 256/400 [06:55<03:13,  1.34s/it]Running loglikelihood requests:  64%|██████▍   | 257/400 [06:57<03:11,  1.34s/it]Running loglikelihood requests:  64%|██████▍   | 258/400 [06:58<03:10,  1.34s/it]Running loglikelihood requests:  65%|██████▍   | 259/400 [06:59<03:09,  1.34s/it]Running loglikelihood requests:  65%|██████▌   | 260/400 [07:01<03:07,  1.34s/it]Running loglikelihood requests:  65%|██████▌   | 261/400 [07:02<03:06,  1.34s/it]Running loglikelihood requests:  66%|██████▌   | 262/400 [07:03<03:04,  1.34s/it]Running loglikelihood requests:  66%|██████▌   | 263/400 [07:05<03:02,  1.33s/it]Running loglikelihood requests:  66%|██████▌   | 264/400 [07:06<03:00,  1.33s/it]Running loglikelihood requests:  66%|██████▋   | 265/400 [07:07<02:58,  1.32s/it]Running loglikelihood requests:  66%|██████▋   | 266/400 [07:09<02:57,  1.32s/it]Running loglikelihood requests:  67%|██████▋   | 267/400 [07:10<02:55,  1.32s/it]Running loglikelihood requests:  67%|██████▋   | 268/400 [07:11<02:54,  1.32s/it]Running loglikelihood requests:  67%|██████▋   | 269/400 [07:13<02:52,  1.32s/it]Running loglikelihood requests:  68%|██████▊   | 270/400 [07:14<02:51,  1.32s/it]Running loglikelihood requests:  68%|██████▊   | 271/400 [07:15<02:49,  1.31s/it]Running loglikelihood requests:  68%|██████▊   | 272/400 [07:17<02:47,  1.31s/it]Running loglikelihood requests:  68%|██████▊   | 273/400 [07:18<02:46,  1.31s/it]Running loglikelihood requests:  68%|██████▊   | 274/400 [07:19<02:45,  1.31s/it]Running loglikelihood requests:  69%|██████▉   | 275/400 [07:21<02:43,  1.31s/it]Running loglikelihood requests:  69%|██████▉   | 276/400 [07:22<02:41,  1.31s/it]Running loglikelihood requests:  69%|██████▉   | 277/400 [07:23<02:40,  1.30s/it]Running loglikelihood requests:  70%|██████▉   | 278/400 [07:24<02:38,  1.30s/it]Running loglikelihood requests:  70%|███████   | 280/400 [07:26<01:59,  1.00it/s]Running loglikelihood requests:  70%|███████   | 281/400 [07:27<02:07,  1.07s/it]Running loglikelihood requests:  70%|███████   | 282/400 [07:28<02:13,  1.13s/it]Running loglikelihood requests:  71%|███████   | 283/400 [07:30<02:16,  1.17s/it]Running loglikelihood requests:  71%|███████   | 284/400 [07:31<02:19,  1.20s/it]Running loglikelihood requests:  71%|███████▏  | 285/400 [07:32<02:20,  1.22s/it]Running loglikelihood requests:  72%|███████▏  | 286/400 [07:33<02:21,  1.24s/it]Running loglikelihood requests:  72%|███████▏  | 287/400 [07:35<02:21,  1.25s/it]Running loglikelihood requests:  72%|███████▏  | 288/400 [07:36<02:21,  1.26s/it]Running loglikelihood requests:  72%|███████▏  | 289/400 [07:37<02:19,  1.26s/it]Running loglikelihood requests:  72%|███████▎  | 290/400 [07:39<02:18,  1.26s/it]Running loglikelihood requests:  73%|███████▎  | 291/400 [07:40<02:16,  1.26s/it]Running loglikelihood requests:  73%|███████▎  | 292/400 [07:41<02:15,  1.25s/it]Running loglikelihood requests:  73%|███████▎  | 293/400 [07:42<02:14,  1.25s/it]Running loglikelihood requests:  74%|███████▎  | 294/400 [07:44<02:12,  1.25s/it]Running loglikelihood requests:  74%|███████▍  | 295/400 [07:45<02:11,  1.25s/it]Running loglikelihood requests:  74%|███████▍  | 296/400 [07:46<02:09,  1.25s/it]Running loglikelihood requests:  74%|███████▍  | 297/400 [07:47<02:08,  1.25s/it]Running loglikelihood requests:  74%|███████▍  | 298/400 [07:48<02:06,  1.24s/it]Running loglikelihood requests:  75%|███████▍  | 299/400 [07:50<02:05,  1.24s/it]Running loglikelihood requests:  75%|███████▌  | 300/400 [07:51<02:04,  1.24s/it]Running loglikelihood requests:  75%|███████▌  | 301/400 [07:52<02:02,  1.24s/it]Running loglikelihood requests:  76%|███████▌  | 302/400 [07:53<02:01,  1.24s/it]Running loglikelihood requests:  76%|███████▌  | 303/400 [07:55<01:59,  1.23s/it]Running loglikelihood requests:  76%|███████▌  | 304/400 [07:56<01:58,  1.23s/it]Running loglikelihood requests:  76%|███████▋  | 305/400 [07:57<01:56,  1.23s/it]Running loglikelihood requests:  76%|███████▋  | 306/400 [07:58<01:55,  1.23s/it]Running loglikelihood requests:  77%|███████▋  | 307/400 [08:00<01:53,  1.22s/it]Running loglikelihood requests:  77%|███████▋  | 308/400 [08:01<01:52,  1.22s/it]Running loglikelihood requests:  77%|███████▋  | 309/400 [08:02<01:51,  1.22s/it]Running loglikelihood requests:  78%|███████▊  | 310/400 [08:03<01:49,  1.22s/it]Running loglikelihood requests:  78%|███████▊  | 311/400 [08:04<01:48,  1.22s/it]Running loglikelihood requests:  78%|███████▊  | 312/400 [08:06<01:47,  1.22s/it]Running loglikelihood requests:  78%|███████▊  | 313/400 [08:07<01:45,  1.22s/it]Running loglikelihood requests:  78%|███████▊  | 314/400 [08:08<01:44,  1.22s/it]Running loglikelihood requests:  79%|███████▉  | 315/400 [08:09<01:43,  1.21s/it]Running loglikelihood requests:  79%|███████▉  | 316/400 [08:10<01:42,  1.21s/it]Running loglikelihood requests:  79%|███████▉  | 317/400 [08:12<01:40,  1.21s/it]Running loglikelihood requests:  80%|███████▉  | 318/400 [08:13<01:39,  1.21s/it]Running loglikelihood requests:  80%|███████▉  | 319/400 [08:14<01:37,  1.21s/it]Running loglikelihood requests:  80%|████████  | 320/400 [08:15<01:36,  1.20s/it]Running loglikelihood requests:  80%|████████  | 321/400 [08:16<01:34,  1.20s/it]Running loglikelihood requests:  80%|████████  | 322/400 [08:18<01:33,  1.20s/it]Running loglikelihood requests:  81%|████████  | 323/400 [08:19<01:32,  1.20s/it]Running loglikelihood requests:  81%|████████  | 324/400 [08:20<01:31,  1.20s/it]Running loglikelihood requests:  81%|████████▏ | 325/400 [08:21<01:29,  1.20s/it]Running loglikelihood requests:  82%|████████▏ | 326/400 [08:22<01:28,  1.19s/it]Running loglikelihood requests:  82%|████████▏ | 327/400 [08:24<01:27,  1.19s/it]Running loglikelihood requests:  82%|████████▏ | 328/400 [08:25<01:25,  1.19s/it]Running loglikelihood requests:  82%|████████▏ | 329/400 [08:26<01:24,  1.19s/it]Running loglikelihood requests:  82%|████████▎ | 330/400 [08:27<01:23,  1.19s/it]Running loglikelihood requests:  83%|████████▎ | 331/400 [08:28<01:21,  1.19s/it]Running loglikelihood requests:  83%|████████▎ | 332/400 [08:30<01:20,  1.19s/it]Running loglikelihood requests:  83%|████████▎ | 333/400 [08:31<01:19,  1.18s/it]Running loglikelihood requests:  84%|████████▎ | 334/400 [08:32<01:17,  1.18s/it]Running loglikelihood requests:  84%|████████▍ | 335/400 [08:33<01:16,  1.18s/it]Running loglikelihood requests:  84%|████████▍ | 336/400 [08:34<01:15,  1.18s/it]Running loglikelihood requests:  84%|████████▍ | 337/400 [08:35<01:14,  1.18s/it]Running loglikelihood requests:  84%|████████▍ | 338/400 [08:37<01:12,  1.17s/it]Running loglikelihood requests:  85%|████████▍ | 339/400 [08:38<01:11,  1.17s/it]Running loglikelihood requests:  85%|████████▌ | 340/400 [08:39<01:10,  1.17s/it]Running loglikelihood requests:  85%|████████▌ | 341/400 [08:40<01:08,  1.17s/it]Running loglikelihood requests:  86%|████████▌ | 342/400 [08:41<01:07,  1.16s/it]Running loglikelihood requests:  86%|████████▌ | 343/400 [08:42<01:06,  1.16s/it]Running loglikelihood requests:  86%|████████▌ | 344/400 [08:44<01:04,  1.16s/it]Running loglikelihood requests:  86%|████████▋ | 345/400 [08:45<01:03,  1.15s/it]Running loglikelihood requests:  86%|████████▋ | 346/400 [08:46<01:02,  1.15s/it]Running loglikelihood requests:  87%|████████▋ | 347/400 [08:47<01:00,  1.15s/it]Running loglikelihood requests:  87%|████████▋ | 348/400 [08:48<00:59,  1.15s/it]Running loglikelihood requests:  87%|████████▋ | 349/400 [08:49<00:58,  1.15s/it]Running loglikelihood requests:  88%|████████▊ | 350/400 [08:50<00:57,  1.15s/it]Running loglikelihood requests:  88%|████████▊ | 351/400 [08:52<00:56,  1.14s/it]Running loglikelihood requests:  88%|████████▊ | 352/400 [08:53<00:54,  1.14s/it]Running loglikelihood requests:  88%|████████▊ | 353/400 [08:54<00:53,  1.14s/it]Running loglikelihood requests:  88%|████████▊ | 354/400 [08:55<00:52,  1.14s/it]Running loglikelihood requests:  89%|████████▉ | 355/400 [08:56<00:51,  1.14s/it]Running loglikelihood requests:  89%|████████▉ | 356/400 [08:57<00:49,  1.13s/it]Running loglikelihood requests:  89%|████████▉ | 357/400 [08:58<00:48,  1.13s/it]Running loglikelihood requests:  90%|████████▉ | 358/400 [08:59<00:47,  1.13s/it]Running loglikelihood requests:  90%|████████▉ | 359/400 [09:01<00:46,  1.13s/it]Running loglikelihood requests:  90%|█████████ | 360/400 [09:02<00:44,  1.12s/it]Running loglikelihood requests:  90%|█████████ | 361/400 [09:03<00:43,  1.12s/it]Running loglikelihood requests:  90%|█████████ | 362/400 [09:04<00:42,  1.12s/it]Running loglikelihood requests:  91%|█████████ | 363/400 [09:05<00:41,  1.12s/it]Running loglikelihood requests:  91%|█████████ | 364/400 [09:06<00:40,  1.12s/it]Running loglikelihood requests:  91%|█████████▏| 365/400 [09:07<00:39,  1.11s/it]Running loglikelihood requests:  92%|█████████▏| 366/400 [09:08<00:37,  1.11s/it]Running loglikelihood requests:  92%|█████████▏| 367/400 [09:10<00:36,  1.11s/it]Running loglikelihood requests:  92%|█████████▏| 368/400 [09:11<00:35,  1.11s/it]Running loglikelihood requests:  92%|█████████▏| 369/400 [09:12<00:34,  1.11s/it]Running loglikelihood requests:  92%|█████████▎| 370/400 [09:13<00:33,  1.11s/it]Running loglikelihood requests:  93%|█████████▎| 371/400 [09:14<00:32,  1.10s/it]Running loglikelihood requests:  93%|█████████▎| 372/400 [09:15<00:30,  1.10s/it]Running loglikelihood requests:  93%|█████████▎| 373/400 [09:16<00:29,  1.10s/it]Running loglikelihood requests:  94%|█████████▎| 374/400 [09:17<00:28,  1.09s/it]Running loglikelihood requests:  94%|█████████▍| 375/400 [09:18<00:27,  1.09s/it]Running loglikelihood requests:  94%|█████████▍| 376/400 [09:19<00:25,  1.08s/it]Running loglikelihood requests:  94%|█████████▍| 377/400 [09:20<00:24,  1.07s/it]Running loglikelihood requests:  94%|█████████▍| 378/400 [09:21<00:23,  1.07s/it]Running loglikelihood requests:  95%|█████████▍| 379/400 [09:22<00:22,  1.06s/it]Running loglikelihood requests:  95%|█████████▌| 380/400 [09:23<00:20,  1.05s/it]Running loglikelihood requests:  95%|█████████▌| 381/400 [09:25<00:19,  1.03s/it]Running loglikelihood requests:  96%|█████████▌| 382/400 [09:26<00:18,  1.03s/it]Running loglikelihood requests:  96%|█████████▌| 383/400 [09:27<00:17,  1.02s/it]Running loglikelihood requests:  96%|█████████▌| 384/400 [09:28<00:16,  1.02s/it]Running loglikelihood requests:  96%|█████████▋| 385/400 [09:29<00:15,  1.01s/it]Running loglikelihood requests:  96%|█████████▋| 386/400 [09:30<00:14,  1.01s/it]Running loglikelihood requests:  97%|█████████▋| 387/400 [09:31<00:13,  1.00s/it]Running loglikelihood requests:  97%|█████████▋| 389/400 [09:31<00:08,  1.31it/s]Running loglikelihood requests:  98%|█████████▊| 390/400 [09:32<00:08,  1.24it/s]Running loglikelihood requests:  98%|█████████▊| 391/400 [09:33<00:07,  1.18it/s]Running loglikelihood requests:  98%|█████████▊| 393/400 [09:34<00:04,  1.48it/s]Running loglikelihood requests:  98%|█████████▊| 394/400 [09:35<00:04,  1.38it/s]Running loglikelihood requests:  99%|█████████▉| 395/400 [09:36<00:03,  1.31it/s]Running loglikelihood requests:  99%|█████████▉| 396/400 [09:37<00:03,  1.25it/s]Running loglikelihood requests:  99%|█████████▉| 397/400 [09:38<00:02,  1.21it/s]Running loglikelihood requests: 100%|█████████▉| 398/400 [09:39<00:01,  1.19it/s]Running loglikelihood requests: 100%|█████████▉| 399/400 [09:40<00:00,  1.18it/s]Running loglikelihood requests: 100%|██████████| 400/400 [09:40<00:00,  1.17it/s]Running loglikelihood requests: 100%|██████████| 400/400 [09:40<00:00,  1.45s/it]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:2'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:2'}
full model:
{'logiqa': {'alias': 'logiqa', 'acc,none': 0.29, 'acc_stderr,none': 0.045604802157206865, 'acc_norm,none': 0.33, 'acc_norm_stderr,none': 0.04725815626252609}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9179964803140478
0.7817057225882229
0.8413553272072316
0.9274797474668193
0.8768807463293081
0.9494139907523571
0.8960692461846443
0.9131107283061946
0.6329173647892901
0.8375042173336539
0.8817471801904351
0.8172295355829869
0.7824572665005357
0.9227400642857845
0.9246594853497696
0.8075911590072223
0.6900210787422486
0.599615993999193
0.9308030044211123
0.9504015361511146
0.8866807231108503
0.540104242930401
0.6701728801805507
0.9744992661822648
0.8193037468812308
0.840784693447352
0.9052511591891966
Total groups 70 exceeded the threshold, stopping comparison.
The group tensor is
[3, 6, 7, 1, 5, 2, 4, 0]
tensor([3, 6, 7, 1, 5, 2, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 2, 6, 3, 7, 1, 5, 0]
tensor([4, 2, 6, 3, 7, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 3, 6, 1, 7, 2, 4, 0]
tensor([5, 3, 6, 1, 7, 2, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 4, 6, 1, 7, 2, 3, 0]
tensor([5, 4, 6, 1, 7, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 3, 0, 2, 1, 0, 4, 1]
tensor([5, 3, 0, 2, 1, 0, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 0, 5, 0, 1, 2, 3, 1]
tensor([4, 0, 5, 0, 1, 2, 3, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Normal merging for layer 2
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 4 to 8
done!
Normal merging for layer 9
tensor([2, 5])
tensor(2)
tensor([4, 7])
tensor(4)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 10 to 13
done!
Normal merging for layer 14
tensor([1, 3])
tensor(1)
tensor([4, 7])
tensor(4)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Cross-layer merge completed for layers 15 to 31
done!
all done!
Model size: 11.9458 GB
4
cuda:2
mastermind_46_easy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:43<00:43, 43.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:56<00:00, 25.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:56<00:00, 28.14s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_46_mcq_random HTTP/1.1" 200 778
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/flair/mastermind_46_mcq_random/flair/mastermind_46_mcq_random.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_46_mcq_random HTTP/1.1" 200 786
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/flair/mastermind_46_mcq_random/resolve/544d077942975b1664c0bc4fd54df026050329a4/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/flair/mastermind_46_mcq_random/resolve/544d077942975b1664c0bc4fd54df026050329a4/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:filelock:Attempting to acquire lock 139750522633536 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_46_mcq_random_default_0.0.0_544d077942975b1664c0bc4fd54df026050329a4.lock
DEBUG:filelock:Lock 139750522633536 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_46_mcq_random_default_0.0.0_544d077942975b1664c0bc4fd54df026050329a4.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_46_mcq_random/default/0.0.0/544d077942975b1664c0bc4fd54df026050329a4/dataset_info.json
DEBUG:filelock:Attempting to release lock 139750522633536 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_46_mcq_random_default_0.0.0_544d077942975b1664c0bc4fd54df026050329a4.lock
DEBUG:filelock:Lock 139750522633536 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_46_mcq_random_default_0.0.0_544d077942975b1664c0bc4fd54df026050329a4.lock
DEBUG:filelock:Attempting to acquire lock 139722783347088 on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_46_mcq_random/default/0.0.0/544d077942975b1664c0bc4fd54df026050329a4_builder.lock
DEBUG:filelock:Lock 139722783347088 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_46_mcq_random/default/0.0.0/544d077942975b1664c0bc4fd54df026050329a4_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_46_mcq_random/default/0.0.0/544d077942975b1664c0bc4fd54df026050329a4/dataset_info.json
DEBUG:filelock:Attempting to release lock 139722783347088 on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_46_mcq_random/default/0.0.0/544d077942975b1664c0bc4fd54df026050329a4_builder.lock
DEBUG:filelock:Lock 139722783347088 released on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_46_mcq_random/default/0.0.0/544d077942975b1664c0bc4fd54df026050329a4_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mastermind_46_easy from None to 0
INFO:lm_eval.api.task:Building contexts for mastermind_46_easy on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1508.32it/s]
DEBUG:lm_eval.evaluator:Task: mastermind_46_easy; number of requests on this rank: 400
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/400 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/400 [00:01<13:03,  1.96s/it]Running loglikelihood requests:   0%|          | 2/400 [00:03<11:18,  1.71s/it]Running loglikelihood requests:   1%|          | 3/400 [00:05<10:43,  1.62s/it]Running loglikelihood requests:   1%|          | 4/400 [00:06<10:25,  1.58s/it]Running loglikelihood requests:   1%|▏         | 5/400 [00:08<10:15,  1.56s/it]Running loglikelihood requests:   2%|▏         | 6/400 [00:09<10:08,  1.55s/it]Running loglikelihood requests:   2%|▏         | 7/400 [00:11<10:03,  1.54s/it]Running loglikelihood requests:   2%|▏         | 8/400 [00:12<09:59,  1.53s/it]Running loglikelihood requests:   2%|▏         | 9/400 [00:14<09:56,  1.53s/it]Running loglikelihood requests:   2%|▎         | 10/400 [00:15<09:52,  1.52s/it]Running loglikelihood requests:   3%|▎         | 11/400 [00:17<09:49,  1.52s/it]Running loglikelihood requests:   3%|▎         | 12/400 [00:18<09:46,  1.51s/it]Running loglikelihood requests:   3%|▎         | 13/400 [00:20<09:44,  1.51s/it]Running loglikelihood requests:   4%|▎         | 14/400 [00:21<09:42,  1.51s/it]Running loglikelihood requests:   4%|▍         | 15/400 [00:23<09:40,  1.51s/it]Running loglikelihood requests:   4%|▍         | 16/400 [00:24<09:38,  1.51s/it]Running loglikelihood requests:   4%|▍         | 17/400 [00:26<09:36,  1.51s/it]Running loglikelihood requests:   4%|▍         | 18/400 [00:27<09:34,  1.50s/it]Running loglikelihood requests:   5%|▍         | 19/400 [00:29<09:32,  1.50s/it]Running loglikelihood requests:   5%|▌         | 20/400 [00:30<09:30,  1.50s/it]Running loglikelihood requests:   5%|▌         | 21/400 [00:32<09:28,  1.50s/it]Running loglikelihood requests:   6%|▌         | 22/400 [00:33<09:27,  1.50s/it]Running loglikelihood requests:   6%|▌         | 23/400 [00:35<09:25,  1.50s/it]Running loglikelihood requests:   6%|▌         | 24/400 [00:36<09:23,  1.50s/it]Running loglikelihood requests:   6%|▋         | 25/400 [00:38<09:21,  1.50s/it]Running loglikelihood requests:   6%|▋         | 26/400 [00:39<09:19,  1.50s/it]Running loglikelihood requests:   7%|▋         | 27/400 [00:41<09:17,  1.49s/it]Running loglikelihood requests:   7%|▋         | 28/400 [00:42<09:15,  1.49s/it]Running loglikelihood requests:   7%|▋         | 29/400 [00:44<09:13,  1.49s/it]Running loglikelihood requests:   8%|▊         | 30/400 [00:45<09:11,  1.49s/it]Running loglikelihood requests:   8%|▊         | 31/400 [00:47<09:10,  1.49s/it]Running loglikelihood requests:   8%|▊         | 32/400 [00:48<09:08,  1.49s/it]Running loglikelihood requests:   8%|▊         | 33/400 [00:50<09:06,  1.49s/it]Running loglikelihood requests:   8%|▊         | 34/400 [00:51<09:05,  1.49s/it]Running loglikelihood requests:   9%|▉         | 35/400 [00:53<09:03,  1.49s/it]Running loglikelihood requests:   9%|▉         | 36/400 [00:54<09:01,  1.49s/it]Running loglikelihood requests:   9%|▉         | 37/400 [00:56<09:00,  1.49s/it]Running loglikelihood requests:  10%|▉         | 38/400 [00:57<08:58,  1.49s/it]Running loglikelihood requests:  10%|▉         | 39/400 [00:58<08:56,  1.49s/it]Running loglikelihood requests:  10%|█         | 40/400 [01:00<08:55,  1.49s/it]Running loglikelihood requests:  10%|█         | 41/400 [01:01<08:53,  1.49s/it]Running loglikelihood requests:  10%|█         | 42/400 [01:03<08:51,  1.48s/it]Running loglikelihood requests:  11%|█         | 43/400 [01:04<08:49,  1.48s/it]Running loglikelihood requests:  11%|█         | 44/400 [01:06<08:48,  1.48s/it]Running loglikelihood requests:  11%|█▏        | 45/400 [01:07<08:46,  1.48s/it]Running loglikelihood requests:  12%|█▏        | 46/400 [01:09<08:44,  1.48s/it]Running loglikelihood requests:  12%|█▏        | 47/400 [01:10<08:43,  1.48s/it]Running loglikelihood requests:  12%|█▏        | 48/400 [01:12<08:41,  1.48s/it]Running loglikelihood requests:  12%|█▏        | 49/400 [01:13<08:39,  1.48s/it]Running loglikelihood requests:  12%|█▎        | 50/400 [01:15<08:38,  1.48s/it]Running loglikelihood requests:  13%|█▎        | 51/400 [01:16<08:36,  1.48s/it]Running loglikelihood requests:  13%|█▎        | 52/400 [01:18<08:34,  1.48s/it]Running loglikelihood requests:  13%|█▎        | 53/400 [01:19<08:32,  1.48s/it]Running loglikelihood requests:  14%|█▎        | 54/400 [01:21<08:31,  1.48s/it]Running loglikelihood requests:  14%|█▍        | 55/400 [01:22<08:29,  1.48s/it]Running loglikelihood requests:  14%|█▍        | 56/400 [01:24<08:27,  1.48s/it]Running loglikelihood requests:  14%|█▍        | 57/400 [01:25<08:26,  1.48s/it]Running loglikelihood requests:  14%|█▍        | 58/400 [01:27<08:25,  1.48s/it]Running loglikelihood requests:  15%|█▍        | 59/400 [01:28<08:23,  1.48s/it]Running loglikelihood requests:  15%|█▌        | 60/400 [01:30<08:21,  1.48s/it]Running loglikelihood requests:  15%|█▌        | 61/400 [01:31<08:20,  1.48s/it]Running loglikelihood requests:  16%|█▌        | 62/400 [01:32<08:19,  1.48s/it]Running loglikelihood requests:  16%|█▌        | 63/400 [01:34<08:17,  1.48s/it]Running loglikelihood requests:  16%|█▌        | 64/400 [01:35<08:16,  1.48s/it]Running loglikelihood requests:  16%|█▋        | 65/400 [01:37<08:14,  1.48s/it]Running loglikelihood requests:  16%|█▋        | 66/400 [01:38<08:12,  1.47s/it]Running loglikelihood requests:  17%|█▋        | 67/400 [01:40<08:10,  1.47s/it]Running loglikelihood requests:  17%|█▋        | 68/400 [01:41<08:09,  1.47s/it]Running loglikelihood requests:  17%|█▋        | 69/400 [01:43<08:07,  1.47s/it]Running loglikelihood requests:  18%|█▊        | 71/400 [01:44<06:13,  1.13s/it]Running loglikelihood requests:  18%|█▊        | 72/400 [01:46<06:39,  1.22s/it]Running loglikelihood requests:  18%|█▊        | 73/400 [01:47<06:59,  1.28s/it]Running loglikelihood requests:  18%|█▊        | 74/400 [01:49<07:14,  1.33s/it]Running loglikelihood requests:  19%|█▉        | 75/400 [01:50<07:25,  1.37s/it]Running loglikelihood requests:  19%|█▉        | 76/400 [01:52<07:32,  1.40s/it]Running loglikelihood requests:  19%|█▉        | 77/400 [01:53<07:37,  1.42s/it]Running loglikelihood requests:  20%|█▉        | 78/400 [01:55<07:40,  1.43s/it]Running loglikelihood requests:  20%|█▉        | 79/400 [01:56<07:42,  1.44s/it]Running loglikelihood requests:  20%|██        | 80/400 [01:57<07:42,  1.45s/it]Running loglikelihood requests:  20%|██        | 81/400 [01:59<07:42,  1.45s/it]Running loglikelihood requests:  20%|██        | 82/400 [02:00<07:42,  1.45s/it]Running loglikelihood requests:  21%|██        | 83/400 [02:02<07:41,  1.46s/it]Running loglikelihood requests:  21%|██        | 84/400 [02:03<07:40,  1.46s/it]Running loglikelihood requests:  21%|██▏       | 85/400 [02:05<07:38,  1.46s/it]Running loglikelihood requests:  22%|██▏       | 86/400 [02:06<07:37,  1.46s/it]Running loglikelihood requests:  22%|██▏       | 87/400 [02:08<07:36,  1.46s/it]Running loglikelihood requests:  22%|██▏       | 88/400 [02:09<07:34,  1.46s/it]Running loglikelihood requests:  22%|██▏       | 89/400 [02:11<07:33,  1.46s/it]Running loglikelihood requests:  22%|██▎       | 90/400 [02:12<07:31,  1.46s/it]Running loglikelihood requests:  23%|██▎       | 91/400 [02:14<07:29,  1.46s/it]Running loglikelihood requests:  23%|██▎       | 92/400 [02:15<07:27,  1.45s/it]Running loglikelihood requests:  23%|██▎       | 93/400 [02:16<07:26,  1.45s/it]Running loglikelihood requests:  24%|██▎       | 94/400 [02:18<07:25,  1.46s/it]Running loglikelihood requests:  24%|██▍       | 95/400 [02:19<07:23,  1.45s/it]Running loglikelihood requests:  24%|██▍       | 96/400 [02:21<07:21,  1.45s/it]Running loglikelihood requests:  24%|██▍       | 97/400 [02:22<07:19,  1.45s/it]Running loglikelihood requests:  24%|██▍       | 98/400 [02:24<07:18,  1.45s/it]Running loglikelihood requests:  25%|██▍       | 99/400 [02:25<07:17,  1.45s/it]Running loglikelihood requests:  25%|██▌       | 100/400 [02:27<07:15,  1.45s/it]Running loglikelihood requests:  25%|██▌       | 101/400 [02:28<07:14,  1.45s/it]Running loglikelihood requests:  26%|██▌       | 102/400 [02:29<07:12,  1.45s/it]Running loglikelihood requests:  26%|██▌       | 103/400 [02:31<07:11,  1.45s/it]Running loglikelihood requests:  26%|██▌       | 104/400 [02:32<07:09,  1.45s/it]Running loglikelihood requests:  26%|██▋       | 105/400 [02:34<07:07,  1.45s/it]Running loglikelihood requests:  26%|██▋       | 106/400 [02:35<07:06,  1.45s/it]Running loglikelihood requests:  27%|██▋       | 107/400 [02:37<07:04,  1.45s/it]Running loglikelihood requests:  27%|██▋       | 108/400 [02:38<07:03,  1.45s/it]Running loglikelihood requests:  27%|██▋       | 109/400 [02:40<07:01,  1.45s/it]Running loglikelihood requests:  28%|██▊       | 110/400 [02:41<06:59,  1.45s/it]Running loglikelihood requests:  28%|██▊       | 111/400 [02:43<06:58,  1.45s/it]Running loglikelihood requests:  28%|██▊       | 112/400 [02:44<06:56,  1.45s/it]Running loglikelihood requests:  28%|██▊       | 113/400 [02:45<06:55,  1.45s/it]Running loglikelihood requests:  28%|██▊       | 114/400 [02:47<06:53,  1.44s/it]Running loglikelihood requests:  29%|██▉       | 115/400 [02:48<06:51,  1.44s/it]Running loglikelihood requests:  29%|██▉       | 116/400 [02:50<06:49,  1.44s/it]Running loglikelihood requests:  29%|██▉       | 117/400 [02:51<06:48,  1.44s/it]Running loglikelihood requests:  30%|██▉       | 118/400 [02:53<06:46,  1.44s/it]Running loglikelihood requests:  30%|██▉       | 119/400 [02:54<06:45,  1.44s/it]Running loglikelihood requests:  30%|███       | 120/400 [02:56<06:43,  1.44s/it]Running loglikelihood requests:  30%|███       | 121/400 [02:57<06:41,  1.44s/it]Running loglikelihood requests:  30%|███       | 122/400 [02:58<06:40,  1.44s/it]Running loglikelihood requests:  31%|███       | 123/400 [03:00<06:38,  1.44s/it]Running loglikelihood requests:  31%|███       | 124/400 [03:01<06:37,  1.44s/it]Running loglikelihood requests:  31%|███▏      | 125/400 [03:03<06:36,  1.44s/it]Running loglikelihood requests:  32%|███▏      | 126/400 [03:04<06:34,  1.44s/it]Running loglikelihood requests:  32%|███▏      | 127/400 [03:06<06:33,  1.44s/it]Running loglikelihood requests:  32%|███▏      | 128/400 [03:07<06:31,  1.44s/it]Running loglikelihood requests:  32%|███▏      | 129/400 [03:08<06:29,  1.44s/it]Running loglikelihood requests:  32%|███▎      | 130/400 [03:10<06:27,  1.44s/it]Running loglikelihood requests:  33%|███▎      | 131/400 [03:11<06:25,  1.43s/it]Running loglikelihood requests:  33%|███▎      | 132/400 [03:13<06:24,  1.43s/it]Running loglikelihood requests:  33%|███▎      | 133/400 [03:14<06:23,  1.44s/it]Running loglikelihood requests:  34%|███▎      | 134/400 [03:16<06:21,  1.44s/it]Running loglikelihood requests:  34%|███▍      | 135/400 [03:17<06:20,  1.44s/it]Running loglikelihood requests:  34%|███▍      | 136/400 [03:19<06:19,  1.44s/it]Running loglikelihood requests:  34%|███▍      | 137/400 [03:20<06:17,  1.43s/it]Running loglikelihood requests:  34%|███▍      | 138/400 [03:21<06:15,  1.43s/it]Running loglikelihood requests:  35%|███▍      | 139/400 [03:23<06:13,  1.43s/it]Running loglikelihood requests:  35%|███▌      | 140/400 [03:24<06:12,  1.43s/it]Running loglikelihood requests:  35%|███▌      | 141/400 [03:26<06:10,  1.43s/it]Running loglikelihood requests:  36%|███▌      | 142/400 [03:27<06:09,  1.43s/it]Running loglikelihood requests:  36%|███▌      | 143/400 [03:29<06:07,  1.43s/it]Running loglikelihood requests:  36%|███▌      | 144/400 [03:30<06:05,  1.43s/it]Running loglikelihood requests:  36%|███▋      | 145/400 [03:31<06:03,  1.43s/it]Running loglikelihood requests:  36%|███▋      | 146/400 [03:33<06:02,  1.43s/it]Running loglikelihood requests:  37%|███▋      | 147/400 [03:34<06:00,  1.43s/it]Running loglikelihood requests:  37%|███▋      | 148/400 [03:36<05:58,  1.42s/it]Running loglikelihood requests:  37%|███▋      | 149/400 [03:37<05:56,  1.42s/it]Running loglikelihood requests:  38%|███▊      | 150/400 [03:38<05:55,  1.42s/it]Running loglikelihood requests:  38%|███▊      | 151/400 [03:40<05:53,  1.42s/it]Running loglikelihood requests:  38%|███▊      | 152/400 [03:41<05:52,  1.42s/it]Running loglikelihood requests:  38%|███▊      | 153/400 [03:43<05:50,  1.42s/it]Running loglikelihood requests:  38%|███▊      | 154/400 [03:44<05:48,  1.42s/it]Running loglikelihood requests:  39%|███▉      | 155/400 [03:46<05:47,  1.42s/it]Running loglikelihood requests:  39%|███▉      | 156/400 [03:47<05:46,  1.42s/it]Running loglikelihood requests:  39%|███▉      | 157/400 [03:48<05:44,  1.42s/it]Running loglikelihood requests:  40%|███▉      | 158/400 [03:50<05:42,  1.42s/it]Running loglikelihood requests:  40%|███▉      | 159/400 [03:51<05:41,  1.42s/it]Running loglikelihood requests:  40%|████      | 160/400 [03:53<05:39,  1.42s/it]Running loglikelihood requests:  40%|████      | 161/400 [03:54<05:37,  1.41s/it]Running loglikelihood requests:  40%|████      | 162/400 [03:55<05:36,  1.41s/it]Running loglikelihood requests:  41%|████      | 163/400 [03:57<05:34,  1.41s/it]Running loglikelihood requests:  41%|████      | 164/400 [03:58<05:33,  1.41s/it]Running loglikelihood requests:  41%|████▏     | 165/400 [04:00<05:31,  1.41s/it]Running loglikelihood requests:  42%|████▏     | 166/400 [04:01<05:30,  1.41s/it]Running loglikelihood requests:  42%|████▏     | 167/400 [04:03<05:28,  1.41s/it]Running loglikelihood requests:  42%|████▏     | 168/400 [04:04<05:27,  1.41s/it]Running loglikelihood requests:  42%|████▏     | 169/400 [04:05<05:25,  1.41s/it]Running loglikelihood requests:  42%|████▎     | 170/400 [04:07<05:24,  1.41s/it]Running loglikelihood requests:  43%|████▎     | 171/400 [04:08<05:22,  1.41s/it]Running loglikelihood requests:  43%|████▎     | 172/400 [04:10<05:21,  1.41s/it]Running loglikelihood requests:  43%|████▎     | 173/400 [04:11<05:20,  1.41s/it]Running loglikelihood requests:  44%|████▎     | 174/400 [04:12<05:18,  1.41s/it]Running loglikelihood requests:  44%|████▍     | 175/400 [04:14<05:16,  1.41s/it]Running loglikelihood requests:  44%|████▍     | 176/400 [04:15<05:15,  1.41s/it]Running loglikelihood requests:  44%|████▍     | 177/400 [04:17<05:13,  1.41s/it]Running loglikelihood requests:  44%|████▍     | 178/400 [04:18<05:12,  1.41s/it]Running loglikelihood requests:  45%|████▍     | 179/400 [04:19<05:10,  1.41s/it]Running loglikelihood requests:  45%|████▌     | 180/400 [04:21<05:09,  1.41s/it]Running loglikelihood requests:  45%|████▌     | 181/400 [04:22<05:08,  1.41s/it]Running loglikelihood requests:  46%|████▌     | 182/400 [04:24<05:06,  1.40s/it]Running loglikelihood requests:  46%|████▌     | 183/400 [04:25<05:04,  1.40s/it]Running loglikelihood requests:  46%|████▌     | 184/400 [04:26<05:03,  1.40s/it]Running loglikelihood requests:  46%|████▋     | 185/400 [04:28<05:01,  1.40s/it]Running loglikelihood requests:  46%|████▋     | 186/400 [04:29<05:00,  1.40s/it]Running loglikelihood requests:  47%|████▋     | 187/400 [04:31<04:58,  1.40s/it]Running loglikelihood requests:  47%|████▋     | 188/400 [04:32<04:56,  1.40s/it]Running loglikelihood requests:  47%|████▋     | 189/400 [04:33<04:55,  1.40s/it]Running loglikelihood requests:  48%|████▊     | 190/400 [04:35<04:53,  1.40s/it]Running loglikelihood requests:  48%|████▊     | 191/400 [04:36<04:52,  1.40s/it]Running loglikelihood requests:  48%|████▊     | 192/400 [04:38<04:50,  1.40s/it]Running loglikelihood requests:  48%|████▊     | 193/400 [04:39<04:49,  1.40s/it]Running loglikelihood requests:  48%|████▊     | 194/400 [04:40<04:48,  1.40s/it]Running loglikelihood requests:  49%|████▉     | 195/400 [04:42<04:46,  1.40s/it]Running loglikelihood requests:  49%|████▉     | 196/400 [04:43<04:44,  1.40s/it]Running loglikelihood requests:  49%|████▉     | 197/400 [04:45<04:43,  1.39s/it]Running loglikelihood requests:  50%|████▉     | 198/400 [04:46<04:41,  1.39s/it]Running loglikelihood requests:  50%|████▉     | 199/400 [04:47<04:40,  1.39s/it]Running loglikelihood requests:  50%|█████     | 200/400 [04:49<04:38,  1.39s/it]Running loglikelihood requests:  50%|█████     | 201/400 [04:50<04:37,  1.39s/it]Running loglikelihood requests:  50%|█████     | 202/400 [04:52<04:35,  1.39s/it]Running loglikelihood requests:  51%|█████     | 203/400 [04:53<04:33,  1.39s/it]Running loglikelihood requests:  51%|█████     | 204/400 [04:54<04:32,  1.39s/it]Running loglikelihood requests:  51%|█████▏    | 205/400 [04:56<04:30,  1.39s/it]Running loglikelihood requests:  52%|█████▏    | 206/400 [04:57<04:29,  1.39s/it]Running loglikelihood requests:  52%|█████▏    | 207/400 [04:58<04:27,  1.39s/it]Running loglikelihood requests:  52%|█████▏    | 208/400 [05:00<04:26,  1.39s/it]Running loglikelihood requests:  52%|█████▏    | 209/400 [05:01<04:25,  1.39s/it]Running loglikelihood requests:  52%|█████▎    | 210/400 [05:03<04:23,  1.39s/it]Running loglikelihood requests:  53%|█████▎    | 211/400 [05:04<04:22,  1.39s/it]Running loglikelihood requests:  53%|█████▎    | 212/400 [05:05<04:20,  1.39s/it]Running loglikelihood requests:  53%|█████▎    | 213/400 [05:07<04:18,  1.38s/it]Running loglikelihood requests:  54%|█████▎    | 214/400 [05:08<04:16,  1.38s/it]Running loglikelihood requests:  54%|█████▍    | 215/400 [05:10<04:14,  1.38s/it]Running loglikelihood requests:  54%|█████▍    | 216/400 [05:11<04:13,  1.38s/it]Running loglikelihood requests:  54%|█████▍    | 217/400 [05:12<04:11,  1.38s/it]Running loglikelihood requests:  55%|█████▍    | 218/400 [05:14<04:10,  1.38s/it]Running loglikelihood requests:  55%|█████▍    | 219/400 [05:15<04:08,  1.38s/it]Running loglikelihood requests:  55%|█████▌    | 220/400 [05:16<04:07,  1.37s/it]Running loglikelihood requests:  55%|█████▌    | 221/400 [05:18<04:05,  1.37s/it]Running loglikelihood requests:  56%|█████▌    | 222/400 [05:19<04:03,  1.37s/it]Running loglikelihood requests:  56%|█████▌    | 223/400 [05:21<04:02,  1.37s/it]Running loglikelihood requests:  56%|█████▌    | 224/400 [05:22<04:01,  1.37s/it]Running loglikelihood requests:  56%|█████▋    | 225/400 [05:23<03:59,  1.37s/it]Running loglikelihood requests:  56%|█████▋    | 226/400 [05:25<03:57,  1.37s/it]Running loglikelihood requests:  57%|█████▋    | 227/400 [05:26<03:56,  1.37s/it]Running loglikelihood requests:  57%|█████▋    | 228/400 [05:27<03:55,  1.37s/it]Running loglikelihood requests:  57%|█████▋    | 229/400 [05:29<03:52,  1.36s/it]Running loglikelihood requests:  57%|█████▊    | 230/400 [05:30<03:51,  1.36s/it]Running loglikelihood requests:  58%|█████▊    | 231/400 [05:31<03:49,  1.36s/it]Running loglikelihood requests:  58%|█████▊    | 232/400 [05:33<03:47,  1.35s/it]Running loglikelihood requests:  58%|█████▊    | 233/400 [05:34<03:46,  1.35s/it]Running loglikelihood requests:  58%|█████▊    | 234/400 [05:35<03:44,  1.35s/it]Running loglikelihood requests:  59%|█████▉    | 235/400 [05:37<03:43,  1.35s/it]Running loglikelihood requests:  59%|█████▉    | 236/400 [05:38<03:41,  1.35s/it]Running loglikelihood requests:  59%|█████▉    | 237/400 [05:40<03:40,  1.35s/it]Running loglikelihood requests:  60%|█████▉    | 238/400 [05:41<03:38,  1.35s/it]Running loglikelihood requests:  60%|█████▉    | 239/400 [05:42<03:36,  1.35s/it]Running loglikelihood requests:  60%|██████    | 240/400 [05:44<03:35,  1.35s/it]Running loglikelihood requests:  60%|██████    | 241/400 [05:45<03:33,  1.34s/it]Running loglikelihood requests:  60%|██████    | 242/400 [05:46<03:31,  1.34s/it]Running loglikelihood requests:  61%|██████    | 243/400 [05:48<03:30,  1.34s/it]Running loglikelihood requests:  61%|██████    | 244/400 [05:49<03:28,  1.34s/it]Running loglikelihood requests:  61%|██████▏   | 245/400 [05:50<03:27,  1.34s/it]Running loglikelihood requests:  62%|██████▏   | 246/400 [05:52<03:25,  1.33s/it]Running loglikelihood requests:  62%|██████▏   | 247/400 [05:53<03:23,  1.33s/it]Running loglikelihood requests:  62%|██████▏   | 248/400 [05:54<03:22,  1.33s/it]Running loglikelihood requests:  62%|██████▏   | 249/400 [05:56<03:20,  1.33s/it]Running loglikelihood requests:  62%|██████▎   | 250/400 [05:57<03:19,  1.33s/it]Running loglikelihood requests:  63%|██████▎   | 251/400 [05:58<03:17,  1.33s/it]Running loglikelihood requests:  63%|██████▎   | 252/400 [06:00<03:16,  1.33s/it]Running loglikelihood requests:  63%|██████▎   | 253/400 [06:01<03:14,  1.33s/it]Running loglikelihood requests:  64%|██████▎   | 254/400 [06:02<03:13,  1.33s/it]Running loglikelihood requests:  64%|██████▍   | 255/400 [06:03<03:11,  1.32s/it]Running loglikelihood requests:  64%|██████▍   | 256/400 [06:05<03:10,  1.32s/it]Running loglikelihood requests:  64%|██████▍   | 257/400 [06:06<03:08,  1.32s/it]Running loglikelihood requests:  64%|██████▍   | 258/400 [06:07<03:07,  1.32s/it]Running loglikelihood requests:  65%|██████▍   | 259/400 [06:09<03:05,  1.32s/it]Running loglikelihood requests:  65%|██████▌   | 260/400 [06:10<03:04,  1.32s/it]Running loglikelihood requests:  65%|██████▌   | 261/400 [06:11<03:02,  1.31s/it]Running loglikelihood requests:  66%|██████▌   | 262/400 [06:13<03:01,  1.31s/it]Running loglikelihood requests:  66%|██████▌   | 263/400 [06:14<02:59,  1.31s/it]Running loglikelihood requests:  66%|██████▌   | 264/400 [06:15<02:58,  1.31s/it]Running loglikelihood requests:  66%|██████▋   | 265/400 [06:17<02:57,  1.31s/it]Running loglikelihood requests:  66%|██████▋   | 266/400 [06:18<02:55,  1.31s/it]Running loglikelihood requests:  67%|██████▋   | 267/400 [06:19<02:53,  1.31s/it]Running loglikelihood requests:  67%|██████▋   | 268/400 [06:21<02:52,  1.31s/it]Running loglikelihood requests:  67%|██████▋   | 269/400 [06:22<02:51,  1.31s/it]Running loglikelihood requests:  68%|██████▊   | 270/400 [06:23<02:49,  1.31s/it]Running loglikelihood requests:  68%|██████▊   | 271/400 [06:24<02:48,  1.31s/it]Running loglikelihood requests:  68%|██████▊   | 272/400 [06:26<02:47,  1.31s/it]Running loglikelihood requests:  68%|██████▊   | 273/400 [06:27<02:45,  1.31s/it]Running loglikelihood requests:  68%|██████▊   | 274/400 [06:28<02:44,  1.31s/it]Running loglikelihood requests:  69%|██████▉   | 275/400 [06:30<02:43,  1.30s/it]Running loglikelihood requests:  69%|██████▉   | 276/400 [06:31<02:41,  1.30s/it]Running loglikelihood requests:  69%|██████▉   | 277/400 [06:32<02:40,  1.30s/it]Running loglikelihood requests:  70%|██████▉   | 278/400 [06:34<02:38,  1.30s/it]Running loglikelihood requests:  70%|██████▉   | 279/400 [06:35<02:37,  1.30s/it]Running loglikelihood requests:  70%|███████   | 280/400 [06:36<02:36,  1.30s/it]Running loglikelihood requests:  70%|███████   | 281/400 [06:37<02:34,  1.30s/it]Running loglikelihood requests:  70%|███████   | 282/400 [06:39<02:33,  1.30s/it]Running loglikelihood requests:  71%|███████   | 283/400 [06:40<02:31,  1.30s/it]Running loglikelihood requests:  71%|███████   | 284/400 [06:41<02:30,  1.30s/it]Running loglikelihood requests:  71%|███████▏  | 285/400 [06:43<02:29,  1.30s/it]Running loglikelihood requests:  72%|███████▏  | 286/400 [06:44<02:27,  1.30s/it]Running loglikelihood requests:  72%|███████▏  | 287/400 [06:45<02:26,  1.30s/it]Running loglikelihood requests:  72%|███████▏  | 288/400 [06:47<02:25,  1.30s/it]Running loglikelihood requests:  72%|███████▏  | 289/400 [06:48<02:23,  1.30s/it]Running loglikelihood requests:  72%|███████▎  | 290/400 [06:49<02:22,  1.30s/it]Running loglikelihood requests:  73%|███████▎  | 291/400 [06:50<02:21,  1.30s/it]Running loglikelihood requests:  73%|███████▎  | 292/400 [06:52<02:19,  1.30s/it]Running loglikelihood requests:  73%|███████▎  | 293/400 [06:53<02:18,  1.29s/it]Running loglikelihood requests:  74%|███████▎  | 294/400 [06:54<02:16,  1.29s/it]Running loglikelihood requests:  74%|███████▍  | 295/400 [06:56<02:15,  1.29s/it]Running loglikelihood requests:  74%|███████▍  | 296/400 [06:57<02:13,  1.29s/it]Running loglikelihood requests:  74%|███████▍  | 297/400 [06:58<02:12,  1.29s/it]Running loglikelihood requests:  74%|███████▍  | 298/400 [06:59<02:10,  1.28s/it]Running loglikelihood requests:  75%|███████▍  | 299/400 [07:01<02:09,  1.28s/it]Running loglikelihood requests:  75%|███████▌  | 300/400 [07:02<02:08,  1.28s/it]Running loglikelihood requests:  75%|███████▌  | 301/400 [07:03<02:06,  1.28s/it]Running loglikelihood requests:  76%|███████▌  | 302/400 [07:05<02:05,  1.28s/it]Running loglikelihood requests:  76%|███████▌  | 303/400 [07:06<02:04,  1.28s/it]Running loglikelihood requests:  76%|███████▌  | 304/400 [07:07<02:02,  1.28s/it]Running loglikelihood requests:  76%|███████▋  | 305/400 [07:08<02:01,  1.28s/it]Running loglikelihood requests:  76%|███████▋  | 306/400 [07:10<01:59,  1.28s/it]Running loglikelihood requests:  77%|███████▋  | 307/400 [07:11<01:58,  1.27s/it]Running loglikelihood requests:  77%|███████▋  | 308/400 [07:12<01:57,  1.27s/it]Running loglikelihood requests:  77%|███████▋  | 309/400 [07:13<01:55,  1.27s/it]Running loglikelihood requests:  78%|███████▊  | 310/400 [07:15<01:54,  1.27s/it]Running loglikelihood requests:  78%|███████▊  | 311/400 [07:16<01:53,  1.27s/it]Running loglikelihood requests:  78%|███████▊  | 312/400 [07:17<01:51,  1.27s/it]Running loglikelihood requests:  78%|███████▊  | 313/400 [07:19<01:50,  1.27s/it]Running loglikelihood requests:  78%|███████▊  | 314/400 [07:20<01:49,  1.27s/it]Running loglikelihood requests:  79%|███████▉  | 315/400 [07:21<01:47,  1.27s/it]Running loglikelihood requests:  79%|███████▉  | 316/400 [07:22<01:46,  1.27s/it]Running loglikelihood requests:  79%|███████▉  | 317/400 [07:24<01:45,  1.27s/it]Running loglikelihood requests:  80%|███████▉  | 318/400 [07:25<01:44,  1.27s/it]Running loglikelihood requests:  80%|███████▉  | 319/400 [07:26<01:42,  1.27s/it]Running loglikelihood requests:  80%|████████  | 320/400 [07:27<01:41,  1.27s/it]Running loglikelihood requests:  80%|████████  | 321/400 [07:29<01:39,  1.27s/it]Running loglikelihood requests:  80%|████████  | 322/400 [07:30<01:38,  1.26s/it]Running loglikelihood requests:  81%|████████  | 323/400 [07:31<01:37,  1.27s/it]Running loglikelihood requests:  81%|████████  | 324/400 [07:32<01:36,  1.26s/it]Running loglikelihood requests:  81%|████████▏ | 325/400 [07:34<01:34,  1.26s/it]Running loglikelihood requests:  82%|████████▏ | 326/400 [07:35<01:33,  1.26s/it]Running loglikelihood requests:  82%|████████▏ | 327/400 [07:36<01:32,  1.26s/it]Running loglikelihood requests:  82%|████████▏ | 328/400 [07:37<01:30,  1.26s/it]Running loglikelihood requests:  82%|████████▏ | 329/400 [07:39<01:29,  1.26s/it]Running loglikelihood requests:  82%|████████▎ | 330/400 [07:40<01:28,  1.26s/it]Running loglikelihood requests:  83%|████████▎ | 331/400 [07:41<01:26,  1.26s/it]Running loglikelihood requests:  83%|████████▎ | 332/400 [07:43<01:25,  1.26s/it]Running loglikelihood requests:  83%|████████▎ | 333/400 [07:44<01:24,  1.26s/it]Running loglikelihood requests:  84%|████████▎ | 334/400 [07:45<01:22,  1.26s/it]Running loglikelihood requests:  84%|████████▍ | 335/400 [07:46<01:21,  1.26s/it]Running loglikelihood requests:  84%|████████▍ | 336/400 [07:48<01:20,  1.26s/it]Running loglikelihood requests:  84%|████████▍ | 337/400 [07:49<01:19,  1.26s/it]Running loglikelihood requests:  84%|████████▍ | 338/400 [07:50<01:17,  1.26s/it]Running loglikelihood requests:  85%|████████▍ | 339/400 [07:51<01:16,  1.25s/it]Running loglikelihood requests:  85%|████████▌ | 340/400 [07:53<01:15,  1.25s/it]Running loglikelihood requests:  85%|████████▌ | 341/400 [07:54<01:13,  1.25s/it]Running loglikelihood requests:  86%|████████▌ | 342/400 [07:55<01:12,  1.25s/it]Running loglikelihood requests:  86%|████████▌ | 343/400 [07:56<01:11,  1.25s/it]Running loglikelihood requests:  86%|████████▌ | 344/400 [07:58<01:10,  1.25s/it]Running loglikelihood requests:  86%|████████▋ | 345/400 [07:59<01:08,  1.25s/it]Running loglikelihood requests:  86%|████████▋ | 346/400 [08:00<01:07,  1.25s/it]Running loglikelihood requests:  87%|████████▋ | 347/400 [08:01<01:06,  1.25s/it]Running loglikelihood requests:  87%|████████▋ | 348/400 [08:03<01:04,  1.25s/it]Running loglikelihood requests:  87%|████████▋ | 349/400 [08:04<01:03,  1.25s/it]Running loglikelihood requests:  88%|████████▊ | 350/400 [08:05<01:02,  1.25s/it]Running loglikelihood requests:  88%|████████▊ | 351/400 [08:06<01:01,  1.25s/it]Running loglikelihood requests:  88%|████████▊ | 352/400 [08:08<00:59,  1.25s/it]Running loglikelihood requests:  88%|████████▊ | 353/400 [08:09<00:58,  1.24s/it]Running loglikelihood requests:  88%|████████▊ | 354/400 [08:10<00:57,  1.24s/it]Running loglikelihood requests:  89%|████████▉ | 355/400 [08:11<00:55,  1.24s/it]Running loglikelihood requests:  89%|████████▉ | 356/400 [08:12<00:54,  1.24s/it]Running loglikelihood requests:  89%|████████▉ | 357/400 [08:14<00:53,  1.24s/it]Running loglikelihood requests:  90%|████████▉ | 358/400 [08:15<00:52,  1.24s/it]Running loglikelihood requests:  90%|████████▉ | 359/400 [08:16<00:50,  1.24s/it]Running loglikelihood requests:  90%|█████████ | 360/400 [08:17<00:49,  1.24s/it]Running loglikelihood requests:  90%|█████████ | 361/400 [08:19<00:48,  1.24s/it]Running loglikelihood requests:  90%|█████████ | 362/400 [08:20<00:47,  1.24s/it]Running loglikelihood requests:  91%|█████████ | 363/400 [08:21<00:45,  1.24s/it]Running loglikelihood requests:  91%|█████████ | 364/400 [08:22<00:44,  1.24s/it]Running loglikelihood requests:  91%|█████████▏| 365/400 [08:24<00:43,  1.24s/it]Running loglikelihood requests:  92%|█████████▏| 366/400 [08:25<00:42,  1.24s/it]Running loglikelihood requests:  92%|█████████▏| 367/400 [08:26<00:40,  1.24s/it]Running loglikelihood requests:  92%|█████████▏| 368/400 [08:27<00:39,  1.24s/it]Running loglikelihood requests:  92%|█████████▏| 369/400 [08:29<00:38,  1.23s/it]Running loglikelihood requests:  92%|█████████▎| 370/400 [08:30<00:37,  1.23s/it]Running loglikelihood requests:  93%|█████████▎| 371/400 [08:31<00:35,  1.23s/it]Running loglikelihood requests:  93%|█████████▎| 372/400 [08:32<00:34,  1.23s/it]Running loglikelihood requests:  93%|█████████▎| 373/400 [08:33<00:33,  1.23s/it]Running loglikelihood requests:  94%|█████████▎| 374/400 [08:35<00:31,  1.23s/it]Running loglikelihood requests:  94%|█████████▍| 375/400 [08:36<00:30,  1.23s/it]Running loglikelihood requests:  94%|█████████▍| 376/400 [08:37<00:29,  1.22s/it]Running loglikelihood requests:  94%|█████████▍| 377/400 [08:38<00:28,  1.22s/it]Running loglikelihood requests:  94%|█████████▍| 378/400 [08:40<00:26,  1.22s/it]Running loglikelihood requests:  95%|█████████▍| 379/400 [08:41<00:25,  1.22s/it]Running loglikelihood requests:  95%|█████████▌| 380/400 [08:42<00:24,  1.21s/it]Running loglikelihood requests:  95%|█████████▌| 381/400 [08:43<00:23,  1.21s/it]Running loglikelihood requests:  96%|█████████▌| 382/400 [08:44<00:21,  1.21s/it]Running loglikelihood requests:  96%|█████████▌| 383/400 [08:46<00:20,  1.21s/it]Running loglikelihood requests:  96%|█████████▌| 384/400 [08:47<00:19,  1.20s/it]Running loglikelihood requests:  96%|█████████▋| 385/400 [08:48<00:17,  1.19s/it]Running loglikelihood requests:  96%|█████████▋| 386/400 [08:49<00:16,  1.19s/it]Running loglikelihood requests:  97%|█████████▋| 387/400 [08:50<00:15,  1.18s/it]Running loglikelihood requests:  97%|█████████▋| 388/400 [08:51<00:14,  1.18s/it]Running loglikelihood requests:  97%|█████████▋| 389/400 [08:53<00:12,  1.15s/it]Running loglikelihood requests:  98%|█████████▊| 390/400 [08:54<00:11,  1.13s/it]Running loglikelihood requests:  98%|█████████▊| 391/400 [08:55<00:10,  1.12s/it]Running loglikelihood requests:  98%|█████████▊| 392/400 [08:56<00:08,  1.11s/it]Running loglikelihood requests:  98%|█████████▊| 393/400 [08:57<00:07,  1.09s/it]Running loglikelihood requests:  98%|█████████▊| 394/400 [08:58<00:06,  1.08s/it]Running loglikelihood requests:  99%|█████████▉| 395/400 [08:59<00:05,  1.08s/it]Running loglikelihood requests:  99%|█████████▉| 396/400 [09:00<00:04,  1.07s/it]Running loglikelihood requests:  99%|█████████▉| 397/400 [09:01<00:03,  1.05s/it]Running loglikelihood requests: 100%|█████████▉| 398/400 [09:02<00:02,  1.04s/it]Running loglikelihood requests: 100%|█████████▉| 399/400 [09:03<00:01,  1.03s/it]Running loglikelihood requests: 100%|██████████| 400/400 [09:04<00:00,  1.02s/it]Running loglikelihood requests: 100%|██████████| 400/400 [09:04<00:00,  1.36s/it]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:3'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:3'}
full model:
{'mastermind_46_easy': {'alias': 'mastermind_46_easy', 'acc,none': 0.75, 'acc_stderr,none': 0.04351941398892446}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9900730655060652
0.9975621416797388
0.9971758007187725
0.9980230222224056
0.9889479987910904
0.9764864248764976
0.9903944102306983
0.9944743493554844
0.9959595842537624
0.9872350810596702
0.9630442697748985
0.9836939129473328
0.9680042833072414
0.9739989664157891
0.9945965755000291
0.9874567967365809
0.9910190996776087
0.9888895436517939
0.9820307305549418
0.9881803990776891
0.9859944271811626
0.9931460182904469
0.984259193892523
0.99673879588459
0.9800909214289261
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[5, 2, 0, 3, 7, 6, 1, 4]
tensor([5, 2, 0, 3, 7, 6, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 0, 3, 7, 6, 1, 4]
tensor([5, 2, 0, 3, 7, 6, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 0, 3, 7, 6, 1, 4]
tensor([5, 2, 0, 3, 7, 6, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 0, 3, 7, 6, 1, 4]
tensor([5, 2, 0, 3, 7, 6, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 0, 3, 7, 6, 1, 4]
tensor([5, 2, 0, 3, 7, 6, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 0, 3, 7, 6, 1, 4]
tensor([5, 2, 0, 3, 7, 6, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Normal merging for layer 2
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Normal merging for layer 3
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Normal merging for layer 4
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Normal merging for layer 5
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 6 to 31
done!
all done!
Model size: 12.0718 GB
161
cuda:3
boolq
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:43<00:43, 43.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:57<00:00, 25.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:57<00:00, 28.57s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/super_glue/super_glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 237
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue/tree/3de24cf8022e94f4ee4b9d55a6f539891524d646/boolq?recursive=False&expand=False HTTP/1.1" 307 144
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue/tree/3de24cf8022e94f4ee4b9d55a6f539891524d646/boolq?recursive=False&expand=False HTTP/1.1" 200 355
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 237
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 237
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 237
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 237
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 237
DEBUG:filelock:Attempting to acquire lock 139727031359664 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_boolq_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 139727031359664 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_boolq_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Attempting to release lock 139727031359664 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_boolq_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 139727031359664 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_boolq_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Attempting to acquire lock 139722699523712 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/boolq/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 139722699523712 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/boolq/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): storage.googleapis.com:443
DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 "HEAD /huggingface-nlp/cache/datasets/super_glue/boolq/0.0.0/dataset_info.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 363
DEBUG:filelock:Attempting to acquire lock 139720655790464 on /public/home/zouyifei001/.cache/huggingface/datasets/downloads/403917ae5feafd995b0b845b229c339704e55972d7c0807a7110d1e03cebb4aa.lock
DEBUG:filelock:Lock 139720655790464 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/downloads/403917ae5feafd995b0b845b229c339704e55972d7c0807a7110d1e03cebb4aa.lock
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 363
Downloading data:   0%|          | 0.00/1.31M [00:00<?, ?B/s]DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/boolq/validation-00000-of-00001.parquet HTTP/1.1" 307 148
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/boolq/validation-00000-of-00001.parquet HTTP/1.1" 302 787
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): cdn-lfs.hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://cdn-lfs.hf-mirror.com:443 "GET /datasets/super_glue/f46438b8cce048184552a2bfcdb8252eadb3a2602f0c22334caccd9b6ea547d6?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27validation-00000-of-00001.parquet%3B+filename%3D%22validation-00000-of-00001.parquet%22%3B&Expires=1747510804&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NzUxMDgwNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9kYXRhc2V0cy9zdXBlcl9nbHVlL2Y0NjQzOGI4Y2NlMDQ4MTg0NTUyYTJiZmNkYjgyNTJlYWRiM2EyNjAyZjBjMjIzMzRjYWNjZDliNmVhNTQ3ZDY~cmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=dmsnneGXqCUc7v5v6SJBElLYAELGFJjnbYGjWDlHnHdwcUNnkeXSvKfs56i9zAjkGmHNr90DNyI0bFy0-wYe4y9h-mKyzNb0hrCmK7F-C~aYrUa3C2Z2oYH0BPUv6T7PWW70khBU~jrDM-U7Hx0vwD8ehI5Q91yDsJ7dg7BgYljCyck8wDpTT8pNGfiRi0m1MVThPBAYW6qk5RUDrZNdvWWJUSdWcowGzy9rWfu7mMS2UKB9U6Y6Q3a0jSRpgG9yfhxY-uU-AjPZHeqlkKa8JWH92GdwA4gtIgOkkHP3k463WTe~~KKik2~JgWdamBgeba4ti7twMLs5odSOJsnusA__&Key-Pair-Id=K3RPWS32NSSJCE HTTP/1.1" 200 1313731
Downloading data: 100%|██████████| 1.31M/1.31M [00:01<00:00, 1.29MB/s]Downloading data: 100%|██████████| 1.31M/1.31M [00:01<00:00, 1.29MB/s]
DEBUG:filelock:Attempting to release lock 139720655790464 on /public/home/zouyifei001/.cache/huggingface/datasets/downloads/403917ae5feafd995b0b845b229c339704e55972d7c0807a7110d1e03cebb4aa.lock
DEBUG:filelock:Lock 139720655790464 released on /public/home/zouyifei001/.cache/huggingface/datasets/downloads/403917ae5feafd995b0b845b229c339704e55972d7c0807a7110d1e03cebb4aa.lock
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 359
DEBUG:filelock:Attempting to acquire lock 139720654384416 on /public/home/zouyifei001/.cache/huggingface/datasets/downloads/089e908d31686e2bbc02ae34e24bcd2dcdadecd40b4e15d277221a37e84b35d5.lock
DEBUG:filelock:Lock 139720654384416 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/downloads/089e908d31686e2bbc02ae34e24bcd2dcdadecd40b4e15d277221a37e84b35d5.lock
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 359
Downloading data:   0%|          | 0.00/1.31M [00:00<?, ?B/s]DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/boolq/test-00000-of-00001.parquet HTTP/1.1" 307 142
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/boolq/test-00000-of-00001.parquet HTTP/1.1" 302 786
DEBUG:urllib3.connectionpool:https://cdn-lfs.hf-mirror.com:443 "GET /datasets/super_glue/95a74cd7c8fdbae1aa9ba767fa62993fcc2bd582ee5512f42a8c6c89b88a7c3d?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27test-00000-of-00001.parquet%3B+filename%3D%22test-00000-of-00001.parquet%22%3B&Expires=1747510806&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NzUxMDgwNn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9kYXRhc2V0cy9zdXBlcl9nbHVlLzk1YTc0Y2Q3YzhmZGJhZTFhYTliYTc2N2ZhNjI5OTNmY2MyYmQ1ODJlZTU1MTJmNDJhOGM2Yzg5Yjg4YTdjM2Q~cmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=SOMYNNy2CdoxVr8rX~3NS7xkgkMV5dWCg3PuZXfQm25SSo9NARGKgnVK75UkOK5sOcr5d7K5MRIxdsK0tEA3E-kK9B6J9CG4djPsW22I~gpwi3~7Dj0pUGjZrMAP674uKCnOWExI1HZdM8qO9rzH-q7tdopE1DXMFjgdu75rq6BKfxqXwEm1cBmc6fZ9bZD5TQxX2E06S3EOTYqbhjqMyICY~arZruLj6qOekmDYSwEWGEhxCwQnZRXukn3vVIiGJH~-bE5sA-XLll7Mn7XZyZ0D7oDJy4I-j~~K6IPGh6Kx64tf99pjEr5fBbwXiiE3GTGf6qooBalwOPtmc1lSZQ__&Key-Pair-Id=K3RPWS32NSSJCE HTTP/1.1" 200 1309912
Downloading data: 100%|██████████| 1.31M/1.31M [00:00<00:00, 2.24MB/s]Downloading data: 100%|██████████| 1.31M/1.31M [00:00<00:00, 2.23MB/s]
DEBUG:filelock:Attempting to release lock 139720654384416 on /public/home/zouyifei001/.cache/huggingface/datasets/downloads/089e908d31686e2bbc02ae34e24bcd2dcdadecd40b4e15d277221a37e84b35d5.lock
DEBUG:filelock:Lock 139720654384416 released on /public/home/zouyifei001/.cache/huggingface/datasets/downloads/089e908d31686e2bbc02ae34e24bcd2dcdadecd40b4e15d277221a37e84b35d5.lock
Generating train split:   0%|          | 0/9427 [00:00<?, ? examples/s]DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/boolq/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646.incomplete/super_glue-train-00000-00000-of-NNNNN.arrow
Generating train split: 100%|██████████| 9427/9427 [00:00<00:00, 26799.66 examples/s]Generating train split: 100%|██████████| 9427/9427 [00:00<00:00, 26544.94 examples/s]
Generating validation split:   0%|          | 0/3270 [00:00<?, ? examples/s]DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/boolq/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646.incomplete/super_glue-validation-00000-00000-of-NNNNN.arrow
Generating validation split: 100%|██████████| 3270/3270 [00:00<00:00, 119692.94 examples/s]
Generating test split:   0%|          | 0/3245 [00:00<?, ? examples/s]DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/boolq/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646.incomplete/super_glue-test-00000-00000-of-NNNNN.arrow
Generating test split: 100%|██████████| 3245/3245 [00:00<00:00, 135798.26 examples/s]
DEBUG:filelock:Attempting to acquire lock 139720654373808 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/boolq/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646.incomplete_info.lock
DEBUG:filelock:Lock 139720654373808 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/boolq/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646.incomplete_info.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/boolq/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646.incomplete/dataset_info.json
DEBUG:filelock:Attempting to release lock 139720654373808 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/boolq/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646.incomplete_info.lock
DEBUG:filelock:Lock 139720654373808 released on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/boolq/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646.incomplete_info.lock
DEBUG:filelock:Attempting to release lock 139722699523712 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/boolq/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 139722699523712 released on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/boolq/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of boolq from None to 0
INFO:lm_eval.api.task:Building contexts for boolq on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 2638.31it/s]
DEBUG:lm_eval.evaluator:Task: boolq; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:04<14:42,  4.44s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:06<05:58,  1.82s/it]Running loglikelihood requests:   2%|▎         | 5/200 [00:08<04:21,  1.34s/it]Running loglikelihood requests:   4%|▎         | 7/200 [00:09<03:39,  1.14s/it]Running loglikelihood requests:   4%|▍         | 9/200 [00:11<03:14,  1.02s/it]Running loglikelihood requests:   6%|▌         | 11/200 [00:12<02:57,  1.07it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:14<02:44,  1.13it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:16<02:36,  1.19it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:17<02:28,  1.23it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:18<02:21,  1.28it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:20<02:16,  1.31it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:21<02:12,  1.34it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:23<02:08,  1.37it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:24<02:04,  1.39it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:25<02:01,  1.40it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:27<01:59,  1.42it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:28<01:56,  1.43it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:30<01:54,  1.44it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:31<01:51,  1.46it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:32<01:49,  1.47it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:34<01:47,  1.48it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:35<01:45,  1.48it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:36<01:43,  1.50it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:38<01:40,  1.52it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:39<01:38,  1.54it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:40<01:35,  1.55it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:41<01:33,  1.56it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:43<01:32,  1.57it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:44<01:29,  1.59it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:45<01:27,  1.61it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:46<01:25,  1.62it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:47<01:23,  1.64it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:49<01:21,  1.65it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:50<01:20,  1.66it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:51<01:18,  1.68it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:52<01:15,  1.70it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:53<01:13,  1.72it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:54<01:11,  1.75it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:55<01:09,  1.77it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:56<01:07,  1.79it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:58<01:06,  1.80it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:59<01:04,  1.81it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [01:00<01:03,  1.82it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [01:01<01:01,  1.83it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [01:02<01:00,  1.84it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [01:03<00:59,  1.84it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [01:04<00:57,  1.85it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [01:05<00:56,  1.86it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [01:06<00:55,  1.86it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [01:07<00:53,  1.87it/s]Running loglikelihood requests:  50%|█████     | 101/200 [01:08<00:52,  1.89it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [01:09<00:51,  1.90it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [01:10<00:49,  1.91it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [01:11<00:48,  1.92it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [01:12<00:47,  1.93it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [01:13<00:45,  1.94it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [01:14<00:44,  1.95it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [01:15<00:43,  1.95it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [01:16<00:42,  1.97it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [01:17<00:40,  1.98it/s]Running loglikelihood requests:  60%|██████    | 121/200 [01:18<00:39,  2.00it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [01:19<00:37,  2.03it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [01:20<00:36,  2.05it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [01:21<00:35,  2.07it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [01:22<00:33,  2.10it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [01:23<00:32,  2.13it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [01:24<00:31,  2.16it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [01:25<00:29,  2.18it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [01:26<00:28,  2.19it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [01:27<00:27,  2.20it/s]Running loglikelihood requests:  70%|███████   | 141/200 [01:28<00:26,  2.22it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [01:28<00:25,  2.26it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [01:29<00:24,  2.28it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [01:30<00:23,  2.30it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [01:31<00:21,  2.32it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [01:32<00:20,  2.34it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [01:33<00:19,  2.35it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [01:33<00:18,  2.37it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [01:34<00:17,  2.40it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [01:35<00:16,  2.42it/s]Running loglikelihood requests:  80%|████████  | 161/200 [01:36<00:15,  2.44it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [01:37<00:15,  2.46it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [01:37<00:14,  2.49it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [01:38<00:13,  2.51it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [01:39<00:12,  2.53it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [01:40<00:11,  2.57it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [01:41<00:10,  2.61it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [01:41<00:09,  2.64it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [01:42<00:08,  2.68it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [01:43<00:07,  2.70it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [01:43<00:06,  2.72it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [01:44<00:06,  2.75it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [01:45<00:05,  2.78it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [01:46<00:04,  2.84it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [01:46<00:03,  2.87it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [01:47<00:03,  2.90it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [01:48<00:02,  2.92it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:48<00:01,  2.98it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:49<00:00,  3.11it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:49<00:00,  3.27it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:49<00:00,  1.82it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:4'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:4'}
full model:
{'boolq': {'alias': 'boolq', 'acc,none': 0.67, 'acc_stderr,none': 0.04725815626252609}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9782993007407264
0.4824830207482711
0.6583529368570694
0.8822475410601947
0.3059812833421515
0.7645942683746021
0.5411564675926485
0.6399758236302138
0.752913626333875
0.9170504110771489
0.8755679311709376
0.9130694495301263
0.6399088029710222
0.5907791688883935
0.8704540476128766
0.484807489124531
0.7579322019225017
0.8465026175931075
0.8104840653949666
0.671147278193032
0.7709951349967222
0.532915988335396
0.6066099270395096
0.5511989097245372
0.4671998655475952
0.6078287002452507
0.3992240879306912
0.5299030614769079
0.5709371890677749
0.9782993007407264
0.4824830207482711
0.6583529368570694
0.8822475410601947
0.3059812833421515
0.7645942683746021
0.5411564675926485
0.6399758236302138
0.752913626333875
0.9170504110771489
0.8755679311709376
0.9130694495301263
0.6399088029710222
0.5907791688883935
0.8704540476128766
0.484807489124531
0.7579322019225017
0.8465026175931075
0.8104840653949666
0.671147278193032
0.7709951349967222
0.532915988335396
0.6066099270395096
0.5511989097245372
0.4671998655475952
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[6, 2, 7, 0, 5, 3, 4, 1]
tensor([6, 2, 7, 0, 5, 3, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 2, 3, 0, 6, 1, 4, 5]
tensor([7, 2, 3, 0, 6, 1, 4, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 1, 7, 0, 6, 4, 2, 3]
tensor([5, 1, 7, 0, 6, 4, 2, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 3, 5, 1, 7, 2, 6, 0]
tensor([4, 3, 5, 1, 7, 2, 6, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[1, 6, 7, 3, 4, 5, 0, 2]
tensor([1, 6, 7, 3, 4, 5, 0, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 4, 1, 7, 2, 5, 0]
tensor([6, 3, 4, 1, 7, 2, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([7])
tensor(7)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
done!
Normal merging for layer 2
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
done!
Normal merging for layer 4
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
done!
Normal merging for layer 5
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 6 to 31
done!
all done!
Model size: 12.0718 GB
230
cuda:4
piqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:43<00:43, 43.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:55<00:00, 25.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:55<00:00, 27.87s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/baber/piqa HTTP/1.1" 200 389
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/baber/piqa/baber/piqa.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/baber/piqa HTTP/1.1" 200 389
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/baber/piqa/resolve/142f6d7367fd9877f0fb3b5734ea6a545f54cdd1/README.md HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/baber/piqa/revision/142f6d7367fd9877f0fb3b5734ea6a545f54cdd1 HTTP/1.1" 200 389
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/baber/piqa/tree/142f6d7367fd9877f0fb3b5734ea6a545f54cdd1?recursive=False&expand=False HTTP/1.1" 200 513
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/baber/piqa/tree/142f6d7367fd9877f0fb3b5734ea6a545f54cdd1/data?recursive=False&expand=False HTTP/1.1" 404 79
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/baber/piqa/tree/142f6d7367fd9877f0fb3b5734ea6a545f54cdd1/data?recursive=False&expand=False HTTP/1.1" 404 79
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/baber/piqa/revision/142f6d7367fd9877f0fb3b5734ea6a545f54cdd1 HTTP/1.1" 200 389
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/baber/piqa/resolve/142f6d7367fd9877f0fb3b5734ea6a545f54cdd1/dataset_infos.json HTTP/1.1" 404 0
DEBUG:filelock:Attempting to acquire lock 139720663842592 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_baber___piqa_default_0.0.0_142f6d7367fd9877f0fb3b5734ea6a545f54cdd1.lock
DEBUG:filelock:Lock 139720663842592 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_baber___piqa_default_0.0.0_142f6d7367fd9877f0fb3b5734ea6a545f54cdd1.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/baber___piqa/default/0.0.0/142f6d7367fd9877f0fb3b5734ea6a545f54cdd1/dataset_info.json
DEBUG:filelock:Attempting to release lock 139720663842592 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_baber___piqa_default_0.0.0_142f6d7367fd9877f0fb3b5734ea6a545f54cdd1.lock
DEBUG:filelock:Lock 139720663842592 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_baber___piqa_default_0.0.0_142f6d7367fd9877f0fb3b5734ea6a545f54cdd1.lock
DEBUG:filelock:Attempting to acquire lock 139745889263520 on /public/home/zouyifei001/.cache/huggingface/datasets/baber___piqa/default/0.0.0/142f6d7367fd9877f0fb3b5734ea6a545f54cdd1_builder.lock
DEBUG:filelock:Lock 139745889263520 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/baber___piqa/default/0.0.0/142f6d7367fd9877f0fb3b5734ea6a545f54cdd1_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/baber___piqa/default/0.0.0/142f6d7367fd9877f0fb3b5734ea6a545f54cdd1/dataset_info.json
DEBUG:filelock:Attempting to release lock 139745889263520 on /public/home/zouyifei001/.cache/huggingface/datasets/baber___piqa/default/0.0.0/142f6d7367fd9877f0fb3b5734ea6a545f54cdd1_builder.lock
DEBUG:filelock:Lock 139745889263520 released on /public/home/zouyifei001/.cache/huggingface/datasets/baber___piqa/default/0.0.0/142f6d7367fd9877f0fb3b5734ea6a545f54cdd1_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of piqa from None to 0
INFO:lm_eval.api.task:Building contexts for piqa on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1427.64it/s]
DEBUG:lm_eval.evaluator:Task: piqa; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:01<05:02,  1.52s/it]Running loglikelihood requests:   1%|          | 2/200 [00:02<04:12,  1.27s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:03<03:33,  1.08s/it]Running loglikelihood requests:   2%|▏         | 4/200 [00:04<03:13,  1.02it/s]Running loglikelihood requests:   2%|▎         | 5/200 [00:05<03:00,  1.08it/s]Running loglikelihood requests:   3%|▎         | 6/200 [00:05<02:52,  1.12it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:06<02:45,  1.17it/s]Running loglikelihood requests:   4%|▍         | 8/200 [00:07<02:38,  1.21it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:08<02:33,  1.25it/s]Running loglikelihood requests:   5%|▌         | 10/200 [00:08<02:27,  1.28it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:09<02:23,  1.31it/s]Running loglikelihood requests:   6%|▌         | 12/200 [00:10<02:20,  1.33it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:11<02:18,  1.35it/s]Running loglikelihood requests:   7%|▋         | 14/200 [00:11<02:16,  1.37it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:12<02:13,  1.39it/s]Running loglikelihood requests:   8%|▊         | 16/200 [00:13<02:10,  1.41it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:13<02:08,  1.43it/s]Running loglikelihood requests:   9%|▉         | 18/200 [00:14<02:05,  1.45it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:15<02:03,  1.47it/s]Running loglikelihood requests:  10%|█         | 20/200 [00:15<02:01,  1.48it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:16<01:59,  1.50it/s]Running loglikelihood requests:  11%|█         | 22/200 [00:17<01:57,  1.52it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:17<01:55,  1.53it/s]Running loglikelihood requests:  12%|█▏        | 24/200 [00:18<01:54,  1.54it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:19<01:53,  1.55it/s]Running loglikelihood requests:  13%|█▎        | 26/200 [00:19<01:51,  1.56it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:20<01:50,  1.56it/s]Running loglikelihood requests:  14%|█▍        | 28/200 [00:21<01:49,  1.56it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:21<01:48,  1.57it/s]Running loglikelihood requests:  15%|█▌        | 30/200 [00:22<01:47,  1.58it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:22<01:46,  1.59it/s]Running loglikelihood requests:  16%|█▌        | 32/200 [00:23<01:45,  1.60it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:24<01:44,  1.60it/s]Running loglikelihood requests:  17%|█▋        | 34/200 [00:24<01:43,  1.61it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:25<01:42,  1.61it/s]Running loglikelihood requests:  18%|█▊        | 36/200 [00:25<01:41,  1.62it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:26<01:40,  1.62it/s]Running loglikelihood requests:  19%|█▉        | 38/200 [00:27<01:39,  1.62it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:27<01:38,  1.63it/s]Running loglikelihood requests:  20%|██        | 40/200 [00:28<01:37,  1.63it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:29<01:36,  1.64it/s]Running loglikelihood requests:  21%|██        | 42/200 [00:29<01:35,  1.65it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:30<01:34,  1.66it/s]Running loglikelihood requests:  22%|██▏       | 44/200 [00:30<01:33,  1.66it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:31<01:33,  1.66it/s]Running loglikelihood requests:  23%|██▎       | 46/200 [00:32<01:32,  1.67it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:32<01:30,  1.68it/s]Running loglikelihood requests:  24%|██▍       | 48/200 [00:33<01:30,  1.69it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:33<01:29,  1.70it/s]Running loglikelihood requests:  25%|██▌       | 50/200 [00:34<01:28,  1.70it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:34<01:27,  1.71it/s]Running loglikelihood requests:  26%|██▌       | 52/200 [00:35<01:26,  1.71it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:36<01:25,  1.71it/s]Running loglikelihood requests:  27%|██▋       | 54/200 [00:36<01:24,  1.72it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:37<01:24,  1.72it/s]Running loglikelihood requests:  28%|██▊       | 56/200 [00:37<01:23,  1.73it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:38<01:22,  1.73it/s]Running loglikelihood requests:  29%|██▉       | 58/200 [00:38<01:22,  1.73it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:39<01:21,  1.73it/s]Running loglikelihood requests:  30%|███       | 60/200 [00:40<01:20,  1.74it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:40<01:19,  1.74it/s]Running loglikelihood requests:  31%|███       | 62/200 [00:41<01:19,  1.74it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:41<01:18,  1.75it/s]Running loglikelihood requests:  32%|███▏      | 64/200 [00:42<01:17,  1.75it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:42<01:16,  1.76it/s]Running loglikelihood requests:  33%|███▎      | 66/200 [00:43<01:16,  1.76it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:44<01:15,  1.76it/s]Running loglikelihood requests:  34%|███▍      | 68/200 [00:44<01:14,  1.77it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:45<01:13,  1.77it/s]Running loglikelihood requests:  35%|███▌      | 70/200 [00:45<01:13,  1.78it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:46<01:12,  1.78it/s]Running loglikelihood requests:  36%|███▌      | 72/200 [00:46<01:11,  1.79it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:47<01:10,  1.79it/s]Running loglikelihood requests:  37%|███▋      | 74/200 [00:48<01:10,  1.80it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:48<01:09,  1.81it/s]Running loglikelihood requests:  38%|███▊      | 76/200 [00:49<01:08,  1.81it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:49<01:07,  1.81it/s]Running loglikelihood requests:  39%|███▉      | 78/200 [00:50<01:07,  1.82it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:50<01:06,  1.82it/s]Running loglikelihood requests:  40%|████      | 80/200 [00:51<01:05,  1.82it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:51<01:05,  1.83it/s]Running loglikelihood requests:  41%|████      | 82/200 [00:52<01:04,  1.83it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:52<01:03,  1.83it/s]Running loglikelihood requests:  42%|████▏     | 84/200 [00:53<01:02,  1.84it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:53<01:02,  1.85it/s]Running loglikelihood requests:  43%|████▎     | 86/200 [00:54<01:01,  1.86it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:55<01:00,  1.86it/s]Running loglikelihood requests:  44%|████▍     | 88/200 [00:55<01:00,  1.87it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:56<00:59,  1.87it/s]Running loglikelihood requests:  45%|████▌     | 90/200 [00:56<00:58,  1.87it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:57<00:58,  1.87it/s]Running loglikelihood requests:  46%|████▌     | 92/200 [00:57<00:57,  1.87it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:58<00:57,  1.88it/s]Running loglikelihood requests:  47%|████▋     | 94/200 [00:58<00:56,  1.88it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:59<00:55,  1.89it/s]Running loglikelihood requests:  48%|████▊     | 96/200 [00:59<00:54,  1.90it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [01:00<00:53,  1.91it/s]Running loglikelihood requests:  49%|████▉     | 98/200 [01:00<00:53,  1.91it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [01:01<00:52,  1.92it/s]Running loglikelihood requests:  50%|█████     | 100/200 [01:01<00:51,  1.93it/s]Running loglikelihood requests:  50%|█████     | 101/200 [01:02<00:51,  1.93it/s]Running loglikelihood requests:  51%|█████     | 102/200 [01:02<00:50,  1.94it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [01:03<00:49,  1.95it/s]Running loglikelihood requests:  52%|█████▏    | 104/200 [01:03<00:49,  1.95it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [01:04<00:48,  1.96it/s]Running loglikelihood requests:  53%|█████▎    | 106/200 [01:04<00:47,  1.96it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [01:05<00:47,  1.97it/s]Running loglikelihood requests:  54%|█████▍    | 108/200 [01:05<00:46,  1.97it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [01:06<00:45,  1.98it/s]Running loglikelihood requests:  55%|█████▌    | 110/200 [01:06<00:45,  1.99it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [01:07<00:44,  2.00it/s]Running loglikelihood requests:  56%|█████▌    | 112/200 [01:07<00:43,  2.01it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [01:08<00:43,  2.01it/s]Running loglikelihood requests:  57%|█████▋    | 114/200 [01:08<00:42,  2.02it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [01:09<00:41,  2.03it/s]Running loglikelihood requests:  58%|█████▊    | 116/200 [01:09<00:41,  2.03it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [01:10<00:40,  2.04it/s]Running loglikelihood requests:  59%|█████▉    | 118/200 [01:10<00:40,  2.04it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [01:11<00:39,  2.04it/s]Running loglikelihood requests:  60%|██████    | 120/200 [01:11<00:39,  2.04it/s]Running loglikelihood requests:  60%|██████    | 121/200 [01:12<00:38,  2.05it/s]Running loglikelihood requests:  61%|██████    | 122/200 [01:12<00:37,  2.06it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [01:13<00:37,  2.06it/s]Running loglikelihood requests:  62%|██████▏   | 124/200 [01:13<00:36,  2.06it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [01:14<00:36,  2.06it/s]Running loglikelihood requests:  63%|██████▎   | 126/200 [01:14<00:35,  2.06it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [01:15<00:35,  2.07it/s]Running loglikelihood requests:  64%|██████▍   | 128/200 [01:15<00:34,  2.07it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [01:16<00:34,  2.07it/s]Running loglikelihood requests:  65%|██████▌   | 130/200 [01:16<00:33,  2.08it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [01:17<00:33,  2.08it/s]Running loglikelihood requests:  66%|██████▌   | 132/200 [01:17<00:32,  2.09it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [01:18<00:31,  2.10it/s]Running loglikelihood requests:  67%|██████▋   | 134/200 [01:18<00:31,  2.10it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [01:19<00:30,  2.11it/s]Running loglikelihood requests:  68%|██████▊   | 136/200 [01:19<00:30,  2.11it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [01:20<00:29,  2.12it/s]Running loglikelihood requests:  69%|██████▉   | 138/200 [01:20<00:29,  2.12it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [01:20<00:28,  2.12it/s]Running loglikelihood requests:  70%|███████   | 140/200 [01:21<00:28,  2.12it/s]Running loglikelihood requests:  70%|███████   | 141/200 [01:21<00:27,  2.12it/s]Running loglikelihood requests:  71%|███████   | 142/200 [01:22<00:27,  2.13it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [01:22<00:26,  2.13it/s]Running loglikelihood requests:  72%|███████▏  | 144/200 [01:23<00:26,  2.13it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [01:23<00:25,  2.13it/s]Running loglikelihood requests:  73%|███████▎  | 146/200 [01:24<00:25,  2.13it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [01:24<00:24,  2.14it/s]Running loglikelihood requests:  74%|███████▍  | 148/200 [01:25<00:24,  2.15it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [01:25<00:23,  2.15it/s]Running loglikelihood requests:  75%|███████▌  | 150/200 [01:26<00:23,  2.15it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [01:26<00:22,  2.16it/s]Running loglikelihood requests:  76%|███████▌  | 152/200 [01:27<00:22,  2.16it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [01:27<00:21,  2.17it/s]Running loglikelihood requests:  77%|███████▋  | 154/200 [01:27<00:21,  2.17it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [01:28<00:20,  2.18it/s]Running loglikelihood requests:  78%|███████▊  | 156/200 [01:28<00:20,  2.19it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [01:29<00:19,  2.19it/s]Running loglikelihood requests:  79%|███████▉  | 158/200 [01:29<00:19,  2.20it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [01:30<00:18,  2.20it/s]Running loglikelihood requests:  80%|████████  | 160/200 [01:30<00:18,  2.20it/s]Running loglikelihood requests:  80%|████████  | 161/200 [01:31<00:17,  2.20it/s]Running loglikelihood requests:  81%|████████  | 162/200 [01:31<00:17,  2.20it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [01:32<00:16,  2.20it/s]Running loglikelihood requests:  82%|████████▏ | 164/200 [01:32<00:16,  2.20it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [01:32<00:15,  2.21it/s]Running loglikelihood requests:  83%|████████▎ | 166/200 [01:33<00:15,  2.21it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [01:33<00:14,  2.22it/s]Running loglikelihood requests:  84%|████████▍ | 168/200 [01:34<00:14,  2.22it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [01:34<00:13,  2.22it/s]Running loglikelihood requests:  85%|████████▌ | 170/200 [01:35<00:13,  2.23it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [01:35<00:13,  2.23it/s]Running loglikelihood requests:  86%|████████▌ | 172/200 [01:36<00:12,  2.23it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [01:36<00:12,  2.23it/s]Running loglikelihood requests:  87%|████████▋ | 174/200 [01:36<00:11,  2.24it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [01:37<00:11,  2.24it/s]Running loglikelihood requests:  88%|████████▊ | 176/200 [01:37<00:10,  2.25it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [01:38<00:10,  2.26it/s]Running loglikelihood requests:  89%|████████▉ | 178/200 [01:38<00:09,  2.26it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [01:39<00:09,  2.27it/s]Running loglikelihood requests:  90%|█████████ | 180/200 [01:39<00:08,  2.27it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [01:40<00:08,  2.27it/s]Running loglikelihood requests:  91%|█████████ | 182/200 [01:40<00:07,  2.30it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [01:40<00:07,  2.31it/s]Running loglikelihood requests:  92%|█████████▏| 184/200 [01:41<00:06,  2.31it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [01:41<00:06,  2.30it/s]Running loglikelihood requests:  93%|█████████▎| 186/200 [01:42<00:06,  2.30it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [01:42<00:05,  2.31it/s]Running loglikelihood requests:  94%|█████████▍| 188/200 [01:43<00:05,  2.31it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [01:43<00:04,  2.32it/s]Running loglikelihood requests:  95%|█████████▌| 190/200 [01:43<00:04,  2.33it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [01:44<00:03,  2.34it/s]Running loglikelihood requests:  96%|█████████▌| 192/200 [01:44<00:03,  2.34it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [01:45<00:02,  2.36it/s]Running loglikelihood requests:  97%|█████████▋| 194/200 [01:45<00:02,  2.40it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:45<00:02,  2.44it/s]Running loglikelihood requests:  98%|█████████▊| 196/200 [01:46<00:01,  2.49it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:46<00:01,  2.55it/s]Running loglikelihood requests:  99%|█████████▉| 198/200 [01:47<00:00,  2.59it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:47<00:00,  2.61it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:47<00:00,  2.62it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:47<00:00,  1.85it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:5'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:5'}
full model:
{'piqa': {'alias': 'piqa', 'acc,none': 0.72, 'acc_stderr,none': 0.045126085985421296, 'acc_norm,none': 0.77, 'acc_norm_stderr,none': 0.042295258468165065}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9064246834015742
0.6971166389992818
0.984178396878105
0.6423720440493765
0.5982521563321566
0.8713841941840345
0.9082138941524238
0.5158918062056659
0.5749897473491503
0.6077434510351011
0.43990863946687114
0.513037250698066
0.6008178290360138
0.6217761889117341
0.7015566479448269
0.9265609444578461
0.9509391107686297
0.916894288805361
0.6283461914591203
0.8581337818466952
0.9688813419052539
0.8840066034830325
0.9210978928752702
0.6224518401606872
0.9119076639613269
0.9079101501328887
0.6461990702766951
0.594705914504569
0.6124297016957765
0.9064246834015742
0.6971166389992818
0.984178396878105
0.6423720440493765
0.5982521563321566
0.8713841941840345
0.9082138941524238
0.5158918062056659
0.5749897473491503
0.6077434510351011
0.43990863946687114
Total groups 76 exceeded the threshold, stopping comparison.
The group tensor is
[6, 3, 2, 4, 1, 5, 7, 0]
tensor([6, 3, 2, 4, 1, 5, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 0, 6, 3, 4, 2, 5, 1]
tensor([7, 0, 6, 3, 4, 2, 5, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 3, 5, 2, 4, 0, 6, 1]
tensor([7, 3, 5, 2, 4, 0, 6, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 1, 4, 3, 5, 2, 6, 0]
tensor([7, 1, 4, 3, 5, 2, 6, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 1, 5, 4, 3, 0, 6, 2]
tensor([7, 1, 5, 4, 3, 0, 6, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 1, 2, 2, 1, 3, 0]
tensor([0, 3, 1, 2, 2, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 3, 1, 2, 2, 0, 3, 1]
tensor([0, 3, 1, 2, 2, 0, 3, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 0, 1, 2, 3, 1, 3, 2]
tensor([0, 0, 1, 2, 3, 1, 3, 2], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
done!
Normal merging for layer 2
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
done!
Normal merging for layer 4
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([4])
tensor(4)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 5 to 16
done!
Normal merging for layer 17
tensor([0, 7])
tensor(0)
tensor([2, 5])
tensor(2)
tensor([3, 4])
tensor(3)
tensor([1, 6])
tensor(1)
done!
Normal merging for layer 18
tensor([0, 5])
tensor(0)
tensor([2, 7])
tensor(2)
tensor([3, 4])
tensor(3)
tensor([1, 6])
tensor(1)
done!
Normal merging for layer 19
tensor([0, 1])
tensor(0)
tensor([2, 5])
tensor(2)
tensor([3, 7])
tensor(3)
tensor([4, 6])
tensor(4)
done!
Cross-layer merge completed for layers 20 to 31
done!
all done!
Model size: 12.3867 GB
64
cuda:5
mrpc
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:41<00:41, 41.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 24.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 27.15s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: mrpc] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: mrpc] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
WARNING:lm_eval.api.task:[Task: mrpc] metric f1 is defined, but aggregation is not. using default aggregation=f1
WARNING:lm_eval.api.task:[Task: mrpc] metric f1 is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/revision/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 111
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/revision/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/mrpc?recursive=False&expand=False HTTP/1.1" 307 141
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/mrpc?recursive=False&expand=False HTTP/1.1" 200 356
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139720663842352 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_mrpc_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139720663842352 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_mrpc_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/mrpc/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139720663842352 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_mrpc_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139720663842352 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_mrpc_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139722704629120 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/mrpc/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139722704629120 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/mrpc/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/mrpc/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139722704629120 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/mrpc/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139722704629120 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/mrpc/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mrpc from None to 0
INFO:lm_eval.api.task:Building contexts for mrpc on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 2411.02it/s]
DEBUG:lm_eval.evaluator:Task: mrpc; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:01<05:02,  1.52s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:02<02:22,  1.39it/s]Running loglikelihood requests:   2%|▎         | 5/200 [00:03<01:52,  1.73it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:04<01:39,  1.94it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:05<01:32,  2.06it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:05<01:27,  2.15it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:06<01:24,  2.21it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:07<01:21,  2.26it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:08<01:20,  2.29it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:09<01:18,  2.31it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:10<01:16,  2.33it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:10<01:15,  2.35it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:11<01:13,  2.37it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:12<01:12,  2.38it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:13<01:11,  2.40it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:14<01:10,  2.41it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:15<01:08,  2.43it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:15<01:07,  2.44it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:16<01:06,  2.45it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:17<01:05,  2.46it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:18<01:04,  2.47it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:19<01:03,  2.48it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:19<01:02,  2.49it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:20<01:01,  2.50it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:21<01:00,  2.51it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:22<00:59,  2.52it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:23<00:58,  2.53it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:23<00:57,  2.54it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:24<00:56,  2.55it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:25<00:55,  2.56it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:26<00:54,  2.56it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:26<00:53,  2.57it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:27<00:52,  2.58it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:28<00:51,  2.59it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:29<00:50,  2.59it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:29<00:49,  2.61it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:30<00:48,  2.62it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:31<00:47,  2.63it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:32<00:46,  2.64it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:32<00:45,  2.64it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:33<00:44,  2.65it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:34<00:43,  2.66it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:35<00:43,  2.66it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:35<00:42,  2.67it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:36<00:41,  2.68it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:37<00:40,  2.69it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:38<00:39,  2.70it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:38<00:38,  2.72it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:39<00:37,  2.73it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:40<00:36,  2.74it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:41<00:36,  2.74it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:41<00:35,  2.75it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:42<00:34,  2.75it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:43<00:33,  2.76it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:43<00:32,  2.77it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:44<00:32,  2.77it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:45<00:31,  2.77it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:46<00:30,  2.77it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:46<00:29,  2.77it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:47<00:29,  2.78it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:48<00:28,  2.78it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:49<00:27,  2.79it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:49<00:26,  2.80it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [00:50<00:26,  2.80it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [00:51<00:25,  2.81it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [00:51<00:24,  2.82it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [00:52<00:23,  2.83it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [00:53<00:22,  2.84it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [00:53<00:22,  2.84it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [00:54<00:21,  2.85it/s]Running loglikelihood requests:  70%|███████   | 141/200 [00:55<00:20,  2.86it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [00:56<00:19,  2.87it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [00:56<00:19,  2.88it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [00:57<00:18,  2.89it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [00:58<00:17,  2.89it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [00:58<00:16,  2.90it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [00:59<00:16,  2.90it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [01:00<00:15,  2.90it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [01:00<00:14,  2.91it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [01:01<00:14,  2.93it/s]Running loglikelihood requests:  80%|████████  | 161/200 [01:02<00:13,  2.93it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [01:02<00:12,  2.94it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [01:03<00:11,  2.96it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [01:04<00:11,  2.98it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [01:04<00:10,  3.00it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [01:05<00:09,  3.02it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [01:06<00:08,  3.04it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [01:06<00:08,  3.05it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [01:07<00:07,  3.07it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [01:08<00:06,  3.10it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [01:08<00:06,  3.12it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [01:09<00:05,  3.15it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [01:09<00:04,  3.17it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [01:10<00:04,  3.19it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [01:11<00:03,  3.21it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [01:11<00:02,  3.23it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [01:12<00:02,  3.25it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:13<00:01,  3.26it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:13<00:00,  3.28it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:14<00:00,  3.33it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:14<00:00,  2.70it/s]
bootstrapping for stddev (sequential): f1_score
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:01<02:00,  1.21s/it]  2%|▏         | 2/100 [00:02<01:58,  1.21s/it]  3%|▎         | 3/100 [00:03<01:57,  1.21s/it]  4%|▍         | 4/100 [00:04<01:56,  1.21s/it]  5%|▌         | 5/100 [00:06<01:54,  1.21s/it]  6%|▌         | 6/100 [00:07<01:53,  1.21s/it]  7%|▋         | 7/100 [00:08<01:52,  1.21s/it]  8%|▊         | 8/100 [00:09<01:51,  1.21s/it]  9%|▉         | 9/100 [00:10<01:49,  1.21s/it] 10%|█         | 10/100 [00:12<01:48,  1.21s/it] 11%|█         | 11/100 [00:13<01:47,  1.21s/it] 12%|█▏        | 12/100 [00:14<01:45,  1.20s/it] 13%|█▎        | 13/100 [00:15<01:44,  1.20s/it] 14%|█▍        | 14/100 [00:16<01:43,  1.20s/it] 15%|█▌        | 15/100 [00:18<01:42,  1.20s/it] 16%|█▌        | 16/100 [00:19<01:41,  1.20s/it] 17%|█▋        | 17/100 [00:20<01:39,  1.20s/it] 18%|█▊        | 18/100 [00:21<01:38,  1.20s/it] 19%|█▉        | 19/100 [00:22<01:37,  1.20s/it] 20%|██        | 20/100 [00:24<01:36,  1.20s/it] 21%|██        | 21/100 [00:25<01:35,  1.20s/it] 22%|██▏       | 22/100 [00:26<01:33,  1.20s/it] 23%|██▎       | 23/100 [00:27<01:32,  1.20s/it] 24%|██▍       | 24/100 [00:28<01:31,  1.20s/it] 25%|██▌       | 25/100 [00:30<01:30,  1.21s/it] 26%|██▌       | 26/100 [00:31<01:29,  1.20s/it] 27%|██▋       | 27/100 [00:32<01:27,  1.20s/it] 28%|██▊       | 28/100 [00:33<01:26,  1.20s/it] 29%|██▉       | 29/100 [00:34<01:25,  1.21s/it] 30%|███       | 30/100 [00:36<01:24,  1.20s/it] 31%|███       | 31/100 [00:37<01:23,  1.20s/it] 32%|███▏      | 32/100 [00:38<01:21,  1.20s/it] 33%|███▎      | 33/100 [00:39<01:20,  1.20s/it] 34%|███▍      | 34/100 [00:40<01:19,  1.20s/it] 35%|███▌      | 35/100 [00:42<01:18,  1.20s/it] 36%|███▌      | 36/100 [00:43<01:17,  1.20s/it] 37%|███▋      | 37/100 [00:44<01:15,  1.20s/it] 38%|███▊      | 38/100 [00:45<01:14,  1.20s/it] 39%|███▉      | 39/100 [00:46<01:13,  1.20s/it] 40%|████      | 40/100 [00:48<01:12,  1.20s/it] 41%|████      | 41/100 [00:49<01:11,  1.20s/it] 42%|████▏     | 42/100 [00:50<01:09,  1.20s/it] 43%|████▎     | 43/100 [00:51<01:08,  1.20s/it] 44%|████▍     | 44/100 [00:53<01:07,  1.20s/it] 45%|████▌     | 45/100 [00:54<01:06,  1.20s/it] 46%|████▌     | 46/100 [00:55<01:05,  1.20s/it] 47%|████▋     | 47/100 [00:56<01:03,  1.21s/it] 48%|████▊     | 48/100 [00:57<01:02,  1.20s/it] 49%|████▉     | 49/100 [00:59<01:01,  1.20s/it] 50%|█████     | 50/100 [01:00<01:00,  1.21s/it] 51%|█████     | 51/100 [01:01<00:59,  1.21s/it] 52%|█████▏    | 52/100 [01:02<00:57,  1.21s/it] 53%|█████▎    | 53/100 [01:03<00:56,  1.21s/it] 54%|█████▍    | 54/100 [01:05<00:55,  1.21s/it] 55%|█████▌    | 55/100 [01:06<00:54,  1.21s/it] 56%|█████▌    | 56/100 [01:07<00:53,  1.21s/it] 57%|█████▋    | 57/100 [01:08<00:51,  1.21s/it] 58%|█████▊    | 58/100 [01:09<00:50,  1.21s/it] 59%|█████▉    | 59/100 [01:11<00:49,  1.21s/it] 60%|██████    | 60/100 [01:12<00:48,  1.21s/it] 61%|██████    | 61/100 [01:13<00:47,  1.21s/it] 62%|██████▏   | 62/100 [01:14<00:45,  1.21s/it] 63%|██████▎   | 63/100 [01:15<00:44,  1.21s/it] 64%|██████▍   | 64/100 [01:17<00:43,  1.21s/it] 65%|██████▌   | 65/100 [01:18<00:42,  1.21s/it] 66%|██████▌   | 66/100 [01:19<00:41,  1.21s/it] 67%|██████▋   | 67/100 [01:20<00:39,  1.21s/it] 68%|██████▊   | 68/100 [01:21<00:38,  1.21s/it] 69%|██████▉   | 69/100 [01:23<00:37,  1.21s/it] 70%|███████   | 70/100 [01:24<00:36,  1.21s/it] 71%|███████   | 71/100 [01:25<00:35,  1.21s/it] 72%|███████▏  | 72/100 [01:26<00:33,  1.21s/it] 73%|███████▎  | 73/100 [01:28<00:32,  1.21s/it] 74%|███████▍  | 74/100 [01:29<00:31,  1.21s/it] 75%|███████▌  | 75/100 [01:30<00:30,  1.21s/it] 76%|███████▌  | 76/100 [01:31<00:28,  1.21s/it] 77%|███████▋  | 77/100 [01:32<00:27,  1.21s/it] 78%|███████▊  | 78/100 [01:34<00:26,  1.21s/it] 79%|███████▉  | 79/100 [01:35<00:25,  1.21s/it] 80%|████████  | 80/100 [01:36<00:24,  1.21s/it] 81%|████████  | 81/100 [01:37<00:22,  1.21s/it] 82%|████████▏ | 82/100 [01:38<00:21,  1.21s/it] 83%|████████▎ | 83/100 [01:40<00:20,  1.21s/it] 84%|████████▍ | 84/100 [01:41<00:19,  1.21s/it] 85%|████████▌ | 85/100 [01:42<00:18,  1.21s/it] 86%|████████▌ | 86/100 [01:43<00:16,  1.21s/it] 87%|████████▋ | 87/100 [01:44<00:15,  1.21s/it] 88%|████████▊ | 88/100 [01:46<00:14,  1.21s/it] 89%|████████▉ | 89/100 [01:47<00:13,  1.21s/it] 90%|█████████ | 90/100 [01:48<00:12,  1.21s/it] 91%|█████████ | 91/100 [01:49<00:10,  1.21s/it] 92%|█████████▏| 92/100 [01:50<00:09,  1.21s/it] 93%|█████████▎| 93/100 [01:52<00:08,  1.21s/it] 94%|█████████▍| 94/100 [01:53<00:07,  1.21s/it] 95%|█████████▌| 95/100 [01:54<00:06,  1.21s/it] 96%|█████████▌| 96/100 [01:55<00:04,  1.21s/it] 97%|█████████▋| 97/100 [01:57<00:03,  1.21s/it] 98%|█████████▊| 98/100 [01:58<00:02,  1.21s/it] 99%|█████████▉| 99/100 [01:59<00:01,  1.21s/it]100%|██████████| 100/100 [02:00<00:00,  1.21s/it]100%|██████████| 100/100 [02:00<00:00,  1.21s/it]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:6'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:6'}
full model:
{'mrpc': {'alias': 'mrpc', 'acc,none': 0.7, 'acc_stderr,none': 0.04605661864718383, 'f1,none': np.float64(0.8214285714285714), 'f1_stderr,none': 0.0323693653386572}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.32375514242269293
0.9664141198776434
0.4263233992087649
0.29258192731768157
0.3497718342079178
0.5968480671674146
0.7870107004084098
0.7068508532201193
0.7836897379939763
0.2579819071737284
0.5774144903645764
0.7819348699339372
0.7404680063618143
0.651835611327285
0.6832243011482585
0.34680079188801705
0.6033476505145444
0.6299526106979766
0.6468468631829007
0.8458578364778718
0.39447753640727073
0.5291234791393744
0.944540808938638
0.8460909093145242
0.4915397062049404
0.5314721523201049
0.8670806018560002
0.6451914961665037
0.7380077491787214
0.32375514242269293
0.9664141198776434
0.4263233992087649
0.29258192731768157
0.3497718342079178
0.5968480671674146
0.7870107004084098
0.7068508532201193
0.7836897379939763
0.2579819071737284
0.5774144903645764
0.7819348699339372
0.7404680063618143
0.651835611327285
0.6832243011482585
0.34680079188801705
0.6033476505145444
0.6299526106979766
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[4, 5, 7, 1, 6, 2, 3, 0]
tensor([4, 5, 7, 1, 6, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 7, 4, 5, 0, 1, 2]
tensor([6, 3, 7, 4, 5, 0, 1, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 1, 7, 2, 6, 0, 3, 5]
tensor([4, 1, 7, 2, 6, 0, 3, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 5, 2, 7, 0, 4, 1]
tensor([6, 3, 5, 2, 7, 0, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 5, 6, 7, 3, 1, 0, 2]
tensor([4, 5, 6, 7, 3, 1, 0, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 1, 2, 4, 1, 0, 5]
tensor([0, 3, 1, 2, 4, 1, 0, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1.0, 1.0, 0, 1, 1.0]
tensor([0, 1, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1, 1.0, 1.0, 1.0, 0]
tensor([0, 1, 1, 1, 1, 1, 1, 0], dtype=torch.int32)
[0, 1]
Normal merging for layer 1
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 2
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([7])
tensor(7)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 4 to 5
done!
Normal merging for layer 6
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
done!
Cross-layer merge completed for layers 7 to 9
done!
Normal merging for layer 10
tensor([0, 6])
tensor(0)
tensor([2, 5])
tensor(2)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
tensor([7])
tensor(7)
done!
Cross-layer merge completed for layers 11 to 26
done!
Normal merging for layer 27
tensor([0, 5])
tensor(0)
tensor([1, 2, 3, 4, 6, 7])
tensor(1)
done!
Cross-layer merge completed for layers 28 to 30
done!
Normal merging for layer 31
tensor([0, 7])
tensor(0)
tensor([1, 2, 3, 4, 5, 6])
tensor(1)
done!
all done!
Model size: 12.3867 GB
27
cuda:6
rte
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:42<00:42, 42.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:55<00:00, 24.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:55<00:00, 27.58s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: rte] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: rte] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:filelock:Attempting to acquire lock 139720651783344 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139720651783344 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139720651783344 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139720651783344 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139750522790992 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139750522790992 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139750522790992 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139750522790992 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of rte from None to 0
INFO:lm_eval.api.task:Building contexts for rte on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 2562.13it/s]
DEBUG:lm_eval.evaluator:Task: rte; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:02<06:59,  2.11s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:03<03:37,  1.11s/it]Running loglikelihood requests:   2%|▎         | 5/200 [00:04<02:47,  1.16it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:06<02:25,  1.33it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:07<02:12,  1.44it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:08<02:03,  1.52it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:09<01:58,  1.58it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:10<01:53,  1.63it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:11<01:49,  1.67it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:13<01:46,  1.70it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:14<01:42,  1.74it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:15<01:40,  1.77it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:16<01:37,  1.80it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:17<01:34,  1.84it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:18<01:31,  1.87it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:19<01:28,  1.90it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:20<01:26,  1.93it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:21<01:24,  1.95it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:22<01:23,  1.96it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:23<01:21,  1.99it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:24<01:18,  2.02it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:25<01:16,  2.06it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:26<01:13,  2.10it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:27<01:11,  2.14it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:27<01:09,  2.19it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:28<01:06,  2.24it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:29<01:03,  2.30it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:30<01:01,  2.36it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:31<00:59,  2.42it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:31<00:57,  2.46it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:32<00:55,  2.51it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:33<00:53,  2.54it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:34<00:52,  2.57it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:34<00:51,  2.59it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:35<00:49,  2.62it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:36<00:48,  2.64it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:37<00:47,  2.66it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:37<00:46,  2.69it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:38<00:45,  2.72it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:39<00:44,  2.74it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:40<00:43,  2.76it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:40<00:41,  2.79it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:41<00:40,  2.81it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:42<00:39,  2.83it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:42<00:38,  2.85it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:43<00:37,  2.87it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:44<00:37,  2.89it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:44<00:36,  2.90it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:45<00:35,  2.92it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:46<00:34,  2.94it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:46<00:33,  2.95it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:47<00:32,  2.96it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:48<00:31,  2.98it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:48<00:31,  2.99it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:49<00:30,  3.01it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:50<00:29,  3.02it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:50<00:28,  3.04it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:51<00:27,  3.04it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:52<00:27,  3.05it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:52<00:26,  3.06it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:53<00:25,  3.07it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:54<00:25,  3.08it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:54<00:24,  3.08it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [00:55<00:23,  3.09it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [00:56<00:22,  3.09it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [00:56<00:22,  3.10it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [00:57<00:21,  3.12it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [00:57<00:20,  3.15it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [00:58<00:19,  3.16it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [00:59<00:19,  3.18it/s]Running loglikelihood requests:  70%|███████   | 141/200 [00:59<00:18,  3.19it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [01:00<00:17,  3.21it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [01:01<00:17,  3.22it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [01:01<00:16,  3.23it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [01:02<00:15,  3.24it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [01:02<00:15,  3.25it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [01:03<00:14,  3.27it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [01:04<00:13,  3.28it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [01:04<00:13,  3.30it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [01:05<00:12,  3.33it/s]Running loglikelihood requests:  80%|████████  | 161/200 [01:05<00:11,  3.34it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [01:06<00:11,  3.36it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [01:07<00:10,  3.37it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [01:07<00:09,  3.39it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [01:08<00:09,  3.40it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [01:08<00:08,  3.43it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [01:09<00:07,  3.45it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [01:09<00:07,  3.46it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [01:10<00:06,  3.48it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [01:11<00:06,  3.49it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [01:11<00:05,  3.50it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [01:12<00:04,  3.51it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [01:12<00:04,  3.52it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [01:13<00:03,  3.54it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [01:13<00:03,  3.55it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [01:14<00:02,  3.57it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [01:14<00:01,  3.59it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:15<00:01,  3.61it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:16<00:00,  3.69it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:16<00:00,  3.76it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:16<00:00,  2.61it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:7'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:7'}
full model:
{'rte': {'alias': 'rte', 'acc,none': 0.5, 'acc_stderr,none': 0.050251890762960605}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.34161229456626735
0.905233410256777
0.5205040718697735
0.4121994254524892
0.7398116665887099
0.6225415196831932
0.7923970242263771
0.7353888240887675
0.6535613357308766
0.7757058271862038
0.734046359122903
0.4471799126982846
0.773619360921301
0.7955347039939479
0.8672068064531693
0.8652880343596522
0.3302235467760883
0.6789268064017625
0.6072221471952108
0.9194446824778495
0.4812004589187253
0.5728915095234594
0.1682455054057436
0.93212414632396
0.9148362604533635
0.8268537756297094
0.7592245907029287
0.7256008379011685
0.7109756105942956
0.34161229456626735
0.905233410256777
0.5205040718697735
0.4121994254524892
0.7398116665887099
0.6225415196831932
0.7923970242263771
0.7353888240887675
0.6535613357308766
0.7757058271862038
0.734046359122903
0.4471799126982846
0.773619360921301
0.7955347039939479
0.8672068064531693
0.8652880343596522
0.3302235467760883
0.6789268064017625
0.6072221471952108
0.9194446824778495
0.4812004589187253
Total groups 73 exceeded the threshold, stopping comparison.
The group tensor is
[5, 2, 7, 1, 6, 4, 3, 0]
tensor([5, 2, 7, 1, 6, 4, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 6, 0, 7, 3, 4, 1]
tensor([5, 2, 6, 0, 7, 3, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 7, 2, 5, 4, 3, 0]
tensor([6, 1, 7, 2, 5, 4, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 7, 2, 4, 1, 5, 0]
tensor([6, 3, 7, 2, 4, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 5, 6, 2, 3, 1, 4, 0]
tensor([7, 5, 6, 2, 3, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 2, 5, 4, 1, 0, 1, 3]
tensor([0, 2, 5, 4, 1, 0, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1.0, 1.0, 0, 1.0, 1]
tensor([0, 1, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
Normal merging for layer 1
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Normal merging for layer 2
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 4
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 5 to 8
done!
Normal merging for layer 9
tensor([0, 5])
tensor(0)
tensor([4, 6])
tensor(4)
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
done!
Cross-layer merge completed for layers 10 to 30
done!
Normal merging for layer 31
tensor([0, 5])
tensor(0)
tensor([1, 2, 3, 4, 6, 7])
tensor(1)
done!
all done!
Model size: 12.1348 GB
60
cuda:7
cb
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:44<00:44, 44.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:57<00:00, 26.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:57<00:00, 28.84s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: cb] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: cb] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
WARNING:lm_eval.api.task:[Task: cb] metric f1 is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/super_glue/super_glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue/revision/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue/revision/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue/tree/3de24cf8022e94f4ee4b9d55a6f539891524d646/cb?recursive=False&expand=False HTTP/1.1" 307 141
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue/tree/3de24cf8022e94f4ee4b9d55a6f539891524d646/cb?recursive=False&expand=False HTTP/1.1" 200 347
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:filelock:Attempting to acquire lock 139748103657456 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_cb_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 139748103657456 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_cb_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/cb/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 139748103657456 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_cb_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 139748103657456 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_cb_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Attempting to acquire lock 139720655782256 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/cb/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 139720655782256 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/cb/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/cb/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 139720655782256 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/cb/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 139720655782256 released on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/cb/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of cb from None to 0
INFO:lm_eval.api.task:Building contexts for cb on rank 0...
  0%|          | 0/56 [00:00<?, ?it/s]100%|██████████| 56/56 [00:00<00:00, 2016.91it/s]
DEBUG:lm_eval.evaluator:Task: cb; number of requests on this rank: 168
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/168 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/168 [00:02<06:09,  2.21s/it]Running loglikelihood requests:   1%|          | 2/168 [00:03<05:13,  1.89s/it]Running loglikelihood requests:   2%|▏         | 4/168 [00:05<03:20,  1.22s/it]Running loglikelihood requests:   3%|▎         | 5/168 [00:07<03:40,  1.35s/it]Running loglikelihood requests:   4%|▍         | 7/168 [00:08<02:50,  1.06s/it]Running loglikelihood requests:   5%|▍         | 8/168 [00:10<03:04,  1.15s/it]Running loglikelihood requests:   6%|▌         | 10/168 [00:11<02:25,  1.08it/s]Running loglikelihood requests:   7%|▋         | 11/168 [00:12<02:34,  1.01it/s]Running loglikelihood requests:   8%|▊         | 13/168 [00:13<02:07,  1.21it/s]Running loglikelihood requests:   8%|▊         | 14/168 [00:14<02:17,  1.12it/s]Running loglikelihood requests:  10%|▉         | 16/168 [00:15<01:57,  1.30it/s]Running loglikelihood requests:  10%|█         | 17/168 [00:17<02:08,  1.17it/s]Running loglikelihood requests:  11%|█▏        | 19/168 [00:18<01:49,  1.37it/s]Running loglikelihood requests:  12%|█▏        | 20/168 [00:19<01:59,  1.24it/s]Running loglikelihood requests:  13%|█▎        | 22/168 [00:20<01:41,  1.44it/s]Running loglikelihood requests:  14%|█▎        | 23/168 [00:21<01:50,  1.31it/s]Running loglikelihood requests:  15%|█▍        | 25/168 [00:22<01:34,  1.51it/s]Running loglikelihood requests:  15%|█▌        | 26/168 [00:23<01:43,  1.37it/s]Running loglikelihood requests:  17%|█▋        | 28/168 [00:24<01:29,  1.56it/s]Running loglikelihood requests:  17%|█▋        | 29/168 [00:25<01:38,  1.41it/s]Running loglikelihood requests:  18%|█▊        | 31/168 [00:26<01:25,  1.60it/s]Running loglikelihood requests:  19%|█▉        | 32/168 [00:27<01:34,  1.44it/s]Running loglikelihood requests:  20%|█▉        | 33/168 [00:28<01:42,  1.32it/s]Running loglikelihood requests:  21%|██        | 35/168 [00:28<01:25,  1.55it/s]Running loglikelihood requests:  22%|██▏       | 37/168 [00:29<01:16,  1.71it/s]Running loglikelihood requests:  23%|██▎       | 38/168 [00:30<01:25,  1.52it/s]Running loglikelihood requests:  24%|██▍       | 40/168 [00:31<01:15,  1.70it/s]Running loglikelihood requests:  24%|██▍       | 41/168 [00:32<01:23,  1.52it/s]Running loglikelihood requests:  26%|██▌       | 43/168 [00:33<01:13,  1.71it/s]Running loglikelihood requests:  26%|██▌       | 44/168 [00:34<01:21,  1.53it/s]Running loglikelihood requests:  27%|██▋       | 46/168 [00:35<01:10,  1.74it/s]Running loglikelihood requests:  28%|██▊       | 47/168 [00:36<01:17,  1.56it/s]Running loglikelihood requests:  29%|██▉       | 49/168 [00:37<01:06,  1.78it/s]Running loglikelihood requests:  30%|██▉       | 50/168 [00:38<01:13,  1.60it/s]Running loglikelihood requests:  30%|███       | 51/168 [00:38<01:19,  1.47it/s]Running loglikelihood requests:  31%|███       | 52/168 [00:39<01:23,  1.38it/s]Running loglikelihood requests:  32%|███▏      | 54/168 [00:40<01:08,  1.67it/s]Running loglikelihood requests:  33%|███▎      | 56/168 [00:41<00:59,  1.87it/s]Running loglikelihood requests:  35%|███▍      | 58/168 [00:42<00:54,  2.01it/s]Running loglikelihood requests:  35%|███▌      | 59/168 [00:43<01:01,  1.76it/s]Running loglikelihood requests:  36%|███▌      | 60/168 [00:44<01:07,  1.59it/s]Running loglikelihood requests:  37%|███▋      | 62/168 [00:44<00:58,  1.82it/s]Running loglikelihood requests:  38%|███▊      | 64/168 [00:45<00:52,  1.99it/s]Running loglikelihood requests:  39%|███▊      | 65/168 [00:46<00:58,  1.75it/s]Running loglikelihood requests:  40%|███▉      | 67/168 [00:47<00:52,  1.94it/s]Running loglikelihood requests:  40%|████      | 68/168 [00:48<00:58,  1.72it/s]Running loglikelihood requests:  42%|████▏     | 70/168 [00:49<00:50,  1.93it/s]Running loglikelihood requests:  42%|████▏     | 71/168 [00:49<00:56,  1.72it/s]Running loglikelihood requests:  43%|████▎     | 73/168 [00:50<00:49,  1.93it/s]Running loglikelihood requests:  44%|████▍     | 74/168 [00:51<00:54,  1.72it/s]Running loglikelihood requests:  45%|████▍     | 75/168 [00:52<00:59,  1.57it/s]Running loglikelihood requests:  45%|████▌     | 76/168 [00:53<01:02,  1.47it/s]Running loglikelihood requests:  46%|████▋     | 78/168 [00:53<00:50,  1.77it/s]Running loglikelihood requests:  48%|████▊     | 80/168 [00:54<00:44,  1.97it/s]Running loglikelihood requests:  49%|████▉     | 82/168 [00:55<00:40,  2.12it/s]Running loglikelihood requests:  49%|████▉     | 83/168 [00:56<00:45,  1.85it/s]Running loglikelihood requests:  51%|█████     | 85/168 [00:57<00:40,  2.05it/s]Running loglikelihood requests:  51%|█████     | 86/168 [00:57<00:44,  1.83it/s]Running loglikelihood requests:  52%|█████▏    | 88/168 [00:58<00:39,  2.04it/s]Running loglikelihood requests:  53%|█████▎    | 89/168 [00:59<00:43,  1.81it/s]Running loglikelihood requests:  54%|█████▎    | 90/168 [01:00<00:47,  1.66it/s]Running loglikelihood requests:  55%|█████▍    | 92/168 [01:01<00:39,  1.93it/s]Running loglikelihood requests:  56%|█████▌    | 94/168 [01:01<00:34,  2.14it/s]Running loglikelihood requests:  57%|█████▋    | 95/168 [01:02<00:38,  1.90it/s]Running loglikelihood requests:  58%|█████▊    | 97/168 [01:03<00:33,  2.11it/s]Running loglikelihood requests:  58%|█████▊    | 98/168 [01:04<00:37,  1.88it/s]Running loglikelihood requests:  60%|█████▉    | 100/168 [01:04<00:32,  2.12it/s]Running loglikelihood requests:  60%|██████    | 101/168 [01:05<00:35,  1.89it/s]Running loglikelihood requests:  61%|██████▏   | 103/168 [01:06<00:30,  2.14it/s]Running loglikelihood requests:  62%|██████▏   | 104/168 [01:07<00:33,  1.91it/s]Running loglikelihood requests:  62%|██████▎   | 105/168 [01:07<00:35,  1.75it/s]Running loglikelihood requests:  63%|██████▎   | 106/168 [01:08<00:37,  1.64it/s]Running loglikelihood requests:  64%|██████▍   | 108/168 [01:09<00:30,  1.97it/s]Running loglikelihood requests:  65%|██████▌   | 110/168 [01:09<00:26,  2.20it/s]Running loglikelihood requests:  66%|██████▌   | 111/168 [01:10<00:29,  1.96it/s]Running loglikelihood requests:  67%|██████▋   | 113/168 [01:11<00:25,  2.20it/s]Running loglikelihood requests:  68%|██████▊   | 114/168 [01:12<00:27,  1.96it/s]Running loglikelihood requests:  69%|██████▉   | 116/168 [01:12<00:23,  2.20it/s]Running loglikelihood requests:  70%|███████   | 118/168 [01:13<00:21,  2.38it/s]Running loglikelihood requests:  71%|███████   | 119/168 [01:14<00:23,  2.09it/s]Running loglikelihood requests:  71%|███████▏  | 120/168 [01:15<00:25,  1.88it/s]Running loglikelihood requests:  73%|███████▎  | 122/168 [01:15<00:21,  2.16it/s]Running loglikelihood requests:  74%|███████▍  | 124/168 [01:16<00:18,  2.36it/s]Running loglikelihood requests:  74%|███████▍  | 125/168 [01:17<00:20,  2.08it/s]Running loglikelihood requests:  76%|███████▌  | 127/168 [01:17<00:17,  2.31it/s]Running loglikelihood requests:  76%|███████▌  | 128/168 [01:18<00:19,  2.05it/s]Running loglikelihood requests:  77%|███████▋  | 129/168 [01:19<00:20,  1.87it/s]Running loglikelihood requests:  78%|███████▊  | 131/168 [01:19<00:17,  2.17it/s]Running loglikelihood requests:  79%|███████▉  | 133/168 [01:20<00:14,  2.41it/s]Running loglikelihood requests:  80%|███████▉  | 134/168 [01:21<00:15,  2.16it/s]Running loglikelihood requests:  81%|████████  | 136/168 [01:21<00:13,  2.42it/s]Running loglikelihood requests:  82%|████████▏ | 137/168 [01:22<00:14,  2.16it/s]Running loglikelihood requests:  82%|████████▏ | 138/168 [01:23<00:15,  1.98it/s]Running loglikelihood requests:  83%|████████▎ | 139/168 [01:23<00:15,  1.85it/s]Running loglikelihood requests:  83%|████████▎ | 140/168 [01:24<00:15,  1.76it/s]Running loglikelihood requests:  85%|████████▍ | 142/168 [01:25<00:12,  2.16it/s]Running loglikelihood requests:  86%|████████▌ | 144/168 [01:25<00:09,  2.44it/s]Running loglikelihood requests:  87%|████████▋ | 146/168 [01:26<00:08,  2.64it/s]Running loglikelihood requests:  88%|████████▊ | 148/168 [01:27<00:07,  2.79it/s]Running loglikelihood requests:  89%|████████▊ | 149/168 [01:27<00:07,  2.44it/s]Running loglikelihood requests:  89%|████████▉ | 150/168 [01:28<00:08,  2.18it/s]Running loglikelihood requests:  90%|█████████ | 152/168 [01:28<00:06,  2.48it/s]Running loglikelihood requests:  92%|█████████▏| 154/168 [01:29<00:05,  2.70it/s]Running loglikelihood requests:  92%|█████████▏| 155/168 [01:30<00:05,  2.38it/s]Running loglikelihood requests:  93%|█████████▎| 157/168 [01:30<00:04,  2.64it/s]Running loglikelihood requests:  94%|█████████▍| 158/168 [01:31<00:04,  2.34it/s]Running loglikelihood requests:  95%|█████████▌| 160/168 [01:31<00:02,  2.67it/s]Running loglikelihood requests:  96%|█████████▌| 161/168 [01:32<00:02,  2.41it/s]Running loglikelihood requests:  97%|█████████▋| 163/168 [01:33<00:01,  2.75it/s]Running loglikelihood requests:  98%|█████████▊| 164/168 [01:33<00:01,  2.48it/s]Running loglikelihood requests:  99%|█████████▉| 166/168 [01:34<00:00,  2.83it/s]Running loglikelihood requests:  99%|█████████▉| 167/168 [01:34<00:00,  2.55it/s]Running loglikelihood requests: 100%|██████████| 168/168 [01:34<00:00,  1.77it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
full model:
{'cb': {'alias': 'cb', 'acc,none': 0.44642857142857145, 'acc_stderr,none': 0.06703189227942397, 'f1,none': np.float64(0.2946127946127946), 'f1_stderr,none': 'N/A'}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8754479021250823
0.8035282713865031
0.9500865550679058
0.9469110267801961
0.9212663689239236
0.9365178765256775
0.671589453090406
0.6744336218334667
0.8076345549626031
0.7976470386087894
0.807072393829993
0.6600400889592184
0.7484904863798857
0.9363063771008698
0.6357711114598822
0.9166089836828051
0.6715835426958833
0.7409884813902188
0.412428535140908
0.8747283305135303
0.8491219158212996
0.9125101690232402
0.8366676259845086
0.705936129020536
0.7920385356495101
0.9243830461584077
0.9274604399644588
0.7835428130351293
0.8119111717866335
Total groups 67 exceeded the threshold, stopping comparison.
The group tensor is
[6, 3, 5, 2, 7, 1, 4, 0]
tensor([6, 3, 5, 2, 7, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 4, 7, 3, 6, 1, 2, 0]
tensor([5, 4, 7, 3, 6, 1, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 1, 6, 3, 7, 2, 4, 0]
tensor([5, 1, 6, 3, 7, 2, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 2, 0, 1, 5, 0, 1, 3]
tensor([4, 2, 0, 1, 5, 0, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[4, 3, 0, 2, 1, 1, 5, 0]
tensor([4, 3, 0, 2, 1, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 1, 2, 2, 1, 3, 0]
tensor([0, 3, 1, 2, 2, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1.0, 1.0, 0, 1.0, 1]
tensor([0, 1, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
done!
Cross-layer merge completed for layers 2 to 6
done!
Normal merging for layer 7
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 8 to 12
done!
Normal merging for layer 13
tensor([2, 5])
tensor(2)
tensor([3, 6])
tensor(3)
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Normal merging for layer 14
tensor([2, 7])
tensor(2)
tensor([4, 5])
tensor(4)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 15 to 18
done!
Normal merging for layer 19
tensor([0, 7])
tensor(0)
tensor([2, 5])
tensor(2)
tensor([3, 4])
tensor(3)
tensor([1, 6])
tensor(1)
done!
Cross-layer merge completed for layers 20 to 23
done!
Normal merging for layer 24
tensor([0, 5])
tensor(0)
tensor([1, 2, 3, 4, 6, 7])
tensor(1)
done!
Cross-layer merge completed for layers 25 to 31
done!
all done!
Model size: 11.9458 GB
Node 109 Flask server is running on port 5109...
Node 141 Flask server is running on port 5141...
Node 163 Flask server is running on port 5163...
Node 196 Flask server is running on port 5196...
Node 55 Flask server is running on port 5055...
Node 26 Flask server is running on port 5026...
Node 206 Flask server is running on port 5206...
Node 87 Flask server is running on port 5087...
Node 44 Flask server is running on port 5044...
Node 30 Flask server is running on port 5030...
Node 82 Flask server is running on port 5082...
Node 45 Flask server is running on port 5045...
Node 6 Flask server is running on port 5006...
Node 133 Flask server is running on port 5133...
Node 104 Flask server is running on port 5104...
Node 80 Flask server is running on port 5080...
Node 178 Flask server is running on port 5178...
Node 236 Flask server is running on port 5236...
Node 242 Flask server is running on port 5242...
Node 13 Flask server is running on port 5013...
Node 29 Flask server is running on port 5029...
Node 11 Flask server is running on port 5011...
Node 205 Flask server is running on port 5205...
Node 243 Flask server is running on port 5243...
Node 171 Flask server is running on port 5171...
Node 94 Flask server is running on port 5094...
Node 4 Flask server is running on port 5004...
Node 161 Flask server is running on port 5161...
Node 230 Flask server is running on port 5230...
Node 64 Flask server is running on port 5064...
Node 27 Flask server is running on port 5027...
Node 60 Flask server is running on port 5060...
[109] Inference Step Starting
 * Serving Flask app 'Node_llama_test'
 * Serving Flask app 'Node_llama_test'
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Debug mode: off
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Serving Flask app 'Node_llama_test'
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Debug mode: off
 * Debug mode: off
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5243
 * Running on http://173.0.64.7:5243
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5104
 * Running on http://173.0.64.7:5104
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5030
 * Running on http://173.0.64.7:5030
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5082
 * Running on http://173.0.64.7:5082
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5055
 * Running on http://173.0.64.7:5055
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5230
 * Running on http://173.0.64.7:5230
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5004
 * Running on http://173.0.64.7:5004
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5094
 * Running on http://173.0.64.7:5094
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5087
 * Running on http://173.0.64.7:5087
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5196
 * Running on http://173.0.64.7:5196
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5109
 * Running on http://173.0.64.7:5109
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5133
 * Running on http://173.0.64.7:5133
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5161
 * Running on http://173.0.64.7:5161
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5027
 * Running on http://173.0.64.7:5027
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5163
 * Running on http://173.0.64.7:5163
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5080
 * Running on http://173.0.64.7:5080
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5044
 * Running on http://173.0.64.7:5044
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5011
 * Running on http://173.0.64.7:5011
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5236
 * Running on http://173.0.64.7:5236
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5026
 * Running on http://173.0.64.7:5026
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5242
 * Running on http://173.0.64.7:5242
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5178
 * Running on http://173.0.64.7:5178
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5045
 * Running on http://173.0.64.7:5045
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5171
 * Running on http://173.0.64.7:5171
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5013
 * Running on http://173.0.64.7:5013
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5006
 * Running on http://173.0.64.7:5006
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5205
 * Running on http://173.0.64.7:5205
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5064
 * Running on http://173.0.64.7:5064
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5141
 * Running on http://173.0.64.7:5141
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5060
 * Running on http://173.0.64.7:5060
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5206
 * Running on http://173.0.64.7:5206
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5029
 * Running on http://173.0.64.7:5029
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[33mPress CTRL+C to quit[0m
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/revision/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 111
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/revision/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139721436798592 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139721436798592 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139721436798592 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139721436798592 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139748103662688 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139748103662688 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139748103662688 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139748103662688 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2577.62it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:03<07:33,  3.21s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:05<03:50,  1.66s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:07<02:59,  1.31s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:09<02:37,  1.17s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:11<02:25,  1.09s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:13<02:15,  1.03s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:15<02:16,  1.06s/it]Running loglikelihood requests:  11%|█         | 15/142 [00:17<02:18,  1.09s/it]Running loglikelihood requests:  12%|█▏        | 17/142 [00:19<02:07,  1.02s/it]Running loglikelihood requests:  13%|█▎        | 19/142 [00:20<01:56,  1.05it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:22<01:48,  1.11it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:24<01:44,  1.14it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:25<01:38,  1.19it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:27<01:32,  1.24it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:28<01:28,  1.27it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:30<01:25,  1.30it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:31<01:23,  1.31it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:33<01:20,  1.33it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:35<01:26,  1.22it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:36<01:21,  1.26it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:37<01:17,  1.30it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:39<01:14,  1.33it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:40<01:11,  1.36it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:42<01:08,  1.39it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:43<01:05,  1.41it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:45<01:08,  1.33it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:46<01:03,  1.39it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:47<01:00,  1.43it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:49<00:58,  1.46it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:50<00:55,  1.48it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:51<00:54,  1.50it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:52<00:52,  1.52it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:54<00:50,  1.54it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:55<00:50,  1.47it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:56<00:48,  1.50it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:58<00:46,  1.53it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:59<00:44,  1.55it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [01:00<00:42,  1.56it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:01<00:41,  1.57it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:03<00:39,  1.59it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:04<00:38,  1.60it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:05<00:39,  1.51it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:07<00:37,  1.54it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:08<00:35,  1.57it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:09<00:33,  1.58it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:10<00:32,  1.59it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:12<00:30,  1.60it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:13<00:29,  1.62it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:14<00:27,  1.63it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:15<00:27,  1.58it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:17<00:25,  1.61it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:18<00:23,  1.63it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:19<00:22,  1.65it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:20<00:21,  1.66it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:21<00:19,  1.67it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:22<00:18,  1.68it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:24<00:17,  1.70it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:25<00:16,  1.60it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:26<00:15,  1.63it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:27<00:13,  1.65it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:29<00:12,  1.67it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:30<00:11,  1.67it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:31<00:10,  1.67it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:32<00:09,  1.58it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:34<00:08,  1.62it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:35<00:06,  1.65it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:36<00:05,  1.62it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:37<00:04,  1.66it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:38<00:02,  1.71it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:39<00:01,  1.74it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:40<00:00,  1.77it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:40<00:00,  1.41it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-2): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (3-4): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-7): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (8-28): 21 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (29): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (30-31): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-2): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (3-4): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-7): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (8-28): 21 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (29): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (30-31): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/109.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5205
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:50:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5205 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 205
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5029
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:50:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5029 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 29
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:50:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:50:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5206
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:50:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5206 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 206
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5243
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:50:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5243 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 243
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5141
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:50:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5141 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 141
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5080
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:50:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5080 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 80
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5082
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:50:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5082 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 82
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5004
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:50:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5004 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 4
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:50:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5045
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:50:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5045 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 45
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5026
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:50:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5026 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 26
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:50:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5242
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:50:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5242 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 242
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5171
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:50:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5171 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 171
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5011
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:50:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5011 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 11
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:50:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5104
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:50:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5104 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 104
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5044
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:50:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5044 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 44
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5006
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:50:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5006 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 6
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:50:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5133
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:50:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5133 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 133
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:50:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5236
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:50:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5236 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 236
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:50:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5230
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:50:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5230 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 230
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:50:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5060
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:50:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5060 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 60
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5027
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:50:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5027 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 27
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5013
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:50:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5013 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 13
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139722773311328 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139722773311328 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139722773311328 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139722773311328 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139722780711712 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139722780711712 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139722780711712 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139722780711712 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[109] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4507042253521127, 'acc_stderr,none': 0.05947027187738001}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.6024646571659534
0.8979951240825792
0.626373129339755
0.44935206242731585
0.8784896158641048
0.6837759248511185
0.6015518094762149
0.3505110226931915
0.8777011536981446
0.9326494344559366
0.9677722596476288
0.8304234396005722
0.8190920250237561
0.9903242845857883
0.8267732717549456
0.828751210253346
0.9341138981557521
0.49221062986878583
0.3069647614672379
0.9540155558764357
0.17208911684447897
0.24981632210046514
0.9635863021858757
0.7455052133761656
0.8389345141460378
0.9946030373097186
0.6620732151580052
0.6342744878528105
0.8890512085844174
Total groups 67 exceeded the threshold, stopping comparison.
The group tensor is
[2, 4, 7, 1, 3, 0, 6, 5]
tensor([2, 4, 7, 1, 3, 0, 6, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 7, 6, 5, 0, 1, 4, 3]
tensor([2, 7, 6, 5, 0, 1, 4, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 6, 4, 3, 0, 1, 7, 2]
tensor([5, 6, 4, 3, 0, 1, 7, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 4, 1, 0, 1, 2, 5, 3]
tensor([0, 4, 1, 0, 1, 2, 5, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[2, 4, 0, 0, 5, 1, 1, 3]
tensor([2, 4, 0, 0, 5, 1, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 1, 1.0, 1.0, 1, 1.0, 1.0]
tensor([0, 0, 1, 1, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[0, 1, 1.0, 1.0, 0, 1, 1.0, 1.0]
tensor([0, 1, 1, 1, 0, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1.0, 1.0, 1, 1.0, 0]
tensor([0, 1, 1, 1, 1, 1, 1, 0], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 0, 1.0, 1.0, 1.0, 1]
tensor([0, 1, 1, 0, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
Model saved locally at saved_models/109.pt
[RECEIVE] Queued message from 109
[QUEUE] Processing info from 109
[QUEUE] Stored info from 109
[RECEIVE] Queued message from 109
[QUEUE] Processing info from 109
[QUEUE] Stored info from 109
[RECEIVE] Queued message from 109
[QUEUE] Processing info from 109
[QUEUE] Stored info from 109
[RECEIVE] Queued message from 109
[QUEUE] Processing info from 109
[QUEUE] Stored info from 109
[RECEIVE] Queued message from 109
[QUEUE] Processing info from 109
[QUEUE] Stored info from 109
[RECEIVE] Queued message from 109
[QUEUE] Processing info from 109
[QUEUE] Stored info from 109
[RECEIVE] Queued message from 109
[QUEUE] Processing info from 109
[QUEUE] Stored info from 109
[RECEIVE] Queued message from 109
[QUEUE] Processing info from 109
[QUEUE] Stored info from 109
[RECEIVE] Queued message from 109
[QUEUE] Processing info from 109
[QUEUE] Stored info from 109
[RECEIVE] Queued message from 109
[QUEUE] Processing info from 109
[QUEUE] Stored info from 109
[RECEIVE] Queued message from 109
[QUEUE] Processing info from 109
[QUEUE] Stored info from 109
[RECEIVE] Queued message from 109
[QUEUE] Processing info from 109
[QUEUE] Stored info from 109
[RECEIVE] Queued message from 109
[QUEUE] Processing info from 109
[QUEUE] Stored info from 109
[RECEIVE] Queued message from 109
[QUEUE] Processing info from 109
[QUEUE] Stored info from 109
[RECEIVE] Queued message from 109
[QUEUE] Processing info from 109
[QUEUE] Stored info from 109
[RECEIVE] Queued message from 109
[QUEUE] Processing info from 109
[QUEUE] Stored info from 109
[RECEIVE] Queued message from 109
[QUEUE] Processing info from 109
[QUEUE] Stored info from 109
[RECEIVE] Queued message from 109
[QUEUE] Processing info from 109
[QUEUE] Stored info from 109
[RECEIVE] Queued message from 109
[QUEUE] Processing info from 109
[QUEUE] Stored info from 109
[RECEIVE] Queued message from 109
[QUEUE] Processing info from 109
[QUEUE] Stored info from 109
[RECEIVE] Queued message from 109
[QUEUE] Processing info from 109
[QUEUE] Stored info from 109
[RECEIVE] Queued message from 109
[QUEUE] Processing info from 109
[QUEUE] Stored info from 109
[RECEIVE] Queued message from 109
[QUEUE] Processing info from 109
[QUEUE] Stored info from 109
[RECEIVE] Queued message from 109
[QUEUE] Processing info from 109
[QUEUE] Stored info from 109
[RECEIVE] Queued message from 109
[QUEUE] Processing info from 109
[QUEUE] Stored info from 109
[RECEIVE] Queued message from 109
[QUEUE] Processing info from 109
[QUEUE] Stored info from 109
[RECEIVE] Queued message from 109
[QUEUE] Processing info from 109
[QUEUE] Stored info from 109
[RECEIVE] Queued message from 109
[QUEUE] Processing info from 109
[QUEUE] Stored info from 109
[RECEIVE] Queued message from 109
[QUEUE] Processing info from 109
[QUEUE] Stored info from 109
[RECEIVE] Queued message from 109
[QUEUE] Processing info from 109
[QUEUE] Stored info from 109
[RECEIVE] Queued message from 109
[QUEUE] Processing info from 109
[QUEUE] Stored info from 109
[141] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2338.18it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:20,  2.70s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:23,  1.46s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:47,  1.23s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:33,  1.13s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:27,  1.11s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:13<02:24,  1.10s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:14,  1.05s/it]Running loglikelihood requests:  11%|█         | 15/142 [00:17<02:24,  1.14s/it]Running loglikelihood requests:  12%|█▏        | 17/142 [00:19<02:11,  1.05s/it]Running loglikelihood requests:  13%|█▎        | 19/142 [00:21<02:04,  1.01s/it]Running loglikelihood requests:  15%|█▍        | 21/142 [00:23<02:03,  1.02s/it]Running loglikelihood requests:  16%|█▌        | 23/142 [00:24<01:52,  1.06it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:26<01:44,  1.12it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:27<01:38,  1.17it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:29<01:33,  1.21it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:31<01:34,  1.18it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:32<01:29,  1.21it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:34<01:26,  1.24it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:35<01:22,  1.27it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:37<01:20,  1.28it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:38<01:18,  1.29it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:40<01:15,  1.31it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:41<01:15,  1.29it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:43<01:11,  1.33it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:44<01:07,  1.37it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:45<01:04,  1.41it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:47<01:02,  1.43it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:48<00:59,  1.46it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:49<00:57,  1.47it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:51<00:58,  1.42it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:52<00:55,  1.45it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:54<00:53,  1.48it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:55<00:51,  1.50it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:56<00:49,  1.52it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:57<00:47,  1.54it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:59<00:45,  1.55it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [01:00<00:44,  1.56it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [01:01<00:44,  1.49it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:03<00:42,  1.52it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:04<00:40,  1.54it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:05<00:39,  1.56it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:06<00:37,  1.57it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:08<00:36,  1.58it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:09<00:34,  1.59it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:10<00:33,  1.60it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:12<00:37,  1.35it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:13<00:34,  1.42it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:15<00:31,  1.48it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:16<00:29,  1.51it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:17<00:27,  1.54it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:18<00:26,  1.57it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:20<00:24,  1.59it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:22<00:30,  1.23it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:23<00:26,  1.33it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:27<00:34,  1.04s/it]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:28<00:28,  1.10it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:29<00:23,  1.23it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:30<00:20,  1.34it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:32<00:18,  1.38it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:33<00:16,  1.38it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:34<00:14,  1.45it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:35<00:12,  1.51it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:37<00:11,  1.51it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:38<00:09,  1.56it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:39<00:08,  1.61it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:40<00:06,  1.63it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:42<00:06,  1.50it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:43<00:04,  1.57it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:44<00:03,  1.63it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:45<00:01,  1.67it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:46<00:00,  1.71it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:46<00:00,  1.33it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-4): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-6): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (7-8): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (11-12): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (13): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14-31): 18 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-4): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-6): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (7-8): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (11-12): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (13): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14-31): 18 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/141.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5206
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:52:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5206 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 206
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5230
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:52:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5230 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 230
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:52:34] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5013
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:52:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5013 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 13
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5006
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:52:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5006 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 6
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5044
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:52:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5044 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 44
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5133
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:52:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5133 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 133
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:52:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5082
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:52:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5082 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 82
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:52:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5104
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:52:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5104 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 104
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5026
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:52:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5026 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 26
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5109
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:52:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5109 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 109
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5004
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:52:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5004 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 4
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:52:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:52:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5205
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:52:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5205 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 205
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5027
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:52:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5027 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 27
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5242
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:52:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5242 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 242
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5243
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:52:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5243 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 243
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:52:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:52:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:52:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5029
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:52:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5029 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 29
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5080
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:52:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5080 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 80
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5060
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:52:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5060 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 60
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5011
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:52:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5011 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 11
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5236
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:52:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5236 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 236
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5045
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:52:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5045 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 45
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:52:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5171
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:52:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5171 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 171
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139721436304720 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139721436304720 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139721436304720 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139721436304720 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139722780710656 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139722780710656 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139722780710656 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139722780710656 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[141] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4507042253521127, 'acc_stderr,none': 0.05947027187738001}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9728816226148068
0.5587440604316873
0.8603958805228331
0.8559030347476725
0.9827298775692989
0.9752051704922662
0.9320451620794601
0.8534915859631292
0.8216376829910712
0.7152752058820862
0.865677149871932
0.6996438609344103
0.5450489764598446
0.9459412501293835
0.800938078166953
0.9388899316299849
0.6171018502143922
0.5700995146297211
0.9725502911927032
0.8593526631716398
0.8340908152739906
0.8867570952520308
0.8278223956249111
0.6726110030960961
0.822005113004547
0.952024055144357
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[2, 6, 4, 1, 3, 0, 7, 5]
tensor([2, 6, 4, 1, 3, 0, 7, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 6, 3, 1, 5, 0, 7, 2]
tensor([4, 6, 3, 1, 5, 0, 7, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 4, 2, 5, 0, 7, 3]
tensor([6, 1, 4, 2, 5, 0, 7, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 3, 7, 1, 6, 0, 5, 2]
tensor([4, 3, 7, 1, 6, 0, 5, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 6, 5, 1, 3, 0, 4, 2]
tensor([7, 6, 5, 1, 3, 0, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[1, 0, 5, 4, 3, 0, 1, 2]
tensor([1, 0, 5, 4, 3, 0, 1, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 3, 0, 2, 1, 3, 2]
tensor([0, 1, 3, 0, 2, 1, 3, 2], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/141.pt
[RECEIVE] Queued message from 141
[QUEUE] Processing info from 141
[QUEUE] Stored info from 141
[RECEIVE] Queued message from 141
[QUEUE] Processing info from 141
[QUEUE] Stored info from 141
[RECEIVE] Queued message from 141
[QUEUE] Processing info from 141
[QUEUE] Stored info from 141
[RECEIVE] Queued message from 141
[QUEUE] Processing info from 141
[QUEUE] Stored info from 141
[RECEIVE] Queued message from 141
[QUEUE] Processing info from 141
[QUEUE] Stored info from 141
[RECEIVE] Queued message from 141
[QUEUE] Processing info from 141
[QUEUE] Stored info from 141
[RECEIVE] Queued message from 141
[QUEUE] Processing info from 141
[QUEUE] Stored info from 141
[RECEIVE] Queued message from 141
[QUEUE] Processing info from 141
[QUEUE] Stored info from 141
[RECEIVE] Queued message from 141
[QUEUE] Processing info from 141
[QUEUE] Stored info from 141
[RECEIVE] Queued message from 141
[QUEUE] Processing info from 141
[QUEUE] Stored info from 141
[RECEIVE] Queued message from 141
[QUEUE] Processing info from 141
[QUEUE] Stored info from 141
[RECEIVE] Queued message from 141
[QUEUE] Processing info from 141
[QUEUE] Stored info from 141
[RECEIVE] Queued message from 141
[QUEUE] Processing info from 141
[QUEUE] Stored info from 141
[RECEIVE] Queued message from 141
[QUEUE] Processing info from 141
[QUEUE] Stored info from 141
[RECEIVE] Queued message from 141
[QUEUE] Processing info from 141
[QUEUE] Stored info from 141
[RECEIVE] Queued message from 141
[QUEUE] Processing info from 141
[QUEUE] Stored info from 141
[RECEIVE] Queued message from 141
[QUEUE] Processing info from 141
[QUEUE] Stored info from 141
[RECEIVE] Queued message from 141
[QUEUE] Processing info from 141
[QUEUE] Stored info from 141
[RECEIVE] Queued message from 141
[QUEUE] Processing info from 141
[QUEUE] Stored info from 141
[RECEIVE] Queued message from 141
[QUEUE] Processing info from 141
[QUEUE] Stored info from 141
[RECEIVE] Queued message from 141
[QUEUE] Processing info from 141
[QUEUE] Stored info from 141
[RECEIVE] Queued message from 141
[QUEUE] Processing info from 141
[QUEUE] Stored info from 141
[RECEIVE] Queued message from 141
[QUEUE] Processing info from 141
[QUEUE] Stored info from 141
[RECEIVE] Queued message from 141
[QUEUE] Processing info from 141
[QUEUE] Stored info from 141
[RECEIVE] Queued message from 141
[QUEUE] Processing info from 141
[QUEUE] Stored info from 141
[RECEIVE] Queued message from 141
[QUEUE] Processing info from 141
[QUEUE] Stored info from 141
[RECEIVE] Queued message from 141
[QUEUE] Processing info from 141
[QUEUE] Stored info from 141
[RECEIVE] Queued message from 141
[QUEUE] Processing info from 141
[QUEUE] Stored info from 141
[RECEIVE] Queued message from 141
[QUEUE] Processing info from 141
[QUEUE] Stored info from 141
[RECEIVE] Queued message from 141
[QUEUE] Processing info from 141
[QUEUE] Stored info from 141
[RECEIVE] Queued message from 141
[QUEUE] Processing info from 141
[QUEUE] Stored info from 141
[163] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2585.39it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:03,  2.57s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:11,  1.38s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:38,  1.15s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:24,  1.07s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:19,  1.05s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:11,  1.00s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:13<02:04,  1.04it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:15<01:57,  1.08it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:17<01:51,  1.12it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:18<01:45,  1.16it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:20<01:44,  1.15it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:22<01:39,  1.20it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:23<01:33,  1.25it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:25<01:29,  1.29it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:26<01:26,  1.31it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:27<01:23,  1.33it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:29<01:20,  1.35it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:30<01:21,  1.31it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:32<01:18,  1.33it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:33<01:16,  1.35it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:35<01:17,  1.30it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:36<01:14,  1.33it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:38<01:11,  1.36it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:42<01:48,  1.15s/it]Running loglikelihood requests:  35%|███▍      | 49/142 [00:43<01:33,  1.00s/it]Running loglikelihood requests:  36%|███▌      | 51/142 [00:45<01:21,  1.12it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:46<01:13,  1.22it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:47<01:06,  1.30it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:49<01:01,  1.37it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:50<00:58,  1.43it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:51<00:57,  1.41it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:53<00:54,  1.46it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:54<00:51,  1.50it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:55<00:49,  1.53it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:56<00:46,  1.55it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:58<00:45,  1.57it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:59<00:43,  1.59it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [01:00<00:41,  1.60it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:01<00:42,  1.52it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:03<00:40,  1.55it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:04<00:38,  1.58it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:05<00:36,  1.60it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:06<00:35,  1.61it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:08<00:33,  1.63it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:09<00:32,  1.64it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:10<00:30,  1.65it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:11<00:31,  1.55it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:13<00:29,  1.59it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:14<00:27,  1.62it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:15<00:26,  1.65it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:16<00:24,  1.67it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:17<00:23,  1.69it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:18<00:21,  1.69it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:20<00:20,  1.70it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:21<00:19,  1.72it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:22<00:18,  1.66it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:23<00:17,  1.68it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:24<00:15,  1.70it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:25<00:14,  1.70it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:27<00:13,  1.72it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:28<00:12,  1.73it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:29<00:10,  1.73it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:30<00:09,  1.75it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:31<00:08,  1.77it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:33<00:08,  1.61it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:34<00:06,  1.66it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:35<00:05,  1.71it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:36<00:03,  1.75it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:37<00:02,  1.79it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:38<00:01,  1.82it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:39<00:00,  1.86it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:39<00:00,  1.43it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-31): 26 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-31): 26 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/163.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5109
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:54:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5109 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 109
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5045
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:54:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5045 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 45
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5011
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:54:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5011 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 11
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:54:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5004
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:54:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5004 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 4
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:54:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:54:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:54:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5133
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:54:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5133 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 133
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:54:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5060
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:54:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5060 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 60
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5029
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:54:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5029 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 29
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5006
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:54:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5006 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 6
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5243
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:54:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5243 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 243
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5205
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:54:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5205 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 205
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5206
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:54:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5206 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 206
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5026
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:54:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5026 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 26
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5027
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:54:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5027 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 27
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5080
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:54:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5080 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 80
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5082
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:54:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5082 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 82
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:54:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:54:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5171
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:54:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5171 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 171
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5141
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:54:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5141 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 141
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5242
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:54:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5242 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 242
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5044
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:54:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5044 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 44
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5230
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:54:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5230 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 230
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:54:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5013
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:54:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5013 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 13
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5104
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:54:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5104 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 104
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5236
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:54:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5236 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 236
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139721450090192 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139721450090192 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139721450090192 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139721450090192 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139721071807952 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139721071807952 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139721071807952 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139721071807952 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[163] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4225352112676056, 'acc_stderr,none': 0.059039842056825796}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8301327615319641
0.7817720914227475
0.8113678911982368
0.2257173763133808
0.2927105469616105
0.5177793359335131
0.8145737190612207
0.7363478990038121
0.20758834533702153
0.2533018140549718
0.30764875086796684
0.29044714199656413
0.9350374080783923
0.6277994360424477
0.603553220567354
0.78279661631625
0.6718149226457006
0.5353760149732133
0.6848376228333551
0.9446001512801305
0.7972906165117697
0.5043025319455414
0.5939887608746786
0.6455402209569181
0.2505215486241291
0.321550947803521
0.8361163063826382
0.7208169010376037
0.9633188772100769
0.8301327615319641
0.7817720914227475
0.8113678911982368
0.2257173763133808
0.2927105469616105
0.5177793359335131
0.8145737190612207
0.7363478990038121
0.20758834533702153
0.2533018140549718
0.30764875086796684
0.29044714199656413
0.9350374080783923
0.6277994360424477
0.603553220567354
0.78279661631625
0.6718149226457006
0.5353760149732133
0.6848376228333551
0.9446001512801305
0.7972906165117697
0.5043025319455414
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[6, 5, 4, 1, 3, 0, 7, 2]
tensor([6, 5, 4, 1, 3, 0, 7, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 7, 5, 1, 0, 4, 2]
tensor([6, 3, 7, 5, 1, 0, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[6, 4, 7, 0, 3, 1, 5, 2]
tensor([6, 4, 7, 0, 3, 1, 5, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 5, 3, 4, 1, 0, 7, 6]
tensor([2, 5, 3, 4, 1, 0, 7, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 5, 0, 2, 4, 0, 1, 1]
tensor([3, 5, 0, 2, 4, 0, 1, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 1, 0, 2, 1, 2, 3]
tensor([0, 3, 1, 0, 2, 1, 2, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 3, 1, 2, 2, 1, 3, 0]
tensor([0, 3, 1, 2, 2, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 1, 2, 0, 3, 3, 2, 1]
tensor([0, 1, 2, 0, 3, 3, 2, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1, 0, 1.0, 1.0, 1.0, 1.0]
tensor([0, 1, 1, 0, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/163.pt
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[196] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2557.61it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:08,  2.61s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:18,  1.43s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:45,  1.21s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:35,  1.15s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:23,  1.08s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:15,  1.04s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:08,  1.00it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:16<02:02,  1.03it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:18<01:57,  1.07it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:21<02:32,  1.24s/it]Running loglikelihood requests:  15%|█▍        | 21/142 [00:23<02:14,  1.11s/it]Running loglikelihood requests:  16%|█▌        | 23/142 [00:25<01:59,  1.01s/it]Running loglikelihood requests:  18%|█▊        | 25/142 [00:26<01:49,  1.07it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:28<01:41,  1.13it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:29<01:40,  1.12it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:32<01:54,  1.03s/it]Running loglikelihood requests:  23%|██▎       | 33/142 [00:34<01:43,  1.06it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:35<01:34,  1.13it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:37<01:28,  1.19it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:38<01:23,  1.23it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:40<01:24,  1.20it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:41<01:19,  1.25it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:43<01:14,  1.29it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:44<01:11,  1.33it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:45<01:07,  1.37it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:47<01:04,  1.41it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:48<01:01,  1.44it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:50<01:02,  1.39it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:51<00:59,  1.42it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:52<00:57,  1.45it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:54<00:55,  1.47it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:55<00:53,  1.49it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:56<00:51,  1.50it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:58<00:49,  1.51it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:59<00:51,  1.42it/s]Running loglikelihood requests:  50%|█████     | 71/142 [01:00<00:48,  1.46it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [01:02<00:46,  1.49it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [01:03<00:44,  1.51it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:04<00:42,  1.53it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:05<00:40,  1.55it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:07<00:38,  1.57it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:08<00:37,  1.57it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:10<00:40,  1.42it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:11<00:37,  1.48it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:12<00:34,  1.52it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:13<00:32,  1.55it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:15<00:31,  1.57it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:16<00:29,  1.60it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:17<00:27,  1.61it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:18<00:27,  1.55it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:20<00:27,  1.51it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:21<00:25,  1.54it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:22<00:23,  1.57it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:24<00:22,  1.58it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:25<00:20,  1.60it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:26<00:19,  1.62it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:27<00:17,  1.63it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:29<00:17,  1.55it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:30<00:18,  1.38it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:32<00:16,  1.40it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:33<00:14,  1.42it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:34<00:12,  1.50it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:36<00:10,  1.56it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:37<00:09,  1.60it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:38<00:08,  1.62it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:39<00:06,  1.64it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:41<00:05,  1.54it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:42<00:04,  1.61it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:43<00:02,  1.67it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:44<00:01,  1.71it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:45<00:00,  1.63it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:45<00:00,  1.34it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-3): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (4): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-7): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (8): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9-10): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (11): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (12-13): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (15): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (16): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (17-31): 15 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-3): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (4): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-7): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (8): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9-10): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (11): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (12-13): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (15): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (16): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (17-31): 15 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/196.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:56:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5029
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:56:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5029 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 29
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:56:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5045
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:56:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5045 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 45
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:56:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:56:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:56:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5026
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:56:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5026 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 26
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5206
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:56:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5206 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 206
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5060
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:56:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5060 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 60
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5011
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:56:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5011 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 11
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5230
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:56:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5230 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 230
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5141
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:56:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5141 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 141
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5243
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:56:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5243 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 243
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5171
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:56:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5171 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 171
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5080
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:56:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5080 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 80
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5236
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:56:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5236 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 236
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5104
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:56:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5104 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 104
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5133
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:56:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5133 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 133
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5006
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:56:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5006 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 6
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5013
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:56:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5013 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 13
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5044
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:56:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5044 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 44
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:56:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5027
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:56:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5027 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 27
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5109
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:56:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5109 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 109
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:56:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5082
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:56:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5082 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 82
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5004
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:56:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5004 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 4
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:56:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5242
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:56:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5242 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 242
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5205
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:56:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5205 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 205
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139721059469216 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139721059469216 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139721059469216 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139721059469216 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139722764557952 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139722764557952 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139722764557952 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139722764557952 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[196] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.43661971830985913, 'acc_stderr,none': 0.05927935558412972}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.6384788962207051
0.4946572039289874
0.7062468225311351
0.5924118081316296
0.8055799477986278
0.4290834385090486
0.5207152243980063
0.40307410421369466
0.575849756312845
0.37833122092903004
0.559402975459772
0.9202435099718248
0.7328649512638977
0.4656521136449837
0.6226167455222542
0.6500475926241498
0.14933051029764177
0.852848973497393
0.7020336348742873
0.8036038458930006
0.25840240277743587
0.45348406473870356
0.7291236246725161
0.5999541971262276
0.7071125031923391
0.6523270915574834
0.5982105985982268
0.6520903105513685
0.39933491227192136
0.6384788962207051
0.4946572039289874
0.7062468225311351
0.5924118081316296
0.8055799477986278
0.4290834385090486
0.5207152243980063
0.40307410421369466
0.575849756312845
0.37833122092903004
0.559402975459772
0.9202435099718248
0.7328649512638977
0.4656521136449837
0.6226167455222542
0.6500475926241498
0.14933051029764177
0.852848973497393
0.7020336348742873
0.8036038458930006
0.25840240277743587
0.45348406473870356
0.7291236246725161
0.5999541971262276
0.7071125031923391
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[6, 3, 2, 1, 5, 0, 7, 4]
tensor([6, 3, 2, 1, 5, 0, 7, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 5, 4, 2, 6, 0, 7, 1]
tensor([3, 5, 4, 2, 6, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 7, 6, 3, 4, 1, 5, 0]
tensor([2, 7, 6, 3, 4, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 2, 5, 4, 6, 0, 7, 1]
tensor([3, 2, 5, 4, 6, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 5, 7, 0, 3, 2, 6, 1]
tensor([4, 5, 7, 0, 3, 2, 6, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 6, 3, 4, 2, 1, 7, 0]
tensor([5, 6, 3, 4, 2, 1, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/196.pt
[RECEIVE] Queued message from 196
[QUEUE] Processing info from 196
[QUEUE] Stored info from 196
[RECEIVE] Queued message from 196
[QUEUE] Processing info from 196
[QUEUE] Stored info from 196
[RECEIVE] Queued message from 196
[QUEUE] Processing info from 196
[QUEUE] Stored info from 196
[RECEIVE] Queued message from 196
[QUEUE] Processing info from 196
[QUEUE] Stored info from 196
[RECEIVE] Queued message from 196
[QUEUE] Processing info from 196
[QUEUE] Stored info from 196
[RECEIVE] Queued message from 196
[QUEUE] Processing info from 196
[QUEUE] Stored info from 196
[RECEIVE] Queued message from 196
[QUEUE] Processing info from 196
[QUEUE] Stored info from 196
[RECEIVE] Queued message from 196
[QUEUE] Processing info from 196
[QUEUE] Stored info from 196
[RECEIVE] Queued message from 196
[QUEUE] Processing info from 196
[QUEUE] Stored info from 196
[RECEIVE] Queued message from 196
[QUEUE] Processing info from 196
[QUEUE] Stored info from 196
[RECEIVE] Queued message from 196
[QUEUE] Processing info from 196
[QUEUE] Stored info from 196
[RECEIVE] Queued message from 196
[QUEUE] Processing info from 196
[QUEUE] Stored info from 196
[RECEIVE] Queued message from 196
[QUEUE] Processing info from 196
[QUEUE] Stored info from 196
[RECEIVE] Queued message from 196
[QUEUE] Processing info from 196
[QUEUE] Stored info from 196
[RECEIVE] Queued message from 196
[QUEUE] Processing info from 196
[QUEUE] Stored info from 196
[RECEIVE] Queued message from 196
[QUEUE] Processing info from 196
[QUEUE] Stored info from 196
[RECEIVE] Queued message from 196
[QUEUE] Processing info from 196
[QUEUE] Stored info from 196
[RECEIVE] Queued message from 196
[QUEUE] Processing info from 196
[QUEUE] Stored info from 196
[RECEIVE] Queued message from 196
[QUEUE] Processing info from 196
[QUEUE] Stored info from 196
[RECEIVE] Queued message from 196
[QUEUE] Processing info from 196
[QUEUE] Stored info from 196
[RECEIVE] Queued message from 196
[QUEUE] Processing info from 196
[QUEUE] Stored info from 196
[RECEIVE] Queued message from 196
[QUEUE] Processing info from 196
[QUEUE] Stored info from 196
[RECEIVE] Queued message from 196
[QUEUE] Processing info from 196
[QUEUE] Stored info from 196
[RECEIVE] Queued message from 196
[QUEUE] Processing info from 196
[QUEUE] Stored info from 196
[RECEIVE] Queued message from 196
[QUEUE] Processing info from 196
[QUEUE] Stored info from 196
[RECEIVE] Queued message from 196
[QUEUE] Processing info from 196
[QUEUE] Stored info from 196
[RECEIVE] Queued message from 196
[QUEUE] Processing info from 196
[QUEUE] Stored info from 196
[RECEIVE] Queued message from 196
[QUEUE] Processing info from 196
[QUEUE] Stored info from 196
[RECEIVE] Queued message from 196
[QUEUE] Processing info from 196
[QUEUE] Stored info from 196
[RECEIVE] Queued message from 196
[QUEUE] Processing info from 196
[QUEUE] Stored info from 196
[RECEIVE] Queued message from 196
[QUEUE] Processing info from 196
[QUEUE] Stored info from 196
[55] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2594.92it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:38,  2.82s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:21,  1.45s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:44,  1.20s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:28,  1.10s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:21,  1.07s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:12,  1.01s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:05,  1.03it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:15<01:58,  1.08it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:17<01:52,  1.11it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:19<01:45,  1.17it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:20<01:44,  1.16it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:22<01:38,  1.21it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:23<01:33,  1.26it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:25<01:28,  1.30it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:26<01:25,  1.32it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:28<01:22,  1.34it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:29<01:20,  1.35it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:31<01:25,  1.26it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:32<01:21,  1.29it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:34<01:17,  1.32it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:35<01:14,  1.35it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:37<01:12,  1.37it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:38<01:09,  1.40it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:39<01:06,  1.43it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:41<01:07,  1.38it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:42<01:05,  1.39it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:44<01:01,  1.44it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:45<00:58,  1.48it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:46<00:56,  1.51it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:47<00:54,  1.53it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:49<00:52,  1.54it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:50<00:52,  1.52it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:52<00:54,  1.41it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:53<00:51,  1.46it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:54<00:48,  1.51it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:55<00:46,  1.54it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:57<00:43,  1.57it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [00:58<00:42,  1.58it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [00:59<00:40,  1.59it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:00<00:39,  1.61it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:02<00:38,  1.57it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:03<00:37,  1.59it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:04<00:37,  1.54it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:05<00:34,  1.58it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:07<00:33,  1.61it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:08<00:31,  1.62it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:09<00:29,  1.64it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:10<00:28,  1.65it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:12<00:28,  1.56it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:13<00:26,  1.59it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:14<00:25,  1.63it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:15<00:23,  1.65it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:16<00:22,  1.67it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:18<00:20,  1.69it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:19<00:19,  1.67it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:20<00:18,  1.69it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:22<00:19,  1.49it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:23<00:17,  1.56it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:24<00:15,  1.60it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:25<00:13,  1.65it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:26<00:12,  1.68it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:27<00:11,  1.67it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:29<00:11,  1.51it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:30<00:09,  1.58it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:31<00:08,  1.58it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:33<00:06,  1.64it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:34<00:05,  1.70it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:35<00:04,  1.74it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:36<00:02,  1.77it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:37<00:01,  1.80it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:38<00:00,  1.82it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:38<00:00,  1.44it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-2): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (3-4): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-7): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (8-31): 24 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-2): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (3-4): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-7): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (8-31): 24 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/55.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5013
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:58:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5013 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 13
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5242
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:58:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5242 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 242
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:58:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5205
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:58:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5205 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 205
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5026
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:58:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5026 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 26
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:58:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5011
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:58:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5011 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 11
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5044
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:58:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5044 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 44
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5082
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:58:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5082 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 82
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5141
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:58:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5141 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 141
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:58:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5104
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:58:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5104 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 104
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:58:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5060
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:58:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5060 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 60
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5171
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:58:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5171 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 171
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5080
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:58:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5080 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 80
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:58:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5004
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:58:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5004 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 4
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5027
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:58:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5027 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 27
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:58:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:58:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5109
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:58:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5109 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 109
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5133
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:58:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5133 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 133
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5029
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:58:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5029 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 29
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5236
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:58:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5236 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 236
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5206
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:58:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5206 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 206
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5243
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:58:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5243 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 243
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:58:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5230
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:58:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5230 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 230
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5006
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:58:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5006 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 6
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5045
INFO:werkzeug:127.0.0.1 - - [17/May/2025 18:58:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5045 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 45
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139720623535888 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139720623535888 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139720623535888 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139720623535888 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139720623535888 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139720623535888 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139720623535888 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139720623535888 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[55] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4647887323943662, 'acc_stderr,none': 0.05961305784972239}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8184046739906345
0.7274935575095154
0.7761510346641957
0.4952640991880176
0.6026187510593423
0.9057397954213379
0.8847150465408834
0.8902479029100969
0.8909574741962474
0.9547688146913799
0.8922781384249192
0.8543488371673005
0.875959532399785
0.5999975074231996
0.5166995128054149
0.9251070768460925
0.9548013456523431
0.895916642208903
0.816962777390054
0.8352073170783986
0.8879963837403804
0.7652959230128763
0.6541271822267725
0.6185613360581901
0.9254826611316034
0.6384241255415785
0.5206869695172345
0.6788316772896046
0.8168301435765506
Total groups 76 exceeded the threshold, stopping comparison.
The group tensor is
[3, 2, 6, 5, 1, 0, 7, 4]
tensor([3, 2, 6, 5, 1, 0, 7, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[1, 3, 6, 5, 2, 0, 7, 4]
tensor([1, 3, 6, 5, 2, 0, 7, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[6, 1, 4, 2, 5, 0, 7, 3]
tensor([6, 1, 4, 2, 5, 0, 7, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 0, 7, 4, 3, 1, 6, 5]
tensor([2, 0, 7, 4, 3, 1, 6, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 4, 1, 3, 1, 0, 5, 2]
tensor([0, 4, 1, 3, 1, 0, 5, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[3, 4, 0, 1, 1, 0, 2, 5]
tensor([3, 4, 0, 1, 1, 0, 2, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 3, 1, 2, 1, 2, 3]
tensor([0, 0, 3, 1, 2, 1, 2, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 1, 1.0, 1.0, 1, 1.0, 1.0]
tensor([0, 0, 1, 1, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[1, 0, 1, 1.0, 1.0, 0, 1.0, 1.0]
tensor([1, 0, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[1, 0, 1, 1.0, 1.0, 0, 1.0, 1.0]
tensor([1, 0, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/55.pt
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[26] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2539.60it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:13,  2.65s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:14,  1.40s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:40,  1.17s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:26,  1.08s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:21,  1.06s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:12,  1.01s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:05,  1.03it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:15<01:59,  1.06it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:17<01:53,  1.10it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:19<01:51,  1.10it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:20<01:45,  1.14it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:22<01:39,  1.19it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:23<01:34,  1.23it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:25<01:30,  1.26it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:26<01:27,  1.29it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:28<01:24,  1.31it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:30<01:36,  1.13it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:32<01:29,  1.19it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:33<01:25,  1.23it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:35<01:21,  1.27it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:36<01:17,  1.30it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:38<01:15,  1.32it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:39<01:14,  1.30it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:41<01:11,  1.34it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:42<01:07,  1.38it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:44<01:08,  1.33it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:45<01:04,  1.38it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:46<01:01,  1.42it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:47<00:58,  1.46it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:49<00:56,  1.48it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:50<00:56,  1.43it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:52<00:54,  1.46it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:53<00:51,  1.49it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:54<00:49,  1.50it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:56<00:49,  1.46it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:57<00:47,  1.49it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:58<00:45,  1.52it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [01:00<00:46,  1.44it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:01<00:43,  1.48it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:02<00:41,  1.51it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:03<00:39,  1.53it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:05<00:38,  1.55it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:06<00:36,  1.57it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:07<00:34,  1.58it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:08<00:33,  1.59it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:10<00:34,  1.49it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:11<00:31,  1.53it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:12<00:30,  1.56it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:14<00:28,  1.58it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:15<00:26,  1.60it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:16<00:25,  1.62it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:17<00:23,  1.64it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:18<00:22,  1.64it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:20<00:21,  1.65it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:21<00:20,  1.58it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:22<00:19,  1.61it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:23<00:17,  1.64it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:25<00:16,  1.65it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:26<00:15,  1.66it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:27<00:13,  1.68it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:28<00:12,  1.68it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:29<00:11,  1.70it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:31<00:10,  1.63it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:32<00:09,  1.66it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:34<00:09,  1.44it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:35<00:07,  1.52it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:36<00:05,  1.59it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:37<00:04,  1.60it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:38<00:03,  1.66it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:39<00:01,  1.72it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:41<00:00,  1.70it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:41<00:00,  1.41it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-5): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (7-18): 12 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (19): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (20): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (21): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (22): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (23): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24-27): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (28): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (29-31): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-5): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (7-18): 12 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (19): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (20): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (21): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (22): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (23): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24-27): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (28): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (29-31): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/26.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5205
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:00:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5205 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 205
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:00:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:00:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5243
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:00:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5243 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 243
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5242
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:00:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5242 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 242
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5006
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:00:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5006 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 6
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5044
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:00:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5044 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 44
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5080
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:00:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5080 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 80
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5004
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:00:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5004 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 4
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5060
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:00:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5060 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 60
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:00:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5013
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:00:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5013 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 13
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:00:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5109
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:00:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5109 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 109
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:00:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5206
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:00:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5206 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 206
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5133
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:00:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5133 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 133
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:00:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5171
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:00:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5171 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 171
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:00:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5230
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:00:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5230 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 230
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:00:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5011
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:00:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5011 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 11
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:00:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5104
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:00:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5104 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 104
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5236
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:00:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5236 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 236
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5141
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:00:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5141 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 141
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5045
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:00:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5045 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 45
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5082
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:00:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5082 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 82
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5027
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:00:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5027 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 27
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5029
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:00:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5029 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 29
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139721436307408 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139721436307408 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139721436307408 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139721436307408 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139720654629456 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139720654629456 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139720654629456 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139720654629456 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[26] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.43661971830985913, 'acc_stderr,none': 0.05927935558412972}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8579940969956122
0.9172414698319051
0.5383905049167778
0.7154451748054276
0.547671504517951
0.8833126318549385
0.815742382492854
0.6517871119418787
0.320270438500039
0.20847052823122236
0.9142272844016534
0.8979022224289909
0.8081306275049516
0.5991072724268783
0.8920856671099552
0.8548931916511182
0.9545918502043321
0.9270787839270334
0.4466502436196787
0.892147307459623
0.7319083135729072
0.8321772812735796
0.9605666801588856
0.3242808765028886
0.884060616512067
0.5116280105615226
0.22259676802614164
0.8272877996431262
Total groups 68 exceeded the threshold, stopping comparison.
The group tensor is
[3, 2, 7, 4, 5, 0, 6, 1]
tensor([3, 2, 7, 4, 5, 0, 6, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[1, 6, 5, 4, 2, 0, 7, 3]
tensor([1, 6, 5, 4, 2, 0, 7, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 3, 5, 6, 1, 2, 7, 0]
tensor([4, 3, 5, 6, 1, 2, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[2, 5, 3, 7, 0, 1, 6, 4]
tensor([2, 5, 3, 7, 0, 1, 6, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 2, 1, 1, 3, 2, 3]
tensor([0, 0, 2, 1, 1, 3, 2, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[3, 0, 2, 1, 1, 0, 2, 3]
tensor([3, 0, 2, 1, 1, 0, 2, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 1, 1.0, 1, 1.0, 1.0, 1.0]
tensor([0, 0, 1, 1, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[1, 0, 1, 1.0, 1.0, 0, 1.0, 1.0]
tensor([1, 0, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/26.pt
[RECEIVE] Queued message from 26
[QUEUE] Processing info from 26
[QUEUE] Stored info from 26
[RECEIVE] Queued message from 26
[QUEUE] Processing info from 26
[QUEUE] Stored info from 26
[RECEIVE] Queued message from 26
[QUEUE] Processing info from 26
[QUEUE] Stored info from 26
[RECEIVE] Queued message from 26
[QUEUE] Processing info from 26
[QUEUE] Stored info from 26
[RECEIVE] Queued message from 26
[QUEUE] Processing info from 26
[QUEUE] Stored info from 26
[RECEIVE] Queued message from 26
[QUEUE] Processing info from 26
[QUEUE] Stored info from 26
[RECEIVE] Queued message from 26
[QUEUE] Processing info from 26
[QUEUE] Stored info from 26
[RECEIVE] Queued message from 26
[QUEUE] Processing info from 26
[QUEUE] Stored info from 26
[RECEIVE] Queued message from 26
[QUEUE] Processing info from 26
[QUEUE] Stored info from 26
[RECEIVE] Queued message from 26
[QUEUE] Processing info from 26
[QUEUE] Stored info from 26
[RECEIVE] Queued message from 26
[QUEUE] Processing info from 26
[QUEUE] Stored info from 26
[RECEIVE] Queued message from 26
[QUEUE] Processing info from 26
[QUEUE] Stored info from 26
[RECEIVE] Queued message from 26
[QUEUE] Processing info from 26
[QUEUE] Stored info from 26
[RECEIVE] Queued message from 26
[QUEUE] Processing info from 26
[QUEUE] Stored info from 26
[RECEIVE] Queued message from 26
[QUEUE] Processing info from 26
[QUEUE] Stored info from 26
[RECEIVE] Queued message from 26
[QUEUE] Processing info from 26
[QUEUE] Stored info from 26
[RECEIVE] Queued message from 26
[QUEUE] Processing info from 26
[QUEUE] Stored info from 26
[RECEIVE] Queued message from 26
[QUEUE] Processing info from 26
[QUEUE] Stored info from 26
[RECEIVE] Queued message from 26
[QUEUE] Processing info from 26
[QUEUE] Stored info from 26
[RECEIVE] Queued message from 26
[QUEUE] Processing info from 26
[QUEUE] Stored info from 26
[RECEIVE] Queued message from 26
[QUEUE] Processing info from 26
[QUEUE] Stored info from 26
[RECEIVE] Queued message from 26
[QUEUE] Processing info from 26
[QUEUE] Stored info from 26
[RECEIVE] Queued message from 26
[QUEUE] Processing info from 26
[QUEUE] Stored info from 26
[RECEIVE] Queued message from 26
[QUEUE] Processing info from 26
[QUEUE] Stored info from 26
[RECEIVE] Queued message from 26
[QUEUE] Processing info from 26
[QUEUE] Stored info from 26
[RECEIVE] Queued message from 26
[QUEUE] Processing info from 26
[QUEUE] Stored info from 26
[RECEIVE] Queued message from 26
[QUEUE] Processing info from 26
[QUEUE] Stored info from 26
[RECEIVE] Queued message from 26
[QUEUE] Processing info from 26
[QUEUE] Stored info from 26
[RECEIVE] Queued message from 26
[QUEUE] Processing info from 26
[QUEUE] Stored info from 26
[RECEIVE] Queued message from 26
[QUEUE] Processing info from 26
[QUEUE] Stored info from 26
[RECEIVE] Queued message from 26
[QUEUE] Processing info from 26
[QUEUE] Stored info from 26
[206] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2624.86it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:10,  2.63s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:16,  1.41s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:52,  1.26s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:32,  1.13s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:20,  1.06s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:11,  1.00s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:04,  1.04it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:16<02:00,  1.05it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:17<01:54,  1.09it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:19<01:46,  1.15it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:20<01:41,  1.20it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:22<01:35,  1.24it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:23<01:31,  1.28it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:25<01:27,  1.31it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:26<01:26,  1.30it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:28<01:23,  1.33it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:29<01:21,  1.34it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:30<01:18,  1.36it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:32<01:16,  1.37it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:33<01:14,  1.38it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:35<01:12,  1.39it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:36<01:14,  1.33it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:38<01:10,  1.37it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:39<01:07,  1.41it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:40<01:04,  1.44it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:42<01:04,  1.42it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:43<01:00,  1.46it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:44<00:57,  1.50it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:46<00:57,  1.47it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:47<00:55,  1.50it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:48<00:53,  1.52it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:50<00:51,  1.54it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:51<00:49,  1.56it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:52<00:47,  1.58it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:53<00:45,  1.59it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:55<00:44,  1.60it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:56<00:44,  1.53it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [00:57<00:42,  1.57it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [00:58<00:40,  1.60it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:00<00:38,  1.62it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:01<00:37,  1.64it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:02<00:35,  1.64it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:03<00:34,  1.65it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:04<00:33,  1.66it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:06<00:31,  1.68it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:07<00:33,  1.53it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:08<00:31,  1.58it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:09<00:29,  1.62it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:11<00:27,  1.65it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:12<00:25,  1.67it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:13<00:24,  1.68it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:14<00:23,  1.69it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:15<00:21,  1.69it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:17<00:23,  1.51it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:18<00:21,  1.57it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:19<00:19,  1.62it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:20<00:17,  1.66it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:21<00:15,  1.70it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:23<00:14,  1.71it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:24<00:13,  1.73it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:25<00:12,  1.75it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:26<00:10,  1.77it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:28<00:11,  1.53it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:29<00:09,  1.60it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:30<00:07,  1.66it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:31<00:06,  1.71it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:32<00:05,  1.75it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:33<00:03,  1.79it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:34<00:02,  1.82it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:35<00:01,  1.85it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:37<00:00,  1.59it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:37<00:00,  1.46it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-2): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (3-4): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-7): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (8-25): 18 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (26): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (27-31): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-2): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (3-4): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-7): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (8-25): 18 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (26): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (27-31): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/206.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5171
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:02:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5171 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 171
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5006
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:02:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5006 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 6
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:02:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:02:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:02:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5026
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:02:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5026 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 26
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:02:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:02:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5082
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:02:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5082 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 82
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5205
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:02:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5205 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 205
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:02:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:02:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5004
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:02:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5004 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 4
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5011
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:02:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5011 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 11
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:02:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5141
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:02:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5141 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 141
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5044
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:02:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5044 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 44
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5060
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:02:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5060 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 60
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5242
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:02:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5242 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 242
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:02:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5027
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:02:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5027 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 27
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5109
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:02:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5109 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 109
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5133
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:02:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5133 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 133
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5243
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:02:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5243 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 243
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5045
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:02:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5045 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 45
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5080
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:02:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5080 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 80
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5104
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:02:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5104 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 104
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5230
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:02:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5230 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 230
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5029
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:02:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5029 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 29
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5013
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:02:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5013 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 13
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5236
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:02:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5236 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 236
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139718426427024 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139718426427024 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139718426427024 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139718426427024 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139718425634880 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139718425634880 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139718425634880 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139718425634880 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[206] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4507042253521127, 'acc_stderr,none': 0.05947027187738001}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.4211049002945932
0.6717558353282359
0.7474911564899941
0.6826176878179091
0.7797142635267413
0.8231499933202435
0.9112841579744179
0.9329117857417774
0.3884156651377716
0.7116719161574963
0.3163186199985964
0.7579641143181478
0.7487852880300513
0.644901206148365
0.6252899485594469
0.8300709483875389
0.9686405093585702
0.4827230969630938
0.4401250454367978
0.846541236433719
0.9874080634814415
0.6954384705363965
0.33457229698994645
0.3090774332022817
0.9161115178604439
0.6466213503285708
0.719815146262638
0.8765685188625579
0.30061586460742784
0.4211049002945932
0.6717558353282359
0.7474911564899941
0.6826176878179091
0.7797142635267413
0.8231499933202435
0.9112841579744179
0.9329117857417774
0.3884156651377716
0.7116719161574963
0.3163186199985964
0.7579641143181478
0.7487852880300513
0.644901206148365
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[2, 5, 6, 1, 4, 0, 7, 3]
tensor([2, 5, 6, 1, 4, 0, 7, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 4, 6, 1, 5, 0, 7, 3]
tensor([2, 4, 6, 1, 5, 0, 7, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 2, 7, 0, 1, 3, 6, 5]
tensor([4, 2, 7, 0, 1, 3, 6, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[6, 3, 7, 1, 2, 0, 5, 4]
tensor([6, 3, 7, 1, 2, 0, 5, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 5, 0, 0, 2, 3, 1, 1]
tensor([4, 5, 0, 0, 2, 3, 1, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 4, 1, 2, 1, 0, 3, 5]
tensor([0, 4, 1, 2, 1, 0, 3, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 5, 0, 2, 1, 1, 4]
tensor([0, 3, 5, 0, 2, 1, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/206.pt
[RECEIVE] Queued message from 206
[QUEUE] Processing info from 206
[QUEUE] Stored info from 206
[RECEIVE] Queued message from 206
[QUEUE] Processing info from 206
[QUEUE] Stored info from 206
[RECEIVE] Queued message from 206
[QUEUE] Processing info from 206
[QUEUE] Stored info from 206
[RECEIVE] Queued message from 206
[QUEUE] Processing info from 206
[QUEUE] Stored info from 206
[RECEIVE] Queued message from 206
[QUEUE] Processing info from 206
[QUEUE] Stored info from 206
[RECEIVE] Queued message from 206
[QUEUE] Processing info from 206
[QUEUE] Stored info from 206
[RECEIVE] Queued message from 206
[QUEUE] Processing info from 206
[QUEUE] Stored info from 206
[RECEIVE] Queued message from 206
[QUEUE] Processing info from 206
[QUEUE] Stored info from 206
[RECEIVE] Queued message from 206
[QUEUE] Processing info from 206
[QUEUE] Stored info from 206
[RECEIVE] Queued message from 206
[QUEUE] Processing info from 206
[QUEUE] Stored info from 206
[RECEIVE] Queued message from 206
[QUEUE] Processing info from 206
[QUEUE] Stored info from 206
[RECEIVE] Queued message from 206
[QUEUE] Processing info from 206
[QUEUE] Stored info from 206
[RECEIVE] Queued message from 206
[QUEUE] Processing info from 206
[QUEUE] Stored info from 206
[RECEIVE] Queued message from 206
[QUEUE] Processing info from 206
[QUEUE] Stored info from 206
[RECEIVE] Queued message from 206
[QUEUE] Processing info from 206
[QUEUE] Stored info from 206
[RECEIVE] Queued message from 206
[QUEUE] Processing info from 206
[QUEUE] Stored info from 206
[RECEIVE] Queued message from 206
[QUEUE] Processing info from 206
[QUEUE] Stored info from 206
[RECEIVE] Queued message from 206
[QUEUE] Processing info from 206
[QUEUE] Stored info from 206
[RECEIVE] Queued message from 206
[QUEUE] Processing info from 206
[QUEUE] Stored info from 206
[RECEIVE] Queued message from 206
[QUEUE] Processing info from 206
[QUEUE] Stored info from 206
[RECEIVE] Queued message from 206
[QUEUE] Processing info from 206
[QUEUE] Stored info from 206
[RECEIVE] Queued message from 206
[QUEUE] Processing info from 206
[QUEUE] Stored info from 206
[RECEIVE] Queued message from 206
[QUEUE] Processing info from 206
[QUEUE] Stored info from 206
[RECEIVE] Queued message from 206
[QUEUE] Processing info from 206
[QUEUE] Stored info from 206
[RECEIVE] Queued message from 206
[QUEUE] Processing info from 206
[QUEUE] Stored info from 206
[RECEIVE] Queued message from 206
[QUEUE] Processing info from 206
[QUEUE] Stored info from 206
[RECEIVE] Queued message from 206
[QUEUE] Processing info from 206
[QUEUE] Stored info from 206
[RECEIVE] Queued message from 206
[QUEUE] Processing info from 206
[QUEUE] Stored info from 206
[RECEIVE] Queued message from 206
[QUEUE] Processing info from 206
[QUEUE] Stored info from 206
[RECEIVE] Queued message from 206
[QUEUE] Processing info from 206
[QUEUE] Stored info from 206
[RECEIVE] Queued message from 206
[QUEUE] Processing info from 206
[QUEUE] Stored info from 206
[87] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 1688.33it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:04,  2.59s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:10,  1.37s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:44,  1.20s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:25,  1.08s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:22,  1.07s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:12,  1.01s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:05,  1.03it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:15<02:02,  1.04it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:17<01:54,  1.09it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:19<01:46,  1.15it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:20<01:40,  1.20it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:22<01:34,  1.25it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:23<01:30,  1.29it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:24<01:27,  1.32it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:26<01:27,  1.30it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:27<01:23,  1.33it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:29<01:20,  1.35it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:30<01:17,  1.38it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:32<01:15,  1.39it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:33<01:13,  1.41it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:34<01:11,  1.41it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:36<01:12,  1.36it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:37<01:09,  1.40it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:39<01:06,  1.43it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:40<01:03,  1.47it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:41<01:00,  1.50it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:43<00:58,  1.53it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:44<00:56,  1.55it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:45<00:54,  1.56it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:47<01:05,  1.27it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:49<00:59,  1.35it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:50<00:55,  1.42it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:51<00:51,  1.48it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:52<00:49,  1.52it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:53<00:46,  1.56it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:55<00:44,  1.59it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:56<00:44,  1.56it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [00:57<00:42,  1.59it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [00:58<00:40,  1.61it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:00<00:38,  1.63it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:01<00:37,  1.65it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:02<00:35,  1.66it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:03<00:34,  1.67it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:04<00:32,  1.69it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:05<00:31,  1.68it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:07<00:32,  1.56it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:08<00:30,  1.61it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:09<00:28,  1.64it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:10<00:26,  1.67it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:12<00:25,  1.70it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:13<00:23,  1.71it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:14<00:22,  1.73it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:15<00:21,  1.74it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:17<00:23,  1.46it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:18<00:21,  1.54it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:19<00:19,  1.61it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:20<00:17,  1.66it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:21<00:15,  1.70it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:22<00:14,  1.72it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:24<00:13,  1.76it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:25<00:11,  1.78it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:26<00:10,  1.79it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:27<00:09,  1.72it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:28<00:09,  1.61it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:30<00:07,  1.67it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:31<00:06,  1.72it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:32<00:05,  1.77it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:33<00:03,  1.81it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:34<00:02,  1.81it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:35<00:01,  1.85it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:36<00:00,  1.90it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:36<00:00,  1.47it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-7): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (8): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9-13): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14-15): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (16): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (17-23): 7 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24-25): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (26-31): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-7): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (8): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9-13): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14-15): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (16): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (17-23): 7 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24-25): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (26-31): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/87.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5206
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:04:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5206 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 206
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5027
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:04:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5027 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 27
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5011
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:04:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5011 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 11
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5109
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:04:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5109 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 109
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5044
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:04:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5044 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 44
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:04:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5243
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:04:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5243 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 243
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5026
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:04:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5026 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 26
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5006
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:04:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5006 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 6
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5141
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:04:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5141 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 141
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5004
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:04:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5004 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 4
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:04:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5230
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:04:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5230 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 230
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:04:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5082
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:04:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5082 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 82
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5013
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:04:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5013 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 13
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5080
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:04:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5080 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 80
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5236
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:04:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5236 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 236
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:04:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5242
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:04:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5242 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 242
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5029
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:04:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5029 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 29
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5060
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:04:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5060 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 60
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5133
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:04:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5133 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 133
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5171
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:04:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5171 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 171
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5045
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:04:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5045 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 45
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:04:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5104
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:04:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5104 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 104
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:04:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:04:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:04:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5205
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:04:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5205 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 205
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139721063725152 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139721063725152 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139721063725152 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139721063725152 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139718426358320 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139718426358320 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139718426358320 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139718426358320 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[87] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4225352112676056, 'acc_stderr,none': 0.059039842056825796}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.4006974550645674
0.553274626438677
0.7114020264319938
0.6984504610379519
0.8708568984836823
0.6210210193880212
0.7638777300395475
0.4562187856309214
0.27778416422139596
0.7174549442708792
0.8874047516186899
0.7197371862802024
0.9973953807217149
0.8197334014617479
0.9421229754064668
0.9500023700992883
0.6312941692561447
0.47890039407555335
0.4338007663161437
0.9443928308635141
0.5752272779462101
0.5023096877772295
0.7917678755247893
0.42255885423676204
0.5830463630592772
0.884102890932443
0.7935069002678894
0.6274856483424485
0.841637545221562
0.4006974550645674
0.553274626438677
0.7114020264319938
0.6984504610379519
0.8708568984836823
0.6210210193880212
0.7638777300395475
0.4562187856309214
0.27778416422139596
0.7174549442708792
0.8874047516186899
0.7197371862802024
0.9973953807217149
0.8197334014617479
0.9421229754064668
0.9500023700992883
0.6312941692561447
0.47890039407555335
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[4, 2, 5, 1, 6, 3, 7, 0]
tensor([4, 2, 5, 1, 6, 3, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 4, 7, 5, 1, 0, 6, 2]
tensor([3, 4, 7, 5, 1, 0, 6, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[2, 5, 6, 4, 3, 1, 7, 0]
tensor([2, 5, 6, 4, 3, 1, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[7, 1, 4, 3, 6, 0, 5, 2]
tensor([7, 1, 4, 3, 6, 0, 5, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[0, 5, 3, 1, 1, 0, 2, 4]
tensor([0, 5, 3, 1, 1, 0, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[2, 5, 1, 0, 1, 0, 4, 3]
tensor([2, 5, 1, 0, 1, 0, 4, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[4, 0, 3, 0, 2, 1, 5, 1]
tensor([4, 0, 3, 0, 2, 1, 5, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/87.pt
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[44] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2619.04it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:03<07:28,  3.18s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:05<03:31,  1.52s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:07<02:53,  1.27s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:31,  1.12s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:11<02:36,  1.18s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:13<02:20,  1.07s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:15<02:10,  1.01s/it]Running loglikelihood requests:  11%|█         | 15/142 [00:16<02:05,  1.01it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:18<01:56,  1.07it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:20<01:47,  1.14it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:21<01:41,  1.20it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:22<01:34,  1.25it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:24<01:31,  1.27it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:26<01:29,  1.28it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:27<01:25,  1.32it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:28<01:22,  1.35it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:30<01:19,  1.37it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:31<01:16,  1.39it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:33<01:14,  1.40it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:34<01:12,  1.42it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:35<01:10,  1.43it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:37<01:11,  1.39it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:38<01:07,  1.43it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:39<01:05,  1.45it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:41<01:02,  1.48it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:42<00:59,  1.52it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:43<00:57,  1.54it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:44<00:55,  1.56it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:46<00:54,  1.56it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:47<00:54,  1.53it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:48<00:51,  1.56it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:50<00:50,  1.58it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:51<00:48,  1.60it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:52<00:46,  1.62it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:53<00:44,  1.63it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:54<00:43,  1.64it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:56<00:41,  1.66it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [00:57<00:42,  1.59it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [00:58<00:40,  1.62it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [00:59<00:38,  1.65it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:00<00:36,  1.67it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:02<00:35,  1.68it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:03<00:33,  1.68it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:04<00:32,  1.70it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:05<00:31,  1.70it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:06<00:30,  1.65it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:08<00:29,  1.67it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:09<00:27,  1.70it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:10<00:26,  1.71it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:11<00:24,  1.72it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:12<00:23,  1.74it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:13<00:22,  1.75it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:14<00:21,  1.75it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:15<00:19,  1.76it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:17<00:20,  1.61it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:18<00:18,  1.66it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:19<00:17,  1.70it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:20<00:15,  1.73it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:21<00:14,  1.75it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:23<00:12,  1.77it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:24<00:11,  1.79it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:25<00:10,  1.81it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:26<00:09,  1.81it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:27<00:08,  1.74it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:28<00:07,  1.77it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:29<00:06,  1.79it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:30<00:04,  1.81it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:31<00:03,  1.84it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:32<00:02,  1.86it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:33<00:01,  1.89it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:34<00:00,  1.92it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:34<00:00,  1.50it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-31): 26 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-31): 26 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/44.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:05:55] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5230
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:05:55] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5230 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 230
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5013
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:05:55] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5013 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 13
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5104
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:05:55] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5104 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 104
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5011
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:05:55] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5011 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 11
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:05:55] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5060
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:05:55] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5060 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 60
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5206
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:05:55] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5206 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 206
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5006
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:05:55] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5006 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 6
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5109
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:05:55] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5109 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 109
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:05:55] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5242
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:05:55] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5242 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 242
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5026
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:05:55] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5026 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 26
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5133
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:05:55] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5133 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 133
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5080
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:05:55] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5080 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 80
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5027
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:05:55] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5027 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 27
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5141
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:05:55] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5141 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 141
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5236
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:05:55] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5236 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 236
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:05:55] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5205
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:05:55] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5205 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 205
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5171
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:05:55] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5171 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 171
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5029
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:05:55] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5029 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 29
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5045
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:05:55] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5045 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 45
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5004
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:05:55] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5004 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 4
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:05:55] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5082
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:05:55] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5082 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 82
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5243
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:05:55] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5243 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 243
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:05:55] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:05:55] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:05:55] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:05:55] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139720664293136 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139720664293136 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139720664293136 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139720664293136 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139720638103184 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139720638103184 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139720638103184 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139720638103184 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[44] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4225352112676056, 'acc_stderr,none': 0.059039842056825796}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8301327615319641
0.7817720914227475
0.8113678911982368
0.2257173763133808
0.2927105469616105
0.5177793359335131
0.8145737190612207
0.7363478990038121
0.20758834533702153
0.2533018140549718
0.30764875086796684
0.29044714199656413
0.9350374080783923
0.6277994360424477
0.603553220567354
0.78279661631625
0.6718149226457006
0.5353760149732133
0.6848376228333551
0.9446001512801305
0.7972906165117697
0.5043025319455414
0.5939887608746786
0.6455402209569181
0.2505215486241291
0.321550947803521
0.8361163063826382
0.7208169010376037
0.9633188772100769
0.8301327615319641
0.7817720914227475
0.8113678911982368
0.2257173763133808
0.2927105469616105
0.5177793359335131
0.8145737190612207
0.7363478990038121
0.20758834533702153
0.2533018140549718
0.30764875086796684
0.29044714199656413
0.9350374080783923
0.6277994360424477
0.603553220567354
0.78279661631625
0.6718149226457006
0.5353760149732133
0.6848376228333551
0.9446001512801305
0.7972906165117697
0.5043025319455414
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[6, 5, 4, 1, 3, 0, 7, 2]
tensor([6, 5, 4, 1, 3, 0, 7, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 7, 5, 1, 0, 4, 2]
tensor([6, 3, 7, 5, 1, 0, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[6, 4, 7, 0, 3, 1, 5, 2]
tensor([6, 4, 7, 0, 3, 1, 5, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 5, 3, 4, 1, 0, 7, 6]
tensor([2, 5, 3, 4, 1, 0, 7, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 5, 0, 2, 4, 0, 1, 1]
tensor([3, 5, 0, 2, 4, 0, 1, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 1, 0, 2, 1, 2, 3]
tensor([0, 3, 1, 0, 2, 1, 2, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 3, 1, 2, 2, 1, 3, 0]
tensor([0, 3, 1, 2, 2, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 1, 2, 0, 3, 3, 2, 1]
tensor([0, 1, 2, 0, 3, 3, 2, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1, 0, 1.0, 1.0, 1.0, 1.0]
tensor([0, 1, 1, 0, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/44.pt
[RECEIVE] Queued message from 44
[QUEUE] Processing info from 44
[QUEUE] Stored info from 44
[RECEIVE] Queued message from 44
[QUEUE] Processing info from 44
[QUEUE] Stored info from 44
[RECEIVE] Queued message from 44
[QUEUE] Processing info from 44
[QUEUE] Stored info from 44
[RECEIVE] Queued message from 44
[QUEUE] Processing info from 44
[QUEUE] Stored info from 44
[RECEIVE] Queued message from 44
[QUEUE] Processing info from 44
[QUEUE] Stored info from 44
[RECEIVE] Queued message from 44
[QUEUE] Processing info from 44
[QUEUE] Stored info from 44
[RECEIVE] Queued message from 44
[QUEUE] Processing info from 44
[QUEUE] Stored info from 44
[RECEIVE] Queued message from 44
[QUEUE] Processing info from 44
[QUEUE] Stored info from 44
[RECEIVE] Queued message from 44
[QUEUE] Processing info from 44
[QUEUE] Stored info from 44
[RECEIVE] Queued message from 44
[QUEUE] Processing info from 44
[QUEUE] Stored info from 44
[RECEIVE] Queued message from 44
[QUEUE] Processing info from 44
[QUEUE] Stored info from 44
[RECEIVE] Queued message from 44
[QUEUE] Processing info from 44
[QUEUE] Stored info from 44
[RECEIVE] Queued message from 44
[QUEUE] Processing info from 44
[QUEUE] Stored info from 44
[RECEIVE] Queued message from 44
[QUEUE] Processing info from 44
[QUEUE] Stored info from 44
[RECEIVE] Queued message from 44
[QUEUE] Processing info from 44
[QUEUE] Stored info from 44
[RECEIVE] Queued message from 44
[QUEUE] Processing info from 44
[QUEUE] Stored info from 44
[RECEIVE] Queued message from 44
[QUEUE] Processing info from 44
[QUEUE] Stored info from 44
[RECEIVE] Queued message from 44
[QUEUE] Processing info from 44
[QUEUE] Stored info from 44
[RECEIVE] Queued message from 44
[QUEUE] Processing info from 44
[QUEUE] Stored info from 44
[RECEIVE] Queued message from 44
[QUEUE] Processing info from 44
[QUEUE] Stored info from 44
[RECEIVE] Queued message from 44
[QUEUE] Processing info from 44
[QUEUE] Stored info from 44
[RECEIVE] Queued message from 44
[QUEUE] Processing info from 44
[QUEUE] Stored info from 44
[RECEIVE] Queued message from 44
[QUEUE] Processing info from 44
[QUEUE] Stored info from 44
[RECEIVE] Queued message from 44
[QUEUE] Processing info from 44
[QUEUE] Stored info from 44
[RECEIVE] Queued message from 44
[QUEUE] Processing info from 44
[QUEUE] Stored info from 44
[RECEIVE] Queued message from 44
[QUEUE] Processing info from 44
[QUEUE] Stored info from 44
[RECEIVE] Queued message from 44
[QUEUE] Processing info from 44
[QUEUE] Stored info from 44
[RECEIVE] Queued message from 44
[QUEUE] Processing info from 44
[QUEUE] Stored info from 44
[RECEIVE] Queued message from 44
[QUEUE] Processing info from 44
[QUEUE] Stored info from 44
[RECEIVE] Queued message from 44
[QUEUE] Processing info from 44
[QUEUE] Stored info from 44
[RECEIVE] Queued message from 44
[QUEUE] Processing info from 44
[QUEUE] Stored info from 44
[30] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2599.25it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:04<11:06,  4.73s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:07<05:04,  2.19s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:09<03:32,  1.55s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:11<02:54,  1.30s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:13<02:36,  1.17s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:14<02:21,  1.08s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:16<02:15,  1.05s/it]Running loglikelihood requests:  11%|█         | 15/142 [00:18<02:08,  1.01s/it]Running loglikelihood requests:  12%|█▏        | 17/142 [00:20<01:59,  1.05it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:21<01:51,  1.11it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:23<01:44,  1.15it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:25<01:38,  1.20it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:26<01:36,  1.21it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:28<01:32,  1.24it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:29<01:28,  1.27it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:31<01:25,  1.31it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:32<01:22,  1.33it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:34<01:19,  1.34it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:35<01:17,  1.35it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:37<01:17,  1.32it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:38<01:15,  1.35it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:39<01:12,  1.36it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:41<01:09,  1.39it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:42<01:06,  1.42it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:43<01:04,  1.44it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:45<01:01,  1.47it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:46<00:59,  1.49it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:47<00:59,  1.46it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:49<00:56,  1.50it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:50<00:54,  1.52it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:51<00:52,  1.53it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:53<00:51,  1.54it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:54<00:49,  1.56it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:55<00:47,  1.57it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:56<00:46,  1.58it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:58<00:46,  1.53it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:59<00:44,  1.56it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [01:00<00:42,  1.57it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:01<00:41,  1.58it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:03<00:39,  1.59it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:04<00:38,  1.60it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:05<00:36,  1.61it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:06<00:35,  1.61it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:08<00:35,  1.56it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:09<00:33,  1.59it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:10<00:31,  1.61it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:11<00:30,  1.62it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:13<00:28,  1.63it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:14<00:27,  1.64it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:15<00:26,  1.65it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:16<00:24,  1.67it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:18<00:25,  1.55it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:19<00:23,  1.59it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:20<00:21,  1.62it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:21<00:19,  1.65it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:22<00:18,  1.67it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:23<00:17,  1.69it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:25<00:15,  1.69it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:26<00:14,  1.70it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:27<00:13,  1.72it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:28<00:12,  1.64it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:29<00:11,  1.68it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:31<00:10,  1.58it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:32<00:09,  1.63it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:33<00:07,  1.67it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:34<00:06,  1.70it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:35<00:05,  1.70it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:37<00:04,  1.74it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:38<00:03,  1.66it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:39<00:01,  1.71it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:40<00:00,  1.76it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:40<00:00,  1.41it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-5): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (7-18): 12 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (19): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (20): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (21): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (22): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (23): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24-27): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (28): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (29-31): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-5): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (7-18): 12 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (19): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (20): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (21): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (22): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (23): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24-27): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (28): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (29-31): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/30.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5109
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:07:52] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5109 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 109
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5243
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:07:52] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5243 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 243
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5206
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:07:52] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5206 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 206
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5006
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:07:52] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5006 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 6
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5133
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:07:52] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5133 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 133
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5011
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:07:52] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5011 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 11
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5236
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:07:52] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5236 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 236
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5104
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:07:52] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5104 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 104
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5141
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:07:52] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5141 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 141
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5060
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:07:52] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5060 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 60
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5171
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:07:52] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5171 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 171
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5080
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:07:52] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5080 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 80
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5242
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:07:52] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5242 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 242
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:07:52] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5013
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:07:52] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5013 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 13
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5029
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:07:52] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5029 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 29
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:07:52] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5004
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:07:52] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5004 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 4
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5082
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:07:52] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5082 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 82
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5027
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:07:52] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5027 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 27
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5045
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:07:52] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5045 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 45
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5230
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:07:52] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5230 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 230
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5205
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:07:52] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5205 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 205
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5026
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:07:52] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5026 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 26
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:07:52] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:07:52] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:07:52] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5044
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:07:52] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5044 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 44
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:07:52] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:07:52] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:07:52] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/revision/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 111
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/revision/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139718426304320 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139718426304320 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139718426304320 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139718426304320 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139718978978496 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139718978978496 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139718978978496 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139718978978496 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[30] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.43661971830985913, 'acc_stderr,none': 0.05927935558412972}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8579940969956122
0.9172414698319051
0.5383905049167778
0.7154451748054276
0.547671504517951
0.8833126318549385
0.815742382492854
0.6517871119418787
0.320270438500039
0.20847052823122236
0.9142272844016534
0.8979022224289909
0.8081306275049516
0.5991072724268783
0.8920856671099552
0.8548931916511182
0.9545918502043321
0.9270787839270334
0.4466502436196787
0.892147307459623
0.7319083135729072
0.8321772812735796
0.9605666801588856
0.3242808765028886
0.884060616512067
0.5116280105615226
0.22259676802614164
0.8272877996431262
Total groups 68 exceeded the threshold, stopping comparison.
The group tensor is
[3, 2, 7, 4, 5, 0, 6, 1]
tensor([3, 2, 7, 4, 5, 0, 6, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[1, 6, 5, 4, 2, 0, 7, 3]
tensor([1, 6, 5, 4, 2, 0, 7, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 3, 5, 6, 1, 2, 7, 0]
tensor([4, 3, 5, 6, 1, 2, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[2, 5, 3, 7, 0, 1, 6, 4]
tensor([2, 5, 3, 7, 0, 1, 6, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 2, 1, 1, 3, 2, 3]
tensor([0, 0, 2, 1, 1, 3, 2, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[3, 0, 2, 1, 1, 0, 2, 3]
tensor([3, 0, 2, 1, 1, 0, 2, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 1, 1.0, 1, 1.0, 1.0, 1.0]
tensor([0, 0, 1, 1, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[1, 0, 1, 1.0, 1.0, 0, 1.0, 1.0]
tensor([1, 0, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/30.pt
[RECEIVE] Queued message from 30
[QUEUE] Processing info from 30
[QUEUE] Stored info from 30
[RECEIVE] Queued message from 30
[QUEUE] Processing info from 30
[QUEUE] Stored info from 30
[RECEIVE] Queued message from 30
[QUEUE] Processing info from 30
[QUEUE] Stored info from 30
[RECEIVE] Queued message from 30
[QUEUE] Processing info from 30
[QUEUE] Stored info from 30
[RECEIVE] Queued message from 30
[QUEUE] Processing info from 30
[QUEUE] Stored info from 30
[RECEIVE] Queued message from 30
[QUEUE] Processing info from 30
[QUEUE] Stored info from 30
[RECEIVE] Queued message from 30
[QUEUE] Processing info from 30
[QUEUE] Stored info from 30
[RECEIVE] Queued message from 30
[QUEUE] Processing info from 30
[QUEUE] Stored info from 30
[RECEIVE] Queued message from 30
[QUEUE] Processing info from 30
[QUEUE] Stored info from 30
[RECEIVE] Queued message from 30
[QUEUE] Processing info from 30
[QUEUE] Stored info from 30
[RECEIVE] Queued message from 30
[QUEUE] Processing info from 30
[QUEUE] Stored info from 30
[RECEIVE] Queued message from 30
[QUEUE] Processing info from 30
[QUEUE] Stored info from 30
[RECEIVE] Queued message from 30
[QUEUE] Processing info from 30
[QUEUE] Stored info from 30
[RECEIVE] Queued message from 30
[QUEUE] Processing info from 30
[QUEUE] Stored info from 30
[RECEIVE] Queued message from 30
[QUEUE] Processing info from 30
[QUEUE] Stored info from 30
[RECEIVE] Queued message from 30
[QUEUE] Processing info from 30
[QUEUE] Stored info from 30
[RECEIVE] Queued message from 30
[QUEUE] Processing info from 30
[QUEUE] Stored info from 30
[RECEIVE] Queued message from 30
[QUEUE] Processing info from 30
[QUEUE] Stored info from 30
[RECEIVE] Queued message from 30
[QUEUE] Processing info from 30
[QUEUE] Stored info from 30
[RECEIVE] Queued message from 30
[QUEUE] Processing info from 30
[QUEUE] Stored info from 30
[RECEIVE] Queued message from 30
[QUEUE] Processing info from 30
[QUEUE] Stored info from 30
[RECEIVE] Queued message from 30
[QUEUE] Processing info from 30
[QUEUE] Stored info from 30
[RECEIVE] Queued message from 30
[QUEUE] Processing info from 30
[QUEUE] Stored info from 30
[RECEIVE] Queued message from 30
[QUEUE] Processing info from 30
[QUEUE] Stored info from 30
[RECEIVE] Queued message from 30
[QUEUE] Processing info from 30
[QUEUE] Stored info from 30
[RECEIVE] Queued message from 30
[QUEUE] Processing info from 30
[QUEUE] Stored info from 30
[RECEIVE] Queued message from 30
[QUEUE] Processing info from 30
[QUEUE] Stored info from 30
[RECEIVE] Queued message from 30
[QUEUE] Processing info from 30
[QUEUE] Stored info from 30
[RECEIVE] Queued message from 30
[QUEUE] Processing info from 30
[QUEUE] Stored info from 30
[RECEIVE] Queued message from 30
[QUEUE] Processing info from 30
[QUEUE] Stored info from 30
[RECEIVE] Queued message from 30
[QUEUE] Processing info from 30
[QUEUE] Stored info from 30
[82] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2522.67it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:55,  2.95s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:24,  1.47s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:44,  1.20s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:27,  1.09s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:16,  1.03s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:08,  1.02it/s]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:08,  1.00it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:16<02:00,  1.05it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:18<02:12,  1.06s/it]Running loglikelihood requests:  13%|█▎        | 19/142 [00:20<01:59,  1.03it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:22<01:55,  1.05it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:23<01:52,  1.06it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:25<01:43,  1.13it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:26<01:35,  1.20it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:28<01:30,  1.26it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:29<01:25,  1.30it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:31<01:21,  1.33it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:32<01:19,  1.35it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:34<01:19,  1.32it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:35<01:16,  1.35it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:36<01:13,  1.37it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:38<01:11,  1.39it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:39<01:08,  1.41it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:40<01:06,  1.44it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:42<01:03,  1.47it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:43<01:04,  1.40it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:45<01:01,  1.44it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:46<00:58,  1.48it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:47<00:56,  1.51it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:48<00:54,  1.53it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:50<00:52,  1.54it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:51<00:50,  1.56it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:52<00:49,  1.57it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:54<00:50,  1.50it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:55<00:47,  1.53it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:56<00:45,  1.55it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:57<00:43,  1.58it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [00:59<00:42,  1.59it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:00<00:40,  1.61it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:01<00:38,  1.62it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:02<00:37,  1.63it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:04<00:38,  1.55it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:05<00:36,  1.58it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:06<00:34,  1.61it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:07<00:32,  1.63it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:08<00:31,  1.64it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:10<00:29,  1.66it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:11<00:28,  1.67it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:12<00:26,  1.68it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:13<00:25,  1.69it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:15<00:28,  1.45it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:16<00:25,  1.52it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:17<00:23,  1.57it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:19<00:21,  1.61it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:20<00:20,  1.65it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:21<00:18,  1.68it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:22<00:17,  1.70it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:23<00:15,  1.71it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:24<00:15,  1.65it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:26<00:13,  1.69it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:27<00:12,  1.71it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:28<00:10,  1.73it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:29<00:09,  1.74it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:30<00:08,  1.76it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:31<00:07,  1.66it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:32<00:06,  1.70it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:34<00:05,  1.74it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:35<00:04,  1.70it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:36<00:02,  1.75it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:37<00:01,  1.58it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:40<00:00,  1.31it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:40<00:00,  1.42it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-29): 24 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (30-31): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-29): 24 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (30-31): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/82.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5060
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:09:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5060 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 60
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:09:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5080
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:09:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5080 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 80
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5013
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:09:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5013 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 13
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5171
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:09:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5171 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 171
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5109
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:09:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5109 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 109
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:09:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5133
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:09:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5133 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 133
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5243
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:09:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5243 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 243
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:09:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5230
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:09:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5230 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 230
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5104
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:09:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5104 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 104
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5026
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:09:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5026 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 26
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5206
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:09:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5206 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 206
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5004
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:09:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5004 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 4
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5205
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:09:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5205 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 205
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:09:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5141
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:09:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5141 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 141
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:09:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5045
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:09:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5045 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 45
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:09:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5242
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:09:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5242 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 242
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5029
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:09:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5029 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 29
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5044
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:09:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5044 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 44
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5006
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:09:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5006 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 6
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5236
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:09:51] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5236 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 236
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5011
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:09:51] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5011 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 11
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:09:51] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:09:51] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5027
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:09:51] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5027 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 27
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:09:51] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139722783472096 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139722783472096 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139722783472096 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139722783472096 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139721061360096 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139721061360096 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139721061360096 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139721061360096 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[82] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4084507042253521, 'acc_stderr,none': 0.058751136942575236}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9179357562486347
0.7304758827874278
0.9028361165350093
0.9177386064031547
0.736264115539795
0.7821589386855158
0.7475448337241333
0.6622221680289488
0.7583296634655016
0.33645990832698236
0.21982307453464583
0.17345324326533693
0.35977004925853934
0.8808900006571698
0.6260065234155616
0.8246960552033293
0.6144641592309815
0.6394144929277611
0.9223063206094516
0.7309208925817541
0.5091734316973643
0.7222829855220914
0.24969394334306674
0.508931879405537
0.8097279042671086
0.5258809052220982
0.4071243454156871
0.9510154626938295
0.3256867622893698
0.9179357562486347
0.7304758827874278
0.9028361165350093
0.9177386064031547
0.736264115539795
0.7821589386855158
0.7475448337241333
0.6622221680289488
0.7583296634655016
0.33645990832698236
0.21982307453464583
0.17345324326533693
0.35977004925853934
0.8808900006571698
0.6260065234155616
0.8246960552033293
0.6144641592309815
0.6394144929277611
0.9223063206094516
0.7309208925817541
0.5091734316973643
0.7222829855220914
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[1, 4, 3, 6, 2, 0, 7, 5]
tensor([1, 4, 3, 6, 2, 0, 7, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 1, 4, 7, 2, 0, 6, 5]
tensor([3, 1, 4, 7, 2, 0, 6, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 6, 7, 0, 3, 2, 4, 1]
tensor([5, 6, 7, 0, 3, 2, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 6, 3, 5, 0, 1, 7, 2]
tensor([4, 6, 3, 5, 0, 1, 7, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 2, 5, 0, 4, 1, 1, 3]
tensor([0, 2, 5, 0, 4, 1, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 2, 3, 0, 2, 3, 1]
tensor([0, 1, 2, 3, 0, 2, 3, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[2, 1, 0, 1, 2, 0, 3, 3]
tensor([2, 1, 0, 1, 2, 0, 3, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 2, 1, 3, 0, 1, 2, 3]
tensor([0, 2, 1, 3, 0, 1, 2, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/82.pt
[RECEIVE] Queued message from 82
[QUEUE] Processing info from 82
[QUEUE] Stored info from 82
[RECEIVE] Queued message from 82
[QUEUE] Processing info from 82
[QUEUE] Stored info from 82
[RECEIVE] Queued message from 82
[QUEUE] Processing info from 82
[QUEUE] Stored info from 82
[RECEIVE] Queued message from 82
[QUEUE] Processing info from 82
[QUEUE] Stored info from 82
[RECEIVE] Queued message from 82
[QUEUE] Processing info from 82
[QUEUE] Stored info from 82
[RECEIVE] Queued message from 82
[QUEUE] Processing info from 82
[QUEUE] Stored info from 82
[RECEIVE] Queued message from 82
[QUEUE] Processing info from 82
[QUEUE] Stored info from 82
[RECEIVE] Queued message from 82
[QUEUE] Processing info from 82
[QUEUE] Stored info from 82
[RECEIVE] Queued message from 82
[QUEUE] Processing info from 82
[QUEUE] Stored info from 82
[RECEIVE] Queued message from 82
[QUEUE] Processing info from 82
[QUEUE] Stored info from 82
[RECEIVE] Queued message from 82
[QUEUE] Processing info from 82
[QUEUE] Stored info from 82
[RECEIVE] Queued message from 82
[QUEUE] Processing info from 82
[QUEUE] Stored info from 82
[RECEIVE] Queued message from 82
[QUEUE] Processing info from 82
[QUEUE] Stored info from 82
[RECEIVE] Queued message from 82
[QUEUE] Processing info from 82
[QUEUE] Stored info from 82
[RECEIVE] Queued message from 82
[QUEUE] Processing info from 82
[QUEUE] Stored info from 82
[RECEIVE] Queued message from 82
[QUEUE] Processing info from 82
[QUEUE] Stored info from 82
[RECEIVE] Queued message from 82
[QUEUE] Processing info from 82
[QUEUE] Stored info from 82
[RECEIVE] Queued message from 82
[QUEUE] Processing info from 82
[QUEUE] Stored info from 82
[RECEIVE] Queued message from 82
[QUEUE] Processing info from 82
[QUEUE] Stored info from 82
[RECEIVE] Queued message from 82
[QUEUE] Processing info from 82
[QUEUE] Stored info from 82
[RECEIVE] Queued message from 82
[QUEUE] Processing info from 82
[QUEUE] Stored info from 82
[RECEIVE] Queued message from 82
[QUEUE] Processing info from 82
[QUEUE] Stored info from 82
[RECEIVE] Queued message from 82
[QUEUE] Processing info from 82
[QUEUE] Stored info from 82
[RECEIVE] Queued message from 82
[QUEUE] Processing info from 82
[QUEUE] Stored info from 82
[RECEIVE] Queued message from 82
[QUEUE] Processing info from 82
[QUEUE] Stored info from 82
[RECEIVE] Queued message from 82
[QUEUE] Processing info from 82
[QUEUE] Stored info from 82
[RECEIVE] Queued message from 82
[QUEUE] Processing info from 82
[QUEUE] Stored info from 82
[RECEIVE] Queued message from 82
[QUEUE] Processing info from 82
[QUEUE] Stored info from 82
[RECEIVE] Queued message from 82
[QUEUE] Processing info from 82
[QUEUE] Stored info from 82
[RECEIVE] Queued message from 82
[QUEUE] Processing info from 82
[QUEUE] Stored info from 82
[RECEIVE] Queued message from 82
[QUEUE] Processing info from 82
[QUEUE] Stored info from 82
[45] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2610.89it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:54,  2.94s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:23,  1.47s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:51,  1.25s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:30,  1.12s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:18,  1.04s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:09,  1.01it/s]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:02,  1.05it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:15<01:56,  1.09it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:17<01:57,  1.06it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:19<01:49,  1.12it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:20<01:43,  1.17it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:22<01:37,  1.22it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:23<01:32,  1.27it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:25<01:28,  1.29it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:26<01:27,  1.29it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:28<01:23,  1.33it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:29<01:20,  1.35it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:31<01:18,  1.37it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:32<01:15,  1.39it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:33<01:13,  1.40it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:35<01:11,  1.42it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:36<01:09,  1.42it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:38<01:17,  1.25it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:40<01:11,  1.32it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:41<01:06,  1.39it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:42<01:02,  1.45it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:43<00:59,  1.49it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:45<00:57,  1.52it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:46<00:54,  1.55it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:47<00:55,  1.49it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:48<00:53,  1.52it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:50<00:50,  1.55it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:51<00:48,  1.58it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:53<00:55,  1.36it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:54<00:50,  1.44it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:55<00:47,  1.49it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:57<00:44,  1.55it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [00:58<00:44,  1.52it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [00:59<00:41,  1.56it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:00<00:39,  1.60it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:01<00:37,  1.62it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:03<00:41,  1.42it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:04<00:38,  1.49it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:06<00:35,  1.55it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:07<00:33,  1.61it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:08<00:35,  1.45it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:10<00:32,  1.53it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:11<00:29,  1.59it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:12<00:27,  1.61it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:13<00:26,  1.65it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:14<00:24,  1.67it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:15<00:22,  1.70it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:17<00:21,  1.71it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:18<00:21,  1.66it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:19<00:19,  1.69it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:20<00:18,  1.72it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:22<00:19,  1.49it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:23<00:17,  1.57it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:24<00:15,  1.63it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:25<00:13,  1.69it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:26<00:12,  1.73it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:27<00:10,  1.76it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:29<00:11,  1.45it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:30<00:09,  1.55it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:31<00:07,  1.63it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:33<00:06,  1.68it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:34<00:05,  1.74it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:35<00:03,  1.79it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:36<00:02,  1.83it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:37<00:01,  1.86it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:38<00:00,  1.81it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:38<00:00,  1.44it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-8): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10-30): 21 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (31): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-8): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10-30): 21 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (31): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/45.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:11:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:11:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5026
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:11:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5026 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 26
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5082
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:11:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5082 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 82
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5242
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:11:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5242 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 242
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:11:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5027
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:11:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5027 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 27
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:11:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5004
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:11:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5004 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 4
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5171
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:11:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5171 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 171
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5141
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:11:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5141 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 141
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:11:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5080
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:11:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5080 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 80
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5006
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:11:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5006 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 6
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:11:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5243
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:11:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5243 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 243
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5206
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:11:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5206 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 206
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5230
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:11:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5230 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 230
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5013
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:11:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5013 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 13
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5104
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:11:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5104 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 104
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5011
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:11:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5011 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 11
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5133
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:11:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5133 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 133
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5060
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:11:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5060 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 60
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5236
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:11:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5236 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 236
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5029
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:11:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5029 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 29
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5044
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:11:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5044 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 44
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:11:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:11:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:11:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5205
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:11:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5205 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 205
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5109
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:11:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5109 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 109
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139720667790224 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139720667790224 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139720667790224 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139720667790224 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139720639767680 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139720639767680 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139720639767680 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139720639767680 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[45] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4507042253521127, 'acc_stderr,none': 0.05947027187738001}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.891975958338049
0.3982001908036579
0.26652204443251004
0.14111026067874816
0.11763525057572936
0.8635004180455561
0.8741394655456793
0.5304527321557103
0.44617634270319845
0.7007455592903002
0.6799150362476898
0.3511365594568724
0.47145939463701925
0.4744673317050211
0.905435493752087
0.903612941640167
0.8893763849001028
0.6821933807976941
0.6796182015499347
0.7774502436639344
0.8164788896198145
0.9011095591650676
0.8564639597370403
0.9528866120532432
0.4784452972921274
0.48852492817861076
0.8397355586186119
0.7433051149723976
0.5457687574271932
0.891975958338049
0.3982001908036579
0.26652204443251004
0.14111026067874816
0.11763525057572936
0.8635004180455561
0.8741394655456793
0.5304527321557103
0.44617634270319845
0.7007455592903002
0.6799150362476898
0.3511365594568724
0.47145939463701925
0.4744673317050211
0.905435493752087
0.903612941640167
0.8893763849001028
0.6821933807976941
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[6, 5, 4, 3, 2, 1, 7, 0]
tensor([6, 5, 4, 3, 2, 1, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 7, 4, 1, 0, 6, 3]
tensor([5, 2, 7, 4, 1, 0, 6, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 6, 5, 2, 4, 0, 7, 1]
tensor([3, 6, 5, 2, 4, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 4, 6, 0, 2, 1, 7, 3]
tensor([5, 4, 6, 0, 2, 1, 7, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 0, 7, 3, 5, 1, 6, 2]
tensor([4, 0, 7, 3, 5, 1, 6, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 5, 1, 3, 2, 0, 1, 4]
tensor([0, 5, 1, 3, 2, 0, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[1, 0, 0, 1, 1.0, 1.0, 1.0, 1.0]
tensor([1, 0, 0, 1, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[1, 0, 1, 1.0, 1.0, 0, 1.0, 1.0]
tensor([1, 0, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[0, 1, 1.0, 1.0, 0, 1, 1.0, 1.0]
tensor([0, 1, 1, 1, 0, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/45.pt
[RECEIVE] Queued message from 45
[QUEUE] Processing info from 45
[QUEUE] Stored info from 45
[RECEIVE] Queued message from 45
[QUEUE] Processing info from 45
[QUEUE] Stored info from 45
[RECEIVE] Queued message from 45
[QUEUE] Processing info from 45
[QUEUE] Stored info from 45
[RECEIVE] Queued message from 45
[QUEUE] Processing info from 45
[QUEUE] Stored info from 45
[RECEIVE] Queued message from 45
[QUEUE] Processing info from 45
[QUEUE] Stored info from 45
[RECEIVE] Queued message from 45
[QUEUE] Processing info from 45
[QUEUE] Stored info from 45
[RECEIVE] Queued message from 45
[QUEUE] Processing info from 45
[QUEUE] Stored info from 45
[RECEIVE] Queued message from 45
[QUEUE] Processing info from 45
[QUEUE] Stored info from 45
[RECEIVE] Queued message from 45
[QUEUE] Processing info from 45
[QUEUE] Stored info from 45
[RECEIVE] Queued message from 45
[QUEUE] Processing info from 45
[QUEUE] Stored info from 45
[RECEIVE] Queued message from 45
[QUEUE] Processing info from 45
[QUEUE] Stored info from 45
[RECEIVE] Queued message from 45
[QUEUE] Processing info from 45
[QUEUE] Stored info from 45
[RECEIVE] Queued message from 45
[QUEUE] Processing info from 45
[QUEUE] Stored info from 45
[RECEIVE] Queued message from 45
[QUEUE] Processing info from 45
[QUEUE] Stored info from 45
[RECEIVE] Queued message from 45
[QUEUE] Processing info from 45
[QUEUE] Stored info from 45
[RECEIVE] Queued message from 45
[QUEUE] Processing info from 45
[QUEUE] Stored info from 45
[RECEIVE] Queued message from 45
[QUEUE] Processing info from 45
[QUEUE] Stored info from 45
[RECEIVE] Queued message from 45
[QUEUE] Processing info from 45
[QUEUE] Stored info from 45
[RECEIVE] Queued message from 45
[QUEUE] Processing info from 45
[QUEUE] Stored info from 45
[RECEIVE] Queued message from 45
[QUEUE] Processing info from 45
[QUEUE] Stored info from 45
[RECEIVE] Queued message from 45
[QUEUE] Processing info from 45
[QUEUE] Stored info from 45
[RECEIVE] Queued message from 45
[QUEUE] Processing info from 45
[QUEUE] Stored info from 45
[RECEIVE] Queued message from 45
[QUEUE] Processing info from 45
[QUEUE] Stored info from 45
[RECEIVE] Queued message from 45
[QUEUE] Processing info from 45
[QUEUE] Stored info from 45
[RECEIVE] Queued message from 45
[QUEUE] Processing info from 45
[QUEUE] Stored info from 45
[RECEIVE] Queued message from 45
[QUEUE] Processing info from 45
[QUEUE] Stored info from 45
[RECEIVE] Queued message from 45
[QUEUE] Processing info from 45
[QUEUE] Stored info from 45
[RECEIVE] Queued message from 45
[QUEUE] Processing info from 45
[QUEUE] Stored info from 45
[RECEIVE] Queued message from 45
[QUEUE] Processing info from 45
[QUEUE] Stored info from 45
[RECEIVE] Queued message from 45
[QUEUE] Processing info from 45
[QUEUE] Stored info from 45
[RECEIVE] Queued message from 45
[QUEUE] Processing info from 45
[QUEUE] Stored info from 45
[6] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2569.68it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:39,  2.83s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:30,  1.51s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:47,  1.22s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:29,  1.11s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:18,  1.04s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:10,  1.00it/s]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:18,  1.07s/it]Running loglikelihood requests:  11%|█         | 15/142 [00:16<02:07,  1.00s/it]Running loglikelihood requests:  12%|█▏        | 17/142 [00:18<01:58,  1.06it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:19<01:50,  1.11it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:21<01:43,  1.16it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:22<01:38,  1.21it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:25<02:00,  1.03s/it]Running loglikelihood requests:  19%|█▉        | 27/142 [00:27<01:48,  1.06it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:28<01:39,  1.13it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:30<01:32,  1.19it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:31<01:27,  1.25it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:33<01:23,  1.28it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:35<01:28,  1.19it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:36<01:22,  1.24it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:38<01:18,  1.28it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:39<01:15,  1.31it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:40<01:13,  1.33it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:42<01:09,  1.37it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:43<01:05,  1.41it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:45<01:07,  1.34it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:46<01:03,  1.39it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:47<01:00,  1.43it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:49<00:57,  1.47it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:50<00:55,  1.49it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:51<00:53,  1.51it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:53<00:51,  1.52it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:55<01:01,  1.25it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:56<00:56,  1.33it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:57<00:52,  1.39it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:59<00:49,  1.44it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [01:00<00:46,  1.49it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [01:01<00:44,  1.51it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:02<00:42,  1.54it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:04<00:40,  1.56it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:05<00:40,  1.51it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:07<00:41,  1.41it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:08<00:38,  1.47it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:09<00:36,  1.52it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:10<00:34,  1.55it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:13<00:45,  1.11it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:16<00:48,  1.01it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:17<00:41,  1.14it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:18<00:35,  1.26it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:19<00:31,  1.36it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:21<00:28,  1.45it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:22<00:25,  1.51it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:23<00:23,  1.56it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:24<00:21,  1.60it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:25<00:21,  1.57it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:27<00:19,  1.60it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:28<00:17,  1.63it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:29<00:16,  1.65it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:30<00:15,  1.66it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:31<00:13,  1.68it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:32<00:12,  1.69it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:34<00:11,  1.71it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:35<00:10,  1.63it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:36<00:09,  1.66it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:37<00:07,  1.69it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:38<00:06,  1.71it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:39<00:05,  1.73it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:41<00:04,  1.72it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:42<00:02,  1.75it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:43<00:01,  1.77it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:44<00:00,  1.81it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:44<00:00,  1.36it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-31): 26 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-31): 26 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/6.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5205
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:13:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5205 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 205
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5004
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:13:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5004 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 4
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5029
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:13:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5029 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 29
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5133
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:13:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5133 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 133
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:13:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:13:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:13:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:13:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5027
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:13:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5027 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 27
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5011
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:13:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5011 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 11
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5104
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:13:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5104 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 104
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5060
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:13:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5060 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 60
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5045
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:13:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5045 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 45
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5141
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:13:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5141 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 141
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5026
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:13:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5026 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 26
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:13:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5044
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:13:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5044 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 44
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:13:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:13:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5080
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:13:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5080 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 80
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5013
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:13:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5013 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 13
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5242
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:13:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5242 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 242
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5243
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:13:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5243 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 243
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5171
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:13:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5171 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 171
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:13:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5236
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:13:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5236 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 236
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5230
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:13:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5230 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 230
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5206
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:13:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5206 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 206
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5109
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:13:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5109 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 109
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5082
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:13:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5082 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 82
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:13:46] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139720679114512 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139720679114512 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139720679114512 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139720679114512 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139722700605296 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139722700605296 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139722700605296 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139722700605296 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[6] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4225352112676056, 'acc_stderr,none': 0.059039842056825796}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.4249710358556562
0.875077076525312
0.8377657430496294
0.7631146361001728
0.8061134194824199
0.597293936853132
0.8993038548124084
0.40672319990150296
0.4427306135620195
0.6697754068966065
0.560869697816391
0.6365238158372074
0.7977251509942833
0.5774168099619936
0.7636367981130562
0.45204149170439595
0.2621700055892588
0.8796773875905071
0.8519712476811715
0.8067705781994788
0.5994711637356425
0.8334667984344581
0.8573465838873401
0.8381586594258955
0.8329727759300379
0.8464402476627775
0.7864641899632313
0.6699089018877085
0.7340555031678195
0.4249710358556562
0.875077076525312
0.8377657430496294
0.7631146361001728
0.8061134194824199
0.597293936853132
0.8993038548124084
0.40672319990150296
0.4427306135620195
0.6697754068966065
0.560869697816391
0.6365238158372074
0.7977251509942833
0.5774168099619936
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[2, 1, 7, 5, 6, 0, 4, 3]
tensor([2, 1, 7, 5, 6, 0, 4, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 6, 7, 1, 3, 0, 5, 4]
tensor([2, 6, 7, 1, 3, 0, 5, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 1, 7, 4, 3, 0, 5, 6]
tensor([2, 1, 7, 4, 3, 0, 5, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 3, 7, 1, 4, 0, 6, 2]
tensor([5, 3, 7, 1, 4, 0, 6, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 4, 6, 1, 3, 0, 7, 2]
tensor([5, 4, 6, 1, 3, 0, 7, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[2, 5, 0, 4, 1, 3, 1, 0]
tensor([2, 5, 0, 4, 1, 3, 1, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 3, 1, 1, 2, 0, 3, 2]
tensor([0, 3, 1, 1, 2, 0, 3, 2], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/6.pt
[RECEIVE] Queued message from 6
[QUEUE] Processing info from 6
[QUEUE] Stored info from 6
[RECEIVE] Queued message from 6
[QUEUE] Processing info from 6
[QUEUE] Stored info from 6
[RECEIVE] Queued message from 6
[QUEUE] Processing info from 6
[QUEUE] Stored info from 6
[RECEIVE] Queued message from 6
[QUEUE] Processing info from 6
[QUEUE] Stored info from 6
[RECEIVE] Queued message from 6
[QUEUE] Processing info from 6
[QUEUE] Stored info from 6
[RECEIVE] Queued message from 6
[QUEUE] Processing info from 6
[QUEUE] Stored info from 6
[RECEIVE] Queued message from 6
[QUEUE] Processing info from 6
[QUEUE] Stored info from 6
[RECEIVE] Queued message from 6
[QUEUE] Processing info from 6
[QUEUE] Stored info from 6
[RECEIVE] Queued message from 6
[QUEUE] Processing info from 6
[QUEUE] Stored info from 6
[RECEIVE] Queued message from 6
[QUEUE] Processing info from 6
[QUEUE] Stored info from 6
[RECEIVE] Queued message from 6
[QUEUE] Processing info from 6
[QUEUE] Stored info from 6
[RECEIVE] Queued message from 6
[QUEUE] Processing info from 6
[QUEUE] Stored info from 6
[RECEIVE] Queued message from 6
[QUEUE] Processing info from 6
[QUEUE] Stored info from 6
[RECEIVE] Queued message from 6
[QUEUE] Processing info from 6
[QUEUE] Stored info from 6
[RECEIVE] Queued message from 6
[QUEUE] Processing info from 6
[QUEUE] Stored info from 6
[RECEIVE] Queued message from 6
[QUEUE] Processing info from 6
[QUEUE] Stored info from 6
[RECEIVE] Queued message from 6
[QUEUE] Processing info from 6
[QUEUE] Stored info from 6
[RECEIVE] Queued message from 6
[QUEUE] Processing info from 6
[QUEUE] Stored info from 6
[RECEIVE] Queued message from 6
[QUEUE] Processing info from 6
[QUEUE] Stored info from 6
[RECEIVE] Queued message from 6
[QUEUE] Processing info from 6
[QUEUE] Stored info from 6
[RECEIVE] Queued message from 6
[QUEUE] Processing info from 6
[QUEUE] Stored info from 6
[RECEIVE] Queued message from 6
[QUEUE] Processing info from 6
[QUEUE] Stored info from 6
[RECEIVE] Queued message from 6
[QUEUE] Processing info from 6
[QUEUE] Stored info from 6
[RECEIVE] Queued message from 6
[QUEUE] Processing info from 6
[QUEUE] Stored info from 6
[RECEIVE] Queued message from 6
[QUEUE] Processing info from 6
[QUEUE] Stored info from 6
[RECEIVE] Queued message from 6
[QUEUE] Processing info from 6
[QUEUE] Stored info from 6
[RECEIVE] Queued message from 6
[QUEUE] Processing info from 6
[QUEUE] Stored info from 6
[RECEIVE] Queued message from 6
[QUEUE] Processing info from 6
[QUEUE] Stored info from 6
[RECEIVE] Queued message from 6
[QUEUE] Processing info from 6
[QUEUE] Stored info from 6
[RECEIVE] Queued message from 6
[QUEUE] Processing info from 6
[QUEUE] Stored info from 6
[RECEIVE] Queued message from 6
[QUEUE] Processing info from 6
[QUEUE] Stored info from 6
[133] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2595.42it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:01,  2.57s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:13,  1.39s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:48,  1.23s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:30,  1.12s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:19,  1.05s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:13,  1.02s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:05,  1.02it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:15<01:59,  1.06it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:17<01:56,  1.07it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:19<01:54,  1.07it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:21<01:47,  1.13it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:22<01:42,  1.16it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:24<01:37,  1.20it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:25<01:33,  1.24it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:27<01:33,  1.21it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:29<01:32,  1.20it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:30<01:27,  1.24it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:32<01:23,  1.28it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:33<01:20,  1.31it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:35<01:17,  1.33it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:36<01:15,  1.33it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:38<01:18,  1.26it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:39<01:13,  1.31it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:41<01:10,  1.35it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:42<01:06,  1.39it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:43<01:03,  1.43it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:45<01:01,  1.45it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:46<00:58,  1.48it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:47<00:59,  1.43it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:49<00:56,  1.46it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:50<00:54,  1.48it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:51<00:52,  1.50it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:53<00:50,  1.51it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:54<00:49,  1.52it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:55<00:47,  1.54it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:56<00:45,  1.54it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:58<00:46,  1.47it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [00:59<00:44,  1.50it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:00<00:42,  1.53it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:02<00:40,  1.55it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:03<00:38,  1.57it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:04<00:37,  1.58it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:05<00:35,  1.59it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:07<00:34,  1.60it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:08<00:34,  1.55it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:09<00:32,  1.58it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:10<00:30,  1.59it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:14<00:47,  1.02s/it]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:16<00:40,  1.12it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:17<00:34,  1.24it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:18<00:32,  1.25it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:20<00:28,  1.35it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:21<00:25,  1.43it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:22<00:23,  1.49it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:23<00:22,  1.46it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:25<00:21,  1.47it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:26<00:18,  1.53it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:27<00:17,  1.58it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:28<00:16,  1.54it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:30<00:14,  1.58it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:31<00:13,  1.61it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:32<00:11,  1.64it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:33<00:10,  1.66it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:34<00:08,  1.67it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:36<00:07,  1.68it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:37<00:06,  1.69it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:38<00:05,  1.65it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:39<00:04,  1.69it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:40<00:02,  1.72it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:41<00:01,  1.75it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:42<00:00,  1.78it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:42<00:00,  1.38it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-8): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10-22): 13 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (23): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24-31): 8 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-8): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10-22): 13 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (23): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24-31): 8 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/133.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5013
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:15:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5013 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 13
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:15:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5242
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:15:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5242 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 242
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5004
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:15:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5004 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 4
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5082
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:15:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5082 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 82
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5206
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:15:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5206 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 206
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:15:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5027
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:15:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5027 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 27
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5060
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:15:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5060 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 60
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5029
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:15:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5029 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 29
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5104
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:15:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5104 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 104
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5171
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:15:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5171 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 171
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5243
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:15:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5243 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 243
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5109
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:15:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5109 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 109
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5045
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:15:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5045 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 45
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:15:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5080
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:15:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5080 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 80
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5026
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:15:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5026 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 26
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5006
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:15:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5006 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 6
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:15:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5205
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:15:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5205 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 205
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5236
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:15:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5236 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 236
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:15:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:15:44] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:15:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:15:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5044
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:15:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5044 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 44
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5011
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:15:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5011 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 11
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:15:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5230
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:15:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5230 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 230
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5141
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:15:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5141 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 141
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139717305909024 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139717305909024 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139717305909024 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139717305909024 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139718352137408 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139718352137408 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139718352137408 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139718352137408 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[133] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4647887323943662, 'acc_stderr,none': 0.05961305784972239}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8670569790937798
0.5488271932172035
0.673013746499191
0.7739554714966184
0.626122351153327
0.7480239804573661
0.8404062667282521
0.585845593784257
0.5486089643527782
0.295628094796439
0.8187255304150794
0.4183228390778105
0.5130578032019412
0.8769017151034573
0.9364820135353734
0.9916222006713932
0.9862354083632185
0.9582978800582982
0.8980649992917061
0.8669816466709701
0.9008509099634621
0.9321426254796342
0.8646919425811247
0.6505326186022521
0.6612551300691957
0.8835733690017037
0.7234157945938043
0.7342253877992871
0.5683390151095499
0.8670569790937798
0.5488271932172035
0.673013746499191
0.7739554714966184
0.626122351153327
0.7480239804573661
0.8404062667282521
0.585845593784257
0.5486089643527782
0.295628094796439
0.8187255304150794
0.4183228390778105
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[5, 3, 6, 2, 4, 0, 7, 1]
tensor([5, 3, 6, 2, 4, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 4, 6, 7, 2, 0, 5, 1]
tensor([3, 4, 6, 7, 2, 0, 5, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 6, 2, 1, 3, 0, 7, 5]
tensor([4, 6, 2, 1, 3, 0, 7, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 4, 6, 0, 1, 2, 7, 3]
tensor([5, 4, 6, 0, 1, 2, 7, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 2, 6, 5, 4, 0, 7, 1]
tensor([3, 2, 6, 5, 4, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 2, 5, 6, 3, 0, 7, 1]
tensor([4, 2, 5, 6, 3, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/133.pt
[RECEIVE] Queued message from 133
[QUEUE] Processing info from 133
[QUEUE] Stored info from 133
[RECEIVE] Queued message from 133
[QUEUE] Processing info from 133
[QUEUE] Stored info from 133
[RECEIVE] Queued message from 133
[QUEUE] Processing info from 133
[QUEUE] Stored info from 133
[RECEIVE] Queued message from 133
[QUEUE] Processing info from 133
[QUEUE] Stored info from 133
[RECEIVE] Queued message from 133
[QUEUE] Processing info from 133
[QUEUE] Stored info from 133
[RECEIVE] Queued message from 133
[QUEUE] Processing info from 133
[QUEUE] Stored info from 133
[RECEIVE] Queued message from 133
[QUEUE] Processing info from 133
[QUEUE] Stored info from 133
[RECEIVE] Queued message from 133
[QUEUE] Processing info from 133
[QUEUE] Stored info from 133
[RECEIVE] Queued message from 133
[QUEUE] Processing info from 133
[QUEUE] Stored info from 133
[RECEIVE] Queued message from 133
[QUEUE] Processing info from 133
[QUEUE] Stored info from 133
[RECEIVE] Queued message from 133
[QUEUE] Processing info from 133
[QUEUE] Stored info from 133
[RECEIVE] Queued message from 133
[QUEUE] Processing info from 133
[QUEUE] Stored info from 133
[RECEIVE] Queued message from 133
[QUEUE] Processing info from 133
[QUEUE] Stored info from 133
[RECEIVE] Queued message from 133
[QUEUE] Processing info from 133
[QUEUE] Stored info from 133
[RECEIVE] Queued message from 133
[QUEUE] Processing info from 133
[QUEUE] Stored info from 133
[RECEIVE] Queued message from 133
[QUEUE] Processing info from 133
[QUEUE] Stored info from 133
[RECEIVE] Queued message from 133
[QUEUE] Processing info from 133
[QUEUE] Stored info from 133
[RECEIVE] Queued message from 133
[QUEUE] Processing info from 133
[QUEUE] Stored info from 133
[RECEIVE] Queued message from 133
[QUEUE] Processing info from 133
[QUEUE] Stored info from 133
[RECEIVE] Queued message from 133
[QUEUE] Processing info from 133
[QUEUE] Stored info from 133
[RECEIVE] Queued message from 133
[QUEUE] Processing info from 133
[QUEUE] Stored info from 133
[RECEIVE] Queued message from 133
[QUEUE] Processing info from 133
[QUEUE] Stored info from 133
[RECEIVE] Queued message from 133
[QUEUE] Processing info from 133
[QUEUE] Stored info from 133
[RECEIVE] Queued message from 133
[QUEUE] Processing info from 133
[QUEUE] Stored info from 133
[RECEIVE] Queued message from 133
[QUEUE] Processing info from 133
[QUEUE] Stored info from 133
[RECEIVE] Queued message from 133
[QUEUE] Processing info from 133
[QUEUE] Stored info from 133
[RECEIVE] Queued message from 133
[QUEUE] Processing info from 133
[QUEUE] Stored info from 133
[RECEIVE] Queued message from 133
[QUEUE] Processing info from 133
[QUEUE] Stored info from 133
[RECEIVE] Queued message from 133
[QUEUE] Processing info from 133
[QUEUE] Stored info from 133
[RECEIVE] Queued message from 133
[QUEUE] Processing info from 133
[QUEUE] Stored info from 133
[RECEIVE] Queued message from 133
[QUEUE] Processing info from 133
[QUEUE] Stored info from 133
[104] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 1472.15it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:27,  2.75s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:17,  1.42s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:40,  1.17s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:24,  1.07s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:14,  1.01s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:11,  1.00s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:13<02:03,  1.04it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:15<01:56,  1.09it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:17<01:50,  1.13it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:18<01:44,  1.17it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:20<01:40,  1.21it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:22<01:38,  1.20it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:23<01:34,  1.24it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:25<01:30,  1.27it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:26<01:26,  1.30it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:27<01:23,  1.34it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:29<01:20,  1.36it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:30<01:17,  1.37it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:32<01:18,  1.34it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:33<01:15,  1.37it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:35<01:12,  1.39it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:37<01:19,  1.25it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:38<01:13,  1.32it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:39<01:09,  1.37it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:40<01:05,  1.43it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:42<01:03,  1.42it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:43<01:00,  1.47it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:44<00:57,  1.51it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:46<00:55,  1.54it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:47<00:53,  1.56it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:48<00:51,  1.59it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:49<00:49,  1.60it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:51<00:54,  1.41it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:53<00:53,  1.39it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:54<00:50,  1.46it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:55<00:47,  1.51it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:56<00:44,  1.55it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [00:57<00:42,  1.59it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [00:59<00:40,  1.61it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:00<00:38,  1.64it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:01<00:36,  1.65it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:02<00:36,  1.61it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:03<00:34,  1.63it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:05<00:33,  1.66it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:06<00:31,  1.68it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:07<00:30,  1.69it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:08<00:28,  1.69it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:09<00:27,  1.70it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:10<00:26,  1.71it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:12<00:24,  1.72it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:13<00:24,  1.65it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:14<00:23,  1.68it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:15<00:21,  1.69it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:16<00:20,  1.70it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:18<00:19,  1.72it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:19<00:17,  1.74it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:20<00:16,  1.73it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:21<00:15,  1.74it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:22<00:14,  1.74it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:23<00:13,  1.69it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:24<00:12,  1.71it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:26<00:10,  1.74it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:27<00:09,  1.76it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:28<00:08,  1.78it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:29<00:07,  1.79it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:30<00:06,  1.80it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:31<00:04,  1.81it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:32<00:03,  1.83it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:33<00:02,  1.74it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:34<00:01,  1.79it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:35<00:00,  1.84it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:35<00:00,  1.48it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-8): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10-30): 21 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (31): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-8): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10-30): 21 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (31): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/104.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5171
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:17:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5171 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 171
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5082
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:17:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5082 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 82
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:17:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:17:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5045
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:17:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5045 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 45
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5205
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:17:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5205 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 205
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5013
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:17:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5013 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 13
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5109
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:17:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5109 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 109
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5006
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:17:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5006 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 6
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:17:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:17:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5242
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:17:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5242 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 242
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5004
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:17:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5004 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 4
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:17:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:17:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:17:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5141
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:17:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5141 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 141
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5236
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:17:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5236 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 236
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:17:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5206
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:17:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5206 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 206
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5011
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:17:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5011 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 11
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5029
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:17:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5029 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 29
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5230
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:17:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5230 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 230
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:17:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5026
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:17:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5026 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 26
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5080
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:17:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5080 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 80
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5027
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:17:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5027 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 27
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5044
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:17:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5044 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 44
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5133
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:17:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5133 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 133
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5243
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:17:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5243 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 243
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5060
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:17:35] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5060 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 60
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139718417217632 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139718417217632 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139718417217632 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139718417217632 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139718978268064 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139718978268064 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139718978268064 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139718978268064 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[104] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4507042253521127, 'acc_stderr,none': 0.05947027187738001}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.891975958338049
0.3982001908036579
0.26652204443251004
0.14111026067874816
0.11763525057572936
0.8635004180455561
0.8741394655456793
0.5304527321557103
0.44617634270319845
0.7007455592903002
0.6799150362476898
0.3511365594568724
0.47145939463701925
0.4744673317050211
0.905435493752087
0.903612941640167
0.8893763849001028
0.6821933807976941
0.6796182015499347
0.7774502436639344
0.8164788896198145
0.9011095591650676
0.8564639597370403
0.9528866120532432
0.4784452972921274
0.48852492817861076
0.8397355586186119
0.7433051149723976
0.5457687574271932
0.891975958338049
0.3982001908036579
0.26652204443251004
0.14111026067874816
0.11763525057572936
0.8635004180455561
0.8741394655456793
0.5304527321557103
0.44617634270319845
0.7007455592903002
0.6799150362476898
0.3511365594568724
0.47145939463701925
0.4744673317050211
0.905435493752087
0.903612941640167
0.8893763849001028
0.6821933807976941
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[6, 5, 4, 3, 2, 1, 7, 0]
tensor([6, 5, 4, 3, 2, 1, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 7, 4, 1, 0, 6, 3]
tensor([5, 2, 7, 4, 1, 0, 6, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 6, 5, 2, 4, 0, 7, 1]
tensor([3, 6, 5, 2, 4, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 4, 6, 0, 2, 1, 7, 3]
tensor([5, 4, 6, 0, 2, 1, 7, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 0, 7, 3, 5, 1, 6, 2]
tensor([4, 0, 7, 3, 5, 1, 6, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 5, 1, 3, 2, 0, 1, 4]
tensor([0, 5, 1, 3, 2, 0, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[1, 0, 0, 1, 1.0, 1.0, 1.0, 1.0]
tensor([1, 0, 0, 1, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[1, 0, 1, 1.0, 1.0, 0, 1.0, 1.0]
tensor([1, 0, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[0, 1, 1.0, 1.0, 0, 1, 1.0, 1.0]
tensor([0, 1, 1, 1, 0, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/104.pt
[RECEIVE] Queued message from 104
[QUEUE] Processing info from 104
[QUEUE] Stored info from 104
[RECEIVE] Queued message from 104
[QUEUE] Processing info from 104
[QUEUE] Stored info from 104
[RECEIVE] Queued message from 104
[QUEUE] Processing info from 104
[QUEUE] Stored info from 104
[RECEIVE] Queued message from 104
[QUEUE] Processing info from 104
[QUEUE] Stored info from 104
[RECEIVE] Queued message from 104
[QUEUE] Processing info from 104
[QUEUE] Stored info from 104
[RECEIVE] Queued message from 104
[QUEUE] Processing info from 104
[QUEUE] Stored info from 104
[RECEIVE] Queued message from 104
[QUEUE] Processing info from 104
[QUEUE] Stored info from 104
[RECEIVE] Queued message from 104
[QUEUE] Processing info from 104
[QUEUE] Stored info from 104
[RECEIVE] Queued message from 104
[QUEUE] Processing info from 104
[QUEUE] Stored info from 104
[RECEIVE] Queued message from 104
[QUEUE] Processing info from 104
[QUEUE] Stored info from 104
[RECEIVE] Queued message from 104
[QUEUE] Processing info from 104
[QUEUE] Stored info from 104
[RECEIVE] Queued message from 104
[QUEUE] Processing info from 104
[QUEUE] Stored info from 104
[RECEIVE] Queued message from 104
[QUEUE] Processing info from 104
[QUEUE] Stored info from 104
[RECEIVE] Queued message from 104
[QUEUE] Processing info from 104
[QUEUE] Stored info from 104
[RECEIVE] Queued message from 104
[QUEUE] Processing info from 104
[QUEUE] Stored info from 104
[RECEIVE] Queued message from 104
[QUEUE] Processing info from 104
[QUEUE] Stored info from 104
[RECEIVE] Queued message from 104
[QUEUE] Processing info from 104
[QUEUE] Stored info from 104
[RECEIVE] Queued message from 104
[QUEUE] Processing info from 104
[QUEUE] Stored info from 104
[RECEIVE] Queued message from 104
[QUEUE] Processing info from 104
[QUEUE] Stored info from 104
[RECEIVE] Queued message from 104
[QUEUE] Processing info from 104
[QUEUE] Stored info from 104
[RECEIVE] Queued message from 104
[QUEUE] Processing info from 104
[QUEUE] Stored info from 104
[RECEIVE] Queued message from 104
[QUEUE] Processing info from 104
[QUEUE] Stored info from 104
[RECEIVE] Queued message from 104
[QUEUE] Processing info from 104
[QUEUE] Stored info from 104
[RECEIVE] Queued message from 104
[QUEUE] Processing info from 104
[QUEUE] Stored info from 104
[RECEIVE] Queued message from 104
[QUEUE] Processing info from 104
[QUEUE] Stored info from 104
[RECEIVE] Queued message from 104
[QUEUE] Processing info from 104
[QUEUE] Stored info from 104
[RECEIVE] Queued message from 104
[QUEUE] Processing info from 104
[QUEUE] Stored info from 104
[RECEIVE] Queued message from 104
[QUEUE] Processing info from 104
[QUEUE] Stored info from 104
[RECEIVE] Queued message from 104
[QUEUE] Processing info from 104
[QUEUE] Stored info from 104
[RECEIVE] Queued message from 104
[QUEUE] Processing info from 104
[QUEUE] Stored info from 104
[RECEIVE] Queued message from 104
[QUEUE] Processing info from 104
[QUEUE] Stored info from 104
[80] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2589.05it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<05:54,  2.52s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:20,  1.44s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:40,  1.17s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:24,  1.07s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:13,  1.00s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:11<02:06,  1.04it/s]Running loglikelihood requests:   9%|▉         | 13/142 [00:13<02:04,  1.04it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:15<01:56,  1.09it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:17<01:50,  1.14it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:18<01:43,  1.19it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:20<01:38,  1.23it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:21<01:33,  1.28it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:22<01:28,  1.32it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:26<02:01,  1.05s/it]Running loglikelihood requests:  20%|██        | 29/142 [00:27<01:47,  1.05it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:29<01:37,  1.13it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:30<01:30,  1.20it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:32<01:25,  1.26it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:33<01:23,  1.26it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:35<01:18,  1.31it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:36<01:14,  1.35it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:37<01:12,  1.37it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:39<01:08,  1.42it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:40<01:05,  1.45it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:43<01:26,  1.07it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:45<01:24,  1.07it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:46<01:14,  1.19it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:47<01:07,  1.29it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:49<01:01,  1.38it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:50<00:57,  1.45it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:51<00:54,  1.50it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:52<00:51,  1.53it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:54<00:51,  1.51it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:55<00:48,  1.54it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:56<00:46,  1.58it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:57<00:44,  1.60it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:58<00:42,  1.63it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [01:00<00:40,  1.64it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:01<00:39,  1.66it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:02<00:37,  1.67it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:03<00:36,  1.68it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:05<00:37,  1.57it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:06<00:35,  1.60it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:07<00:33,  1.63it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:08<00:31,  1.66it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:09<00:30,  1.67it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:10<00:29,  1.69it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:12<00:27,  1.71it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:13<00:26,  1.72it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:15<00:30,  1.41it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:16<00:27,  1.49it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:17<00:24,  1.56it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:18<00:23,  1.61it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:19<00:21,  1.65it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:20<00:19,  1.69it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:22<00:18,  1.72it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:23<00:16,  1.74it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:24<00:15,  1.75it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:25<00:14,  1.68it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:26<00:13,  1.72it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:27<00:12,  1.74it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:28<00:10,  1.76it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:30<00:09,  1.78it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:31<00:08,  1.80it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:32<00:07,  1.81it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:33<00:06,  1.82it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:34<00:04,  1.83it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:35<00:03,  1.75it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:36<00:02,  1.80it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:37<00:01,  1.83it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:38<00:00,  1.87it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:38<00:00,  1.44it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-31): 26 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-31): 26 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/80.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5109
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:19:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5109 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 109
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5171
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:19:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5171 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 171
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5141
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:19:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5141 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 141
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5044
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:19:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5044 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 44
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5104
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:19:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5104 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 104
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5230
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:19:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5230 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 230
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:19:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5013
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:19:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5013 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 13
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5236
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:19:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5236 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 236
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5011
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:19:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5011 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 11
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5045
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:19:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5045 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 45
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:19:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:19:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:19:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:19:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5006
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:19:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5006 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 6
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5082
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:19:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5082 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 82
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5027
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:19:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5027 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 27
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:19:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5242
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:19:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5242 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 242
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5133
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:19:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5133 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 133
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5060
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:19:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5060 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 60
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:19:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5243
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:19:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5243 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 243
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5206
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:19:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5206 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 206
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5205
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:19:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5205 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 205
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:19:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5029
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:19:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5029 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 29
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:19:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5026
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:19:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5026 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 26
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5004
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:19:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5004 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 4
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139718417203664 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139718417203664 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139718417203664 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139718417203664 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139718418784592 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139718418784592 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139718418784592 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139718418784592 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[80] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4225352112676056, 'acc_stderr,none': 0.059039842056825796}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9416968404415913
0.7938815868474761
0.8191819727516524
0.8917669687772857
0.90570342985793
0.3043907333176312
0.4952220736758006
0.29899990072660143
0.7758711420345523
0.838301482150715
0.8086122742620726
0.9126741954079025
0.6304407611776705
0.6595297618724628
0.176689009460142
0.4424440684940646
0.43152501031897406
0.48316840881543294
0.43857258209632005
0.7021905687600761
0.2402003641072479
0.27348823957209967
0.6649171314730306
0.25117416182112623
0.9114030338716436
0.9328254651349717
0.9096786197852272
0.9107213191843687
0.8764776988845487
0.9416968404415913
0.7938815868474761
0.8191819727516524
0.8917669687772857
0.90570342985793
0.3043907333176312
0.4952220736758006
0.29899990072660143
0.7758711420345523
0.838301482150715
0.8086122742620726
0.9126741954079025
0.6304407611776705
0.6595297618724628
0.176689009460142
0.4424440684940646
0.43152501031897406
Total groups 76 exceeded the threshold, stopping comparison.
The group tensor is
[4, 3, 7, 2, 5, 1, 6, 0]
tensor([4, 3, 7, 2, 5, 1, 6, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 5, 7, 4, 3, 0, 6, 1]
tensor([2, 5, 7, 4, 3, 0, 6, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 5, 4, 0, 1, 1, 2]
tensor([0, 3, 5, 4, 0, 1, 1, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[4, 3, 0, 2, 5, 0, 1, 1]
tensor([4, 3, 0, 2, 5, 0, 1, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 0, 5, 1, 4, 2, 1, 3]
tensor([0, 0, 5, 1, 4, 2, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[3, 4, 0, 1, 2, 0, 5, 1]
tensor([3, 4, 0, 1, 2, 0, 5, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[5, 0, 4, 3, 2, 0, 1, 1]
tensor([5, 0, 4, 3, 2, 0, 1, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 3, 4, 0, 1, 2, 1, 5]
tensor([0, 3, 4, 0, 1, 2, 1, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/80.pt
[RECEIVE] Queued message from 80
[QUEUE] Processing info from 80
[QUEUE] Stored info from 80
[RECEIVE] Queued message from 80
[QUEUE] Processing info from 80
[QUEUE] Stored info from 80
[RECEIVE] Queued message from 80
[QUEUE] Processing info from 80
[QUEUE] Stored info from 80
[RECEIVE] Queued message from 80
[QUEUE] Processing info from 80
[QUEUE] Stored info from 80
[RECEIVE] Queued message from 80
[QUEUE] Processing info from 80
[QUEUE] Stored info from 80
[RECEIVE] Queued message from 80
[QUEUE] Processing info from 80
[QUEUE] Stored info from 80
[RECEIVE] Queued message from 80
[QUEUE] Processing info from 80
[QUEUE] Stored info from 80
[RECEIVE] Queued message from 80
[QUEUE] Processing info from 80
[QUEUE] Stored info from 80
[RECEIVE] Queued message from 80
[QUEUE] Processing info from 80
[QUEUE] Stored info from 80
[RECEIVE] Queued message from 80
[QUEUE] Processing info from 80
[QUEUE] Stored info from 80
[RECEIVE] Queued message from 80
[QUEUE] Processing info from 80
[QUEUE] Stored info from 80
[RECEIVE] Queued message from 80
[QUEUE] Processing info from 80
[QUEUE] Stored info from 80
[RECEIVE] Queued message from 80
[QUEUE] Processing info from 80
[QUEUE] Stored info from 80
[RECEIVE] Queued message from 80
[QUEUE] Processing info from 80
[QUEUE] Stored info from 80
[RECEIVE] Queued message from 80
[QUEUE] Processing info from 80
[QUEUE] Stored info from 80
[RECEIVE] Queued message from 80
[QUEUE] Processing info from 80
[QUEUE] Stored info from 80
[RECEIVE] Queued message from 80
[QUEUE] Processing info from 80
[QUEUE] Stored info from 80
[RECEIVE] Queued message from 80
[QUEUE] Processing info from 80
[QUEUE] Stored info from 80
[RECEIVE] Queued message from 80
[QUEUE] Processing info from 80
[QUEUE] Stored info from 80
[RECEIVE] Queued message from 80
[QUEUE] Processing info from 80
[QUEUE] Stored info from 80
[RECEIVE] Queued message from 80
[QUEUE] Processing info from 80
[QUEUE] Stored info from 80
[RECEIVE] Queued message from 80
[QUEUE] Processing info from 80
[QUEUE] Stored info from 80
[RECEIVE] Queued message from 80
[QUEUE] Processing info from 80
[QUEUE] Stored info from 80
[RECEIVE] Queued message from 80
[QUEUE] Processing info from 80
[QUEUE] Stored info from 80
[RECEIVE] Queued message from 80
[QUEUE] Processing info from 80
[QUEUE] Stored info from 80
[RECEIVE] Queued message from 80
[QUEUE] Processing info from 80
[QUEUE] Stored info from 80
[RECEIVE] Queued message from 80
[QUEUE] Processing info from 80
[QUEUE] Stored info from 80
[RECEIVE] Queued message from 80
[QUEUE] Processing info from 80
[QUEUE] Stored info from 80
[RECEIVE] Queued message from 80
[QUEUE] Processing info from 80
[QUEUE] Stored info from 80
[RECEIVE] Queued message from 80
[QUEUE] Processing info from 80
[QUEUE] Stored info from 80
[RECEIVE] Queued message from 80
[QUEUE] Processing info from 80
[QUEUE] Stored info from 80
[178] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2578.32it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:03<08:31,  3.62s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:05<03:48,  1.64s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:07<02:54,  1.28s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:09<02:32,  1.13s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:11<02:19,  1.05s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:14<02:41,  1.23s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:15<02:22,  1.11s/it]Running loglikelihood requests:  11%|█         | 15/142 [00:17<02:10,  1.02s/it]Running loglikelihood requests:  12%|█▏        | 17/142 [00:19<02:00,  1.04it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:20<01:51,  1.10it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:25<02:33,  1.27s/it]Running loglikelihood requests:  16%|█▌        | 23/142 [00:26<02:11,  1.11s/it]Running loglikelihood requests:  18%|█▊        | 25/142 [00:27<01:56,  1.00it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:29<01:45,  1.09it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:30<01:37,  1.16it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:32<01:35,  1.17it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:34<01:30,  1.21it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:35<01:25,  1.26it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:37<01:21,  1.29it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:38<01:17,  1.32it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:39<01:14,  1.35it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:41<01:12,  1.36it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:42<01:12,  1.35it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:44<01:08,  1.38it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:45<01:05,  1.42it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:46<01:02,  1.45it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:48<01:00,  1.48it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:49<00:58,  1.50it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:50<00:55,  1.52it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:51<00:54,  1.53it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:53<00:54,  1.48it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:54<00:52,  1.50it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:55<00:50,  1.53it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:57<00:48,  1.54it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:58<00:46,  1.56it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:59<00:45,  1.57it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [01:00<00:43,  1.58it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [01:02<00:42,  1.59it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:04<00:46,  1.40it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:05<00:43,  1.46it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:06<00:40,  1.51it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:07<00:38,  1.54it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:08<00:36,  1.57it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:10<00:34,  1.59it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:11<00:33,  1.60it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:12<00:31,  1.61it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:13<00:31,  1.55it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:15<00:29,  1.58it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:16<00:28,  1.60it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:17<00:26,  1.63it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:18<00:24,  1.64it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:20<00:26,  1.47it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:21<00:24,  1.53it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:22<00:22,  1.58it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:26<00:31,  1.04it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:27<00:26,  1.18it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:28<00:22,  1.30it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:29<00:19,  1.40it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:31<00:16,  1.47it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:32<00:14,  1.54it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:33<00:13,  1.59it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:34<00:12,  1.58it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:35<00:10,  1.62it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:36<00:08,  1.67it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:37<00:07,  1.71it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:39<00:06,  1.73it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:40<00:05,  1.76it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:41<00:04,  1.74it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:42<00:02,  1.78it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:43<00:01,  1.81it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:44<00:00,  1.73it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:44<00:00,  1.36it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-15): 11 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (16): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (17): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (18-30): 13 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (31): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-15): 11 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (16): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (17): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (18-30): 13 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (31): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/178.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:21:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5133
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:21:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5133 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 133
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5026
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:21:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5026 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 26
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5109
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:21:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5109 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 109
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5104
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:21:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5104 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 104
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5004
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:21:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5004 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 4
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5141
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:21:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5141 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 141
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:21:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5206
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:21:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5206 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 206
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:21:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5236
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:21:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5236 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 236
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5171
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:21:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5171 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 171
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5230
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:21:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5230 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 230
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:21:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5006
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:21:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5006 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 6
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5082
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:21:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5082 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 82
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5029
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:21:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5029 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 29
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5205
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:21:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5205 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 205
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:21:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:21:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5060
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:21:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5060 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 60
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5080
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:21:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5080 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 80
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5243
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:21:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5243 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 243
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5013
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:21:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5013 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 13
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:21:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5045
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:21:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5045 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 45
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5044
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:21:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5044 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 44
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:21:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5242
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:21:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5242 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 242
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5027
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:21:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5027 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 27
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5011
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:21:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5011 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 11
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139718419226528 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139718419226528 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139718419226528 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139718419226528 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139720664296736 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139720664296736 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139720664296736 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139720664296736 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[178] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4225352112676056, 'acc_stderr,none': 0.059039842056825796}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8980271762152415
0.2639787465429745
0.5625332696290335
0.793649776762635
0.3255906663223904
0.0484338095439226
0.14923347971103265
0.5710137578745996
0.4024845012023718
0.40192324238029414
0.7421347168699821
0.33528288680973795
0.3799695309319889
0.38260979896102654
0.8288488026343434
0.5741428622514854
0.32292256805357755
0.2608862087917634
0.5815302784189874
0.6526878745506514
0.23164180573632143
0.7209107763819704
0.641400211099821
0.36378810546943974
0.5869502091248732
0.1447672816588167
0.22624580082754567
0.43042437260655503
0.5802248606876254
0.8980271762152415
0.2639787465429745
0.5625332696290335
0.793649776762635
0.3255906663223904
0.0484338095439226
0.14923347971103265
0.5710137578745996
0.4024845012023718
0.40192324238029414
0.7421347168699821
0.33528288680973795
0.3799695309319889
0.38260979896102654
0.8288488026343434
0.5741428622514854
0.32292256805357755
0.2608862087917634
0.5815302784189874
0.6526878745506514
0.23164180573632143
0.7209107763819704
0.641400211099821
0.36378810546943974
0.5869502091248732
0.1447672816588167
0.22624580082754567
0.43042437260655503
Total groups 73 exceeded the threshold, stopping comparison.
The group tensor is
[5, 3, 7, 4, 1, 0, 6, 2]
tensor([5, 3, 7, 4, 1, 0, 6, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 5, 1, 2, 4, 0, 7, 3]
tensor([6, 5, 1, 2, 4, 0, 7, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 4, 3, 1, 5, 0, 7, 2]
tensor([6, 4, 3, 1, 5, 0, 7, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[7, 3, 6, 0, 4, 2, 5, 1]
tensor([7, 3, 6, 0, 4, 2, 5, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 4, 1, 2, 0, 3, 5, 1]
tensor([0, 4, 1, 2, 0, 3, 5, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[2, 0, 1, 3, 1, 0, 2, 3]
tensor([2, 0, 1, 3, 1, 0, 2, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 1, 1, 3, 0, 2, 3, 2]
tensor([0, 1, 1, 3, 0, 2, 3, 2], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1, 1.0, 1.0, 1.0, 0]
tensor([0, 1, 1, 1, 1, 1, 1, 0], dtype=torch.int32)
[0, 1]
The group tensor is
[1, 0, 1, 1.0, 1.0, 0, 1.0, 1.0]
tensor([1, 0, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/178.pt
[RECEIVE] Queued message from 178
[QUEUE] Processing info from 178
[QUEUE] Stored info from 178
[RECEIVE] Queued message from 178
[QUEUE] Processing info from 178
[QUEUE] Stored info from 178
[RECEIVE] Queued message from 178
[QUEUE] Processing info from 178
[QUEUE] Stored info from 178
[RECEIVE] Queued message from 178
[QUEUE] Processing info from 178
[QUEUE] Stored info from 178
[RECEIVE] Queued message from 178
[QUEUE] Processing info from 178
[QUEUE] Stored info from 178
[RECEIVE] Queued message from 178
[QUEUE] Processing info from 178
[QUEUE] Stored info from 178
[RECEIVE] Queued message from 178
[QUEUE] Processing info from 178
[QUEUE] Stored info from 178
[RECEIVE] Queued message from 178
[QUEUE] Processing info from 178
[QUEUE] Stored info from 178
[RECEIVE] Queued message from 178
[QUEUE] Processing info from 178
[QUEUE] Stored info from 178
[RECEIVE] Queued message from 178
[QUEUE] Processing info from 178
[QUEUE] Stored info from 178
[RECEIVE] Queued message from 178
[QUEUE] Processing info from 178
[QUEUE] Stored info from 178
[RECEIVE] Queued message from 178
[QUEUE] Processing info from 178
[QUEUE] Stored info from 178
[RECEIVE] Queued message from 178
[QUEUE] Processing info from 178
[QUEUE] Stored info from 178
[RECEIVE] Queued message from 178
[QUEUE] Processing info from 178
[QUEUE] Stored info from 178
[RECEIVE] Queued message from 178
[QUEUE] Processing info from 178
[QUEUE] Stored info from 178
[RECEIVE] Queued message from 178
[QUEUE] Processing info from 178
[QUEUE] Stored info from 178
[RECEIVE] Queued message from 178
[QUEUE] Processing info from 178
[QUEUE] Stored info from 178
[RECEIVE] Queued message from 178
[QUEUE] Processing info from 178
[QUEUE] Stored info from 178
[RECEIVE] Queued message from 178
[QUEUE] Processing info from 178
[QUEUE] Stored info from 178
[RECEIVE] Queued message from 178
[QUEUE] Processing info from 178
[QUEUE] Stored info from 178
[RECEIVE] Queued message from 178
[QUEUE] Processing info from 178
[QUEUE] Stored info from 178
[RECEIVE] Queued message from 178
[QUEUE] Processing info from 178
[QUEUE] Stored info from 178
[RECEIVE] Queued message from 178
[QUEUE] Processing info from 178
[QUEUE] Stored info from 178
[RECEIVE] Queued message from 178
[QUEUE] Processing info from 178
[QUEUE] Stored info from 178
[RECEIVE] Queued message from 178
[QUEUE] Processing info from 178
[QUEUE] Stored info from 178
[RECEIVE] Queued message from 178
[QUEUE] Processing info from 178
[QUEUE] Stored info from 178
[RECEIVE] Queued message from 178
[QUEUE] Processing info from 178
[QUEUE] Stored info from 178
[RECEIVE] Queued message from 178
[QUEUE] Processing info from 178
[QUEUE] Stored info from 178
[RECEIVE] Queued message from 178
[QUEUE] Processing info from 178
[QUEUE] Stored info from 178
[RECEIVE] Queued message from 178
[QUEUE] Processing info from 178
[QUEUE] Stored info from 178
[RECEIVE] Queued message from 178
[QUEUE] Processing info from 178
[QUEUE] Stored info from 178
[236] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2591.94it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:17,  2.68s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:34,  1.54s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:50,  1.24s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:31,  1.12s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:20,  1.05s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:12,  1.01s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:14,  1.04s/it]Running loglikelihood requests:  11%|█         | 15/142 [00:16<02:05,  1.01it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:18<01:58,  1.06it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:19<01:50,  1.11it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:21<01:45,  1.15it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:22<01:39,  1.19it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:24<01:43,  1.13it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:26<01:37,  1.18it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:28<01:33,  1.21it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:29<01:30,  1.23it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:31<01:27,  1.25it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:32<01:24,  1.26it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:34<01:24,  1.24it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:35<01:21,  1.27it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:37<01:18,  1.29it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:38<01:15,  1.31it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:40<01:12,  1.33it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:41<01:09,  1.36it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:43<01:07,  1.38it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:44<01:11,  1.27it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:46<01:06,  1.33it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:47<01:03,  1.38it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:48<01:00,  1.41it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:50<00:57,  1.44it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:51<00:55,  1.46it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:52<00:53,  1.47it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:54<00:53,  1.44it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:55<00:51,  1.46it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:56<00:49,  1.49it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:58<00:47,  1.50it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:59<00:45,  1.52it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [01:00<00:43,  1.53it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:02<00:42,  1.53it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:03<00:40,  1.54it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:04<00:41,  1.45it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:06<00:39,  1.49it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:07<00:37,  1.51it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:08<00:35,  1.53it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:10<00:34,  1.54it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:11<00:32,  1.55it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:12<00:31,  1.55it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:13<00:30,  1.56it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:15<00:32,  1.40it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:17<00:30,  1.42it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:18<00:27,  1.48it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:19<00:25,  1.52it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:20<00:24,  1.48it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:22<00:22,  1.53it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:23<00:20,  1.57it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:24<00:19,  1.60it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:25<00:18,  1.57it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:27<00:16,  1.60it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:28<00:15,  1.61it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:29<00:14,  1.63it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:30<00:13,  1.53it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:32<00:12,  1.57it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:33<00:10,  1.61it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:34<00:09,  1.63it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:35<00:08,  1.58it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:37<00:06,  1.61it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:38<00:05,  1.65it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:39<00:04,  1.68it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:40<00:02,  1.71it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:41<00:01,  1.72it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:42<00:00,  1.75it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:42<00:00,  1.38it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-5): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (7-18): 12 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (19): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (20): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (21): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (22): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (23): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24-27): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (28): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (29-31): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-5): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (7-18): 12 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (19): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (20): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (21): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (22): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (23): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24-27): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (28): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (29-31): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/236.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5205
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:23:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5205 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 205
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5045
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:23:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5045 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 45
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5026
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:23:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5026 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 26
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5242
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:23:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5242 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 242
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:23:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5206
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:23:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5206 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 206
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5082
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:23:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5082 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 82
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5243
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:23:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5243 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 243
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5171
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:23:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5171 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 171
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:23:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5027
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:23:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5027 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 27
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:23:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5029
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:23:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5029 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 29
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5044
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:23:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5044 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 44
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5006
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:23:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5006 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 6
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:23:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5230
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:23:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5230 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 230
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5133
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:23:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5133 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 133
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:23:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5080
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:23:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5080 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 80
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5104
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:23:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5104 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 104
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5141
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:23:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5141 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 141
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5109
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:23:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5109 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 109
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5060
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:23:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5060 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 60
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:23:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:23:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:23:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:23:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5004
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:23:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5004 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 4
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5011
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:23:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5011 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 11
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5013
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:23:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5013 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 13
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139718425969344 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139718425969344 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139718425969344 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139718425969344 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139715691930080 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139715691930080 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139715691930080 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139715691930080 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[236] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.43661971830985913, 'acc_stderr,none': 0.05927935558412972}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8579940969956122
0.9172414698319051
0.5383905049167778
0.7154451748054276
0.547671504517951
0.8833126318549385
0.815742382492854
0.6517871119418787
0.320270438500039
0.20847052823122236
0.9142272844016534
0.8979022224289909
0.8081306275049516
0.5991072724268783
0.8920856671099552
0.8548931916511182
0.9545918502043321
0.9270787839270334
0.4466502436196787
0.892147307459623
0.7319083135729072
0.8321772812735796
0.9605666801588856
0.3242808765028886
0.884060616512067
0.5116280105615226
0.22259676802614164
0.8272877996431262
Total groups 68 exceeded the threshold, stopping comparison.
The group tensor is
[3, 2, 7, 4, 5, 0, 6, 1]
tensor([3, 2, 7, 4, 5, 0, 6, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[1, 6, 5, 4, 2, 0, 7, 3]
tensor([1, 6, 5, 4, 2, 0, 7, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 3, 5, 6, 1, 2, 7, 0]
tensor([4, 3, 5, 6, 1, 2, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[2, 5, 3, 7, 0, 1, 6, 4]
tensor([2, 5, 3, 7, 0, 1, 6, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 2, 1, 1, 3, 2, 3]
tensor([0, 0, 2, 1, 1, 3, 2, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[3, 0, 2, 1, 1, 0, 2, 3]
tensor([3, 0, 2, 1, 1, 0, 2, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 1, 1.0, 1, 1.0, 1.0, 1.0]
tensor([0, 0, 1, 1, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[1, 0, 1, 1.0, 1.0, 0, 1.0, 1.0]
tensor([1, 0, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/236.pt
[RECEIVE] Queued message from 236
[QUEUE] Processing info from 236
[QUEUE] Stored info from 236
[RECEIVE] Queued message from 236
[QUEUE] Processing info from 236
[QUEUE] Stored info from 236
[RECEIVE] Queued message from 236
[QUEUE] Processing info from 236
[QUEUE] Stored info from 236
[RECEIVE] Queued message from 236
[QUEUE] Processing info from 236
[QUEUE] Stored info from 236
[RECEIVE] Queued message from 236
[QUEUE] Processing info from 236
[QUEUE] Stored info from 236
[RECEIVE] Queued message from 236
[QUEUE] Processing info from 236
[QUEUE] Stored info from 236
[RECEIVE] Queued message from 236
[QUEUE] Processing info from 236
[QUEUE] Stored info from 236
[RECEIVE] Queued message from 236
[QUEUE] Processing info from 236
[QUEUE] Stored info from 236
[RECEIVE] Queued message from 236
[QUEUE] Processing info from 236
[QUEUE] Stored info from 236
[RECEIVE] Queued message from 236
[QUEUE] Processing info from 236
[QUEUE] Stored info from 236
[RECEIVE] Queued message from 236
[QUEUE] Processing info from 236
[QUEUE] Stored info from 236
[RECEIVE] Queued message from 236
[QUEUE] Processing info from 236
[QUEUE] Stored info from 236
[RECEIVE] Queued message from 236
[QUEUE] Processing info from 236
[QUEUE] Stored info from 236
[RECEIVE] Queued message from 236
[QUEUE] Processing info from 236
[QUEUE] Stored info from 236
[RECEIVE] Queued message from 236
[QUEUE] Processing info from 236
[QUEUE] Stored info from 236
[RECEIVE] Queued message from 236
[QUEUE] Processing info from 236
[QUEUE] Stored info from 236
[RECEIVE] Queued message from 236
[QUEUE] Processing info from 236
[QUEUE] Stored info from 236
[RECEIVE] Queued message from 236
[QUEUE] Processing info from 236
[QUEUE] Stored info from 236
[RECEIVE] Queued message from 236
[QUEUE] Processing info from 236
[QUEUE] Stored info from 236
[RECEIVE] Queued message from 236
[QUEUE] Processing info from 236
[QUEUE] Stored info from 236
[RECEIVE] Queued message from 236
[QUEUE] Processing info from 236
[QUEUE] Stored info from 236
[RECEIVE] Queued message from 236
[QUEUE] Processing info from 236
[QUEUE] Stored info from 236
[RECEIVE] Queued message from 236
[QUEUE] Processing info from 236
[QUEUE] Stored info from 236
[RECEIVE] Queued message from 236
[QUEUE] Processing info from 236
[QUEUE] Stored info from 236
[RECEIVE] Queued message from 236
[QUEUE] Processing info from 236
[QUEUE] Stored info from 236
[RECEIVE] Queued message from 236
[QUEUE] Processing info from 236
[QUEUE] Stored info from 236
[RECEIVE] Queued message from 236
[QUEUE] Processing info from 236
[QUEUE] Stored info from 236
[RECEIVE] Queued message from 236
[QUEUE] Processing info from 236
[QUEUE] Stored info from 236
[RECEIVE] Queued message from 236
[QUEUE] Processing info from 236
[QUEUE] Stored info from 236
[RECEIVE] Queued message from 236
[QUEUE] Processing info from 236
[QUEUE] Stored info from 236
[RECEIVE] Queued message from 236
[QUEUE] Processing info from 236
[QUEUE] Stored info from 236
[242] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2613.96it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:10,  2.63s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:11,  1.38s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:37,  1.15s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:29,  1.11s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:17,  1.04s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:09,  1.01it/s]Running loglikelihood requests:   9%|▉         | 13/142 [00:13<02:02,  1.05it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:15<01:55,  1.10it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:17<01:54,  1.10it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:18<01:47,  1.15it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:20<01:41,  1.19it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:21<01:36,  1.23it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:23<01:33,  1.25it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:24<01:29,  1.28it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:26<01:26,  1.30it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:28<01:26,  1.28it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:32<02:19,  1.28s/it]Running loglikelihood requests:  25%|██▍       | 35/142 [00:34<01:58,  1.11s/it]Running loglikelihood requests:  26%|██▌       | 37/142 [00:35<01:44,  1.01it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:37<01:33,  1.10it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:38<01:28,  1.14it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:40<01:21,  1.21it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:41<01:15,  1.28it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:42<01:11,  1.33it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:44<01:07,  1.38it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:45<01:03,  1.43it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:46<01:00,  1.46it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:49<01:21,  1.07it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:51<01:11,  1.19it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:52<01:04,  1.28it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:53<00:59,  1.36it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:54<00:55,  1.42it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:56<00:52,  1.47it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:57<00:49,  1.50it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:59<00:54,  1.33it/s]Running loglikelihood requests:  50%|█████     | 71/142 [01:00<00:50,  1.40it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [01:01<00:47,  1.46it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [01:03<00:44,  1.50it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:04<00:42,  1.53it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:05<00:40,  1.56it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:06<00:38,  1.58it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:08<00:36,  1.59it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:09<00:38,  1.46it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:10<00:36,  1.52it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:12<00:33,  1.57it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:13<00:31,  1.60it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:14<00:30,  1.62it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:15<00:28,  1.64it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:16<00:27,  1.66it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:17<00:25,  1.67it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:19<00:25,  1.59it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:20<00:23,  1.63it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:23<00:31,  1.19it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:24<00:26,  1.32it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:25<00:23,  1.42it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:26<00:20,  1.50it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:27<00:18,  1.54it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:29<00:17,  1.53it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:30<00:15,  1.57it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:31<00:14,  1.62it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:32<00:12,  1.65it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:33<00:11,  1.69it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:35<00:09,  1.71it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:36<00:08,  1.73it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:37<00:07,  1.74it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:38<00:06,  1.76it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:39<00:05,  1.62it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:40<00:04,  1.68it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:42<00:02,  1.73it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:43<00:01,  1.77it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:44<00:00,  1.81it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:44<00:00,  1.36it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-31): 26 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-31): 26 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/242.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:25:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5104
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:25:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5104 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 104
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5230
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:25:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5230 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 230
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5026
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:25:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5026 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 26
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5109
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:25:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5109 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 109
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:25:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5006
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:25:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5006 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 6
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:25:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5205
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:25:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5205 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 205
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5044
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:25:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5044 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 44
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5133
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:25:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5133 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 133
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5141
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:25:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5141 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 141
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5004
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:25:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5004 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 4
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5029
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:25:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5029 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 29
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:25:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5171
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:25:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5171 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 171
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5045
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:25:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5045 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 45
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:25:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5060
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:25:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5060 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 60
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5082
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:25:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5082 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 82
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:25:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5027
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:25:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5027 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 27
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:25:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5013
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:25:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5013 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 13
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5206
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:25:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5206 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 206
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5243
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:25:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5243 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 243
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:25:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5080
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:25:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5080 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 80
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5236
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:25:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5236 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 236
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5011
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:25:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5011 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 11
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:25:28] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139715693579584 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139715693579584 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139715693579584 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139715693579584 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139715691991392 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139715691991392 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139715691991392 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139715691991392 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[242] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4225352112676056, 'acc_stderr,none': 0.059039842056825796}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.4249710358556562
0.875077076525312
0.8377657430496294
0.7631146361001728
0.8061134194824199
0.597293936853132
0.8993038548124084
0.40672319990150296
0.4427306135620195
0.6697754068966065
0.560869697816391
0.6365238158372074
0.7977251509942833
0.5774168099619936
0.7636367981130562
0.45204149170439595
0.2621700055892588
0.8796773875905071
0.8519712476811715
0.8067705781994788
0.5994711637356425
0.8334667984344581
0.8573465838873401
0.8381586594258955
0.8329727759300379
0.8464402476627775
0.7864641899632313
0.6699089018877085
0.7340555031678195
0.4249710358556562
0.875077076525312
0.8377657430496294
0.7631146361001728
0.8061134194824199
0.597293936853132
0.8993038548124084
0.40672319990150296
0.4427306135620195
0.6697754068966065
0.560869697816391
0.6365238158372074
0.7977251509942833
0.5774168099619936
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[2, 1, 7, 5, 6, 0, 4, 3]
tensor([2, 1, 7, 5, 6, 0, 4, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 6, 7, 1, 3, 0, 5, 4]
tensor([2, 6, 7, 1, 3, 0, 5, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 1, 7, 4, 3, 0, 5, 6]
tensor([2, 1, 7, 4, 3, 0, 5, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 3, 7, 1, 4, 0, 6, 2]
tensor([5, 3, 7, 1, 4, 0, 6, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 4, 6, 1, 3, 0, 7, 2]
tensor([5, 4, 6, 1, 3, 0, 7, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[2, 5, 0, 4, 1, 3, 1, 0]
tensor([2, 5, 0, 4, 1, 3, 1, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 3, 1, 1, 2, 0, 3, 2]
tensor([0, 3, 1, 1, 2, 0, 3, 2], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/242.pt
[RECEIVE] Queued message from 242
[QUEUE] Processing info from 242
[QUEUE] Stored info from 242
[RECEIVE] Queued message from 242
[QUEUE] Processing info from 242
[QUEUE] Stored info from 242
[RECEIVE] Queued message from 242
[QUEUE] Processing info from 242
[QUEUE] Stored info from 242
[RECEIVE] Queued message from 242
[QUEUE] Processing info from 242
[QUEUE] Stored info from 242
[RECEIVE] Queued message from 242
[QUEUE] Processing info from 242
[QUEUE] Stored info from 242
[RECEIVE] Queued message from 242
[QUEUE] Processing info from 242
[QUEUE] Stored info from 242
[RECEIVE] Queued message from 242
[QUEUE] Processing info from 242
[QUEUE] Stored info from 242
[RECEIVE] Queued message from 242
[QUEUE] Processing info from 242
[QUEUE] Stored info from 242
[RECEIVE] Queued message from 242
[QUEUE] Processing info from 242
[QUEUE] Stored info from 242
[RECEIVE] Queued message from 242
[QUEUE] Processing info from 242
[QUEUE] Stored info from 242
[RECEIVE] Queued message from 242
[QUEUE] Processing info from 242
[QUEUE] Stored info from 242
[RECEIVE] Queued message from 242
[QUEUE] Processing info from 242
[QUEUE] Stored info from 242
[RECEIVE] Queued message from 242
[QUEUE] Processing info from 242
[QUEUE] Stored info from 242
[RECEIVE] Queued message from 242
[QUEUE] Processing info from 242
[QUEUE] Stored info from 242
[RECEIVE] Queued message from 242
[QUEUE] Processing info from 242
[QUEUE] Stored info from 242
[RECEIVE] Queued message from 242
[QUEUE] Processing info from 242
[QUEUE] Stored info from 242
[RECEIVE] Queued message from 242
[QUEUE] Processing info from 242
[QUEUE] Stored info from 242
[RECEIVE] Queued message from 242
[QUEUE] Processing info from 242
[QUEUE] Stored info from 242
[RECEIVE] Queued message from 242
[QUEUE] Processing info from 242
[QUEUE] Stored info from 242
[RECEIVE] Queued message from 242
[QUEUE] Processing info from 242
[QUEUE] Stored info from 242
[RECEIVE] Queued message from 242
[QUEUE] Processing info from 242
[QUEUE] Stored info from 242
[RECEIVE] Queued message from 242
[QUEUE] Processing info from 242
[QUEUE] Stored info from 242
[RECEIVE] Queued message from 242
[QUEUE] Processing info from 242
[QUEUE] Stored info from 242
[RECEIVE] Queued message from 242
[QUEUE] Processing info from 242
[QUEUE] Stored info from 242
[RECEIVE] Queued message from 242
[QUEUE] Processing info from 242
[QUEUE] Stored info from 242
[RECEIVE] Queued message from 242
[QUEUE] Processing info from 242
[QUEUE] Stored info from 242
[RECEIVE] Queued message from 242
[QUEUE] Processing info from 242
[QUEUE] Stored info from 242
[RECEIVE] Queued message from 242
[QUEUE] Processing info from 242
[QUEUE] Stored info from 242
[RECEIVE] Queued message from 242
[QUEUE] Processing info from 242
[QUEUE] Stored info from 242
[RECEIVE] Queued message from 242
[QUEUE] Processing info from 242
[QUEUE] Stored info from 242
[RECEIVE] Queued message from 242
[QUEUE] Processing info from 242
[QUEUE] Stored info from 242
[13] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2568.93it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:07,  2.60s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:12,  1.39s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:39,  1.16s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:25,  1.08s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:21,  1.07s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:13,  1.02s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:05,  1.03it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:15<01:59,  1.06it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:17<01:54,  1.09it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:19<01:52,  1.09it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:21<01:51,  1.08it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:22<01:44,  1.14it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:24<01:39,  1.17it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:25<01:34,  1.22it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:27<01:30,  1.25it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:28<01:27,  1.27it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:30<01:32,  1.18it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:32<01:27,  1.22it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:33<01:23,  1.25it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:35<01:20,  1.28it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:40<02:15,  1.35s/it]Running loglikelihood requests:  30%|███       | 43/142 [00:42<01:54,  1.16s/it]Running loglikelihood requests:  32%|███▏      | 45/142 [00:43<01:38,  1.02s/it]Running loglikelihood requests:  33%|███▎      | 47/142 [00:44<01:27,  1.09it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:46<01:18,  1.18it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:47<01:12,  1.26it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:48<01:07,  1.32it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:50<01:06,  1.31it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:51<01:02,  1.37it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:53<00:59,  1.41it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:54<00:56,  1.44it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:55<00:54,  1.46it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:57<00:52,  1.48it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:58<00:50,  1.50it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:59<00:48,  1.51it/s]Running loglikelihood requests:  50%|█████     | 71/142 [01:01<00:49,  1.42it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [01:02<00:47,  1.46it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [01:03<00:45,  1.47it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:05<00:43,  1.50it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:06<00:41,  1.51it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:07<00:39,  1.53it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:09<00:38,  1.54it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:10<00:36,  1.54it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:11<00:38,  1.42it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:13<00:36,  1.45it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:14<00:34,  1.49it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:15<00:32,  1.52it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:17<00:30,  1.54it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:18<00:28,  1.56it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:19<00:27,  1.57it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:20<00:26,  1.56it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:22<00:28,  1.39it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:23<00:25,  1.46it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:25<00:23,  1.51it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:26<00:21,  1.55it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:27<00:19,  1.59it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:28<00:18,  1.61it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:29<00:16,  1.63it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:32<00:20,  1.25it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:33<00:17,  1.35it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:34<00:14,  1.43it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:35<00:12,  1.50it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:37<00:10,  1.55it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:38<00:09,  1.59it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:39<00:08,  1.62it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:40<00:06,  1.65it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:42<00:05,  1.58it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:43<00:04,  1.64it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:44<00:02,  1.69it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:45<00:01,  1.73it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:46<00:00,  1.76it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:46<00:00,  1.33it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-4): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-9): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (11-12): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (13): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14-19): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (20-21): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (22-23): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (25-31): 7 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-4): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-9): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (11-12): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (13): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14-19): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (20-21): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (22-23): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (25-31): 7 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/13.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5141
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:27:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5141 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 141
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5236
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:27:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5236 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 236
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5242
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:27:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5242 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 242
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5082
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:27:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5082 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 82
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:27:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5171
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:27:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5171 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 171
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5044
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:27:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5044 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 44
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5029
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:27:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5029 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 29
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5104
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:27:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5104 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 104
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5133
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:27:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5133 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 133
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:27:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5080
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:27:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5080 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 80
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:27:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5004
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:27:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5004 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 4
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:27:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:27:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5006
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:27:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5006 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 6
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:27:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5060
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:27:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5060 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 60
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5027
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:27:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5027 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 27
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5045
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:27:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5045 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 45
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5243
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:27:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5243 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 243
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5026
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:27:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5026 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 26
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:27:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5230
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:27:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5230 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 230
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5205
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:27:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5205 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 205
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5011
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:27:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5011 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 11
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:27:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:27:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5109
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:27:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5109 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 109
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5206
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:27:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5206 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 206
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139715693591440 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139715693591440 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139715693591440 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139715693591440 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139714890766272 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139714890766272 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139714890766272 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139714890766272 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[13] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.43661971830985913, 'acc_stderr,none': 0.05927935558412972}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8840011732877091
0.9530187867791682
0.922962504956303
0.7839472459406365
0.8981387177104178
0.9267264969548299
0.5821108615798573
0.2837945650872556
0.6077879555368297
0.40197237439213185
0.8904940347912964
0.7509530386402397
0.901875691813653
0.9122390055224058
0.7316046462179062
0.7968435583929763
0.548007144578676
0.5393492220671232
0.9101317167988644
0.5489553505889563
0.4310648048222707
0.3687557715800523
0.8114931082909914
0.5012706843250611
0.2095243909347347
0.3518983916697559
0.9676050865236582
0.8840253404453832
0.6389046419601837
0.8840011732877091
0.9530187867791682
0.922962504956303
0.7839472459406365
0.8981387177104178
0.9267264969548299
0.5821108615798573
0.2837945650872556
0.6077879555368297
0.40197237439213185
0.8904940347912964
0.7509530386402397
0.901875691813653
0.9122390055224058
0.7316046462179062
0.7968435583929763
0.548007144578676
0.5393492220671232
0.9101317167988644
0.5489553505889563
Total groups 72 exceeded the threshold, stopping comparison.
The group tensor is
[1, 2, 7, 4, 3, 0, 6, 5]
tensor([1, 2, 7, 4, 3, 0, 6, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 5, 4, 1, 0, 7, 2]
tensor([6, 3, 5, 4, 1, 0, 7, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[1, 3, 6, 4, 2, 0, 7, 5]
tensor([1, 3, 6, 4, 2, 0, 7, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 3, 6, 4, 0, 1, 7, 2]
tensor([5, 3, 6, 4, 0, 1, 7, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 4, 6, 5, 3, 0, 7, 1]
tensor([2, 4, 6, 5, 3, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 5, 2, 4, 0, 1, 3]
tensor([0, 1, 5, 2, 4, 0, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/13.pt
[RECEIVE] Queued message from 13
[QUEUE] Processing info from 13
[QUEUE] Stored info from 13
[RECEIVE] Queued message from 13
[QUEUE] Processing info from 13
[QUEUE] Stored info from 13
[RECEIVE] Queued message from 13
[QUEUE] Processing info from 13
[QUEUE] Stored info from 13
[RECEIVE] Queued message from 13
[QUEUE] Processing info from 13
[QUEUE] Stored info from 13
[RECEIVE] Queued message from 13
[QUEUE] Processing info from 13
[QUEUE] Stored info from 13
[RECEIVE] Queued message from 13
[QUEUE] Processing info from 13
[QUEUE] Stored info from 13
[RECEIVE] Queued message from 13
[QUEUE] Processing info from 13
[QUEUE] Stored info from 13
[RECEIVE] Queued message from 13
[QUEUE] Processing info from 13
[QUEUE] Stored info from 13
[RECEIVE] Queued message from 13
[QUEUE] Processing info from 13
[QUEUE] Stored info from 13
[RECEIVE] Queued message from 13
[QUEUE] Processing info from 13
[QUEUE] Stored info from 13
[RECEIVE] Queued message from 13
[QUEUE] Processing info from 13
[QUEUE] Stored info from 13
[RECEIVE] Queued message from 13
[QUEUE] Processing info from 13
[QUEUE] Stored info from 13
[RECEIVE] Queued message from 13
[QUEUE] Processing info from 13
[QUEUE] Stored info from 13
[RECEIVE] Queued message from 13
[QUEUE] Processing info from 13
[QUEUE] Stored info from 13
[RECEIVE] Queued message from 13
[QUEUE] Processing info from 13
[QUEUE] Stored info from 13
[RECEIVE] Queued message from 13
[QUEUE] Processing info from 13
[QUEUE] Stored info from 13
[RECEIVE] Queued message from 13
[QUEUE] Processing info from 13
[QUEUE] Stored info from 13
[RECEIVE] Queued message from 13
[QUEUE] Processing info from 13
[QUEUE] Stored info from 13
[RECEIVE] Queued message from 13
[QUEUE] Processing info from 13
[QUEUE] Stored info from 13
[RECEIVE] Queued message from 13
[QUEUE] Processing info from 13
[QUEUE] Stored info from 13
[RECEIVE] Queued message from 13
[QUEUE] Processing info from 13
[QUEUE] Stored info from 13
[RECEIVE] Queued message from 13
[QUEUE] Processing info from 13
[QUEUE] Stored info from 13
[RECEIVE] Queued message from 13
[QUEUE] Processing info from 13
[QUEUE] Stored info from 13
[RECEIVE] Queued message from 13
[QUEUE] Processing info from 13
[QUEUE] Stored info from 13
[RECEIVE] Queued message from 13
[QUEUE] Processing info from 13
[QUEUE] Stored info from 13
[RECEIVE] Queued message from 13
[QUEUE] Processing info from 13
[QUEUE] Stored info from 13
[RECEIVE] Queued message from 13
[QUEUE] Processing info from 13
[QUEUE] Stored info from 13
[RECEIVE] Queued message from 13
[QUEUE] Processing info from 13
[QUEUE] Stored info from 13
[RECEIVE] Queued message from 13
[QUEUE] Processing info from 13
[QUEUE] Stored info from 13
[RECEIVE] Queued message from 13
[QUEUE] Processing info from 13
[QUEUE] Stored info from 13
[RECEIVE] Queued message from 13
[QUEUE] Processing info from 13
[QUEUE] Stored info from 13
[29] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2617.57it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:03<07:15,  3.09s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:05<03:34,  1.54s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:07<02:52,  1.26s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:09<02:34,  1.15s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:12<03:05,  1.39s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:15<03:03,  1.40s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:17<02:39,  1.24s/it]Running loglikelihood requests:  11%|█         | 15/142 [00:19<02:23,  1.13s/it]Running loglikelihood requests:  12%|█▏        | 17/142 [00:21<02:14,  1.07s/it]Running loglikelihood requests:  13%|█▎        | 19/142 [00:22<02:02,  1.00it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:24<01:55,  1.05it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:25<01:46,  1.11it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:27<01:40,  1.16it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:29<01:35,  1.20it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:30<01:34,  1.20it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:32<01:30,  1.23it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:33<01:26,  1.25it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:35<01:23,  1.28it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:36<01:21,  1.29it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:38<01:19,  1.30it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:39<01:17,  1.31it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:41<01:18,  1.26it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:42<01:14,  1.30it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:44<01:11,  1.33it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:45<01:08,  1.36it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:47<01:05,  1.39it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:48<01:03,  1.40it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:49<01:01,  1.42it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:51<01:08,  1.24it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:53<01:03,  1.30it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:54<00:59,  1.35it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:56<00:56,  1.39it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:57<00:54,  1.42it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:58<00:52,  1.44it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [01:00<00:50,  1.45it/s]Running loglikelihood requests:  50%|█████     | 71/142 [01:01<00:53,  1.32it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [01:03<00:50,  1.38it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [01:04<00:47,  1.41it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:05<00:45,  1.44it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:07<00:42,  1.47it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:08<00:40,  1.49it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:09<00:39,  1.50it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:11<00:37,  1.50it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:12<00:37,  1.47it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:13<00:35,  1.51it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:15<00:33,  1.52it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:16<00:31,  1.54it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:17<00:30,  1.55it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:18<00:28,  1.56it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:20<00:27,  1.57it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:21<00:26,  1.52it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:22<00:25,  1.55it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:23<00:23,  1.56it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:25<00:22,  1.58it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:26<00:20,  1.59it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:27<00:19,  1.60it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:28<00:17,  1.61it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:30<00:16,  1.62it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:32<00:18,  1.34it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:33<00:16,  1.42it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:34<00:14,  1.49it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:35<00:12,  1.54it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:36<00:10,  1.59it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:38<00:09,  1.62it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:39<00:07,  1.64it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:40<00:06,  1.66it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:41<00:05,  1.68it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:48<00:10,  1.51s/it]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:50<00:06,  1.23s/it]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:51<00:03,  1.03s/it]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:52<00:00,  1.08it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:52<00:00,  1.26it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-3): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (4): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-7): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (8): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9-10): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (11): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (12-13): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (15): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (16): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (17-31): 15 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-3): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (4): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-7): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (8): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9-10): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (11): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (12-13): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (15): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (16): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (17-31): 15 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/29.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:29:39] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5206
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:29:39] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5206 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 206
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5230
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:29:39] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5230 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 230
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5133
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:29:39] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5133 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 133
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:29:39] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5027
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:29:39] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5027 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 27
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5080
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:29:39] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5080 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 80
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5026
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:29:39] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5026 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 26
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5045
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:29:39] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5045 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 45
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:29:39] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:29:39] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5243
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:29:39] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5243 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 243
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5171
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:29:39] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5171 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 171
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:29:39] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5011
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:29:39] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5011 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 11
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5205
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:29:39] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5205 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 205
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5004
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:29:39] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5004 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 4
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5006
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:29:39] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5006 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 6
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5242
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:29:39] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5242 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 242
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5141
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:29:39] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5141 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 141
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5013
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:29:39] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5013 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 13
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:29:39] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5044
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:29:39] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5044 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 44
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:29:39] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5109
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:29:39] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5109 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 109
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:29:39] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5104
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:29:39] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5104 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 104
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5060
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:29:39] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5060 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 60
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5082
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:29:39] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5082 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 82
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5236
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:29:39] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5236 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 236
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:29:39] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139716275602544 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139716275602544 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139716275602544 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139716275602544 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139716275293312 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139716275293312 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139716275293312 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139716275293312 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[29] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.43661971830985913, 'acc_stderr,none': 0.05927935558412972}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.6384788962207051
0.4946572039289874
0.7062468225311351
0.5924118081316296
0.8055799477986278
0.4290834385090486
0.5207152243980063
0.40307410421369466
0.575849756312845
0.37833122092903004
0.559402975459772
0.9202435099718248
0.7328649512638977
0.4656521136449837
0.6226167455222542
0.6500475926241498
0.14933051029764177
0.852848973497393
0.7020336348742873
0.8036038458930006
0.25840240277743587
0.45348406473870356
0.7291236246725161
0.5999541971262276
0.7071125031923391
0.6523270915574834
0.5982105985982268
0.6520903105513685
0.39933491227192136
0.6384788962207051
0.4946572039289874
0.7062468225311351
0.5924118081316296
0.8055799477986278
0.4290834385090486
0.5207152243980063
0.40307410421369466
0.575849756312845
0.37833122092903004
0.559402975459772
0.9202435099718248
0.7328649512638977
0.4656521136449837
0.6226167455222542
0.6500475926241498
0.14933051029764177
0.852848973497393
0.7020336348742873
0.8036038458930006
0.25840240277743587
0.45348406473870356
0.7291236246725161
0.5999541971262276
0.7071125031923391
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[6, 3, 2, 1, 5, 0, 7, 4]
tensor([6, 3, 2, 1, 5, 0, 7, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 5, 4, 2, 6, 0, 7, 1]
tensor([3, 5, 4, 2, 6, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 7, 6, 3, 4, 1, 5, 0]
tensor([2, 7, 6, 3, 4, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 2, 5, 4, 6, 0, 7, 1]
tensor([3, 2, 5, 4, 6, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 5, 7, 0, 3, 2, 6, 1]
tensor([4, 5, 7, 0, 3, 2, 6, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 6, 3, 4, 2, 1, 7, 0]
tensor([5, 6, 3, 4, 2, 1, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/29.pt
[RECEIVE] Queued message from 29
[QUEUE] Processing info from 29
[QUEUE] Stored info from 29
[RECEIVE] Queued message from 29
[QUEUE] Processing info from 29
[QUEUE] Stored info from 29
[RECEIVE] Queued message from 29
[QUEUE] Processing info from 29
[QUEUE] Stored info from 29
[RECEIVE] Queued message from 29
[QUEUE] Processing info from 29
[QUEUE] Stored info from 29
[RECEIVE] Queued message from 29
[QUEUE] Processing info from 29
[QUEUE] Stored info from 29
[RECEIVE] Queued message from 29
[QUEUE] Processing info from 29
[QUEUE] Stored info from 29
[RECEIVE] Queued message from 29
[QUEUE] Processing info from 29
[QUEUE] Stored info from 29
[RECEIVE] Queued message from 29
[QUEUE] Processing info from 29
[QUEUE] Stored info from 29
[RECEIVE] Queued message from 29
[QUEUE] Processing info from 29
[QUEUE] Stored info from 29
[RECEIVE] Queued message from 29
[QUEUE] Processing info from 29
[QUEUE] Stored info from 29
[RECEIVE] Queued message from 29
[QUEUE] Processing info from 29
[QUEUE] Stored info from 29
[RECEIVE] Queued message from 29
[QUEUE] Processing info from 29
[QUEUE] Stored info from 29
[RECEIVE] Queued message from 29
[QUEUE] Processing info from 29
[QUEUE] Stored info from 29
[RECEIVE] Queued message from 29
[QUEUE] Processing info from 29
[QUEUE] Stored info from 29
[RECEIVE] Queued message from 29
[QUEUE] Processing info from 29
[QUEUE] Stored info from 29
[RECEIVE] Queued message from 29
[QUEUE] Processing info from 29
[QUEUE] Stored info from 29
[RECEIVE] Queued message from 29
[QUEUE] Processing info from 29
[QUEUE] Stored info from 29
[RECEIVE] Queued message from 29
[QUEUE] Processing info from 29
[QUEUE] Stored info from 29
[RECEIVE] Queued message from 29
[QUEUE] Processing info from 29
[QUEUE] Stored info from 29
[RECEIVE] Queued message from 29
[QUEUE] Processing info from 29
[QUEUE] Stored info from 29
[RECEIVE] Queued message from 29
[QUEUE] Processing info from 29
[QUEUE] Stored info from 29
[RECEIVE] Queued message from 29
[QUEUE] Processing info from 29
[QUEUE] Stored info from 29
[RECEIVE] Queued message from 29
[QUEUE] Processing info from 29
[QUEUE] Stored info from 29
[RECEIVE] Queued message from 29
[QUEUE] Processing info from 29
[QUEUE] Stored info from 29
[RECEIVE] Queued message from 29
[QUEUE] Processing info from 29
[QUEUE] Stored info from 29
[RECEIVE] Queued message from 29
[QUEUE] Processing info from 29
[QUEUE] Stored info from 29
[RECEIVE] Queued message from 29
[QUEUE] Processing info from 29
[QUEUE] Stored info from 29
[RECEIVE] Queued message from 29
[QUEUE] Processing info from 29
[QUEUE] Stored info from 29
[RECEIVE] Queued message from 29
[QUEUE] Processing info from 29
[QUEUE] Stored info from 29
[RECEIVE] Queued message from 29
[QUEUE] Processing info from 29
[QUEUE] Stored info from 29
[RECEIVE] Queued message from 29
[QUEUE] Processing info from 29
[QUEUE] Stored info from 29
[11] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2648.44it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:05,  2.59s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:18,  1.43s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:39,  1.16s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:23,  1.06s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:12,  1.00it/s]Running loglikelihood requests:   8%|▊         | 11/142 [00:11<02:05,  1.05it/s]Running loglikelihood requests:   9%|▉         | 13/142 [00:13<01:58,  1.09it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:15<02:09,  1.02s/it]Running loglikelihood requests:  12%|█▏        | 17/142 [00:17<01:58,  1.05it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:19<01:49,  1.12it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:20<01:42,  1.18it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:22<01:42,  1.16it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:23<01:35,  1.22it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:25<01:35,  1.21it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:26<01:29,  1.26it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:28<01:25,  1.30it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:29<01:21,  1.33it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:31<01:19,  1.35it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:32<01:17,  1.35it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:34<01:15,  1.37it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:35<01:15,  1.34it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:37<01:12,  1.37it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:38<01:09,  1.41it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:39<01:06,  1.44it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:41<01:03,  1.47it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:42<01:00,  1.50it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:43<00:58,  1.52it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:44<00:56,  1.54it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:46<00:56,  1.51it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:47<00:54,  1.51it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:48<00:52,  1.54it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:50<00:50,  1.56it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:51<00:48,  1.58it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:52<00:46,  1.60it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:53<00:45,  1.61it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:54<00:43,  1.62it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:56<00:46,  1.47it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [00:57<00:43,  1.53it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [00:58<00:41,  1.57it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:00<00:39,  1.60it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:01<00:37,  1.62it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:02<00:35,  1.64it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:03<00:34,  1.65it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:04<00:32,  1.67it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:06<00:33,  1.57it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:07<00:31,  1.60it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:08<00:30,  1.62it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:09<00:28,  1.64it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:12<00:34,  1.31it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:13<00:30,  1.41it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:14<00:27,  1.49it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:15<00:25,  1.54it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:16<00:24,  1.53it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:18<00:21,  1.59it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:19<00:20,  1.64it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:21<00:23,  1.34it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:22<00:20,  1.45it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:23<00:17,  1.53it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:24<00:15,  1.59it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:25<00:14,  1.64it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:27<00:12,  1.62it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:28<00:11,  1.68it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:29<00:09,  1.72it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:30<00:08,  1.74it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:31<00:07,  1.77it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:32<00:06,  1.78it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:33<00:05,  1.80it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:35<00:04,  1.50it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:36<00:03,  1.48it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:38<00:01,  1.55it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:39<00:00,  1.63it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:39<00:00,  1.43it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-31): 26 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-31): 26 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/11.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:31:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5013
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:31:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5013 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 13
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5060
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:31:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5060 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 60
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5029
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:31:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5029 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 29
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5109
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:31:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5109 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 109
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5080
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:31:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5080 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 80
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:31:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5243
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:31:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5243 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 243
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:31:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5206
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:31:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5206 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 206
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5242
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:31:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5242 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 242
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5044
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:31:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5044 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 44
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5045
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:31:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5045 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 45
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:31:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5104
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:31:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5104 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 104
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5205
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:31:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5205 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 205
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:31:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5026
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:31:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5026 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 26
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5230
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:31:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5230 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 230
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5027
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:31:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5027 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 27
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:31:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5133
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:31:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5133 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 133
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5171
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:31:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5171 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 171
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5082
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:31:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5082 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 82
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:31:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5006
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:31:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5006 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 6
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:31:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:31:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5004
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:31:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5004 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 4
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5236
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:31:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5236 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 236
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5141
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:31:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5141 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 141
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139718396752000 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139718396752000 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139718396752000 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139718396752000 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139714886401872 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139714886401872 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139714886401872 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139714886401872 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[11] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4225352112676056, 'acc_stderr,none': 0.059039842056825796}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8301327615319641
0.7817720914227475
0.8113678911982368
0.2257173763133808
0.2927105469616105
0.5177793359335131
0.8145737190612207
0.7363478990038121
0.20758834533702153
0.2533018140549718
0.30764875086796684
0.29044714199656413
0.9350374080783923
0.6277994360424477
0.603553220567354
0.78279661631625
0.6718149226457006
0.5353760149732133
0.6848376228333551
0.9446001512801305
0.7972906165117697
0.5043025319455414
0.5939887608746786
0.6455402209569181
0.2505215486241291
0.321550947803521
0.8361163063826382
0.7208169010376037
0.9633188772100769
0.8301327615319641
0.7817720914227475
0.8113678911982368
0.2257173763133808
0.2927105469616105
0.5177793359335131
0.8145737190612207
0.7363478990038121
0.20758834533702153
0.2533018140549718
0.30764875086796684
0.29044714199656413
0.9350374080783923
0.6277994360424477
0.603553220567354
0.78279661631625
0.6718149226457006
0.5353760149732133
0.6848376228333551
0.9446001512801305
0.7972906165117697
0.5043025319455414
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[6, 5, 4, 1, 3, 0, 7, 2]
tensor([6, 5, 4, 1, 3, 0, 7, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 7, 5, 1, 0, 4, 2]
tensor([6, 3, 7, 5, 1, 0, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[6, 4, 7, 0, 3, 1, 5, 2]
tensor([6, 4, 7, 0, 3, 1, 5, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 5, 3, 4, 1, 0, 7, 6]
tensor([2, 5, 3, 4, 1, 0, 7, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 5, 0, 2, 4, 0, 1, 1]
tensor([3, 5, 0, 2, 4, 0, 1, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 1, 0, 2, 1, 2, 3]
tensor([0, 3, 1, 0, 2, 1, 2, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 3, 1, 2, 2, 1, 3, 0]
tensor([0, 3, 1, 2, 2, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 1, 2, 0, 3, 3, 2, 1]
tensor([0, 1, 2, 0, 3, 3, 2, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1, 0, 1.0, 1.0, 1.0, 1.0]
tensor([0, 1, 1, 0, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/11.pt
[RECEIVE] Queued message from 11
[QUEUE] Processing info from 11
[QUEUE] Stored info from 11
[RECEIVE] Queued message from 11
[QUEUE] Processing info from 11
[QUEUE] Stored info from 11
[RECEIVE] Queued message from 11
[QUEUE] Processing info from 11
[QUEUE] Stored info from 11
[RECEIVE] Queued message from 11
[QUEUE] Processing info from 11
[QUEUE] Stored info from 11
[RECEIVE] Queued message from 11
[QUEUE] Processing info from 11
[QUEUE] Stored info from 11
[RECEIVE] Queued message from 11
[QUEUE] Processing info from 11
[QUEUE] Stored info from 11
[RECEIVE] Queued message from 11
[QUEUE] Processing info from 11
[QUEUE] Stored info from 11
[RECEIVE] Queued message from 11
[QUEUE] Processing info from 11
[QUEUE] Stored info from 11
[RECEIVE] Queued message from 11
[QUEUE] Processing info from 11
[QUEUE] Stored info from 11
[RECEIVE] Queued message from 11
[QUEUE] Processing info from 11
[QUEUE] Stored info from 11
[RECEIVE] Queued message from 11
[QUEUE] Processing info from 11
[QUEUE] Stored info from 11
[RECEIVE] Queued message from 11
[QUEUE] Processing info from 11
[QUEUE] Stored info from 11
[RECEIVE] Queued message from 11
[QUEUE] Processing info from 11
[QUEUE] Stored info from 11
[RECEIVE] Queued message from 11
[QUEUE] Processing info from 11
[QUEUE] Stored info from 11
[RECEIVE] Queued message from 11
[QUEUE] Processing info from 11
[QUEUE] Stored info from 11
[RECEIVE] Queued message from 11
[QUEUE] Processing info from 11
[QUEUE] Stored info from 11
[RECEIVE] Queued message from 11
[QUEUE] Processing info from 11
[QUEUE] Stored info from 11
[RECEIVE] Queued message from 11
[QUEUE] Processing info from 11
[QUEUE] Stored info from 11
[RECEIVE] Queued message from 11
[QUEUE] Processing info from 11
[QUEUE] Stored info from 11
[RECEIVE] Queued message from 11
[QUEUE] Processing info from 11
[QUEUE] Stored info from 11
[RECEIVE] Queued message from 11
[QUEUE] Processing info from 11
[QUEUE] Stored info from 11
[RECEIVE] Queued message from 11
[QUEUE] Processing info from 11
[QUEUE] Stored info from 11
[RECEIVE] Queued message from 11
[QUEUE] Processing info from 11
[QUEUE] Stored info from 11
[RECEIVE] Queued message from 11
[QUEUE] Processing info from 11
[QUEUE] Stored info from 11
[RECEIVE] Queued message from 11
[QUEUE] Processing info from 11
[QUEUE] Stored info from 11
[RECEIVE] Queued message from 11
[QUEUE] Processing info from 11
[QUEUE] Stored info from 11
[RECEIVE] Queued message from 11
[QUEUE] Processing info from 11
[QUEUE] Stored info from 11
[RECEIVE] Queued message from 11
[QUEUE] Processing info from 11
[QUEUE] Stored info from 11
[RECEIVE] Queued message from 11
[QUEUE] Processing info from 11
[QUEUE] Stored info from 11
[RECEIVE] Queued message from 11
[QUEUE] Processing info from 11
[QUEUE] Stored info from 11
[RECEIVE] Queued message from 11
[QUEUE] Processing info from 11
[QUEUE] Stored info from 11
[205] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2624.88it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:03<07:46,  3.31s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:05<03:39,  1.58s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:07<02:51,  1.25s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:09<02:31,  1.12s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:11<02:22,  1.08s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:13<02:20,  1.07s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:10,  1.01s/it]Running loglikelihood requests:  11%|█         | 15/142 [00:16<02:01,  1.04it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:18<01:55,  1.08it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:19<01:48,  1.13it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:21<01:43,  1.17it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:23<01:42,  1.16it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:24<01:36,  1.21it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:26<01:32,  1.24it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:27<01:28,  1.27it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:29<01:25,  1.30it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:30<01:22,  1.31it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:32<01:20,  1.33it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:34<01:26,  1.21it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:35<01:22,  1.25it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:37<01:22,  1.23it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:38<01:18,  1.26it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:40<01:14,  1.30it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:41<01:11,  1.34it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:43<01:14,  1.25it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:44<01:10,  1.30it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:46<01:05,  1.35it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:47<01:02,  1.39it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:48<01:00,  1.40it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:50<00:58,  1.43it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:51<00:55,  1.45it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:52<00:54,  1.46it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:54<00:59,  1.28it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:56<00:55,  1.35it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:57<00:51,  1.41it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:58<00:48,  1.45it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [01:00<00:46,  1.49it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [01:01<00:44,  1.52it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:02<00:42,  1.54it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:03<00:41,  1.51it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:05<00:39,  1.53it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:06<00:38,  1.55it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:07<00:36,  1.57it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:08<00:34,  1.58it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:10<00:33,  1.60it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:11<00:31,  1.60it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:12<00:30,  1.61it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:14<00:29,  1.57it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:15<00:29,  1.55it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:16<00:27,  1.59it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:17<00:25,  1.61it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:18<00:23,  1.63it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:20<00:22,  1.65it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:21<00:21,  1.66it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:22<00:19,  1.67it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:24<00:21,  1.45it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:25<00:19,  1.51it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:26<00:17,  1.56it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:27<00:15,  1.60it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:28<00:14,  1.64it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:30<00:12,  1.65it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:31<00:11,  1.67it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:32<00:10,  1.69it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:33<00:08,  1.70it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:35<00:08,  1.60it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:36<00:06,  1.63it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:37<00:05,  1.66it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:38<00:04,  1.68it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:39<00:02,  1.69it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:40<00:01,  1.69it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:42<00:00,  1.71it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:42<00:00,  1.39it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-15): 11 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (16): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (17): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (18-30): 13 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (31): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-15): 11 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (16): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (17): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (18-30): 13 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (31): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/205.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5006
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:33:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5006 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 6
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5082
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:33:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5082 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 82
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5206
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:33:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5206 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 206
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5026
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:33:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5026 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 26
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5236
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:33:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5236 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 236
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5029
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:33:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5029 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 29
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5243
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:33:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5243 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 243
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:33:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5242
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:33:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5242 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 242
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5109
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:33:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5109 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 109
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:33:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5004
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:33:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5004 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 4
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5141
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:33:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5141 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 141
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5044
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:33:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5044 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 44
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:33:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:33:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5011
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:33:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5011 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 11
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5060
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:33:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5060 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 60
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5080
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:33:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5080 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 80
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:33:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5045
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:33:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5045 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 45
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5133
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:33:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5133 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 133
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5104
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:33:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5104 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 104
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5230
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:33:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5230 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 230
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5027
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:33:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5027 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 27
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5013
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:33:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5013 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 13
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:33:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5171
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:33:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5171 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 171
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:33:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:33:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:33:31] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139714886392896 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139714886392896 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139714886392896 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139714886392896 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139715693133792 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139715693133792 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139715693133792 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139715693133792 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[205] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4225352112676056, 'acc_stderr,none': 0.059039842056825796}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8980271762152415
0.2639787465429745
0.5625332696290335
0.793649776762635
0.3255906663223904
0.0484338095439226
0.14923347971103265
0.5710137578745996
0.4024845012023718
0.40192324238029414
0.7421347168699821
0.33528288680973795
0.3799695309319889
0.38260979896102654
0.8288488026343434
0.5741428622514854
0.32292256805357755
0.2608862087917634
0.5815302784189874
0.6526878745506514
0.23164180573632143
0.7209107763819704
0.641400211099821
0.36378810546943974
0.5869502091248732
0.1447672816588167
0.22624580082754567
0.43042437260655503
0.5802248606876254
0.8980271762152415
0.2639787465429745
0.5625332696290335
0.793649776762635
0.3255906663223904
0.0484338095439226
0.14923347971103265
0.5710137578745996
0.4024845012023718
0.40192324238029414
0.7421347168699821
0.33528288680973795
0.3799695309319889
0.38260979896102654
0.8288488026343434
0.5741428622514854
0.32292256805357755
0.2608862087917634
0.5815302784189874
0.6526878745506514
0.23164180573632143
0.7209107763819704
0.641400211099821
0.36378810546943974
0.5869502091248732
0.1447672816588167
0.22624580082754567
0.43042437260655503
Total groups 73 exceeded the threshold, stopping comparison.
The group tensor is
[5, 3, 7, 4, 1, 0, 6, 2]
tensor([5, 3, 7, 4, 1, 0, 6, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 5, 1, 2, 4, 0, 7, 3]
tensor([6, 5, 1, 2, 4, 0, 7, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 4, 3, 1, 5, 0, 7, 2]
tensor([6, 4, 3, 1, 5, 0, 7, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[7, 3, 6, 0, 4, 2, 5, 1]
tensor([7, 3, 6, 0, 4, 2, 5, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 4, 1, 2, 0, 3, 5, 1]
tensor([0, 4, 1, 2, 0, 3, 5, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[2, 0, 1, 3, 1, 0, 2, 3]
tensor([2, 0, 1, 3, 1, 0, 2, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 1, 1, 3, 0, 2, 3, 2]
tensor([0, 1, 1, 3, 0, 2, 3, 2], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1, 1.0, 1.0, 1.0, 0]
tensor([0, 1, 1, 1, 1, 1, 1, 0], dtype=torch.int32)
[0, 1]
The group tensor is
[1, 0, 1, 1.0, 1.0, 0, 1.0, 1.0]
tensor([1, 0, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/205.pt
[RECEIVE] Queued message from 205
[QUEUE] Processing info from 205
[QUEUE] Stored info from 205
[RECEIVE] Queued message from 205
[QUEUE] Processing info from 205
[QUEUE] Stored info from 205
[RECEIVE] Queued message from 205
[QUEUE] Processing info from 205
[QUEUE] Stored info from 205
[RECEIVE] Queued message from 205
[QUEUE] Processing info from 205
[QUEUE] Stored info from 205
[RECEIVE] Queued message from 205
[QUEUE] Processing info from 205
[QUEUE] Stored info from 205
[RECEIVE] Queued message from 205
[QUEUE] Processing info from 205
[QUEUE] Stored info from 205
[RECEIVE] Queued message from 205
[QUEUE] Processing info from 205
[QUEUE] Stored info from 205
[RECEIVE] Queued message from 205
[QUEUE] Processing info from 205
[QUEUE] Stored info from 205
[RECEIVE] Queued message from 205
[QUEUE] Processing info from 205
[QUEUE] Stored info from 205
[RECEIVE] Queued message from 205
[QUEUE] Processing info from 205
[QUEUE] Stored info from 205
[RECEIVE] Queued message from 205
[QUEUE] Processing info from 205
[QUEUE] Stored info from 205
[RECEIVE] Queued message from 205
[QUEUE] Processing info from 205
[QUEUE] Stored info from 205
[RECEIVE] Queued message from 205
[QUEUE] Processing info from 205
[QUEUE] Stored info from 205
[RECEIVE] Queued message from 205
[QUEUE] Processing info from 205
[QUEUE] Stored info from 205
[RECEIVE] Queued message from 205
[QUEUE] Processing info from 205
[QUEUE] Stored info from 205
[RECEIVE] Queued message from 205
[QUEUE] Processing info from 205
[QUEUE] Stored info from 205
[RECEIVE] Queued message from 205
[QUEUE] Processing info from 205
[QUEUE] Stored info from 205
[RECEIVE] Queued message from 205
[QUEUE] Processing info from 205
[QUEUE] Stored info from 205
[RECEIVE] Queued message from 205
[QUEUE] Processing info from 205
[QUEUE] Stored info from 205
[RECEIVE] Queued message from 205
[QUEUE] Processing info from 205
[QUEUE] Stored info from 205
[RECEIVE] Queued message from 205
[QUEUE] Processing info from 205
[QUEUE] Stored info from 205
[RECEIVE] Queued message from 205
[QUEUE] Processing info from 205
[QUEUE] Stored info from 205
[RECEIVE] Queued message from 205
[QUEUE] Processing info from 205
[QUEUE] Stored info from 205
[RECEIVE] Queued message from 205
[QUEUE] Processing info from 205
[QUEUE] Stored info from 205
[RECEIVE] Queued message from 205
[QUEUE] Processing info from 205
[QUEUE] Stored info from 205
[RECEIVE] Queued message from 205
[QUEUE] Processing info from 205
[QUEUE] Stored info from 205
[RECEIVE] Queued message from 205
[QUEUE] Processing info from 205
[QUEUE] Stored info from 205
[RECEIVE] Queued message from 205
[QUEUE] Processing info from 205
[QUEUE] Stored info from 205
[RECEIVE] Queued message from 205
[QUEUE] Processing info from 205
[QUEUE] Stored info from 205
[RECEIVE] Queued message from 205
[QUEUE] Processing info from 205
[QUEUE] Stored info from 205
[RECEIVE] Queued message from 205
[QUEUE] Processing info from 205
[QUEUE] Stored info from 205
[243] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2607.53it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:03<08:36,  3.66s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:05<03:54,  1.69s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:07<03:14,  1.42s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:09<02:46,  1.24s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:11<02:30,  1.13s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:13<02:19,  1.07s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:15<02:11,  1.02s/it]Running loglikelihood requests:  11%|█         | 15/142 [00:17<02:04,  1.02it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:19<02:00,  1.04it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:20<01:52,  1.09it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:22<01:46,  1.14it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:24<01:40,  1.18it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:25<01:36,  1.22it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:28<01:57,  1.02s/it]Running loglikelihood requests:  20%|██        | 29/142 [00:30<01:46,  1.06it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:31<01:38,  1.13it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:33<01:32,  1.18it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:34<01:27,  1.22it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:36<01:23,  1.25it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:37<01:20,  1.28it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:39<01:24,  1.20it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:40<01:20,  1.24it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:42<01:15,  1.28it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:43<01:11,  1.32it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:45<01:08,  1.36it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:46<01:05,  1.39it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:47<01:02,  1.42it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:49<01:05,  1.33it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:50<01:01,  1.38it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:52<00:58,  1.41it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:53<00:56,  1.44it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:54<00:54,  1.46it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:56<00:52,  1.48it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:57<00:50,  1.49it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:59<00:50,  1.46it/s]Running loglikelihood requests:  50%|█████     | 71/142 [01:00<00:47,  1.48it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [01:01<00:45,  1.50it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [01:02<00:44,  1.52it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:04<00:42,  1.53it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:05<00:40,  1.54it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:06<00:39,  1.54it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:08<00:38,  1.55it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:10<00:42,  1.33it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:11<00:39,  1.40it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:12<00:36,  1.45it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:13<00:34,  1.49it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:15<00:32,  1.53it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:16<00:30,  1.55it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:17<00:28,  1.57it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:18<00:27,  1.59it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:20<00:26,  1.54it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:21<00:24,  1.57it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:22<00:23,  1.59it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:24<00:24,  1.40it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:25<00:22,  1.48it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:26<00:20,  1.54it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:27<00:18,  1.59it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:29<00:16,  1.63it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:31<00:21,  1.17it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:33<00:17,  1.29it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:34<00:15,  1.39it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:35<00:12,  1.47it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:36<00:11,  1.53it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:37<00:09,  1.58it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:38<00:08,  1.61it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:40<00:07,  1.57it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:41<00:05,  1.60it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:42<00:04,  1.63it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:43<00:03,  1.66it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:44<00:01,  1.69it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:46<00:00,  1.73it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:46<00:00,  1.34it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-4): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-6): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (7-8): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (11-12): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (13): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14-31): 18 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-4): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-6): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (7-8): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (11-12): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (13): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14-31): 18 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/243.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5060
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:35:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5060 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 60
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5205
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:35:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5205 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 205
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:35:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:35:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:35:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5006
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:35:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5006 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 6
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:35:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5236
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:35:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5236 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 236
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:35:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5133
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:35:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5133 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 133
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5230
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:35:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5230 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 230
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5141
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:35:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5141 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 141
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5029
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:35:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5029 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 29
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5013
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:35:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5013 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 13
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5080
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:35:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5080 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 80
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5011
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:35:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5011 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 11
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5104
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:35:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5104 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 104
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5171
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:35:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5171 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 171
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5206
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:35:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5206 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 206
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5242
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:35:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5242 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 242
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:35:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5027
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:35:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5027 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 27
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5004
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:35:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5004 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 4
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:35:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:35:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5044
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:35:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5044 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 44
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5109
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:35:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5109 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 109
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5045
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:35:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5045 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 45
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5026
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:35:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5026 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 26
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:35:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5082
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:35:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5082 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 82
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139714664507888 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139714664507888 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139714664507888 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139714664507888 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139718425979328 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139718425979328 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139718425979328 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139718425979328 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[243] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4507042253521127, 'acc_stderr,none': 0.05947027187738001}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9728816226148068
0.5587440604316873
0.8603958805228331
0.8559030347476725
0.9827298775692989
0.9752051704922662
0.9320451620794601
0.8534915859631292
0.8216376829910712
0.7152752058820862
0.865677149871932
0.6996438609344103
0.5450489764598446
0.9459412501293835
0.800938078166953
0.9388899316299849
0.6171018502143922
0.5700995146297211
0.9725502911927032
0.8593526631716398
0.8340908152739906
0.8867570952520308
0.8278223956249111
0.6726110030960961
0.822005113004547
0.952024055144357
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[2, 6, 4, 1, 3, 0, 7, 5]
tensor([2, 6, 4, 1, 3, 0, 7, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 6, 3, 1, 5, 0, 7, 2]
tensor([4, 6, 3, 1, 5, 0, 7, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 4, 2, 5, 0, 7, 3]
tensor([6, 1, 4, 2, 5, 0, 7, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 3, 7, 1, 6, 0, 5, 2]
tensor([4, 3, 7, 1, 6, 0, 5, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 6, 5, 1, 3, 0, 4, 2]
tensor([7, 6, 5, 1, 3, 0, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[1, 0, 5, 4, 3, 0, 1, 2]
tensor([1, 0, 5, 4, 3, 0, 1, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 3, 0, 2, 1, 3, 2]
tensor([0, 1, 3, 0, 2, 1, 3, 2], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/243.pt
[RECEIVE] Queued message from 243
[QUEUE] Processing info from 243
[QUEUE] Stored info from 243
[RECEIVE] Queued message from 243
[QUEUE] Processing info from 243
[QUEUE] Stored info from 243
[RECEIVE] Queued message from 243
[QUEUE] Processing info from 243
[QUEUE] Stored info from 243
[RECEIVE] Queued message from 243
[QUEUE] Processing info from 243
[QUEUE] Stored info from 243
[RECEIVE] Queued message from 243
[QUEUE] Processing info from 243
[QUEUE] Stored info from 243
[RECEIVE] Queued message from 243
[QUEUE] Processing info from 243
[QUEUE] Stored info from 243
[RECEIVE] Queued message from 243
[QUEUE] Processing info from 243
[QUEUE] Stored info from 243
[RECEIVE] Queued message from 243
[QUEUE] Processing info from 243
[QUEUE] Stored info from 243
[RECEIVE] Queued message from 243
[QUEUE] Processing info from 243
[QUEUE] Stored info from 243
[RECEIVE] Queued message from 243
[QUEUE] Processing info from 243
[QUEUE] Stored info from 243
[RECEIVE] Queued message from 243
[QUEUE] Processing info from 243
[QUEUE] Stored info from 243
[RECEIVE] Queued message from 243
[QUEUE] Processing info from 243
[QUEUE] Stored info from 243
[RECEIVE] Queued message from 243
[QUEUE] Processing info from 243
[QUEUE] Stored info from 243
[RECEIVE] Queued message from 243
[QUEUE] Processing info from 243
[QUEUE] Stored info from 243
[RECEIVE] Queued message from 243
[QUEUE] Processing info from 243
[QUEUE] Stored info from 243
[RECEIVE] Queued message from 243
[QUEUE] Processing info from 243
[QUEUE] Stored info from 243
[RECEIVE] Queued message from 243
[QUEUE] Processing info from 243
[QUEUE] Stored info from 243
[RECEIVE] Queued message from 243
[QUEUE] Processing info from 243
[QUEUE] Stored info from 243
[RECEIVE] Queued message from 243
[QUEUE] Processing info from 243
[QUEUE] Stored info from 243
[RECEIVE] Queued message from 243
[QUEUE] Processing info from 243
[QUEUE] Stored info from 243
[RECEIVE] Queued message from 243
[QUEUE] Processing info from 243
[QUEUE] Stored info from 243
[RECEIVE] Queued message from 243
[QUEUE] Processing info from 243
[QUEUE] Stored info from 243
[RECEIVE] Queued message from 243
[QUEUE] Processing info from 243
[QUEUE] Stored info from 243
[RECEIVE] Queued message from 243
[QUEUE] Processing info from 243
[QUEUE] Stored info from 243
[RECEIVE] Queued message from 243
[QUEUE] Processing info from 243
[QUEUE] Stored info from 243
[RECEIVE] Queued message from 243
[QUEUE] Processing info from 243
[QUEUE] Stored info from 243
[RECEIVE] Queued message from 243
[QUEUE] Processing info from 243
[QUEUE] Stored info from 243
[RECEIVE] Queued message from 243
[QUEUE] Processing info from 243
[QUEUE] Stored info from 243
[RECEIVE] Queued message from 243
[QUEUE] Processing info from 243
[QUEUE] Stored info from 243
[RECEIVE] Queued message from 243
[QUEUE] Processing info from 243
[QUEUE] Stored info from 243
[RECEIVE] Queued message from 243
[QUEUE] Processing info from 243
[QUEUE] Stored info from 243
[171] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2561.04it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:24,  2.73s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:17,  1.42s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:41,  1.18s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:34,  1.14s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:20,  1.05s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:10,  1.00it/s]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:03,  1.04it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:15<01:56,  1.09it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:17<01:51,  1.12it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:19<01:53,  1.08it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:20<01:45,  1.14it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:22<01:45,  1.12it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:24<01:38,  1.19it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:28<02:14,  1.17s/it]Running loglikelihood requests:  20%|██        | 29/142 [00:29<02:00,  1.06s/it]Running loglikelihood requests:  22%|██▏       | 31/142 [00:31<01:46,  1.04it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:32<01:36,  1.13it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:34<01:29,  1.20it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:35<01:23,  1.25it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:36<01:19,  1.30it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:38<01:15,  1.33it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:40<01:23,  1.19it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:41<01:16,  1.26it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:43<01:12,  1.32it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:44<01:07,  1.38it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:45<01:03,  1.43it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:46<01:00,  1.47it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:48<00:58,  1.50it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:49<00:58,  1.44it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:51<00:56,  1.47it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:52<00:53,  1.51it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:53<00:55,  1.44it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:55<00:51,  1.48it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:56<00:49,  1.52it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:57<00:47,  1.55it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:58<00:45,  1.56it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [01:00<00:46,  1.49it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [01:01<00:43,  1.53it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:02<00:41,  1.56it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:03<00:39,  1.59it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:05<00:37,  1.61it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:06<00:36,  1.62it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:07<00:34,  1.63it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:08<00:33,  1.64it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:10<00:34,  1.54it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:11<00:32,  1.59it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:12<00:29,  1.63it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:13<00:28,  1.67it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:14<00:26,  1.69it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:16<00:25,  1.71it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:17<00:23,  1.72it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:18<00:22,  1.74it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:19<00:21,  1.74it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:20<00:20,  1.68it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:21<00:19,  1.70it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:22<00:18,  1.72it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:24<00:16,  1.73it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:25<00:15,  1.74it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:26<00:14,  1.75it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:27<00:13,  1.76it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:28<00:11,  1.76it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:30<00:12,  1.47it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:31<00:10,  1.55it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:34<00:12,  1.24it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:35<00:09,  1.34it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:36<00:07,  1.46it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:37<00:05,  1.55it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:38<00:04,  1.65it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:39<00:03,  1.60it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:41<00:01,  1.51it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:42<00:00,  1.62it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:42<00:00,  1.39it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-8): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10-30): 21 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (31): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-8): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10-30): 21 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (31): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/171.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:37:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5013
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:37:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5013 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 13
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5044
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:37:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5044 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 44
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5242
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:37:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5242 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 242
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:37:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5004
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:37:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5004 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 4
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5080
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:37:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5080 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 80
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5205
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:37:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5205 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 205
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5060
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:37:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5060 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 60
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5006
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:37:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5006 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 6
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:37:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:37:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:37:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5029
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:37:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5029 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 29
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5206
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:37:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5206 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 206
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5027
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:37:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5027 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 27
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5026
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:37:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5026 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 26
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:37:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5230
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:37:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5230 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 230
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5011
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:37:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5011 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 11
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5109
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:37:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5109 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 109
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5236
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:37:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5236 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 236
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5243
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:37:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5243 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 243
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5082
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:37:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5082 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 82
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:37:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5045
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:37:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5045 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 45
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:37:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5133
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:37:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5133 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 133
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:37:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5104
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:37:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5104 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 104
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5141
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:37:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5141 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 141
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139717086415520 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139717086415520 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139717086415520 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139717086415520 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139714662190112 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139714662190112 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139714662190112 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139714662190112 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[171] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4507042253521127, 'acc_stderr,none': 0.05947027187738001}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.891975958338049
0.3982001908036579
0.26652204443251004
0.14111026067874816
0.11763525057572936
0.8635004180455561
0.8741394655456793
0.5304527321557103
0.44617634270319845
0.7007455592903002
0.6799150362476898
0.3511365594568724
0.47145939463701925
0.4744673317050211
0.905435493752087
0.903612941640167
0.8893763849001028
0.6821933807976941
0.6796182015499347
0.7774502436639344
0.8164788896198145
0.9011095591650676
0.8564639597370403
0.9528866120532432
0.4784452972921274
0.48852492817861076
0.8397355586186119
0.7433051149723976
0.5457687574271932
0.891975958338049
0.3982001908036579
0.26652204443251004
0.14111026067874816
0.11763525057572936
0.8635004180455561
0.8741394655456793
0.5304527321557103
0.44617634270319845
0.7007455592903002
0.6799150362476898
0.3511365594568724
0.47145939463701925
0.4744673317050211
0.905435493752087
0.903612941640167
0.8893763849001028
0.6821933807976941
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[6, 5, 4, 3, 2, 1, 7, 0]
tensor([6, 5, 4, 3, 2, 1, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 7, 4, 1, 0, 6, 3]
tensor([5, 2, 7, 4, 1, 0, 6, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 6, 5, 2, 4, 0, 7, 1]
tensor([3, 6, 5, 2, 4, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 4, 6, 0, 2, 1, 7, 3]
tensor([5, 4, 6, 0, 2, 1, 7, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 0, 7, 3, 5, 1, 6, 2]
tensor([4, 0, 7, 3, 5, 1, 6, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 5, 1, 3, 2, 0, 1, 4]
tensor([0, 5, 1, 3, 2, 0, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[1, 0, 0, 1, 1.0, 1.0, 1.0, 1.0]
tensor([1, 0, 0, 1, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[1, 0, 1, 1.0, 1.0, 0, 1.0, 1.0]
tensor([1, 0, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[0, 1, 1.0, 1.0, 0, 1, 1.0, 1.0]
tensor([0, 1, 1, 1, 0, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/171.pt
[RECEIVE] Queued message from 171
[QUEUE] Processing info from 171
[QUEUE] Stored info from 171
[RECEIVE] Queued message from 171
[QUEUE] Processing info from 171
[QUEUE] Stored info from 171
[RECEIVE] Queued message from 171
[QUEUE] Processing info from 171
[QUEUE] Stored info from 171
[RECEIVE] Queued message from 171
[QUEUE] Processing info from 171
[QUEUE] Stored info from 171
[RECEIVE] Queued message from 171
[QUEUE] Processing info from 171
[QUEUE] Stored info from 171
[RECEIVE] Queued message from 171
[QUEUE] Processing info from 171
[QUEUE] Stored info from 171
[RECEIVE] Queued message from 171
[QUEUE] Processing info from 171
[QUEUE] Stored info from 171
[RECEIVE] Queued message from 171
[QUEUE] Processing info from 171
[QUEUE] Stored info from 171
[RECEIVE] Queued message from 171
[QUEUE] Processing info from 171
[QUEUE] Stored info from 171
[RECEIVE] Queued message from 171
[QUEUE] Processing info from 171
[QUEUE] Stored info from 171
[RECEIVE] Queued message from 171
[QUEUE] Processing info from 171
[QUEUE] Stored info from 171
[RECEIVE] Queued message from 171
[QUEUE] Processing info from 171
[QUEUE] Stored info from 171
[RECEIVE] Queued message from 171
[QUEUE] Processing info from 171
[QUEUE] Stored info from 171
[RECEIVE] Queued message from 171
[QUEUE] Processing info from 171
[QUEUE] Stored info from 171
[RECEIVE] Queued message from 171
[QUEUE] Processing info from 171
[QUEUE] Stored info from 171
[RECEIVE] Queued message from 171
[QUEUE] Processing info from 171
[QUEUE] Stored info from 171
[RECEIVE] Queued message from 171
[QUEUE] Processing info from 171
[QUEUE] Stored info from 171
[RECEIVE] Queued message from 171
[QUEUE] Processing info from 171
[QUEUE] Stored info from 171
[RECEIVE] Queued message from 171
[QUEUE] Processing info from 171
[QUEUE] Stored info from 171
[RECEIVE] Queued message from 171
[QUEUE] Processing info from 171
[QUEUE] Stored info from 171
[RECEIVE] Queued message from 171
[QUEUE] Processing info from 171
[QUEUE] Stored info from 171
[RECEIVE] Queued message from 171
[QUEUE] Processing info from 171
[QUEUE] Stored info from 171
[RECEIVE] Queued message from 171
[QUEUE] Processing info from 171
[QUEUE] Stored info from 171
[RECEIVE] Queued message from 171
[QUEUE] Processing info from 171
[QUEUE] Stored info from 171
[RECEIVE] Queued message from 171
[QUEUE] Processing info from 171
[QUEUE] Stored info from 171
[RECEIVE] Queued message from 171
[QUEUE] Processing info from 171
[QUEUE] Stored info from 171
[RECEIVE] Queued message from 171
[QUEUE] Processing info from 171
[QUEUE] Stored info from 171
[RECEIVE] Queued message from 171
[QUEUE] Processing info from 171
[QUEUE] Stored info from 171
[RECEIVE] Queued message from 171
[QUEUE] Processing info from 171
[QUEUE] Stored info from 171
[RECEIVE] Queued message from 171
[QUEUE] Processing info from 171
[QUEUE] Stored info from 171
[RECEIVE] Queued message from 171
[QUEUE] Processing info from 171
[QUEUE] Stored info from 171
[94] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2584.13it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:03<07:26,  3.17s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:05<03:38,  1.57s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:07<02:52,  1.26s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:09<02:31,  1.12s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:20,  1.06s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:13<02:20,  1.07s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:09,  1.01s/it]Running loglikelihood requests:  11%|█         | 15/142 [00:16<02:06,  1.01it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:18<01:57,  1.06it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:19<01:49,  1.12it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:21<01:43,  1.17it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:23<01:40,  1.18it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:24<01:36,  1.21it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:26<01:32,  1.24it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:27<01:28,  1.27it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:29<01:25,  1.30it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:30<01:22,  1.32it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:32<01:20,  1.33it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:33<01:20,  1.30it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:35<01:17,  1.33it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:36<01:14,  1.35it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:38<01:12,  1.36it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:39<01:10,  1.38it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:40<01:08,  1.39it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:42<01:05,  1.42it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:45<01:24,  1.08it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:46<01:15,  1.18it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:47<01:08,  1.26it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:49<01:03,  1.34it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:50<00:59,  1.39it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:51<00:56,  1.43it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:52<00:54,  1.46it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:54<00:54,  1.43it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:55<00:51,  1.46it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:57<00:49,  1.49it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:58<00:47,  1.51it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:59<00:45,  1.52it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [01:00<00:43,  1.53it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:02<00:42,  1.54it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:03<00:40,  1.56it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:04<00:40,  1.51it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:06<00:38,  1.53it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:07<00:36,  1.55it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:08<00:35,  1.57it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:09<00:33,  1.58it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:11<00:32,  1.59it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:12<00:30,  1.60it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:13<00:29,  1.61it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:14<00:29,  1.53it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:16<00:27,  1.56it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:17<00:25,  1.58it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:18<00:24,  1.60it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:19<00:22,  1.62it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:21<00:21,  1.63it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:22<00:20,  1.64it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:23<00:18,  1.65it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:24<00:18,  1.56it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:26<00:16,  1.61it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:29<00:24,  1.02it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:30<00:19,  1.16it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:32<00:16,  1.28it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:33<00:13,  1.38it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:34<00:12,  1.41it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:35<00:10,  1.48it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:36<00:08,  1.55it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:38<00:06,  1.61it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:39<00:05,  1.66it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:40<00:04,  1.71it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:41<00:02,  1.74it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:42<00:01,  1.77it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:43<00:00,  1.80it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:43<00:00,  1.37it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-3): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (4-8): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10-13): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (15-31): 17 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-3): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (4-8): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10-13): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (15-31): 17 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/94.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5171
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:39:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5171 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 171
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:39:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5236
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:39:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5236 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 236
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5243
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:39:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5243 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 243
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:39:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5006
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:39:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5006 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 6
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5027
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:39:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5027 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 27
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5242
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:39:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5242 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 242
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5029
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:39:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5029 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 29
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5230
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:39:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5230 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 230
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5205
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:39:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5205 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 205
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5004
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:39:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5004 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 4
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5060
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:39:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5060 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 60
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5082
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:39:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5082 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 82
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:39:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:39:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5133
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:39:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5133 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 133
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:39:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5141
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:39:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5141 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 141
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5011
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:39:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5011 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 11
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5026
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:39:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5026 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 26
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5045
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:39:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5045 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 45
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5013
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:39:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5013 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 13
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:39:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5044
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:39:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5044 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 44
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:39:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5104
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:39:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5104 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 104
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5206
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:39:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5206 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 206
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:39:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5109
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:39:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5109 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 109
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5080
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:39:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5080 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 80
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139714111625152 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139714111625152 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139714111625152 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139714111625152 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139714654097184 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139714654097184 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139714654097184 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139714654097184 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[94] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4507042253521127, 'acc_stderr,none': 0.05947027187738001}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.36326485003451675
0.9393611658494853
0.5347697273308267
0.4619639883096971
0.26830156279453604
0.8380027464731019
0.8263233574501603
0.6320977880109986
0.7843146415103402
0.2072713135482749
0.3805984042723936
0.43289830555723763
0.19273781754260347
0.8181624071033468
0.5320194969946469
0.7203219641552613
0.7789354624632999
0.3567665334531696
0.2604208944916411
0.942273921845013
0.8798126471295904
0.8327076147848976
0.5471221204152548
0.8016285641373796
0.8787721123612405
0.7314094662215913
0.733830137407364
0.7399689895148621
0.8815844426907766
0.36326485003451675
0.9393611658494853
0.5347697273308267
0.4619639883096971
0.26830156279453604
0.8380027464731019
0.8263233574501603
0.6320977880109986
0.7843146415103402
0.2072713135482749
0.3805984042723936
0.43289830555723763
0.19273781754260347
0.8181624071033468
0.5320194969946469
0.7203219641552613
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[1, 2, 5, 4, 3, 0, 7, 6]
tensor([1, 2, 5, 4, 3, 0, 7, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 3, 2, 6, 0, 1, 4, 7]
tensor([5, 3, 2, 6, 0, 1, 4, 7], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[1, 2, 6, 7, 4, 0, 3, 5]
tensor([1, 2, 6, 7, 4, 0, 3, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[1, 4, 5, 6, 2, 0, 7, 3]
tensor([1, 4, 5, 6, 2, 0, 7, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 5, 1, 0, 0, 2, 1, 3]
tensor([4, 5, 1, 0, 0, 2, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[1, 5, 0, 3, 4, 0, 1, 2]
tensor([1, 5, 0, 3, 4, 0, 1, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 1, 2, 0, 1, 3, 2]
tensor([0, 3, 1, 2, 0, 1, 3, 2], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1.0, 1, 0, 1.0, 1.0]
tensor([0, 1, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
Model saved locally at saved_models/94.pt
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[4] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2536.87it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:03<08:45,  3.73s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:05<03:53,  1.68s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:07<03:01,  1.32s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:09<02:38,  1.17s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:11<02:23,  1.08s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:13<02:18,  1.06s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:15<02:09,  1.01s/it]Running loglikelihood requests:  11%|█         | 15/142 [00:17<02:06,  1.00it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:18<01:58,  1.06it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:20<01:50,  1.12it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:22<01:43,  1.16it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:23<01:43,  1.15it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:25<01:37,  1.20it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:26<01:34,  1.22it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:28<01:30,  1.25it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:29<01:26,  1.28it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:31<01:23,  1.30it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:32<01:23,  1.29it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:34<01:20,  1.30it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:35<01:17,  1.32it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:37<01:15,  1.33it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:38<01:13,  1.34it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:40<01:10,  1.37it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:41<01:08,  1.39it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:42<01:05,  1.42it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:44<01:06,  1.37it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:45<01:03,  1.41it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:47<01:00,  1.43it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:48<00:58,  1.45it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:49<00:57,  1.45it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:51<00:55,  1.47it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:52<00:53,  1.49it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:54<00:57,  1.33it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:55<00:53,  1.40it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:56<00:50,  1.44it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:58<00:47,  1.48it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:59<00:45,  1.52it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [01:00<00:43,  1.54it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:01<00:41,  1.56it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:03<00:39,  1.58it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:04<00:42,  1.45it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:06<00:39,  1.49it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:07<00:37,  1.53it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:08<00:35,  1.56it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:09<00:33,  1.59it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:10<00:31,  1.61it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:12<00:30,  1.63it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:13<00:28,  1.64it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:14<00:28,  1.57it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:15<00:26,  1.61it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:17<00:25,  1.63it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:18<00:23,  1.65it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:19<00:22,  1.66it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:20<00:20,  1.68it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:21<00:19,  1.69it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:22<00:18,  1.69it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:24<00:17,  1.62it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:25<00:16,  1.64it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:26<00:15,  1.65it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:27<00:13,  1.66it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:29<00:13,  1.54it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:30<00:11,  1.59it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:31<00:10,  1.64it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:32<00:08,  1.68it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:33<00:07,  1.71it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:35<00:07,  1.56it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:36<00:05,  1.63it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:37<00:04,  1.67it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:38<00:02,  1.71it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:39<00:01,  1.73it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:40<00:00,  1.77it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:40<00:00,  1.41it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-31): 26 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-31): 26 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/4.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5171
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:41:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5171 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 171
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5243
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:41:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5243 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 243
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5109
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:41:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5109 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 109
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5060
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:41:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5060 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 60
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5027
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:41:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5027 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 27
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5230
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:41:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5230 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 230
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5029
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:41:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5029 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 29
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:41:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5206
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:41:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5206 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 206
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5104
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:41:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5104 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 104
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:41:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5236
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:41:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5236 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 236
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:41:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:41:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5242
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:41:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5242 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 242
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5026
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:41:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5026 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 26
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5133
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:41:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5133 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 133
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:41:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:41:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5045
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:41:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5045 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 45
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:41:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5006
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:41:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5006 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 6
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5082
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:41:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5082 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 82
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5011
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:41:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5011 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 11
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5044
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:41:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5044 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 44
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:41:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:41:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5080
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:41:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5080 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 80
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5205
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:41:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5205 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 205
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5141
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:41:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5141 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 141
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5013
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:41:30] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5013 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 13
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139720653494736 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139720653494736 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139720653494736 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139720653494736 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139722764816352 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139722764816352 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139722764816352 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139722764816352 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[4] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4225352112676056, 'acc_stderr,none': 0.059039842056825796}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9416968404415913
0.7938815868474761
0.8191819727516524
0.8917669687772857
0.90570342985793
0.3043907333176312
0.4952220736758006
0.29899990072660143
0.7758711420345523
0.838301482150715
0.8086122742620726
0.9126741954079025
0.6304407611776705
0.6595297618724628
0.176689009460142
0.4424440684940646
0.43152501031897406
0.48316840881543294
0.43857258209632005
0.7021905687600761
0.2402003641072479
0.27348823957209967
0.6649171314730306
0.25117416182112623
0.9114030338716436
0.9328254651349717
0.9096786197852272
0.9107213191843687
0.8764776988845487
0.9416968404415913
0.7938815868474761
0.8191819727516524
0.8917669687772857
0.90570342985793
0.3043907333176312
0.4952220736758006
0.29899990072660143
0.7758711420345523
0.838301482150715
0.8086122742620726
0.9126741954079025
0.6304407611776705
0.6595297618724628
0.176689009460142
0.4424440684940646
0.43152501031897406
Total groups 76 exceeded the threshold, stopping comparison.
The group tensor is
[4, 3, 7, 2, 5, 1, 6, 0]
tensor([4, 3, 7, 2, 5, 1, 6, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 5, 7, 4, 3, 0, 6, 1]
tensor([2, 5, 7, 4, 3, 0, 6, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 5, 4, 0, 1, 1, 2]
tensor([0, 3, 5, 4, 0, 1, 1, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[4, 3, 0, 2, 5, 0, 1, 1]
tensor([4, 3, 0, 2, 5, 0, 1, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 0, 5, 1, 4, 2, 1, 3]
tensor([0, 0, 5, 1, 4, 2, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[3, 4, 0, 1, 2, 0, 5, 1]
tensor([3, 4, 0, 1, 2, 0, 5, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[5, 0, 4, 3, 2, 0, 1, 1]
tensor([5, 0, 4, 3, 2, 0, 1, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 3, 4, 0, 1, 2, 1, 5]
tensor([0, 3, 4, 0, 1, 2, 1, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/4.pt
[RECEIVE] Queued message from 4
[QUEUE] Processing info from 4
[QUEUE] Stored info from 4
[RECEIVE] Queued message from 4
[QUEUE] Processing info from 4
[QUEUE] Stored info from 4
[RECEIVE] Queued message from 4
[QUEUE] Processing info from 4
[QUEUE] Stored info from 4
[RECEIVE] Queued message from 4
[QUEUE] Processing info from 4
[QUEUE] Stored info from 4
[RECEIVE] Queued message from 4
[QUEUE] Processing info from 4
[QUEUE] Stored info from 4
[RECEIVE] Queued message from 4
[QUEUE] Processing info from 4
[QUEUE] Stored info from 4
[RECEIVE] Queued message from 4
[QUEUE] Processing info from 4
[QUEUE] Stored info from 4
[RECEIVE] Queued message from 4
[QUEUE] Processing info from 4
[QUEUE] Stored info from 4
[RECEIVE] Queued message from 4
[QUEUE] Processing info from 4
[QUEUE] Stored info from 4
[RECEIVE] Queued message from 4
[QUEUE] Processing info from 4
[QUEUE] Stored info from 4
[RECEIVE] Queued message from 4
[QUEUE] Processing info from 4
[QUEUE] Stored info from 4
[RECEIVE] Queued message from 4
[QUEUE] Processing info from 4
[QUEUE] Stored info from 4
[RECEIVE] Queued message from 4
[QUEUE] Processing info from 4
[QUEUE] Stored info from 4
[RECEIVE] Queued message from 4
[QUEUE] Processing info from 4
[QUEUE] Stored info from 4
[RECEIVE] Queued message from 4
[QUEUE] Processing info from 4
[QUEUE] Stored info from 4
[RECEIVE] Queued message from 4
[QUEUE] Processing info from 4
[QUEUE] Stored info from 4
[RECEIVE] Queued message from 4
[QUEUE] Processing info from 4
[QUEUE] Stored info from 4
[RECEIVE] Queued message from 4
[QUEUE] Processing info from 4
[QUEUE] Stored info from 4
[RECEIVE] Queued message from 4
[QUEUE] Processing info from 4
[QUEUE] Stored info from 4
[RECEIVE] Queued message from 4
[QUEUE] Processing info from 4
[QUEUE] Stored info from 4
[RECEIVE] Queued message from 4
[QUEUE] Processing info from 4
[QUEUE] Stored info from 4
[RECEIVE] Queued message from 4
[QUEUE] Processing info from 4
[QUEUE] Stored info from 4
[RECEIVE] Queued message from 4
[QUEUE] Processing info from 4
[QUEUE] Stored info from 4
[RECEIVE] Queued message from 4
[QUEUE] Processing info from 4
[QUEUE] Stored info from 4
[RECEIVE] Queued message from 4
[QUEUE] Processing info from 4
[QUEUE] Stored info from 4
[RECEIVE] Queued message from 4
[QUEUE] Processing info from 4
[QUEUE] Stored info from 4
[RECEIVE] Queued message from 4
[QUEUE] Processing info from 4
[QUEUE] Stored info from 4
[RECEIVE] Queued message from 4
[QUEUE] Processing info from 4
[QUEUE] Stored info from 4
[RECEIVE] Queued message from 4
[QUEUE] Processing info from 4
[QUEUE] Stored info from 4
[RECEIVE] Queued message from 4
[QUEUE] Processing info from 4
[QUEUE] Stored info from 4
[RECEIVE] Queued message from 4
[QUEUE] Processing info from 4
[QUEUE] Stored info from 4
[161] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2536.68it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:28,  2.76s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:18,  1.43s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:45,  1.21s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:28,  1.10s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:22,  1.07s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:13,  1.02s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:05,  1.03it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:15<01:59,  1.07it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:17<01:52,  1.11it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:19<01:56,  1.05it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:21<01:48,  1.12it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:22<01:40,  1.18it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:24<01:35,  1.23it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:25<01:32,  1.25it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:27<01:27,  1.29it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:31<02:09,  1.17s/it]Running loglikelihood requests:  23%|██▎       | 33/142 [00:32<01:53,  1.04s/it]Running loglikelihood requests:  25%|██▍       | 35/142 [00:34<01:41,  1.06it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:35<01:32,  1.14it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:37<01:25,  1.21it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:38<01:20,  1.26it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:40<01:18,  1.25it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:41<01:13,  1.31it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:42<01:09,  1.36it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:44<01:06,  1.41it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:45<01:02,  1.45it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:46<01:00,  1.47it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:48<00:58,  1.50it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:49<00:56,  1.52it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:50<00:57,  1.45it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:52<00:54,  1.48it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:53<00:52,  1.51it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:54<00:50,  1.52it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:55<00:48,  1.54it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:57<00:46,  1.55it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:58<00:45,  1.55it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:59<00:45,  1.51it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [01:01<00:43,  1.54it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:02<00:41,  1.56it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:03<00:39,  1.58it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:04<00:38,  1.59it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:06<00:36,  1.60it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:07<00:35,  1.61it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:08<00:33,  1.63it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:09<00:32,  1.63it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:13<00:52,  1.03s/it]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:14<00:44,  1.11it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:16<00:37,  1.24it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:17<00:33,  1.34it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:18<00:30,  1.43it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:19<00:27,  1.50it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:21<00:25,  1.51it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:22<00:23,  1.56it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:23<00:21,  1.59it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:24<00:20,  1.62it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:25<00:18,  1.64it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:26<00:17,  1.66it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:28<00:16,  1.66it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:29<00:15,  1.66it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:31<00:18,  1.27it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:32<00:15,  1.38it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:34<00:12,  1.49it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:35<00:10,  1.57it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:36<00:09,  1.64it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:37<00:07,  1.69it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:38<00:06,  1.73it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:39<00:05,  1.77it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:40<00:03,  1.78it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:41<00:02,  1.71it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:42<00:01,  1.75it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:44<00:00,  1.79it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:44<00:00,  1.37it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-31): 26 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-31): 26 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/161.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:43:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5109
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:43:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5109 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 109
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:43:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:43:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:43:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5029
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:43:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5029 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 29
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5013
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:43:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5013 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 13
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5133
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:43:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5133 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 133
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:43:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5080
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:43:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5080 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 80
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5242
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:43:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5242 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 242
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5060
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:43:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5060 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 60
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:43:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5006
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:43:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5006 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 6
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5230
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:43:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5230 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 230
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5236
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:43:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5236 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 236
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5104
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:43:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5104 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 104
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:43:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5141
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:43:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5141 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 141
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5206
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:43:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5206 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 206
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5045
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:43:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5045 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 45
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5243
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:43:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5243 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 243
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:43:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5026
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:43:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5026 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 26
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5011
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:43:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5011 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 11
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5027
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:43:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5027 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 27
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5205
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:43:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5205 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 205
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5171
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:43:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5171 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 171
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5044
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:43:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5044 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 44
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5004
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:43:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5004 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 4
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5082
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:43:29] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5082 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 82
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139720638097952 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139720638097952 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139720638097952 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139720638097952 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139720638516784 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139720638516784 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139720638516784 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139720638516784 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[161] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4084507042253521, 'acc_stderr,none': 0.058751136942575236}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8470147925890528
0.7476864669376683
0.7057458194715966
0.9259961826035564
0.9063486644110201
0.24963708122926456
0.19827660218091203
0.8342224461031358
0.674768686362321
0.8317740713616216
0.8052770539851904
0.87411142785436
0.9423251627051763
0.6325449231299249
0.5709019604280002
0.492272078021527
0.5470094105753499
0.8106788106419917
0.8007286389438932
0.8514363351777328
0.5678533410855942
0.6964663000476322
0.43791892189616227
0.24333097709743945
0.6773756911035087
0.7468917488225975
0.9536421875896308
0.6970547096788922
0.8446279043078407
0.8470147925890528
0.7476864669376683
0.7057458194715966
0.9259961826035564
0.9063486644110201
0.24963708122926456
0.19827660218091203
0.8342224461031358
0.674768686362321
0.8317740713616216
0.8052770539851904
0.87411142785436
0.9423251627051763
0.6325449231299249
0.5709019604280002
0.492272078021527
Total groups 76 exceeded the threshold, stopping comparison.
The group tensor is
[3, 4, 6, 5, 2, 0, 7, 1]
tensor([3, 4, 6, 5, 2, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 4, 6, 5, 3, 0, 7, 1]
tensor([2, 4, 6, 5, 3, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[6, 3, 4, 5, 2, 0, 7, 1]
tensor([6, 3, 4, 5, 2, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[1, 4, 7, 2, 5, 0, 6, 3]
tensor([1, 4, 7, 2, 5, 0, 6, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[0, 3, 5, 2, 0, 1, 1, 4]
tensor([0, 3, 5, 2, 0, 1, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[4, 3, 0, 5, 2, 0, 1, 1]
tensor([4, 3, 0, 5, 2, 0, 1, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 3, 5, 1, 4, 0, 1, 2]
tensor([0, 3, 5, 1, 4, 0, 1, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1, 0, 1.0, 1.0, 1.0]
tensor([0, 1, 1, 1, 0, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/161.pt
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[230] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2577.69it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:03<07:08,  3.04s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:30,  1.51s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:49,  1.24s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:31,  1.12s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:20,  1.06s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:17,  1.05s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:09,  1.00s/it]Running loglikelihood requests:  11%|█         | 15/142 [00:16<02:01,  1.04it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:18<01:55,  1.08it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:19<01:48,  1.13it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:21<01:55,  1.05it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:23<01:47,  1.11it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:24<01:39,  1.17it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:27<01:48,  1.06it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:28<01:39,  1.13it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:30<01:33,  1.19it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:32<01:36,  1.13it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:33<01:30,  1.18it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:37<02:07,  1.22s/it]Running loglikelihood requests:  27%|██▋       | 39/142 [00:39<01:50,  1.07s/it]Running loglikelihood requests:  29%|██▉       | 41/142 [00:40<01:38,  1.02it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:42<01:31,  1.08it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:43<01:23,  1.16it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:45<01:17,  1.23it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:46<01:12,  1.29it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:48<01:08,  1.34it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:49<01:04,  1.37it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:50<01:02,  1.40it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:52<01:03,  1.34it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:53<00:59,  1.39it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:55<00:57,  1.42it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:56<00:54,  1.44it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:57<00:52,  1.46it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:59<00:50,  1.48it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [01:00<00:48,  1.49it/s]Running loglikelihood requests:  50%|█████     | 71/142 [01:01<00:47,  1.50it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [01:06<01:21,  1.18s/it]Running loglikelihood requests:  53%|█████▎    | 75/142 [01:07<01:08,  1.02s/it]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:09<00:58,  1.10it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:10<00:52,  1.21it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:11<00:47,  1.29it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:13<00:45,  1.31it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:14<00:41,  1.38it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:15<00:38,  1.44it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:16<00:35,  1.48it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:18<00:33,  1.51it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:19<00:31,  1.53it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:20<00:30,  1.56it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:21<00:28,  1.57it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:25<00:44,  1.04s/it]Running loglikelihood requests:  71%|███████   | 101/142 [01:27<00:38,  1.07it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:30<00:43,  1.13s/it]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:31<00:36,  1.03it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:32<00:30,  1.13it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:34<00:26,  1.24it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:35<00:23,  1.34it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:36<00:20,  1.42it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:37<00:18,  1.45it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:39<00:16,  1.50it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:40<00:14,  1.54it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:41<00:13,  1.57it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:42<00:11,  1.60it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:44<00:10,  1.55it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:45<00:09,  1.58it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:46<00:08,  1.59it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:47<00:06,  1.62it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:48<00:05,  1.65it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:50<00:04,  1.68it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:51<00:02,  1.71it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:52<00:01,  1.72it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:54<00:00,  1.52it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:54<00:00,  1.25it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-16): 12 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (17-18): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (19): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (20-31): 12 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-16): 12 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (17-18): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (19): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (20-31): 12 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/230.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:45:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:45:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5026
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:45:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5026 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 26
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5206
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:45:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5206 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 206
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5044
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:45:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5044 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 44
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5045
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:45:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5045 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 45
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5242
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:45:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5242 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 242
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:45:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5060
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:45:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5060 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 60
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5205
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:45:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5205 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 205
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5080
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:45:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5080 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 80
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5104
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:45:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5104 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 104
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5243
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:45:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5243 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 243
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5171
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:45:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5171 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 171
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:45:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:45:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5011
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:45:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5011 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 11
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5027
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:45:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5027 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 27
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5141
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:45:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5141 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 141
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:45:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5029
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:45:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5029 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 29
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5013
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:45:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5013 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 13
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:45:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5004
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:45:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5004 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 4
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5006
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:45:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5006 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 6
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:45:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5082
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:45:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5082 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 82
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5109
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:45:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5109 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 109
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:45:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5236
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:45:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5236 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 236
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5133
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:45:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5133 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 133
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139714111679152 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139714111679152 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139714111679152 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139714111679152 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139714890688480 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139714890688480 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139714890688480 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139714890688480 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[230] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4507042253521127, 'acc_stderr,none': 0.05947027187738001}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.5492204626454702
0.13502488496756465
0.9275303495607449
0.7165821511880784
0.7594126839120312
0.8664668964215797
0.7349473681509868
0.7930425076096883
0.8162917298680349
0.8517270618457119
0.5861829129308435
0.5835405684895388
0.588879417394676
0.5205548377189629
0.7140538082286251
0.531207880500868
0.8809821166189434
0.6995488915401884
0.4683250920235365
0.5868402787291006
0.7967272991738612
0.8359030243014328
0.776130470073111
0.7836617242516619
0.8225513545207798
0.7161038509602672
0.7843138704646394
0.6004827793986917
0.8596931332130378
0.5492204626454702
0.13502488496756465
0.9275303495607449
0.7165821511880784
0.7594126839120312
0.8664668964215797
0.7349473681509868
0.7930425076096883
0.8162917298680349
0.8517270618457119
0.5861829129308435
0.5835405684895388
0.588879417394676
0.5205548377189629
0.7140538082286251
0.531207880500868
0.8809821166189434
0.6995488915401884
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[2, 4, 6, 3, 5, 0, 7, 1]
tensor([2, 4, 6, 3, 5, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 2, 0, 5, 3, 1, 6, 7]
tensor([4, 2, 0, 5, 3, 1, 6, 7], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 3, 6, 2, 4, 0, 7, 1]
tensor([5, 3, 6, 2, 4, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 1, 6, 4, 2, 0, 5, 3]
tensor([7, 1, 6, 4, 2, 0, 5, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 5, 1, 2, 3, 0, 1, 4]
tensor([0, 5, 1, 2, 3, 0, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[3, 0, 2, 5, 4, 1, 1, 0]
tensor([3, 0, 2, 5, 4, 1, 1, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 1, 4, 5, 2, 0, 1, 3]
tensor([0, 1, 4, 5, 2, 0, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/230.pt
[RECEIVE] Queued message from 230
[QUEUE] Processing info from 230
[QUEUE] Stored info from 230
[RECEIVE] Queued message from 230
[QUEUE] Processing info from 230
[QUEUE] Stored info from 230
[RECEIVE] Queued message from 230
[QUEUE] Processing info from 230
[QUEUE] Stored info from 230
[RECEIVE] Queued message from 230
[QUEUE] Processing info from 230
[QUEUE] Stored info from 230
[RECEIVE] Queued message from 230
[QUEUE] Processing info from 230
[QUEUE] Stored info from 230
[RECEIVE] Queued message from 230
[QUEUE] Processing info from 230
[QUEUE] Stored info from 230
[RECEIVE] Queued message from 230
[QUEUE] Processing info from 230
[QUEUE] Stored info from 230
[RECEIVE] Queued message from 230
[QUEUE] Processing info from 230
[QUEUE] Stored info from 230
[RECEIVE] Queued message from 230
[QUEUE] Processing info from 230
[QUEUE] Stored info from 230
[RECEIVE] Queued message from 230
[QUEUE] Processing info from 230
[QUEUE] Stored info from 230
[RECEIVE] Queued message from 230
[QUEUE] Processing info from 230
[QUEUE] Stored info from 230
[RECEIVE] Queued message from 230
[QUEUE] Processing info from 230
[QUEUE] Stored info from 230
[RECEIVE] Queued message from 230
[QUEUE] Processing info from 230
[QUEUE] Stored info from 230
[RECEIVE] Queued message from 230
[QUEUE] Processing info from 230
[QUEUE] Stored info from 230
[RECEIVE] Queued message from 230
[QUEUE] Processing info from 230
[QUEUE] Stored info from 230
[RECEIVE] Queued message from 230
[QUEUE] Processing info from 230
[QUEUE] Stored info from 230
[RECEIVE] Queued message from 230
[QUEUE] Processing info from 230
[QUEUE] Stored info from 230
[RECEIVE] Queued message from 230
[QUEUE] Processing info from 230
[QUEUE] Stored info from 230
[RECEIVE] Queued message from 230
[QUEUE] Processing info from 230
[QUEUE] Stored info from 230
[RECEIVE] Queued message from 230
[QUEUE] Processing info from 230
[QUEUE] Stored info from 230
[RECEIVE] Queued message from 230
[QUEUE] Processing info from 230
[QUEUE] Stored info from 230
[RECEIVE] Queued message from 230
[QUEUE] Processing info from 230
[QUEUE] Stored info from 230
[RECEIVE] Queued message from 230
[QUEUE] Processing info from 230
[QUEUE] Stored info from 230
[RECEIVE] Queued message from 230
[QUEUE] Processing info from 230
[QUEUE] Stored info from 230
[RECEIVE] Queued message from 230
[QUEUE] Processing info from 230
[QUEUE] Stored info from 230
[RECEIVE] Queued message from 230
[QUEUE] Processing info from 230
[QUEUE] Stored info from 230
[RECEIVE] Queued message from 230
[QUEUE] Processing info from 230
[QUEUE] Stored info from 230
[RECEIVE] Queued message from 230
[QUEUE] Processing info from 230
[QUEUE] Stored info from 230
[RECEIVE] Queued message from 230
[QUEUE] Processing info from 230
[QUEUE] Stored info from 230
[RECEIVE] Queued message from 230
[QUEUE] Processing info from 230
[QUEUE] Stored info from 230
[RECEIVE] Queued message from 230
[QUEUE] Processing info from 230
[QUEUE] Stored info from 230
[64] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 1397.47it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:41,  2.84s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:23,  1.46s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:45,  1.21s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:28,  1.10s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:18,  1.04s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:11,  1.00s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:13,  1.03s/it]Running loglikelihood requests:  11%|█         | 15/142 [00:16<02:04,  1.02it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:18<02:00,  1.03it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:19<01:52,  1.10it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:21<01:45,  1.15it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:22<01:39,  1.20it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:24<01:39,  1.18it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:26<01:33,  1.22it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:27<01:29,  1.26it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:29<01:26,  1.29it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:30<01:23,  1.30it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:32<01:21,  1.32it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:33<01:21,  1.28it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:35<01:18,  1.31it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:36<01:16,  1.33it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:38<01:13,  1.35it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:39<01:10,  1.38it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:40<01:07,  1.40it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:42<01:04,  1.43it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:43<01:04,  1.42it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:44<01:01,  1.45it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:46<00:59,  1.47it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:47<00:56,  1.49it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:48<00:54,  1.51it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:50<00:53,  1.52it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:51<00:51,  1.54it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:52<00:49,  1.55it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:54<00:50,  1.47it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:55<00:48,  1.50it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:56<00:46,  1.52it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:57<00:44,  1.54it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [00:59<00:43,  1.55it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:00<00:41,  1.56it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:01<00:39,  1.58it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:02<00:38,  1.59it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:04<00:40,  1.45it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:05<00:38,  1.50it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:07<00:35,  1.53it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:08<00:34,  1.55it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:09<00:32,  1.57it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:10<00:31,  1.58it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:12<00:29,  1.58it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:13<00:27,  1.61it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:14<00:27,  1.57it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:15<00:25,  1.60it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:16<00:23,  1.63it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:18<00:22,  1.65it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:19<00:20,  1.67it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:20<00:19,  1.68it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:22<00:23,  1.34it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:23<00:20,  1.44it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:26<00:25,  1.07it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:27<00:20,  1.21it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:29<00:17,  1.33it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:30<00:14,  1.43it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:31<00:12,  1.51it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:32<00:10,  1.58it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:33<00:09,  1.63it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:34<00:08,  1.60it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:36<00:06,  1.66it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:37<00:05,  1.71it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:38<00:04,  1.75it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:39<00:02,  1.78it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:40<00:01,  1.81it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:41<00:00,  1.84it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:41<00:00,  1.40it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-3): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (4-5): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (7-9): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (11-26): 16 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (27): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (28-30): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (31): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-3): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (4-5): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (7-9): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (11-26): 16 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (27): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (28-30): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (31): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/64.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:47:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5006
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:47:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5006 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 6
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:47:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5060
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:47:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5060 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 60
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:47:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5133
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:47:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5133 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 133
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5243
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:47:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5243 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 243
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5013
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:47:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5013 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 13
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5236
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:47:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5236 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 236
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5104
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:47:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5104 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 104
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5141
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:47:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5141 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 141
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5026
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:47:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5026 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 26
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:47:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5044
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:47:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5044 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 44
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5242
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:47:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5242 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 242
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:47:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5080
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:47:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5080 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 80
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:47:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5045
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:47:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5045 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 45
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5206
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:47:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5206 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 206
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5171
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:47:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5171 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 171
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5082
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:47:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5082 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 82
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5109
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:47:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5109 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 109
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5029
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:47:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5029 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 29
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5004
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:47:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5004 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 4
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5011
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:47:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5011 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 11
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5205
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:47:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5205 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 205
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:47:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:47:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5027
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:47:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5027 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 27
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5230
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:47:38] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5230 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 230
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139714107068624 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139714107068624 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139714107068624 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139714107068624 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139721059548624 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139721059548624 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139721059548624 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139721059548624 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[64] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4225352112676056, 'acc_stderr,none': 0.059039842056825796}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.7169249479288816
0.6183111372245332
0.46095560668163316
0.45412629074361927
0.5961385422474115
0.8890533054728373
0.9122749865545955
0.7722412965326397
0.28598717020359266
0.16135518374824295
0.6405733513488978
0.34881239744915987
0.02163114281968652
0.8586809120820075
0.5280864903169471
0.5549214872848108
0.8809884720847853
0.8184475126773784
0.7411818478320343
0.9204128494945557
0.8828541622108917
0.8520796846320295
0.9938665155729866
0.8532228506983649
0.8363754351071634
0.7452449391867536
0.8461045724576085
0.3693743162395131
0.3582309316878524
0.7169249479288816
0.6183111372245332
0.46095560668163316
0.45412629074361927
0.5961385422474115
0.8890533054728373
0.9122749865545955
0.7722412965326397
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[5, 4, 6, 3, 2, 0, 7, 1]
tensor([5, 4, 6, 3, 2, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 7, 2, 4, 0, 5, 3]
tensor([6, 1, 7, 2, 4, 0, 5, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 4, 6, 3, 1, 0, 7, 5]
tensor([2, 4, 6, 3, 1, 0, 7, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 0, 6, 4, 3, 1, 5, 7]
tensor([2, 0, 6, 4, 3, 1, 5, 7], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[3, 1, 0, 1, 2, 0, 2, 3]
tensor([3, 1, 0, 1, 2, 0, 2, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 2, 1, 0, 2, 3, 3]
tensor([0, 1, 2, 1, 0, 2, 3, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[3, 1, 0, 1, 2, 0, 3, 2]
tensor([3, 1, 0, 1, 2, 0, 3, 2], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 1, 2, 2, 3, 0, 3, 1]
tensor([0, 1, 2, 2, 3, 0, 3, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[3, 0, 1, 2, 1, 2, 3, 0]
tensor([3, 0, 1, 2, 1, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/64.pt
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[RECEIVE] Queued message from 64
[QUEUE] Processing info from 64
[QUEUE] Stored info from 64
[27] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2553.34it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:35,  2.81s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:21,  1.45s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:44,  1.20s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:32,  1.13s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:22,  1.07s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:13,  1.02s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:06,  1.02it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:16<02:00,  1.06it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:17<01:55,  1.08it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [01:36<26:28, 12.92s/it]Running loglikelihood requests:  15%|█▍        | 21/142 [02:06<27:04, 13.42s/it]Running loglikelihood requests:  16%|█▌        | 23/142 [02:07<18:58,  9.57s/it]Running loglikelihood requests:  18%|█▊        | 25/142 [02:09<13:26,  6.89s/it]Running loglikelihood requests:  19%|█▉        | 27/142 [02:10<09:44,  5.08s/it]Running loglikelihood requests:  20%|██        | 29/142 [02:12<07:05,  3.77s/it]Running loglikelihood requests:  22%|██▏       | 31/142 [02:13<05:17,  2.86s/it]Running loglikelihood requests:  23%|██▎       | 33/142 [02:15<04:11,  2.31s/it]Running loglikelihood requests:  25%|██▍       | 35/142 [02:17<03:17,  1.84s/it]Running loglikelihood requests:  26%|██▌       | 37/142 [02:18<02:38,  1.51s/it]Running loglikelihood requests:  27%|██▋       | 39/142 [02:20<02:12,  1.28s/it]Running loglikelihood requests:  29%|██▉       | 41/142 [02:22<01:56,  1.15s/it]Running loglikelihood requests:  30%|███       | 43/142 [02:23<01:41,  1.03s/it]Running loglikelihood requests:  32%|███▏      | 45/142 [02:25<01:29,  1.08it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [02:26<01:21,  1.16it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [02:27<01:14,  1.24it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [02:29<01:09,  1.31it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [02:32<01:28,  1.01it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [02:33<01:18,  1.11it/s]Running loglikelihood requests:  40%|████      | 57/142 [02:34<01:10,  1.21it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [02:36<01:04,  1.28it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [02:37<01:00,  1.35it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [02:38<00:56,  1.39it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [02:40<00:53,  1.43it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [02:41<00:55,  1.36it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [02:43<00:51,  1.41it/s]Running loglikelihood requests:  50%|█████     | 71/142 [02:44<00:51,  1.37it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [02:45<00:48,  1.43it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [02:47<00:45,  1.47it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [02:48<00:43,  1.50it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [02:49<00:41,  1.53it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [02:50<00:39,  1.54it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [02:52<00:44,  1.33it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [02:54<00:40,  1.40it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [02:55<00:37,  1.47it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [02:56<00:34,  1.52it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [02:57<00:32,  1.55it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [02:59<00:31,  1.58it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [03:00<00:29,  1.60it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [03:01<00:29,  1.53it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [03:02<00:27,  1.57it/s]Running loglikelihood requests:  71%|███████   | 101/142 [03:04<00:25,  1.60it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [03:05<00:23,  1.63it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [03:06<00:22,  1.65it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [03:07<00:21,  1.66it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [03:08<00:19,  1.66it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [03:09<00:18,  1.68it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [03:11<00:17,  1.69it/s]Running loglikelihood requests:  81%|████████  | 115/142 [03:12<00:16,  1.64it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [03:13<00:15,  1.66it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [03:14<00:13,  1.67it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [03:16<00:12,  1.65it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [03:17<00:11,  1.66it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [03:18<00:10,  1.67it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [03:23<00:17,  1.17s/it]Running loglikelihood requests:  91%|█████████ | 129/142 [03:24<00:13,  1.00s/it]Running loglikelihood requests:  92%|█████████▏| 131/142 [03:25<00:09,  1.15it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [03:26<00:07,  1.28it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [03:28<00:04,  1.41it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [03:29<00:03,  1.51it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [03:30<00:01,  1.59it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [03:31<00:00,  1.66it/s]Running loglikelihood requests: 100%|██████████| 142/142 [03:31<00:00,  1.49s/it]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-8): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10-30): 21 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (31): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-8): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10-30): 21 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (31): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/27.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5004
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:51:27] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5004 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 4
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5026
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:51:27] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5026 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 26
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:51:27] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:51:27] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5082
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:51:27] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5082 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 82
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5029
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:51:27] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5029 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 29
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:51:27] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5141
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:51:27] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5141 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 141
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5060
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:51:27] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5060 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 60
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5109
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:51:27] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5109 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 109
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:51:27] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5243
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:51:27] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5243 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 243
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:51:27] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:51:27] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5045
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:51:27] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5045 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 45
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5206
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:51:27] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5206 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 206
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5013
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:51:27] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5013 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 13
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:51:27] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5006
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:51:27] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5006 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 6
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5104
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:51:27] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5104 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 104
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5236
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:51:27] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5236 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 236
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5011
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:51:27] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5011 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 11
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5242
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:51:27] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5242 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 242
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5171
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:51:27] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5171 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 171
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5080
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:51:27] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5080 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 80
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5044
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:51:27] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5044 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 44
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5205
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:51:27] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5205 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 205
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:51:27] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5230
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:51:27] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5230 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 230
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5133
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:51:27] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5133 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 133
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:51:27] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 139717086421088 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139717086421088 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139717086421088 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 139717086421088 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 139714113326784 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139714113326784 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 139714113326784 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 139714113326784 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[27] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4507042253521127, 'acc_stderr,none': 0.05947027187738001}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.891975958338049
0.3982001908036579
0.26652204443251004
0.14111026067874816
0.11763525057572936
0.8635004180455561
0.8741394655456793
0.5304527321557103
0.44617634270319845
0.7007455592903002
0.6799150362476898
0.3511365594568724
0.47145939463701925
0.4744673317050211
0.905435493752087
0.903612941640167
0.8893763849001028
0.6821933807976941
0.6796182015499347
0.7774502436639344
0.8164788896198145
0.9011095591650676
0.8564639597370403
0.9528866120532432
0.4784452972921274
0.48852492817861076
0.8397355586186119
0.7433051149723976
0.5457687574271932
0.891975958338049
0.3982001908036579
0.26652204443251004
0.14111026067874816
0.11763525057572936
0.8635004180455561
0.8741394655456793
0.5304527321557103
0.44617634270319845
0.7007455592903002
0.6799150362476898
0.3511365594568724
0.47145939463701925
0.4744673317050211
0.905435493752087
0.903612941640167
0.8893763849001028
0.6821933807976941
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[6, 5, 4, 3, 2, 1, 7, 0]
tensor([6, 5, 4, 3, 2, 1, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 7, 4, 1, 0, 6, 3]
tensor([5, 2, 7, 4, 1, 0, 6, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 6, 5, 2, 4, 0, 7, 1]
tensor([3, 6, 5, 2, 4, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 4, 6, 0, 2, 1, 7, 3]
tensor([5, 4, 6, 0, 2, 1, 7, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 0, 7, 3, 5, 1, 6, 2]
tensor([4, 0, 7, 3, 5, 1, 6, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 5, 1, 3, 2, 0, 1, 4]
tensor([0, 5, 1, 3, 2, 0, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[1, 0, 0, 1, 1.0, 1.0, 1.0, 1.0]
tensor([1, 0, 0, 1, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[1, 0, 1, 1.0, 1.0, 0, 1.0, 1.0]
tensor([1, 0, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[0, 1, 1.0, 1.0, 0, 1, 1.0, 1.0]
tensor([0, 1, 1, 1, 0, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/27.pt
[RECEIVE] Queued message from 27
[QUEUE] Processing info from 27
[QUEUE] Stored info from 27
[RECEIVE] Queued message from 27
[QUEUE] Processing info from 27
[QUEUE] Stored info from 27
[RECEIVE] Queued message from 27
[QUEUE] Processing info from 27
[QUEUE] Stored info from 27
[RECEIVE] Queued message from 27
[QUEUE] Processing info from 27
[QUEUE] Stored info from 27
[RECEIVE] Queued message from 27
[QUEUE] Processing info from 27
[QUEUE] Stored info from 27
[RECEIVE] Queued message from 27
[QUEUE] Processing info from 27
[QUEUE] Stored info from 27
[RECEIVE] Queued message from 27
[QUEUE] Processing info from 27
[QUEUE] Stored info from 27
[RECEIVE] Queued message from 27
[QUEUE] Processing info from 27
[QUEUE] Stored info from 27
[RECEIVE] Queued message from 27
[QUEUE] Processing info from 27
[QUEUE] Stored info from 27
[RECEIVE] Queued message from 27
[QUEUE] Processing info from 27
[QUEUE] Stored info from 27
[RECEIVE] Queued message from 27
[QUEUE] Processing info from 27
[QUEUE] Stored info from 27
[RECEIVE] Queued message from 27
[QUEUE] Processing info from 27
[QUEUE] Stored info from 27
[RECEIVE] Queued message from 27
[QUEUE] Processing info from 27
[QUEUE] Stored info from 27
[RECEIVE] Queued message from 27
[QUEUE] Processing info from 27
[QUEUE] Stored info from 27
[RECEIVE] Queued message from 27
[QUEUE] Processing info from 27
[QUEUE] Stored info from 27
[RECEIVE] Queued message from 27
[QUEUE] Processing info from 27
[QUEUE] Stored info from 27
[RECEIVE] Queued message from 27
[QUEUE] Processing info from 27
[QUEUE] Stored info from 27
[RECEIVE] Queued message from 27
[QUEUE] Processing info from 27
[QUEUE] Stored info from 27
[RECEIVE] Queued message from 27
[QUEUE] Processing info from 27
[QUEUE] Stored info from 27
[RECEIVE] Queued message from 27
[QUEUE] Processing info from 27
[QUEUE] Stored info from 27
[RECEIVE] Queued message from 27
[QUEUE] Processing info from 27
[QUEUE] Stored info from 27
[RECEIVE] Queued message from 27
[QUEUE] Processing info from 27
[QUEUE] Stored info from 27
[RECEIVE] Queued message from 27
[QUEUE] Processing info from 27
[QUEUE] Stored info from 27
[RECEIVE] Queued message from 27
[QUEUE] Processing info from 27
[QUEUE] Stored info from 27
[RECEIVE] Queued message from 27
[QUEUE] Processing info from 27
[QUEUE] Stored info from 27
[RECEIVE] Queued message from 27
[QUEUE] Processing info from 27
[QUEUE] Stored info from 27
[RECEIVE] Queued message from 27
[QUEUE] Processing info from 27
[QUEUE] Stored info from 27
[RECEIVE] Queued message from 27
[QUEUE] Processing info from 27
[QUEUE] Stored info from 27
[RECEIVE] Queued message from 27
[QUEUE] Processing info from 27
[QUEUE] Stored info from 27
[RECEIVE] Queued message from 27
[QUEUE] Processing info from 27
[QUEUE] Stored info from 27
[RECEIVE] Queued message from 27
[QUEUE] Processing info from 27
[QUEUE] Stored info from 27
[60] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2564.97it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:03<07:53,  3.36s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:05<03:56,  1.70s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:07<02:57,  1.30s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:09<02:33,  1.13s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:11<02:18,  1.04s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:08,  1.02it/s]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:00,  1.07it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:16<01:57,  1.08it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:17<01:50,  1.13it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:19<01:43,  1.19it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:20<01:38,  1.23it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:22<01:32,  1.28it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:23<01:28,  1.32it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:25<01:30,  1.27it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:26<01:26,  1.30it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:28<01:22,  1.34it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:29<01:19,  1.37it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:30<01:16,  1.39it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:32<01:14,  1.41it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:33<01:12,  1.42it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:35<01:15,  1.34it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:36<01:11,  1.38it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:38<01:08,  1.42it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:39<01:05,  1.45it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:40<01:02,  1.49it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:41<00:59,  1.53it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:43<00:57,  1.55it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:44<00:55,  1.58it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:45<00:55,  1.53it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:46<00:53,  1.56it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:48<00:51,  1.58it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:49<00:49,  1.60it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:50<00:47,  1.62it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:51<00:46,  1.63it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:53<00:44,  1.64it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:54<00:42,  1.65it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:55<00:43,  1.58it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [00:56<00:42,  1.57it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [00:58<00:40,  1.60it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [00:59<00:38,  1.62it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:00<00:37,  1.63it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:01<00:35,  1.65it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:02<00:34,  1.67it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:04<00:32,  1.69it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:05<00:31,  1.70it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:07<00:42,  1.20it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:09<00:37,  1.32it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:10<00:33,  1.41it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:11<00:31,  1.43it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:12<00:28,  1.51it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:13<00:26,  1.58it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:15<00:24,  1.62it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:16<00:23,  1.55it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:17<00:21,  1.61it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:18<00:19,  1.66it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:19<00:18,  1.71it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:21<00:16,  1.74it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:22<00:15,  1.76it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:23<00:14,  1.77it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:24<00:12,  1.79it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:25<00:11,  1.80it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:27<00:12,  1.54it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:28<00:10,  1.61it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:29<00:09,  1.66it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:30<00:08,  1.53it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:32<00:07,  1.47it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:33<00:05,  1.57it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:34<00:04,  1.67it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:35<00:02,  1.72it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:36<00:01,  1.66it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:37<00:00,  1.75it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:37<00:00,  1.45it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-6): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (7): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (8-12): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (13): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (15-18): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (19): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (20-23): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (25-31): 7 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-6): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (7): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (8-12): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (13): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (15-18): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (19): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (20-23): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (25-31): 7 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/60.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5178
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:53:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5178 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 178
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5011
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:53:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5011 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 11
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5109
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:53:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5109 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 109
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5141
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:53:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5141 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 141
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5064
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:53:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5064 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 64
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5082
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:53:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5082 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 82
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5044
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:53:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5044 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 44
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5029
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:53:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5029 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 29
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5205
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:53:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5205 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 205
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5004
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:53:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5004 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 4
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5243
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:53:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5243 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 243
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5236
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:53:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5236 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 236
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5045
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:53:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5045 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 45
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:53:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:53:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5230
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:53:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5230 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 230
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5104
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:53:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5104 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 104
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:53:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5080
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:53:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5080 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 80
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:53:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5171
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:53:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5171 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 171
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5006
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:53:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5006 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 6
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5030
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:53:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5030 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5027
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:53:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5027 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 27
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5013
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:53:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5013 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 13
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5242
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:53:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5242 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 242
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5206
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:53:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5206 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 206
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:53:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5026
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:53:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5026 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 26
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5133
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:53:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5133 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 133
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5196
INFO:werkzeug:127.0.0.1 - - [17/May/2025 19:53:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5196 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 196
