nohup: ignoring input
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:0'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}
网络架构：{'39': ['123', '9', '247', '180', '94', '98', '161', '211', '164', '87', '52', '172', '63', '55', '157', '12', '127', '173', '239', '140', '160', '117', '112', '174', '163', '40', '151', '99', '34', '219', '75'], '123': ['34', '164', '157', '160', '163', '112', '40', '180', '140', '94', '174', '173', '63', '87', '75', '52', '9', '151', '239', '127', '39', '211', '172', '161', '219', '117', '98', '247', '55', '99', '12'], '174': ['123', '40', '157', '151', '34', '172', '127', '9', '87', '12', '219', '239', '39', '163', '55', '94', '164', '98', '99', '161', '75', '211', '112', '140', '117', '160', '247', '52', '173', '180', '63'], '75': ['163', '52', '63', '98', '34', '151', '123', '174', '39', '40', '87', '157', '161', '172', '247', '219', '9', '173', '160', '140', '127', '117', '164', '55', '94', '239', '12', '112', '180', '99', '211'], '239': ['117', '123', '151', '9', '163', '99', '94', '34', '75', '172', '112', '211', '127', '98', '87', '180', '157', '161', '12', '219', '160', '40', '55', '164', '63', '174', '39', '52', '140', '173', '247'], '172': ['40', '52', '247', '34', '112', '117', '123', '211', '63', '98', '219', '173', '55', '39', '157', '75', '87', '140', '160', '164', '94', '239', '12', '161', '9', '180', '127', '99', '174', '163', '151'], '55': ['75', '211', '157', '160', '172', '161', '12', '87', '94', '9', '173', '127', '40', '112', '219', '34', '117', '180', '239', '63', '151', '99', '123', '140', '163', '52', '247', '174', '39', '164', '98'], '9': ['94', '34', '123', '219', '164', '12', '55', '172', '99', '174', '161', '247', '163', '151', '239', '98', '180', '39', '117', '211', '112', '140', '87', '127', '52', '75', '63', '157', '160', '40', '173'], '99': ['211', '98', '161', '140', '12', '87', '9', '219', '239', '160', '39', '52', '157', '112', '63', '34', '127', '40', '180', '163', '164', '247', '172', '94', '117', '55', '173', '174', '123', '151', '75'], '98': ['112', '172', '173', '75', '239', '9', '52', '12', '160', '211', '163', '219', '87', '164', '174', '55', '117', '157', '63', '151', '161', '247', '34', '140', '99', '40', '39', '127', '123', '94', '180'], '160': ['247', '180', '117', '151', '40', '174', '112', '211', '75', '99', '219', '157', '39', '34', '172', '55', '127', '173', '239', '161', '9', '12', '52', '163', '98', '63', '94', '123', '87', '140', '164'], '12': ['247', '172', '157', '123', '160', '163', '140', '87', '219', '55', '63', '40', '127', '117', '39', '99', '180', '94', '52', '34', '151', '164', '9', '173', '174', '75', '98', '161', '211', '239', '112'], '173': ['112', '87', '140', '75', '63', '9', '180', '12', '34', '163', '239', '40', '157', '127', '160', '151', '39', '172', '211', '161', '123', '247', '98', '219', '99', '52', '55', '94', '117', '174', '164'], '247': ['117', '99', '161', '52', '9', '239', '151', '55', '160', '112', '180', '40', '173', '172', '140', '12', '164', '94', '75', '219', '174', '63', '34', '127', '98', '157', '87', '163', '211', '123', '39'], '63': ['87', '247', '75', '163', '40', '211', '98', '55', '180', '140', '12', '117', '94', '34', '127', '151', '172', '173', '39', '160', '219', '99', '164', '52', '9', '239', '157', '112', '123', '174', '161'], '161': ['140', '211', '174', '94', '239', '219', '123', '75', '112', '40', '157', '151', '9', '52', '98', '163', '55', '247', '39', '12', '127', '172', '34', '160', '63', '99', '164', '87', '173', '180', '117'], '34': ['39', '98', '160', '52', '127', '117', '173', '180', '75', '211', '94', '99', '157', '164', '239', '151', '55', '172', '123', '219', '63', '140', '247', '112', '161', '174', '163', '40', '12', '9', '87'], '87': ['211', '174', '161', '75', '98', '219', '55', '180', '140', '112', '164', '99', '157', '163', '173', '160', '172', '127', '123', '151', '247', '94', '34', '117', '9', '52', '63', '40', '39', '12', '239'], '164': ['117', '127', '123', '211', '163', '63', '34', '174', '87', '55', '219', '75', '140', '161', '52', '112', '151', '9', '172', '39', '157', '98', '247', '180', '99', '40', '94', '239', '173', '160', '12'], '117': ['87', '161', '75', '112', '151', '98', '163', '160', '247', '40', '172', '94', '34', '55', '211', '63', '239', '52', '127', '174', '164', '12', '219', '173', '140', '99', '9', '123', '39', '157', '180'], '157': ['34', '219', '247', '98', '164', '112', '160', '87', '151', '39', '52', '12', '180', '55', '211', '239', '140', '99', '174', '63', '40', '117', '173', '127', '94', '172', '163', '9', '161', '123', '75'], '127': ['98', '172', '117', '112', '39', '87', '151', '40', '9', '52', '34', '123', '180', '157', '211', '63', '140', '239', '164', '247', '160', '219', '161', '55', '12', '99', '174', '94', '75', '163', '173'], '94': ['239', '172', '173', '174', '34', '75', '123', '164', '63', '127', '161', '55', '219', '40', '12', '180', '211', '117', '247', '52', '9', '160', '87', '98', '112', '163', '157', '140', '151', '99', '39'], '40': ['161', '239', '39', '151', '63', '164', '34', '160', '157', '12', '247', '112', '174', '140', '173', '172', '75', '9', '211', '94', '87', '99', '117', '52', '127', '123', '55', '180', '98', '163', '219'], '180': ['9', '174', '75', '211', '151', '87', '98', '99', '239', '40', '112', '52', '34', '39', '160', '163', '172', '164', '12', '117', '140', '219', '63', '247', '173', '123', '157', '161', '94', '127', '55'], '211': ['94', '161', '160', '173', '12', '127', '117', '34', '40', '55', '98', '52', '174', '164', '151', '157', '63', '247', '219', '87', '75', '112', '180', '123', '99', '39', '9', '140', '172', '163', '239'], '163': ['172', '9', '140', '180', '211', '157', '39', '161', '63', '12', '99', '219', '112', '52', '164', '98', '160', '94', '117', '173', '127', '87', '34', '123', '75', '239', '40', '55', '174', '247', '151'], '52': ['63', '160', '164', '247', '87', '211', '34', '99', '157', '12', '117', '98', '173', '180', '140', '161', '94', '127', '123', '112', '55', '174', '163', '40', '172', '39', '75', '9', '239', '151', '219'], '140': ['112', '151', '12', '239', '211', '173', '157', '161', '94', '164', '99', '163', '180', '117', '123', '40', '87', '55', '39', '172', '174', '9', '63', '75', '98', '52', '219', '247', '34', '160', '127'], '219': ['112', '174', '151', '239', '161', '99', '55', '12', '164', '9', '75', '163', '94', '117', '172', '40', '123', '180', '173', '63', '52', '211', '127', '98', '140', '34', '160', '87', '157', '247', '39'], '151': ['173', '94', '52', '12', '160', '63', '163', '140', '75', '34', '161', '98', '180', '164', '87', '174', '40', '239', '247', '219', '112', '55', '172', '117', '127', '123', '211', '9', '99', '157', '39'], '112': ['12', '161', '247', '173', '174', '157', '239', '140', '151', '127', '164', '99', '163', '55', '63', '87', '34', '39', '211', '172', '52', '98', '117', '9', '160', '40', '75', '94', '219', '180', '123']}
39
cuda:0
coqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:48<00:48, 48.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:02<00:00, 28.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:02<00:00, 31.15s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa HTTP/1.1" 200 857
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/EleutherAI/coqa/EleutherAI/coqa.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa HTTP/1.1" 200 857
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/coqa/resolve/82e11af842af6c1396f5e9a5c7de260107c50cf1/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa/revision/82e11af842af6c1396f5e9a5c7de260107c50cf1 HTTP/1.1" 200 857
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa/tree/82e11af842af6c1396f5e9a5c7de260107c50cf1?recursive=False&expand=False HTTP/1.1" 200 489
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa/tree/82e11af842af6c1396f5e9a5c7de260107c50cf1/data?recursive=False&expand=False HTTP/1.1" 404 79
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa/tree/82e11af842af6c1396f5e9a5c7de260107c50cf1/data?recursive=False&expand=False HTTP/1.1" 404 79
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa/revision/82e11af842af6c1396f5e9a5c7de260107c50cf1 HTTP/1.1" 200 857
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/coqa/resolve/82e11af842af6c1396f5e9a5c7de260107c50cf1/dataset_infos.json HTTP/1.1" 200 0
DEBUG:filelock:Attempting to acquire lock 140243571659296 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___coqa_default_0.0.0_82e11af842af6c1396f5e9a5c7de260107c50cf1.lock
DEBUG:filelock:Lock 140243571659296 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___coqa_default_0.0.0_82e11af842af6c1396f5e9a5c7de260107c50cf1.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1/dataset_info.json
DEBUG:filelock:Attempting to release lock 140243571659296 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___coqa_default_0.0.0_82e11af842af6c1396f5e9a5c7de260107c50cf1.lock
DEBUG:filelock:Lock 140243571659296 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___coqa_default_0.0.0_82e11af842af6c1396f5e9a5c7de260107c50cf1.lock
DEBUG:filelock:Attempting to acquire lock 140242299948592 on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1_builder.lock
DEBUG:filelock:Lock 140242299948592 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1/dataset_info.json
DEBUG:filelock:Attempting to release lock 140242299948592 on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1_builder.lock
DEBUG:filelock:Lock 140242299948592 released on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
DEBUG:lm_eval.api.task:doc_to_target returned a list. Assuming multiple targets.
INFO:lm_eval.evaluator:coqa: Using gen_kwargs: {'until': ['\nQ:']}
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of coqa from None to 0
INFO:lm_eval.api.task:Building contexts for coqa on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 75045.70it/s]
DEBUG:lm_eval.evaluator:Task: coqa; number of requests on this rank: 100
INFO:lm_eval.evaluator:Running generate_until requests
Running generate_until requests:   0%|          | 0/100 [00:00<?, ?it/s]Running generate_until requests:   1%|          | 1/100 [00:06<11:31,  6.99s/it]Running generate_until requests:   2%|▏         | 2/100 [00:11<09:10,  5.62s/it]Running generate_until requests:   3%|▎         | 3/100 [00:17<09:06,  5.64s/it]Running generate_until requests:   4%|▍         | 4/100 [00:21<08:20,  5.21s/it]Running generate_until requests:   5%|▌         | 5/100 [00:26<08:01,  5.07s/it]Running generate_until requests:   6%|▌         | 6/100 [00:31<07:33,  4.82s/it]Running generate_until requests:   7%|▋         | 7/100 [00:36<07:42,  4.97s/it]Running generate_until requests:   8%|▊         | 8/100 [00:40<07:19,  4.78s/it]Running generate_until requests:   9%|▉         | 9/100 [00:45<07:12,  4.75s/it]Running generate_until requests:  10%|█         | 10/100 [00:50<07:18,  4.87s/it]Running generate_until requests:  11%|█         | 11/100 [00:55<07:10,  4.84s/it]Running generate_until requests:  12%|█▏        | 12/100 [01:01<07:32,  5.14s/it]Running generate_until requests:  13%|█▎        | 13/100 [01:05<07:01,  4.84s/it]Running generate_until requests:  14%|█▍        | 14/100 [01:09<06:38,  4.63s/it]Running generate_until requests:  15%|█▌        | 15/100 [01:13<06:26,  4.55s/it]Running generate_until requests:  16%|█▌        | 16/100 [01:17<06:10,  4.41s/it]Running generate_until requests:  17%|█▋        | 17/100 [01:22<06:01,  4.36s/it]Running generate_until requests:  18%|█▊        | 18/100 [01:26<05:47,  4.24s/it]Running generate_until requests:  19%|█▉        | 19/100 [01:30<05:42,  4.23s/it]Running generate_until requests:  20%|██        | 20/100 [01:34<05:34,  4.18s/it]Running generate_until requests:  21%|██        | 21/100 [01:38<05:29,  4.17s/it]Running generate_until requests:  22%|██▏       | 22/100 [01:42<05:28,  4.21s/it]Running generate_until requests:  23%|██▎       | 23/100 [01:47<05:42,  4.45s/it]Running generate_until requests:  24%|██▍       | 24/100 [01:52<05:48,  4.58s/it]Running generate_until requests:  25%|██▌       | 25/100 [01:56<05:30,  4.41s/it]Running generate_until requests:  26%|██▌       | 26/100 [02:01<05:24,  4.39s/it]Running generate_until requests:  27%|██▋       | 27/100 [02:05<05:19,  4.38s/it]Running generate_until requests:  28%|██▊       | 28/100 [02:09<05:11,  4.33s/it]Running generate_until requests:  29%|██▉       | 29/100 [02:13<05:04,  4.29s/it]Running generate_until requests:  30%|███       | 30/100 [02:18<05:00,  4.30s/it]Running generate_until requests:  31%|███       | 31/100 [02:21<04:46,  4.15s/it]Running generate_until requests:  32%|███▏      | 32/100 [02:26<04:47,  4.23s/it]Running generate_until requests:  33%|███▎      | 33/100 [02:30<04:44,  4.24s/it]Running generate_until requests:  34%|███▍      | 34/100 [02:34<04:37,  4.21s/it]Running generate_until requests:  35%|███▌      | 35/100 [02:38<04:25,  4.08s/it]Running generate_until requests:  36%|███▌      | 36/100 [02:43<04:43,  4.42s/it]Running generate_until requests:  37%|███▋      | 37/100 [02:47<04:25,  4.22s/it]Running generate_until requests:  38%|███▊      | 38/100 [02:51<04:12,  4.07s/it]Running generate_until requests:  39%|███▉      | 39/100 [02:55<04:06,  4.03s/it]Running generate_until requests:  40%|████      | 40/100 [02:58<03:55,  3.93s/it]Running generate_until requests:  41%|████      | 41/100 [03:02<03:51,  3.93s/it]Running generate_until requests:  42%|████▏     | 42/100 [03:07<04:06,  4.26s/it]Running generate_until requests:  43%|████▎     | 43/100 [03:11<03:56,  4.15s/it]Running generate_until requests:  44%|████▍     | 44/100 [03:15<03:52,  4.14s/it]Running generate_until requests:  45%|████▌     | 45/100 [03:19<03:45,  4.10s/it]Running generate_until requests:  46%|████▌     | 46/100 [03:23<03:33,  3.96s/it]Running generate_until requests:  47%|████▋     | 47/100 [03:27<03:24,  3.85s/it]Running generate_until requests:  48%|████▊     | 48/100 [03:31<03:24,  3.93s/it]Running generate_until requests:  49%|████▉     | 49/100 [03:35<03:30,  4.13s/it]Running generate_until requests:  50%|█████     | 50/100 [03:39<03:18,  3.97s/it]Running generate_until requests:  51%|█████     | 51/100 [03:43<03:23,  4.15s/it]Running generate_until requests:  52%|█████▏    | 52/100 [03:47<03:10,  3.97s/it]Running generate_until requests:  53%|█████▎    | 53/100 [03:51<03:09,  4.03s/it]Running generate_until requests:  54%|█████▍    | 54/100 [03:55<02:58,  3.88s/it]Running generate_until requests:  55%|█████▌    | 55/100 [03:59<02:55,  3.89s/it]Running generate_until requests:  56%|█████▌    | 56/100 [04:03<02:56,  4.01s/it]Running generate_until requests:  57%|█████▋    | 57/100 [04:07<02:52,  4.01s/it]Running generate_until requests:  58%|█████▊    | 58/100 [04:10<02:42,  3.86s/it]Running generate_until requests:  59%|█████▉    | 59/100 [04:15<02:49,  4.12s/it]Running generate_until requests:  60%|██████    | 60/100 [04:19<02:37,  3.93s/it]Running generate_until requests:  61%|██████    | 61/100 [04:23<02:39,  4.08s/it]Running generate_until requests:  62%|██████▏   | 62/100 [04:27<02:38,  4.18s/it]Running generate_until requests:  63%|██████▎   | 63/100 [04:31<02:26,  3.95s/it]Running generate_until requests:  64%|██████▍   | 64/100 [04:34<02:16,  3.78s/it]Running generate_until requests:  65%|██████▌   | 65/100 [04:38<02:07,  3.65s/it]Running generate_until requests:  66%|██████▌   | 66/100 [04:41<02:01,  3.57s/it]Running generate_until requests:  67%|██████▋   | 67/100 [04:44<01:55,  3.50s/it]Running generate_until requests:  68%|██████▊   | 68/100 [04:48<01:55,  3.62s/it]Running generate_until requests:  69%|██████▉   | 69/100 [04:54<02:07,  4.12s/it]Running generate_until requests:  70%|███████   | 70/100 [04:57<02:00,  4.02s/it]Running generate_until requests:  71%|███████   | 71/100 [05:05<02:29,  5.17s/it]Running generate_until requests:  72%|███████▏  | 72/100 [05:08<02:08,  4.59s/it]Running generate_until requests:  73%|███████▎  | 73/100 [05:12<01:53,  4.22s/it]Running generate_until requests:  74%|███████▍  | 74/100 [05:15<01:45,  4.05s/it]Running generate_until requests:  75%|███████▌  | 75/100 [05:19<01:35,  3.83s/it]Running generate_until requests:  76%|███████▌  | 76/100 [05:22<01:27,  3.66s/it]Running generate_until requests:  77%|███████▋  | 77/100 [05:26<01:27,  3.81s/it]Running generate_until requests:  78%|███████▊  | 78/100 [05:30<01:21,  3.68s/it]Running generate_until requests:  79%|███████▉  | 79/100 [05:33<01:13,  3.51s/it]Running generate_until requests:  80%|████████  | 80/100 [05:36<01:10,  3.53s/it]Running generate_until requests:  81%|████████  | 81/100 [05:42<01:17,  4.07s/it]Running generate_until requests:  82%|████████▏ | 82/100 [05:45<01:07,  3.77s/it]Running generate_until requests:  83%|████████▎ | 83/100 [05:48<01:02,  3.66s/it]Running generate_until requests:  84%|████████▍ | 84/100 [05:51<00:55,  3.47s/it]Running generate_until requests:  85%|████████▌ | 85/100 [05:54<00:49,  3.32s/it]Running generate_until requests:  86%|████████▌ | 86/100 [05:57<00:46,  3.29s/it]Running generate_until requests:  87%|████████▋ | 87/100 [06:01<00:45,  3.52s/it]Running generate_until requests:  88%|████████▊ | 88/100 [06:05<00:41,  3.44s/it]Running generate_until requests:  89%|████████▉ | 89/100 [06:07<00:35,  3.25s/it]Running generate_until requests:  90%|█████████ | 90/100 [06:10<00:30,  3.08s/it]Running generate_until requests:  91%|█████████ | 91/100 [06:13<00:26,  2.93s/it]Running generate_until requests:  92%|█████████▏| 92/100 [06:15<00:22,  2.85s/it]Running generate_until requests:  93%|█████████▎| 93/100 [06:18<00:19,  2.81s/it]Running generate_until requests:  94%|█████████▍| 94/100 [06:21<00:16,  2.82s/it]Running generate_until requests:  95%|█████████▌| 95/100 [06:24<00:14,  2.88s/it]Running generate_until requests:  96%|█████████▌| 96/100 [06:27<00:11,  2.89s/it]Running generate_until requests:  97%|█████████▋| 97/100 [06:29<00:08,  2.73s/it]Running generate_until requests:  98%|█████████▊| 98/100 [06:31<00:05,  2.62s/it]Running generate_until requests:  99%|█████████▉| 99/100 [06:34<00:02,  2.61s/it]Running generate_until requests: 100%|██████████| 100/100 [06:37<00:00,  2.62s/it]Running generate_until requests: 100%|██████████| 100/100 [06:37<00:00,  3.97s/it]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:1'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:1'}
full model:
{'coqa': {'alias': 'coqa', 'em,none': 0.595, 'em_stderr,none': 0.044774970461162564, 'f1,none': 0.7211574141733987, 'f1_stderr,none': 0.037128235455690536}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.6057853926542468
0.4195568875297668
0.5244744113321889
0.5202703028806769
0.6150870974034927
0.5299634576457063
0.9336763524510373
0.23649940737178063
0.388911200696845
0.6478041116722705
0.5517233675449297
0.6723258763091353
0.7175526480521238
0.8411089149883405
0.7404554224148189
0.26376935916880817
0.9373006475493478
0.5360566853939598
0.38729358133282565
0.4541602442018795
0.8623573205888978
0.7318340566806717
0.6643209906079897
0.8122565195147101
0.4707270481319977
0.9785001455445378
0.17075087907531752
0.489625917805058
0.7595051272431785
0.6057853926542468
0.4195568875297668
0.5244744113321889
0.5202703028806769
0.6150870974034927
0.5299634576457063
0.9336763524510373
0.23649940737178063
0.388911200696845
0.6478041116722705
0.5517233675449297
0.6723258763091353
0.7175526480521238
0.8411089149883405
0.7404554224148189
0.26376935916880817
0.9373006475493478
0.5360566853939598
0.38729358133282565
0.4541602442018795
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[5, 4, 3, 2, 0, 1, 7, 6]
tensor([5, 4, 3, 2, 0, 1, 7, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 3, 4, 0, 2, 1, 7, 6]
tensor([5, 3, 4, 0, 2, 1, 7, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 1, 7, 0, 6, 2, 3, 4]
tensor([5, 1, 7, 0, 6, 2, 3, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 3, 6, 0, 5, 2, 4, 1]
tensor([7, 3, 6, 0, 5, 2, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 5, 7, 2, 4, 0, 3, 1]
tensor([6, 5, 7, 2, 4, 0, 3, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 5, 0, 0, 1, 2, 1, 3]
tensor([4, 5, 0, 0, 1, 2, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1, 2, 2, 0, 3, 3]
tensor([0, 1, 1, 2, 2, 0, 3, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([7])
tensor(7)
tensor([6])
tensor(6)
done!
Normal merging for layer 2
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
done!
Normal merging for layer 4
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Cross-layer merge completed for layers 5 to 8
done!
Normal merging for layer 9
tensor([2, 3])
tensor(2)
tensor([4, 6])
tensor(4)
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([1])
tensor(1)
done!
Cross-layer merge completed for layers 10 to 22
done!
Normal merging for layer 23
tensor([0, 5])
tensor(0)
tensor([1, 2])
tensor(1)
tensor([3, 4])
tensor(3)
tensor([6, 7])
tensor(6)
done!
Cross-layer merge completed for layers 24 to 31
done!
all done!
Model size: 12.3238 GB
123
cuda:1
sciq
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:48<00:48, 48.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:02<00:00, 28.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:02<00:00, 31.09s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq HTTP/1.1" 200 1237
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/sciq/sciq.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq HTTP/1.1" 200 1237
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/allenai/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq/revision/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 111
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq/revision/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 1237
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq/tree/2c94ad3e1aafab77146f384e23536f97a4849815?recursive=False&expand=False HTTP/1.1" 307 136
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq/tree/2c94ad3e1aafab77146f384e23536f97a4849815?recursive=False&expand=False HTTP/1.1" 200 291
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq/tree/2c94ad3e1aafab77146f384e23536f97a4849815/data?recursive=False&expand=False HTTP/1.1" 307 141
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq/tree/2c94ad3e1aafab77146f384e23536f97a4849815/data?recursive=False&expand=False HTTP/1.1" 200 358
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq/revision/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 111
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq/revision/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 1237
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/allenai/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:filelock:Attempting to acquire lock 140242299215968 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:filelock:Lock 140242299215968 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_info.json
DEBUG:filelock:Attempting to release lock 140242299215968 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:filelock:Lock 140242299215968 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:filelock:Attempting to acquire lock 140243098804368 on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:filelock:Lock 140243098804368 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_info.json
DEBUG:filelock:Attempting to release lock 140243098804368 on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:filelock:Lock 140243098804368 released on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of sciq from None to 0
INFO:lm_eval.api.task:Building contexts for sciq on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1035.91it/s]
DEBUG:lm_eval.evaluator:Task: sciq; number of requests on this rank: 400
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/400 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/400 [00:04<27:59,  4.21s/it]Running loglikelihood requests:   0%|          | 2/400 [00:07<24:35,  3.71s/it]Running loglikelihood requests:   1%|          | 3/400 [00:10<23:15,  3.52s/it]Running loglikelihood requests:   1%|          | 4/400 [00:14<22:35,  3.42s/it]Running loglikelihood requests:   1%|▏         | 5/400 [00:17<21:46,  3.31s/it]Running loglikelihood requests:   2%|▏         | 6/400 [00:20<21:14,  3.23s/it]Running loglikelihood requests:   2%|▏         | 7/400 [00:23<20:54,  3.19s/it]Running loglikelihood requests:   2%|▏         | 8/400 [00:26<20:40,  3.17s/it]Running loglikelihood requests:   2%|▏         | 9/400 [00:29<19:48,  3.04s/it]Running loglikelihood requests:   2%|▎         | 10/400 [00:32<19:11,  2.95s/it]Running loglikelihood requests:   3%|▎         | 11/400 [00:34<18:45,  2.89s/it]Running loglikelihood requests:   3%|▎         | 12/400 [00:37<18:24,  2.85s/it]Running loglikelihood requests:   3%|▎         | 13/400 [00:40<17:44,  2.75s/it]Running loglikelihood requests:   4%|▎         | 14/400 [00:42<17:16,  2.68s/it]Running loglikelihood requests:   4%|▍         | 15/400 [00:45<16:55,  2.64s/it]Running loglikelihood requests:   4%|▍         | 16/400 [00:47<16:39,  2.60s/it]Running loglikelihood requests:   4%|▍         | 17/400 [00:50<16:19,  2.56s/it]Running loglikelihood requests:   4%|▍         | 18/400 [00:52<16:03,  2.52s/it]Running loglikelihood requests:   5%|▍         | 19/400 [00:55<15:51,  2.50s/it]Running loglikelihood requests:   5%|▌         | 20/400 [00:57<15:42,  2.48s/it]Running loglikelihood requests:   5%|▌         | 21/400 [00:59<15:35,  2.47s/it]Running loglikelihood requests:   6%|▌         | 22/400 [01:02<15:23,  2.44s/it]Running loglikelihood requests:   6%|▌         | 23/400 [01:04<15:13,  2.42s/it]Running loglikelihood requests:   6%|▌         | 24/400 [01:07<15:06,  2.41s/it]Running loglikelihood requests:   6%|▋         | 25/400 [01:09<14:45,  2.36s/it]Running loglikelihood requests:   6%|▋         | 26/400 [01:11<14:29,  2.32s/it]Running loglikelihood requests:   7%|▋         | 27/400 [01:13<14:16,  2.30s/it]Running loglikelihood requests:   7%|▋         | 28/400 [01:15<14:06,  2.27s/it]Running loglikelihood requests:   7%|▋         | 29/400 [01:17<13:36,  2.20s/it]Running loglikelihood requests:   8%|▊         | 30/400 [01:20<13:15,  2.15s/it]Running loglikelihood requests:   8%|▊         | 31/400 [01:22<12:59,  2.11s/it]Running loglikelihood requests:   8%|▊         | 32/400 [01:24<12:47,  2.09s/it]Running loglikelihood requests:   8%|▊         | 33/400 [01:25<12:25,  2.03s/it]Running loglikelihood requests:   8%|▊         | 34/400 [01:27<12:08,  1.99s/it]Running loglikelihood requests:   9%|▉         | 35/400 [01:29<11:56,  1.96s/it]Running loglikelihood requests:   9%|▉         | 36/400 [01:31<11:47,  1.94s/it]Running loglikelihood requests:   9%|▉         | 37/400 [01:33<11:39,  1.93s/it]Running loglikelihood requests:  10%|▉         | 38/400 [01:35<11:33,  1.92s/it]Running loglikelihood requests:  10%|█         | 40/400 [01:37<08:48,  1.47s/it]Running loglikelihood requests:  10%|█         | 41/400 [01:39<09:10,  1.53s/it]Running loglikelihood requests:  10%|█         | 42/400 [01:40<09:27,  1.59s/it]Running loglikelihood requests:  11%|█         | 43/400 [01:42<09:40,  1.63s/it]Running loglikelihood requests:  11%|█         | 44/400 [01:44<09:48,  1.65s/it]Running loglikelihood requests:  11%|█▏        | 45/400 [01:46<09:59,  1.69s/it]Running loglikelihood requests:  12%|█▏        | 46/400 [01:47<09:54,  1.68s/it]Running loglikelihood requests:  12%|█▏        | 47/400 [01:49<09:49,  1.67s/it]Running loglikelihood requests:  12%|█▏        | 48/400 [01:50<09:45,  1.66s/it]Running loglikelihood requests:  12%|█▏        | 49/400 [01:52<09:41,  1.66s/it]Running loglikelihood requests:  12%|█▎        | 50/400 [01:54<09:38,  1.65s/it]Running loglikelihood requests:  13%|█▎        | 51/400 [01:55<09:34,  1.65s/it]Running loglikelihood requests:  13%|█▎        | 52/400 [01:57<09:31,  1.64s/it]Running loglikelihood requests:  13%|█▎        | 53/400 [01:59<09:12,  1.59s/it]Running loglikelihood requests:  14%|█▎        | 54/400 [02:00<08:58,  1.56s/it]Running loglikelihood requests:  14%|█▍        | 55/400 [02:01<08:47,  1.53s/it]Running loglikelihood requests:  14%|█▍        | 57/400 [02:03<06:33,  1.15s/it]Running loglikelihood requests:  14%|█▍        | 58/400 [02:04<06:53,  1.21s/it]Running loglikelihood requests:  15%|█▍        | 59/400 [02:06<07:09,  1.26s/it]Running loglikelihood requests:  16%|█▌        | 62/400 [02:07<04:43,  1.19it/s]Running loglikelihood requests:  16%|█▌        | 63/400 [02:08<05:20,  1.05it/s]Running loglikelihood requests:  16%|█▌        | 64/400 [02:10<05:53,  1.05s/it]Running loglikelihood requests:  16%|█▋        | 65/400 [02:11<06:16,  1.13s/it]Running loglikelihood requests:  16%|█▋        | 66/400 [02:13<06:34,  1.18s/it]Running loglikelihood requests:  17%|█▋        | 67/400 [02:14<06:48,  1.23s/it]Running loglikelihood requests:  17%|█▋        | 68/400 [02:15<06:58,  1.26s/it]Running loglikelihood requests:  17%|█▋        | 69/400 [02:17<07:02,  1.28s/it]Running loglikelihood requests:  18%|█▊        | 70/400 [02:18<07:05,  1.29s/it]Running loglikelihood requests:  18%|█▊        | 71/400 [02:19<07:07,  1.30s/it]Running loglikelihood requests:  18%|█▊        | 72/400 [02:21<07:07,  1.30s/it]Running loglikelihood requests:  18%|█▊        | 73/400 [02:22<07:07,  1.31s/it]Running loglikelihood requests:  18%|█▊        | 74/400 [02:23<07:05,  1.31s/it]Running loglikelihood requests:  19%|█▉        | 77/400 [02:24<04:22,  1.23it/s]Running loglikelihood requests:  20%|█▉        | 78/400 [02:26<04:53,  1.10it/s]Running loglikelihood requests:  20%|█▉        | 79/400 [02:27<05:19,  1.01it/s]Running loglikelihood requests:  20%|██        | 81/400 [02:28<04:25,  1.20it/s]Running loglikelihood requests:  20%|██        | 82/400 [02:29<04:47,  1.11it/s]Running loglikelihood requests:  21%|██        | 83/400 [02:30<05:06,  1.04it/s]Running loglikelihood requests:  21%|██        | 84/400 [02:32<05:20,  1.02s/it]Running loglikelihood requests:  21%|██▏       | 85/400 [02:33<05:30,  1.05s/it]Running loglikelihood requests:  22%|██▏       | 86/400 [02:34<05:37,  1.08s/it]Running loglikelihood requests:  22%|██▏       | 89/400 [02:35<03:37,  1.43it/s]Running loglikelihood requests:  22%|██▎       | 90/400 [02:36<04:04,  1.27it/s]Running loglikelihood requests:  23%|██▎       | 91/400 [02:37<04:27,  1.16it/s]Running loglikelihood requests:  23%|██▎       | 92/400 [02:38<04:46,  1.08it/s]Running loglikelihood requests:  23%|██▎       | 93/400 [02:40<05:01,  1.02it/s]Running loglikelihood requests:  24%|██▍       | 97/400 [02:41<02:50,  1.78it/s]Running loglikelihood requests:  24%|██▍       | 98/400 [02:42<03:18,  1.52it/s]Running loglikelihood requests:  25%|██▍       | 99/400 [02:43<03:45,  1.34it/s]Running loglikelihood requests:  25%|██▌       | 100/400 [02:44<04:08,  1.21it/s]Running loglikelihood requests:  25%|██▌       | 101/400 [02:45<04:27,  1.12it/s]Running loglikelihood requests:  26%|██▌       | 102/400 [02:46<04:42,  1.06it/s]Running loglikelihood requests:  26%|██▌       | 103/400 [02:47<04:53,  1.01it/s]Running loglikelihood requests:  26%|██▌       | 104/400 [02:48<05:01,  1.02s/it]Running loglikelihood requests:  26%|██▋       | 105/400 [02:50<05:06,  1.04s/it]Running loglikelihood requests:  26%|██▋       | 106/400 [02:51<05:09,  1.05s/it]Running loglikelihood requests:  27%|██▋       | 107/400 [02:52<05:11,  1.06s/it]Running loglikelihood requests:  27%|██▋       | 108/400 [02:53<05:11,  1.07s/it]Running loglikelihood requests:  27%|██▋       | 109/400 [02:54<05:10,  1.07s/it]Running loglikelihood requests:  28%|██▊       | 110/400 [02:55<05:12,  1.08s/it]Running loglikelihood requests:  28%|██▊       | 111/400 [02:56<05:20,  1.11s/it]Running loglikelihood requests:  28%|██▊       | 112/400 [02:57<05:16,  1.10s/it]Running loglikelihood requests:  28%|██▊       | 113/400 [02:58<05:12,  1.09s/it]Running loglikelihood requests:  28%|██▊       | 114/400 [02:59<05:09,  1.08s/it]Running loglikelihood requests:  29%|██▉       | 115/400 [03:00<05:06,  1.08s/it]Running loglikelihood requests:  29%|██▉       | 116/400 [03:01<05:03,  1.07s/it]Running loglikelihood requests:  29%|██▉       | 117/400 [03:02<05:00,  1.06s/it]Running loglikelihood requests:  30%|██▉       | 118/400 [03:04<04:56,  1.05s/it]Running loglikelihood requests:  30%|██▉       | 119/400 [03:05<04:53,  1.04s/it]Running loglikelihood requests:  30%|███       | 120/400 [03:06<04:50,  1.04s/it]Running loglikelihood requests:  30%|███       | 121/400 [03:07<04:49,  1.04s/it]Running loglikelihood requests:  30%|███       | 122/400 [03:08<04:47,  1.03s/it]Running loglikelihood requests:  31%|███       | 123/400 [03:09<04:45,  1.03s/it]Running loglikelihood requests:  31%|███       | 124/400 [03:10<04:43,  1.03s/it]Running loglikelihood requests:  31%|███▏      | 125/400 [03:11<04:41,  1.02s/it]Running loglikelihood requests:  32%|███▏      | 126/400 [03:12<04:38,  1.02s/it]Running loglikelihood requests:  32%|███▏      | 127/400 [03:13<04:35,  1.01s/it]Running loglikelihood requests:  32%|███▏      | 128/400 [03:14<04:33,  1.01s/it]Running loglikelihood requests:  32%|███▏      | 129/400 [03:15<04:32,  1.00s/it]Running loglikelihood requests:  32%|███▎      | 130/400 [03:16<04:30,  1.00s/it]Running loglikelihood requests:  33%|███▎      | 131/400 [03:17<04:28,  1.00it/s]Running loglikelihood requests:  34%|███▎      | 134/400 [03:18<02:45,  1.61it/s]Running loglikelihood requests:  34%|███▍      | 135/400 [03:19<03:04,  1.43it/s]Running loglikelihood requests:  34%|███▍      | 136/400 [03:20<03:21,  1.31it/s]Running loglikelihood requests:  34%|███▍      | 137/400 [03:21<03:34,  1.22it/s]Running loglikelihood requests:  34%|███▍      | 138/400 [03:22<03:45,  1.16it/s]Running loglikelihood requests:  35%|███▍      | 139/400 [03:23<03:52,  1.12it/s]Running loglikelihood requests:  36%|███▌      | 142/400 [03:24<02:31,  1.71it/s]Running loglikelihood requests:  36%|███▌      | 143/400 [03:24<02:51,  1.50it/s]Running loglikelihood requests:  36%|███▌      | 144/400 [03:25<03:08,  1.36it/s]Running loglikelihood requests:  36%|███▋      | 145/400 [03:26<03:22,  1.26it/s]Running loglikelihood requests:  36%|███▋      | 146/400 [03:27<03:32,  1.19it/s]Running loglikelihood requests:  37%|███▋      | 147/400 [03:28<03:40,  1.15it/s]Running loglikelihood requests:  37%|███▋      | 148/400 [03:29<03:46,  1.11it/s]Running loglikelihood requests:  37%|███▋      | 149/400 [03:30<03:50,  1.09it/s]Running loglikelihood requests:  38%|███▊      | 150/400 [03:31<03:51,  1.08it/s]Running loglikelihood requests:  38%|███▊      | 151/400 [03:32<03:52,  1.07it/s]Running loglikelihood requests:  38%|███▊      | 152/400 [03:33<03:53,  1.06it/s]Running loglikelihood requests:  38%|███▊      | 153/400 [03:34<03:53,  1.06it/s]Running loglikelihood requests:  38%|███▊      | 154/400 [03:35<03:53,  1.05it/s]Running loglikelihood requests:  39%|███▉      | 155/400 [03:36<03:52,  1.05it/s]Running loglikelihood requests:  39%|███▉      | 156/400 [03:37<03:51,  1.05it/s]Running loglikelihood requests:  39%|███▉      | 157/400 [03:38<03:50,  1.05it/s]Running loglikelihood requests:  40%|███▉      | 158/400 [03:39<03:49,  1.05it/s]Running loglikelihood requests:  40%|███▉      | 159/400 [03:40<03:48,  1.05it/s]Running loglikelihood requests:  40%|████      | 160/400 [03:41<03:47,  1.05it/s]Running loglikelihood requests:  40%|████      | 161/400 [03:42<03:46,  1.06it/s]Running loglikelihood requests:  40%|████      | 162/400 [03:43<03:44,  1.06it/s]Running loglikelihood requests:  41%|████      | 163/400 [03:44<03:43,  1.06it/s]Running loglikelihood requests:  41%|████      | 164/400 [03:45<03:41,  1.06it/s]Running loglikelihood requests:  41%|████▏     | 165/400 [03:45<03:39,  1.07it/s]Running loglikelihood requests:  42%|████▏     | 166/400 [03:46<03:37,  1.07it/s]Running loglikelihood requests:  42%|████▏     | 167/400 [03:47<03:36,  1.08it/s]Running loglikelihood requests:  42%|████▏     | 168/400 [03:48<03:35,  1.08it/s]Running loglikelihood requests:  42%|████▏     | 169/400 [03:49<03:33,  1.08it/s]Running loglikelihood requests:  42%|████▎     | 170/400 [03:50<03:32,  1.08it/s]Running loglikelihood requests:  43%|████▎     | 172/400 [03:51<02:41,  1.41it/s]Running loglikelihood requests:  43%|████▎     | 173/400 [03:52<02:51,  1.32it/s]Running loglikelihood requests:  44%|████▎     | 174/400 [03:53<02:58,  1.27it/s]Running loglikelihood requests:  44%|████▍     | 177/400 [03:54<01:57,  1.90it/s]Running loglikelihood requests:  44%|████▍     | 178/400 [03:55<02:13,  1.67it/s]Running loglikelihood requests:  45%|████▍     | 179/400 [03:55<02:26,  1.51it/s]Running loglikelihood requests:  45%|████▌     | 180/400 [03:56<02:37,  1.40it/s]Running loglikelihood requests:  45%|████▌     | 181/400 [03:57<02:44,  1.33it/s]Running loglikelihood requests:  46%|████▌     | 182/400 [03:58<02:50,  1.28it/s]Running loglikelihood requests:  46%|████▌     | 183/400 [03:59<02:54,  1.24it/s]Running loglikelihood requests:  46%|████▌     | 184/400 [04:00<02:57,  1.22it/s]Running loglikelihood requests:  46%|████▋     | 185/400 [04:01<02:58,  1.20it/s]Running loglikelihood requests:  46%|████▋     | 186/400 [04:01<02:59,  1.19it/s]Running loglikelihood requests:  47%|████▋     | 187/400 [04:02<02:59,  1.19it/s]Running loglikelihood requests:  47%|████▋     | 188/400 [04:03<02:59,  1.18it/s]Running loglikelihood requests:  47%|████▋     | 189/400 [04:04<02:58,  1.18it/s]Running loglikelihood requests:  48%|████▊     | 190/400 [04:05<02:57,  1.18it/s]Running loglikelihood requests:  48%|████▊     | 191/400 [04:06<02:56,  1.18it/s]Running loglikelihood requests:  48%|████▊     | 192/400 [04:07<02:54,  1.19it/s]Running loglikelihood requests:  48%|████▊     | 193/400 [04:07<02:53,  1.19it/s]Running loglikelihood requests:  48%|████▊     | 194/400 [04:08<02:51,  1.20it/s]Running loglikelihood requests:  49%|████▉     | 195/400 [04:09<02:50,  1.20it/s]Running loglikelihood requests:  49%|████▉     | 196/400 [04:10<02:49,  1.21it/s]Running loglikelihood requests:  49%|████▉     | 197/400 [04:11<02:47,  1.21it/s]Running loglikelihood requests:  50%|████▉     | 198/400 [04:11<02:45,  1.22it/s]Running loglikelihood requests:  50%|████▉     | 199/400 [04:12<02:44,  1.22it/s]Running loglikelihood requests:  50%|█████     | 200/400 [04:13<02:43,  1.23it/s]Running loglikelihood requests:  50%|█████     | 201/400 [04:14<02:41,  1.23it/s]Running loglikelihood requests:  50%|█████     | 202/400 [04:15<02:40,  1.23it/s]Running loglikelihood requests:  51%|█████     | 203/400 [04:15<02:39,  1.23it/s]Running loglikelihood requests:  51%|█████     | 204/400 [04:16<02:39,  1.23it/s]Running loglikelihood requests:  51%|█████▏    | 205/400 [04:17<02:38,  1.23it/s]Running loglikelihood requests:  52%|█████▏    | 206/400 [04:18<02:37,  1.23it/s]Running loglikelihood requests:  52%|█████▏    | 207/400 [04:19<02:36,  1.23it/s]Running loglikelihood requests:  52%|█████▏    | 208/400 [04:20<02:35,  1.23it/s]Running loglikelihood requests:  52%|█████▏    | 209/400 [04:20<02:34,  1.23it/s]Running loglikelihood requests:  53%|█████▎    | 212/400 [04:21<01:34,  1.98it/s]Running loglikelihood requests:  53%|█████▎    | 213/400 [04:22<01:45,  1.77it/s]Running loglikelihood requests:  54%|█████▎    | 214/400 [04:23<01:54,  1.62it/s]Running loglikelihood requests:  54%|█████▍    | 215/400 [04:24<02:01,  1.52it/s]Running loglikelihood requests:  54%|█████▍    | 216/400 [04:24<02:06,  1.45it/s]Running loglikelihood requests:  54%|█████▍    | 217/400 [04:25<02:10,  1.40it/s]Running loglikelihood requests:  55%|█████▍    | 218/400 [04:26<02:13,  1.36it/s]Running loglikelihood requests:  55%|█████▍    | 219/400 [04:27<02:15,  1.34it/s]Running loglikelihood requests:  55%|█████▌    | 220/400 [04:27<02:16,  1.32it/s]Running loglikelihood requests:  55%|█████▌    | 221/400 [04:28<02:16,  1.31it/s]Running loglikelihood requests:  56%|█████▌    | 222/400 [04:29<02:16,  1.30it/s]Running loglikelihood requests:  56%|█████▌    | 223/400 [04:30<02:16,  1.30it/s]Running loglikelihood requests:  56%|█████▌    | 224/400 [04:31<02:15,  1.30it/s]Running loglikelihood requests:  56%|█████▋    | 225/400 [04:31<02:14,  1.30it/s]Running loglikelihood requests:  56%|█████▋    | 226/400 [04:32<02:13,  1.30it/s]Running loglikelihood requests:  57%|█████▋    | 227/400 [04:33<02:13,  1.30it/s]Running loglikelihood requests:  57%|█████▋    | 228/400 [04:34<02:12,  1.30it/s]Running loglikelihood requests:  57%|█████▋    | 229/400 [04:34<02:11,  1.30it/s]Running loglikelihood requests:  57%|█████▊    | 230/400 [04:35<02:10,  1.30it/s]Running loglikelihood requests:  58%|█████▊    | 231/400 [04:36<02:10,  1.30it/s]Running loglikelihood requests:  58%|█████▊    | 232/400 [04:37<02:09,  1.30it/s]Running loglikelihood requests:  58%|█████▊    | 233/400 [04:37<02:08,  1.30it/s]Running loglikelihood requests:  58%|█████▊    | 234/400 [04:38<02:07,  1.30it/s]Running loglikelihood requests:  59%|█████▉    | 235/400 [04:39<02:06,  1.31it/s]Running loglikelihood requests:  59%|█████▉    | 236/400 [04:40<02:05,  1.31it/s]Running loglikelihood requests:  59%|█████▉    | 237/400 [04:40<02:04,  1.31it/s]Running loglikelihood requests:  60%|██████    | 240/400 [04:41<01:16,  2.10it/s]Running loglikelihood requests:  60%|██████    | 241/400 [04:42<01:24,  1.88it/s]Running loglikelihood requests:  60%|██████    | 242/400 [04:43<01:31,  1.72it/s]Running loglikelihood requests:  61%|██████    | 243/400 [04:43<01:37,  1.61it/s]Running loglikelihood requests:  61%|██████    | 244/400 [04:44<01:41,  1.54it/s]Running loglikelihood requests:  61%|██████▏   | 245/400 [04:45<01:47,  1.44it/s]Running loglikelihood requests:  62%|██████▏   | 246/400 [04:46<01:51,  1.38it/s]Running loglikelihood requests:  62%|██████▏   | 247/400 [04:47<01:52,  1.36it/s]Running loglikelihood requests:  62%|██████▏   | 248/400 [04:47<01:51,  1.36it/s]Running loglikelihood requests:  62%|██████▏   | 249/400 [04:48<01:51,  1.36it/s]Running loglikelihood requests:  62%|██████▎   | 250/400 [04:49<01:50,  1.36it/s]Running loglikelihood requests:  63%|██████▎   | 251/400 [04:50<01:49,  1.36it/s]Running loglikelihood requests:  63%|██████▎   | 252/400 [04:50<01:48,  1.36it/s]Running loglikelihood requests:  63%|██████▎   | 253/400 [04:51<01:47,  1.36it/s]Running loglikelihood requests:  64%|██████▎   | 254/400 [04:52<01:46,  1.37it/s]Running loglikelihood requests:  64%|██████▍   | 255/400 [04:52<01:45,  1.37it/s]Running loglikelihood requests:  64%|██████▍   | 256/400 [04:53<01:45,  1.37it/s]Running loglikelihood requests:  64%|██████▍   | 257/400 [04:54<01:44,  1.37it/s]Running loglikelihood requests:  64%|██████▍   | 258/400 [04:55<01:43,  1.37it/s]Running loglikelihood requests:  65%|██████▍   | 259/400 [04:55<01:42,  1.38it/s]Running loglikelihood requests:  65%|██████▌   | 260/400 [04:56<01:41,  1.38it/s]Running loglikelihood requests:  65%|██████▌   | 261/400 [04:57<01:38,  1.41it/s]Running loglikelihood requests:  66%|██████▌   | 262/400 [04:57<01:36,  1.43it/s]Running loglikelihood requests:  66%|██████▌   | 263/400 [04:58<01:34,  1.44it/s]Running loglikelihood requests:  66%|██████▌   | 264/400 [04:59<01:33,  1.45it/s]Running loglikelihood requests:  66%|██████▋   | 265/400 [04:59<01:30,  1.48it/s]Running loglikelihood requests:  66%|██████▋   | 266/400 [05:00<01:28,  1.51it/s]Running loglikelihood requests:  67%|██████▋   | 267/400 [05:01<01:27,  1.52it/s]Running loglikelihood requests:  67%|██████▋   | 268/400 [05:01<01:25,  1.54it/s]Running loglikelihood requests:  67%|██████▋   | 269/400 [05:02<01:24,  1.55it/s]Running loglikelihood requests:  68%|██████▊   | 270/400 [05:03<01:22,  1.57it/s]Running loglikelihood requests:  68%|██████▊   | 271/400 [05:03<01:21,  1.58it/s]Running loglikelihood requests:  68%|██████▊   | 272/400 [05:04<01:20,  1.59it/s]Running loglikelihood requests:  68%|██████▊   | 273/400 [05:04<01:18,  1.62it/s]Running loglikelihood requests:  68%|██████▊   | 274/400 [05:05<01:16,  1.64it/s]Running loglikelihood requests:  69%|██████▉   | 275/400 [05:06<01:15,  1.66it/s]Running loglikelihood requests:  69%|██████▉   | 276/400 [05:06<01:13,  1.68it/s]Running loglikelihood requests:  69%|██████▉   | 277/400 [05:07<01:12,  1.69it/s]Running loglikelihood requests:  70%|██████▉   | 278/400 [05:07<01:11,  1.70it/s]Running loglikelihood requests:  70%|██████▉   | 279/400 [05:08<01:10,  1.71it/s]Running loglikelihood requests:  70%|███████   | 280/400 [05:08<01:09,  1.72it/s]Running loglikelihood requests:  70%|███████   | 281/400 [05:09<01:08,  1.73it/s]Running loglikelihood requests:  70%|███████   | 282/400 [05:10<01:08,  1.73it/s]Running loglikelihood requests:  71%|███████   | 283/400 [05:10<01:07,  1.74it/s]Running loglikelihood requests:  71%|███████   | 284/400 [05:11<01:06,  1.74it/s]Running loglikelihood requests:  71%|███████▏  | 285/400 [05:11<01:05,  1.75it/s]Running loglikelihood requests:  72%|███████▏  | 286/400 [05:12<01:04,  1.75it/s]Running loglikelihood requests:  72%|███████▏  | 287/400 [05:12<01:04,  1.76it/s]Running loglikelihood requests:  72%|███████▏  | 288/400 [05:13<01:03,  1.76it/s]Running loglikelihood requests:  72%|███████▏  | 289/400 [05:14<01:02,  1.76it/s]Running loglikelihood requests:  72%|███████▎  | 290/400 [05:14<01:02,  1.77it/s]Running loglikelihood requests:  73%|███████▎  | 291/400 [05:15<01:01,  1.76it/s]Running loglikelihood requests:  73%|███████▎  | 292/400 [05:15<01:01,  1.76it/s]Running loglikelihood requests:  73%|███████▎  | 293/400 [05:16<01:00,  1.77it/s]Running loglikelihood requests:  74%|███████▎  | 294/400 [05:16<00:59,  1.77it/s]Running loglikelihood requests:  74%|███████▍  | 295/400 [05:17<00:58,  1.78it/s]Running loglikelihood requests:  74%|███████▍  | 296/400 [05:18<00:58,  1.79it/s]Running loglikelihood requests:  74%|███████▍  | 297/400 [05:18<00:57,  1.79it/s]Running loglikelihood requests:  74%|███████▍  | 298/400 [05:19<00:56,  1.79it/s]Running loglikelihood requests:  75%|███████▍  | 299/400 [05:19<00:56,  1.80it/s]Running loglikelihood requests:  75%|███████▌  | 300/400 [05:20<00:55,  1.80it/s]Running loglikelihood requests:  75%|███████▌  | 301/400 [05:20<00:55,  1.80it/s]Running loglikelihood requests:  76%|███████▌  | 302/400 [05:21<00:54,  1.80it/s]Running loglikelihood requests:  76%|███████▌  | 303/400 [05:21<00:53,  1.80it/s]Running loglikelihood requests:  76%|███████▌  | 304/400 [05:22<00:53,  1.81it/s]Running loglikelihood requests:  76%|███████▋  | 305/400 [05:23<00:52,  1.81it/s]Running loglikelihood requests:  76%|███████▋  | 306/400 [05:23<00:51,  1.81it/s]Running loglikelihood requests:  77%|███████▋  | 307/400 [05:24<00:51,  1.81it/s]Running loglikelihood requests:  78%|███████▊  | 310/400 [05:24<00:31,  2.90it/s]Running loglikelihood requests:  78%|███████▊  | 311/400 [05:25<00:34,  2.58it/s]Running loglikelihood requests:  78%|███████▊  | 312/400 [05:25<00:37,  2.35it/s]Running loglikelihood requests:  78%|███████▊  | 313/400 [05:26<00:39,  2.19it/s]Running loglikelihood requests:  78%|███████▊  | 314/400 [05:26<00:41,  2.08it/s]Running loglikelihood requests:  79%|███████▉  | 315/400 [05:27<00:42,  2.01it/s]Running loglikelihood requests:  79%|███████▉  | 316/400 [05:27<00:42,  1.96it/s]Running loglikelihood requests:  79%|███████▉  | 317/400 [05:28<00:43,  1.93it/s]Running loglikelihood requests:  80%|███████▉  | 318/400 [05:29<00:42,  1.91it/s]Running loglikelihood requests:  80%|███████▉  | 319/400 [05:29<00:42,  1.91it/s]Running loglikelihood requests:  80%|████████  | 321/400 [05:30<00:32,  2.46it/s]Running loglikelihood requests:  80%|████████  | 322/400 [05:30<00:33,  2.30it/s]Running loglikelihood requests:  81%|████████  | 323/400 [05:31<00:35,  2.19it/s]Running loglikelihood requests:  81%|████████  | 324/400 [05:31<00:36,  2.11it/s]Running loglikelihood requests:  81%|████████▏ | 325/400 [05:32<00:36,  2.05it/s]Running loglikelihood requests:  82%|████████▏ | 326/400 [05:32<00:36,  2.02it/s]Running loglikelihood requests:  82%|████████▏ | 327/400 [05:33<00:36,  2.00it/s]Running loglikelihood requests:  82%|████████▏ | 328/400 [05:33<00:36,  1.99it/s]Running loglikelihood requests:  82%|████████▏ | 329/400 [05:34<00:35,  1.98it/s]Running loglikelihood requests:  82%|████████▎ | 330/400 [05:34<00:35,  1.97it/s]Running loglikelihood requests:  83%|████████▎ | 331/400 [05:35<00:35,  1.97it/s]Running loglikelihood requests:  83%|████████▎ | 332/400 [05:35<00:34,  1.96it/s]Running loglikelihood requests:  83%|████████▎ | 333/400 [05:36<00:33,  1.98it/s]Running loglikelihood requests:  84%|████████▎ | 334/400 [05:36<00:33,  1.99it/s]Running loglikelihood requests:  84%|████████▍ | 335/400 [05:37<00:32,  2.00it/s]Running loglikelihood requests:  84%|████████▍ | 336/400 [05:37<00:31,  2.00it/s]Running loglikelihood requests:  84%|████████▍ | 337/400 [05:38<00:31,  2.01it/s]Running loglikelihood requests:  84%|████████▍ | 338/400 [05:38<00:30,  2.02it/s]Running loglikelihood requests:  85%|████████▍ | 339/400 [05:39<00:30,  2.02it/s]Running loglikelihood requests:  85%|████████▌ | 340/400 [05:39<00:29,  2.03it/s]Running loglikelihood requests:  85%|████████▌ | 341/400 [05:40<00:29,  2.03it/s]Running loglikelihood requests:  86%|████████▌ | 342/400 [05:40<00:28,  2.03it/s]Running loglikelihood requests:  86%|████████▌ | 343/400 [05:41<00:27,  2.04it/s]Running loglikelihood requests:  86%|████████▌ | 344/400 [05:41<00:27,  2.04it/s]Running loglikelihood requests:  86%|████████▋ | 345/400 [05:42<00:26,  2.04it/s]Running loglikelihood requests:  86%|████████▋ | 346/400 [05:42<00:26,  2.05it/s]Running loglikelihood requests:  87%|████████▋ | 347/400 [05:43<00:25,  2.05it/s]Running loglikelihood requests:  87%|████████▋ | 348/400 [05:43<00:25,  2.05it/s]Running loglikelihood requests:  87%|████████▋ | 349/400 [05:44<00:24,  2.06it/s]Running loglikelihood requests:  88%|████████▊ | 350/400 [05:44<00:24,  2.06it/s]Running loglikelihood requests:  88%|████████▊ | 351/400 [05:45<00:23,  2.06it/s]Running loglikelihood requests:  88%|████████▊ | 352/400 [05:45<00:23,  2.06it/s]Running loglikelihood requests:  88%|████████▊ | 353/400 [05:46<00:22,  2.06it/s]Running loglikelihood requests:  88%|████████▊ | 354/400 [05:46<00:22,  2.07it/s]Running loglikelihood requests:  89%|████████▉ | 355/400 [05:46<00:21,  2.07it/s]Running loglikelihood requests:  89%|████████▉ | 356/400 [05:47<00:21,  2.08it/s]Running loglikelihood requests:  89%|████████▉ | 357/400 [05:47<00:20,  2.09it/s]Running loglikelihood requests:  90%|████████▉ | 358/400 [05:48<00:20,  2.09it/s]Running loglikelihood requests:  90%|████████▉ | 359/400 [05:48<00:19,  2.09it/s]Running loglikelihood requests:  90%|█████████ | 360/400 [05:49<00:19,  2.10it/s]Running loglikelihood requests:  90%|█████████ | 361/400 [05:49<00:18,  2.10it/s]Running loglikelihood requests:  90%|█████████ | 362/400 [05:50<00:18,  2.10it/s]Running loglikelihood requests:  91%|█████████ | 363/400 [05:50<00:17,  2.10it/s]Running loglikelihood requests:  91%|█████████ | 364/400 [05:51<00:17,  2.11it/s]Running loglikelihood requests:  91%|█████████▏| 365/400 [05:51<00:16,  2.11it/s]Running loglikelihood requests:  92%|█████████▏| 366/400 [05:52<00:16,  2.11it/s]Running loglikelihood requests:  92%|█████████▏| 368/400 [05:52<00:11,  2.75it/s]Running loglikelihood requests:  92%|█████████▏| 369/400 [05:53<00:12,  2.56it/s]Running loglikelihood requests:  92%|█████████▎| 370/400 [05:53<00:12,  2.43it/s]Running loglikelihood requests:  93%|█████████▎| 371/400 [05:54<00:12,  2.34it/s]Running loglikelihood requests:  93%|█████████▎| 373/400 [05:54<00:09,  2.91it/s]Running loglikelihood requests:  94%|█████████▎| 374/400 [05:55<00:09,  2.68it/s]Running loglikelihood requests:  94%|█████████▍| 375/400 [05:55<00:09,  2.51it/s]Running loglikelihood requests:  94%|█████████▍| 376/400 [05:55<00:09,  2.41it/s]Running loglikelihood requests:  94%|█████████▍| 377/400 [05:56<00:09,  2.34it/s]Running loglikelihood requests:  94%|█████████▍| 378/400 [05:56<00:09,  2.30it/s]Running loglikelihood requests:  95%|█████████▍| 379/400 [05:57<00:09,  2.27it/s]Running loglikelihood requests:  95%|█████████▌| 380/400 [05:57<00:08,  2.25it/s]Running loglikelihood requests:  95%|█████████▌| 381/400 [05:58<00:08,  2.23it/s]Running loglikelihood requests:  96%|█████████▌| 382/400 [05:58<00:08,  2.23it/s]Running loglikelihood requests:  96%|█████████▌| 383/400 [05:59<00:07,  2.23it/s]Running loglikelihood requests:  96%|█████████▌| 384/400 [05:59<00:07,  2.23it/s]Running loglikelihood requests:  96%|█████████▋| 385/400 [06:00<00:06,  2.24it/s]Running loglikelihood requests:  96%|█████████▋| 386/400 [06:00<00:06,  2.24it/s]Running loglikelihood requests:  97%|█████████▋| 387/400 [06:00<00:05,  2.25it/s]Running loglikelihood requests:  97%|█████████▋| 388/400 [06:01<00:05,  2.25it/s]Running loglikelihood requests:  97%|█████████▋| 389/400 [06:01<00:04,  2.26it/s]Running loglikelihood requests:  98%|█████████▊| 390/400 [06:02<00:04,  2.26it/s]Running loglikelihood requests:  98%|█████████▊| 391/400 [06:02<00:03,  2.26it/s]Running loglikelihood requests:  98%|█████████▊| 392/400 [06:03<00:03,  2.27it/s]Running loglikelihood requests:  98%|█████████▊| 393/400 [06:03<00:03,  2.28it/s]Running loglikelihood requests:  98%|█████████▊| 394/400 [06:03<00:02,  2.28it/s]Running loglikelihood requests:  99%|█████████▉| 395/400 [06:04<00:02,  2.28it/s]Running loglikelihood requests:  99%|█████████▉| 396/400 [06:04<00:01,  2.29it/s]Running loglikelihood requests:  99%|█████████▉| 397/400 [06:05<00:01,  2.29it/s]Running loglikelihood requests: 100%|█████████▉| 398/400 [06:05<00:00,  2.30it/s]Running loglikelihood requests: 100%|█████████▉| 399/400 [06:06<00:00,  2.30it/s]Running loglikelihood requests: 100%|██████████| 400/400 [06:06<00:00,  2.31it/s]Running loglikelihood requests: 100%|██████████| 400/400 [06:06<00:00,  1.09it/s]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:2'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:2'}
full model:
{'sciq': {'alias': 'sciq', 'acc,none': 0.94, 'acc_stderr,none': 0.023868325657594204, 'acc_norm,none': 0.91, 'acc_norm_stderr,none': 0.028762349126466136}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.969062788859705
0.9024924890572922
0.7706109127217512
0.8221264026535647
0.9190490061886575
0.9866654579796295
0.6586322754204971
0.7962110384246164
0.8195614021629236
0.7124178311176441
0.787697814339696
0.7034455022322618
0.8136386046534271
0.8174990104652458
0.6784276389594894
0.8698440245672888
0.8886492811850213
0.6541737276411673
0.6560861559753316
0.8139845219953913
0.6714741870309046
0.6164364868717988
0.8331581872497299
0.9065420049234512
0.9246185715568276
0.7477515960551026
0.574165362968651
0.8586446364199891
0.8889771415746612
Total groups 70 exceeded the threshold, stopping comparison.
The group tensor is
[7, 3, 4, 2, 6, 1, 5, 0]
tensor([7, 3, 4, 2, 6, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 2, 5, 3, 4, 0, 7, 1]
tensor([6, 2, 5, 3, 4, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 3, 6, 2, 7, 1, 4, 0]
tensor([5, 3, 6, 2, 7, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 4, 2, 1, 3, 5, 1]
tensor([0, 0, 4, 2, 1, 3, 5, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 2, 3, 4, 5, 0, 1, 1]
tensor([0, 2, 3, 4, 5, 0, 1, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 1, 0, 2, 2, 3, 1]
tensor([0, 3, 1, 0, 2, 2, 3, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 3, 1, 1, 2, 2, 3, 0]
tensor([0, 3, 1, 1, 2, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 1, 1.0, 1.0, 1.0, 1.0, 1]
tensor([0, 0, 1, 1, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 2 to 4
done!
Normal merging for layer 5
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 6 to 9
done!
Normal merging for layer 10
tensor([0, 1])
tensor(0)
tensor([4, 7])
tensor(4)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 11 to 12
done!
Normal merging for layer 13
tensor([0, 5])
tensor(0)
tensor([6, 7])
tensor(6)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 14 to 19
done!
Normal merging for layer 20
tensor([0, 3])
tensor(0)
tensor([2, 7])
tensor(2)
tensor([4, 5])
tensor(4)
tensor([1, 6])
tensor(1)
done!
Normal merging for layer 21
tensor([0, 7])
tensor(0)
tensor([2, 3])
tensor(2)
tensor([4, 5])
tensor(4)
tensor([1, 6])
tensor(1)
done!
Cross-layer merge completed for layers 22 to 23
done!
Normal merging for layer 24
tensor([0, 1])
tensor(0)
tensor([2, 3, 4, 5, 6, 7])
tensor(2)
done!
Cross-layer merge completed for layers 25 to 31
done!
all done!
Model size: 12.2608 GB
174
cuda:2
boolq
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:45<00:45, 45.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:59<00:00, 26.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:59<00:00, 29.76s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/super_glue/super_glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue/revision/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue/revision/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue/tree/3de24cf8022e94f4ee4b9d55a6f539891524d646?recursive=False&expand=False HTTP/1.1" 307 138
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue/tree/3de24cf8022e94f4ee4b9d55a6f539891524d646?recursive=False&expand=False HTTP/1.1" 200 501
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue/tree/3de24cf8022e94f4ee4b9d55a6f539891524d646/axb?recursive=False&expand=False HTTP/1.1" 307 142
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue/tree/3de24cf8022e94f4ee4b9d55a6f539891524d646/axb?recursive=False&expand=False HTTP/1.1" 200 232
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue/revision/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue/revision/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 237
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue/tree/3de24cf8022e94f4ee4b9d55a6f539891524d646/boolq?recursive=False&expand=False HTTP/1.1" 307 144
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue/tree/3de24cf8022e94f4ee4b9d55a6f539891524d646/boolq?recursive=False&expand=False HTTP/1.1" 200 355
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 237
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 237
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 237
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 237
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 237
DEBUG:filelock:Attempting to acquire lock 140242299405424 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_boolq_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 140242299405424 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_boolq_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/boolq/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 140242299405424 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_boolq_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 140242299405424 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_boolq_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Attempting to acquire lock 140243592300112 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/boolq/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 140243592300112 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/boolq/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/boolq/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 140243592300112 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/boolq/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 140243592300112 released on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/boolq/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of boolq from None to 0
INFO:lm_eval.api.task:Building contexts for boolq on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 2659.76it/s]
DEBUG:lm_eval.evaluator:Task: boolq; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:04<14:34,  4.40s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:06<05:49,  1.78s/it]Running loglikelihood requests:   2%|▎         | 5/200 [00:07<04:13,  1.30s/it]Running loglikelihood requests:   4%|▎         | 7/200 [00:09<03:31,  1.10s/it]Running loglikelihood requests:   4%|▍         | 9/200 [00:11<03:07,  1.02it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:12<02:50,  1.11it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:14<02:38,  1.18it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:15<02:30,  1.23it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:16<02:22,  1.28it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:18<02:16,  1.33it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:19<02:11,  1.36it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:21<02:07,  1.39it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:22<02:03,  1.42it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:23<02:00,  1.44it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:25<01:57,  1.45it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:26<01:55,  1.47it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:27<01:52,  1.48it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:29<01:50,  1.49it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:30<01:48,  1.51it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:31<01:45,  1.52it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:32<01:43,  1.53it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:34<01:42,  1.54it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:35<01:39,  1.55it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:36<01:37,  1.57it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:37<01:34,  1.59it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:39<01:32,  1.61it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:40<01:30,  1.62it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:41<01:28,  1.63it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:42<01:26,  1.65it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:43<01:24,  1.66it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:45<01:22,  1.68it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:46<01:21,  1.69it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:47<01:19,  1.70it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:48<01:17,  1.71it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:49<01:15,  1.73it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:50<01:13,  1.76it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:51<01:11,  1.78it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:52<01:09,  1.80it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:54<01:07,  1.82it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:55<01:05,  1.84it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:56<01:04,  1.85it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:57<01:02,  1.86it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:58<01:01,  1.87it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:59<01:00,  1.88it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [01:00<00:58,  1.89it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [01:01<00:57,  1.89it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [01:02<00:56,  1.90it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [01:03<00:55,  1.91it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [01:04<00:53,  1.91it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [01:05<00:52,  1.93it/s]Running loglikelihood requests:  50%|█████     | 101/200 [01:06<00:50,  1.94it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [01:07<00:49,  1.95it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [01:08<00:48,  1.97it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [01:09<00:47,  1.98it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [01:10<00:45,  1.99it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [01:11<00:44,  1.99it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [01:12<00:43,  2.00it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [01:13<00:42,  2.01it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [01:14<00:41,  2.02it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [01:15<00:39,  2.04it/s]Running loglikelihood requests:  60%|██████    | 121/200 [01:16<00:38,  2.06it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [01:17<00:36,  2.08it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [01:18<00:35,  2.11it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [01:19<00:34,  2.12it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [01:20<00:32,  2.16it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [01:20<00:31,  2.19it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [01:21<00:30,  2.22it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [01:22<00:29,  2.24it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [01:23<00:27,  2.26it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [01:24<00:26,  2.27it/s]Running loglikelihood requests:  70%|███████   | 141/200 [01:25<00:25,  2.29it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [01:26<00:24,  2.32it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [01:26<00:23,  2.35it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [01:27<00:22,  2.37it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [01:28<00:21,  2.39it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [01:29<00:20,  2.41it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [01:30<00:19,  2.42it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [01:31<00:18,  2.44it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [01:31<00:17,  2.46it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [01:32<00:16,  2.49it/s]Running loglikelihood requests:  80%|████████  | 161/200 [01:33<00:15,  2.51it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [01:34<00:14,  2.53it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [01:34<00:13,  2.55it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [01:35<00:12,  2.58it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [01:36<00:11,  2.59it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [01:37<00:11,  2.63it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [01:37<00:10,  2.67it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [01:38<00:09,  2.71it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [01:39<00:08,  2.75it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [01:40<00:07,  2.77it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [01:40<00:06,  2.79it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [01:41<00:06,  2.82it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [01:42<00:05,  2.85it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [01:42<00:04,  2.90it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [01:43<00:03,  2.94it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [01:44<00:03,  2.97it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [01:44<00:02,  2.99it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:45<00:01,  3.05it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:45<00:00,  3.18it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:46<00:00,  3.35it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:46<00:00,  1.88it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:3'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:3'}
full model:
{'boolq': {'alias': 'boolq', 'acc,none': 0.67, 'acc_stderr,none': 0.04725815626252609}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9782993007407264
0.4824830207482711
0.6583529368570694
0.8822475410601947
0.3059812833421515
0.7645942683746021
0.5411564675926485
0.6399758236302138
0.752913626333875
0.9170504110771489
0.8755679311709376
0.9130694495301263
0.6399088029710222
0.5907791688883935
0.8704540476128766
0.484807489124531
0.7579322019225017
0.8465026175931075
0.8104840653949666
0.671147278193032
0.7709951349967222
0.532915988335396
0.6066099270395096
0.5511989097245372
0.4671998655475952
0.6078287002452507
0.3992240879306912
0.5299030614769079
0.5709371890677749
0.9782993007407264
0.4824830207482711
0.6583529368570694
0.8822475410601947
0.3059812833421515
0.7645942683746021
0.5411564675926485
0.6399758236302138
0.752913626333875
0.9170504110771489
0.8755679311709376
0.9130694495301263
0.6399088029710222
0.5907791688883935
0.8704540476128766
0.484807489124531
0.7579322019225017
0.8465026175931075
0.8104840653949666
0.671147278193032
0.7709951349967222
0.532915988335396
0.6066099270395096
0.5511989097245372
0.4671998655475952
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[6, 2, 7, 0, 5, 3, 4, 1]
tensor([6, 2, 7, 0, 5, 3, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 2, 3, 0, 6, 1, 4, 5]
tensor([7, 2, 3, 0, 6, 1, 4, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 1, 7, 0, 6, 4, 2, 3]
tensor([5, 1, 7, 0, 6, 4, 2, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 3, 5, 1, 7, 2, 6, 0]
tensor([4, 3, 5, 1, 7, 2, 6, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[1, 6, 7, 3, 4, 5, 0, 2]
tensor([1, 6, 7, 3, 4, 5, 0, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 4, 1, 7, 2, 5, 0]
tensor([6, 3, 4, 1, 7, 2, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([7])
tensor(7)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
done!
Normal merging for layer 2
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
done!
Normal merging for layer 4
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
done!
Normal merging for layer 5
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 6 to 31
done!
all done!
Model size: 12.0718 GB
75
cuda:3
boolq
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:47<00:47, 47.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:00<00:00, 27.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:00<00:00, 30.44s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/super_glue/super_glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 237
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 237
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 237
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 237
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 237
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 237
DEBUG:filelock:Attempting to acquire lock 140243031249680 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_boolq_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 140243031249680 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_boolq_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/boolq/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 140243031249680 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_boolq_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 140243031249680 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_boolq_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Attempting to acquire lock 140237193543408 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/boolq/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 140237193543408 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/boolq/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/boolq/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 140237193543408 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/boolq/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 140237193543408 released on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/boolq/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of boolq from None to 0
INFO:lm_eval.api.task:Building contexts for boolq on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 2555.88it/s]
DEBUG:lm_eval.evaluator:Task: boolq; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:04<14:30,  4.37s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:06<05:49,  1.77s/it]Running loglikelihood requests:   2%|▎         | 5/200 [00:07<04:13,  1.30s/it]Running loglikelihood requests:   4%|▎         | 7/200 [00:09<03:32,  1.10s/it]Running loglikelihood requests:   4%|▍         | 9/200 [00:11<03:08,  1.01it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:12<02:52,  1.10it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:14<02:40,  1.16it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:15<02:32,  1.21it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:17<02:25,  1.26it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:18<02:20,  1.29it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:19<02:15,  1.32it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:21<02:11,  1.35it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:22<02:07,  1.38it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:24<02:03,  1.40it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:25<02:01,  1.41it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:26<01:58,  1.43it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:28<01:56,  1.44it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:29<01:53,  1.45it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:30<01:50,  1.47it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:32<01:48,  1.48it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:33<01:46,  1.49it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:34<01:44,  1.50it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:36<01:42,  1.51it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:37<01:39,  1.53it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:38<01:37,  1.55it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:39<01:35,  1.57it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:41<01:33,  1.58it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:42<01:31,  1.59it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:43<01:29,  1.60it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:44<01:26,  1.62it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:46<01:25,  1.63it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:47<01:23,  1.65it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:48<01:21,  1.66it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:49<01:19,  1.67it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:50<01:17,  1.68it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:51<01:15,  1.71it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:53<01:13,  1.73it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:54<01:11,  1.75it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:55<01:09,  1.77it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:56<01:07,  1.79it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:57<01:05,  1.80it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:58<01:04,  1.82it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:59<01:02,  1.83it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [01:00<01:01,  1.83it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [01:01<01:00,  1.84it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [01:02<00:59,  1.85it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [01:03<00:57,  1.85it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [01:04<00:56,  1.86it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [01:06<00:55,  1.86it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [01:07<00:53,  1.88it/s]Running loglikelihood requests:  50%|█████     | 101/200 [01:08<00:52,  1.89it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [01:09<00:51,  1.90it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [01:10<00:49,  1.91it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [01:11<00:48,  1.92it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [01:12<00:47,  1.93it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [01:13<00:45,  1.94it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [01:14<00:44,  1.95it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [01:15<00:43,  1.96it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [01:16<00:42,  1.97it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [01:17<00:40,  1.99it/s]Running loglikelihood requests:  60%|██████    | 121/200 [01:18<00:39,  2.01it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [01:19<00:37,  2.03it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [01:20<00:36,  2.05it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [01:21<00:35,  2.07it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [01:22<00:33,  2.12it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [01:22<00:32,  2.15it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [01:23<00:30,  2.18it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [01:24<00:29,  2.20it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [01:25<00:28,  2.22it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [01:26<00:27,  2.23it/s]Running loglikelihood requests:  70%|███████   | 141/200 [01:27<00:26,  2.25it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [01:28<00:24,  2.29it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [01:29<00:23,  2.31it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [01:29<00:22,  2.34it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [01:30<00:21,  2.36it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [01:31<00:20,  2.37it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [01:32<00:19,  2.38it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [01:33<00:18,  2.39it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [01:33<00:17,  2.42it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [01:34<00:16,  2.44it/s]Running loglikelihood requests:  80%|████████  | 161/200 [01:35<00:15,  2.46it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [01:36<00:14,  2.48it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [01:37<00:13,  2.50it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [01:37<00:13,  2.52it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [01:38<00:12,  2.54it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [01:39<00:11,  2.58it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [01:40<00:10,  2.62it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [01:40<00:09,  2.66it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [01:41<00:08,  2.69it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [01:42<00:07,  2.72it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [01:43<00:06,  2.74it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [01:43<00:06,  2.76it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [01:44<00:05,  2.80it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [01:45<00:04,  2.85it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [01:45<00:03,  2.88it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [01:46<00:03,  2.92it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [01:47<00:02,  2.94it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:47<00:01,  3.00it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:48<00:00,  3.13it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:48<00:00,  3.29it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:48<00:00,  1.84it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:4'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:4'}
full model:
{'boolq': {'alias': 'boolq', 'acc,none': 0.67, 'acc_stderr,none': 0.04725815626252609}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9782993007407264
0.4824830207482711
0.6583529368570694
0.8822475410601947
0.3059812833421515
0.7645942683746021
0.5411564675926485
0.6399758236302138
0.752913626333875
0.9170504110771489
0.8755679311709376
0.9130694495301263
0.6399088029710222
0.5907791688883935
0.8704540476128766
0.484807489124531
0.7579322019225017
0.8465026175931075
0.8104840653949666
0.671147278193032
0.7709951349967222
0.532915988335396
0.6066099270395096
0.5511989097245372
0.4671998655475952
0.6078287002452507
0.3992240879306912
0.5299030614769079
0.5709371890677749
0.9782993007407264
0.4824830207482711
0.6583529368570694
0.8822475410601947
0.3059812833421515
0.7645942683746021
0.5411564675926485
0.6399758236302138
0.752913626333875
0.9170504110771489
0.8755679311709376
0.9130694495301263
0.6399088029710222
0.5907791688883935
0.8704540476128766
0.484807489124531
0.7579322019225017
0.8465026175931075
0.8104840653949666
0.671147278193032
0.7709951349967222
0.532915988335396
0.6066099270395096
0.5511989097245372
0.4671998655475952
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[6, 2, 7, 0, 5, 3, 4, 1]
tensor([6, 2, 7, 0, 5, 3, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 2, 3, 0, 6, 1, 4, 5]
tensor([7, 2, 3, 0, 6, 1, 4, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 1, 7, 0, 6, 4, 2, 3]
tensor([5, 1, 7, 0, 6, 4, 2, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 3, 5, 1, 7, 2, 6, 0]
tensor([4, 3, 5, 1, 7, 2, 6, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[1, 6, 7, 3, 4, 5, 0, 2]
tensor([1, 6, 7, 3, 4, 5, 0, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 4, 1, 7, 2, 5, 0]
tensor([6, 3, 4, 1, 7, 2, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([7])
tensor(7)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
done!
Normal merging for layer 2
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
done!
Normal merging for layer 4
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
done!
Normal merging for layer 5
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 6 to 31
done!
all done!
Model size: 12.0718 GB
239
cuda:4
cb
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:45<00:45, 45.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:59<00:00, 26.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:59<00:00, 29.54s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: cb] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: cb] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
WARNING:lm_eval.api.task:[Task: cb] metric f1 is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/super_glue/super_glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue/tree/3de24cf8022e94f4ee4b9d55a6f539891524d646/cb?recursive=False&expand=False HTTP/1.1" 307 141
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue/tree/3de24cf8022e94f4ee4b9d55a6f539891524d646/cb?recursive=False&expand=False HTTP/1.1" 200 347
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:filelock:Attempting to acquire lock 140243031318192 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_cb_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 140243031318192 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_cb_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/cb/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 140243031318192 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_cb_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 140243031318192 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_cb_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Attempting to acquire lock 140242299800800 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/cb/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 140242299800800 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/cb/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/cb/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 140242299800800 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/cb/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 140242299800800 released on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/cb/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of cb from None to 0
INFO:lm_eval.api.task:Building contexts for cb on rank 0...
  0%|          | 0/56 [00:00<?, ?it/s]100%|██████████| 56/56 [00:00<00:00, 2085.00it/s]
DEBUG:lm_eval.evaluator:Task: cb; number of requests on this rank: 168
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/168 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/168 [00:02<07:13,  2.60s/it]Running loglikelihood requests:   1%|          | 2/168 [00:04<05:46,  2.09s/it]Running loglikelihood requests:   2%|▏         | 4/168 [00:06<03:35,  1.32s/it]Running loglikelihood requests:   3%|▎         | 5/168 [00:07<03:54,  1.44s/it]Running loglikelihood requests:   4%|▍         | 7/168 [00:09<02:59,  1.12s/it]Running loglikelihood requests:   5%|▍         | 8/168 [00:10<03:14,  1.21s/it]Running loglikelihood requests:   6%|▌         | 10/168 [00:12<02:33,  1.03it/s]Running loglikelihood requests:   7%|▋         | 11/168 [00:13<02:42,  1.03s/it]Running loglikelihood requests:   8%|▊         | 13/168 [00:14<02:14,  1.15it/s]Running loglikelihood requests:   8%|▊         | 14/168 [00:15<02:25,  1.06it/s]Running loglikelihood requests:  10%|▉         | 16/168 [00:16<02:03,  1.23it/s]Running loglikelihood requests:  10%|█         | 17/168 [00:18<02:15,  1.11it/s]Running loglikelihood requests:  11%|█▏        | 19/168 [00:19<01:54,  1.30it/s]Running loglikelihood requests:  12%|█▏        | 20/168 [00:20<02:04,  1.19it/s]Running loglikelihood requests:  13%|█▎        | 22/168 [00:21<01:44,  1.39it/s]Running loglikelihood requests:  14%|█▎        | 23/168 [00:22<01:54,  1.27it/s]Running loglikelihood requests:  15%|█▍        | 25/168 [00:23<01:37,  1.47it/s]Running loglikelihood requests:  15%|█▌        | 26/168 [00:24<01:46,  1.33it/s]Running loglikelihood requests:  17%|█▋        | 28/168 [00:25<01:31,  1.52it/s]Running loglikelihood requests:  17%|█▋        | 29/168 [00:26<01:41,  1.37it/s]Running loglikelihood requests:  18%|█▊        | 31/168 [00:27<01:27,  1.56it/s]Running loglikelihood requests:  19%|█▉        | 32/168 [00:28<01:37,  1.40it/s]Running loglikelihood requests:  20%|█▉        | 33/168 [00:29<01:44,  1.29it/s]Running loglikelihood requests:  21%|██        | 35/168 [00:30<01:27,  1.51it/s]Running loglikelihood requests:  22%|██▏       | 37/168 [00:31<01:18,  1.67it/s]Running loglikelihood requests:  23%|██▎       | 38/168 [00:32<01:27,  1.48it/s]Running loglikelihood requests:  24%|██▍       | 40/168 [00:33<01:17,  1.66it/s]Running loglikelihood requests:  24%|██▍       | 41/168 [00:34<01:25,  1.48it/s]Running loglikelihood requests:  26%|██▌       | 43/168 [00:35<01:14,  1.67it/s]Running loglikelihood requests:  26%|██▌       | 44/168 [00:36<01:23,  1.49it/s]Running loglikelihood requests:  27%|██▋       | 46/168 [00:37<01:11,  1.70it/s]Running loglikelihood requests:  28%|██▊       | 47/168 [00:37<01:19,  1.53it/s]Running loglikelihood requests:  29%|██▉       | 49/168 [00:38<01:08,  1.75it/s]Running loglikelihood requests:  30%|██▉       | 50/168 [00:39<01:14,  1.58it/s]Running loglikelihood requests:  30%|███       | 51/168 [00:40<01:20,  1.45it/s]Running loglikelihood requests:  31%|███       | 52/168 [00:41<01:25,  1.36it/s]Running loglikelihood requests:  32%|███▏      | 54/168 [00:42<01:09,  1.64it/s]Running loglikelihood requests:  33%|███▎      | 56/168 [00:43<01:00,  1.84it/s]Running loglikelihood requests:  35%|███▍      | 58/168 [00:44<00:55,  1.98it/s]Running loglikelihood requests:  35%|███▌      | 59/168 [00:44<01:02,  1.73it/s]Running loglikelihood requests:  36%|███▌      | 60/168 [00:45<01:09,  1.56it/s]Running loglikelihood requests:  37%|███▋      | 62/168 [00:46<00:59,  1.79it/s]Running loglikelihood requests:  38%|███▊      | 64/168 [00:47<00:53,  1.96it/s]Running loglikelihood requests:  39%|███▊      | 65/168 [00:48<00:59,  1.72it/s]Running loglikelihood requests:  40%|███▉      | 67/168 [00:49<00:52,  1.91it/s]Running loglikelihood requests:  40%|████      | 68/168 [00:49<00:58,  1.70it/s]Running loglikelihood requests:  42%|████▏     | 70/168 [00:50<00:51,  1.90it/s]Running loglikelihood requests:  42%|████▏     | 71/168 [00:51<00:57,  1.69it/s]Running loglikelihood requests:  43%|████▎     | 73/168 [00:52<00:49,  1.90it/s]Running loglikelihood requests:  44%|████▍     | 74/168 [00:53<00:55,  1.69it/s]Running loglikelihood requests:  45%|████▍     | 75/168 [00:54<01:00,  1.55it/s]Running loglikelihood requests:  45%|████▌     | 76/168 [00:54<01:03,  1.45it/s]Running loglikelihood requests:  46%|████▋     | 78/168 [00:55<00:51,  1.74it/s]Running loglikelihood requests:  48%|████▊     | 80/168 [00:56<00:45,  1.94it/s]Running loglikelihood requests:  49%|████▉     | 82/168 [00:57<00:41,  2.09it/s]Running loglikelihood requests:  49%|████▉     | 83/168 [00:58<00:46,  1.83it/s]Running loglikelihood requests:  51%|█████     | 85/168 [00:59<00:41,  2.02it/s]Running loglikelihood requests:  51%|█████     | 86/168 [00:59<00:45,  1.79it/s]Running loglikelihood requests:  52%|█████▏    | 88/168 [01:00<00:39,  2.01it/s]Running loglikelihood requests:  53%|█████▎    | 89/168 [01:01<00:44,  1.78it/s]Running loglikelihood requests:  54%|█████▎    | 90/168 [01:02<00:47,  1.63it/s]Running loglikelihood requests:  55%|█████▍    | 92/168 [01:03<00:40,  1.89it/s]Running loglikelihood requests:  56%|█████▌    | 94/168 [01:03<00:35,  2.09it/s]Running loglikelihood requests:  57%|█████▋    | 95/168 [01:04<00:39,  1.86it/s]Running loglikelihood requests:  58%|█████▊    | 97/168 [01:05<00:34,  2.07it/s]Running loglikelihood requests:  58%|█████▊    | 98/168 [01:06<00:37,  1.84it/s]Running loglikelihood requests:  60%|█████▉    | 100/168 [01:06<00:32,  2.08it/s]Running loglikelihood requests:  60%|██████    | 101/168 [01:07<00:36,  1.85it/s]Running loglikelihood requests:  61%|██████▏   | 103/168 [01:08<00:30,  2.10it/s]Running loglikelihood requests:  62%|██████▏   | 104/168 [01:09<00:34,  1.87it/s]Running loglikelihood requests:  62%|██████▎   | 105/168 [01:09<00:36,  1.72it/s]Running loglikelihood requests:  63%|██████▎   | 106/168 [01:10<00:38,  1.61it/s]Running loglikelihood requests:  64%|██████▍   | 108/168 [01:11<00:31,  1.93it/s]Running loglikelihood requests:  65%|██████▌   | 110/168 [01:12<00:26,  2.16it/s]Running loglikelihood requests:  66%|██████▌   | 111/168 [01:12<00:29,  1.92it/s]Running loglikelihood requests:  67%|██████▋   | 113/168 [01:13<00:25,  2.15it/s]Running loglikelihood requests:  68%|██████▊   | 114/168 [01:14<00:28,  1.91it/s]Running loglikelihood requests:  69%|██████▉   | 116/168 [01:15<00:24,  2.16it/s]Running loglikelihood requests:  70%|███████   | 118/168 [01:15<00:21,  2.33it/s]Running loglikelihood requests:  71%|███████   | 119/168 [01:16<00:23,  2.04it/s]Running loglikelihood requests:  71%|███████▏  | 120/168 [01:17<00:26,  1.85it/s]Running loglikelihood requests:  73%|███████▎  | 122/168 [01:17<00:21,  2.12it/s]Running loglikelihood requests:  74%|███████▍  | 124/168 [01:18<00:19,  2.31it/s]Running loglikelihood requests:  74%|███████▍  | 125/168 [01:19<00:21,  2.03it/s]Running loglikelihood requests:  76%|███████▌  | 127/168 [01:20<00:18,  2.26it/s]Running loglikelihood requests:  76%|███████▌  | 128/168 [01:20<00:19,  2.00it/s]Running loglikelihood requests:  77%|███████▋  | 129/168 [01:21<00:21,  1.82it/s]Running loglikelihood requests:  78%|███████▊  | 131/168 [01:22<00:17,  2.11it/s]Running loglikelihood requests:  79%|███████▉  | 133/168 [01:22<00:14,  2.36it/s]Running loglikelihood requests:  80%|███████▉  | 134/168 [01:23<00:16,  2.11it/s]Running loglikelihood requests:  81%|████████  | 136/168 [01:24<00:13,  2.37it/s]Running loglikelihood requests:  82%|████████▏ | 137/168 [01:24<00:14,  2.11it/s]Running loglikelihood requests:  82%|████████▏ | 138/168 [01:25<00:15,  1.94it/s]Running loglikelihood requests:  83%|████████▎ | 139/168 [01:26<00:15,  1.81it/s]Running loglikelihood requests:  83%|████████▎ | 140/168 [01:26<00:16,  1.73it/s]Running loglikelihood requests:  85%|████████▍ | 142/168 [01:27<00:12,  2.12it/s]Running loglikelihood requests:  86%|████████▌ | 144/168 [01:28<00:10,  2.40it/s]Running loglikelihood requests:  87%|████████▋ | 146/168 [01:28<00:08,  2.59it/s]Running loglikelihood requests:  88%|████████▊ | 148/168 [01:29<00:07,  2.74it/s]Running loglikelihood requests:  89%|████████▊ | 149/168 [01:30<00:07,  2.39it/s]Running loglikelihood requests:  89%|████████▉ | 150/168 [01:30<00:08,  2.14it/s]Running loglikelihood requests:  90%|█████████ | 152/168 [01:31<00:06,  2.44it/s]Running loglikelihood requests:  92%|█████████▏| 154/168 [01:32<00:05,  2.65it/s]Running loglikelihood requests:  92%|█████████▏| 155/168 [01:32<00:05,  2.34it/s]Running loglikelihood requests:  93%|█████████▎| 157/168 [01:33<00:04,  2.59it/s]Running loglikelihood requests:  94%|█████████▍| 158/168 [01:33<00:04,  2.30it/s]Running loglikelihood requests:  95%|█████████▌| 160/168 [01:34<00:03,  2.62it/s]Running loglikelihood requests:  96%|█████████▌| 161/168 [01:35<00:02,  2.37it/s]Running loglikelihood requests:  97%|█████████▋| 163/168 [01:35<00:01,  2.71it/s]Running loglikelihood requests:  98%|█████████▊| 164/168 [01:36<00:01,  2.45it/s]Running loglikelihood requests:  99%|█████████▉| 166/168 [01:36<00:00,  2.79it/s]Running loglikelihood requests:  99%|█████████▉| 167/168 [01:37<00:00,  2.51it/s]Running loglikelihood requests: 100%|██████████| 168/168 [01:37<00:00,  1.73it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:5'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:5'}
full model:
{'cb': {'alias': 'cb', 'acc,none': 0.44642857142857145, 'acc_stderr,none': 0.06703189227942397, 'f1,none': np.float64(0.2946127946127946), 'f1_stderr,none': 'N/A'}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8754479021250823
0.8035282713865031
0.9500865550679058
0.9469110267801961
0.9212663689239236
0.9365178765256775
0.671589453090406
0.6744336218334667
0.8076345549626031
0.7976470386087894
0.807072393829993
0.6600400889592184
0.7484904863798857
0.9363063771008698
0.6357711114598822
0.9166089836828051
0.6715835426958833
0.7409884813902188
0.412428535140908
0.8747283305135303
0.8491219158212996
0.9125101690232402
0.8366676259845086
0.705936129020536
0.7920385356495101
0.9243830461584077
0.9274604399644588
0.7835428130351293
0.8119111717866335
Total groups 67 exceeded the threshold, stopping comparison.
The group tensor is
[6, 3, 5, 2, 7, 1, 4, 0]
tensor([6, 3, 5, 2, 7, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 4, 7, 3, 6, 1, 2, 0]
tensor([5, 4, 7, 3, 6, 1, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 1, 6, 3, 7, 2, 4, 0]
tensor([5, 1, 6, 3, 7, 2, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 2, 0, 1, 5, 0, 1, 3]
tensor([4, 2, 0, 1, 5, 0, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[4, 3, 0, 2, 1, 1, 5, 0]
tensor([4, 3, 0, 2, 1, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 1, 2, 2, 1, 3, 0]
tensor([0, 3, 1, 2, 2, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1.0, 1.0, 0, 1.0, 1]
tensor([0, 1, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
done!
Cross-layer merge completed for layers 2 to 6
done!
Normal merging for layer 7
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 8 to 12
done!
Normal merging for layer 13
tensor([2, 5])
tensor(2)
tensor([3, 6])
tensor(3)
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Normal merging for layer 14
tensor([2, 7])
tensor(2)
tensor([4, 5])
tensor(4)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 15 to 18
done!
Normal merging for layer 19
tensor([0, 7])
tensor(0)
tensor([2, 5])
tensor(2)
tensor([3, 4])
tensor(3)
tensor([1, 6])
tensor(1)
done!
Cross-layer merge completed for layers 20 to 23
done!
Normal merging for layer 24
tensor([0, 5])
tensor(0)
tensor([1, 2, 3, 4, 6, 7])
tensor(1)
done!
Cross-layer merge completed for layers 25 to 31
done!
all done!
Model size: 11.9458 GB
172
cuda:5
mastermind_35_easy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:44<00:44, 44.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:58<00:00, 26.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:58<00:00, 29.08s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_35_mcq_random HTTP/1.1" 200 772
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/flair/mastermind_35_mcq_random/flair/mastermind_35_mcq_random.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_35_mcq_random HTTP/1.1" 200 780
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/flair/mastermind_35_mcq_random/resolve/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_35_mcq_random/revision/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 780
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_35_mcq_random/tree/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1?recursive=False&expand=False HTTP/1.1" 200 290
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_35_mcq_random/tree/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1/data?recursive=False&expand=False HTTP/1.1" 200 359
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_35_mcq_random/revision/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 780
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/flair/mastermind_35_mcq_random/resolve/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:filelock:Attempting to acquire lock 140242299213664 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_35_mcq_random_default_0.0.0_15dd5105771e9c8d2d3ea71c8d44fffda374a7a1.lock
DEBUG:filelock:Lock 140242299213664 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_35_mcq_random_default_0.0.0_15dd5105771e9c8d2d3ea71c8d44fffda374a7a1.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1/dataset_info.json
DEBUG:filelock:Attempting to release lock 140242299213664 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_35_mcq_random_default_0.0.0_15dd5105771e9c8d2d3ea71c8d44fffda374a7a1.lock
DEBUG:filelock:Lock 140242299213664 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_35_mcq_random_default_0.0.0_15dd5105771e9c8d2d3ea71c8d44fffda374a7a1.lock
DEBUG:filelock:Attempting to acquire lock 140233711974400 on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1_builder.lock
DEBUG:filelock:Lock 140233711974400 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1/dataset_info.json
DEBUG:filelock:Attempting to release lock 140233711974400 on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1_builder.lock
DEBUG:filelock:Lock 140233711974400 released on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mastermind_35_easy from None to 0
INFO:lm_eval.api.task:Building contexts for mastermind_35_easy on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1523.90it/s]
DEBUG:lm_eval.evaluator:Task: mastermind_35_easy; number of requests on this rank: 400
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/400 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/400 [00:01<12:15,  1.84s/it]Running loglikelihood requests:   0%|          | 2/400 [00:03<09:51,  1.49s/it]Running loglikelihood requests:   1%|          | 3/400 [00:04<08:59,  1.36s/it]Running loglikelihood requests:   1%|          | 4/400 [00:05<08:31,  1.29s/it]Running loglikelihood requests:   1%|▏         | 5/400 [00:06<08:16,  1.26s/it]Running loglikelihood requests:   2%|▏         | 6/400 [00:07<08:06,  1.24s/it]Running loglikelihood requests:   2%|▏         | 7/400 [00:09<08:00,  1.22s/it]Running loglikelihood requests:   2%|▏         | 8/400 [00:10<07:55,  1.21s/it]Running loglikelihood requests:   2%|▏         | 9/400 [00:11<07:51,  1.21s/it]Running loglikelihood requests:   2%|▎         | 10/400 [00:12<07:48,  1.20s/it]Running loglikelihood requests:   3%|▎         | 11/400 [00:13<07:46,  1.20s/it]Running loglikelihood requests:   3%|▎         | 12/400 [00:15<07:43,  1.19s/it]Running loglikelihood requests:   3%|▎         | 13/400 [00:16<07:40,  1.19s/it]Running loglikelihood requests:   4%|▎         | 14/400 [00:17<07:38,  1.19s/it]Running loglikelihood requests:   4%|▍         | 15/400 [00:18<07:36,  1.19s/it]Running loglikelihood requests:   4%|▍         | 16/400 [00:19<07:35,  1.19s/it]Running loglikelihood requests:   4%|▍         | 17/400 [00:20<07:34,  1.19s/it]Running loglikelihood requests:   4%|▍         | 18/400 [00:22<07:32,  1.18s/it]Running loglikelihood requests:   5%|▍         | 19/400 [00:23<07:29,  1.18s/it]Running loglikelihood requests:   5%|▌         | 20/400 [00:24<07:28,  1.18s/it]Running loglikelihood requests:   5%|▌         | 21/400 [00:25<07:26,  1.18s/it]Running loglikelihood requests:   6%|▌         | 23/400 [00:26<05:39,  1.11it/s]Running loglikelihood requests:   6%|▌         | 24/400 [00:27<06:03,  1.03it/s]Running loglikelihood requests:   6%|▋         | 25/400 [00:29<06:22,  1.02s/it]Running loglikelihood requests:   6%|▋         | 26/400 [00:30<06:36,  1.06s/it]Running loglikelihood requests:   7%|▋         | 27/400 [00:31<06:46,  1.09s/it]Running loglikelihood requests:   7%|▋         | 28/400 [00:32<06:53,  1.11s/it]Running loglikelihood requests:   7%|▋         | 29/400 [00:33<06:58,  1.13s/it]Running loglikelihood requests:   8%|▊         | 30/400 [00:34<07:01,  1.14s/it]Running loglikelihood requests:   8%|▊         | 31/400 [00:36<07:03,  1.15s/it]Running loglikelihood requests:   8%|▊         | 32/400 [00:37<07:03,  1.15s/it]Running loglikelihood requests:   8%|▊         | 33/400 [00:38<07:04,  1.16s/it]Running loglikelihood requests:   8%|▊         | 34/400 [00:39<07:04,  1.16s/it]Running loglikelihood requests:   9%|▉         | 35/400 [00:40<07:03,  1.16s/it]Running loglikelihood requests:   9%|▉         | 36/400 [00:41<07:02,  1.16s/it]Running loglikelihood requests:   9%|▉         | 37/400 [00:43<07:02,  1.16s/it]Running loglikelihood requests:  10%|▉         | 38/400 [00:44<07:00,  1.16s/it]Running loglikelihood requests:  10%|▉         | 39/400 [00:45<06:59,  1.16s/it]Running loglikelihood requests:  10%|█         | 40/400 [00:46<06:59,  1.16s/it]Running loglikelihood requests:  10%|█         | 41/400 [00:47<06:57,  1.16s/it]Running loglikelihood requests:  10%|█         | 42/400 [00:48<06:56,  1.16s/it]Running loglikelihood requests:  11%|█         | 43/400 [00:50<06:55,  1.16s/it]Running loglikelihood requests:  11%|█         | 44/400 [00:51<06:53,  1.16s/it]Running loglikelihood requests:  11%|█▏        | 45/400 [00:52<06:52,  1.16s/it]Running loglikelihood requests:  12%|█▏        | 46/400 [00:53<06:51,  1.16s/it]Running loglikelihood requests:  12%|█▏        | 47/400 [00:54<06:50,  1.16s/it]Running loglikelihood requests:  12%|█▏        | 48/400 [00:55<06:48,  1.16s/it]Running loglikelihood requests:  12%|█▏        | 49/400 [00:57<06:47,  1.16s/it]Running loglikelihood requests:  12%|█▎        | 50/400 [00:58<06:46,  1.16s/it]Running loglikelihood requests:  13%|█▎        | 51/400 [00:59<06:45,  1.16s/it]Running loglikelihood requests:  13%|█▎        | 52/400 [01:00<06:43,  1.16s/it]Running loglikelihood requests:  13%|█▎        | 53/400 [01:01<06:42,  1.16s/it]Running loglikelihood requests:  14%|█▎        | 54/400 [01:02<06:41,  1.16s/it]Running loglikelihood requests:  14%|█▍        | 55/400 [01:04<06:40,  1.16s/it]Running loglikelihood requests:  14%|█▍        | 56/400 [01:05<06:39,  1.16s/it]Running loglikelihood requests:  14%|█▍        | 57/400 [01:06<06:38,  1.16s/it]Running loglikelihood requests:  14%|█▍        | 58/400 [01:07<06:37,  1.16s/it]Running loglikelihood requests:  15%|█▍        | 59/400 [01:08<06:36,  1.16s/it]Running loglikelihood requests:  15%|█▌        | 60/400 [01:09<06:35,  1.16s/it]Running loglikelihood requests:  15%|█▌        | 61/400 [01:11<06:34,  1.16s/it]Running loglikelihood requests:  16%|█▌        | 62/400 [01:12<06:33,  1.16s/it]Running loglikelihood requests:  16%|█▌        | 63/400 [01:13<06:31,  1.16s/it]Running loglikelihood requests:  16%|█▌        | 64/400 [01:14<06:30,  1.16s/it]Running loglikelihood requests:  16%|█▋        | 65/400 [01:15<06:29,  1.16s/it]Running loglikelihood requests:  16%|█▋        | 66/400 [01:16<06:28,  1.16s/it]Running loglikelihood requests:  17%|█▋        | 67/400 [01:17<06:27,  1.16s/it]Running loglikelihood requests:  17%|█▋        | 68/400 [01:19<06:26,  1.16s/it]Running loglikelihood requests:  17%|█▋        | 69/400 [01:20<06:24,  1.16s/it]Running loglikelihood requests:  18%|█▊        | 70/400 [01:21<06:23,  1.16s/it]Running loglikelihood requests:  18%|█▊        | 71/400 [01:22<06:22,  1.16s/it]Running loglikelihood requests:  18%|█▊        | 72/400 [01:23<06:20,  1.16s/it]Running loglikelihood requests:  18%|█▊        | 73/400 [01:24<06:19,  1.16s/it]Running loglikelihood requests:  18%|█▊        | 74/400 [01:26<06:17,  1.16s/it]Running loglikelihood requests:  19%|█▉        | 75/400 [01:27<06:16,  1.16s/it]Running loglikelihood requests:  19%|█▉        | 76/400 [01:28<06:15,  1.16s/it]Running loglikelihood requests:  19%|█▉        | 77/400 [01:29<06:13,  1.16s/it]Running loglikelihood requests:  20%|█▉        | 78/400 [01:30<06:12,  1.16s/it]Running loglikelihood requests:  20%|█▉        | 79/400 [01:31<06:11,  1.16s/it]Running loglikelihood requests:  20%|██        | 80/400 [01:33<06:10,  1.16s/it]Running loglikelihood requests:  20%|██        | 81/400 [01:34<06:09,  1.16s/it]Running loglikelihood requests:  20%|██        | 82/400 [01:35<06:08,  1.16s/it]Running loglikelihood requests:  21%|██        | 83/400 [01:36<06:06,  1.16s/it]Running loglikelihood requests:  21%|██        | 84/400 [01:37<06:05,  1.16s/it]Running loglikelihood requests:  21%|██▏       | 85/400 [01:38<06:04,  1.16s/it]Running loglikelihood requests:  22%|██▏       | 86/400 [01:39<06:03,  1.16s/it]Running loglikelihood requests:  22%|██▏       | 87/400 [01:41<06:01,  1.16s/it]Running loglikelihood requests:  22%|██▏       | 88/400 [01:42<06:00,  1.16s/it]Running loglikelihood requests:  22%|██▏       | 89/400 [01:43<05:59,  1.16s/it]Running loglikelihood requests:  22%|██▎       | 90/400 [01:44<05:58,  1.16s/it]Running loglikelihood requests:  23%|██▎       | 91/400 [01:45<05:57,  1.16s/it]Running loglikelihood requests:  23%|██▎       | 92/400 [01:46<05:56,  1.16s/it]Running loglikelihood requests:  23%|██▎       | 93/400 [01:48<05:54,  1.16s/it]Running loglikelihood requests:  24%|██▎       | 94/400 [01:49<05:53,  1.16s/it]Running loglikelihood requests:  24%|██▍       | 95/400 [01:50<05:52,  1.16s/it]Running loglikelihood requests:  24%|██▍       | 96/400 [01:51<05:51,  1.16s/it]Running loglikelihood requests:  24%|██▍       | 97/400 [01:52<05:50,  1.16s/it]Running loglikelihood requests:  24%|██▍       | 98/400 [01:53<05:49,  1.16s/it]Running loglikelihood requests:  25%|██▍       | 99/400 [01:55<05:49,  1.16s/it]Running loglikelihood requests:  25%|██▌       | 100/400 [01:56<05:47,  1.16s/it]Running loglikelihood requests:  25%|██▌       | 101/400 [01:57<05:46,  1.16s/it]Running loglikelihood requests:  26%|██▌       | 102/400 [01:58<05:44,  1.16s/it]Running loglikelihood requests:  26%|██▌       | 103/400 [01:59<05:43,  1.16s/it]Running loglikelihood requests:  26%|██▌       | 104/400 [02:00<05:41,  1.15s/it]Running loglikelihood requests:  26%|██▋       | 105/400 [02:01<05:40,  1.15s/it]Running loglikelihood requests:  26%|██▋       | 106/400 [02:03<05:39,  1.15s/it]Running loglikelihood requests:  27%|██▋       | 107/400 [02:04<05:37,  1.15s/it]Running loglikelihood requests:  27%|██▋       | 108/400 [02:05<05:36,  1.15s/it]Running loglikelihood requests:  27%|██▋       | 109/400 [02:06<05:35,  1.15s/it]Running loglikelihood requests:  28%|██▊       | 110/400 [02:07<05:33,  1.15s/it]Running loglikelihood requests:  28%|██▊       | 112/400 [02:08<04:14,  1.13it/s]Running loglikelihood requests:  28%|██▊       | 113/400 [02:10<04:32,  1.05it/s]Running loglikelihood requests:  28%|██▊       | 114/400 [02:11<04:46,  1.00s/it]Running loglikelihood requests:  29%|██▉       | 115/400 [02:12<04:57,  1.04s/it]Running loglikelihood requests:  29%|██▉       | 116/400 [02:13<05:05,  1.07s/it]Running loglikelihood requests:  29%|██▉       | 117/400 [02:14<05:10,  1.10s/it]Running loglikelihood requests:  30%|██▉       | 118/400 [02:15<05:14,  1.11s/it]Running loglikelihood requests:  30%|██▉       | 119/400 [02:16<05:16,  1.13s/it]Running loglikelihood requests:  30%|███       | 120/400 [02:18<05:17,  1.14s/it]Running loglikelihood requests:  30%|███       | 121/400 [02:19<05:18,  1.14s/it]Running loglikelihood requests:  30%|███       | 122/400 [02:20<05:18,  1.14s/it]Running loglikelihood requests:  31%|███       | 123/400 [02:21<05:17,  1.15s/it]Running loglikelihood requests:  31%|███       | 124/400 [02:22<05:16,  1.15s/it]Running loglikelihood requests:  31%|███▏      | 125/400 [02:23<05:16,  1.15s/it]Running loglikelihood requests:  32%|███▏      | 126/400 [02:25<05:15,  1.15s/it]Running loglikelihood requests:  32%|███▏      | 127/400 [02:26<05:13,  1.15s/it]Running loglikelihood requests:  32%|███▏      | 128/400 [02:27<05:12,  1.15s/it]Running loglikelihood requests:  32%|███▏      | 129/400 [02:28<05:11,  1.15s/it]Running loglikelihood requests:  32%|███▎      | 130/400 [02:29<05:10,  1.15s/it]Running loglikelihood requests:  33%|███▎      | 131/400 [02:30<05:08,  1.15s/it]Running loglikelihood requests:  33%|███▎      | 132/400 [02:31<05:07,  1.15s/it]Running loglikelihood requests:  33%|███▎      | 133/400 [02:33<05:06,  1.15s/it]Running loglikelihood requests:  34%|███▎      | 134/400 [02:34<05:05,  1.15s/it]Running loglikelihood requests:  34%|███▍      | 135/400 [02:35<05:03,  1.15s/it]Running loglikelihood requests:  34%|███▍      | 136/400 [02:36<05:02,  1.15s/it]Running loglikelihood requests:  34%|███▍      | 137/400 [02:37<05:01,  1.15s/it]Running loglikelihood requests:  34%|███▍      | 138/400 [02:38<05:00,  1.15s/it]Running loglikelihood requests:  35%|███▍      | 139/400 [02:39<04:59,  1.15s/it]Running loglikelihood requests:  35%|███▌      | 140/400 [02:41<04:58,  1.15s/it]Running loglikelihood requests:  35%|███▌      | 141/400 [02:42<04:56,  1.14s/it]Running loglikelihood requests:  36%|███▌      | 142/400 [02:43<04:55,  1.14s/it]Running loglikelihood requests:  36%|███▌      | 143/400 [02:44<04:54,  1.14s/it]Running loglikelihood requests:  36%|███▌      | 144/400 [02:45<04:52,  1.14s/it]Running loglikelihood requests:  36%|███▋      | 145/400 [02:46<04:51,  1.14s/it]Running loglikelihood requests:  36%|███▋      | 146/400 [02:47<04:49,  1.14s/it]Running loglikelihood requests:  37%|███▋      | 147/400 [02:49<04:48,  1.14s/it]Running loglikelihood requests:  37%|███▋      | 148/400 [02:50<04:47,  1.14s/it]Running loglikelihood requests:  37%|███▋      | 149/400 [02:51<04:45,  1.14s/it]Running loglikelihood requests:  38%|███▊      | 150/400 [02:52<04:44,  1.14s/it]Running loglikelihood requests:  38%|███▊      | 151/400 [02:53<04:45,  1.15s/it]Running loglikelihood requests:  38%|███▊      | 152/400 [02:54<04:44,  1.15s/it]Running loglikelihood requests:  38%|███▊      | 153/400 [02:55<04:43,  1.15s/it]Running loglikelihood requests:  38%|███▊      | 154/400 [02:57<04:42,  1.15s/it]Running loglikelihood requests:  39%|███▉      | 155/400 [02:58<04:40,  1.15s/it]Running loglikelihood requests:  39%|███▉      | 156/400 [02:59<04:39,  1.15s/it]Running loglikelihood requests:  39%|███▉      | 157/400 [03:00<04:38,  1.15s/it]Running loglikelihood requests:  40%|███▉      | 158/400 [03:01<04:37,  1.15s/it]Running loglikelihood requests:  40%|███▉      | 159/400 [03:02<04:36,  1.15s/it]Running loglikelihood requests:  40%|████      | 160/400 [03:03<04:35,  1.15s/it]Running loglikelihood requests:  40%|████      | 161/400 [03:05<04:33,  1.15s/it]Running loglikelihood requests:  40%|████      | 162/400 [03:06<04:32,  1.14s/it]Running loglikelihood requests:  41%|████      | 163/400 [03:07<04:31,  1.14s/it]Running loglikelihood requests:  41%|████      | 164/400 [03:08<04:29,  1.14s/it]Running loglikelihood requests:  41%|████▏     | 165/400 [03:09<04:28,  1.14s/it]Running loglikelihood requests:  42%|████▏     | 166/400 [03:10<04:27,  1.14s/it]Running loglikelihood requests:  42%|████▏     | 167/400 [03:11<04:25,  1.14s/it]Running loglikelihood requests:  42%|████▏     | 168/400 [03:13<04:24,  1.14s/it]Running loglikelihood requests:  42%|████▏     | 169/400 [03:14<04:23,  1.14s/it]Running loglikelihood requests:  42%|████▎     | 170/400 [03:15<04:21,  1.14s/it]Running loglikelihood requests:  43%|████▎     | 171/400 [03:16<04:20,  1.14s/it]Running loglikelihood requests:  43%|████▎     | 172/400 [03:17<04:19,  1.14s/it]Running loglikelihood requests:  43%|████▎     | 173/400 [03:18<04:17,  1.14s/it]Running loglikelihood requests:  44%|████▎     | 174/400 [03:19<04:16,  1.14s/it]Running loglikelihood requests:  44%|████▍     | 175/400 [03:21<04:15,  1.14s/it]Running loglikelihood requests:  44%|████▍     | 177/400 [03:22<03:15,  1.14it/s]Running loglikelihood requests:  44%|████▍     | 178/400 [03:23<03:28,  1.06it/s]Running loglikelihood requests:  45%|████▍     | 179/400 [03:24<03:39,  1.01it/s]Running loglikelihood requests:  45%|████▌     | 180/400 [03:25<03:47,  1.03s/it]Running loglikelihood requests:  45%|████▌     | 181/400 [03:26<03:52,  1.06s/it]Running loglikelihood requests:  46%|████▌     | 182/400 [03:27<03:55,  1.08s/it]Running loglikelihood requests:  46%|████▌     | 183/400 [03:29<03:58,  1.10s/it]Running loglikelihood requests:  46%|████▌     | 184/400 [03:30<03:59,  1.11s/it]Running loglikelihood requests:  46%|████▋     | 185/400 [03:31<04:00,  1.12s/it]Running loglikelihood requests:  46%|████▋     | 186/400 [03:32<04:00,  1.12s/it]Running loglikelihood requests:  47%|████▋     | 187/400 [03:33<03:59,  1.12s/it]Running loglikelihood requests:  47%|████▋     | 188/400 [03:34<03:58,  1.13s/it]Running loglikelihood requests:  47%|████▋     | 189/400 [03:35<03:58,  1.13s/it]Running loglikelihood requests:  48%|████▊     | 190/400 [03:36<03:57,  1.13s/it]Running loglikelihood requests:  48%|████▊     | 191/400 [03:38<03:55,  1.13s/it]Running loglikelihood requests:  48%|████▊     | 192/400 [03:39<03:54,  1.13s/it]Running loglikelihood requests:  48%|████▊     | 193/400 [03:40<03:53,  1.13s/it]Running loglikelihood requests:  48%|████▊     | 194/400 [03:41<03:52,  1.13s/it]Running loglikelihood requests:  49%|████▉     | 195/400 [03:42<03:51,  1.13s/it]Running loglikelihood requests:  49%|████▉     | 196/400 [03:43<03:50,  1.13s/it]Running loglikelihood requests:  49%|████▉     | 197/400 [03:44<03:49,  1.13s/it]Running loglikelihood requests:  50%|████▉     | 198/400 [03:45<03:48,  1.13s/it]Running loglikelihood requests:  50%|████▉     | 199/400 [03:47<03:47,  1.13s/it]Running loglikelihood requests:  50%|█████     | 200/400 [03:48<03:46,  1.13s/it]Running loglikelihood requests:  50%|█████     | 201/400 [03:49<03:44,  1.13s/it]Running loglikelihood requests:  50%|█████     | 202/400 [03:50<03:43,  1.13s/it]Running loglikelihood requests:  51%|█████     | 203/400 [03:51<03:42,  1.13s/it]Running loglikelihood requests:  51%|█████▏    | 205/400 [03:52<02:49,  1.15it/s]Running loglikelihood requests:  52%|█████▏    | 206/400 [03:53<03:00,  1.07it/s]Running loglikelihood requests:  52%|█████▏    | 207/400 [03:55<03:09,  1.02it/s]Running loglikelihood requests:  52%|█████▏    | 208/400 [03:56<03:16,  1.02s/it]Running loglikelihood requests:  52%|█████▏    | 209/400 [03:57<03:20,  1.05s/it]Running loglikelihood requests:  52%|█████▎    | 210/400 [03:58<03:23,  1.07s/it]Running loglikelihood requests:  53%|█████▎    | 211/400 [03:59<03:25,  1.09s/it]Running loglikelihood requests:  53%|█████▎    | 212/400 [04:00<03:26,  1.10s/it]Running loglikelihood requests:  53%|█████▎    | 213/400 [04:01<03:27,  1.11s/it]Running loglikelihood requests:  54%|█████▎    | 214/400 [04:02<03:26,  1.11s/it]Running loglikelihood requests:  54%|█████▍    | 215/400 [04:04<03:26,  1.12s/it]Running loglikelihood requests:  54%|█████▍    | 216/400 [04:05<03:25,  1.12s/it]Running loglikelihood requests:  54%|█████▍    | 217/400 [04:06<03:25,  1.12s/it]Running loglikelihood requests:  55%|█████▍    | 218/400 [04:07<03:24,  1.12s/it]Running loglikelihood requests:  55%|█████▍    | 219/400 [04:08<03:23,  1.12s/it]Running loglikelihood requests:  55%|█████▌    | 220/400 [04:09<03:22,  1.12s/it]Running loglikelihood requests:  55%|█████▌    | 221/400 [04:10<03:21,  1.13s/it]Running loglikelihood requests:  56%|█████▌    | 222/400 [04:11<03:20,  1.13s/it]Running loglikelihood requests:  56%|█████▌    | 223/400 [04:13<03:19,  1.12s/it]Running loglikelihood requests:  56%|█████▌    | 224/400 [04:14<03:18,  1.13s/it]Running loglikelihood requests:  56%|█████▋    | 225/400 [04:15<03:16,  1.13s/it]Running loglikelihood requests:  56%|█████▋    | 226/400 [04:16<03:15,  1.12s/it]Running loglikelihood requests:  57%|█████▋    | 227/400 [04:17<03:14,  1.12s/it]Running loglikelihood requests:  57%|█████▋    | 228/400 [04:18<03:13,  1.12s/it]Running loglikelihood requests:  57%|█████▋    | 229/400 [04:19<03:12,  1.12s/it]Running loglikelihood requests:  57%|█████▊    | 230/400 [04:20<03:10,  1.12s/it]Running loglikelihood requests:  58%|█████▊    | 231/400 [04:22<03:09,  1.12s/it]Running loglikelihood requests:  58%|█████▊    | 232/400 [04:23<03:08,  1.12s/it]Running loglikelihood requests:  58%|█████▊    | 233/400 [04:24<03:07,  1.12s/it]Running loglikelihood requests:  58%|█████▊    | 234/400 [04:25<03:05,  1.12s/it]Running loglikelihood requests:  59%|█████▉    | 235/400 [04:26<03:04,  1.12s/it]Running loglikelihood requests:  59%|█████▉    | 236/400 [04:27<03:03,  1.12s/it]Running loglikelihood requests:  59%|█████▉    | 237/400 [04:28<03:02,  1.12s/it]Running loglikelihood requests:  60%|█████▉    | 238/400 [04:29<03:01,  1.12s/it]Running loglikelihood requests:  60%|█████▉    | 239/400 [04:30<03:00,  1.12s/it]Running loglikelihood requests:  60%|██████    | 241/400 [04:32<02:17,  1.16it/s]Running loglikelihood requests:  60%|██████    | 242/400 [04:33<02:26,  1.08it/s]Running loglikelihood requests:  61%|██████    | 243/400 [04:34<02:33,  1.02it/s]Running loglikelihood requests:  61%|██████    | 244/400 [04:35<02:38,  1.02s/it]Running loglikelihood requests:  61%|██████▏   | 245/400 [04:36<02:41,  1.04s/it]Running loglikelihood requests:  62%|██████▏   | 246/400 [04:37<02:44,  1.07s/it]Running loglikelihood requests:  62%|██████▏   | 247/400 [04:38<02:45,  1.08s/it]Running loglikelihood requests:  62%|██████▏   | 248/400 [04:39<02:45,  1.09s/it]Running loglikelihood requests:  62%|██████▏   | 249/400 [04:41<02:45,  1.10s/it]Running loglikelihood requests:  62%|██████▎   | 250/400 [04:42<02:45,  1.10s/it]Running loglikelihood requests:  63%|██████▎   | 251/400 [04:43<02:44,  1.11s/it]Running loglikelihood requests:  63%|██████▎   | 252/400 [04:44<02:44,  1.11s/it]Running loglikelihood requests:  63%|██████▎   | 253/400 [04:45<02:43,  1.11s/it]Running loglikelihood requests:  64%|██████▍   | 255/400 [04:46<02:04,  1.17it/s]Running loglikelihood requests:  64%|██████▍   | 256/400 [04:47<02:12,  1.09it/s]Running loglikelihood requests:  64%|██████▍   | 257/400 [04:48<02:18,  1.03it/s]Running loglikelihood requests:  64%|██████▍   | 258/400 [04:49<02:23,  1.01s/it]Running loglikelihood requests:  65%|██████▍   | 259/400 [04:51<02:26,  1.04s/it]Running loglikelihood requests:  65%|██████▌   | 260/400 [04:52<02:28,  1.06s/it]Running loglikelihood requests:  65%|██████▌   | 261/400 [04:53<02:29,  1.07s/it]Running loglikelihood requests:  66%|██████▌   | 262/400 [04:54<02:30,  1.09s/it]Running loglikelihood requests:  66%|██████▌   | 263/400 [04:55<02:30,  1.10s/it]Running loglikelihood requests:  66%|██████▌   | 264/400 [04:56<02:29,  1.10s/it]Running loglikelihood requests:  66%|██████▋   | 265/400 [04:57<02:28,  1.10s/it]Running loglikelihood requests:  66%|██████▋   | 266/400 [04:58<02:28,  1.11s/it]Running loglikelihood requests:  67%|██████▋   | 267/400 [04:59<02:27,  1.11s/it]Running loglikelihood requests:  67%|██████▋   | 268/400 [05:01<02:26,  1.11s/it]Running loglikelihood requests:  68%|██████▊   | 270/400 [05:02<01:50,  1.17it/s]Running loglikelihood requests:  68%|██████▊   | 271/400 [05:03<01:58,  1.09it/s]Running loglikelihood requests:  68%|██████▊   | 272/400 [05:04<02:03,  1.04it/s]Running loglikelihood requests:  68%|██████▊   | 273/400 [05:05<02:07,  1.00s/it]Running loglikelihood requests:  68%|██████▊   | 274/400 [05:06<02:09,  1.03s/it]Running loglikelihood requests:  69%|██████▉   | 275/400 [05:07<02:11,  1.05s/it]Running loglikelihood requests:  69%|██████▉   | 276/400 [05:08<02:12,  1.07s/it]Running loglikelihood requests:  69%|██████▉   | 277/400 [05:09<02:12,  1.07s/it]Running loglikelihood requests:  70%|██████▉   | 278/400 [05:10<02:11,  1.08s/it]Running loglikelihood requests:  70%|██████▉   | 279/400 [05:12<02:11,  1.09s/it]Running loglikelihood requests:  70%|███████   | 280/400 [05:13<02:10,  1.09s/it]Running loglikelihood requests:  70%|███████   | 281/400 [05:14<02:09,  1.09s/it]Running loglikelihood requests:  70%|███████   | 282/400 [05:15<02:09,  1.09s/it]Running loglikelihood requests:  71%|███████   | 283/400 [05:16<02:08,  1.10s/it]Running loglikelihood requests:  71%|███████   | 284/400 [05:17<02:07,  1.10s/it]Running loglikelihood requests:  71%|███████▏  | 285/400 [05:18<02:06,  1.10s/it]Running loglikelihood requests:  72%|███████▏  | 286/400 [05:19<02:04,  1.10s/it]Running loglikelihood requests:  72%|███████▏  | 287/400 [05:20<02:03,  1.10s/it]Running loglikelihood requests:  72%|███████▏  | 288/400 [05:21<02:02,  1.09s/it]Running loglikelihood requests:  72%|███████▏  | 289/400 [05:23<02:01,  1.09s/it]Running loglikelihood requests:  72%|███████▎  | 290/400 [05:24<02:00,  1.09s/it]Running loglikelihood requests:  73%|███████▎  | 291/400 [05:25<01:59,  1.09s/it]Running loglikelihood requests:  73%|███████▎  | 292/400 [05:26<01:58,  1.09s/it]Running loglikelihood requests:  73%|███████▎  | 293/400 [05:27<01:57,  1.09s/it]Running loglikelihood requests:  74%|███████▎  | 294/400 [05:28<01:55,  1.09s/it]Running loglikelihood requests:  74%|███████▍  | 295/400 [05:29<01:54,  1.09s/it]Running loglikelihood requests:  74%|███████▍  | 296/400 [05:30<01:53,  1.09s/it]Running loglikelihood requests:  74%|███████▍  | 297/400 [05:31<01:52,  1.09s/it]Running loglikelihood requests:  74%|███████▍  | 298/400 [05:32<01:51,  1.09s/it]Running loglikelihood requests:  75%|███████▍  | 299/400 [05:33<01:49,  1.09s/it]Running loglikelihood requests:  75%|███████▌  | 300/400 [05:35<01:48,  1.09s/it]Running loglikelihood requests:  75%|███████▌  | 301/400 [05:36<01:47,  1.09s/it]Running loglikelihood requests:  76%|███████▌  | 302/400 [05:37<01:46,  1.09s/it]Running loglikelihood requests:  76%|███████▌  | 304/400 [05:38<01:20,  1.20it/s]Running loglikelihood requests:  76%|███████▋  | 305/400 [05:39<01:25,  1.11it/s]Running loglikelihood requests:  76%|███████▋  | 306/400 [05:40<01:29,  1.06it/s]Running loglikelihood requests:  77%|███████▋  | 307/400 [05:41<01:31,  1.02it/s]Running loglikelihood requests:  77%|███████▋  | 308/400 [05:42<01:32,  1.01s/it]Running loglikelihood requests:  77%|███████▋  | 309/400 [05:43<01:33,  1.03s/it]Running loglikelihood requests:  78%|███████▊  | 310/400 [05:44<01:33,  1.04s/it]Running loglikelihood requests:  78%|███████▊  | 311/400 [05:45<01:33,  1.05s/it]Running loglikelihood requests:  78%|███████▊  | 312/400 [05:46<01:33,  1.06s/it]Running loglikelihood requests:  78%|███████▊  | 313/400 [05:48<01:32,  1.06s/it]Running loglikelihood requests:  78%|███████▊  | 314/400 [05:49<01:31,  1.07s/it]Running loglikelihood requests:  79%|███████▉  | 315/400 [05:50<01:30,  1.07s/it]Running loglikelihood requests:  79%|███████▉  | 316/400 [05:51<01:29,  1.07s/it]Running loglikelihood requests:  79%|███████▉  | 317/400 [05:52<01:28,  1.07s/it]Running loglikelihood requests:  80%|███████▉  | 318/400 [05:53<01:27,  1.07s/it]Running loglikelihood requests:  80%|███████▉  | 319/400 [05:54<01:26,  1.07s/it]Running loglikelihood requests:  80%|████████  | 320/400 [05:55<01:25,  1.07s/it]Running loglikelihood requests:  80%|████████  | 321/400 [05:56<01:24,  1.07s/it]Running loglikelihood requests:  80%|████████  | 322/400 [05:57<01:23,  1.07s/it]Running loglikelihood requests:  81%|████████  | 323/400 [05:58<01:22,  1.07s/it]Running loglikelihood requests:  81%|████████  | 324/400 [05:59<01:21,  1.07s/it]Running loglikelihood requests:  81%|████████▏ | 325/400 [06:00<01:20,  1.07s/it]Running loglikelihood requests:  82%|████████▏ | 326/400 [06:01<01:19,  1.07s/it]Running loglikelihood requests:  82%|████████▏ | 327/400 [06:03<01:18,  1.07s/it]Running loglikelihood requests:  82%|████████▏ | 328/400 [06:04<01:17,  1.07s/it]Running loglikelihood requests:  82%|████████▎ | 330/400 [06:05<00:57,  1.22it/s]Running loglikelihood requests:  83%|████████▎ | 331/400 [06:06<01:00,  1.13it/s]Running loglikelihood requests:  83%|████████▎ | 332/400 [06:07<01:03,  1.07it/s]Running loglikelihood requests:  83%|████████▎ | 333/400 [06:08<01:04,  1.04it/s]Running loglikelihood requests:  84%|████████▎ | 334/400 [06:09<01:05,  1.01it/s]Running loglikelihood requests:  84%|████████▍ | 335/400 [06:10<01:05,  1.01s/it]Running loglikelihood requests:  84%|████████▍ | 336/400 [06:11<01:05,  1.03s/it]Running loglikelihood requests:  84%|████████▍ | 337/400 [06:12<01:05,  1.04s/it]Running loglikelihood requests:  84%|████████▍ | 338/400 [06:13<01:04,  1.04s/it]Running loglikelihood requests:  85%|████████▍ | 339/400 [06:14<01:03,  1.05s/it]Running loglikelihood requests:  85%|████████▌ | 340/400 [06:15<01:03,  1.05s/it]Running loglikelihood requests:  85%|████████▌ | 341/400 [06:16<01:02,  1.05s/it]Running loglikelihood requests:  86%|████████▌ | 342/400 [06:17<01:01,  1.05s/it]Running loglikelihood requests:  86%|████████▌ | 343/400 [06:18<01:00,  1.05s/it]Running loglikelihood requests:  86%|████████▌ | 344/400 [06:19<00:59,  1.05s/it]Running loglikelihood requests:  86%|████████▋ | 345/400 [06:21<00:58,  1.06s/it]Running loglikelihood requests:  86%|████████▋ | 346/400 [06:22<00:57,  1.06s/it]Running loglikelihood requests:  87%|████████▋ | 347/400 [06:23<00:55,  1.06s/it]Running loglikelihood requests:  87%|████████▋ | 348/400 [06:24<00:54,  1.06s/it]Running loglikelihood requests:  87%|████████▋ | 349/400 [06:25<00:53,  1.05s/it]Running loglikelihood requests:  88%|████████▊ | 350/400 [06:26<00:52,  1.05s/it]Running loglikelihood requests:  88%|████████▊ | 351/400 [06:27<00:51,  1.05s/it]Running loglikelihood requests:  88%|████████▊ | 352/400 [06:28<00:50,  1.04s/it]Running loglikelihood requests:  88%|████████▊ | 353/400 [06:29<00:49,  1.04s/it]Running loglikelihood requests:  88%|████████▊ | 354/400 [06:30<00:47,  1.04s/it]Running loglikelihood requests:  89%|████████▉ | 355/400 [06:31<00:46,  1.04s/it]Running loglikelihood requests:  89%|████████▉ | 356/400 [06:32<00:45,  1.04s/it]Running loglikelihood requests:  89%|████████▉ | 357/400 [06:33<00:44,  1.04s/it]Running loglikelihood requests:  90%|████████▉ | 358/400 [06:34<00:43,  1.04s/it]Running loglikelihood requests:  90%|████████▉ | 359/400 [06:35<00:42,  1.04s/it]Running loglikelihood requests:  90%|█████████ | 360/400 [06:36<00:41,  1.03s/it]Running loglikelihood requests:  90%|█████████ | 361/400 [06:37<00:40,  1.03s/it]Running loglikelihood requests:  90%|█████████ | 362/400 [06:38<00:39,  1.03s/it]Running loglikelihood requests:  91%|█████████ | 363/400 [06:39<00:37,  1.03s/it]Running loglikelihood requests:  91%|█████████ | 364/400 [06:40<00:36,  1.02s/it]Running loglikelihood requests:  91%|█████████▏| 365/400 [06:41<00:35,  1.02s/it]Running loglikelihood requests:  92%|█████████▏| 366/400 [06:42<00:34,  1.02s/it]Running loglikelihood requests:  92%|█████████▏| 367/400 [06:43<00:33,  1.02s/it]Running loglikelihood requests:  92%|█████████▏| 368/400 [06:44<00:32,  1.02s/it]Running loglikelihood requests:  92%|█████████▏| 369/400 [06:45<00:31,  1.02s/it]Running loglikelihood requests:  92%|█████████▎| 370/400 [06:46<00:30,  1.02s/it]Running loglikelihood requests:  93%|█████████▎| 371/400 [06:47<00:29,  1.02s/it]Running loglikelihood requests:  93%|█████████▎| 372/400 [06:48<00:28,  1.02s/it]Running loglikelihood requests:  93%|█████████▎| 373/400 [06:49<00:27,  1.02s/it]Running loglikelihood requests:  94%|█████████▎| 374/400 [06:50<00:26,  1.02s/it]Running loglikelihood requests:  94%|█████████▍| 375/400 [06:51<00:25,  1.01s/it]Running loglikelihood requests:  94%|█████████▍| 376/400 [06:52<00:24,  1.01s/it]Running loglikelihood requests:  94%|█████████▍| 377/400 [06:53<00:23,  1.01s/it]Running loglikelihood requests:  94%|█████████▍| 378/400 [06:54<00:22,  1.00s/it]Running loglikelihood requests:  95%|█████████▍| 379/400 [06:55<00:21,  1.00s/it]Running loglikelihood requests:  95%|█████████▌| 380/400 [06:56<00:20,  1.00s/it]Running loglikelihood requests:  95%|█████████▌| 381/400 [06:57<00:18,  1.00it/s]Running loglikelihood requests:  96%|█████████▌| 382/400 [06:58<00:17,  1.00it/s]Running loglikelihood requests:  96%|█████████▌| 383/400 [06:59<00:16,  1.00it/s]Running loglikelihood requests:  96%|█████████▌| 384/400 [07:00<00:15,  1.00it/s]Running loglikelihood requests:  96%|█████████▋| 385/400 [07:01<00:14,  1.00it/s]Running loglikelihood requests:  96%|█████████▋| 386/400 [07:02<00:13,  1.01it/s]Running loglikelihood requests:  97%|█████████▋| 387/400 [07:03<00:12,  1.01it/s]Running loglikelihood requests:  97%|█████████▋| 388/400 [07:04<00:11,  1.01it/s]Running loglikelihood requests:  97%|█████████▋| 389/400 [07:05<00:10,  1.01it/s]Running loglikelihood requests:  98%|█████████▊| 390/400 [07:06<00:09,  1.01it/s]Running loglikelihood requests:  98%|█████████▊| 391/400 [07:07<00:08,  1.01it/s]Running loglikelihood requests:  98%|█████████▊| 392/400 [07:08<00:07,  1.01it/s]Running loglikelihood requests:  98%|█████████▊| 393/400 [07:09<00:06,  1.01it/s]Running loglikelihood requests:  98%|█████████▊| 394/400 [07:10<00:05,  1.01it/s]Running loglikelihood requests:  99%|█████████▉| 395/400 [07:11<00:04,  1.01it/s]Running loglikelihood requests:  99%|█████████▉| 396/400 [07:12<00:03,  1.01it/s]Running loglikelihood requests:  99%|█████████▉| 397/400 [07:13<00:02,  1.02it/s]Running loglikelihood requests: 100%|█████████▉| 398/400 [07:14<00:01,  1.02it/s]Running loglikelihood requests: 100%|█████████▉| 399/400 [07:15<00:00,  1.03it/s]Running loglikelihood requests: 100%|██████████| 400/400 [07:16<00:00,  1.03it/s]Running loglikelihood requests: 100%|██████████| 400/400 [07:16<00:00,  1.09s/it]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:6'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:6'}
full model:
{'mastermind_35_easy': {'alias': 'mastermind_35_easy', 'acc,none': 0.51, 'acc_stderr,none': 0.05024183937956913}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9685093904417202
0.9837389482734848
0.9887891422859466
0.9728424941793791
0.9273096247071001
0.9956884174036557
0.9936991917224709
0.990637728847171
0.984416562505352
0.9357041463019401
0.957486187236088
0.9794440444506461
0.9854000882321717
0.989321120949945
0.9948124947717892
0.9950699411775289
0.9589145403056732
0.9488498047330014
0.979093344902028
0.9861615563222426
0.9944647439314634
0.9974738465425171
0.9932459641322177
0.9612113452387381
0.9566187588663586
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[5, 1, 0, 3, 7, 6, 2, 4]
tensor([5, 1, 0, 3, 7, 6, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 0, 3, 7, 5, 2, 4]
tensor([6, 1, 0, 3, 7, 5, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 1, 0, 3, 7, 6, 2, 4]
tensor([5, 1, 0, 3, 7, 6, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 0, 3, 7, 5, 2, 4]
tensor([6, 1, 0, 3, 7, 5, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 1, 0, 3, 7, 6, 2, 4]
tensor([5, 1, 0, 3, 7, 6, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 0, 3, 7, 5, 2, 4]
tensor([6, 1, 0, 3, 7, 5, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Normal merging for layer 2
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Normal merging for layer 3
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Normal merging for layer 4
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Normal merging for layer 5
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 6 to 31
done!
all done!
Model size: 12.0718 GB
55
cuda:6
coqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:41<00:41, 41.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 24.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 27.19s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa HTTP/1.1" 200 846
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/EleutherAI/coqa/EleutherAI/coqa.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa HTTP/1.1" 200 857
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/coqa/resolve/82e11af842af6c1396f5e9a5c7de260107c50cf1/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa/tree/82e11af842af6c1396f5e9a5c7de260107c50cf1/data?recursive=False&expand=False HTTP/1.1" 404 79
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa/tree/82e11af842af6c1396f5e9a5c7de260107c50cf1/data?recursive=False&expand=False HTTP/1.1" 404 79
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa/revision/82e11af842af6c1396f5e9a5c7de260107c50cf1 HTTP/1.1" 200 857
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/coqa/resolve/82e11af842af6c1396f5e9a5c7de260107c50cf1/dataset_infos.json HTTP/1.1" 200 0
DEBUG:filelock:Attempting to acquire lock 140237193342288 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___coqa_default_0.0.0_82e11af842af6c1396f5e9a5c7de260107c50cf1.lock
DEBUG:filelock:Lock 140237193342288 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___coqa_default_0.0.0_82e11af842af6c1396f5e9a5c7de260107c50cf1.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1/dataset_info.json
DEBUG:filelock:Attempting to release lock 140237193342288 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___coqa_default_0.0.0_82e11af842af6c1396f5e9a5c7de260107c50cf1.lock
DEBUG:filelock:Lock 140237193342288 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___coqa_default_0.0.0_82e11af842af6c1396f5e9a5c7de260107c50cf1.lock
DEBUG:filelock:Attempting to acquire lock 140237333019056 on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1_builder.lock
DEBUG:filelock:Lock 140237333019056 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1/dataset_info.json
DEBUG:filelock:Attempting to release lock 140237333019056 on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1_builder.lock
DEBUG:filelock:Lock 140237333019056 released on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
DEBUG:lm_eval.api.task:doc_to_target returned a list. Assuming multiple targets.
INFO:lm_eval.evaluator:coqa: Using gen_kwargs: {'until': ['\nQ:']}
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of coqa from None to 0
INFO:lm_eval.api.task:Building contexts for coqa on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 72969.80it/s]
DEBUG:lm_eval.evaluator:Task: coqa; number of requests on this rank: 100
INFO:lm_eval.evaluator:Running generate_until requests
Running generate_until requests:   0%|          | 0/100 [00:00<?, ?it/s]Running generate_until requests:   1%|          | 1/100 [00:05<09:42,  5.89s/it]Running generate_until requests:   2%|▏         | 2/100 [00:10<08:48,  5.39s/it]Running generate_until requests:   3%|▎         | 3/100 [00:17<09:13,  5.71s/it]Running generate_until requests:   4%|▍         | 4/100 [00:21<08:36,  5.38s/it]Running generate_until requests:   5%|▌         | 5/100 [00:26<08:20,  5.27s/it]Running generate_until requests:   6%|▌         | 6/100 [00:31<07:54,  5.05s/it]Running generate_until requests:   7%|▋         | 7/100 [00:37<08:05,  5.23s/it]Running generate_until requests:   8%|▊         | 8/100 [00:41<07:43,  5.04s/it]Running generate_until requests:   9%|▉         | 9/100 [00:46<07:36,  5.02s/it]Running generate_until requests:  10%|█         | 10/100 [00:52<07:43,  5.15s/it]Running generate_until requests:  11%|█         | 11/100 [00:57<07:35,  5.12s/it]Running generate_until requests:  12%|█▏        | 12/100 [01:03<07:58,  5.44s/it]Running generate_until requests:  13%|█▎        | 13/100 [01:07<07:26,  5.13s/it]Running generate_until requests:  14%|█▍        | 14/100 [01:12<07:02,  4.91s/it]Running generate_until requests:  15%|█▌        | 15/100 [01:16<06:50,  4.83s/it]Running generate_until requests:  16%|█▌        | 16/100 [01:21<06:33,  4.69s/it]Running generate_until requests:  17%|█▋        | 17/100 [01:25<06:24,  4.63s/it]Running generate_until requests:  18%|█▊        | 18/100 [01:29<06:09,  4.51s/it]Running generate_until requests:  19%|█▉        | 19/100 [01:34<06:04,  4.49s/it]Running generate_until requests:  20%|██        | 20/100 [01:38<05:55,  4.44s/it]Running generate_until requests:  21%|██        | 21/100 [01:43<05:50,  4.44s/it]Running generate_until requests:  22%|██▏       | 22/100 [01:47<05:42,  4.40s/it]Running generate_until requests:  23%|██▎       | 23/100 [01:52<05:59,  4.67s/it]Running generate_until requests:  24%|██▍       | 24/100 [01:57<06:06,  4.82s/it]Running generate_until requests:  25%|██▌       | 25/100 [02:02<05:48,  4.65s/it]Running generate_until requests:  26%|██▌       | 26/100 [02:06<05:43,  4.64s/it]Running generate_until requests:  27%|██▋       | 27/100 [02:11<05:38,  4.63s/it]Running generate_until requests:  28%|██▊       | 28/100 [02:15<05:30,  4.58s/it]Running generate_until requests:  29%|██▉       | 29/100 [02:20<05:22,  4.54s/it]Running generate_until requests:  30%|███       | 30/100 [02:24<05:18,  4.56s/it]Running generate_until requests:  31%|███       | 31/100 [02:29<05:03,  4.40s/it]Running generate_until requests:  32%|███▏      | 32/100 [02:33<05:04,  4.48s/it]Running generate_until requests:  33%|███▎      | 33/100 [02:38<05:01,  4.50s/it]Running generate_until requests:  34%|███▍      | 34/100 [02:42<04:54,  4.47s/it]Running generate_until requests:  35%|███▌      | 35/100 [02:46<04:41,  4.33s/it]Running generate_until requests:  36%|███▌      | 36/100 [02:52<05:00,  4.70s/it]Running generate_until requests:  37%|███▋      | 37/100 [02:56<04:42,  4.48s/it]Running generate_until requests:  38%|███▊      | 38/100 [03:00<04:28,  4.33s/it]Running generate_until requests:  39%|███▉      | 39/100 [03:04<04:21,  4.29s/it]Running generate_until requests:  40%|████      | 40/100 [03:08<04:10,  4.17s/it]Running generate_until requests:  41%|████      | 41/100 [03:12<04:05,  4.17s/it]Running generate_until requests:  42%|████▏     | 42/100 [03:17<04:26,  4.59s/it]Running generate_until requests:  43%|████▎     | 43/100 [03:22<04:16,  4.51s/it]Running generate_until requests:  44%|████▍     | 44/100 [03:26<04:11,  4.49s/it]Running generate_until requests:  45%|████▌     | 45/100 [03:31<04:03,  4.43s/it]Running generate_until requests:  46%|████▌     | 46/100 [03:34<03:50,  4.27s/it]Running generate_until requests:  47%|████▋     | 47/100 [03:38<03:40,  4.15s/it]Running generate_until requests:  48%|████▊     | 48/100 [03:43<03:39,  4.22s/it]Running generate_until requests:  49%|████▉     | 49/100 [03:48<03:45,  4.42s/it]Running generate_until requests:  50%|█████     | 50/100 [03:51<03:32,  4.25s/it]Running generate_until requests:  51%|█████     | 51/100 [03:56<03:37,  4.44s/it]Running generate_until requests:  52%|█████▏    | 52/100 [04:00<03:24,  4.25s/it]Running generate_until requests:  53%|█████▎    | 53/100 [04:05<03:22,  4.31s/it]Running generate_until requests:  54%|█████▍    | 54/100 [04:08<03:11,  4.15s/it]Running generate_until requests:  55%|█████▌    | 55/100 [04:13<03:07,  4.17s/it]Running generate_until requests:  56%|█████▌    | 56/100 [04:17<03:08,  4.28s/it]Running generate_until requests:  57%|█████▋    | 57/100 [04:21<03:04,  4.29s/it]Running generate_until requests:  58%|█████▊    | 58/100 [04:25<02:53,  4.13s/it]Running generate_until requests:  59%|█████▉    | 59/100 [04:30<03:00,  4.40s/it]Running generate_until requests:  60%|██████    | 60/100 [04:34<02:48,  4.20s/it]Running generate_until requests:  61%|██████    | 61/100 [04:39<02:49,  4.36s/it]Running generate_until requests:  62%|██████▏   | 62/100 [04:43<02:49,  4.46s/it]Running generate_until requests:  63%|██████▎   | 63/100 [04:47<02:36,  4.22s/it]Running generate_until requests:  64%|██████▍   | 64/100 [04:51<02:25,  4.05s/it]Running generate_until requests:  65%|██████▌   | 65/100 [04:54<02:17,  3.92s/it]Running generate_until requests:  66%|██████▌   | 66/100 [04:58<02:10,  3.83s/it]Running generate_until requests:  67%|██████▋   | 67/100 [05:01<02:03,  3.75s/it]Running generate_until requests:  68%|██████▊   | 68/100 [05:06<02:04,  3.88s/it]Running generate_until requests:  69%|██████▉   | 69/100 [05:11<02:16,  4.40s/it]Running generate_until requests:  70%|███████   | 70/100 [05:15<02:08,  4.30s/it]Running generate_until requests:  71%|███████   | 71/100 [05:24<02:39,  5.50s/it]Running generate_until requests:  72%|███████▏  | 72/100 [05:27<02:16,  4.89s/it]Running generate_until requests:  73%|███████▎  | 73/100 [05:31<02:01,  4.50s/it]Running generate_until requests:  74%|███████▍  | 74/100 [05:35<01:52,  4.33s/it]Running generate_until requests:  75%|███████▌  | 75/100 [05:38<01:42,  4.09s/it]Running generate_until requests:  76%|███████▌  | 76/100 [05:42<01:33,  3.92s/it]Running generate_until requests:  77%|███████▋  | 77/100 [05:46<01:34,  4.10s/it]Running generate_until requests:  78%|███████▊  | 78/100 [05:50<01:27,  3.96s/it]Running generate_until requests:  79%|███████▉  | 79/100 [05:53<01:19,  3.77s/it]Running generate_until requests:  80%|████████  | 80/100 [05:57<01:15,  3.79s/it]Running generate_until requests:  81%|████████  | 81/100 [06:03<01:22,  4.35s/it]Running generate_until requests:  82%|████████▏ | 82/100 [06:06<01:12,  4.04s/it]Running generate_until requests:  83%|████████▎ | 83/100 [06:10<01:06,  3.92s/it]Running generate_until requests:  84%|████████▍ | 84/100 [06:13<00:59,  3.72s/it]Running generate_until requests:  85%|████████▌ | 85/100 [06:16<00:53,  3.56s/it]Running generate_until requests:  86%|████████▌ | 86/100 [06:19<00:49,  3.52s/it]Running generate_until requests:  87%|████████▋ | 87/100 [06:24<00:48,  3.77s/it]Running generate_until requests:  88%|████████▊ | 88/100 [06:27<00:44,  3.69s/it]Running generate_until requests:  89%|████████▉ | 89/100 [06:30<00:38,  3.48s/it]Running generate_until requests:  90%|█████████ | 90/100 [06:33<00:33,  3.30s/it]Running generate_until requests:  91%|█████████ | 91/100 [06:36<00:28,  3.14s/it]Running generate_until requests:  92%|█████████▏| 92/100 [06:39<00:24,  3.04s/it]Running generate_until requests:  93%|█████████▎| 93/100 [06:42<00:21,  3.00s/it]Running generate_until requests:  94%|█████████▍| 94/100 [06:45<00:18,  3.01s/it]Running generate_until requests:  95%|█████████▌| 95/100 [06:48<00:15,  3.08s/it]Running generate_until requests:  96%|█████████▌| 96/100 [06:51<00:12,  3.08s/it]Running generate_until requests:  97%|█████████▋| 97/100 [06:54<00:08,  2.91s/it]Running generate_until requests:  98%|█████████▊| 98/100 [06:56<00:05,  2.79s/it]Running generate_until requests:  99%|█████████▉| 99/100 [06:59<00:02,  2.78s/it]Running generate_until requests: 100%|██████████| 100/100 [07:02<00:00,  2.78s/it]Running generate_until requests: 100%|██████████| 100/100 [07:02<00:00,  4.22s/it]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:7'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:7'}
full model:
{'coqa': {'alias': 'coqa', 'em,none': 0.595, 'em_stderr,none': 0.044774970461162564, 'f1,none': 0.7211574141733987, 'f1_stderr,none': 0.037128235455690536}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.6057853926542468
0.4195568875297668
0.5244744113321889
0.5202703028806769
0.6150870974034927
0.5299634576457063
0.9336763524510373
0.23649940737178063
0.388911200696845
0.6478041116722705
0.5517233675449297
0.6723258763091353
0.7175526480521238
0.8411089149883405
0.7404554224148189
0.26376935916880817
0.9373006475493478
0.5360566853939598
0.38729358133282565
0.4541602442018795
0.8623573205888978
0.7318340566806717
0.6643209906079897
0.8122565195147101
0.4707270481319977
0.9785001455445378
0.17075087907531752
0.489625917805058
0.7595051272431785
0.6057853926542468
0.4195568875297668
0.5244744113321889
0.5202703028806769
0.6150870974034927
0.5299634576457063
0.9336763524510373
0.23649940737178063
0.388911200696845
0.6478041116722705
0.5517233675449297
0.6723258763091353
0.7175526480521238
0.8411089149883405
0.7404554224148189
0.26376935916880817
0.9373006475493478
0.5360566853939598
0.38729358133282565
0.4541602442018795
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[5, 4, 3, 2, 0, 1, 7, 6]
tensor([5, 4, 3, 2, 0, 1, 7, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 3, 4, 0, 2, 1, 7, 6]
tensor([5, 3, 4, 0, 2, 1, 7, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 1, 7, 0, 6, 2, 3, 4]
tensor([5, 1, 7, 0, 6, 2, 3, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 3, 6, 0, 5, 2, 4, 1]
tensor([7, 3, 6, 0, 5, 2, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 5, 7, 2, 4, 0, 3, 1]
tensor([6, 5, 7, 2, 4, 0, 3, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 5, 0, 0, 1, 2, 1, 3]
tensor([4, 5, 0, 0, 1, 2, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1, 2, 2, 0, 3, 3]
tensor([0, 1, 1, 2, 2, 0, 3, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([7])
tensor(7)
tensor([6])
tensor(6)
done!
Normal merging for layer 2
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
done!
Normal merging for layer 4
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Cross-layer merge completed for layers 5 to 8
done!
Normal merging for layer 9
tensor([2, 3])
tensor(2)
tensor([4, 6])
tensor(4)
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([1])
tensor(1)
done!
Cross-layer merge completed for layers 10 to 22
done!
Normal merging for layer 23
tensor([0, 5])
tensor(0)
tensor([1, 2])
tensor(1)
tensor([3, 4])
tensor(3)
tensor([6, 7])
tensor(6)
done!
Cross-layer merge completed for layers 24 to 31
done!
all done!
Model size: 12.3238 GB
9
cuda:7
rte
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:41<00:41, 41.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 24.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 27.28s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: rte] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: rte] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/revision/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 111
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/revision/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c?recursive=False&expand=False HTTP/1.1" 307 136
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c?recursive=False&expand=False HTTP/1.1" 200 530
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/ax?recursive=False&expand=False HTTP/1.1" 307 139
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/ax?recursive=False&expand=False HTTP/1.1" 200 231
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/revision/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 111
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/revision/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/rte?recursive=False&expand=False HTTP/1.1" 307 140
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/rte?recursive=False&expand=False HTTP/1.1" 200 354
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:filelock:Attempting to acquire lock 140243030547280 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140243030547280 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140243030547280 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140243030547280 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140243030547280 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140243030547280 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140243030547280 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140243030547280 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of rte from None to 0
INFO:lm_eval.api.task:Building contexts for rte on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 2530.21it/s]
DEBUG:lm_eval.evaluator:Task: rte; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:02<06:53,  2.08s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:03<03:33,  1.09s/it]Running loglikelihood requests:   2%|▎         | 5/200 [00:04<02:46,  1.17it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:06<02:26,  1.32it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:07<02:15,  1.41it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:08<02:07,  1.48it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:09<02:02,  1.53it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:10<01:58,  1.57it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:12<01:54,  1.60it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:13<01:51,  1.63it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:14<01:47,  1.67it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:15<01:44,  1.70it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:16<01:41,  1.73it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:17<01:37,  1.77it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:18<01:34,  1.80it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:19<01:32,  1.83it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:20<01:30,  1.85it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:22<01:28,  1.87it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:23<01:26,  1.89it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:24<01:24,  1.91it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:25<01:21,  1.94it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:26<01:19,  1.98it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:26<01:16,  2.02it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:27<01:14,  2.06it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:28<01:11,  2.10it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:29<01:09,  2.16it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:30<01:06,  2.21it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:31<01:04,  2.26it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:32<01:01,  2.32it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:32<00:59,  2.36it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:33<00:58,  2.40it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:34<00:56,  2.43it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:35<00:54,  2.46it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:36<00:53,  2.49it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:36<00:52,  2.52it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:37<00:50,  2.54it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:38<00:49,  2.55it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:39<00:48,  2.58it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:39<00:47,  2.61it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:40<00:45,  2.64it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:41<00:44,  2.66it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:42<00:43,  2.68it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:42<00:42,  2.70it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:43<00:41,  2.72it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:44<00:40,  2.74it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:45<00:39,  2.76it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:45<00:38,  2.79it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:46<00:37,  2.80it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:47<00:36,  2.82it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:47<00:35,  2.84it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:48<00:34,  2.85it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:49<00:33,  2.86it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:49<00:32,  2.88it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:50<00:32,  2.90it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:51<00:31,  2.92it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:51<00:30,  2.93it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:52<00:29,  2.94it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:53<00:28,  2.95it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:53<00:28,  2.96it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:54<00:27,  2.96it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:55<00:26,  2.97it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:55<00:25,  2.98it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:56<00:25,  2.99it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [00:57<00:24,  3.00it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [00:57<00:23,  2.99it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [00:58<00:22,  3.00it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [00:59<00:22,  3.03it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [00:59<00:21,  3.07it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [01:00<00:20,  3.09it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [01:01<00:19,  3.11it/s]Running loglikelihood requests:  70%|███████   | 141/200 [01:01<00:18,  3.13it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [01:02<00:18,  3.15it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [01:03<00:17,  3.16it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [01:03<00:16,  3.17it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [01:04<00:16,  3.18it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [01:04<00:15,  3.19it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [01:05<00:14,  3.20it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [01:06<00:14,  3.21it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [01:06<00:13,  3.23it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [01:07<00:12,  3.26it/s]Running loglikelihood requests:  80%|████████  | 161/200 [01:08<00:11,  3.28it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [01:08<00:11,  3.30it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [01:09<00:10,  3.31it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [01:09<00:09,  3.33it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [01:10<00:09,  3.35it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [01:10<00:08,  3.38it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [01:11<00:07,  3.39it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [01:12<00:07,  3.41it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [01:12<00:06,  3.42it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [01:13<00:06,  3.43it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [01:13<00:05,  3.44it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [01:14<00:04,  3.46it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [01:15<00:04,  3.47it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [01:15<00:03,  3.48it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [01:16<00:03,  3.50it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [01:16<00:02,  3.51it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [01:17<00:01,  3.53it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:17<00:01,  3.56it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:18<00:00,  3.64it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:18<00:00,  3.70it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:18<00:00,  2.54it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:0'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}
full model:
{'rte': {'alias': 'rte', 'acc,none': 0.5, 'acc_stderr,none': 0.050251890762960605}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.34161229456626735
0.905233410256777
0.5205040718697735
0.4121994254524892
0.7398116665887099
0.6225415196831932
0.7923970242263771
0.7353888240887675
0.6535613357308766
0.7757058271862038
0.734046359122903
0.4471799126982846
0.773619360921301
0.7955347039939479
0.8672068064531693
0.8652880343596522
0.3302235467760883
0.6789268064017625
0.6072221471952108
0.9194446824778495
0.4812004589187253
0.5728915095234594
0.1682455054057436
0.93212414632396
0.9148362604533635
0.8268537756297094
0.7592245907029287
0.7256008379011685
0.7109756105942956
0.34161229456626735
0.905233410256777
0.5205040718697735
0.4121994254524892
0.7398116665887099
0.6225415196831932
0.7923970242263771
0.7353888240887675
0.6535613357308766
0.7757058271862038
0.734046359122903
0.4471799126982846
0.773619360921301
0.7955347039939479
0.8672068064531693
0.8652880343596522
0.3302235467760883
0.6789268064017625
0.6072221471952108
0.9194446824778495
0.4812004589187253
Total groups 73 exceeded the threshold, stopping comparison.
The group tensor is
[5, 2, 7, 1, 6, 4, 3, 0]
tensor([5, 2, 7, 1, 6, 4, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 6, 0, 7, 3, 4, 1]
tensor([5, 2, 6, 0, 7, 3, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 7, 2, 5, 4, 3, 0]
tensor([6, 1, 7, 2, 5, 4, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 7, 2, 4, 1, 5, 0]
tensor([6, 3, 7, 2, 4, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 5, 6, 2, 3, 1, 4, 0]
tensor([7, 5, 6, 2, 3, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 2, 5, 4, 1, 0, 1, 3]
tensor([0, 2, 5, 4, 1, 0, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1.0, 1.0, 0, 1.0, 1]
tensor([0, 1, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
Normal merging for layer 1
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Normal merging for layer 2
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 4
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 5 to 8
done!
Normal merging for layer 9
tensor([0, 5])
tensor(0)
tensor([4, 6])
tensor(4)
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
done!
Cross-layer merge completed for layers 10 to 30
done!
Normal merging for layer 31
tensor([0, 5])
tensor(0)
tensor([1, 2, 3, 4, 6, 7])
tensor(1)
done!
all done!
Model size: 12.1348 GB
99
cuda:0
mastermind_46_easy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:40<00:40, 40.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:52<00:00, 23.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:52<00:00, 26.23s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_46_mcq_random HTTP/1.1" 200 778
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/flair/mastermind_46_mcq_random/flair/mastermind_46_mcq_random.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_46_mcq_random HTTP/1.1" 200 786
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/flair/mastermind_46_mcq_random/resolve/544d077942975b1664c0bc4fd54df026050329a4/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_46_mcq_random/revision/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 786
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_46_mcq_random/tree/544d077942975b1664c0bc4fd54df026050329a4?recursive=False&expand=False HTTP/1.1" 200 290
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_46_mcq_random/tree/544d077942975b1664c0bc4fd54df026050329a4/data?recursive=False&expand=False HTTP/1.1" 200 361
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_46_mcq_random/revision/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 786
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/flair/mastermind_46_mcq_random/resolve/544d077942975b1664c0bc4fd54df026050329a4/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:filelock:Attempting to acquire lock 140240017480672 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_46_mcq_random_default_0.0.0_544d077942975b1664c0bc4fd54df026050329a4.lock
DEBUG:filelock:Lock 140240017480672 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_46_mcq_random_default_0.0.0_544d077942975b1664c0bc4fd54df026050329a4.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_46_mcq_random/default/0.0.0/544d077942975b1664c0bc4fd54df026050329a4/dataset_info.json
DEBUG:filelock:Attempting to release lock 140240017480672 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_46_mcq_random_default_0.0.0_544d077942975b1664c0bc4fd54df026050329a4.lock
DEBUG:filelock:Lock 140240017480672 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_46_mcq_random_default_0.0.0_544d077942975b1664c0bc4fd54df026050329a4.lock
DEBUG:filelock:Attempting to acquire lock 140237193307072 on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_46_mcq_random/default/0.0.0/544d077942975b1664c0bc4fd54df026050329a4_builder.lock
DEBUG:filelock:Lock 140237193307072 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_46_mcq_random/default/0.0.0/544d077942975b1664c0bc4fd54df026050329a4_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_46_mcq_random/default/0.0.0/544d077942975b1664c0bc4fd54df026050329a4/dataset_info.json
DEBUG:filelock:Attempting to release lock 140237193307072 on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_46_mcq_random/default/0.0.0/544d077942975b1664c0bc4fd54df026050329a4_builder.lock
DEBUG:filelock:Lock 140237193307072 released on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_46_mcq_random/default/0.0.0/544d077942975b1664c0bc4fd54df026050329a4_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mastermind_46_easy from None to 0
INFO:lm_eval.api.task:Building contexts for mastermind_46_easy on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1520.01it/s]
DEBUG:lm_eval.evaluator:Task: mastermind_46_easy; number of requests on this rank: 400
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/400 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/400 [00:01<13:15,  1.99s/it]Running loglikelihood requests:   0%|          | 2/400 [00:03<10:55,  1.65s/it]Running loglikelihood requests:   1%|          | 3/400 [00:04<10:07,  1.53s/it]Running loglikelihood requests:   1%|          | 4/400 [00:06<09:44,  1.48s/it]Running loglikelihood requests:   1%|▏         | 5/400 [00:07<09:31,  1.45s/it]Running loglikelihood requests:   2%|▏         | 6/400 [00:08<09:23,  1.43s/it]Running loglikelihood requests:   2%|▏         | 7/400 [00:10<09:17,  1.42s/it]Running loglikelihood requests:   2%|▏         | 8/400 [00:11<09:11,  1.41s/it]Running loglikelihood requests:   2%|▏         | 9/400 [00:13<09:08,  1.40s/it]Running loglikelihood requests:   2%|▎         | 10/400 [00:14<09:15,  1.42s/it]Running loglikelihood requests:   3%|▎         | 11/400 [00:16<09:09,  1.41s/it]Running loglikelihood requests:   3%|▎         | 12/400 [00:17<09:05,  1.40s/it]Running loglikelihood requests:   3%|▎         | 13/400 [00:18<09:01,  1.40s/it]Running loglikelihood requests:   4%|▎         | 14/400 [00:20<08:58,  1.40s/it]Running loglikelihood requests:   4%|▍         | 15/400 [00:21<08:56,  1.39s/it]Running loglikelihood requests:   4%|▍         | 16/400 [00:22<08:53,  1.39s/it]Running loglikelihood requests:   4%|▍         | 17/400 [00:24<08:51,  1.39s/it]Running loglikelihood requests:   4%|▍         | 18/400 [00:25<08:49,  1.39s/it]Running loglikelihood requests:   5%|▍         | 19/400 [00:27<08:47,  1.39s/it]Running loglikelihood requests:   5%|▌         | 20/400 [00:28<08:46,  1.38s/it]Running loglikelihood requests:   5%|▌         | 21/400 [00:29<08:44,  1.38s/it]Running loglikelihood requests:   6%|▌         | 22/400 [00:31<08:43,  1.38s/it]Running loglikelihood requests:   6%|▌         | 23/400 [00:32<08:41,  1.38s/it]Running loglikelihood requests:   6%|▌         | 24/400 [00:33<08:40,  1.38s/it]Running loglikelihood requests:   6%|▋         | 25/400 [00:35<08:38,  1.38s/it]Running loglikelihood requests:   6%|▋         | 26/400 [00:36<08:36,  1.38s/it]Running loglikelihood requests:   7%|▋         | 27/400 [00:38<08:34,  1.38s/it]Running loglikelihood requests:   7%|▋         | 28/400 [00:39<08:33,  1.38s/it]Running loglikelihood requests:   7%|▋         | 29/400 [00:40<08:32,  1.38s/it]Running loglikelihood requests:   8%|▊         | 30/400 [00:42<08:30,  1.38s/it]Running loglikelihood requests:   8%|▊         | 31/400 [00:43<08:29,  1.38s/it]Running loglikelihood requests:   8%|▊         | 32/400 [00:45<08:27,  1.38s/it]Running loglikelihood requests:   8%|▊         | 33/400 [00:46<08:25,  1.38s/it]Running loglikelihood requests:   8%|▊         | 34/400 [00:47<08:23,  1.38s/it]Running loglikelihood requests:   9%|▉         | 35/400 [00:49<08:21,  1.38s/it]Running loglikelihood requests:   9%|▉         | 36/400 [00:50<08:19,  1.37s/it]Running loglikelihood requests:   9%|▉         | 37/400 [00:51<08:18,  1.37s/it]Running loglikelihood requests:  10%|▉         | 38/400 [00:53<08:16,  1.37s/it]Running loglikelihood requests:  10%|▉         | 39/400 [00:54<08:15,  1.37s/it]Running loglikelihood requests:  10%|█         | 40/400 [00:56<08:13,  1.37s/it]Running loglikelihood requests:  10%|█         | 41/400 [00:57<08:11,  1.37s/it]Running loglikelihood requests:  10%|█         | 42/400 [00:58<08:10,  1.37s/it]Running loglikelihood requests:  11%|█         | 43/400 [01:00<08:09,  1.37s/it]Running loglikelihood requests:  11%|█         | 44/400 [01:01<08:07,  1.37s/it]Running loglikelihood requests:  11%|█▏        | 45/400 [01:02<08:06,  1.37s/it]Running loglikelihood requests:  12%|█▏        | 46/400 [01:04<08:05,  1.37s/it]Running loglikelihood requests:  12%|█▏        | 47/400 [01:05<08:03,  1.37s/it]Running loglikelihood requests:  12%|█▏        | 48/400 [01:06<08:02,  1.37s/it]Running loglikelihood requests:  12%|█▏        | 49/400 [01:08<08:00,  1.37s/it]Running loglikelihood requests:  12%|█▎        | 50/400 [01:09<07:59,  1.37s/it]Running loglikelihood requests:  13%|█▎        | 51/400 [01:11<07:57,  1.37s/it]Running loglikelihood requests:  13%|█▎        | 52/400 [01:12<07:55,  1.37s/it]Running loglikelihood requests:  13%|█▎        | 53/400 [01:13<07:53,  1.37s/it]Running loglikelihood requests:  14%|█▎        | 54/400 [01:15<07:52,  1.37s/it]Running loglikelihood requests:  14%|█▍        | 55/400 [01:16<07:50,  1.36s/it]Running loglikelihood requests:  14%|█▍        | 56/400 [01:17<07:49,  1.36s/it]Running loglikelihood requests:  14%|█▍        | 57/400 [01:19<07:47,  1.36s/it]Running loglikelihood requests:  14%|█▍        | 58/400 [01:20<07:45,  1.36s/it]Running loglikelihood requests:  15%|█▍        | 59/400 [01:21<07:44,  1.36s/it]Running loglikelihood requests:  15%|█▌        | 60/400 [01:23<07:42,  1.36s/it]Running loglikelihood requests:  15%|█▌        | 61/400 [01:24<07:40,  1.36s/it]Running loglikelihood requests:  16%|█▌        | 62/400 [01:26<07:39,  1.36s/it]Running loglikelihood requests:  16%|█▌        | 63/400 [01:27<07:38,  1.36s/it]Running loglikelihood requests:  16%|█▌        | 64/400 [01:28<07:40,  1.37s/it]Running loglikelihood requests:  16%|█▋        | 65/400 [01:30<07:37,  1.37s/it]Running loglikelihood requests:  16%|█▋        | 66/400 [01:31<07:36,  1.37s/it]Running loglikelihood requests:  17%|█▋        | 67/400 [01:32<07:35,  1.37s/it]Running loglikelihood requests:  17%|█▋        | 68/400 [01:34<07:34,  1.37s/it]Running loglikelihood requests:  17%|█▋        | 69/400 [01:35<07:31,  1.36s/it]Running loglikelihood requests:  18%|█▊        | 71/400 [01:36<05:43,  1.04s/it]Running loglikelihood requests:  18%|█▊        | 72/400 [01:38<06:09,  1.13s/it]Running loglikelihood requests:  18%|█▊        | 73/400 [01:39<06:28,  1.19s/it]Running loglikelihood requests:  18%|█▊        | 74/400 [01:41<06:42,  1.23s/it]Running loglikelihood requests:  19%|█▉        | 75/400 [01:42<06:52,  1.27s/it]Running loglikelihood requests:  19%|█▉        | 76/400 [01:43<06:59,  1.29s/it]Running loglikelihood requests:  19%|█▉        | 77/400 [01:45<07:03,  1.31s/it]Running loglikelihood requests:  20%|█▉        | 78/400 [01:46<07:06,  1.32s/it]Running loglikelihood requests:  20%|█▉        | 79/400 [01:47<07:20,  1.37s/it]Running loglikelihood requests:  20%|██        | 80/400 [01:49<07:33,  1.42s/it]Running loglikelihood requests:  20%|██        | 81/400 [01:51<07:41,  1.45s/it]Running loglikelihood requests:  20%|██        | 82/400 [01:52<07:40,  1.45s/it]Running loglikelihood requests:  21%|██        | 83/400 [01:53<07:31,  1.42s/it]Running loglikelihood requests:  21%|██        | 84/400 [01:55<07:23,  1.40s/it]Running loglikelihood requests:  21%|██▏       | 85/400 [01:56<07:17,  1.39s/it]Running loglikelihood requests:  22%|██▏       | 86/400 [01:57<07:13,  1.38s/it]Running loglikelihood requests:  22%|██▏       | 87/400 [01:59<07:12,  1.38s/it]Running loglikelihood requests:  22%|██▏       | 88/400 [02:00<07:09,  1.38s/it]Running loglikelihood requests:  22%|██▏       | 89/400 [02:01<07:06,  1.37s/it]Running loglikelihood requests:  22%|██▎       | 90/400 [02:03<07:04,  1.37s/it]Running loglikelihood requests:  23%|██▎       | 91/400 [02:04<07:01,  1.36s/it]Running loglikelihood requests:  23%|██▎       | 92/400 [02:06<06:59,  1.36s/it]Running loglikelihood requests:  23%|██▎       | 93/400 [02:07<06:57,  1.36s/it]Running loglikelihood requests:  24%|██▎       | 94/400 [02:08<06:55,  1.36s/it]Running loglikelihood requests:  24%|██▍       | 95/400 [02:10<06:54,  1.36s/it]Running loglikelihood requests:  24%|██▍       | 96/400 [02:11<06:52,  1.36s/it]Running loglikelihood requests:  24%|██▍       | 97/400 [02:12<06:51,  1.36s/it]Running loglikelihood requests:  24%|██▍       | 98/400 [02:14<06:49,  1.36s/it]Running loglikelihood requests:  25%|██▍       | 99/400 [02:15<06:48,  1.36s/it]Running loglikelihood requests:  25%|██▌       | 100/400 [02:16<06:47,  1.36s/it]Running loglikelihood requests:  25%|██▌       | 101/400 [02:18<06:46,  1.36s/it]Running loglikelihood requests:  26%|██▌       | 102/400 [02:19<06:44,  1.36s/it]Running loglikelihood requests:  26%|██▌       | 103/400 [02:21<06:57,  1.40s/it]Running loglikelihood requests:  26%|██▌       | 104/400 [02:22<07:01,  1.42s/it]Running loglikelihood requests:  26%|██▋       | 105/400 [02:23<06:52,  1.40s/it]Running loglikelihood requests:  26%|██▋       | 106/400 [02:25<06:44,  1.38s/it]Running loglikelihood requests:  27%|██▋       | 107/400 [02:26<06:39,  1.36s/it]Running loglikelihood requests:  27%|██▋       | 108/400 [02:27<06:35,  1.36s/it]Running loglikelihood requests:  27%|██▋       | 109/400 [02:29<06:32,  1.35s/it]Running loglikelihood requests:  28%|██▊       | 110/400 [02:30<06:29,  1.34s/it]Running loglikelihood requests:  28%|██▊       | 111/400 [02:31<06:26,  1.34s/it]Running loglikelihood requests:  28%|██▊       | 112/400 [02:33<06:24,  1.34s/it]Running loglikelihood requests:  28%|██▊       | 113/400 [02:34<06:22,  1.33s/it]Running loglikelihood requests:  28%|██▊       | 114/400 [02:35<06:20,  1.33s/it]Running loglikelihood requests:  29%|██▉       | 115/400 [02:37<06:19,  1.33s/it]Running loglikelihood requests:  29%|██▉       | 116/400 [02:38<06:17,  1.33s/it]Running loglikelihood requests:  29%|██▉       | 117/400 [02:39<06:16,  1.33s/it]Running loglikelihood requests:  30%|██▉       | 118/400 [02:41<06:15,  1.33s/it]Running loglikelihood requests:  30%|██▉       | 119/400 [02:42<06:13,  1.33s/it]Running loglikelihood requests:  30%|███       | 120/400 [02:43<06:12,  1.33s/it]Running loglikelihood requests:  30%|███       | 121/400 [02:45<06:10,  1.33s/it]Running loglikelihood requests:  30%|███       | 122/400 [02:46<06:08,  1.33s/it]Running loglikelihood requests:  31%|███       | 123/400 [02:47<06:07,  1.33s/it]Running loglikelihood requests:  31%|███       | 124/400 [02:49<06:06,  1.33s/it]Running loglikelihood requests:  31%|███▏      | 125/400 [02:50<06:04,  1.32s/it]Running loglikelihood requests:  32%|███▏      | 126/400 [02:51<06:02,  1.32s/it]Running loglikelihood requests:  32%|███▏      | 127/400 [02:53<06:00,  1.32s/it]Running loglikelihood requests:  32%|███▏      | 128/400 [02:54<05:59,  1.32s/it]Running loglikelihood requests:  32%|███▏      | 129/400 [02:55<05:57,  1.32s/it]Running loglikelihood requests:  32%|███▎      | 130/400 [02:57<05:55,  1.32s/it]Running loglikelihood requests:  33%|███▎      | 131/400 [02:58<05:54,  1.32s/it]Running loglikelihood requests:  33%|███▎      | 132/400 [02:59<05:53,  1.32s/it]Running loglikelihood requests:  33%|███▎      | 133/400 [03:01<05:52,  1.32s/it]Running loglikelihood requests:  34%|███▎      | 134/400 [03:02<05:50,  1.32s/it]Running loglikelihood requests:  34%|███▍      | 135/400 [03:03<05:56,  1.34s/it]Running loglikelihood requests:  34%|███▍      | 136/400 [03:05<05:53,  1.34s/it]Running loglikelihood requests:  34%|███▍      | 137/400 [03:06<05:50,  1.33s/it]Running loglikelihood requests:  34%|███▍      | 138/400 [03:07<05:48,  1.33s/it]Running loglikelihood requests:  35%|███▍      | 139/400 [03:09<05:46,  1.33s/it]Running loglikelihood requests:  35%|███▌      | 140/400 [03:10<05:45,  1.33s/it]Running loglikelihood requests:  35%|███▌      | 141/400 [03:11<05:43,  1.33s/it]Running loglikelihood requests:  36%|███▌      | 142/400 [03:13<05:41,  1.32s/it]Running loglikelihood requests:  36%|███▌      | 143/400 [03:14<05:39,  1.32s/it]Running loglikelihood requests:  36%|███▌      | 144/400 [03:15<05:37,  1.32s/it]Running loglikelihood requests:  36%|███▋      | 145/400 [03:17<05:35,  1.32s/it]Running loglikelihood requests:  36%|███▋      | 146/400 [03:18<05:34,  1.32s/it]Running loglikelihood requests:  37%|███▋      | 147/400 [03:19<05:32,  1.31s/it]Running loglikelihood requests:  37%|███▋      | 148/400 [03:20<05:30,  1.31s/it]Running loglikelihood requests:  37%|███▋      | 149/400 [03:22<05:29,  1.31s/it]Running loglikelihood requests:  38%|███▊      | 150/400 [03:23<05:27,  1.31s/it]Running loglikelihood requests:  38%|███▊      | 151/400 [03:24<05:26,  1.31s/it]Running loglikelihood requests:  38%|███▊      | 152/400 [03:26<05:25,  1.31s/it]Running loglikelihood requests:  38%|███▊      | 153/400 [03:27<05:24,  1.31s/it]Running loglikelihood requests:  38%|███▊      | 154/400 [03:28<05:22,  1.31s/it]Running loglikelihood requests:  39%|███▉      | 155/400 [03:30<05:21,  1.31s/it]Running loglikelihood requests:  39%|███▉      | 156/400 [03:31<05:19,  1.31s/it]Running loglikelihood requests:  39%|███▉      | 157/400 [03:32<05:18,  1.31s/it]Running loglikelihood requests:  40%|███▉      | 158/400 [03:34<05:17,  1.31s/it]Running loglikelihood requests:  40%|███▉      | 159/400 [03:35<05:15,  1.31s/it]Running loglikelihood requests:  40%|████      | 160/400 [03:36<05:13,  1.31s/it]Running loglikelihood requests:  40%|████      | 161/400 [03:37<05:12,  1.31s/it]Running loglikelihood requests:  40%|████      | 162/400 [03:39<05:10,  1.31s/it]Running loglikelihood requests:  41%|████      | 163/400 [03:40<05:09,  1.30s/it]Running loglikelihood requests:  41%|████      | 164/400 [03:41<05:07,  1.30s/it]Running loglikelihood requests:  41%|████▏     | 165/400 [03:43<05:05,  1.30s/it]Running loglikelihood requests:  42%|████▏     | 166/400 [03:44<05:04,  1.30s/it]Running loglikelihood requests:  42%|████▏     | 167/400 [03:45<05:03,  1.30s/it]Running loglikelihood requests:  42%|████▏     | 168/400 [03:47<05:02,  1.30s/it]Running loglikelihood requests:  42%|████▏     | 169/400 [03:48<05:00,  1.30s/it]Running loglikelihood requests:  42%|████▎     | 170/400 [03:49<04:59,  1.30s/it]Running loglikelihood requests:  43%|████▎     | 171/400 [03:50<04:58,  1.30s/it]Running loglikelihood requests:  43%|████▎     | 172/400 [03:52<05:06,  1.34s/it]Running loglikelihood requests:  43%|████▎     | 173/400 [03:53<05:01,  1.33s/it]Running loglikelihood requests:  44%|████▎     | 174/400 [03:55<04:58,  1.32s/it]Running loglikelihood requests:  44%|████▍     | 175/400 [03:56<04:55,  1.31s/it]Running loglikelihood requests:  44%|████▍     | 176/400 [03:57<04:52,  1.31s/it]Running loglikelihood requests:  44%|████▍     | 177/400 [03:58<04:51,  1.31s/it]Running loglikelihood requests:  44%|████▍     | 178/400 [04:00<04:49,  1.30s/it]Running loglikelihood requests:  45%|████▍     | 179/400 [04:01<04:47,  1.30s/it]Running loglikelihood requests:  45%|████▌     | 180/400 [04:02<04:45,  1.30s/it]Running loglikelihood requests:  45%|████▌     | 181/400 [04:04<04:43,  1.30s/it]Running loglikelihood requests:  46%|████▌     | 182/400 [04:05<04:42,  1.29s/it]Running loglikelihood requests:  46%|████▌     | 183/400 [04:06<04:40,  1.29s/it]Running loglikelihood requests:  46%|████▌     | 184/400 [04:07<04:38,  1.29s/it]Running loglikelihood requests:  46%|████▋     | 185/400 [04:09<04:37,  1.29s/it]Running loglikelihood requests:  46%|████▋     | 186/400 [04:10<04:35,  1.29s/it]Running loglikelihood requests:  47%|████▋     | 187/400 [04:11<04:34,  1.29s/it]Running loglikelihood requests:  47%|████▋     | 188/400 [04:13<04:32,  1.29s/it]Running loglikelihood requests:  47%|████▋     | 189/400 [04:14<04:30,  1.28s/it]Running loglikelihood requests:  48%|████▊     | 190/400 [04:15<04:29,  1.28s/it]Running loglikelihood requests:  48%|████▊     | 191/400 [04:16<04:28,  1.28s/it]Running loglikelihood requests:  48%|████▊     | 192/400 [04:18<04:27,  1.28s/it]Running loglikelihood requests:  48%|████▊     | 193/400 [04:19<04:25,  1.28s/it]Running loglikelihood requests:  48%|████▊     | 194/400 [04:20<04:24,  1.28s/it]Running loglikelihood requests:  49%|████▉     | 195/400 [04:22<04:23,  1.28s/it]Running loglikelihood requests:  49%|████▉     | 196/400 [04:23<04:22,  1.29s/it]Running loglikelihood requests:  49%|████▉     | 197/400 [04:24<04:21,  1.29s/it]Running loglikelihood requests:  50%|████▉     | 198/400 [04:25<04:19,  1.28s/it]Running loglikelihood requests:  50%|████▉     | 199/400 [04:27<04:17,  1.28s/it]Running loglikelihood requests:  50%|█████     | 200/400 [04:28<04:16,  1.28s/it]Running loglikelihood requests:  50%|█████     | 201/400 [04:29<04:14,  1.28s/it]Running loglikelihood requests:  50%|█████     | 202/400 [04:31<04:13,  1.28s/it]Running loglikelihood requests:  51%|█████     | 203/400 [04:32<04:11,  1.28s/it]Running loglikelihood requests:  51%|█████     | 204/400 [04:33<04:10,  1.28s/it]Running loglikelihood requests:  51%|█████▏    | 205/400 [04:34<04:09,  1.28s/it]Running loglikelihood requests:  52%|█████▏    | 206/400 [04:36<04:07,  1.28s/it]Running loglikelihood requests:  52%|█████▏    | 207/400 [04:37<04:06,  1.28s/it]Running loglikelihood requests:  52%|█████▏    | 208/400 [04:38<04:05,  1.28s/it]Running loglikelihood requests:  52%|█████▏    | 209/400 [04:39<04:03,  1.28s/it]Running loglikelihood requests:  52%|█████▎    | 210/400 [04:41<04:02,  1.28s/it]Running loglikelihood requests:  53%|█████▎    | 211/400 [04:42<04:00,  1.27s/it]Running loglikelihood requests:  53%|█████▎    | 212/400 [04:43<03:59,  1.27s/it]Running loglikelihood requests:  53%|█████▎    | 213/400 [04:45<03:58,  1.27s/it]Running loglikelihood requests:  54%|█████▎    | 214/400 [04:46<03:56,  1.27s/it]Running loglikelihood requests:  54%|█████▍    | 215/400 [04:47<03:54,  1.27s/it]Running loglikelihood requests:  54%|█████▍    | 216/400 [04:48<03:53,  1.27s/it]Running loglikelihood requests:  54%|█████▍    | 217/400 [04:50<03:51,  1.27s/it]Running loglikelihood requests:  55%|█████▍    | 218/400 [04:51<03:50,  1.26s/it]Running loglikelihood requests:  55%|█████▍    | 219/400 [04:52<03:48,  1.26s/it]Running loglikelihood requests:  55%|█████▌    | 220/400 [04:53<03:47,  1.26s/it]Running loglikelihood requests:  55%|█████▌    | 221/400 [04:55<03:45,  1.26s/it]Running loglikelihood requests:  56%|█████▌    | 222/400 [04:56<03:44,  1.26s/it]Running loglikelihood requests:  56%|█████▌    | 223/400 [04:57<03:42,  1.26s/it]Running loglikelihood requests:  56%|█████▌    | 224/400 [04:58<03:41,  1.26s/it]Running loglikelihood requests:  56%|█████▋    | 225/400 [05:00<03:39,  1.26s/it]Running loglikelihood requests:  56%|█████▋    | 226/400 [05:01<03:38,  1.26s/it]Running loglikelihood requests:  57%|█████▋    | 227/400 [05:02<03:36,  1.25s/it]Running loglikelihood requests:  57%|█████▋    | 228/400 [05:03<03:35,  1.25s/it]Running loglikelihood requests:  57%|█████▋    | 229/400 [05:05<03:33,  1.25s/it]Running loglikelihood requests:  57%|█████▊    | 230/400 [05:06<03:32,  1.25s/it]Running loglikelihood requests:  58%|█████▊    | 231/400 [05:07<03:30,  1.24s/it]Running loglikelihood requests:  58%|█████▊    | 232/400 [05:08<03:28,  1.24s/it]Running loglikelihood requests:  58%|█████▊    | 233/400 [05:10<03:27,  1.24s/it]Running loglikelihood requests:  58%|█████▊    | 234/400 [05:11<03:26,  1.24s/it]Running loglikelihood requests:  59%|█████▉    | 235/400 [05:12<03:25,  1.24s/it]Running loglikelihood requests:  59%|█████▉    | 236/400 [05:13<03:24,  1.24s/it]Running loglikelihood requests:  59%|█████▉    | 237/400 [05:15<03:22,  1.24s/it]Running loglikelihood requests:  60%|█████▉    | 238/400 [05:16<03:21,  1.24s/it]Running loglikelihood requests:  60%|█████▉    | 239/400 [05:17<03:19,  1.24s/it]Running loglikelihood requests:  60%|██████    | 240/400 [05:18<03:18,  1.24s/it]Running loglikelihood requests:  60%|██████    | 241/400 [05:20<03:16,  1.24s/it]Running loglikelihood requests:  60%|██████    | 242/400 [05:21<03:14,  1.23s/it]Running loglikelihood requests:  61%|██████    | 243/400 [05:22<03:13,  1.23s/it]Running loglikelihood requests:  61%|██████    | 244/400 [05:23<03:11,  1.23s/it]Running loglikelihood requests:  61%|██████▏   | 245/400 [05:24<03:10,  1.23s/it]Running loglikelihood requests:  62%|██████▏   | 246/400 [05:26<03:08,  1.22s/it]Running loglikelihood requests:  62%|██████▏   | 247/400 [05:27<03:07,  1.22s/it]Running loglikelihood requests:  62%|██████▏   | 248/400 [05:28<03:05,  1.22s/it]Running loglikelihood requests:  62%|██████▏   | 249/400 [05:29<03:04,  1.22s/it]Running loglikelihood requests:  62%|██████▎   | 250/400 [05:31<03:02,  1.22s/it]Running loglikelihood requests:  63%|██████▎   | 251/400 [05:32<03:01,  1.22s/it]Running loglikelihood requests:  63%|██████▎   | 252/400 [05:33<03:00,  1.22s/it]Running loglikelihood requests:  63%|██████▎   | 253/400 [05:34<02:59,  1.22s/it]Running loglikelihood requests:  64%|██████▎   | 254/400 [05:35<02:57,  1.22s/it]Running loglikelihood requests:  64%|██████▍   | 255/400 [05:37<02:56,  1.22s/it]Running loglikelihood requests:  64%|██████▍   | 256/400 [05:38<02:55,  1.22s/it]Running loglikelihood requests:  64%|██████▍   | 257/400 [05:39<02:53,  1.22s/it]Running loglikelihood requests:  64%|██████▍   | 258/400 [05:40<02:52,  1.21s/it]Running loglikelihood requests:  65%|██████▍   | 259/400 [05:41<02:51,  1.21s/it]Running loglikelihood requests:  65%|██████▌   | 260/400 [05:43<02:49,  1.21s/it]Running loglikelihood requests:  65%|██████▌   | 261/400 [05:44<02:48,  1.21s/it]Running loglikelihood requests:  66%|██████▌   | 262/400 [05:45<02:46,  1.21s/it]Running loglikelihood requests:  66%|██████▌   | 263/400 [05:46<02:45,  1.21s/it]Running loglikelihood requests:  66%|██████▌   | 264/400 [05:48<02:44,  1.21s/it]Running loglikelihood requests:  66%|██████▋   | 265/400 [05:49<02:42,  1.21s/it]Running loglikelihood requests:  66%|██████▋   | 266/400 [05:50<02:41,  1.21s/it]Running loglikelihood requests:  67%|██████▋   | 267/400 [05:51<02:40,  1.20s/it]Running loglikelihood requests:  67%|██████▋   | 268/400 [05:52<02:38,  1.20s/it]Running loglikelihood requests:  67%|██████▋   | 269/400 [05:54<02:37,  1.20s/it]Running loglikelihood requests:  68%|██████▊   | 270/400 [05:55<02:36,  1.20s/it]Running loglikelihood requests:  68%|██████▊   | 271/400 [05:56<02:34,  1.20s/it]Running loglikelihood requests:  68%|██████▊   | 272/400 [05:57<02:33,  1.20s/it]Running loglikelihood requests:  68%|██████▊   | 273/400 [05:58<02:32,  1.20s/it]Running loglikelihood requests:  68%|██████▊   | 274/400 [06:00<02:31,  1.20s/it]Running loglikelihood requests:  69%|██████▉   | 275/400 [06:01<02:30,  1.20s/it]Running loglikelihood requests:  69%|██████▉   | 276/400 [06:02<02:28,  1.20s/it]Running loglikelihood requests:  69%|██████▉   | 277/400 [06:03<02:27,  1.20s/it]Running loglikelihood requests:  70%|██████▉   | 278/400 [06:04<02:26,  1.20s/it]Running loglikelihood requests:  70%|██████▉   | 279/400 [06:06<02:25,  1.20s/it]Running loglikelihood requests:  70%|███████   | 280/400 [06:07<02:24,  1.20s/it]Running loglikelihood requests:  70%|███████   | 281/400 [06:08<02:22,  1.20s/it]Running loglikelihood requests:  70%|███████   | 282/400 [06:09<02:21,  1.20s/it]Running loglikelihood requests:  71%|███████   | 283/400 [06:10<02:19,  1.20s/it]Running loglikelihood requests:  71%|███████   | 284/400 [06:12<02:18,  1.19s/it]Running loglikelihood requests:  71%|███████▏  | 285/400 [06:13<02:17,  1.19s/it]Running loglikelihood requests:  72%|███████▏  | 286/400 [06:14<02:15,  1.19s/it]Running loglikelihood requests:  72%|███████▏  | 287/400 [06:15<02:14,  1.19s/it]Running loglikelihood requests:  72%|███████▏  | 288/400 [06:16<02:13,  1.19s/it]Running loglikelihood requests:  72%|███████▏  | 289/400 [06:17<02:12,  1.19s/it]Running loglikelihood requests:  72%|███████▎  | 290/400 [06:19<02:11,  1.19s/it]Running loglikelihood requests:  73%|███████▎  | 291/400 [06:20<02:09,  1.19s/it]Running loglikelihood requests:  73%|███████▎  | 292/400 [06:21<02:08,  1.19s/it]Running loglikelihood requests:  73%|███████▎  | 293/400 [06:22<02:07,  1.19s/it]Running loglikelihood requests:  74%|███████▎  | 294/400 [06:23<02:06,  1.19s/it]Running loglikelihood requests:  74%|███████▍  | 295/400 [06:25<02:04,  1.19s/it]Running loglikelihood requests:  74%|███████▍  | 296/400 [06:26<02:03,  1.19s/it]Running loglikelihood requests:  74%|███████▍  | 297/400 [06:27<02:02,  1.19s/it]Running loglikelihood requests:  74%|███████▍  | 298/400 [06:28<02:00,  1.19s/it]Running loglikelihood requests:  75%|███████▍  | 299/400 [06:29<01:59,  1.18s/it]Running loglikelihood requests:  75%|███████▌  | 300/400 [06:31<01:58,  1.18s/it]Running loglikelihood requests:  75%|███████▌  | 301/400 [06:32<01:56,  1.18s/it]Running loglikelihood requests:  76%|███████▌  | 302/400 [06:33<01:55,  1.18s/it]Running loglikelihood requests:  76%|███████▌  | 303/400 [06:34<01:54,  1.18s/it]Running loglikelihood requests:  76%|███████▌  | 304/400 [06:35<01:53,  1.18s/it]Running loglikelihood requests:  76%|███████▋  | 305/400 [06:36<01:51,  1.18s/it]Running loglikelihood requests:  76%|███████▋  | 306/400 [06:38<01:50,  1.17s/it]Running loglikelihood requests:  77%|███████▋  | 307/400 [06:39<01:49,  1.17s/it]Running loglikelihood requests:  77%|███████▋  | 308/400 [06:40<01:47,  1.17s/it]Running loglikelihood requests:  77%|███████▋  | 309/400 [06:41<01:46,  1.17s/it]Running loglikelihood requests:  78%|███████▊  | 310/400 [06:42<01:45,  1.17s/it]Running loglikelihood requests:  78%|███████▊  | 311/400 [06:43<01:44,  1.17s/it]Running loglikelihood requests:  78%|███████▊  | 312/400 [06:45<01:43,  1.17s/it]Running loglikelihood requests:  78%|███████▊  | 313/400 [06:46<01:41,  1.17s/it]Running loglikelihood requests:  78%|███████▊  | 314/400 [06:47<01:40,  1.17s/it]Running loglikelihood requests:  79%|███████▉  | 315/400 [06:48<01:39,  1.17s/it]Running loglikelihood requests:  79%|███████▉  | 316/400 [06:49<01:38,  1.17s/it]Running loglikelihood requests:  79%|███████▉  | 317/400 [06:50<01:36,  1.17s/it]Running loglikelihood requests:  80%|███████▉  | 318/400 [06:52<01:35,  1.17s/it]Running loglikelihood requests:  80%|███████▉  | 319/400 [06:53<01:34,  1.17s/it]Running loglikelihood requests:  80%|████████  | 320/400 [06:54<01:33,  1.17s/it]Running loglikelihood requests:  80%|████████  | 321/400 [06:55<01:32,  1.17s/it]Running loglikelihood requests:  80%|████████  | 322/400 [06:56<01:31,  1.17s/it]Running loglikelihood requests:  81%|████████  | 323/400 [06:57<01:29,  1.17s/it]Running loglikelihood requests:  81%|████████  | 324/400 [06:59<01:28,  1.17s/it]Running loglikelihood requests:  81%|████████▏ | 325/400 [07:00<01:27,  1.16s/it]Running loglikelihood requests:  82%|████████▏ | 326/400 [07:01<01:26,  1.16s/it]Running loglikelihood requests:  82%|████████▏ | 327/400 [07:02<01:24,  1.16s/it]Running loglikelihood requests:  82%|████████▏ | 328/400 [07:03<01:23,  1.16s/it]Running loglikelihood requests:  82%|████████▏ | 329/400 [07:04<01:22,  1.16s/it]Running loglikelihood requests:  82%|████████▎ | 330/400 [07:06<01:21,  1.16s/it]Running loglikelihood requests:  83%|████████▎ | 331/400 [07:07<01:19,  1.16s/it]Running loglikelihood requests:  83%|████████▎ | 332/400 [07:08<01:18,  1.16s/it]Running loglikelihood requests:  83%|████████▎ | 333/400 [07:09<01:17,  1.16s/it]Running loglikelihood requests:  84%|████████▎ | 334/400 [07:10<01:16,  1.16s/it]Running loglikelihood requests:  84%|████████▍ | 335/400 [07:11<01:15,  1.16s/it]Running loglikelihood requests:  84%|████████▍ | 336/400 [07:12<01:13,  1.15s/it]Running loglikelihood requests:  84%|████████▍ | 337/400 [07:14<01:12,  1.15s/it]Running loglikelihood requests:  84%|████████▍ | 338/400 [07:15<01:11,  1.15s/it]Running loglikelihood requests:  85%|████████▍ | 339/400 [07:16<01:10,  1.16s/it]Running loglikelihood requests:  85%|████████▌ | 340/400 [07:17<01:12,  1.20s/it]Running loglikelihood requests:  85%|████████▌ | 341/400 [07:19<01:12,  1.22s/it]Running loglikelihood requests:  86%|████████▌ | 342/400 [07:20<01:09,  1.21s/it]Running loglikelihood requests:  86%|████████▌ | 343/400 [07:21<01:07,  1.19s/it]Running loglikelihood requests:  86%|████████▌ | 344/400 [07:22<01:06,  1.18s/it]Running loglikelihood requests:  86%|████████▋ | 345/400 [07:23<01:04,  1.18s/it]Running loglikelihood requests:  86%|████████▋ | 346/400 [07:24<01:03,  1.17s/it]Running loglikelihood requests:  87%|████████▋ | 347/400 [07:25<01:01,  1.17s/it]Running loglikelihood requests:  87%|████████▋ | 348/400 [07:27<01:00,  1.17s/it]Running loglikelihood requests:  87%|████████▋ | 349/400 [07:28<00:59,  1.16s/it]Running loglikelihood requests:  88%|████████▊ | 350/400 [07:29<00:58,  1.16s/it]Running loglikelihood requests:  88%|████████▊ | 351/400 [07:30<00:56,  1.16s/it]Running loglikelihood requests:  88%|████████▊ | 352/400 [07:31<00:55,  1.16s/it]Running loglikelihood requests:  88%|████████▊ | 353/400 [07:32<00:54,  1.16s/it]Running loglikelihood requests:  88%|████████▊ | 354/400 [07:34<00:53,  1.16s/it]Running loglikelihood requests:  89%|████████▉ | 355/400 [07:35<00:52,  1.16s/it]Running loglikelihood requests:  89%|████████▉ | 356/400 [07:36<00:51,  1.17s/it]Running loglikelihood requests:  89%|████████▉ | 357/400 [07:37<00:49,  1.16s/it]Running loglikelihood requests:  90%|████████▉ | 358/400 [07:38<00:48,  1.16s/it]Running loglikelihood requests:  90%|████████▉ | 359/400 [07:39<00:47,  1.16s/it]Running loglikelihood requests:  90%|█████████ | 360/400 [07:41<00:46,  1.15s/it]Running loglikelihood requests:  90%|█████████ | 361/400 [07:42<00:44,  1.15s/it]Running loglikelihood requests:  90%|█████████ | 362/400 [07:43<00:43,  1.15s/it]Running loglikelihood requests:  91%|█████████ | 363/400 [07:44<00:42,  1.15s/it]Running loglikelihood requests:  91%|█████████ | 364/400 [07:45<00:41,  1.15s/it]Running loglikelihood requests:  91%|█████████▏| 365/400 [07:46<00:40,  1.15s/it]Running loglikelihood requests:  92%|█████████▏| 366/400 [07:47<00:38,  1.15s/it]Running loglikelihood requests:  92%|█████████▏| 367/400 [07:49<00:37,  1.15s/it]Running loglikelihood requests:  92%|█████████▏| 368/400 [07:50<00:36,  1.15s/it]Running loglikelihood requests:  92%|█████████▏| 369/400 [07:51<00:35,  1.15s/it]Running loglikelihood requests:  92%|█████████▎| 370/400 [07:52<00:34,  1.14s/it]Running loglikelihood requests:  93%|█████████▎| 371/400 [07:53<00:33,  1.14s/it]Running loglikelihood requests:  93%|█████████▎| 372/400 [07:54<00:31,  1.14s/it]Running loglikelihood requests:  93%|█████████▎| 373/400 [07:55<00:30,  1.14s/it]Running loglikelihood requests:  94%|█████████▎| 374/400 [07:57<00:29,  1.14s/it]Running loglikelihood requests:  94%|█████████▍| 375/400 [07:58<00:28,  1.13s/it]Running loglikelihood requests:  94%|█████████▍| 376/400 [07:59<00:27,  1.13s/it]Running loglikelihood requests:  94%|█████████▍| 377/400 [08:00<00:25,  1.13s/it]Running loglikelihood requests:  94%|█████████▍| 378/400 [08:01<00:24,  1.13s/it]Running loglikelihood requests:  95%|█████████▍| 379/400 [08:02<00:23,  1.13s/it]Running loglikelihood requests:  95%|█████████▌| 380/400 [08:03<00:22,  1.12s/it]Running loglikelihood requests:  95%|█████████▌| 381/400 [08:04<00:21,  1.12s/it]Running loglikelihood requests:  96%|█████████▌| 382/400 [08:06<00:20,  1.14s/it]Running loglikelihood requests:  96%|█████████▌| 383/400 [08:07<00:19,  1.13s/it]Running loglikelihood requests:  96%|█████████▌| 384/400 [08:08<00:18,  1.13s/it]Running loglikelihood requests:  96%|█████████▋| 385/400 [08:09<00:16,  1.12s/it]Running loglikelihood requests:  96%|█████████▋| 386/400 [08:10<00:15,  1.11s/it]Running loglikelihood requests:  97%|█████████▋| 387/400 [08:11<00:14,  1.13s/it]Running loglikelihood requests:  97%|█████████▋| 388/400 [08:12<00:13,  1.16s/it]Running loglikelihood requests:  97%|█████████▋| 389/400 [08:13<00:12,  1.13s/it]Running loglikelihood requests:  98%|█████████▊| 390/400 [08:15<00:11,  1.12s/it]Running loglikelihood requests:  98%|█████████▊| 391/400 [08:16<00:10,  1.12s/it]Running loglikelihood requests:  98%|█████████▊| 392/400 [08:17<00:08,  1.10s/it]Running loglikelihood requests:  98%|█████████▊| 393/400 [08:18<00:07,  1.07s/it]Running loglikelihood requests:  98%|█████████▊| 394/400 [08:19<00:06,  1.08s/it]Running loglikelihood requests:  99%|█████████▉| 395/400 [08:20<00:05,  1.09s/it]Running loglikelihood requests:  99%|█████████▉| 396/400 [08:21<00:04,  1.06s/it]Running loglikelihood requests:  99%|█████████▉| 397/400 [08:22<00:03,  1.02s/it]Running loglikelihood requests: 100%|█████████▉| 398/400 [08:23<00:01,  1.01it/s]Running loglikelihood requests: 100%|█████████▉| 399/400 [08:24<00:00,  1.02it/s]Running loglikelihood requests: 100%|██████████| 400/400 [08:25<00:00,  1.00it/s]Running loglikelihood requests: 100%|██████████| 400/400 [08:25<00:00,  1.26s/it]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:1'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:1'}
full model:
{'mastermind_46_easy': {'alias': 'mastermind_46_easy', 'acc,none': 0.75, 'acc_stderr,none': 0.04351941398892446}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9900730655060652
0.9975621416797388
0.9971758007187725
0.9980230222224056
0.9889479987910904
0.9764864248764976
0.9903944102306983
0.9944743493554844
0.9959595842537624
0.9872350810596702
0.9630442697748985
0.9836939129473328
0.9680042833072414
0.9739989664157891
0.9945965755000291
0.9874567967365809
0.9910190996776087
0.9888895436517939
0.9820307305549418
0.9881803990776891
0.9859944271811626
0.9931460182904469
0.984259193892523
0.99673879588459
0.9800909214289261
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[5, 2, 0, 3, 7, 6, 1, 4]
tensor([5, 2, 0, 3, 7, 6, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 0, 3, 7, 6, 1, 4]
tensor([5, 2, 0, 3, 7, 6, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 0, 3, 7, 6, 1, 4]
tensor([5, 2, 0, 3, 7, 6, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 0, 3, 7, 6, 1, 4]
tensor([5, 2, 0, 3, 7, 6, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 0, 3, 7, 6, 1, 4]
tensor([5, 2, 0, 3, 7, 6, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 0, 3, 7, 6, 1, 4]
tensor([5, 2, 0, 3, 7, 6, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Normal merging for layer 2
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Normal merging for layer 3
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Normal merging for layer 4
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Normal merging for layer 5
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 6 to 31
done!
all done!
Model size: 12.0718 GB
98
cuda:1
piqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:42<00:42, 42.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 24.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 27.39s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/baber/piqa HTTP/1.1" 200 389
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/baber/piqa/baber/piqa.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/baber/piqa HTTP/1.1" 200 389
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/baber/piqa/resolve/142f6d7367fd9877f0fb3b5734ea6a545f54cdd1/README.md HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/baber/piqa/revision/142f6d7367fd9877f0fb3b5734ea6a545f54cdd1 HTTP/1.1" 200 389
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/baber/piqa/tree/142f6d7367fd9877f0fb3b5734ea6a545f54cdd1?recursive=False&expand=False HTTP/1.1" 200 513
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/baber/piqa/tree/142f6d7367fd9877f0fb3b5734ea6a545f54cdd1/data?recursive=False&expand=False HTTP/1.1" 404 79
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/baber/piqa/tree/142f6d7367fd9877f0fb3b5734ea6a545f54cdd1/data?recursive=False&expand=False HTTP/1.1" 404 79
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/baber/piqa/revision/142f6d7367fd9877f0fb3b5734ea6a545f54cdd1 HTTP/1.1" 200 389
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/baber/piqa/resolve/142f6d7367fd9877f0fb3b5734ea6a545f54cdd1/dataset_infos.json HTTP/1.1" 404 0
DEBUG:filelock:Attempting to acquire lock 140233713386656 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_baber___piqa_default_0.0.0_142f6d7367fd9877f0fb3b5734ea6a545f54cdd1.lock
DEBUG:filelock:Lock 140233713386656 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_baber___piqa_default_0.0.0_142f6d7367fd9877f0fb3b5734ea6a545f54cdd1.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/baber___piqa/default/0.0.0/142f6d7367fd9877f0fb3b5734ea6a545f54cdd1/dataset_info.json
DEBUG:filelock:Attempting to release lock 140233713386656 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_baber___piqa_default_0.0.0_142f6d7367fd9877f0fb3b5734ea6a545f54cdd1.lock
DEBUG:filelock:Lock 140233713386656 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_baber___piqa_default_0.0.0_142f6d7367fd9877f0fb3b5734ea6a545f54cdd1.lock
DEBUG:filelock:Attempting to acquire lock 140240017046656 on /public/home/zouyifei001/.cache/huggingface/datasets/baber___piqa/default/0.0.0/142f6d7367fd9877f0fb3b5734ea6a545f54cdd1_builder.lock
DEBUG:filelock:Lock 140240017046656 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/baber___piqa/default/0.0.0/142f6d7367fd9877f0fb3b5734ea6a545f54cdd1_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/baber___piqa/default/0.0.0/142f6d7367fd9877f0fb3b5734ea6a545f54cdd1/dataset_info.json
DEBUG:filelock:Attempting to release lock 140240017046656 on /public/home/zouyifei001/.cache/huggingface/datasets/baber___piqa/default/0.0.0/142f6d7367fd9877f0fb3b5734ea6a545f54cdd1_builder.lock
DEBUG:filelock:Lock 140240017046656 released on /public/home/zouyifei001/.cache/huggingface/datasets/baber___piqa/default/0.0.0/142f6d7367fd9877f0fb3b5734ea6a545f54cdd1_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of piqa from None to 0
INFO:lm_eval.api.task:Building contexts for piqa on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1440.86it/s]
DEBUG:lm_eval.evaluator:Task: piqa; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:01<05:30,  1.66s/it]Running loglikelihood requests:   1%|          | 2/200 [00:02<04:26,  1.35s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:03<03:46,  1.15s/it]Running loglikelihood requests:   2%|▏         | 4/200 [00:04<03:23,  1.04s/it]Running loglikelihood requests:   2%|▎         | 5/200 [00:05<03:09,  1.03it/s]Running loglikelihood requests:   3%|▎         | 6/200 [00:06<03:00,  1.07it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:07<02:52,  1.12it/s]Running loglikelihood requests:   4%|▍         | 8/200 [00:07<02:45,  1.16it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:08<02:39,  1.20it/s]Running loglikelihood requests:   5%|▌         | 10/200 [00:09<02:34,  1.23it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:10<02:29,  1.26it/s]Running loglikelihood requests:   6%|▌         | 12/200 [00:10<02:26,  1.28it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:11<02:24,  1.30it/s]Running loglikelihood requests:   7%|▋         | 14/200 [00:12<02:24,  1.29it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:13<02:20,  1.31it/s]Running loglikelihood requests:   8%|▊         | 16/200 [00:13<02:17,  1.34it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:14<02:14,  1.36it/s]Running loglikelihood requests:   9%|▉         | 18/200 [00:15<02:11,  1.39it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:15<02:08,  1.41it/s]Running loglikelihood requests:  10%|█         | 20/200 [00:16<02:06,  1.42it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:17<02:04,  1.44it/s]Running loglikelihood requests:  11%|█         | 22/200 [00:18<02:03,  1.44it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:18<02:00,  1.47it/s]Running loglikelihood requests:  12%|█▏        | 24/200 [00:19<01:59,  1.48it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:20<01:58,  1.48it/s]Running loglikelihood requests:  13%|█▎        | 26/200 [00:20<01:56,  1.49it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:21<01:55,  1.50it/s]Running loglikelihood requests:  14%|█▍        | 28/200 [00:21<01:53,  1.51it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:22<01:52,  1.52it/s]Running loglikelihood requests:  15%|█▌        | 30/200 [00:23<01:50,  1.53it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:23<01:49,  1.54it/s]Running loglikelihood requests:  16%|█▌        | 32/200 [00:24<01:48,  1.55it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:25<01:47,  1.56it/s]Running loglikelihood requests:  17%|█▋        | 34/200 [00:25<01:46,  1.56it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:26<01:45,  1.57it/s]Running loglikelihood requests:  18%|█▊        | 36/200 [00:27<01:44,  1.57it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:27<01:43,  1.57it/s]Running loglikelihood requests:  19%|█▉        | 38/200 [00:28<01:42,  1.58it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:28<01:41,  1.58it/s]Running loglikelihood requests:  20%|██        | 40/200 [00:29<01:40,  1.59it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:30<01:39,  1.60it/s]Running loglikelihood requests:  21%|██        | 42/200 [00:30<01:38,  1.60it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:31<01:37,  1.61it/s]Running loglikelihood requests:  22%|██▏       | 44/200 [00:32<01:36,  1.62it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:32<01:35,  1.62it/s]Running loglikelihood requests:  23%|██▎       | 46/200 [00:33<01:34,  1.63it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:33<01:33,  1.64it/s]Running loglikelihood requests:  24%|██▍       | 48/200 [00:34<01:32,  1.64it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:35<01:31,  1.65it/s]Running loglikelihood requests:  25%|██▌       | 50/200 [00:35<01:31,  1.64it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:36<01:29,  1.66it/s]Running loglikelihood requests:  26%|██▌       | 52/200 [00:36<01:28,  1.67it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:37<01:27,  1.69it/s]Running loglikelihood requests:  27%|██▋       | 54/200 [00:38<01:26,  1.70it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:38<01:25,  1.70it/s]Running loglikelihood requests:  28%|██▊       | 56/200 [00:39<01:24,  1.69it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:39<01:24,  1.69it/s]Running loglikelihood requests:  29%|██▉       | 58/200 [00:40<01:23,  1.69it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:41<01:23,  1.70it/s]Running loglikelihood requests:  30%|███       | 60/200 [00:41<01:22,  1.70it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:42<01:21,  1.70it/s]Running loglikelihood requests:  31%|███       | 62/200 [00:42<01:20,  1.71it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:43<01:20,  1.71it/s]Running loglikelihood requests:  32%|███▏      | 64/200 [00:43<01:19,  1.71it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:44<01:19,  1.71it/s]Running loglikelihood requests:  33%|███▎      | 66/200 [00:45<01:18,  1.71it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:45<01:17,  1.72it/s]Running loglikelihood requests:  34%|███▍      | 68/200 [00:46<01:16,  1.72it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:46<01:15,  1.73it/s]Running loglikelihood requests:  35%|███▌      | 70/200 [00:47<01:14,  1.74it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:47<01:13,  1.75it/s]Running loglikelihood requests:  36%|███▌      | 72/200 [00:48<01:13,  1.73it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:49<01:12,  1.75it/s]Running loglikelihood requests:  37%|███▋      | 74/200 [00:49<01:11,  1.76it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:50<01:10,  1.78it/s]Running loglikelihood requests:  38%|███▊      | 76/200 [00:50<01:09,  1.79it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:51<01:08,  1.79it/s]Running loglikelihood requests:  39%|███▉      | 78/200 [00:51<01:07,  1.80it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:52<01:07,  1.80it/s]Running loglikelihood requests:  40%|████      | 80/200 [00:52<01:06,  1.81it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:53<01:05,  1.81it/s]Running loglikelihood requests:  41%|████      | 82/200 [00:54<01:04,  1.82it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:54<01:04,  1.80it/s]Running loglikelihood requests:  42%|████▏     | 84/200 [00:55<01:03,  1.82it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:55<01:02,  1.83it/s]Running loglikelihood requests:  43%|████▎     | 86/200 [00:56<01:01,  1.85it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:56<01:01,  1.83it/s]Running loglikelihood requests:  44%|████▍     | 88/200 [00:57<01:01,  1.83it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:57<01:01,  1.81it/s]Running loglikelihood requests:  45%|████▌     | 90/200 [00:58<01:00,  1.83it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:58<00:59,  1.84it/s]Running loglikelihood requests:  46%|████▌     | 92/200 [00:59<00:58,  1.84it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [01:00<00:57,  1.85it/s]Running loglikelihood requests:  47%|████▋     | 94/200 [01:00<00:56,  1.86it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [01:01<00:55,  1.88it/s]Running loglikelihood requests:  48%|████▊     | 96/200 [01:01<00:55,  1.88it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [01:02<00:55,  1.87it/s]Running loglikelihood requests:  49%|████▉     | 98/200 [01:02<00:54,  1.87it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [01:03<00:54,  1.85it/s]Running loglikelihood requests:  50%|█████     | 100/200 [01:03<00:54,  1.85it/s]Running loglikelihood requests:  50%|█████     | 101/200 [01:04<00:53,  1.84it/s]Running loglikelihood requests:  51%|█████     | 102/200 [01:04<00:52,  1.86it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [01:05<00:51,  1.88it/s]Running loglikelihood requests:  52%|█████▏    | 104/200 [01:05<00:50,  1.89it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [01:06<00:49,  1.91it/s]Running loglikelihood requests:  53%|█████▎    | 106/200 [01:06<00:49,  1.89it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [01:07<00:48,  1.90it/s]Running loglikelihood requests:  54%|█████▍    | 108/200 [01:08<00:48,  1.91it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [01:08<00:47,  1.92it/s]Running loglikelihood requests:  55%|█████▌    | 110/200 [01:09<00:46,  1.94it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [01:09<00:45,  1.94it/s]Running loglikelihood requests:  56%|█████▌    | 112/200 [01:10<00:45,  1.96it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [01:10<00:44,  1.96it/s]Running loglikelihood requests:  57%|█████▋    | 114/200 [01:11<00:44,  1.93it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [01:11<00:43,  1.94it/s]Running loglikelihood requests:  58%|█████▊    | 116/200 [01:12<00:42,  1.96it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [01:12<00:42,  1.97it/s]Running loglikelihood requests:  59%|█████▉    | 118/200 [01:13<00:41,  1.98it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [01:13<00:40,  1.98it/s]Running loglikelihood requests:  60%|██████    | 120/200 [01:14<00:40,  1.99it/s]Running loglikelihood requests:  60%|██████    | 121/200 [01:14<00:39,  2.00it/s]Running loglikelihood requests:  61%|██████    | 122/200 [01:15<00:38,  2.00it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [01:15<00:38,  2.01it/s]Running loglikelihood requests:  62%|██████▏   | 124/200 [01:16<00:37,  2.01it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [01:16<00:37,  2.01it/s]Running loglikelihood requests:  63%|██████▎   | 126/200 [01:17<00:36,  2.02it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [01:17<00:36,  2.02it/s]Running loglikelihood requests:  64%|██████▍   | 128/200 [01:18<00:35,  2.02it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [01:18<00:35,  2.03it/s]Running loglikelihood requests:  65%|██████▌   | 130/200 [01:19<00:35,  1.98it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [01:19<00:35,  1.97it/s]Running loglikelihood requests:  66%|██████▌   | 132/200 [01:20<00:33,  2.00it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [01:20<00:33,  2.02it/s]Running loglikelihood requests:  67%|██████▋   | 134/200 [01:21<00:32,  2.04it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [01:21<00:31,  2.06it/s]Running loglikelihood requests:  68%|██████▊   | 136/200 [01:22<00:31,  2.05it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [01:22<00:30,  2.06it/s]Running loglikelihood requests:  69%|██████▉   | 138/200 [01:22<00:30,  2.04it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [01:23<00:29,  2.06it/s]Running loglikelihood requests:  70%|███████   | 140/200 [01:23<00:28,  2.09it/s]Running loglikelihood requests:  70%|███████   | 141/200 [01:24<00:28,  2.10it/s]Running loglikelihood requests:  71%|███████   | 142/200 [01:24<00:27,  2.11it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [01:25<00:27,  2.07it/s]Running loglikelihood requests:  72%|███████▏  | 144/200 [01:25<00:27,  2.07it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [01:26<00:26,  2.07it/s]Running loglikelihood requests:  73%|███████▎  | 146/200 [01:26<00:26,  2.08it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [01:27<00:25,  2.09it/s]Running loglikelihood requests:  74%|███████▍  | 148/200 [01:27<00:24,  2.09it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [01:28<00:24,  2.06it/s]Running loglikelihood requests:  75%|███████▌  | 150/200 [01:28<00:24,  2.08it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [01:29<00:23,  2.10it/s]Running loglikelihood requests:  76%|███████▌  | 152/200 [01:29<00:22,  2.09it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [01:30<00:22,  2.09it/s]Running loglikelihood requests:  77%|███████▋  | 154/200 [01:30<00:21,  2.09it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [01:31<00:21,  2.10it/s]Running loglikelihood requests:  78%|███████▊  | 156/200 [01:31<00:20,  2.11it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [01:32<00:20,  2.11it/s]Running loglikelihood requests:  79%|███████▉  | 158/200 [01:32<00:19,  2.12it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [01:32<00:19,  2.12it/s]Running loglikelihood requests:  80%|████████  | 160/200 [01:33<00:18,  2.12it/s]Running loglikelihood requests:  80%|████████  | 161/200 [01:33<00:18,  2.11it/s]Running loglikelihood requests:  81%|████████  | 162/200 [01:34<00:18,  2.11it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [01:34<00:17,  2.11it/s]Running loglikelihood requests:  82%|████████▏ | 164/200 [01:35<00:17,  2.11it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [01:35<00:16,  2.12it/s]Running loglikelihood requests:  83%|████████▎ | 166/200 [01:36<00:16,  2.12it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [01:36<00:15,  2.13it/s]Running loglikelihood requests:  84%|████████▍ | 168/200 [01:37<00:15,  2.13it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [01:37<00:14,  2.14it/s]Running loglikelihood requests:  85%|████████▌ | 170/200 [01:38<00:14,  2.14it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [01:38<00:13,  2.15it/s]Running loglikelihood requests:  86%|████████▌ | 172/200 [01:39<00:13,  2.15it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [01:39<00:12,  2.14it/s]Running loglikelihood requests:  87%|████████▋ | 174/200 [01:40<00:12,  2.15it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [01:40<00:11,  2.16it/s]Running loglikelihood requests:  88%|████████▊ | 176/200 [01:40<00:11,  2.16it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [01:41<00:10,  2.17it/s]Running loglikelihood requests:  89%|████████▉ | 178/200 [01:41<00:10,  2.18it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [01:42<00:09,  2.18it/s]Running loglikelihood requests:  90%|█████████ | 180/200 [01:42<00:09,  2.19it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [01:43<00:08,  2.19it/s]Running loglikelihood requests:  91%|█████████ | 182/200 [01:43<00:08,  2.21it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [01:44<00:07,  2.23it/s]Running loglikelihood requests:  92%|█████████▏| 184/200 [01:44<00:07,  2.22it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [01:45<00:06,  2.22it/s]Running loglikelihood requests:  93%|█████████▎| 186/200 [01:45<00:06,  2.22it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [01:45<00:05,  2.22it/s]Running loglikelihood requests:  94%|█████████▍| 188/200 [01:46<00:05,  2.23it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [01:46<00:04,  2.24it/s]Running loglikelihood requests:  95%|█████████▌| 190/200 [01:47<00:04,  2.25it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [01:47<00:03,  2.26it/s]Running loglikelihood requests:  96%|█████████▌| 192/200 [01:48<00:03,  2.26it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [01:48<00:03,  2.28it/s]Running loglikelihood requests:  97%|█████████▋| 194/200 [01:48<00:02,  2.32it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:49<00:02,  2.36it/s]Running loglikelihood requests:  98%|█████████▊| 196/200 [01:49<00:01,  2.41it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:50<00:01,  2.47it/s]Running loglikelihood requests:  99%|█████████▉| 198/200 [01:50<00:00,  2.50it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:50<00:00,  2.52it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:51<00:00,  2.53it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:51<00:00,  1.80it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:2'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:2'}
full model:
{'piqa': {'alias': 'piqa', 'acc,none': 0.72, 'acc_stderr,none': 0.045126085985421296, 'acc_norm,none': 0.77, 'acc_norm_stderr,none': 0.042295258468165065}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9064246834015742
0.6971166389992818
0.984178396878105
0.6423720440493765
0.5982521563321566
0.8713841941840345
0.9082138941524238
0.5158918062056659
0.5749897473491503
0.6077434510351011
0.43990863946687114
0.513037250698066
0.6008178290360138
0.6217761889117341
0.7015566479448269
0.9265609444578461
0.9509391107686297
0.916894288805361
0.6283461914591203
0.8581337818466952
0.9688813419052539
0.8840066034830325
0.9210978928752702
0.6224518401606872
0.9119076639613269
0.9079101501328887
0.6461990702766951
0.594705914504569
0.6124297016957765
0.9064246834015742
0.6971166389992818
0.984178396878105
0.6423720440493765
0.5982521563321566
0.8713841941840345
0.9082138941524238
0.5158918062056659
0.5749897473491503
0.6077434510351011
0.43990863946687114
Total groups 76 exceeded the threshold, stopping comparison.
The group tensor is
[6, 3, 2, 4, 1, 5, 7, 0]
tensor([6, 3, 2, 4, 1, 5, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 0, 6, 3, 4, 2, 5, 1]
tensor([7, 0, 6, 3, 4, 2, 5, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 3, 5, 2, 4, 0, 6, 1]
tensor([7, 3, 5, 2, 4, 0, 6, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 1, 4, 3, 5, 2, 6, 0]
tensor([7, 1, 4, 3, 5, 2, 6, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 1, 5, 4, 3, 0, 6, 2]
tensor([7, 1, 5, 4, 3, 0, 6, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 1, 2, 2, 1, 3, 0]
tensor([0, 3, 1, 2, 2, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 3, 1, 2, 2, 0, 3, 1]
tensor([0, 3, 1, 2, 2, 0, 3, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 0, 1, 2, 3, 1, 3, 2]
tensor([0, 0, 1, 2, 3, 1, 3, 2], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
done!
Normal merging for layer 2
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
done!
Normal merging for layer 4
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([4])
tensor(4)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 5 to 16
done!
Normal merging for layer 17
tensor([0, 7])
tensor(0)
tensor([2, 5])
tensor(2)
tensor([3, 4])
tensor(3)
tensor([1, 6])
tensor(1)
done!
Normal merging for layer 18
tensor([0, 5])
tensor(0)
tensor([2, 7])
tensor(2)
tensor([3, 4])
tensor(3)
tensor([1, 6])
tensor(1)
done!
Normal merging for layer 19
tensor([0, 1])
tensor(0)
tensor([2, 5])
tensor(2)
tensor([3, 7])
tensor(3)
tensor([4, 6])
tensor(4)
done!
Cross-layer merge completed for layers 20 to 31
done!
all done!
Model size: 12.3867 GB
160
cuda:2
wic
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:41<00:41, 41.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:53<00:00, 24.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:53<00:00, 26.97s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wic] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wic] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/super_glue/super_glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue/tree/3de24cf8022e94f4ee4b9d55a6f539891524d646/wic?recursive=False&expand=False HTTP/1.1" 307 142
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue/tree/3de24cf8022e94f4ee4b9d55a6f539891524d646/wic?recursive=False&expand=False HTTP/1.1" 200 356
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 235
DEBUG:filelock:Attempting to acquire lock 140239877334576 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_wic_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 140239877334576 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_wic_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wic/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 140239877334576 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_wic_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 140239877334576 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_wic_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Attempting to acquire lock 140233173100032 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wic/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 140233173100032 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wic/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wic/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 140233173100032 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wic/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 140233173100032 released on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wic/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wic from None to 0
INFO:lm_eval.api.task:Building contexts for wic on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1538.43it/s]
DEBUG:lm_eval.evaluator:Task: wic; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:01<04:08,  1.25s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:01<01:56,  1.69it/s]Running loglikelihood requests:   2%|▎         | 5/200 [00:02<01:31,  2.13it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:03<01:21,  2.38it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:04<01:14,  2.55it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:04<01:11,  2.66it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:05<01:08,  2.75it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:06<01:06,  2.80it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:06<01:04,  2.86it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:07<01:02,  2.89it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:08<01:01,  2.92it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:08<01:00,  2.94it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:09<00:59,  2.96it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:10<00:58,  2.97it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:10<00:57,  2.98it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:11<00:56,  2.99it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:12<00:55,  3.00it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:12<00:54,  3.02it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:13<00:53,  3.03it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:14<00:52,  3.04it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:14<00:52,  3.05it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:15<00:51,  3.03it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:16<00:51,  3.02it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:16<00:50,  3.04it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:17<00:49,  3.03it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:18<00:48,  3.07it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:18<00:47,  3.11it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:19<00:46,  3.14it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:19<00:45,  3.12it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:20<00:45,  3.10it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:21<00:44,  3.10it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:21<00:44,  3.10it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:22<00:43,  3.10it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:23<00:42,  3.10it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:23<00:42,  3.11it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:24<00:41,  3.11it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:25<00:40,  3.12it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:25<00:39,  3.13it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:26<00:39,  3.13it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:26<00:38,  3.14it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:27<00:37,  3.15it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:28<00:37,  3.16it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:28<00:36,  3.16it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:29<00:35,  3.17it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:30<00:35,  3.17it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:30<00:34,  3.17it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:31<00:33,  3.17it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:32<00:33,  3.17it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:32<00:32,  3.17it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:33<00:31,  3.17it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:33<00:31,  3.17it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:34<00:30,  3.17it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:35<00:29,  3.18it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:35<00:29,  3.18it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:36<00:28,  3.14it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:37<00:27,  3.19it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:37<00:26,  3.23it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:38<00:26,  3.25it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:38<00:25,  3.27it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:39<00:24,  3.29it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:40<00:23,  3.30it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:40<00:23,  3.29it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:41<00:23,  3.26it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [00:41<00:22,  3.24it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [00:42<00:21,  3.23it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [00:43<00:21,  3.23it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [00:43<00:20,  3.23it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [00:44<00:20,  3.23it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [00:45<00:19,  3.19it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [00:45<00:18,  3.23it/s]Running loglikelihood requests:  70%|███████   | 141/200 [00:46<00:18,  3.25it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [00:46<00:17,  3.27it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [00:47<00:16,  3.30it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [00:48<00:16,  3.30it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [00:48<00:15,  3.32it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [00:49<00:14,  3.32it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [00:49<00:14,  3.32it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [00:50<00:13,  3.33it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [00:51<00:12,  3.34it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [00:51<00:12,  3.36it/s]Running loglikelihood requests:  80%|████████  | 161/200 [00:52<00:11,  3.36it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [00:52<00:10,  3.37it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [00:53<00:10,  3.38it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [00:54<00:09,  3.39it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [00:54<00:09,  3.40it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [00:55<00:08,  3.41it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [00:55<00:07,  3.42it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [00:56<00:07,  3.40it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [00:56<00:06,  3.41it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [00:57<00:06,  3.41it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [00:58<00:05,  3.41it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [00:58<00:04,  3.42it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [00:59<00:04,  3.42it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [00:59<00:03,  3.43it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [01:00<00:03,  3.44it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [01:01<00:02,  3.45it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [01:01<00:02,  3.46it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:02<00:01,  3.47it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:02<00:00,  3.48it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:03<00:00,  3.49it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:03<00:00,  3.16it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:3'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:3'}
full model:
{'wic': {'alias': 'wic', 'acc,none': 0.47, 'acc_stderr,none': 0.05016135580465919}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.7015569150227223
0.5302361010977743
0.6131123609930033
0.8131827739550247
0.5456264918897312
0.5653128506125247
0.9024119585362896
0.8122852497904204
0.9072724946141106
0.866764102055741
0.8260299199157425
0.7472915500213457
0.8874866998217976
0.7441602305581367
0.22948143665096393
0.6763976434023368
0.5909756859477309
0.6775915070630182
0.8311737665735953
0.5882947608660276
0.7888779075700829
0.9530393862783458
0.7563942945196994
0.7021129984434293
0.9133573687405422
0.8864659884483975
0.43949477197814607
0.49530015739760547
0.9835705252160515
0.7015569150227223
0.5302361010977743
0.6131123609930033
0.8131827739550247
0.5456264918897312
0.5653128506125247
0.9024119585362896
0.8122852497904204
0.9072724946141106
0.866764102055741
0.8260299199157425
0.7472915500213457
0.8874866998217976
0.7441602305581367
Total groups 76 exceeded the threshold, stopping comparison.
The group tensor is
[6, 5, 2, 3, 7, 0, 4, 1]
tensor([6, 5, 2, 3, 7, 0, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 6, 1, 5, 4, 2, 3, 0]
tensor([7, 6, 1, 5, 4, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[7, 6, 2, 4, 5, 0, 3, 1]
tensor([7, 6, 2, 4, 5, 0, 3, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 0, 0, 5, 1, 1, 3, 2]
tensor([4, 0, 0, 5, 1, 1, 3, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 0, 2, 5, 3, 4, 1]
tensor([0, 1, 0, 2, 5, 3, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 0, 1, 4, 1, 2, 3, 0]
tensor([5, 0, 1, 4, 1, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 1, 1, 3, 4, 2, 5, 0]
tensor([0, 1, 1, 3, 4, 2, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 1, 0, 2, 3, 1, 2, 3]
tensor([0, 1, 0, 2, 3, 1, 2, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([2])
tensor(2)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 2 to 3
done!
Normal merging for layer 4
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 5 to 7
done!
Normal merging for layer 8
tensor([1, 2])
tensor(1)
tensor([4, 5])
tensor(4)
tensor([7])
tensor(7)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([3])
tensor(3)
done!
Cross-layer merge completed for layers 9 to 10
done!
Normal merging for layer 11
tensor([0, 2])
tensor(0)
tensor([1, 7])
tensor(1)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 12 to 13
done!
Normal merging for layer 14
tensor([1, 7])
tensor(1)
tensor([2, 4])
tensor(2)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([0])
tensor(0)
done!
Normal merging for layer 15
tensor([0, 7])
tensor(0)
tensor([1, 2])
tensor(1)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
done!
Normal merging for layer 16
tensor([0, 2])
tensor(0)
tensor([1, 5])
tensor(1)
tensor([3, 6])
tensor(3)
tensor([4, 7])
tensor(4)
done!
Cross-layer merge completed for layers 17 to 31
done!
all done!
Model size: 12.5757 GB
12
cuda:3
mastermind_46_easy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:43<00:43, 43.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:55<00:00, 25.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:55<00:00, 27.76s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_46_mcq_random HTTP/1.1" 200 786
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/flair/mastermind_46_mcq_random/flair/mastermind_46_mcq_random.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_46_mcq_random HTTP/1.1" 200 786
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/flair/mastermind_46_mcq_random/resolve/544d077942975b1664c0bc4fd54df026050329a4/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/flair/mastermind_46_mcq_random/resolve/544d077942975b1664c0bc4fd54df026050329a4/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_46_mcq_random/paths-info/544d077942975b1664c0bc4fd54df026050329a4 HTTP/1.1" 200 218
DEBUG:filelock:Attempting to acquire lock 140239477866912 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_46_mcq_random_default_0.0.0_544d077942975b1664c0bc4fd54df026050329a4.lock
DEBUG:filelock:Lock 140239477866912 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_46_mcq_random_default_0.0.0_544d077942975b1664c0bc4fd54df026050329a4.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_46_mcq_random/default/0.0.0/544d077942975b1664c0bc4fd54df026050329a4/dataset_info.json
DEBUG:filelock:Attempting to release lock 140239477866912 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_46_mcq_random_default_0.0.0_544d077942975b1664c0bc4fd54df026050329a4.lock
DEBUG:filelock:Lock 140239477866912 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_46_mcq_random_default_0.0.0_544d077942975b1664c0bc4fd54df026050329a4.lock
DEBUG:filelock:Attempting to acquire lock 140239477866912 on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_46_mcq_random/default/0.0.0/544d077942975b1664c0bc4fd54df026050329a4_builder.lock
DEBUG:filelock:Lock 140239477866912 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_46_mcq_random/default/0.0.0/544d077942975b1664c0bc4fd54df026050329a4_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_46_mcq_random/default/0.0.0/544d077942975b1664c0bc4fd54df026050329a4/dataset_info.json
DEBUG:filelock:Attempting to release lock 140239477866912 on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_46_mcq_random/default/0.0.0/544d077942975b1664c0bc4fd54df026050329a4_builder.lock
DEBUG:filelock:Lock 140239477866912 released on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_46_mcq_random/default/0.0.0/544d077942975b1664c0bc4fd54df026050329a4_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mastermind_46_easy from None to 0
INFO:lm_eval.api.task:Building contexts for mastermind_46_easy on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1283.32it/s]
DEBUG:lm_eval.evaluator:Task: mastermind_46_easy; number of requests on this rank: 400
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/400 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/400 [00:01<13:07,  1.97s/it]Running loglikelihood requests:   0%|          | 2/400 [00:03<11:18,  1.70s/it]Running loglikelihood requests:   1%|          | 3/400 [00:05<10:42,  1.62s/it]Running loglikelihood requests:   1%|          | 4/400 [00:06<10:24,  1.58s/it]Running loglikelihood requests:   1%|▏         | 5/400 [00:08<10:13,  1.55s/it]Running loglikelihood requests:   2%|▏         | 6/400 [00:09<10:05,  1.54s/it]Running loglikelihood requests:   2%|▏         | 7/400 [00:11<10:00,  1.53s/it]Running loglikelihood requests:   2%|▏         | 8/400 [00:12<09:55,  1.52s/it]Running loglikelihood requests:   2%|▏         | 9/400 [00:14<09:51,  1.51s/it]Running loglikelihood requests:   2%|▎         | 10/400 [00:15<09:47,  1.51s/it]Running loglikelihood requests:   3%|▎         | 11/400 [00:17<09:44,  1.50s/it]Running loglikelihood requests:   3%|▎         | 12/400 [00:18<09:41,  1.50s/it]Running loglikelihood requests:   3%|▎         | 13/400 [00:20<09:39,  1.50s/it]Running loglikelihood requests:   4%|▎         | 14/400 [00:21<09:37,  1.50s/it]Running loglikelihood requests:   4%|▍         | 15/400 [00:23<09:36,  1.50s/it]Running loglikelihood requests:   4%|▍         | 16/400 [00:24<09:34,  1.50s/it]Running loglikelihood requests:   4%|▍         | 17/400 [00:26<09:35,  1.50s/it]Running loglikelihood requests:   4%|▍         | 18/400 [00:27<09:35,  1.51s/it]Running loglikelihood requests:   5%|▍         | 19/400 [00:29<09:31,  1.50s/it]Running loglikelihood requests:   5%|▌         | 20/400 [00:30<09:29,  1.50s/it]Running loglikelihood requests:   5%|▌         | 21/400 [00:31<09:23,  1.49s/it]Running loglikelihood requests:   6%|▌         | 22/400 [00:33<09:23,  1.49s/it]Running loglikelihood requests:   6%|▌         | 23/400 [00:34<09:22,  1.49s/it]Running loglikelihood requests:   6%|▌         | 24/400 [00:36<09:20,  1.49s/it]Running loglikelihood requests:   6%|▋         | 25/400 [00:37<09:18,  1.49s/it]Running loglikelihood requests:   6%|▋         | 26/400 [00:39<09:17,  1.49s/it]Running loglikelihood requests:   7%|▋         | 27/400 [00:40<09:15,  1.49s/it]Running loglikelihood requests:   7%|▋         | 28/400 [00:42<09:13,  1.49s/it]Running loglikelihood requests:   7%|▋         | 29/400 [00:43<09:14,  1.49s/it]Running loglikelihood requests:   8%|▊         | 30/400 [00:45<09:12,  1.49s/it]Running loglikelihood requests:   8%|▊         | 31/400 [00:46<09:06,  1.48s/it]Running loglikelihood requests:   8%|▊         | 32/400 [00:48<09:05,  1.48s/it]Running loglikelihood requests:   8%|▊         | 33/400 [00:49<09:02,  1.48s/it]Running loglikelihood requests:   8%|▊         | 34/400 [00:51<08:59,  1.47s/it]Running loglikelihood requests:   9%|▉         | 35/400 [00:52<08:57,  1.47s/it]Running loglikelihood requests:   9%|▉         | 36/400 [00:54<08:56,  1.47s/it]Running loglikelihood requests:   9%|▉         | 37/400 [00:55<08:57,  1.48s/it]Running loglikelihood requests:  10%|▉         | 38/400 [00:57<08:57,  1.48s/it]Running loglikelihood requests:  10%|▉         | 39/400 [00:58<08:56,  1.49s/it]Running loglikelihood requests:  10%|█         | 40/400 [01:00<08:56,  1.49s/it]Running loglikelihood requests:  10%|█         | 41/400 [01:01<08:54,  1.49s/it]Running loglikelihood requests:  10%|█         | 42/400 [01:03<08:53,  1.49s/it]Running loglikelihood requests:  11%|█         | 43/400 [01:04<08:51,  1.49s/it]Running loglikelihood requests:  11%|█         | 44/400 [01:06<08:49,  1.49s/it]Running loglikelihood requests:  11%|█▏        | 45/400 [01:07<08:47,  1.48s/it]Running loglikelihood requests:  12%|█▏        | 46/400 [01:09<08:45,  1.49s/it]Running loglikelihood requests:  12%|█▏        | 47/400 [01:10<08:44,  1.49s/it]Running loglikelihood requests:  12%|█▏        | 48/400 [01:12<08:42,  1.49s/it]Running loglikelihood requests:  12%|█▏        | 49/400 [01:13<08:40,  1.48s/it]Running loglikelihood requests:  12%|█▎        | 50/400 [01:15<08:39,  1.49s/it]Running loglikelihood requests:  13%|█▎        | 51/400 [01:16<08:37,  1.48s/it]Running loglikelihood requests:  13%|█▎        | 52/400 [01:18<08:36,  1.48s/it]Running loglikelihood requests:  13%|█▎        | 53/400 [01:19<08:34,  1.48s/it]Running loglikelihood requests:  14%|█▎        | 54/400 [01:20<08:32,  1.48s/it]Running loglikelihood requests:  14%|█▍        | 55/400 [01:22<08:30,  1.48s/it]Running loglikelihood requests:  14%|█▍        | 56/400 [01:23<08:29,  1.48s/it]Running loglikelihood requests:  14%|█▍        | 57/400 [01:25<08:27,  1.48s/it]Running loglikelihood requests:  14%|█▍        | 58/400 [01:26<08:25,  1.48s/it]Running loglikelihood requests:  15%|█▍        | 59/400 [01:28<08:24,  1.48s/it]Running loglikelihood requests:  15%|█▌        | 60/400 [01:29<08:24,  1.48s/it]Running loglikelihood requests:  15%|█▌        | 61/400 [01:31<08:22,  1.48s/it]Running loglikelihood requests:  16%|█▌        | 62/400 [01:32<08:20,  1.48s/it]Running loglikelihood requests:  16%|█▌        | 63/400 [01:34<08:18,  1.48s/it]Running loglikelihood requests:  16%|█▌        | 64/400 [01:35<08:16,  1.48s/it]Running loglikelihood requests:  16%|█▋        | 65/400 [01:37<08:14,  1.48s/it]Running loglikelihood requests:  16%|█▋        | 66/400 [01:38<08:13,  1.48s/it]Running loglikelihood requests:  17%|█▋        | 67/400 [01:40<08:11,  1.48s/it]Running loglikelihood requests:  17%|█▋        | 68/400 [01:41<08:09,  1.48s/it]Running loglikelihood requests:  17%|█▋        | 69/400 [01:43<08:08,  1.47s/it]Running loglikelihood requests:  18%|█▊        | 71/400 [01:44<06:13,  1.13s/it]Running loglikelihood requests:  18%|█▊        | 72/400 [01:46<06:39,  1.22s/it]Running loglikelihood requests:  18%|█▊        | 73/400 [01:47<06:59,  1.28s/it]Running loglikelihood requests:  18%|█▊        | 74/400 [01:49<07:15,  1.33s/it]Running loglikelihood requests:  19%|█▉        | 75/400 [01:50<07:26,  1.37s/it]Running loglikelihood requests:  19%|█▉        | 76/400 [01:51<07:33,  1.40s/it]Running loglikelihood requests:  19%|█▉        | 77/400 [01:53<07:38,  1.42s/it]Running loglikelihood requests:  20%|█▉        | 78/400 [01:54<07:40,  1.43s/it]Running loglikelihood requests:  20%|█▉        | 79/400 [01:56<07:43,  1.44s/it]Running loglikelihood requests:  20%|██        | 80/400 [01:57<07:41,  1.44s/it]Running loglikelihood requests:  20%|██        | 81/400 [01:59<07:39,  1.44s/it]Running loglikelihood requests:  20%|██        | 82/400 [02:00<07:42,  1.45s/it]Running loglikelihood requests:  21%|██        | 83/400 [02:02<07:41,  1.46s/it]Running loglikelihood requests:  21%|██        | 84/400 [02:03<07:40,  1.46s/it]Running loglikelihood requests:  21%|██▏       | 85/400 [02:05<07:39,  1.46s/it]Running loglikelihood requests:  22%|██▏       | 86/400 [02:06<07:38,  1.46s/it]Running loglikelihood requests:  22%|██▏       | 87/400 [02:08<07:37,  1.46s/it]Running loglikelihood requests:  22%|██▏       | 88/400 [02:09<07:35,  1.46s/it]Running loglikelihood requests:  22%|██▏       | 89/400 [02:10<07:33,  1.46s/it]Running loglikelihood requests:  22%|██▎       | 90/400 [02:12<07:31,  1.46s/it]Running loglikelihood requests:  23%|██▎       | 91/400 [02:13<07:29,  1.46s/it]Running loglikelihood requests:  23%|██▎       | 92/400 [02:15<07:27,  1.45s/it]Running loglikelihood requests:  23%|██▎       | 93/400 [02:16<07:26,  1.45s/it]Running loglikelihood requests:  24%|██▎       | 94/400 [02:18<07:24,  1.45s/it]Running loglikelihood requests:  24%|██▍       | 95/400 [02:19<07:23,  1.45s/it]Running loglikelihood requests:  24%|██▍       | 96/400 [02:21<07:21,  1.45s/it]Running loglikelihood requests:  24%|██▍       | 97/400 [02:22<07:20,  1.45s/it]Running loglikelihood requests:  24%|██▍       | 98/400 [02:24<07:18,  1.45s/it]Running loglikelihood requests:  25%|██▍       | 99/400 [02:25<07:18,  1.46s/it]Running loglikelihood requests:  25%|██▌       | 100/400 [02:26<07:13,  1.44s/it]Running loglikelihood requests:  25%|██▌       | 101/400 [02:28<07:09,  1.44s/it]Running loglikelihood requests:  26%|██▌       | 102/400 [02:29<07:06,  1.43s/it]Running loglikelihood requests:  26%|██▌       | 103/400 [02:31<07:04,  1.43s/it]Running loglikelihood requests:  26%|██▌       | 104/400 [02:32<07:05,  1.44s/it]Running loglikelihood requests:  26%|██▋       | 105/400 [02:34<07:05,  1.44s/it]Running loglikelihood requests:  26%|██▋       | 106/400 [02:35<07:05,  1.45s/it]Running loglikelihood requests:  27%|██▋       | 107/400 [02:36<07:03,  1.45s/it]Running loglikelihood requests:  27%|██▋       | 108/400 [02:38<07:02,  1.45s/it]Running loglikelihood requests:  27%|██▋       | 109/400 [02:39<07:01,  1.45s/it]Running loglikelihood requests:  28%|██▊       | 110/400 [02:41<06:59,  1.45s/it]Running loglikelihood requests:  28%|██▊       | 111/400 [02:42<06:58,  1.45s/it]Running loglikelihood requests:  28%|██▊       | 112/400 [02:44<06:56,  1.45s/it]Running loglikelihood requests:  28%|██▊       | 113/400 [02:45<06:54,  1.45s/it]Running loglikelihood requests:  28%|██▊       | 114/400 [02:47<06:52,  1.44s/it]Running loglikelihood requests:  29%|██▉       | 115/400 [02:48<06:51,  1.44s/it]Running loglikelihood requests:  29%|██▉       | 116/400 [02:49<06:49,  1.44s/it]Running loglikelihood requests:  29%|██▉       | 117/400 [02:51<06:48,  1.44s/it]Running loglikelihood requests:  30%|██▉       | 118/400 [02:52<06:47,  1.44s/it]Running loglikelihood requests:  30%|██▉       | 119/400 [02:54<06:46,  1.45s/it]Running loglikelihood requests:  30%|███       | 120/400 [02:55<06:41,  1.43s/it]Running loglikelihood requests:  30%|███       | 121/400 [02:57<06:40,  1.44s/it]Running loglikelihood requests:  30%|███       | 122/400 [02:58<06:39,  1.44s/it]Running loglikelihood requests:  31%|███       | 123/400 [03:00<06:38,  1.44s/it]Running loglikelihood requests:  31%|███       | 124/400 [03:01<06:37,  1.44s/it]Running loglikelihood requests:  31%|███▏      | 125/400 [03:02<06:36,  1.44s/it]Running loglikelihood requests:  32%|███▏      | 126/400 [03:04<06:34,  1.44s/it]Running loglikelihood requests:  32%|███▏      | 127/400 [03:05<06:33,  1.44s/it]Running loglikelihood requests:  32%|███▏      | 128/400 [03:07<06:31,  1.44s/it]Running loglikelihood requests:  32%|███▏      | 129/400 [03:08<06:29,  1.44s/it]Running loglikelihood requests:  32%|███▎      | 130/400 [03:10<06:27,  1.44s/it]Running loglikelihood requests:  33%|███▎      | 131/400 [03:11<06:25,  1.43s/it]Running loglikelihood requests:  33%|███▎      | 132/400 [03:12<06:24,  1.44s/it]Running loglikelihood requests:  33%|███▎      | 133/400 [03:14<06:22,  1.43s/it]Running loglikelihood requests:  34%|███▎      | 134/400 [03:15<06:21,  1.43s/it]Running loglikelihood requests:  34%|███▍      | 135/400 [03:17<06:19,  1.43s/it]Running loglikelihood requests:  34%|███▍      | 136/400 [03:18<06:18,  1.43s/it]Running loglikelihood requests:  34%|███▍      | 137/400 [03:20<06:16,  1.43s/it]Running loglikelihood requests:  34%|███▍      | 138/400 [03:21<06:14,  1.43s/it]Running loglikelihood requests:  35%|███▍      | 139/400 [03:23<06:12,  1.43s/it]Running loglikelihood requests:  35%|███▌      | 140/400 [03:24<06:11,  1.43s/it]Running loglikelihood requests:  35%|███▌      | 141/400 [03:25<06:10,  1.43s/it]Running loglikelihood requests:  36%|███▌      | 142/400 [03:27<06:08,  1.43s/it]Running loglikelihood requests:  36%|███▌      | 143/400 [03:28<06:07,  1.43s/it]Running loglikelihood requests:  36%|███▌      | 144/400 [03:30<06:05,  1.43s/it]Running loglikelihood requests:  36%|███▋      | 145/400 [03:31<06:03,  1.43s/it]Running loglikelihood requests:  36%|███▋      | 146/400 [03:32<06:01,  1.42s/it]Running loglikelihood requests:  37%|███▋      | 147/400 [03:34<06:02,  1.43s/it]Running loglikelihood requests:  37%|███▋      | 148/400 [03:35<06:00,  1.43s/it]Running loglikelihood requests:  37%|███▋      | 149/400 [03:37<05:57,  1.43s/it]Running loglikelihood requests:  38%|███▊      | 150/400 [03:38<05:55,  1.42s/it]Running loglikelihood requests:  38%|███▊      | 151/400 [03:40<05:54,  1.42s/it]Running loglikelihood requests:  38%|███▊      | 152/400 [03:41<05:52,  1.42s/it]Running loglikelihood requests:  38%|███▊      | 153/400 [03:42<05:50,  1.42s/it]Running loglikelihood requests:  38%|███▊      | 154/400 [03:44<05:48,  1.42s/it]Running loglikelihood requests:  39%|███▉      | 155/400 [03:45<05:47,  1.42s/it]Running loglikelihood requests:  39%|███▉      | 156/400 [03:47<05:45,  1.42s/it]Running loglikelihood requests:  39%|███▉      | 157/400 [03:48<05:43,  1.42s/it]Running loglikelihood requests:  40%|███▉      | 158/400 [03:50<05:42,  1.41s/it]Running loglikelihood requests:  40%|███▉      | 159/400 [03:51<05:40,  1.41s/it]Running loglikelihood requests:  40%|████      | 160/400 [03:52<05:38,  1.41s/it]Running loglikelihood requests:  40%|████      | 161/400 [03:54<05:38,  1.42s/it]Running loglikelihood requests:  40%|████      | 162/400 [03:55<05:36,  1.41s/it]Running loglikelihood requests:  41%|████      | 163/400 [03:57<05:34,  1.41s/it]Running loglikelihood requests:  41%|████      | 164/400 [03:58<05:32,  1.41s/it]Running loglikelihood requests:  41%|████▏     | 165/400 [03:59<05:30,  1.41s/it]Running loglikelihood requests:  42%|████▏     | 166/400 [04:01<05:28,  1.40s/it]Running loglikelihood requests:  42%|████▏     | 167/400 [04:02<05:27,  1.41s/it]Running loglikelihood requests:  42%|████▏     | 168/400 [04:04<05:26,  1.41s/it]Running loglikelihood requests:  42%|████▏     | 169/400 [04:05<05:24,  1.41s/it]Running loglikelihood requests:  42%|████▎     | 170/400 [04:06<05:23,  1.41s/it]Running loglikelihood requests:  43%|████▎     | 171/400 [04:08<05:22,  1.41s/it]Running loglikelihood requests:  43%|████▎     | 172/400 [04:09<05:20,  1.41s/it]Running loglikelihood requests:  43%|████▎     | 173/400 [04:11<05:19,  1.41s/it]Running loglikelihood requests:  44%|████▎     | 174/400 [04:12<05:19,  1.41s/it]Running loglikelihood requests:  44%|████▍     | 175/400 [04:13<05:15,  1.40s/it]Running loglikelihood requests:  44%|████▍     | 176/400 [04:15<05:12,  1.40s/it]Running loglikelihood requests:  44%|████▍     | 177/400 [04:16<05:10,  1.39s/it]Running loglikelihood requests:  44%|████▍     | 178/400 [04:18<05:07,  1.39s/it]Running loglikelihood requests:  45%|████▍     | 179/400 [04:19<05:08,  1.40s/it]Running loglikelihood requests:  45%|████▌     | 180/400 [04:20<05:07,  1.40s/it]Running loglikelihood requests:  45%|████▌     | 181/400 [04:22<05:06,  1.40s/it]Running loglikelihood requests:  46%|████▌     | 182/400 [04:23<05:05,  1.40s/it]Running loglikelihood requests:  46%|████▌     | 183/400 [04:25<05:03,  1.40s/it]Running loglikelihood requests:  46%|████▌     | 184/400 [04:26<05:02,  1.40s/it]Running loglikelihood requests:  46%|████▋     | 185/400 [04:27<05:00,  1.40s/it]Running loglikelihood requests:  46%|████▋     | 186/400 [04:29<04:59,  1.40s/it]Running loglikelihood requests:  47%|████▋     | 187/400 [04:30<04:58,  1.40s/it]Running loglikelihood requests:  47%|████▋     | 188/400 [04:32<04:54,  1.39s/it]Running loglikelihood requests:  47%|████▋     | 189/400 [04:33<04:51,  1.38s/it]Running loglikelihood requests:  48%|████▊     | 190/400 [04:34<04:49,  1.38s/it]Running loglikelihood requests:  48%|████▊     | 191/400 [04:36<04:47,  1.38s/it]Running loglikelihood requests:  48%|████▊     | 192/400 [04:37<04:45,  1.37s/it]Running loglikelihood requests:  48%|████▊     | 193/400 [04:38<04:43,  1.37s/it]Running loglikelihood requests:  48%|████▊     | 194/400 [04:40<04:44,  1.38s/it]Running loglikelihood requests:  49%|████▉     | 195/400 [04:41<04:44,  1.39s/it]Running loglikelihood requests:  49%|████▉     | 196/400 [04:43<04:43,  1.39s/it]Running loglikelihood requests:  49%|████▉     | 197/400 [04:44<04:42,  1.39s/it]Running loglikelihood requests:  50%|████▉     | 198/400 [04:45<04:41,  1.39s/it]Running loglikelihood requests:  50%|████▉     | 199/400 [04:47<04:39,  1.39s/it]Running loglikelihood requests:  50%|█████     | 200/400 [04:48<04:38,  1.39s/it]Running loglikelihood requests:  50%|█████     | 201/400 [04:50<04:36,  1.39s/it]Running loglikelihood requests:  50%|█████     | 202/400 [04:51<04:35,  1.39s/it]Running loglikelihood requests:  51%|█████     | 203/400 [04:52<04:33,  1.39s/it]Running loglikelihood requests:  51%|█████     | 204/400 [04:54<04:32,  1.39s/it]Running loglikelihood requests:  51%|█████▏    | 205/400 [04:55<04:30,  1.39s/it]Running loglikelihood requests:  52%|█████▏    | 206/400 [04:57<04:29,  1.39s/it]Running loglikelihood requests:  52%|█████▏    | 207/400 [04:58<04:28,  1.39s/it]Running loglikelihood requests:  52%|█████▏    | 208/400 [04:59<04:26,  1.39s/it]Running loglikelihood requests:  52%|█████▏    | 209/400 [05:01<04:25,  1.39s/it]Running loglikelihood requests:  52%|█████▎    | 210/400 [05:02<04:24,  1.39s/it]Running loglikelihood requests:  53%|█████▎    | 211/400 [05:03<04:22,  1.39s/it]Running loglikelihood requests:  53%|█████▎    | 212/400 [05:05<04:21,  1.39s/it]Running loglikelihood requests:  53%|█████▎    | 213/400 [05:06<04:19,  1.39s/it]Running loglikelihood requests:  54%|█████▎    | 214/400 [05:08<04:17,  1.39s/it]Running loglikelihood requests:  54%|█████▍    | 215/400 [05:09<04:15,  1.38s/it]Running loglikelihood requests:  54%|█████▍    | 216/400 [05:10<04:14,  1.38s/it]Running loglikelihood requests:  54%|█████▍    | 217/400 [05:12<04:12,  1.38s/it]Running loglikelihood requests:  55%|█████▍    | 218/400 [05:13<04:11,  1.38s/it]Running loglikelihood requests:  55%|█████▍    | 219/400 [05:15<04:10,  1.38s/it]Running loglikelihood requests:  55%|█████▌    | 220/400 [05:16<04:07,  1.37s/it]Running loglikelihood requests:  55%|█████▌    | 221/400 [05:17<04:05,  1.37s/it]Running loglikelihood requests:  56%|█████▌    | 222/400 [05:19<04:02,  1.36s/it]Running loglikelihood requests:  56%|█████▌    | 223/400 [05:20<04:01,  1.36s/it]Running loglikelihood requests:  56%|█████▌    | 224/400 [05:21<03:59,  1.36s/it]Running loglikelihood requests:  56%|█████▋    | 225/400 [05:23<03:57,  1.36s/it]Running loglikelihood requests:  56%|█████▋    | 226/400 [05:24<03:55,  1.36s/it]Running loglikelihood requests:  57%|█████▋    | 227/400 [05:25<03:54,  1.35s/it]Running loglikelihood requests:  57%|█████▋    | 228/400 [05:27<03:53,  1.36s/it]Running loglikelihood requests:  57%|█████▋    | 229/400 [05:28<03:53,  1.36s/it]Running loglikelihood requests:  57%|█████▊    | 230/400 [05:29<03:51,  1.36s/it]Running loglikelihood requests:  58%|█████▊    | 231/400 [05:31<03:50,  1.36s/it]Running loglikelihood requests:  58%|█████▊    | 232/400 [05:32<03:48,  1.36s/it]Running loglikelihood requests:  58%|█████▊    | 233/400 [05:34<03:47,  1.36s/it]Running loglikelihood requests:  58%|█████▊    | 234/400 [05:35<03:46,  1.36s/it]Running loglikelihood requests:  59%|█████▉    | 235/400 [05:36<03:44,  1.36s/it]Running loglikelihood requests:  59%|█████▉    | 236/400 [05:38<03:43,  1.36s/it]Running loglikelihood requests:  59%|█████▉    | 237/400 [05:39<03:41,  1.36s/it]Running loglikelihood requests:  60%|█████▉    | 238/400 [05:40<03:40,  1.36s/it]Running loglikelihood requests:  60%|█████▉    | 239/400 [05:42<03:38,  1.36s/it]Running loglikelihood requests:  60%|██████    | 240/400 [05:43<03:38,  1.36s/it]Running loglikelihood requests:  60%|██████    | 241/400 [05:44<03:35,  1.35s/it]Running loglikelihood requests:  60%|██████    | 242/400 [05:46<03:33,  1.35s/it]Running loglikelihood requests:  61%|██████    | 243/400 [05:47<03:30,  1.34s/it]Running loglikelihood requests:  61%|██████    | 244/400 [05:48<03:29,  1.34s/it]Running loglikelihood requests:  61%|██████▏   | 245/400 [05:50<03:26,  1.33s/it]Running loglikelihood requests:  62%|██████▏   | 246/400 [05:51<03:23,  1.32s/it]Running loglikelihood requests:  62%|██████▏   | 247/400 [05:52<03:21,  1.32s/it]Running loglikelihood requests:  62%|██████▏   | 248/400 [05:54<03:21,  1.32s/it]Running loglikelihood requests:  62%|██████▏   | 249/400 [05:55<03:19,  1.32s/it]Running loglikelihood requests:  62%|██████▎   | 250/400 [05:56<03:17,  1.32s/it]Running loglikelihood requests:  63%|██████▎   | 251/400 [05:58<03:15,  1.32s/it]Running loglikelihood requests:  63%|██████▎   | 252/400 [05:59<03:14,  1.31s/it]Running loglikelihood requests:  63%|██████▎   | 253/400 [06:00<03:12,  1.31s/it]Running loglikelihood requests:  64%|██████▎   | 254/400 [06:02<03:11,  1.31s/it]Running loglikelihood requests:  64%|██████▍   | 255/400 [06:03<03:09,  1.31s/it]Running loglikelihood requests:  64%|██████▍   | 256/400 [06:04<03:07,  1.31s/it]Running loglikelihood requests:  64%|██████▍   | 257/400 [06:05<03:07,  1.31s/it]Running loglikelihood requests:  64%|██████▍   | 258/400 [06:07<03:05,  1.30s/it]Running loglikelihood requests:  65%|██████▍   | 259/400 [06:08<03:03,  1.30s/it]Running loglikelihood requests:  65%|██████▌   | 260/400 [06:09<03:01,  1.30s/it]Running loglikelihood requests:  65%|██████▌   | 261/400 [06:11<02:59,  1.29s/it]Running loglikelihood requests:  66%|██████▌   | 262/400 [06:12<02:58,  1.29s/it]Running loglikelihood requests:  66%|██████▌   | 263/400 [06:13<02:56,  1.29s/it]Running loglikelihood requests:  66%|██████▌   | 264/400 [06:14<02:56,  1.29s/it]Running loglikelihood requests:  66%|██████▋   | 265/400 [06:16<02:54,  1.30s/it]Running loglikelihood requests:  66%|██████▋   | 266/400 [06:17<02:54,  1.30s/it]Running loglikelihood requests:  67%|██████▋   | 267/400 [06:18<02:52,  1.30s/it]Running loglikelihood requests:  67%|██████▋   | 268/400 [06:20<02:51,  1.30s/it]Running loglikelihood requests:  67%|██████▋   | 269/400 [06:21<02:50,  1.30s/it]Running loglikelihood requests:  68%|██████▊   | 270/400 [06:22<02:49,  1.30s/it]Running loglikelihood requests:  68%|██████▊   | 271/400 [06:24<02:47,  1.30s/it]Running loglikelihood requests:  68%|██████▊   | 272/400 [06:25<02:46,  1.30s/it]Running loglikelihood requests:  68%|██████▊   | 273/400 [06:26<02:45,  1.30s/it]Running loglikelihood requests:  68%|██████▊   | 274/400 [06:27<02:44,  1.30s/it]Running loglikelihood requests:  69%|██████▉   | 275/400 [06:29<02:42,  1.30s/it]Running loglikelihood requests:  69%|██████▉   | 276/400 [06:30<02:40,  1.29s/it]Running loglikelihood requests:  69%|██████▉   | 277/400 [06:31<02:37,  1.28s/it]Running loglikelihood requests:  70%|██████▉   | 278/400 [06:33<02:37,  1.29s/it]Running loglikelihood requests:  70%|██████▉   | 279/400 [06:34<02:36,  1.30s/it]Running loglikelihood requests:  70%|███████   | 280/400 [06:35<02:36,  1.30s/it]Running loglikelihood requests:  70%|███████   | 281/400 [06:37<02:35,  1.31s/it]Running loglikelihood requests:  70%|███████   | 282/400 [06:38<02:34,  1.31s/it]Running loglikelihood requests:  71%|███████   | 283/400 [06:39<02:33,  1.31s/it]Running loglikelihood requests:  71%|███████   | 284/400 [06:40<02:31,  1.31s/it]Running loglikelihood requests:  71%|███████▏  | 285/400 [06:42<02:30,  1.31s/it]Running loglikelihood requests:  72%|███████▏  | 286/400 [06:43<02:29,  1.31s/it]Running loglikelihood requests:  72%|███████▏  | 287/400 [06:44<02:28,  1.31s/it]Running loglikelihood requests:  72%|███████▏  | 288/400 [06:46<02:26,  1.31s/it]Running loglikelihood requests:  72%|███████▏  | 289/400 [06:47<02:25,  1.31s/it]Running loglikelihood requests:  72%|███████▎  | 290/400 [06:48<02:24,  1.31s/it]Running loglikelihood requests:  73%|███████▎  | 291/400 [06:50<02:22,  1.31s/it]Running loglikelihood requests:  73%|███████▎  | 292/400 [06:51<02:21,  1.31s/it]Running loglikelihood requests:  73%|███████▎  | 293/400 [06:52<02:19,  1.31s/it]Running loglikelihood requests:  74%|███████▎  | 294/400 [06:54<02:18,  1.31s/it]Running loglikelihood requests:  74%|███████▍  | 295/400 [06:55<02:16,  1.30s/it]Running loglikelihood requests:  74%|███████▍  | 296/400 [06:56<02:15,  1.30s/it]Running loglikelihood requests:  74%|███████▍  | 297/400 [06:57<02:13,  1.30s/it]Running loglikelihood requests:  74%|███████▍  | 298/400 [06:59<02:12,  1.30s/it]Running loglikelihood requests:  75%|███████▍  | 299/400 [07:00<02:10,  1.30s/it]Running loglikelihood requests:  75%|███████▌  | 300/400 [07:01<02:09,  1.30s/it]Running loglikelihood requests:  75%|███████▌  | 301/400 [07:03<02:08,  1.29s/it]Running loglikelihood requests:  76%|███████▌  | 302/400 [07:04<02:06,  1.29s/it]Running loglikelihood requests:  76%|███████▌  | 303/400 [07:05<02:05,  1.29s/it]Running loglikelihood requests:  76%|███████▌  | 304/400 [07:07<02:03,  1.29s/it]Running loglikelihood requests:  76%|███████▋  | 305/400 [07:08<02:02,  1.29s/it]Running loglikelihood requests:  76%|███████▋  | 306/400 [07:09<02:01,  1.29s/it]Running loglikelihood requests:  77%|███████▋  | 307/400 [07:10<01:59,  1.29s/it]Running loglikelihood requests:  77%|███████▋  | 308/400 [07:12<01:58,  1.29s/it]Running loglikelihood requests:  77%|███████▋  | 309/400 [07:13<01:57,  1.29s/it]Running loglikelihood requests:  78%|███████▊  | 310/400 [07:14<01:55,  1.29s/it]Running loglikelihood requests:  78%|███████▊  | 311/400 [07:15<01:53,  1.28s/it]Running loglikelihood requests:  78%|███████▊  | 312/400 [07:17<01:51,  1.27s/it]Running loglikelihood requests:  78%|███████▊  | 313/400 [07:18<01:50,  1.27s/it]Running loglikelihood requests:  78%|███████▊  | 314/400 [07:19<01:48,  1.26s/it]Running loglikelihood requests:  79%|███████▉  | 315/400 [07:21<01:47,  1.26s/it]Running loglikelihood requests:  79%|███████▉  | 316/400 [07:22<01:45,  1.26s/it]Running loglikelihood requests:  79%|███████▉  | 317/400 [07:23<01:44,  1.26s/it]Running loglikelihood requests:  80%|███████▉  | 318/400 [07:24<01:43,  1.26s/it]Running loglikelihood requests:  80%|███████▉  | 319/400 [07:26<01:42,  1.27s/it]Running loglikelihood requests:  80%|████████  | 320/400 [07:27<01:41,  1.27s/it]Running loglikelihood requests:  80%|████████  | 321/400 [07:28<01:39,  1.26s/it]Running loglikelihood requests:  80%|████████  | 322/400 [07:29<01:38,  1.26s/it]Running loglikelihood requests:  81%|████████  | 323/400 [07:31<01:36,  1.26s/it]Running loglikelihood requests:  81%|████████  | 324/400 [07:32<01:35,  1.25s/it]Running loglikelihood requests:  81%|████████▏ | 325/400 [07:33<01:34,  1.25s/it]Running loglikelihood requests:  82%|████████▏ | 326/400 [07:34<01:32,  1.25s/it]Running loglikelihood requests:  82%|████████▏ | 327/400 [07:36<01:31,  1.25s/it]Running loglikelihood requests:  82%|████████▏ | 328/400 [07:37<01:30,  1.25s/it]Running loglikelihood requests:  82%|████████▏ | 329/400 [07:38<01:28,  1.25s/it]Running loglikelihood requests:  82%|████████▎ | 330/400 [07:39<01:27,  1.25s/it]Running loglikelihood requests:  83%|████████▎ | 331/400 [07:41<01:26,  1.25s/it]Running loglikelihood requests:  83%|████████▎ | 332/400 [07:42<01:25,  1.26s/it]Running loglikelihood requests:  83%|████████▎ | 333/400 [07:43<01:23,  1.25s/it]Running loglikelihood requests:  84%|████████▎ | 334/400 [07:44<01:22,  1.25s/it]Running loglikelihood requests:  84%|████████▍ | 335/400 [07:46<01:20,  1.24s/it]Running loglikelihood requests:  84%|████████▍ | 336/400 [07:47<01:19,  1.24s/it]Running loglikelihood requests:  84%|████████▍ | 337/400 [07:48<01:18,  1.24s/it]Running loglikelihood requests:  84%|████████▍ | 338/400 [07:49<01:17,  1.24s/it]Running loglikelihood requests:  85%|████████▍ | 339/400 [07:51<01:15,  1.24s/it]Running loglikelihood requests:  85%|████████▌ | 340/400 [07:52<01:14,  1.25s/it]Running loglikelihood requests:  85%|████████▌ | 341/400 [07:53<01:13,  1.25s/it]Running loglikelihood requests:  86%|████████▌ | 342/400 [07:54<01:12,  1.25s/it]Running loglikelihood requests:  86%|████████▌ | 343/400 [07:56<01:11,  1.25s/it]Running loglikelihood requests:  86%|████████▌ | 344/400 [07:57<01:09,  1.25s/it]Running loglikelihood requests:  86%|████████▋ | 345/400 [07:58<01:08,  1.25s/it]Running loglikelihood requests:  86%|████████▋ | 346/400 [07:59<01:07,  1.24s/it]Running loglikelihood requests:  87%|████████▋ | 347/400 [08:01<01:05,  1.24s/it]Running loglikelihood requests:  87%|████████▋ | 348/400 [08:02<01:04,  1.24s/it]Running loglikelihood requests:  87%|████████▋ | 349/400 [08:03<01:03,  1.24s/it]Running loglikelihood requests:  88%|████████▊ | 350/400 [08:04<01:02,  1.24s/it]Running loglikelihood requests:  88%|████████▊ | 351/400 [08:05<01:00,  1.24s/it]Running loglikelihood requests:  88%|████████▊ | 352/400 [08:07<00:59,  1.24s/it]Running loglikelihood requests:  88%|████████▊ | 353/400 [08:08<00:58,  1.24s/it]Running loglikelihood requests:  88%|████████▊ | 354/400 [08:09<00:57,  1.24s/it]Running loglikelihood requests:  89%|████████▉ | 355/400 [08:10<00:55,  1.24s/it]Running loglikelihood requests:  89%|████████▉ | 356/400 [08:12<00:54,  1.24s/it]Running loglikelihood requests:  89%|████████▉ | 357/400 [08:13<00:53,  1.24s/it]Running loglikelihood requests:  90%|████████▉ | 358/400 [08:14<00:52,  1.24s/it]Running loglikelihood requests:  90%|████████▉ | 359/400 [08:15<00:50,  1.24s/it]Running loglikelihood requests:  90%|█████████ | 360/400 [08:17<00:49,  1.25s/it]Running loglikelihood requests:  90%|█████████ | 361/400 [08:18<00:48,  1.24s/it]Running loglikelihood requests:  90%|█████████ | 362/400 [08:19<00:46,  1.24s/it]Running loglikelihood requests:  91%|█████████ | 363/400 [08:20<00:45,  1.24s/it]Running loglikelihood requests:  91%|█████████ | 364/400 [08:22<00:44,  1.23s/it]Running loglikelihood requests:  91%|█████████▏| 365/400 [08:23<00:43,  1.23s/it]Running loglikelihood requests:  92%|█████████▏| 366/400 [08:24<00:41,  1.23s/it]Running loglikelihood requests:  92%|█████████▏| 367/400 [08:25<00:40,  1.23s/it]Running loglikelihood requests:  92%|█████████▏| 368/400 [08:26<00:39,  1.22s/it]Running loglikelihood requests:  92%|█████████▏| 369/400 [08:28<00:37,  1.22s/it]Running loglikelihood requests:  92%|█████████▎| 370/400 [08:29<00:36,  1.22s/it]Running loglikelihood requests:  93%|█████████▎| 371/400 [08:30<00:35,  1.22s/it]Running loglikelihood requests:  93%|█████████▎| 372/400 [08:31<00:34,  1.22s/it]Running loglikelihood requests:  93%|█████████▎| 373/400 [08:33<00:32,  1.22s/it]Running loglikelihood requests:  94%|█████████▎| 374/400 [08:34<00:31,  1.21s/it]Running loglikelihood requests:  94%|█████████▍| 375/400 [08:35<00:30,  1.21s/it]Running loglikelihood requests:  94%|█████████▍| 376/400 [08:36<00:29,  1.21s/it]Running loglikelihood requests:  94%|█████████▍| 377/400 [08:37<00:27,  1.21s/it]Running loglikelihood requests:  94%|█████████▍| 378/400 [08:39<00:26,  1.21s/it]Running loglikelihood requests:  95%|█████████▍| 379/400 [08:40<00:25,  1.21s/it]Running loglikelihood requests:  95%|█████████▌| 380/400 [08:41<00:24,  1.20s/it]Running loglikelihood requests:  95%|█████████▌| 381/400 [08:42<00:22,  1.20s/it]Running loglikelihood requests:  96%|█████████▌| 382/400 [08:43<00:21,  1.20s/it]Running loglikelihood requests:  96%|█████████▌| 383/400 [08:45<00:20,  1.20s/it]Running loglikelihood requests:  96%|█████████▌| 384/400 [08:46<00:19,  1.19s/it]Running loglikelihood requests:  96%|█████████▋| 385/400 [08:47<00:17,  1.18s/it]Running loglikelihood requests:  96%|█████████▋| 386/400 [08:48<00:16,  1.18s/it]Running loglikelihood requests:  97%|█████████▋| 387/400 [08:49<00:15,  1.17s/it]Running loglikelihood requests:  97%|█████████▋| 388/400 [08:50<00:14,  1.17s/it]Running loglikelihood requests:  97%|█████████▋| 389/400 [08:51<00:12,  1.14s/it]Running loglikelihood requests:  98%|█████████▊| 390/400 [08:53<00:11,  1.12s/it]Running loglikelihood requests:  98%|█████████▊| 391/400 [08:54<00:09,  1.11s/it]Running loglikelihood requests:  98%|█████████▊| 392/400 [08:55<00:08,  1.10s/it]Running loglikelihood requests:  98%|█████████▊| 393/400 [08:56<00:07,  1.09s/it]Running loglikelihood requests:  98%|█████████▊| 394/400 [08:57<00:06,  1.08s/it]Running loglikelihood requests:  99%|█████████▉| 395/400 [08:58<00:05,  1.07s/it]Running loglikelihood requests:  99%|█████████▉| 396/400 [08:59<00:04,  1.07s/it]Running loglikelihood requests:  99%|█████████▉| 397/400 [09:00<00:03,  1.06s/it]Running loglikelihood requests: 100%|█████████▉| 398/400 [09:01<00:02,  1.04s/it]Running loglikelihood requests: 100%|█████████▉| 399/400 [09:02<00:01,  1.03s/it]Running loglikelihood requests: 100%|██████████| 400/400 [09:03<00:00,  1.03s/it]Running loglikelihood requests: 100%|██████████| 400/400 [09:03<00:00,  1.36s/it]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:4'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:4'}
full model:
{'mastermind_46_easy': {'alias': 'mastermind_46_easy', 'acc,none': 0.75, 'acc_stderr,none': 0.04351941398892446}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9900730655060652
0.9975621416797388
0.9971758007187725
0.9980230222224056
0.9889479987910904
0.9764864248764976
0.9903944102306983
0.9944743493554844
0.9959595842537624
0.9872350810596702
0.9630442697748985
0.9836939129473328
0.9680042833072414
0.9739989664157891
0.9945965755000291
0.9874567967365809
0.9910190996776087
0.9888895436517939
0.9820307305549418
0.9881803990776891
0.9859944271811626
0.9931460182904469
0.984259193892523
0.99673879588459
0.9800909214289261
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[5, 2, 0, 3, 7, 6, 1, 4]
tensor([5, 2, 0, 3, 7, 6, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 0, 3, 7, 6, 1, 4]
tensor([5, 2, 0, 3, 7, 6, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 0, 3, 7, 6, 1, 4]
tensor([5, 2, 0, 3, 7, 6, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 0, 3, 7, 6, 1, 4]
tensor([5, 2, 0, 3, 7, 6, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 0, 3, 7, 6, 1, 4]
tensor([5, 2, 0, 3, 7, 6, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 0, 3, 7, 6, 1, 4]
tensor([5, 2, 0, 3, 7, 6, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Normal merging for layer 2
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Normal merging for layer 3
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Normal merging for layer 4
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Normal merging for layer 5
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 6 to 31
done!
all done!
Model size: 12.0718 GB
173
cuda:4
coqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:42<00:42, 42.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 24.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 27.49s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa HTTP/1.1" 200 857
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/EleutherAI/coqa/EleutherAI/coqa.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa HTTP/1.1" 200 857
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/coqa/resolve/82e11af842af6c1396f5e9a5c7de260107c50cf1/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa/tree/82e11af842af6c1396f5e9a5c7de260107c50cf1/data?recursive=False&expand=False HTTP/1.1" 404 79
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa/tree/82e11af842af6c1396f5e9a5c7de260107c50cf1/data?recursive=False&expand=False HTTP/1.1" 404 79
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/coqa/resolve/82e11af842af6c1396f5e9a5c7de260107c50cf1/dataset_infos.json HTTP/1.1" 200 0
DEBUG:filelock:Attempting to acquire lock 140240957481296 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___coqa_default_0.0.0_82e11af842af6c1396f5e9a5c7de260107c50cf1.lock
DEBUG:filelock:Lock 140240957481296 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___coqa_default_0.0.0_82e11af842af6c1396f5e9a5c7de260107c50cf1.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1/dataset_info.json
DEBUG:filelock:Attempting to release lock 140240957481296 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___coqa_default_0.0.0_82e11af842af6c1396f5e9a5c7de260107c50cf1.lock
DEBUG:filelock:Lock 140240957481296 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___coqa_default_0.0.0_82e11af842af6c1396f5e9a5c7de260107c50cf1.lock
DEBUG:filelock:Attempting to acquire lock 140237864795648 on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1_builder.lock
DEBUG:filelock:Lock 140237864795648 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1/dataset_info.json
DEBUG:filelock:Attempting to release lock 140237864795648 on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1_builder.lock
DEBUG:filelock:Lock 140237864795648 released on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
DEBUG:lm_eval.api.task:doc_to_target returned a list. Assuming multiple targets.
INFO:lm_eval.evaluator:coqa: Using gen_kwargs: {'until': ['\nQ:']}
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of coqa from None to 0
INFO:lm_eval.api.task:Building contexts for coqa on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 69304.43it/s]
DEBUG:lm_eval.evaluator:Task: coqa; number of requests on this rank: 100
INFO:lm_eval.evaluator:Running generate_until requests
Running generate_until requests:   0%|          | 0/100 [00:00<?, ?it/s]Running generate_until requests:   1%|          | 1/100 [00:05<09:15,  5.61s/it]Running generate_until requests:   2%|▏         | 2/100 [00:10<08:33,  5.24s/it]Running generate_until requests:   3%|▎         | 3/100 [00:16<09:02,  5.59s/it]Running generate_until requests:   4%|▍         | 4/100 [00:21<08:26,  5.27s/it]Running generate_until requests:   5%|▌         | 5/100 [00:26<08:12,  5.18s/it]Running generate_until requests:   6%|▌         | 6/100 [00:31<08:00,  5.11s/it]Running generate_until requests:   7%|▋         | 7/100 [00:37<08:19,  5.37s/it]Running generate_until requests:   8%|▊         | 8/100 [00:42<07:57,  5.19s/it]Running generate_until requests:   9%|▉         | 9/100 [00:47<07:47,  5.14s/it]Running generate_until requests:  10%|█         | 10/100 [00:52<07:52,  5.25s/it]Running generate_until requests:  11%|█         | 11/100 [00:57<07:43,  5.21s/it]Running generate_until requests:  12%|█▏        | 12/100 [01:04<08:06,  5.53s/it]Running generate_until requests:  13%|█▎        | 13/100 [01:08<07:34,  5.22s/it]Running generate_until requests:  14%|█▍        | 14/100 [01:12<07:08,  4.99s/it]Running generate_until requests:  15%|█▌        | 15/100 [01:17<06:56,  4.91s/it]Running generate_until requests:  16%|█▌        | 16/100 [01:22<06:39,  4.75s/it]Running generate_until requests:  17%|█▋        | 17/100 [01:26<06:29,  4.69s/it]Running generate_until requests:  18%|█▊        | 18/100 [01:30<06:11,  4.53s/it]Running generate_until requests:  19%|█▉        | 19/100 [01:35<06:04,  4.50s/it]Running generate_until requests:  20%|██        | 20/100 [01:39<05:53,  4.42s/it]Running generate_until requests:  21%|██        | 21/100 [01:43<05:47,  4.40s/it]Running generate_until requests:  22%|██▏       | 22/100 [01:48<05:41,  4.37s/it]Running generate_until requests:  23%|██▎       | 23/100 [01:53<06:00,  4.69s/it]Running generate_until requests:  24%|██▍       | 24/100 [01:58<06:10,  4.87s/it]Running generate_until requests:  25%|██▌       | 25/100 [02:03<05:50,  4.68s/it]Running generate_until requests:  26%|██▌       | 26/100 [02:07<05:44,  4.65s/it]Running generate_until requests:  27%|██▋       | 27/100 [02:12<05:37,  4.62s/it]Running generate_until requests:  28%|██▊       | 28/100 [02:16<05:28,  4.56s/it]Running generate_until requests:  29%|██▉       | 29/100 [02:21<05:20,  4.52s/it]Running generate_until requests:  30%|███       | 30/100 [02:25<05:23,  4.62s/it]Running generate_until requests:  31%|███       | 31/100 [02:30<05:12,  4.53s/it]Running generate_until requests:  32%|███▏      | 32/100 [02:35<05:16,  4.66s/it]Running generate_until requests:  33%|███▎      | 33/100 [02:39<05:10,  4.63s/it]Running generate_until requests:  34%|███▍      | 34/100 [02:44<05:01,  4.57s/it]Running generate_until requests:  35%|███▌      | 35/100 [02:48<04:46,  4.40s/it]Running generate_until requests:  36%|███▌      | 36/100 [02:53<05:04,  4.76s/it]Running generate_until requests:  37%|███▋      | 37/100 [02:57<04:45,  4.53s/it]Running generate_until requests:  38%|███▊      | 38/100 [03:01<04:33,  4.41s/it]Running generate_until requests:  39%|███▉      | 39/100 [03:06<04:27,  4.38s/it]Running generate_until requests:  40%|████      | 40/100 [03:10<04:17,  4.29s/it]Running generate_until requests:  41%|████      | 41/100 [03:14<04:13,  4.30s/it]Running generate_until requests:  42%|████▏     | 42/100 [03:20<04:28,  4.64s/it]Running generate_until requests:  43%|████▎     | 43/100 [03:24<04:15,  4.49s/it]Running generate_until requests:  44%|████▍     | 44/100 [03:28<04:09,  4.46s/it]Running generate_until requests:  45%|████▌     | 45/100 [03:32<04:01,  4.39s/it]Running generate_until requests:  46%|████▌     | 46/100 [03:36<03:48,  4.23s/it]Running generate_until requests:  47%|████▋     | 47/100 [03:40<03:40,  4.16s/it]Running generate_until requests:  48%|████▊     | 48/100 [03:45<03:39,  4.23s/it]Running generate_until requests:  49%|████▉     | 49/100 [03:49<03:47,  4.45s/it]Running generate_until requests:  50%|█████     | 50/100 [03:53<03:34,  4.28s/it]Running generate_until requests:  51%|█████     | 51/100 [03:58<03:37,  4.44s/it]Running generate_until requests:  52%|█████▏    | 52/100 [04:02<03:23,  4.24s/it]Running generate_until requests:  53%|█████▎    | 53/100 [04:06<03:21,  4.28s/it]Running generate_until requests:  54%|█████▍    | 54/100 [04:10<03:10,  4.14s/it]Running generate_until requests:  55%|█████▌    | 55/100 [04:14<03:06,  4.15s/it]Running generate_until requests:  56%|█████▌    | 56/100 [04:19<03:08,  4.28s/it]Running generate_until requests:  57%|█████▋    | 57/100 [04:23<03:04,  4.28s/it]Running generate_until requests:  58%|█████▊    | 58/100 [04:27<02:55,  4.17s/it]Running generate_until requests:  59%|█████▉    | 59/100 [04:32<03:01,  4.42s/it]Running generate_until requests:  60%|██████    | 60/100 [04:36<02:48,  4.20s/it]Running generate_until requests:  61%|██████    | 61/100 [04:41<02:49,  4.35s/it]Running generate_until requests:  62%|██████▏   | 62/100 [04:45<02:49,  4.46s/it]Running generate_until requests:  63%|██████▎   | 63/100 [04:49<02:35,  4.21s/it]Running generate_until requests:  64%|██████▍   | 64/100 [04:52<02:24,  4.03s/it]Running generate_until requests:  65%|██████▌   | 65/100 [04:56<02:15,  3.88s/it]Running generate_until requests:  66%|██████▌   | 66/100 [05:00<02:10,  3.84s/it]Running generate_until requests:  67%|██████▋   | 67/100 [05:03<02:03,  3.74s/it]Running generate_until requests:  68%|██████▊   | 68/100 [05:07<02:03,  3.86s/it]Running generate_until requests:  69%|██████▉   | 69/100 [05:13<02:15,  4.37s/it]Running generate_until requests:  70%|███████   | 70/100 [05:17<02:07,  4.26s/it]Running generate_until requests:  71%|███████   | 71/100 [05:25<02:37,  5.44s/it]Running generate_until requests:  72%|███████▏  | 72/100 [05:29<02:15,  4.83s/it]Running generate_until requests:  73%|███████▎  | 73/100 [05:32<01:59,  4.44s/it]Running generate_until requests:  74%|███████▍  | 74/100 [05:36<01:50,  4.27s/it]Running generate_until requests:  75%|███████▌  | 75/100 [05:39<01:40,  4.03s/it]Running generate_until requests:  76%|███████▌  | 76/100 [05:43<01:32,  3.85s/it]Running generate_until requests:  77%|███████▋  | 77/100 [05:47<01:31,  4.00s/it]Running generate_until requests:  78%|███████▊  | 78/100 [05:51<01:25,  3.87s/it]Running generate_until requests:  79%|███████▉  | 79/100 [05:54<01:17,  3.71s/it]Running generate_until requests:  80%|████████  | 80/100 [05:58<01:14,  3.74s/it]Running generate_until requests:  81%|████████  | 81/100 [06:04<01:21,  4.31s/it]Running generate_until requests:  82%|████████▏ | 82/100 [06:07<01:12,  4.02s/it]Running generate_until requests:  83%|████████▎ | 83/100 [06:11<01:06,  3.91s/it]Running generate_until requests:  84%|████████▍ | 84/100 [06:14<00:59,  3.71s/it]Running generate_until requests:  85%|████████▌ | 85/100 [06:17<00:53,  3.54s/it]Running generate_until requests:  86%|████████▌ | 86/100 [06:20<00:49,  3.50s/it]Running generate_until requests:  87%|████████▋ | 87/100 [06:25<00:48,  3.75s/it]Running generate_until requests:  88%|████████▊ | 88/100 [06:28<00:44,  3.67s/it]Running generate_until requests:  89%|████████▉ | 89/100 [06:31<00:38,  3.47s/it]Running generate_until requests:  90%|█████████ | 90/100 [06:34<00:32,  3.29s/it]Running generate_until requests:  91%|█████████ | 91/100 [06:37<00:28,  3.13s/it]Running generate_until requests:  92%|█████████▏| 92/100 [06:40<00:24,  3.04s/it]Running generate_until requests:  93%|█████████▎| 93/100 [06:42<00:20,  3.00s/it]Running generate_until requests:  94%|█████████▍| 94/100 [06:45<00:18,  3.00s/it]Running generate_until requests:  95%|█████████▌| 95/100 [06:49<00:15,  3.07s/it]Running generate_until requests:  96%|█████████▌| 96/100 [06:52<00:12,  3.08s/it]Running generate_until requests:  97%|█████████▋| 97/100 [06:54<00:08,  2.91s/it]Running generate_until requests:  98%|█████████▊| 98/100 [06:57<00:05,  2.79s/it]Running generate_until requests:  99%|█████████▉| 99/100 [07:00<00:02,  2.78s/it]Running generate_until requests: 100%|██████████| 100/100 [07:02<00:00,  2.79s/it]Running generate_until requests: 100%|██████████| 100/100 [07:02<00:00,  4.23s/it]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:5'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:5'}
full model:
{'coqa': {'alias': 'coqa', 'em,none': 0.595, 'em_stderr,none': 0.044774970461162564, 'f1,none': 0.7211574141733987, 'f1_stderr,none': 0.037128235455690536}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.6057853926542468
0.4195568875297668
0.5244744113321889
0.5202703028806769
0.6150870974034927
0.5299634576457063
0.9336763524510373
0.23649940737178063
0.388911200696845
0.6478041116722705
0.5517233675449297
0.6723258763091353
0.7175526480521238
0.8411089149883405
0.7404554224148189
0.26376935916880817
0.9373006475493478
0.5360566853939598
0.38729358133282565
0.4541602442018795
0.8623573205888978
0.7318340566806717
0.6643209906079897
0.8122565195147101
0.4707270481319977
0.9785001455445378
0.17075087907531752
0.489625917805058
0.7595051272431785
0.6057853926542468
0.4195568875297668
0.5244744113321889
0.5202703028806769
0.6150870974034927
0.5299634576457063
0.9336763524510373
0.23649940737178063
0.388911200696845
0.6478041116722705
0.5517233675449297
0.6723258763091353
0.7175526480521238
0.8411089149883405
0.7404554224148189
0.26376935916880817
0.9373006475493478
0.5360566853939598
0.38729358133282565
0.4541602442018795
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[5, 4, 3, 2, 0, 1, 7, 6]
tensor([5, 4, 3, 2, 0, 1, 7, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 3, 4, 0, 2, 1, 7, 6]
tensor([5, 3, 4, 0, 2, 1, 7, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 1, 7, 0, 6, 2, 3, 4]
tensor([5, 1, 7, 0, 6, 2, 3, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 3, 6, 0, 5, 2, 4, 1]
tensor([7, 3, 6, 0, 5, 2, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 5, 7, 2, 4, 0, 3, 1]
tensor([6, 5, 7, 2, 4, 0, 3, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 5, 0, 0, 1, 2, 1, 3]
tensor([4, 5, 0, 0, 1, 2, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1, 2, 2, 0, 3, 3]
tensor([0, 1, 1, 2, 2, 0, 3, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([7])
tensor(7)
tensor([6])
tensor(6)
done!
Normal merging for layer 2
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
done!
Normal merging for layer 4
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Cross-layer merge completed for layers 5 to 8
done!
Normal merging for layer 9
tensor([2, 3])
tensor(2)
tensor([4, 6])
tensor(4)
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([1])
tensor(1)
done!
Cross-layer merge completed for layers 10 to 22
done!
Normal merging for layer 23
tensor([0, 5])
tensor(0)
tensor([1, 2])
tensor(1)
tensor([3, 4])
tensor(3)
tensor([6, 7])
tensor(6)
done!
Cross-layer merge completed for layers 24 to 31
done!
all done!
Model size: 12.3238 GB
247
cuda:5
multirc
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:41<00:41, 41.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:53<00:00, 24.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:53<00:00, 26.88s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: multirc] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: multirc] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/super_glue/super_glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 239
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue/tree/3de24cf8022e94f4ee4b9d55a6f539891524d646/multirc?recursive=False&expand=False HTTP/1.1" 307 146
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue/tree/3de24cf8022e94f4ee4b9d55a6f539891524d646/multirc?recursive=False&expand=False HTTP/1.1" 200 365
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 239
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 239
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 239
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 239
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 239
DEBUG:filelock:Attempting to acquire lock 140243031275904 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_multirc_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 140243031275904 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_multirc_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/multirc/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 140243031275904 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_multirc_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 140243031275904 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_multirc_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Attempting to acquire lock 140237868546288 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/multirc/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 140237868546288 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/multirc/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/multirc/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 140237868546288 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/multirc/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 140237868546288 released on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/multirc/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of multirc from None to 0
INFO:lm_eval.api.task:Building contexts for multirc on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1252.65it/s]
DEBUG:lm_eval.evaluator:Task: multirc; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:03<10:10,  3.07s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:05<05:45,  1.75s/it]Running loglikelihood requests:   2%|▎         | 5/200 [00:08<04:49,  1.48s/it]Running loglikelihood requests:   4%|▎         | 7/200 [00:10<04:25,  1.37s/it]Running loglikelihood requests:   4%|▍         | 9/200 [00:13<04:11,  1.32s/it]Running loglikelihood requests:   6%|▌         | 11/200 [00:15<04:02,  1.28s/it]Running loglikelihood requests:   6%|▋         | 13/200 [00:17<03:55,  1.26s/it]Running loglikelihood requests:   8%|▊         | 15/200 [00:20<03:50,  1.24s/it]Running loglikelihood requests:   8%|▊         | 17/200 [00:22<03:45,  1.23s/it]Running loglikelihood requests:  10%|▉         | 19/200 [00:25<03:42,  1.23s/it]Running loglikelihood requests:  10%|█         | 21/200 [00:27<03:38,  1.22s/it]Running loglikelihood requests:  12%|█▏        | 23/200 [00:29<03:35,  1.22s/it]Running loglikelihood requests:  12%|█▎        | 25/200 [00:32<03:33,  1.22s/it]Running loglikelihood requests:  14%|█▎        | 27/200 [00:34<03:31,  1.22s/it]Running loglikelihood requests:  14%|█▍        | 29/200 [00:37<03:29,  1.22s/it]Running loglikelihood requests:  16%|█▌        | 31/200 [00:39<03:26,  1.22s/it]Running loglikelihood requests:  16%|█▋        | 33/200 [00:42<03:24,  1.22s/it]Running loglikelihood requests:  18%|█▊        | 35/200 [00:44<03:22,  1.22s/it]Running loglikelihood requests:  18%|█▊        | 37/200 [00:47<03:19,  1.22s/it]Running loglikelihood requests:  20%|█▉        | 39/200 [00:49<03:16,  1.22s/it]Running loglikelihood requests:  20%|██        | 41/200 [00:52<03:14,  1.22s/it]Running loglikelihood requests:  22%|██▏       | 43/200 [00:54<03:11,  1.22s/it]Running loglikelihood requests:  22%|██▎       | 45/200 [00:56<03:08,  1.22s/it]Running loglikelihood requests:  24%|██▎       | 47/200 [00:59<03:06,  1.22s/it]Running loglikelihood requests:  24%|██▍       | 49/200 [01:01<03:03,  1.22s/it]Running loglikelihood requests:  26%|██▌       | 51/200 [01:04<03:01,  1.22s/it]Running loglikelihood requests:  26%|██▋       | 53/200 [01:06<02:58,  1.22s/it]Running loglikelihood requests:  28%|██▊       | 55/200 [01:09<02:56,  1.22s/it]Running loglikelihood requests:  28%|██▊       | 57/200 [01:11<02:53,  1.21s/it]Running loglikelihood requests:  30%|██▉       | 59/200 [01:13<02:53,  1.23s/it]Running loglikelihood requests:  30%|███       | 61/200 [01:16<02:53,  1.25s/it]Running loglikelihood requests:  32%|███▏      | 63/200 [01:19<02:53,  1.27s/it]Running loglikelihood requests:  32%|███▎      | 65/200 [01:21<02:52,  1.28s/it]Running loglikelihood requests:  34%|███▎      | 67/200 [01:24<02:46,  1.25s/it]Running loglikelihood requests:  34%|███▍      | 69/200 [01:26<02:42,  1.24s/it]Running loglikelihood requests:  36%|███▌      | 71/200 [01:28<02:38,  1.23s/it]Running loglikelihood requests:  36%|███▋      | 73/200 [01:31<02:34,  1.22s/it]Running loglikelihood requests:  38%|███▊      | 75/200 [01:33<02:31,  1.21s/it]Running loglikelihood requests:  38%|███▊      | 77/200 [01:36<02:28,  1.21s/it]Running loglikelihood requests:  40%|███▉      | 79/200 [01:38<02:25,  1.20s/it]Running loglikelihood requests:  40%|████      | 81/200 [01:40<02:23,  1.20s/it]Running loglikelihood requests:  42%|████▏     | 83/200 [01:43<02:20,  1.20s/it]Running loglikelihood requests:  42%|████▎     | 85/200 [01:45<02:17,  1.20s/it]Running loglikelihood requests:  44%|████▎     | 87/200 [01:48<02:15,  1.20s/it]Running loglikelihood requests:  44%|████▍     | 89/200 [01:50<02:12,  1.20s/it]Running loglikelihood requests:  46%|████▌     | 91/200 [01:52<02:10,  1.20s/it]Running loglikelihood requests:  46%|████▋     | 93/200 [01:55<02:07,  1.20s/it]Running loglikelihood requests:  48%|████▊     | 95/200 [01:57<02:05,  1.19s/it]Running loglikelihood requests:  48%|████▊     | 97/200 [02:00<02:02,  1.19s/it]Running loglikelihood requests:  50%|████▉     | 99/200 [02:02<02:00,  1.19s/it]Running loglikelihood requests:  50%|█████     | 101/200 [02:04<01:57,  1.19s/it]Running loglikelihood requests:  52%|█████▏    | 103/200 [02:07<01:55,  1.19s/it]Running loglikelihood requests:  52%|█████▎    | 105/200 [02:09<01:52,  1.19s/it]Running loglikelihood requests:  54%|█████▎    | 107/200 [02:11<01:50,  1.19s/it]Running loglikelihood requests:  55%|█████▍    | 109/200 [02:14<01:48,  1.19s/it]Running loglikelihood requests:  56%|█████▌    | 111/200 [02:16<01:45,  1.19s/it]Running loglikelihood requests:  56%|█████▋    | 113/200 [02:19<01:43,  1.19s/it]Running loglikelihood requests:  57%|█████▊    | 115/200 [02:21<01:40,  1.18s/it]Running loglikelihood requests:  58%|█████▊    | 117/200 [02:23<01:37,  1.18s/it]Running loglikelihood requests:  60%|█████▉    | 119/200 [02:26<01:35,  1.18s/it]Running loglikelihood requests:  60%|██████    | 121/200 [02:28<01:32,  1.18s/it]Running loglikelihood requests:  62%|██████▏   | 123/200 [02:30<01:30,  1.17s/it]Running loglikelihood requests:  62%|██████▎   | 125/200 [02:33<01:28,  1.17s/it]Running loglikelihood requests:  64%|██████▎   | 127/200 [02:35<01:25,  1.17s/it]Running loglikelihood requests:  64%|██████▍   | 129/200 [02:37<01:23,  1.18s/it]Running loglikelihood requests:  66%|██████▌   | 131/200 [02:40<01:20,  1.17s/it]Running loglikelihood requests:  66%|██████▋   | 133/200 [02:42<01:18,  1.17s/it]Running loglikelihood requests:  68%|██████▊   | 135/200 [02:44<01:08,  1.05s/it]Running loglikelihood requests:  68%|██████▊   | 137/200 [02:45<01:00,  1.04it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [02:47<00:54,  1.11it/s]Running loglikelihood requests:  70%|███████   | 141/200 [02:48<00:50,  1.17it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [02:50<00:46,  1.22it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [02:51<00:43,  1.25it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [02:53<00:41,  1.28it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [02:54<00:39,  1.31it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [02:55<00:36,  1.32it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [02:57<00:34,  1.34it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [02:58<00:33,  1.36it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [03:00<00:31,  1.37it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [03:01<00:29,  1.38it/s]Running loglikelihood requests:  80%|████████  | 161/200 [03:03<00:27,  1.40it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [03:04<00:26,  1.42it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [03:05<00:24,  1.45it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [03:07<00:22,  1.47it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [03:08<00:20,  1.49it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [03:09<00:19,  1.50it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [03:10<00:17,  1.51it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [03:12<00:16,  1.52it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [03:13<00:14,  1.54it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [03:14<00:13,  1.54it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [03:16<00:12,  1.55it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [03:17<00:10,  1.56it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [03:18<00:09,  1.56it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [03:19<00:08,  1.57it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [03:21<00:06,  1.57it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [03:22<00:05,  1.57it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [03:23<00:04,  1.58it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [03:24<00:03,  1.58it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [03:26<00:01,  1.58it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [03:27<00:00,  1.58it/s]Running loglikelihood requests: 100%|██████████| 200/200 [03:27<00:00,  1.04s/it]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:6'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:6'}
full model:
{'multirc': {'alias': 'multirc', 'acc,none': 0.54, 'acc_stderr,none': 0.05009082659620331}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.6089030413152259
0.13723554564825818
0.32639298774801107
0.39554004962513223
0.17838079452737773
0.18172395498612623
0.4458149326815675
0.2599923469162762
0.44953845901781375
0.264228421159195
0.28453253935496087
0.5178234519727917
0.18549509579986273
0.3164231435223059
0.47622435667997154
0.5789910219470605
0.38414027299756903
0.6648306636715198
0.2288657593104162
0.30014630918632723
0.28954340172694804
0.7956189982678256
0.789982900191189
0.3644425339397572
0.37373995160413354
0.19965826892219962
0.3752330861186013
0.6279352732581062
0.3474029418882723
0.6089030413152259
0.13723554564825818
0.32639298774801107
0.39554004962513223
0.17838079452737773
0.18172395498612623
0.4458149326815675
0.2599923469162762
0.44953845901781375
0.264228421159195
0.28453253935496087
0.5178234519727917
0.18549509579986273
0.3164231435223059
0.47622435667997154
0.5789910219470605
0.38414027299756903
0.6648306636715198
0.2288657593104162
0.30014630918632723
0.28954340172694804
0.7956189982678256
0.789982900191189
0.3644425339397572
0.37373995160413354
0.19965826892219962
0.3752330861186013
0.6279352732581062
0.3474029418882723
0.6089030413152259
0.13723554564825818
0.32639298774801107
0.39554004962513223
0.17838079452737773
0.18172395498612623
0.4458149326815675
0.2599923469162762
0.44953845901781375
0.264228421159195
0.28453253935496087
0.5178234519727917
0.18549509579986273
0.3164231435223059
0.47622435667997154
0.5789910219470605
0.38414027299756903
0.6648306636715198
0.2288657593104162
0.30014630918632723
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[5, 3, 7, 0, 6, 2, 4, 1]
tensor([5, 3, 7, 0, 6, 2, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 7, 4, 2, 1, 3, 6, 0]
tensor([5, 7, 4, 2, 1, 3, 6, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 1, 3, 6, 0, 5, 7, 4]
tensor([2, 1, 3, 6, 0, 5, 7, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[7, 4, 1, 6, 0, 2, 3, 5]
tensor([7, 4, 1, 6, 0, 2, 3, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 6, 3, 2, 5, 1, 7, 0]
tensor([4, 6, 3, 2, 5, 1, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 0, 2, 1, 4, 7, 3, 6]
tensor([5, 0, 2, 1, 4, 7, 3, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 0, 1, 1.0, 1.0, 1.0]
tensor([0, 1, 1, 0, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([4])
tensor(4)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
done!
Normal merging for layer 2
tensor([4])
tensor(4)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 3 to 4
done!
Normal merging for layer 5
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([0])
tensor(0)
done!
Normal merging for layer 6
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
done!
Normal merging for layer 7
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
done!
Cross-layer merge completed for layers 8 to 25
done!
Normal merging for layer 26
tensor([0, 3])
tensor(0)
tensor([1, 2, 4, 5, 6, 7])
tensor(1)
done!
Cross-layer merge completed for layers 27 to 31
done!
all done!
Model size: 12.3238 GB
63
cuda:6
sciq
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:42<00:42, 42.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 24.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 27.32s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq HTTP/1.1" 200 1237
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/sciq/sciq.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/sciq HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/allenai/sciq HTTP/1.1" 200 1237
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/allenai/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/allenai/sciq/resolve/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/allenai/sciq/paths-info/2c94ad3e1aafab77146f384e23536f97a4849815 HTTP/1.1" 200 235
DEBUG:filelock:Attempting to acquire lock 140239877525232 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:filelock:Lock 140239877525232 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_info.json
DEBUG:filelock:Attempting to release lock 140239877525232 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:filelock:Lock 140239877525232 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_sciq_default_0.0.0_2c94ad3e1aafab77146f384e23536f97a4849815.lock
DEBUG:filelock:Attempting to acquire lock 140239877525232 on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:filelock:Lock 140239877525232 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815/dataset_info.json
DEBUG:filelock:Attempting to release lock 140239877525232 on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:filelock:Lock 140239877525232 released on /public/home/zouyifei001/.cache/huggingface/datasets/sciq/default/0.0.0/2c94ad3e1aafab77146f384e23536f97a4849815_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of sciq from None to 0
INFO:lm_eval.api.task:Building contexts for sciq on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1021.72it/s]
DEBUG:lm_eval.evaluator:Task: sciq; number of requests on this rank: 400
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/400 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/400 [00:03<24:50,  3.73s/it]Running loglikelihood requests:   0%|          | 2/400 [00:07<23:02,  3.47s/it]Running loglikelihood requests:   1%|          | 3/400 [00:10<22:23,  3.38s/it]Running loglikelihood requests:   1%|          | 4/400 [00:13<22:03,  3.34s/it]Running loglikelihood requests:   1%|▏         | 5/400 [00:16<21:25,  3.26s/it]Running loglikelihood requests:   2%|▏         | 6/400 [00:19<21:00,  3.20s/it]Running loglikelihood requests:   2%|▏         | 7/400 [00:22<20:41,  3.16s/it]Running loglikelihood requests:   2%|▏         | 8/400 [00:25<20:30,  3.14s/it]Running loglikelihood requests:   2%|▏         | 9/400 [00:28<19:39,  3.02s/it]Running loglikelihood requests:   2%|▎         | 10/400 [00:31<19:04,  2.94s/it]Running loglikelihood requests:   3%|▎         | 11/400 [00:34<18:39,  2.88s/it]Running loglikelihood requests:   3%|▎         | 12/400 [00:36<18:23,  2.84s/it]Running loglikelihood requests:   3%|▎         | 13/400 [00:39<17:46,  2.76s/it]Running loglikelihood requests:   4%|▎         | 14/400 [00:42<17:20,  2.69s/it]Running loglikelihood requests:   4%|▍         | 15/400 [00:44<17:00,  2.65s/it]Running loglikelihood requests:   4%|▍         | 16/400 [00:47<16:45,  2.62s/it]Running loglikelihood requests:   4%|▍         | 17/400 [00:49<16:23,  2.57s/it]Running loglikelihood requests:   4%|▍         | 18/400 [00:52<16:08,  2.54s/it]Running loglikelihood requests:   5%|▍         | 19/400 [00:54<15:56,  2.51s/it]Running loglikelihood requests:   5%|▌         | 20/400 [00:56<15:46,  2.49s/it]Running loglikelihood requests:   5%|▌         | 21/400 [00:59<15:37,  2.47s/it]Running loglikelihood requests:   6%|▌         | 22/400 [01:01<15:30,  2.46s/it]Running loglikelihood requests:   6%|▌         | 23/400 [01:04<15:24,  2.45s/it]Running loglikelihood requests:   6%|▌         | 24/400 [01:06<15:18,  2.44s/it]Running loglikelihood requests:   6%|▋         | 25/400 [01:08<14:57,  2.39s/it]Running loglikelihood requests:   6%|▋         | 26/400 [01:11<14:41,  2.36s/it]Running loglikelihood requests:   7%|▋         | 27/400 [01:13<14:29,  2.33s/it]Running loglikelihood requests:   7%|▋         | 28/400 [01:15<14:20,  2.31s/it]Running loglikelihood requests:   7%|▋         | 29/400 [01:17<13:51,  2.24s/it]Running loglikelihood requests:   8%|▊         | 30/400 [01:19<13:30,  2.19s/it]Running loglikelihood requests:   8%|▊         | 31/400 [01:21<13:14,  2.15s/it]Running loglikelihood requests:   8%|▊         | 32/400 [01:24<13:02,  2.13s/it]Running loglikelihood requests:   8%|▊         | 33/400 [01:25<12:39,  2.07s/it]Running loglikelihood requests:   8%|▊         | 34/400 [01:27<12:22,  2.03s/it]Running loglikelihood requests:   9%|▉         | 35/400 [01:29<12:10,  2.00s/it]Running loglikelihood requests:   9%|▉         | 36/400 [01:31<12:00,  1.98s/it]Running loglikelihood requests:   9%|▉         | 37/400 [01:33<11:52,  1.96s/it]Running loglikelihood requests:  10%|▉         | 38/400 [01:35<11:47,  1.96s/it]Running loglikelihood requests:  10%|█         | 40/400 [01:37<08:58,  1.50s/it]Running loglikelihood requests:  10%|█         | 41/400 [01:39<09:22,  1.57s/it]Running loglikelihood requests:  10%|█         | 42/400 [01:41<09:40,  1.62s/it]Running loglikelihood requests:  11%|█         | 43/400 [01:42<09:53,  1.66s/it]Running loglikelihood requests:  11%|█         | 44/400 [01:44<10:01,  1.69s/it]Running loglikelihood requests:  11%|█▏        | 45/400 [01:46<10:01,  1.69s/it]Running loglikelihood requests:  12%|█▏        | 46/400 [01:48<10:01,  1.70s/it]Running loglikelihood requests:  12%|█▏        | 47/400 [01:49<09:59,  1.70s/it]Running loglikelihood requests:  12%|█▏        | 48/400 [01:51<09:58,  1.70s/it]Running loglikelihood requests:  12%|█▏        | 49/400 [01:53<09:55,  1.70s/it]Running loglikelihood requests:  12%|█▎        | 50/400 [01:54<09:53,  1.70s/it]Running loglikelihood requests:  13%|█▎        | 51/400 [01:56<09:51,  1.69s/it]Running loglikelihood requests:  13%|█▎        | 52/400 [01:58<09:49,  1.69s/it]Running loglikelihood requests:  13%|█▎        | 53/400 [01:59<09:30,  1.64s/it]Running loglikelihood requests:  14%|█▎        | 54/400 [02:01<09:15,  1.61s/it]Running loglikelihood requests:  14%|█▍        | 55/400 [02:02<09:04,  1.58s/it]Running loglikelihood requests:  14%|█▍        | 57/400 [02:04<06:46,  1.19s/it]Running loglikelihood requests:  14%|█▍        | 58/400 [02:05<07:08,  1.25s/it]Running loglikelihood requests:  15%|█▍        | 59/400 [02:07<07:24,  1.30s/it]Running loglikelihood requests:  16%|█▌        | 62/400 [02:08<04:54,  1.15it/s]Running loglikelihood requests:  16%|█▌        | 63/400 [02:10<05:32,  1.01it/s]Running loglikelihood requests:  16%|█▌        | 64/400 [02:11<06:05,  1.09s/it]Running loglikelihood requests:  16%|█▋        | 65/400 [02:12<06:29,  1.16s/it]Running loglikelihood requests:  16%|█▋        | 66/400 [02:14<06:48,  1.22s/it]Running loglikelihood requests:  17%|█▋        | 67/400 [02:15<07:03,  1.27s/it]Running loglikelihood requests:  17%|█▋        | 68/400 [02:17<07:13,  1.31s/it]Running loglikelihood requests:  17%|█▋        | 69/400 [02:18<07:17,  1.32s/it]Running loglikelihood requests:  18%|█▊        | 70/400 [02:19<07:21,  1.34s/it]Running loglikelihood requests:  18%|█▊        | 71/400 [02:21<07:22,  1.35s/it]Running loglikelihood requests:  18%|█▊        | 72/400 [02:22<07:23,  1.35s/it]Running loglikelihood requests:  18%|█▊        | 73/400 [02:23<07:24,  1.36s/it]Running loglikelihood requests:  18%|█▊        | 74/400 [02:25<07:30,  1.38s/it]Running loglikelihood requests:  19%|█▉        | 77/400 [02:26<04:41,  1.15it/s]Running loglikelihood requests:  20%|█▉        | 78/400 [02:28<05:10,  1.04it/s]Running loglikelihood requests:  20%|█▉        | 79/400 [02:29<05:35,  1.04s/it]Running loglikelihood requests:  20%|██        | 81/400 [02:30<04:37,  1.15it/s]Running loglikelihood requests:  20%|██        | 82/400 [02:31<04:59,  1.06it/s]Running loglikelihood requests:  21%|██        | 83/400 [02:33<05:17,  1.00s/it]Running loglikelihood requests:  21%|██        | 84/400 [02:34<05:32,  1.05s/it]Running loglikelihood requests:  21%|██▏       | 85/400 [02:35<05:42,  1.09s/it]Running loglikelihood requests:  22%|██▏       | 86/400 [02:36<05:49,  1.11s/it]Running loglikelihood requests:  22%|██▏       | 89/400 [02:37<03:46,  1.37it/s]Running loglikelihood requests:  22%|██▎       | 90/400 [02:38<04:15,  1.21it/s]Running loglikelihood requests:  23%|██▎       | 91/400 [02:40<04:37,  1.11it/s]Running loglikelihood requests:  23%|██▎       | 92/400 [02:41<04:56,  1.04it/s]Running loglikelihood requests:  23%|██▎       | 93/400 [02:42<05:11,  1.01s/it]Running loglikelihood requests:  24%|██▍       | 97/400 [02:43<02:55,  1.72it/s]Running loglikelihood requests:  24%|██▍       | 98/400 [02:44<03:24,  1.47it/s]Running loglikelihood requests:  25%|██▍       | 99/400 [02:45<03:52,  1.30it/s]Running loglikelihood requests:  25%|██▌       | 100/400 [02:47<04:15,  1.17it/s]Running loglikelihood requests:  25%|██▌       | 101/400 [02:48<04:35,  1.09it/s]Running loglikelihood requests:  26%|██▌       | 102/400 [02:49<04:50,  1.03it/s]Running loglikelihood requests:  26%|██▌       | 103/400 [02:50<05:01,  1.01s/it]Running loglikelihood requests:  26%|██▌       | 104/400 [02:51<05:09,  1.05s/it]Running loglikelihood requests:  26%|██▋       | 105/400 [02:52<05:14,  1.07s/it]Running loglikelihood requests:  26%|██▋       | 106/400 [02:53<05:17,  1.08s/it]Running loglikelihood requests:  27%|██▋       | 107/400 [02:54<05:19,  1.09s/it]Running loglikelihood requests:  27%|██▋       | 108/400 [02:55<05:20,  1.10s/it]Running loglikelihood requests:  27%|██▋       | 109/400 [02:57<05:19,  1.10s/it]Running loglikelihood requests:  28%|██▊       | 110/400 [02:58<05:17,  1.10s/it]Running loglikelihood requests:  28%|██▊       | 111/400 [02:59<05:16,  1.10s/it]Running loglikelihood requests:  28%|██▊       | 112/400 [03:00<05:15,  1.10s/it]Running loglikelihood requests:  28%|██▊       | 113/400 [03:01<05:13,  1.09s/it]Running loglikelihood requests:  28%|██▊       | 114/400 [03:02<05:11,  1.09s/it]Running loglikelihood requests:  29%|██▉       | 115/400 [03:03<05:09,  1.09s/it]Running loglikelihood requests:  29%|██▉       | 116/400 [03:04<05:07,  1.08s/it]Running loglikelihood requests:  29%|██▉       | 117/400 [03:05<05:04,  1.08s/it]Running loglikelihood requests:  30%|██▉       | 118/400 [03:06<05:00,  1.07s/it]Running loglikelihood requests:  30%|██▉       | 119/400 [03:07<04:58,  1.06s/it]Running loglikelihood requests:  30%|███       | 120/400 [03:08<04:56,  1.06s/it]Running loglikelihood requests:  30%|███       | 121/400 [03:09<04:54,  1.05s/it]Running loglikelihood requests:  30%|███       | 122/400 [03:10<04:53,  1.05s/it]Running loglikelihood requests:  31%|███       | 123/400 [03:12<04:51,  1.05s/it]Running loglikelihood requests:  31%|███       | 124/400 [03:13<04:50,  1.05s/it]Running loglikelihood requests:  31%|███▏      | 125/400 [03:14<04:47,  1.05s/it]Running loglikelihood requests:  32%|███▏      | 126/400 [03:15<04:44,  1.04s/it]Running loglikelihood requests:  32%|███▏      | 127/400 [03:16<04:42,  1.04s/it]Running loglikelihood requests:  32%|███▏      | 128/400 [03:17<04:40,  1.03s/it]Running loglikelihood requests:  32%|███▏      | 129/400 [03:18<04:38,  1.03s/it]Running loglikelihood requests:  32%|███▎      | 130/400 [03:19<04:36,  1.02s/it]Running loglikelihood requests:  33%|███▎      | 131/400 [03:20<04:34,  1.02s/it]Running loglikelihood requests:  34%|███▎      | 134/400 [03:21<02:48,  1.58it/s]Running loglikelihood requests:  34%|███▍      | 135/400 [03:22<03:08,  1.40it/s]Running loglikelihood requests:  34%|███▍      | 136/400 [03:23<03:25,  1.28it/s]Running loglikelihood requests:  34%|███▍      | 137/400 [03:24<03:39,  1.20it/s]Running loglikelihood requests:  34%|███▍      | 138/400 [03:25<03:50,  1.14it/s]Running loglikelihood requests:  35%|███▍      | 139/400 [03:26<03:57,  1.10it/s]Running loglikelihood requests:  36%|███▌      | 142/400 [03:27<02:34,  1.67it/s]Running loglikelihood requests:  36%|███▌      | 143/400 [03:28<02:55,  1.47it/s]Running loglikelihood requests:  36%|███▌      | 144/400 [03:29<03:12,  1.33it/s]Running loglikelihood requests:  36%|███▋      | 145/400 [03:30<03:26,  1.23it/s]Running loglikelihood requests:  36%|███▋      | 146/400 [03:31<03:38,  1.17it/s]Running loglikelihood requests:  37%|███▋      | 147/400 [03:32<03:46,  1.12it/s]Running loglikelihood requests:  37%|███▋      | 148/400 [03:33<03:54,  1.08it/s]Running loglikelihood requests:  37%|███▋      | 149/400 [03:34<03:59,  1.05it/s]Running loglikelihood requests:  38%|███▊      | 150/400 [03:35<04:01,  1.03it/s]Running loglikelihood requests:  38%|███▊      | 151/400 [03:36<04:02,  1.02it/s]Running loglikelihood requests:  38%|███▊      | 152/400 [03:37<04:03,  1.02it/s]Running loglikelihood requests:  38%|███▊      | 153/400 [03:38<04:03,  1.01it/s]Running loglikelihood requests:  38%|███▊      | 154/400 [03:39<04:03,  1.01it/s]Running loglikelihood requests:  39%|███▉      | 155/400 [03:40<04:02,  1.01it/s]Running loglikelihood requests:  39%|███▉      | 156/400 [03:41<04:01,  1.01it/s]Running loglikelihood requests:  39%|███▉      | 157/400 [03:42<04:00,  1.01it/s]Running loglikelihood requests:  40%|███▉      | 158/400 [03:43<03:59,  1.01it/s]Running loglikelihood requests:  40%|███▉      | 159/400 [03:44<03:58,  1.01it/s]Running loglikelihood requests:  40%|████      | 160/400 [03:45<03:56,  1.01it/s]Running loglikelihood requests:  40%|████      | 161/400 [03:46<03:55,  1.01it/s]Running loglikelihood requests:  40%|████      | 162/400 [03:47<03:53,  1.02it/s]Running loglikelihood requests:  41%|████      | 163/400 [03:48<03:52,  1.02it/s]Running loglikelihood requests:  41%|████      | 164/400 [03:49<03:51,  1.02it/s]Running loglikelihood requests:  41%|████▏     | 165/400 [03:50<03:49,  1.03it/s]Running loglikelihood requests:  42%|████▏     | 166/400 [03:51<03:47,  1.03it/s]Running loglikelihood requests:  42%|████▏     | 167/400 [03:51<03:46,  1.03it/s]Running loglikelihood requests:  42%|████▏     | 168/400 [03:52<03:44,  1.03it/s]Running loglikelihood requests:  42%|████▏     | 169/400 [03:53<03:42,  1.04it/s]Running loglikelihood requests:  42%|████▎     | 170/400 [03:54<03:40,  1.04it/s]Running loglikelihood requests:  43%|████▎     | 172/400 [03:55<02:48,  1.36it/s]Running loglikelihood requests:  43%|████▎     | 173/400 [03:56<02:58,  1.27it/s]Running loglikelihood requests:  44%|████▎     | 174/400 [03:57<03:05,  1.22it/s]Running loglikelihood requests:  44%|████▍     | 177/400 [03:58<02:02,  1.82it/s]Running loglikelihood requests:  44%|████▍     | 178/400 [03:59<02:18,  1.61it/s]Running loglikelihood requests:  45%|████▍     | 179/400 [04:00<02:31,  1.45it/s]Running loglikelihood requests:  45%|████▌     | 180/400 [04:01<02:43,  1.35it/s]Running loglikelihood requests:  45%|████▌     | 181/400 [04:02<02:51,  1.28it/s]Running loglikelihood requests:  46%|████▌     | 182/400 [04:03<02:57,  1.23it/s]Running loglikelihood requests:  46%|████▌     | 183/400 [04:04<03:01,  1.20it/s]Running loglikelihood requests:  46%|████▌     | 184/400 [04:04<03:03,  1.18it/s]Running loglikelihood requests:  46%|████▋     | 185/400 [04:05<03:05,  1.16it/s]Running loglikelihood requests:  46%|████▋     | 186/400 [04:06<03:05,  1.15it/s]Running loglikelihood requests:  47%|████▋     | 187/400 [04:07<03:06,  1.14it/s]Running loglikelihood requests:  47%|████▋     | 188/400 [04:08<03:06,  1.14it/s]Running loglikelihood requests:  47%|████▋     | 189/400 [04:09<03:05,  1.14it/s]Running loglikelihood requests:  48%|████▊     | 190/400 [04:10<03:04,  1.14it/s]Running loglikelihood requests:  48%|████▊     | 191/400 [04:11<03:03,  1.14it/s]Running loglikelihood requests:  48%|████▊     | 192/400 [04:11<03:01,  1.14it/s]Running loglikelihood requests:  48%|████▊     | 193/400 [04:12<02:59,  1.15it/s]Running loglikelihood requests:  48%|████▊     | 194/400 [04:13<02:58,  1.16it/s]Running loglikelihood requests:  49%|████▉     | 195/400 [04:14<02:56,  1.16it/s]Running loglikelihood requests:  49%|████▉     | 196/400 [04:15<02:55,  1.16it/s]Running loglikelihood requests:  49%|████▉     | 197/400 [04:16<02:53,  1.17it/s]Running loglikelihood requests:  50%|████▉     | 198/400 [04:17<02:52,  1.17it/s]Running loglikelihood requests:  50%|████▉     | 199/400 [04:17<02:50,  1.18it/s]Running loglikelihood requests:  50%|█████     | 200/400 [04:18<02:49,  1.18it/s]Running loglikelihood requests:  50%|█████     | 201/400 [04:19<02:48,  1.18it/s]Running loglikelihood requests:  50%|█████     | 202/400 [04:20<02:47,  1.19it/s]Running loglikelihood requests:  51%|█████     | 203/400 [04:21<02:45,  1.19it/s]Running loglikelihood requests:  51%|█████     | 204/400 [04:22<02:44,  1.19it/s]Running loglikelihood requests:  51%|█████▏    | 205/400 [04:22<02:43,  1.19it/s]Running loglikelihood requests:  52%|█████▏    | 206/400 [04:23<02:42,  1.19it/s]Running loglikelihood requests:  52%|█████▏    | 207/400 [04:24<02:41,  1.19it/s]Running loglikelihood requests:  52%|█████▏    | 208/400 [04:25<02:41,  1.19it/s]Running loglikelihood requests:  52%|█████▏    | 209/400 [04:26<02:40,  1.19it/s]Running loglikelihood requests:  53%|█████▎    | 212/400 [04:27<01:38,  1.91it/s]Running loglikelihood requests:  53%|█████▎    | 213/400 [04:27<01:49,  1.71it/s]Running loglikelihood requests:  54%|█████▎    | 214/400 [04:28<01:59,  1.56it/s]Running loglikelihood requests:  54%|█████▍    | 215/400 [04:29<02:06,  1.46it/s]Running loglikelihood requests:  54%|█████▍    | 216/400 [04:30<02:12,  1.39it/s]Running loglikelihood requests:  54%|█████▍    | 217/400 [04:31<02:16,  1.34it/s]Running loglikelihood requests:  55%|█████▍    | 218/400 [04:32<02:18,  1.31it/s]Running loglikelihood requests:  55%|█████▍    | 219/400 [04:32<02:20,  1.29it/s]Running loglikelihood requests:  55%|█████▌    | 220/400 [04:33<02:21,  1.27it/s]Running loglikelihood requests:  55%|█████▌    | 221/400 [04:34<02:22,  1.26it/s]Running loglikelihood requests:  56%|█████▌    | 222/400 [04:35<02:21,  1.26it/s]Running loglikelihood requests:  56%|█████▌    | 223/400 [04:36<02:21,  1.25it/s]Running loglikelihood requests:  56%|█████▌    | 224/400 [04:36<02:20,  1.25it/s]Running loglikelihood requests:  56%|█████▋    | 225/400 [04:37<02:19,  1.25it/s]Running loglikelihood requests:  56%|█████▋    | 226/400 [04:38<02:18,  1.25it/s]Running loglikelihood requests:  57%|█████▋    | 227/400 [04:39<02:18,  1.25it/s]Running loglikelihood requests:  57%|█████▋    | 228/400 [04:40<02:17,  1.25it/s]Running loglikelihood requests:  57%|█████▋    | 229/400 [04:40<02:16,  1.25it/s]Running loglikelihood requests:  57%|█████▊    | 230/400 [04:41<02:15,  1.25it/s]Running loglikelihood requests:  58%|█████▊    | 231/400 [04:42<02:14,  1.25it/s]Running loglikelihood requests:  58%|█████▊    | 232/400 [04:43<02:14,  1.25it/s]Running loglikelihood requests:  58%|█████▊    | 233/400 [04:44<02:13,  1.26it/s]Running loglikelihood requests:  58%|█████▊    | 234/400 [04:44<02:11,  1.26it/s]Running loglikelihood requests:  59%|█████▉    | 235/400 [04:45<02:10,  1.26it/s]Running loglikelihood requests:  59%|█████▉    | 236/400 [04:46<02:09,  1.26it/s]Running loglikelihood requests:  59%|█████▉    | 237/400 [04:47<02:08,  1.27it/s]Running loglikelihood requests:  60%|██████    | 240/400 [04:47<01:18,  2.03it/s]Running loglikelihood requests:  60%|██████    | 241/400 [04:48<01:27,  1.81it/s]Running loglikelihood requests:  60%|██████    | 242/400 [04:49<01:34,  1.66it/s]Running loglikelihood requests:  61%|██████    | 243/400 [04:50<01:40,  1.56it/s]Running loglikelihood requests:  61%|██████    | 244/400 [04:51<01:45,  1.48it/s]Running loglikelihood requests:  61%|██████▏   | 245/400 [04:51<01:48,  1.43it/s]Running loglikelihood requests:  62%|██████▏   | 246/400 [04:52<01:50,  1.40it/s]Running loglikelihood requests:  62%|██████▏   | 247/400 [04:53<01:51,  1.38it/s]Running loglikelihood requests:  62%|██████▏   | 248/400 [04:54<01:51,  1.36it/s]Running loglikelihood requests:  62%|██████▏   | 249/400 [04:54<01:52,  1.35it/s]Running loglikelihood requests:  62%|██████▎   | 250/400 [04:55<01:51,  1.34it/s]Running loglikelihood requests:  63%|██████▎   | 251/400 [04:56<01:51,  1.34it/s]Running loglikelihood requests:  63%|██████▎   | 252/400 [04:57<01:50,  1.34it/s]Running loglikelihood requests:  63%|██████▎   | 253/400 [04:57<01:50,  1.34it/s]Running loglikelihood requests:  64%|██████▎   | 254/400 [04:58<01:49,  1.34it/s]Running loglikelihood requests:  64%|██████▍   | 255/400 [04:59<01:48,  1.34it/s]Running loglikelihood requests:  64%|██████▍   | 256/400 [05:00<01:47,  1.34it/s]Running loglikelihood requests:  64%|██████▍   | 257/400 [05:00<01:46,  1.34it/s]Running loglikelihood requests:  64%|██████▍   | 258/400 [05:01<01:45,  1.34it/s]Running loglikelihood requests:  65%|██████▍   | 259/400 [05:02<01:44,  1.34it/s]Running loglikelihood requests:  65%|██████▌   | 260/400 [05:03<01:43,  1.35it/s]Running loglikelihood requests:  65%|██████▌   | 261/400 [05:03<01:41,  1.37it/s]Running loglikelihood requests:  66%|██████▌   | 262/400 [05:04<01:39,  1.39it/s]Running loglikelihood requests:  66%|██████▌   | 263/400 [05:05<01:37,  1.40it/s]Running loglikelihood requests:  66%|██████▌   | 264/400 [05:05<01:36,  1.41it/s]Running loglikelihood requests:  66%|██████▋   | 265/400 [05:06<01:33,  1.44it/s]Running loglikelihood requests:  66%|██████▋   | 266/400 [05:07<01:31,  1.46it/s]Running loglikelihood requests:  67%|██████▋   | 267/400 [05:07<01:30,  1.48it/s]Running loglikelihood requests:  67%|██████▋   | 268/400 [05:08<01:28,  1.49it/s]Running loglikelihood requests:  67%|██████▋   | 269/400 [05:09<01:26,  1.51it/s]Running loglikelihood requests:  68%|██████▊   | 270/400 [05:09<01:25,  1.53it/s]Running loglikelihood requests:  68%|██████▊   | 271/400 [05:10<01:23,  1.54it/s]Running loglikelihood requests:  68%|██████▊   | 272/400 [05:11<01:22,  1.55it/s]Running loglikelihood requests:  68%|██████▊   | 273/400 [05:11<01:20,  1.57it/s]Running loglikelihood requests:  68%|██████▊   | 274/400 [05:12<01:18,  1.60it/s]Running loglikelihood requests:  69%|██████▉   | 275/400 [05:12<01:17,  1.62it/s]Running loglikelihood requests:  69%|██████▉   | 276/400 [05:13<01:15,  1.63it/s]Running loglikelihood requests:  69%|██████▉   | 277/400 [05:14<01:14,  1.65it/s]Running loglikelihood requests:  70%|██████▉   | 278/400 [05:14<01:13,  1.66it/s]Running loglikelihood requests:  70%|██████▉   | 279/400 [05:15<01:12,  1.66it/s]Running loglikelihood requests:  70%|███████   | 280/400 [05:15<01:11,  1.67it/s]Running loglikelihood requests:  70%|███████   | 281/400 [05:16<01:10,  1.68it/s]Running loglikelihood requests:  70%|███████   | 282/400 [05:17<01:09,  1.69it/s]Running loglikelihood requests:  71%|███████   | 283/400 [05:17<01:09,  1.69it/s]Running loglikelihood requests:  71%|███████   | 284/400 [05:18<01:08,  1.70it/s]Running loglikelihood requests:  71%|███████▏  | 285/400 [05:18<01:07,  1.70it/s]Running loglikelihood requests:  72%|███████▏  | 286/400 [05:19<01:06,  1.71it/s]Running loglikelihood requests:  72%|███████▏  | 287/400 [05:19<01:06,  1.71it/s]Running loglikelihood requests:  72%|███████▏  | 288/400 [05:20<01:05,  1.71it/s]Running loglikelihood requests:  72%|███████▏  | 289/400 [05:21<01:04,  1.72it/s]Running loglikelihood requests:  72%|███████▎  | 290/400 [05:21<01:04,  1.72it/s]Running loglikelihood requests:  73%|███████▎  | 291/400 [05:22<01:03,  1.72it/s]Running loglikelihood requests:  73%|███████▎  | 292/400 [05:22<01:02,  1.72it/s]Running loglikelihood requests:  73%|███████▎  | 293/400 [05:23<01:02,  1.72it/s]Running loglikelihood requests:  74%|███████▎  | 294/400 [05:23<01:01,  1.73it/s]Running loglikelihood requests:  74%|███████▍  | 295/400 [05:24<01:00,  1.73it/s]Running loglikelihood requests:  74%|███████▍  | 296/400 [05:25<00:59,  1.74it/s]Running loglikelihood requests:  74%|███████▍  | 297/400 [05:25<00:59,  1.74it/s]Running loglikelihood requests:  74%|███████▍  | 298/400 [05:26<00:58,  1.74it/s]Running loglikelihood requests:  75%|███████▍  | 299/400 [05:26<00:57,  1.74it/s]Running loglikelihood requests:  75%|███████▌  | 300/400 [05:27<00:57,  1.74it/s]Running loglikelihood requests:  75%|███████▌  | 301/400 [05:27<00:56,  1.74it/s]Running loglikelihood requests:  76%|███████▌  | 302/400 [05:28<00:56,  1.75it/s]Running loglikelihood requests:  76%|███████▌  | 303/400 [05:29<00:55,  1.75it/s]Running loglikelihood requests:  76%|███████▌  | 304/400 [05:29<00:54,  1.76it/s]Running loglikelihood requests:  76%|███████▋  | 305/400 [05:30<00:54,  1.76it/s]Running loglikelihood requests:  76%|███████▋  | 306/400 [05:30<00:53,  1.76it/s]Running loglikelihood requests:  77%|███████▋  | 307/400 [05:31<00:52,  1.76it/s]Running loglikelihood requests:  78%|███████▊  | 310/400 [05:31<00:31,  2.82it/s]Running loglikelihood requests:  78%|███████▊  | 311/400 [05:32<00:35,  2.51it/s]Running loglikelihood requests:  78%|███████▊  | 312/400 [05:33<00:38,  2.29it/s]Running loglikelihood requests:  78%|███████▊  | 313/400 [05:33<00:40,  2.14it/s]Running loglikelihood requests:  78%|███████▊  | 314/400 [05:34<00:42,  2.03it/s]Running loglikelihood requests:  79%|███████▉  | 315/400 [05:34<00:43,  1.95it/s]Running loglikelihood requests:  79%|███████▉  | 316/400 [05:35<00:44,  1.91it/s]Running loglikelihood requests:  79%|███████▉  | 317/400 [05:35<00:44,  1.88it/s]Running loglikelihood requests:  80%|███████▉  | 318/400 [05:36<00:44,  1.85it/s]Running loglikelihood requests:  80%|███████▉  | 319/400 [05:36<00:43,  1.85it/s]Running loglikelihood requests:  80%|████████  | 321/400 [05:37<00:32,  2.40it/s]Running loglikelihood requests:  80%|████████  | 322/400 [05:38<00:34,  2.24it/s]Running loglikelihood requests:  81%|████████  | 323/400 [05:38<00:36,  2.13it/s]Running loglikelihood requests:  81%|████████  | 324/400 [05:39<00:37,  2.05it/s]Running loglikelihood requests:  81%|████████▏ | 325/400 [05:39<00:37,  2.00it/s]Running loglikelihood requests:  82%|████████▏ | 326/400 [05:40<00:37,  1.96it/s]Running loglikelihood requests:  82%|████████▏ | 327/400 [05:40<00:37,  1.94it/s]Running loglikelihood requests:  82%|████████▏ | 328/400 [05:41<00:37,  1.93it/s]Running loglikelihood requests:  82%|████████▏ | 329/400 [05:41<00:36,  1.92it/s]Running loglikelihood requests:  82%|████████▎ | 330/400 [05:42<00:36,  1.91it/s]Running loglikelihood requests:  83%|████████▎ | 331/400 [05:42<00:36,  1.91it/s]Running loglikelihood requests:  83%|████████▎ | 332/400 [05:43<00:35,  1.90it/s]Running loglikelihood requests:  83%|████████▎ | 333/400 [05:43<00:34,  1.91it/s]Running loglikelihood requests:  84%|████████▎ | 334/400 [05:44<00:34,  1.92it/s]Running loglikelihood requests:  84%|████████▍ | 335/400 [05:44<00:33,  1.93it/s]Running loglikelihood requests:  84%|████████▍ | 336/400 [05:45<00:33,  1.92it/s]Running loglikelihood requests:  84%|████████▍ | 337/400 [05:45<00:32,  1.92it/s]Running loglikelihood requests:  84%|████████▍ | 338/400 [05:46<00:31,  1.95it/s]Running loglikelihood requests:  85%|████████▍ | 339/400 [05:46<00:31,  1.96it/s]Running loglikelihood requests:  85%|████████▌ | 340/400 [05:47<00:30,  1.98it/s]Running loglikelihood requests:  85%|████████▌ | 341/400 [05:47<00:29,  1.99it/s]Running loglikelihood requests:  86%|████████▌ | 342/400 [05:48<00:29,  1.99it/s]Running loglikelihood requests:  86%|████████▌ | 343/400 [05:48<00:28,  2.00it/s]Running loglikelihood requests:  86%|████████▌ | 344/400 [05:49<00:28,  2.00it/s]Running loglikelihood requests:  86%|████████▋ | 345/400 [05:49<00:27,  2.01it/s]Running loglikelihood requests:  86%|████████▋ | 346/400 [05:50<00:26,  2.01it/s]Running loglikelihood requests:  87%|████████▋ | 347/400 [05:50<00:26,  2.02it/s]Running loglikelihood requests:  87%|████████▋ | 348/400 [05:51<00:25,  2.02it/s]Running loglikelihood requests:  87%|████████▋ | 349/400 [05:51<00:25,  2.03it/s]Running loglikelihood requests:  88%|████████▊ | 350/400 [05:52<00:24,  2.03it/s]Running loglikelihood requests:  88%|████████▊ | 351/400 [05:52<00:24,  2.03it/s]Running loglikelihood requests:  88%|████████▊ | 352/400 [05:53<00:23,  2.03it/s]Running loglikelihood requests:  88%|████████▊ | 353/400 [05:53<00:23,  2.04it/s]Running loglikelihood requests:  88%|████████▊ | 354/400 [05:54<00:22,  2.04it/s]Running loglikelihood requests:  89%|████████▉ | 355/400 [05:54<00:22,  2.04it/s]Running loglikelihood requests:  89%|████████▉ | 356/400 [05:55<00:21,  2.05it/s]Running loglikelihood requests:  89%|████████▉ | 357/400 [05:55<00:20,  2.05it/s]Running loglikelihood requests:  90%|████████▉ | 358/400 [05:56<00:20,  2.06it/s]Running loglikelihood requests:  90%|████████▉ | 359/400 [05:56<00:19,  2.06it/s]Running loglikelihood requests:  90%|█████████ | 360/400 [05:57<00:19,  2.06it/s]Running loglikelihood requests:  90%|█████████ | 361/400 [05:57<00:18,  2.07it/s]Running loglikelihood requests:  90%|█████████ | 362/400 [05:58<00:18,  2.07it/s]Running loglikelihood requests:  91%|█████████ | 363/400 [05:58<00:17,  2.07it/s]Running loglikelihood requests:  91%|█████████ | 364/400 [05:59<00:17,  2.08it/s]Running loglikelihood requests:  91%|█████████▏| 365/400 [05:59<00:16,  2.08it/s]Running loglikelihood requests:  92%|█████████▏| 366/400 [06:00<00:16,  2.08it/s]Running loglikelihood requests:  92%|█████████▏| 368/400 [06:00<00:11,  2.71it/s]Running loglikelihood requests:  92%|█████████▏| 369/400 [06:01<00:12,  2.52it/s]Running loglikelihood requests:  92%|█████████▎| 370/400 [06:01<00:12,  2.39it/s]Running loglikelihood requests:  93%|█████████▎| 371/400 [06:02<00:12,  2.30it/s]Running loglikelihood requests:  93%|█████████▎| 373/400 [06:02<00:09,  2.86it/s]Running loglikelihood requests:  94%|█████████▎| 374/400 [06:03<00:09,  2.64it/s]Running loglikelihood requests:  94%|█████████▍| 375/400 [06:03<00:10,  2.48it/s]Running loglikelihood requests:  94%|█████████▍| 376/400 [06:03<00:10,  2.37it/s]Running loglikelihood requests:  94%|█████████▍| 377/400 [06:04<00:09,  2.30it/s]Running loglikelihood requests:  94%|█████████▍| 378/400 [06:04<00:09,  2.26it/s]Running loglikelihood requests:  95%|█████████▍| 379/400 [06:05<00:09,  2.24it/s]Running loglikelihood requests:  95%|█████████▌| 380/400 [06:05<00:09,  2.21it/s]Running loglikelihood requests:  95%|█████████▌| 381/400 [06:06<00:08,  2.20it/s]Running loglikelihood requests:  96%|█████████▌| 382/400 [06:06<00:08,  2.20it/s]Running loglikelihood requests:  96%|█████████▌| 383/400 [06:07<00:07,  2.20it/s]Running loglikelihood requests:  96%|█████████▌| 384/400 [06:07<00:07,  2.20it/s]Running loglikelihood requests:  96%|█████████▋| 385/400 [06:08<00:06,  2.20it/s]Running loglikelihood requests:  96%|█████████▋| 386/400 [06:08<00:06,  2.20it/s]Running loglikelihood requests:  97%|█████████▋| 387/400 [06:09<00:05,  2.21it/s]Running loglikelihood requests:  97%|█████████▋| 388/400 [06:09<00:05,  2.22it/s]Running loglikelihood requests:  97%|█████████▋| 389/400 [06:09<00:04,  2.22it/s]Running loglikelihood requests:  98%|█████████▊| 390/400 [06:10<00:04,  2.22it/s]Running loglikelihood requests:  98%|█████████▊| 391/400 [06:10<00:04,  2.22it/s]Running loglikelihood requests:  98%|█████████▊| 392/400 [06:11<00:03,  2.23it/s]Running loglikelihood requests:  98%|█████████▊| 393/400 [06:11<00:03,  2.24it/s]Running loglikelihood requests:  98%|█████████▊| 394/400 [06:12<00:02,  2.25it/s]Running loglikelihood requests:  99%|█████████▉| 395/400 [06:12<00:02,  2.25it/s]Running loglikelihood requests:  99%|█████████▉| 396/400 [06:13<00:01,  2.25it/s]Running loglikelihood requests:  99%|█████████▉| 397/400 [06:13<00:01,  2.26it/s]Running loglikelihood requests: 100%|█████████▉| 398/400 [06:13<00:00,  2.27it/s]Running loglikelihood requests: 100%|█████████▉| 399/400 [06:14<00:00,  2.27it/s]Running loglikelihood requests: 100%|██████████| 400/400 [06:14<00:00,  2.28it/s]Running loglikelihood requests: 100%|██████████| 400/400 [06:14<00:00,  1.07it/s]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:7'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:7'}
full model:
{'sciq': {'alias': 'sciq', 'acc,none': 0.94, 'acc_stderr,none': 0.023868325657594204, 'acc_norm,none': 0.91, 'acc_norm_stderr,none': 0.028762349126466136}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.969062788859705
0.9024924890572922
0.7706109127217512
0.8221264026535647
0.9190490061886575
0.9866654579796295
0.6586322754204971
0.7962110384246164
0.8195614021629236
0.7124178311176441
0.787697814339696
0.7034455022322618
0.8136386046534271
0.8174990104652458
0.6784276389594894
0.8698440245672888
0.8886492811850213
0.6541737276411673
0.6560861559753316
0.8139845219953913
0.6714741870309046
0.6164364868717988
0.8331581872497299
0.9065420049234512
0.9246185715568276
0.7477515960551026
0.574165362968651
0.8586446364199891
0.8889771415746612
Total groups 70 exceeded the threshold, stopping comparison.
The group tensor is
[7, 3, 4, 2, 6, 1, 5, 0]
tensor([7, 3, 4, 2, 6, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 2, 5, 3, 4, 0, 7, 1]
tensor([6, 2, 5, 3, 4, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 3, 6, 2, 7, 1, 4, 0]
tensor([5, 3, 6, 2, 7, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 4, 2, 1, 3, 5, 1]
tensor([0, 0, 4, 2, 1, 3, 5, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 2, 3, 4, 5, 0, 1, 1]
tensor([0, 2, 3, 4, 5, 0, 1, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 1, 0, 2, 2, 3, 1]
tensor([0, 3, 1, 0, 2, 2, 3, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 3, 1, 1, 2, 2, 3, 0]
tensor([0, 3, 1, 1, 2, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 1, 1.0, 1.0, 1.0, 1.0, 1]
tensor([0, 0, 1, 1, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 2 to 4
done!
Normal merging for layer 5
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 6 to 9
done!
Normal merging for layer 10
tensor([0, 1])
tensor(0)
tensor([4, 7])
tensor(4)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 11 to 12
done!
Normal merging for layer 13
tensor([0, 5])
tensor(0)
tensor([6, 7])
tensor(6)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 14 to 19
done!
Normal merging for layer 20
tensor([0, 3])
tensor(0)
tensor([2, 7])
tensor(2)
tensor([4, 5])
tensor(4)
tensor([1, 6])
tensor(1)
done!
Normal merging for layer 21
tensor([0, 7])
tensor(0)
tensor([2, 3])
tensor(2)
tensor([4, 5])
tensor(4)
tensor([1, 6])
tensor(1)
done!
Cross-layer merge completed for layers 22 to 23
done!
Normal merging for layer 24
tensor([0, 1])
tensor(0)
tensor([2, 3, 4, 5, 6, 7])
tensor(2)
done!
Cross-layer merge completed for layers 25 to 31
done!
all done!
Model size: 12.2608 GB
161
cuda:7
rte
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:43<00:43, 43.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:56<00:00, 25.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:56<00:00, 28.07s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: rte] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: rte] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:filelock:Attempting to acquire lock 140239877047648 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140239877047648 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140239877047648 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140239877047648 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140239877057584 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140239877057584 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140239877057584 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140239877057584 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of rte from None to 0
INFO:lm_eval.api.task:Building contexts for rte on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 2538.22it/s]
DEBUG:lm_eval.evaluator:Task: rte; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:01<06:32,  1.97s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:03<03:24,  1.04s/it]Running loglikelihood requests:   2%|▎         | 5/200 [00:04<02:40,  1.21it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:05<02:20,  1.37it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:07<02:09,  1.47it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:08<02:01,  1.55it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:09<01:56,  1.60it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:10<01:53,  1.64it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:11<01:49,  1.67it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:12<01:46,  1.70it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:13<01:42,  1.75it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:14<01:39,  1.78it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:16<01:37,  1.80it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:17<01:33,  1.85it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:18<01:30,  1.88it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:19<01:28,  1.91it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:20<01:26,  1.93it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:21<01:24,  1.95it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:22<01:23,  1.96it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:23<01:20,  1.99it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:24<01:18,  2.02it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:24<01:16,  2.06it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:25<01:13,  2.10it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:26<01:11,  2.14it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:27<01:09,  2.18it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:28<01:06,  2.24it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:29<01:03,  2.30it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:30<01:01,  2.36it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:30<00:59,  2.41it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:31<00:57,  2.46it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:32<00:55,  2.50it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:33<00:54,  2.53it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:33<00:52,  2.55it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:34<00:51,  2.58it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:35<00:50,  2.60it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:36<00:49,  2.62it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:36<00:48,  2.64it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:37<00:46,  2.67it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:38<00:45,  2.69it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:39<00:44,  2.72it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:39<00:43,  2.74it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:40<00:42,  2.76it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:41<00:41,  2.78it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:41<00:40,  2.79it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:42<00:39,  2.82it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:43<00:38,  2.84it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:44<00:37,  2.86it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:44<00:36,  2.88it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:45<00:35,  2.89it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:46<00:34,  2.91it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:46<00:33,  2.92it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:47<00:33,  2.93it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:48<00:32,  2.95it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:48<00:31,  2.97it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:49<00:30,  2.98it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:50<00:29,  3.00it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:50<00:28,  3.01it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:51<00:28,  3.01it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:52<00:27,  3.02it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:52<00:26,  3.02it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:53<00:26,  3.02it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:54<00:25,  3.04it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:54<00:24,  3.05it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [00:55<00:23,  3.05it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [00:55<00:23,  3.06it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [00:56<00:22,  3.07it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [00:57<00:21,  3.09it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [00:57<00:20,  3.11it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [00:58<00:20,  3.13it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [00:59<00:19,  3.15it/s]Running loglikelihood requests:  70%|███████   | 141/200 [00:59<00:18,  3.16it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [01:00<00:17,  3.18it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [01:01<00:17,  3.20it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [01:01<00:16,  3.21it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [01:02<00:15,  3.22it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [01:02<00:15,  3.23it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [01:03<00:14,  3.24it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [01:04<00:13,  3.25it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [01:04<00:13,  3.27it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [01:05<00:12,  3.29it/s]Running loglikelihood requests:  80%|████████  | 161/200 [01:05<00:11,  3.31it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [01:06<00:11,  3.32it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [01:07<00:10,  3.33it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [01:07<00:09,  3.36it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [01:08<00:09,  3.37it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [01:08<00:08,  3.40it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [01:09<00:07,  3.42it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [01:09<00:07,  3.44it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [01:10<00:06,  3.45it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [01:11<00:06,  3.46it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [01:11<00:05,  3.47it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [01:12<00:04,  3.43it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [01:12<00:04,  3.44it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [01:13<00:03,  3.46it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [01:14<00:03,  3.47it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [01:14<00:02,  3.49it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [01:15<00:01,  3.51it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:15<00:01,  3.53it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:16<00:00,  3.61it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:16<00:00,  3.68it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:16<00:00,  2.61it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:0'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}
full model:
{'rte': {'alias': 'rte', 'acc,none': 0.5, 'acc_stderr,none': 0.050251890762960605}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.34161229456626735
0.905233410256777
0.5205040718697735
0.4121994254524892
0.7398116665887099
0.6225415196831932
0.7923970242263771
0.7353888240887675
0.6535613357308766
0.7757058271862038
0.734046359122903
0.4471799126982846
0.773619360921301
0.7955347039939479
0.8672068064531693
0.8652880343596522
0.3302235467760883
0.6789268064017625
0.6072221471952108
0.9194446824778495
0.4812004589187253
0.5728915095234594
0.1682455054057436
0.93212414632396
0.9148362604533635
0.8268537756297094
0.7592245907029287
0.7256008379011685
0.7109756105942956
0.34161229456626735
0.905233410256777
0.5205040718697735
0.4121994254524892
0.7398116665887099
0.6225415196831932
0.7923970242263771
0.7353888240887675
0.6535613357308766
0.7757058271862038
0.734046359122903
0.4471799126982846
0.773619360921301
0.7955347039939479
0.8672068064531693
0.8652880343596522
0.3302235467760883
0.6789268064017625
0.6072221471952108
0.9194446824778495
0.4812004589187253
Total groups 73 exceeded the threshold, stopping comparison.
The group tensor is
[5, 2, 7, 1, 6, 4, 3, 0]
tensor([5, 2, 7, 1, 6, 4, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 6, 0, 7, 3, 4, 1]
tensor([5, 2, 6, 0, 7, 3, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 7, 2, 5, 4, 3, 0]
tensor([6, 1, 7, 2, 5, 4, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 7, 2, 4, 1, 5, 0]
tensor([6, 3, 7, 2, 4, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 5, 6, 2, 3, 1, 4, 0]
tensor([7, 5, 6, 2, 3, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 2, 5, 4, 1, 0, 1, 3]
tensor([0, 2, 5, 4, 1, 0, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1.0, 1.0, 0, 1.0, 1]
tensor([0, 1, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
Normal merging for layer 1
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Normal merging for layer 2
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 4
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 5 to 8
done!
Normal merging for layer 9
tensor([0, 5])
tensor(0)
tensor([4, 6])
tensor(4)
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
done!
Cross-layer merge completed for layers 10 to 30
done!
Normal merging for layer 31
tensor([0, 5])
tensor(0)
tensor([1, 2, 3, 4, 6, 7])
tensor(1)
done!
all done!
Model size: 12.1348 GB
34
cuda:0
wic
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:42<00:42, 42.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:55<00:00, 25.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:55<00:00, 27.58s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wic] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wic] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/super_glue/super_glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 235
DEBUG:filelock:Attempting to acquire lock 140237868538560 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_wic_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 140237868538560 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_wic_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wic/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 140237868538560 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_wic_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 140237868538560 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_wic_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Attempting to acquire lock 140243098810608 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wic/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 140243098810608 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wic/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wic/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 140243098810608 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wic/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 140243098810608 released on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wic/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wic from None to 0
INFO:lm_eval.api.task:Building contexts for wic on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1546.18it/s]
DEBUG:lm_eval.evaluator:Task: wic; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:01<03:45,  1.13s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:01<01:48,  1.81it/s]Running loglikelihood requests:   2%|▎         | 5/200 [00:02<01:27,  2.22it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:03<01:18,  2.45it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:03<01:13,  2.59it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:04<01:10,  2.69it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:05<01:07,  2.77it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:05<01:05,  2.83it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:06<01:03,  2.87it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:07<01:02,  2.90it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:08<01:01,  2.93it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:08<01:00,  2.95it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:09<00:59,  2.96it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:10<00:58,  2.97it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:10<00:57,  2.98it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:11<00:56,  2.99it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:11<00:55,  3.00it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:12<00:54,  3.02it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:13<00:53,  3.03it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:13<00:52,  3.05it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:14<00:51,  3.06it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:15<00:51,  3.07it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:15<00:50,  3.07it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:16<00:49,  3.08it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:17<00:49,  3.08it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:17<00:48,  3.08it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:18<00:47,  3.09it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:19<00:46,  3.10it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:19<00:46,  3.11it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:20<00:45,  3.11it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:21<00:44,  3.11it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:21<00:44,  3.08it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:22<00:43,  3.12it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:22<00:42,  3.15it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:23<00:41,  3.17it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:24<00:40,  3.19it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:24<00:39,  3.21it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:25<00:38,  3.23it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:26<00:38,  3.24it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:26<00:37,  3.24it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:27<00:36,  3.25it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:27<00:35,  3.26it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:28<00:35,  3.27it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:29<00:34,  3.26it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:29<00:34,  3.21it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:30<00:34,  3.20it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:30<00:33,  3.20it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:31<00:32,  3.20it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:32<00:32,  3.19it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:32<00:31,  3.19it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:33<00:31,  3.19it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:34<00:30,  3.19it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:34<00:29,  3.20it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:35<00:29,  3.21it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:35<00:28,  3.21it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:36<00:27,  3.21it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:37<00:27,  3.21it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:37<00:26,  3.21it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:38<00:25,  3.21it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:39<00:25,  3.21it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:39<00:24,  3.21it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:40<00:23,  3.21it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:40<00:23,  3.20it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [00:41<00:22,  3.19it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [00:42<00:22,  3.19it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [00:42<00:21,  3.21it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [00:43<00:20,  3.21it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [00:44<00:20,  3.22it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [00:44<00:19,  3.22it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [00:45<00:18,  3.23it/s]Running loglikelihood requests:  70%|███████   | 141/200 [00:45<00:18,  3.24it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [00:46<00:17,  3.25it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [00:47<00:16,  3.26it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [00:47<00:16,  3.27it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [00:48<00:15,  3.28it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [00:48<00:14,  3.28it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [00:49<00:14,  3.29it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [00:50<00:13,  3.29it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [00:50<00:13,  3.30it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [00:51<00:12,  3.31it/s]Running loglikelihood requests:  80%|████████  | 161/200 [00:51<00:11,  3.32it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [00:52<00:11,  3.32it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [00:53<00:10,  3.32it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [00:53<00:09,  3.33it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [00:54<00:09,  3.34it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [00:54<00:08,  3.35it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [00:55<00:08,  3.36it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [00:56<00:07,  3.37it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [00:56<00:06,  3.38it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [00:57<00:06,  3.39it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [00:57<00:05,  3.40it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [00:58<00:05,  3.39it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [00:59<00:04,  3.40it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [00:59<00:03,  3.40it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [01:00<00:03,  3.41it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [01:00<00:02,  3.43it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [01:01<00:02,  3.44it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:02<00:01,  3.44it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:02<00:00,  3.46it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:03<00:00,  3.47it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:03<00:00,  3.17it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:1'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:1'}
full model:
{'wic': {'alias': 'wic', 'acc,none': 0.47, 'acc_stderr,none': 0.05016135580465919}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.7015569150227223
0.5302361010977743
0.6131123609930033
0.8131827739550247
0.5456264918897312
0.5653128506125247
0.9024119585362896
0.8122852497904204
0.9072724946141106
0.866764102055741
0.8260299199157425
0.7472915500213457
0.8874866998217976
0.7441602305581367
0.22948143665096393
0.6763976434023368
0.5909756859477309
0.6775915070630182
0.8311737665735953
0.5882947608660276
0.7888779075700829
0.9530393862783458
0.7563942945196994
0.7021129984434293
0.9133573687405422
0.8864659884483975
0.43949477197814607
0.49530015739760547
0.9835705252160515
0.7015569150227223
0.5302361010977743
0.6131123609930033
0.8131827739550247
0.5456264918897312
0.5653128506125247
0.9024119585362896
0.8122852497904204
0.9072724946141106
0.866764102055741
0.8260299199157425
0.7472915500213457
0.8874866998217976
0.7441602305581367
Total groups 76 exceeded the threshold, stopping comparison.
The group tensor is
[6, 5, 2, 3, 7, 0, 4, 1]
tensor([6, 5, 2, 3, 7, 0, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 6, 1, 5, 4, 2, 3, 0]
tensor([7, 6, 1, 5, 4, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[7, 6, 2, 4, 5, 0, 3, 1]
tensor([7, 6, 2, 4, 5, 0, 3, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 0, 0, 5, 1, 1, 3, 2]
tensor([4, 0, 0, 5, 1, 1, 3, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 0, 2, 5, 3, 4, 1]
tensor([0, 1, 0, 2, 5, 3, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 0, 1, 4, 1, 2, 3, 0]
tensor([5, 0, 1, 4, 1, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 1, 1, 3, 4, 2, 5, 0]
tensor([0, 1, 1, 3, 4, 2, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 1, 0, 2, 3, 1, 2, 3]
tensor([0, 1, 0, 2, 3, 1, 2, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([2])
tensor(2)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 2 to 3
done!
Normal merging for layer 4
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 5 to 7
done!
Normal merging for layer 8
tensor([1, 2])
tensor(1)
tensor([4, 5])
tensor(4)
tensor([7])
tensor(7)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([3])
tensor(3)
done!
Cross-layer merge completed for layers 9 to 10
done!
Normal merging for layer 11
tensor([0, 2])
tensor(0)
tensor([1, 7])
tensor(1)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 12 to 13
done!
Normal merging for layer 14
tensor([1, 7])
tensor(1)
tensor([2, 4])
tensor(2)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([0])
tensor(0)
done!
Normal merging for layer 15
tensor([0, 7])
tensor(0)
tensor([1, 2])
tensor(1)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
done!
Normal merging for layer 16
tensor([0, 2])
tensor(0)
tensor([1, 5])
tensor(1)
tensor([3, 6])
tensor(3)
tensor([4, 7])
tensor(4)
done!
Cross-layer merge completed for layers 17 to 31
done!
all done!
Model size: 12.5757 GB
87
cuda:1
wic
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:42<00:42, 42.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 24.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 27.29s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wic] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wic] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/super_glue/super_glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 235
DEBUG:filelock:Attempting to acquire lock 140218662503008 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_wic_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 140218662503008 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_wic_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wic/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 140218662503008 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_wic_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 140218662503008 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_wic_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Attempting to acquire lock 140237868544080 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wic/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 140237868544080 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wic/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wic/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 140237868544080 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wic/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 140237868544080 released on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wic/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wic from None to 0
INFO:lm_eval.api.task:Building contexts for wic on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1557.55it/s]
DEBUG:lm_eval.evaluator:Task: wic; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:01<04:01,  1.21s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:01<01:54,  1.73it/s]Running loglikelihood requests:   2%|▎         | 5/200 [00:02<01:30,  2.15it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:03<01:20,  2.39it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:04<01:14,  2.55it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:04<01:11,  2.64it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:05<01:08,  2.73it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:06<01:05,  2.82it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:06<01:03,  2.90it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:07<01:01,  2.95it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:08<00:59,  2.99it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:08<00:58,  3.03it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:09<00:57,  3.05it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:09<00:56,  3.06it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:10<00:55,  3.08it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:11<00:55,  3.05it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:11<00:54,  3.05it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:12<00:54,  3.05it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:13<00:52,  3.08it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:13<00:51,  3.12it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:14<00:50,  3.14it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:15<00:49,  3.16it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:15<00:48,  3.17it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:16<00:48,  3.17it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:16<00:47,  3.18it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:17<00:46,  3.19it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:18<00:46,  3.19it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:18<00:45,  3.20it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:19<00:44,  3.21it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:20<00:43,  3.21it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:20<00:43,  3.18it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:21<00:43,  3.12it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:22<00:43,  3.12it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:22<00:42,  3.12it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:23<00:41,  3.12it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:23<00:41,  3.13it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:24<00:40,  3.14it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:25<00:39,  3.15it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:25<00:39,  3.15it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:26<00:38,  3.15it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:27<00:37,  3.16it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:27<00:36,  3.17it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:28<00:36,  3.18it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:29<00:35,  3.18it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:29<00:34,  3.18it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:30<00:34,  3.19it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:30<00:33,  3.19it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:31<00:32,  3.19it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:32<00:32,  3.19it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:32<00:31,  3.19it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:33<00:31,  3.19it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:34<00:30,  3.19it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:34<00:29,  3.20it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:35<00:29,  3.20it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:35<00:28,  3.21it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:36<00:27,  3.21it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:37<00:27,  3.21it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:37<00:26,  3.21it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:38<00:25,  3.21it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:38<00:25,  3.21it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:39<00:24,  3.22it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:40<00:23,  3.22it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:40<00:23,  3.22it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [00:41<00:22,  3.22it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [00:42<00:22,  3.22it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [00:42<00:21,  3.23it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [00:43<00:20,  3.24it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [00:43<00:20,  3.24it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [00:44<00:19,  3.24it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [00:45<00:18,  3.25it/s]Running loglikelihood requests:  70%|███████   | 141/200 [00:45<00:18,  3.25it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [00:46<00:17,  3.26it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [00:47<00:16,  3.27it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [00:47<00:16,  3.28it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [00:48<00:15,  3.29it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [00:48<00:14,  3.30it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [00:49<00:14,  3.30it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [00:50<00:13,  3.30it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [00:50<00:12,  3.31it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [00:51<00:12,  3.31it/s]Running loglikelihood requests:  80%|████████  | 161/200 [00:51<00:11,  3.31it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [00:52<00:11,  3.32it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [00:53<00:10,  3.32it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [00:53<00:09,  3.32it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [00:54<00:09,  3.32it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [00:54<00:08,  3.34it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [00:55<00:08,  3.36it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [00:56<00:07,  3.36it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [00:56<00:06,  3.37it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [00:57<00:06,  3.39it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [00:57<00:05,  3.40it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [00:58<00:05,  3.40it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [00:58<00:04,  3.40it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [00:59<00:03,  3.41it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [01:00<00:03,  3.42it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [01:00<00:02,  3.44it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [01:01<00:02,  3.45it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:01<00:01,  3.46it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:02<00:00,  3.47it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:02<00:00,  3.48it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:02<00:00,  3.18it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:2'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:2'}
full model:
{'wic': {'alias': 'wic', 'acc,none': 0.47, 'acc_stderr,none': 0.05016135580465919}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.7015569150227223
0.5302361010977743
0.6131123609930033
0.8131827739550247
0.5456264918897312
0.5653128506125247
0.9024119585362896
0.8122852497904204
0.9072724946141106
0.866764102055741
0.8260299199157425
0.7472915500213457
0.8874866998217976
0.7441602305581367
0.22948143665096393
0.6763976434023368
0.5909756859477309
0.6775915070630182
0.8311737665735953
0.5882947608660276
0.7888779075700829
0.9530393862783458
0.7563942945196994
0.7021129984434293
0.9133573687405422
0.8864659884483975
0.43949477197814607
0.49530015739760547
0.9835705252160515
0.7015569150227223
0.5302361010977743
0.6131123609930033
0.8131827739550247
0.5456264918897312
0.5653128506125247
0.9024119585362896
0.8122852497904204
0.9072724946141106
0.866764102055741
0.8260299199157425
0.7472915500213457
0.8874866998217976
0.7441602305581367
Total groups 76 exceeded the threshold, stopping comparison.
The group tensor is
[6, 5, 2, 3, 7, 0, 4, 1]
tensor([6, 5, 2, 3, 7, 0, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 6, 1, 5, 4, 2, 3, 0]
tensor([7, 6, 1, 5, 4, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[7, 6, 2, 4, 5, 0, 3, 1]
tensor([7, 6, 2, 4, 5, 0, 3, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 0, 0, 5, 1, 1, 3, 2]
tensor([4, 0, 0, 5, 1, 1, 3, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 0, 2, 5, 3, 4, 1]
tensor([0, 1, 0, 2, 5, 3, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 0, 1, 4, 1, 2, 3, 0]
tensor([5, 0, 1, 4, 1, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 1, 1, 3, 4, 2, 5, 0]
tensor([0, 1, 1, 3, 4, 2, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 1, 0, 2, 3, 1, 2, 3]
tensor([0, 1, 0, 2, 3, 1, 2, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([2])
tensor(2)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 2 to 3
done!
Normal merging for layer 4
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 5 to 7
done!
Normal merging for layer 8
tensor([1, 2])
tensor(1)
tensor([4, 5])
tensor(4)
tensor([7])
tensor(7)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([3])
tensor(3)
done!
Cross-layer merge completed for layers 9 to 10
done!
Normal merging for layer 11
tensor([0, 2])
tensor(0)
tensor([1, 7])
tensor(1)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 12 to 13
done!
Normal merging for layer 14
tensor([1, 7])
tensor(1)
tensor([2, 4])
tensor(2)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([0])
tensor(0)
done!
Normal merging for layer 15
tensor([0, 7])
tensor(0)
tensor([1, 2])
tensor(1)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
done!
Normal merging for layer 16
tensor([0, 2])
tensor(0)
tensor([1, 5])
tensor(1)
tensor([3, 6])
tensor(3)
tensor([4, 7])
tensor(4)
done!
Cross-layer merge completed for layers 17 to 31
done!
all done!
Model size: 12.5757 GB
164
cuda:2
rte
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:41<00:41, 41.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:53<00:00, 24.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:53<00:00, 26.76s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: rte] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: rte] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:filelock:Attempting to acquire lock 140240012153712 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140240012153712 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140240012153712 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140240012153712 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140239877533584 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140239877533584 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140239877533584 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140239877533584 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of rte from None to 0
INFO:lm_eval.api.task:Building contexts for rte on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 2596.14it/s]
DEBUG:lm_eval.evaluator:Task: rte; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:01<06:17,  1.90s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:03<03:24,  1.04s/it]Running loglikelihood requests:   2%|▎         | 5/200 [00:04<02:44,  1.19it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:05<02:25,  1.33it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:07<02:14,  1.42it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:08<02:06,  1.49it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:09<02:01,  1.54it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:10<01:57,  1.58it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:12<01:53,  1.61it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:13<01:50,  1.64it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:14<01:46,  1.68it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:15<01:43,  1.71it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:16<01:40,  1.74it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:17<01:37,  1.78it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:18<01:34,  1.81it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:19<01:31,  1.84it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:20<01:29,  1.86it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:21<01:27,  1.88it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:22<01:26,  1.89it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:23<01:24,  1.92it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:24<01:21,  1.95it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:25<01:19,  1.99it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:26<01:16,  2.03it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:27<01:14,  2.07it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:28<01:11,  2.11it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:29<01:08,  2.17it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:30<01:06,  2.23it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:31<01:03,  2.28it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:31<01:01,  2.33it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:32<00:59,  2.38it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:33<00:57,  2.42it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:34<00:55,  2.45it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:35<00:54,  2.47it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:35<00:53,  2.47it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:36<00:52,  2.49it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:37<00:51,  2.52it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:38<00:49,  2.55it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:38<00:48,  2.58it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:39<00:47,  2.60it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:40<00:46,  2.62it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:41<00:45,  2.63it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:41<00:44,  2.66it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:42<00:43,  2.67it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:43<00:42,  2.69it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:44<00:40,  2.71it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:44<00:39,  2.73it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:45<00:38,  2.75it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:46<00:37,  2.77it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:47<00:36,  2.78it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:47<00:36,  2.80it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:48<00:35,  2.81it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:49<00:34,  2.83it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:49<00:33,  2.84it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:50<00:32,  2.86it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:51<00:31,  2.87it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:51<00:30,  2.89it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:52<00:30,  2.90it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:53<00:29,  2.91it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:53<00:28,  2.91it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:54<00:27,  2.92it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:55<00:27,  2.93it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:55<00:26,  2.93it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:56<00:25,  2.94it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [00:57<00:24,  2.95it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [00:58<00:24,  2.95it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [00:58<00:23,  2.96it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [00:59<00:22,  2.98it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [00:59<00:21,  3.01it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [01:00<00:20,  3.03it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [01:01<00:20,  3.04it/s]Running loglikelihood requests:  70%|███████   | 141/200 [01:01<00:19,  3.06it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [01:02<00:18,  3.08it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [01:03<00:17,  3.09it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [01:03<00:17,  3.10it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [01:04<00:16,  3.11it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [01:05<00:15,  3.12it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [01:05<00:15,  3.13it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [01:06<00:14,  3.14it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [01:07<00:13,  3.16it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [01:07<00:12,  3.18it/s]Running loglikelihood requests:  80%|████████  | 161/200 [01:08<00:12,  3.20it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [01:08<00:11,  3.22it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [01:09<00:10,  3.23it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [01:10<00:10,  3.25it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [01:10<00:09,  3.27it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [01:11<00:08,  3.29it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [01:11<00:08,  3.31it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [01:12<00:07,  3.33it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [01:13<00:06,  3.34it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [01:13<00:06,  3.35it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [01:14<00:05,  3.36it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [01:14<00:05,  3.38it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [01:15<00:04,  3.39it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [01:16<00:03,  3.40it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [01:16<00:03,  3.42it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [01:17<00:02,  3.43it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [01:17<00:02,  3.45it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:18<00:01,  3.48it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:18<00:00,  3.55it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:19<00:00,  3.62it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:19<00:00,  2.52it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:3'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:3'}
full model:
{'rte': {'alias': 'rte', 'acc,none': 0.5, 'acc_stderr,none': 0.050251890762960605}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.34161229456626735
0.905233410256777
0.5205040718697735
0.4121994254524892
0.7398116665887099
0.6225415196831932
0.7923970242263771
0.7353888240887675
0.6535613357308766
0.7757058271862038
0.734046359122903
0.4471799126982846
0.773619360921301
0.7955347039939479
0.8672068064531693
0.8652880343596522
0.3302235467760883
0.6789268064017625
0.6072221471952108
0.9194446824778495
0.4812004589187253
0.5728915095234594
0.1682455054057436
0.93212414632396
0.9148362604533635
0.8268537756297094
0.7592245907029287
0.7256008379011685
0.7109756105942956
0.34161229456626735
0.905233410256777
0.5205040718697735
0.4121994254524892
0.7398116665887099
0.6225415196831932
0.7923970242263771
0.7353888240887675
0.6535613357308766
0.7757058271862038
0.734046359122903
0.4471799126982846
0.773619360921301
0.7955347039939479
0.8672068064531693
0.8652880343596522
0.3302235467760883
0.6789268064017625
0.6072221471952108
0.9194446824778495
0.4812004589187253
Total groups 73 exceeded the threshold, stopping comparison.
The group tensor is
[5, 2, 7, 1, 6, 4, 3, 0]
tensor([5, 2, 7, 1, 6, 4, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 6, 0, 7, 3, 4, 1]
tensor([5, 2, 6, 0, 7, 3, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 7, 2, 5, 4, 3, 0]
tensor([6, 1, 7, 2, 5, 4, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 7, 2, 4, 1, 5, 0]
tensor([6, 3, 7, 2, 4, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 5, 6, 2, 3, 1, 4, 0]
tensor([7, 5, 6, 2, 3, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 2, 5, 4, 1, 0, 1, 3]
tensor([0, 2, 5, 4, 1, 0, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1.0, 1.0, 0, 1.0, 1]
tensor([0, 1, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
Normal merging for layer 1
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Normal merging for layer 2
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 4
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 5 to 8
done!
Normal merging for layer 9
tensor([0, 5])
tensor(0)
tensor([4, 6])
tensor(4)
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
done!
Cross-layer merge completed for layers 10 to 30
done!
Normal merging for layer 31
tensor([0, 5])
tensor(0)
tensor([1, 2, 3, 4, 6, 7])
tensor(1)
done!
all done!
Model size: 12.1348 GB
117
cuda:3
copa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:42<00:42, 42.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:55<00:00, 24.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:55<00:00, 27.62s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: copa] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: copa] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/super_glue/super_glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue/tree/3de24cf8022e94f4ee4b9d55a6f539891524d646/copa?recursive=False&expand=False HTTP/1.1" 307 143
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue/tree/3de24cf8022e94f4ee4b9d55a6f539891524d646/copa?recursive=False&expand=False HTTP/1.1" 200 348
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140240017481344 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_copa_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 140240017481344 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_copa_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/copa/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 140240017481344 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_copa_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 140240017481344 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_copa_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Attempting to acquire lock 140240013620288 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/copa/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 140240013620288 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/copa/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/copa/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 140240013620288 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/copa/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 140240013620288 released on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/copa/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
DEBUG:lm_eval.api.task:Both target_delimiter " " and target choice: " the toilet filled with water." have whitespace
DEBUG:lm_eval.api.task:Both target_delimiter " " and target choice: " water flowed from the spout." have whitespace
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of copa from None to 0
INFO:lm_eval.api.task:Building contexts for copa on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 143591.37it/s]
DEBUG:lm_eval.evaluator:Task: copa; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:00<03:05,  1.07it/s]Running loglikelihood requests:   1%|          | 2/200 [00:01<02:10,  1.51it/s]Running loglikelihood requests:   2%|▏         | 3/200 [00:01<01:52,  1.76it/s]Running loglikelihood requests:   2%|▏         | 4/200 [00:02<01:45,  1.87it/s]Running loglikelihood requests:   2%|▎         | 5/200 [00:02<01:39,  1.96it/s]Running loglikelihood requests:   3%|▎         | 6/200 [00:03<01:36,  2.02it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:03<01:33,  2.07it/s]Running loglikelihood requests:   4%|▍         | 8/200 [00:04<01:31,  2.10it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:04<01:30,  2.12it/s]Running loglikelihood requests:   5%|▌         | 10/200 [00:05<01:29,  2.13it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:05<01:28,  2.15it/s]Running loglikelihood requests:   6%|▌         | 12/200 [00:06<01:26,  2.17it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:06<01:26,  2.17it/s]Running loglikelihood requests:   7%|▋         | 14/200 [00:06<01:25,  2.19it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:07<01:24,  2.20it/s]Running loglikelihood requests:   8%|▊         | 16/200 [00:07<01:23,  2.20it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:08<01:22,  2.21it/s]Running loglikelihood requests:   9%|▉         | 18/200 [00:08<01:22,  2.22it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:09<01:21,  2.22it/s]Running loglikelihood requests:  10%|█         | 20/200 [00:09<01:21,  2.22it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:10<01:20,  2.22it/s]Running loglikelihood requests:  11%|█         | 22/200 [00:10<01:19,  2.23it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:10<01:19,  2.23it/s]Running loglikelihood requests:  12%|█▏        | 24/200 [00:11<01:18,  2.23it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:11<01:18,  2.24it/s]Running loglikelihood requests:  13%|█▎        | 26/200 [00:12<01:17,  2.24it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:12<01:17,  2.24it/s]Running loglikelihood requests:  14%|█▍        | 28/200 [00:13<01:16,  2.24it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:13<01:16,  2.25it/s]Running loglikelihood requests:  15%|█▌        | 30/200 [00:14<01:15,  2.25it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:14<01:14,  2.26it/s]Running loglikelihood requests:  16%|█▌        | 32/200 [00:14<01:14,  2.26it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:15<01:13,  2.27it/s]Running loglikelihood requests:  17%|█▋        | 34/200 [00:15<01:13,  2.27it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:16<01:12,  2.27it/s]Running loglikelihood requests:  18%|█▊        | 36/200 [00:16<01:12,  2.27it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:17<01:11,  2.28it/s]Running loglikelihood requests:  19%|█▉        | 38/200 [00:17<01:11,  2.28it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:18<01:10,  2.28it/s]Running loglikelihood requests:  20%|██        | 40/200 [00:18<01:10,  2.28it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:18<01:09,  2.28it/s]Running loglikelihood requests:  21%|██        | 42/200 [00:19<01:09,  2.28it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:19<01:08,  2.28it/s]Running loglikelihood requests:  22%|██▏       | 44/200 [00:20<01:08,  2.28it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:20<01:07,  2.28it/s]Running loglikelihood requests:  23%|██▎       | 46/200 [00:21<01:07,  2.29it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:21<01:06,  2.29it/s]Running loglikelihood requests:  24%|██▍       | 48/200 [00:21<01:06,  2.28it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:22<01:06,  2.28it/s]Running loglikelihood requests:  25%|██▌       | 50/200 [00:22<01:05,  2.28it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:23<01:05,  2.28it/s]Running loglikelihood requests:  26%|██▌       | 52/200 [00:23<01:04,  2.28it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:24<01:04,  2.28it/s]Running loglikelihood requests:  27%|██▋       | 54/200 [00:24<01:03,  2.28it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:25<01:03,  2.29it/s]Running loglikelihood requests:  28%|██▊       | 56/200 [00:25<01:02,  2.30it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:25<01:02,  2.30it/s]Running loglikelihood requests:  29%|██▉       | 58/200 [00:26<01:01,  2.30it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:26<01:01,  2.30it/s]Running loglikelihood requests:  30%|███       | 60/200 [00:27<01:00,  2.30it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:27<01:00,  2.30it/s]Running loglikelihood requests:  31%|███       | 62/200 [00:28<00:59,  2.30it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:28<00:59,  2.30it/s]Running loglikelihood requests:  32%|███▏      | 64/200 [00:28<00:59,  2.30it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:29<00:58,  2.30it/s]Running loglikelihood requests:  33%|███▎      | 66/200 [00:29<00:58,  2.30it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:30<00:57,  2.30it/s]Running loglikelihood requests:  34%|███▍      | 68/200 [00:30<00:57,  2.31it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:31<00:56,  2.31it/s]Running loglikelihood requests:  35%|███▌      | 70/200 [00:31<00:56,  2.30it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:32<00:56,  2.30it/s]Running loglikelihood requests:  36%|███▌      | 72/200 [00:32<00:55,  2.31it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:32<00:54,  2.31it/s]Running loglikelihood requests:  37%|███▋      | 74/200 [00:33<00:54,  2.32it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:33<00:53,  2.32it/s]Running loglikelihood requests:  38%|███▊      | 76/200 [00:34<00:53,  2.33it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:34<00:52,  2.33it/s]Running loglikelihood requests:  39%|███▉      | 78/200 [00:35<00:52,  2.33it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:35<00:51,  2.34it/s]Running loglikelihood requests:  40%|████      | 80/200 [00:35<00:51,  2.33it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:36<00:51,  2.33it/s]Running loglikelihood requests:  41%|████      | 82/200 [00:36<00:50,  2.33it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:37<00:50,  2.33it/s]Running loglikelihood requests:  42%|████▏     | 84/200 [00:37<00:49,  2.34it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:38<00:49,  2.34it/s]Running loglikelihood requests:  43%|████▎     | 86/200 [00:38<00:48,  2.34it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:38<00:48,  2.34it/s]Running loglikelihood requests:  44%|████▍     | 88/200 [00:39<00:47,  2.34it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:39<00:47,  2.34it/s]Running loglikelihood requests:  45%|████▌     | 90/200 [00:40<00:47,  2.34it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:40<00:46,  2.33it/s]Running loglikelihood requests:  46%|████▌     | 92/200 [00:41<00:46,  2.33it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:41<00:45,  2.33it/s]Running loglikelihood requests:  47%|████▋     | 94/200 [00:41<00:45,  2.33it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:42<00:45,  2.33it/s]Running loglikelihood requests:  48%|████▊     | 96/200 [00:42<00:44,  2.33it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:43<00:44,  2.33it/s]Running loglikelihood requests:  49%|████▉     | 98/200 [00:43<00:45,  2.26it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:44<00:43,  2.30it/s]Running loglikelihood requests:  50%|█████     | 100/200 [00:44<00:43,  2.31it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:44<00:42,  2.33it/s]Running loglikelihood requests:  51%|█████     | 102/200 [00:45<00:41,  2.34it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:45<00:41,  2.35it/s]Running loglikelihood requests:  52%|█████▏    | 104/200 [00:46<00:40,  2.36it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:46<00:40,  2.36it/s]Running loglikelihood requests:  53%|█████▎    | 106/200 [00:46<00:39,  2.36it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:47<00:39,  2.37it/s]Running loglikelihood requests:  54%|█████▍    | 108/200 [00:47<00:38,  2.37it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:48<00:38,  2.36it/s]Running loglikelihood requests:  55%|█████▌    | 110/200 [00:48<00:38,  2.36it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:49<00:37,  2.36it/s]Running loglikelihood requests:  56%|█████▌    | 112/200 [00:49<00:37,  2.36it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:49<00:36,  2.36it/s]Running loglikelihood requests:  57%|█████▋    | 114/200 [00:50<00:36,  2.38it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:50<00:35,  2.38it/s]Running loglikelihood requests:  58%|█████▊    | 116/200 [00:51<00:35,  2.40it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:51<00:34,  2.40it/s]Running loglikelihood requests:  59%|█████▉    | 118/200 [00:52<00:34,  2.40it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:52<00:33,  2.40it/s]Running loglikelihood requests:  60%|██████    | 120/200 [00:52<00:33,  2.39it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:53<00:33,  2.39it/s]Running loglikelihood requests:  61%|██████    | 122/200 [00:53<00:32,  2.39it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:54<00:32,  2.39it/s]Running loglikelihood requests:  62%|██████▏   | 124/200 [00:54<00:31,  2.40it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:54<00:31,  2.40it/s]Running loglikelihood requests:  63%|██████▎   | 126/200 [00:55<00:30,  2.40it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [00:55<00:30,  2.40it/s]Running loglikelihood requests:  64%|██████▍   | 128/200 [00:56<00:30,  2.40it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [00:56<00:29,  2.39it/s]Running loglikelihood requests:  65%|██████▌   | 130/200 [00:57<00:29,  2.40it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [00:57<00:28,  2.40it/s]Running loglikelihood requests:  66%|██████▌   | 132/200 [00:57<00:28,  2.40it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [00:58<00:28,  2.39it/s]Running loglikelihood requests:  67%|██████▋   | 134/200 [00:58<00:27,  2.39it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [00:59<00:27,  2.39it/s]Running loglikelihood requests:  68%|██████▊   | 136/200 [00:59<00:26,  2.39it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [00:59<00:26,  2.39it/s]Running loglikelihood requests:  69%|██████▉   | 138/200 [01:00<00:25,  2.39it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [01:00<00:25,  2.39it/s]Running loglikelihood requests:  70%|███████   | 140/200 [01:01<00:25,  2.39it/s]Running loglikelihood requests:  70%|███████   | 141/200 [01:01<00:24,  2.40it/s]Running loglikelihood requests:  71%|███████   | 142/200 [01:02<00:24,  2.40it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [01:02<00:23,  2.40it/s]Running loglikelihood requests:  72%|███████▏  | 144/200 [01:02<00:23,  2.41it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [01:03<00:22,  2.41it/s]Running loglikelihood requests:  73%|███████▎  | 146/200 [01:03<00:22,  2.41it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [01:04<00:21,  2.42it/s]Running loglikelihood requests:  74%|███████▍  | 148/200 [01:04<00:21,  2.41it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [01:04<00:21,  2.42it/s]Running loglikelihood requests:  75%|███████▌  | 150/200 [01:05<00:20,  2.42it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [01:05<00:20,  2.42it/s]Running loglikelihood requests:  76%|███████▌  | 152/200 [01:06<00:19,  2.42it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [01:06<00:19,  2.42it/s]Running loglikelihood requests:  77%|███████▋  | 154/200 [01:07<00:18,  2.42it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [01:07<00:18,  2.42it/s]Running loglikelihood requests:  78%|███████▊  | 156/200 [01:07<00:18,  2.43it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [01:08<00:17,  2.44it/s]Running loglikelihood requests:  79%|███████▉  | 158/200 [01:08<00:17,  2.43it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [01:09<00:16,  2.43it/s]Running loglikelihood requests:  80%|████████  | 160/200 [01:09<00:16,  2.44it/s]Running loglikelihood requests:  80%|████████  | 161/200 [01:09<00:15,  2.45it/s]Running loglikelihood requests:  81%|████████  | 162/200 [01:10<00:15,  2.45it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [01:10<00:15,  2.46it/s]Running loglikelihood requests:  82%|████████▏ | 164/200 [01:11<00:14,  2.46it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [01:11<00:14,  2.45it/s]Running loglikelihood requests:  83%|████████▎ | 166/200 [01:11<00:13,  2.46it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [01:12<00:13,  2.47it/s]Running loglikelihood requests:  84%|████████▍ | 168/200 [01:12<00:12,  2.47it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [01:13<00:12,  2.47it/s]Running loglikelihood requests:  85%|████████▌ | 170/200 [01:13<00:12,  2.46it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [01:13<00:11,  2.46it/s]Running loglikelihood requests:  86%|████████▌ | 172/200 [01:14<00:11,  2.47it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [01:14<00:10,  2.48it/s]Running loglikelihood requests:  87%|████████▋ | 174/200 [01:15<00:10,  2.48it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [01:15<00:10,  2.49it/s]Running loglikelihood requests:  88%|████████▊ | 176/200 [01:15<00:09,  2.49it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [01:16<00:09,  2.49it/s]Running loglikelihood requests:  89%|████████▉ | 178/200 [01:16<00:08,  2.50it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [01:17<00:08,  2.50it/s]Running loglikelihood requests:  90%|█████████ | 180/200 [01:17<00:07,  2.50it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [01:17<00:07,  2.49it/s]Running loglikelihood requests:  91%|█████████ | 182/200 [01:18<00:07,  2.49it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [01:18<00:06,  2.51it/s]Running loglikelihood requests:  92%|█████████▏| 184/200 [01:19<00:06,  2.52it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [01:19<00:05,  2.52it/s]Running loglikelihood requests:  93%|█████████▎| 186/200 [01:19<00:05,  2.52it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [01:20<00:05,  2.53it/s]Running loglikelihood requests:  94%|█████████▍| 188/200 [01:20<00:04,  2.53it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [01:21<00:04,  2.53it/s]Running loglikelihood requests:  95%|█████████▌| 190/200 [01:21<00:03,  2.56it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [01:21<00:03,  2.55it/s]Running loglikelihood requests:  96%|█████████▌| 192/200 [01:22<00:03,  2.55it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [01:22<00:02,  2.55it/s]Running loglikelihood requests:  97%|█████████▋| 194/200 [01:23<00:02,  2.55it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:23<00:01,  2.58it/s]Running loglikelihood requests:  98%|█████████▊| 196/200 [01:23<00:01,  2.58it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:24<00:01,  2.60it/s]Running loglikelihood requests:  99%|█████████▉| 198/200 [01:24<00:00,  2.61it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:24<00:00,  2.61it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:25<00:00,  2.63it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:25<00:00,  2.34it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:4'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:4'}
full model:
{'copa': {'alias': 'copa', 'acc,none': 0.82, 'acc_stderr,none': 0.03861229196653691}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.7827148355678417
0.8244609672079803
0.649635438690672
0.6067147398962018
0.806517251330611
0.9304450428937726
0.9492767057467371
0.8146777207922447
0.5943920512469448
0.6904992046065734
0.898578027138337
0.9772061768478973
0.9053772479641496
0.8020143483317842
0.5125553000556808
0.7018400400551881
0.8957865573767195
0.6076519427757794
0.975563476608663
0.9639212062070597
0.9296418237714587
0.9150145595079396
0.9197448761365332
0.7066536936990038
0.6639302750778917
0.912306872752127
0.7698141900267782
0.6230420491138425
0.8289959673107662
Total groups 68 exceeded the threshold, stopping comparison.
The group tensor is
[7, 3, 4, 1, 2, 6, 5, 0]
tensor([7, 3, 4, 1, 2, 6, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 4, 1, 0, 5, 7, 2]
tensor([6, 3, 4, 1, 0, 5, 7, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[7, 4, 3, 2, 0, 5, 6, 1]
tensor([7, 4, 3, 2, 0, 5, 6, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[7, 6, 4, 2, 1, 3, 5, 0]
tensor([7, 6, 4, 2, 1, 3, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 3, 0, 1, 2, 3, 2]
tensor([0, 1, 3, 0, 1, 2, 3, 2], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 3, 1, 0, 2, 3, 2]
tensor([0, 1, 3, 1, 0, 2, 3, 2], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 0, 1.0, 1.0, 1.0, 1]
tensor([0, 1, 1, 0, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1, 1.0, 1.0, 1.0, 0]
tensor([0, 1, 1, 1, 1, 1, 1, 0], dtype=torch.int32)
[0, 1]
Normal merging for layer 1
tensor([4])
tensor(4)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 2 to 3
done!
Normal merging for layer 4
tensor([4])
tensor(4)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 5 to 6
done!
Normal merging for layer 7
tensor([7])
tensor(7)
tensor([4])
tensor(4)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 8 to 15
done!
Normal merging for layer 16
tensor([0, 3])
tensor(0)
tensor([1, 4])
tensor(1)
tensor([5, 7])
tensor(5)
tensor([2, 6])
tensor(2)
done!
Cross-layer merge completed for layers 17 to 21
done!
Normal merging for layer 22
tensor([0, 4])
tensor(0)
tensor([1, 3])
tensor(1)
tensor([5, 7])
tensor(5)
tensor([2, 6])
tensor(2)
done!
Cross-layer merge completed for layers 23 to 27
done!
Normal merging for layer 28
tensor([0, 3])
tensor(0)
tensor([1, 2, 4, 5, 6, 7])
tensor(1)
done!
Cross-layer merge completed for layers 29 to 30
done!
Normal merging for layer 31
tensor([0, 7])
tensor(0)
tensor([1, 2, 3, 4, 5, 6])
tensor(1)
done!
all done!
Model size: 12.1348 GB
157
cuda:4
wnli
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:41<00:41, 41.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:53<00:00, 24.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:53<00:00, 26.89s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/wnli?recursive=False&expand=False HTTP/1.1" 307 141
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/wnli?recursive=False&expand=False HTTP/1.1" 200 352
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140237327953184 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140237327953184 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140237327953184 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140237327953184 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140242299338288 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140242299338288 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140242299338288 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140242299338288 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 1672.97it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:01<03:15,  1.39s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:02<01:29,  1.56it/s]Running loglikelihood requests:   4%|▎         | 5/142 [00:02<01:09,  1.97it/s]Running loglikelihood requests:   5%|▍         | 7/142 [00:03<01:01,  2.21it/s]Running loglikelihood requests:   6%|▋         | 9/142 [00:04<00:55,  2.38it/s]Running loglikelihood requests:   8%|▊         | 11/142 [00:05<00:52,  2.51it/s]Running loglikelihood requests:   9%|▉         | 13/142 [00:05<00:49,  2.60it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:06<00:46,  2.71it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:07<00:44,  2.79it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:07<00:42,  2.90it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:08<00:40,  2.98it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:09<00:38,  3.06it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:09<00:37,  3.12it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:10<00:36,  3.18it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:10<00:35,  3.22it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:11<00:34,  3.25it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:12<00:33,  3.28it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:12<00:32,  3.30it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:13<00:31,  3.31it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:13<00:30,  3.33it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:14<00:30,  3.34it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:15<00:29,  3.36it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:15<00:28,  3.39it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:16<00:27,  3.43it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:16<00:26,  3.47it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:17<00:25,  3.51it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:17<00:25,  3.55it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:18<00:24,  3.58it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:18<00:23,  3.61it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:19<00:22,  3.62it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:20<00:22,  3.63it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:20<00:21,  3.64it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:21<00:21,  3.66it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:21<00:20,  3.66it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:22<00:19,  3.68it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:22<00:19,  3.69it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:23<00:18,  3.71it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [00:23<00:18,  3.72it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [00:24<00:17,  3.73it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [00:24<00:16,  3.75it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [00:25<00:16,  3.76it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [00:25<00:15,  3.76it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [00:26<00:15,  3.77it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [00:26<00:14,  3.78it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [00:27<00:13,  3.79it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [00:28<00:13,  3.80it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [00:28<00:12,  3.81it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [00:29<00:12,  3.82it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [00:29<00:11,  3.83it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [00:30<00:11,  3.84it/s]Running loglikelihood requests:  71%|███████   | 101/142 [00:30<00:10,  3.85it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [00:31<00:10,  3.86it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [00:31<00:09,  3.87it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [00:32<00:09,  3.89it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [00:32<00:08,  3.89it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [00:33<00:07,  3.91it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [00:33<00:07,  3.92it/s]Running loglikelihood requests:  81%|████████  | 115/142 [00:34<00:06,  3.93it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [00:34<00:06,  3.93it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [00:35<00:05,  3.95it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [00:35<00:05,  3.96it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [00:36<00:04,  3.98it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [00:36<00:04,  3.98it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [00:37<00:03,  3.99it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [00:37<00:03,  4.00it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [00:38<00:02,  4.02it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [00:38<00:02,  4.04it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [00:39<00:01,  4.07it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [00:39<00:01,  4.10it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [00:40<00:00,  4.11it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [00:40<00:00,  4.16it/s]Running loglikelihood requests: 100%|██████████| 142/142 [00:40<00:00,  3.50it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:5'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:5'}
full model:
{'wnli': {'alias': 'wnli', 'acc,none': 0.5352112676056338, 'acc_stderr,none': 0.0596130578497224}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.31190044950254875
0.7306280553786256
0.6985925052465822
0.5843516732063875
0.8124235844589114
0.820438203921003
0.6253838264581936
0.7600037006947045
0.8225872978677496
0.708398461303215
0.8646089269479391
0.8239362351853257
0.7608099850331435
0.6657423857513638
0.7943257460202938
0.7511476003698512
0.9073696655228775
0.8741838353767599
0.7945799099309127
0.9323691001541556
0.865243808509542
0.8176606226311932
0.6785099625983169
0.9579534328203848
0.788928884938056
0.9833718962298513
0.5933012307657521
0.7829988799240639
0.7823073743206628
0.31190044950254875
0.7306280553786256
0.6985925052465822
0.5843516732063875
0.8124235844589114
0.820438203921003
0.6253838264581936
0.7600037006947045
0.8225872978677496
0.708398461303215
0.8646089269479391
0.8239362351853257
0.7608099850331435
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[7, 4, 5, 1, 6, 3, 2, 0]
tensor([7, 4, 5, 1, 6, 3, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 2, 4, 5, 6, 1, 0, 3]
tensor([7, 2, 4, 5, 6, 1, 0, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 7, 5, 4, 1, 2, 0]
tensor([6, 3, 7, 5, 4, 1, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 3, 6, 4, 7, 1, 2, 0]
tensor([5, 3, 6, 4, 7, 1, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 3, 6, 5, 7, 2, 1, 0]
tensor([4, 3, 6, 5, 7, 2, 1, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1, 2, 3, 2, 3, 0]
tensor([0, 1, 1, 2, 3, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 1, 2, 2, 3, 0, 3, 1]
tensor([0, 1, 2, 2, 3, 0, 3, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 1, 1, 1.0, 1.0, 1.0, 1.0]
tensor([0, 0, 1, 1, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
Normal merging for layer 1
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
done!
Normal merging for layer 2
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
tensor([3])
tensor(3)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Normal merging for layer 4
tensor([7])
tensor(7)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 5 to 15
done!
Normal merging for layer 16
tensor([0, 7])
tensor(0)
tensor([1, 2])
tensor(1)
tensor([3, 5])
tensor(3)
tensor([4, 6])
tensor(4)
done!
Normal merging for layer 17
tensor([0, 5])
tensor(0)
tensor([1, 7])
tensor(1)
tensor([2, 3])
tensor(2)
tensor([4, 6])
tensor(4)
done!
Cross-layer merge completed for layers 18 to 30
done!
Normal merging for layer 31
tensor([0, 1])
tensor(0)
tensor([2, 3, 4, 5, 6, 7])
tensor(2)
done!
all done!
Model size: 12.2608 GB
127
cuda:5
copa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:41<00:41, 41.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 24.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 27.16s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: copa] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: copa] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/super_glue/super_glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140240013619520 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_copa_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 140240013619520 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_copa_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/copa/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 140240013619520 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_copa_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 140240013619520 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_copa_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Attempting to acquire lock 140218738161136 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/copa/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 140218738161136 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/copa/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/copa/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 140218738161136 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/copa/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 140218738161136 released on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/copa/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
DEBUG:lm_eval.api.task:Both target_delimiter " " and target choice: " the toilet filled with water." have whitespace
DEBUG:lm_eval.api.task:Both target_delimiter " " and target choice: " water flowed from the spout." have whitespace
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of copa from None to 0
INFO:lm_eval.api.task:Building contexts for copa on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 145332.78it/s]
DEBUG:lm_eval.evaluator:Task: copa; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:00<03:02,  1.09it/s]Running loglikelihood requests:   1%|          | 2/200 [00:01<02:09,  1.52it/s]Running loglikelihood requests:   2%|▏         | 3/200 [00:01<01:51,  1.77it/s]Running loglikelihood requests:   2%|▏         | 4/200 [00:02<01:42,  1.91it/s]Running loglikelihood requests:   2%|▎         | 5/200 [00:02<01:37,  2.01it/s]Running loglikelihood requests:   3%|▎         | 6/200 [00:03<01:33,  2.07it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:03<01:31,  2.11it/s]Running loglikelihood requests:   4%|▍         | 8/200 [00:04<01:29,  2.15it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:04<01:28,  2.17it/s]Running loglikelihood requests:   5%|▌         | 10/200 [00:05<01:28,  2.14it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:05<01:27,  2.17it/s]Running loglikelihood requests:   6%|▌         | 12/200 [00:05<01:25,  2.19it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:06<01:24,  2.20it/s]Running loglikelihood requests:   7%|▋         | 14/200 [00:06<01:25,  2.18it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:07<01:24,  2.20it/s]Running loglikelihood requests:   8%|▊         | 16/200 [00:07<01:23,  2.21it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:08<01:22,  2.23it/s]Running loglikelihood requests:   9%|▉         | 18/200 [00:08<01:21,  2.24it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:09<01:21,  2.21it/s]Running loglikelihood requests:  10%|█         | 20/200 [00:09<01:21,  2.22it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:10<01:21,  2.19it/s]Running loglikelihood requests:  11%|█         | 22/200 [00:10<01:20,  2.21it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:10<01:19,  2.23it/s]Running loglikelihood requests:  12%|█▏        | 24/200 [00:11<01:18,  2.24it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:11<01:17,  2.25it/s]Running loglikelihood requests:  13%|█▎        | 26/200 [00:12<01:17,  2.25it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:12<01:16,  2.25it/s]Running loglikelihood requests:  14%|█▍        | 28/200 [00:13<01:16,  2.25it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:13<01:15,  2.26it/s]Running loglikelihood requests:  15%|█▌        | 30/200 [00:13<01:14,  2.28it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:14<01:13,  2.29it/s]Running loglikelihood requests:  16%|█▌        | 32/200 [00:14<01:13,  2.29it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:15<01:12,  2.29it/s]Running loglikelihood requests:  17%|█▋        | 34/200 [00:15<01:12,  2.29it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:16<01:11,  2.30it/s]Running loglikelihood requests:  18%|█▊        | 36/200 [00:16<01:11,  2.30it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:17<01:10,  2.30it/s]Running loglikelihood requests:  19%|█▉        | 38/200 [00:17<01:10,  2.30it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:17<01:10,  2.29it/s]Running loglikelihood requests:  20%|██        | 40/200 [00:18<01:09,  2.30it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:18<01:09,  2.29it/s]Running loglikelihood requests:  21%|██        | 42/200 [00:19<01:08,  2.29it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:19<01:08,  2.30it/s]Running loglikelihood requests:  22%|██▏       | 44/200 [00:20<01:08,  2.29it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:20<01:07,  2.30it/s]Running loglikelihood requests:  23%|██▎       | 46/200 [00:20<01:06,  2.30it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:21<01:06,  2.30it/s]Running loglikelihood requests:  24%|██▍       | 48/200 [00:21<01:06,  2.30it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:22<01:05,  2.29it/s]Running loglikelihood requests:  25%|██▌       | 50/200 [00:22<01:05,  2.29it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:23<01:05,  2.29it/s]Running loglikelihood requests:  26%|██▌       | 52/200 [00:23<01:04,  2.29it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:23<01:04,  2.29it/s]Running loglikelihood requests:  27%|██▋       | 54/200 [00:24<01:03,  2.30it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:24<01:03,  2.27it/s]Running loglikelihood requests:  28%|██▊       | 56/200 [00:25<01:03,  2.28it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:25<01:02,  2.29it/s]Running loglikelihood requests:  29%|██▉       | 58/200 [00:26<01:01,  2.30it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:26<01:01,  2.30it/s]Running loglikelihood requests:  30%|███       | 60/200 [00:27<01:00,  2.30it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:27<01:00,  2.30it/s]Running loglikelihood requests:  31%|███       | 62/200 [00:27<00:59,  2.31it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:28<00:59,  2.31it/s]Running loglikelihood requests:  32%|███▏      | 64/200 [00:28<00:58,  2.31it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:29<00:58,  2.31it/s]Running loglikelihood requests:  33%|███▎      | 66/200 [00:29<00:57,  2.31it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:30<00:57,  2.31it/s]Running loglikelihood requests:  34%|███▍      | 68/200 [00:30<00:56,  2.32it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:30<00:56,  2.32it/s]Running loglikelihood requests:  35%|███▌      | 70/200 [00:31<00:56,  2.32it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:31<00:55,  2.32it/s]Running loglikelihood requests:  36%|███▌      | 72/200 [00:32<00:55,  2.32it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:32<00:54,  2.33it/s]Running loglikelihood requests:  37%|███▋      | 74/200 [00:33<00:53,  2.34it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:33<00:53,  2.34it/s]Running loglikelihood requests:  38%|███▊      | 76/200 [00:33<00:52,  2.34it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:34<00:52,  2.34it/s]Running loglikelihood requests:  39%|███▉      | 78/200 [00:34<00:51,  2.35it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:35<00:51,  2.35it/s]Running loglikelihood requests:  40%|████      | 80/200 [00:35<00:51,  2.35it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:36<00:50,  2.35it/s]Running loglikelihood requests:  41%|████      | 82/200 [00:36<00:50,  2.34it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:36<00:49,  2.34it/s]Running loglikelihood requests:  42%|████▏     | 84/200 [00:37<00:49,  2.35it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:37<00:48,  2.35it/s]Running loglikelihood requests:  43%|████▎     | 86/200 [00:38<00:48,  2.35it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:38<00:48,  2.35it/s]Running loglikelihood requests:  44%|████▍     | 88/200 [00:39<00:47,  2.35it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:39<00:47,  2.35it/s]Running loglikelihood requests:  45%|████▌     | 90/200 [00:39<00:46,  2.34it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:40<00:46,  2.34it/s]Running loglikelihood requests:  46%|████▌     | 92/200 [00:40<00:46,  2.34it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:41<00:45,  2.34it/s]Running loglikelihood requests:  47%|████▋     | 94/200 [00:41<00:45,  2.34it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:42<00:44,  2.34it/s]Running loglikelihood requests:  48%|████▊     | 96/200 [00:42<00:44,  2.34it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:42<00:44,  2.34it/s]Running loglikelihood requests:  49%|████▉     | 98/200 [00:43<00:43,  2.35it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:43<00:42,  2.36it/s]Running loglikelihood requests:  50%|█████     | 100/200 [00:44<00:42,  2.36it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:44<00:41,  2.36it/s]Running loglikelihood requests:  51%|█████     | 102/200 [00:45<00:41,  2.36it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:45<00:41,  2.36it/s]Running loglikelihood requests:  52%|█████▏    | 104/200 [00:45<00:40,  2.37it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:46<00:40,  2.37it/s]Running loglikelihood requests:  53%|█████▎    | 106/200 [00:46<00:39,  2.37it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:47<00:39,  2.37it/s]Running loglikelihood requests:  54%|█████▍    | 108/200 [00:47<00:38,  2.37it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:47<00:38,  2.37it/s]Running loglikelihood requests:  55%|█████▌    | 110/200 [00:48<00:38,  2.36it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:48<00:37,  2.37it/s]Running loglikelihood requests:  56%|█████▌    | 112/200 [00:49<00:37,  2.37it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:49<00:36,  2.37it/s]Running loglikelihood requests:  57%|█████▋    | 114/200 [00:50<00:36,  2.38it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:50<00:35,  2.39it/s]Running loglikelihood requests:  58%|█████▊    | 116/200 [00:50<00:34,  2.40it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:51<00:34,  2.41it/s]Running loglikelihood requests:  59%|█████▉    | 118/200 [00:51<00:34,  2.41it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:52<00:33,  2.41it/s]Running loglikelihood requests:  60%|██████    | 120/200 [00:52<00:33,  2.40it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:52<00:32,  2.40it/s]Running loglikelihood requests:  61%|██████    | 122/200 [00:53<00:32,  2.40it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:53<00:32,  2.40it/s]Running loglikelihood requests:  62%|██████▏   | 124/200 [00:54<00:31,  2.41it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:54<00:31,  2.41it/s]Running loglikelihood requests:  63%|██████▎   | 126/200 [00:55<00:30,  2.41it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [00:55<00:30,  2.41it/s]Running loglikelihood requests:  64%|██████▍   | 128/200 [00:55<00:29,  2.41it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [00:56<00:29,  2.40it/s]Running loglikelihood requests:  65%|██████▌   | 130/200 [00:56<00:29,  2.41it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [00:57<00:28,  2.41it/s]Running loglikelihood requests:  66%|██████▌   | 132/200 [00:57<00:28,  2.41it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [00:57<00:27,  2.40it/s]Running loglikelihood requests:  67%|██████▋   | 134/200 [00:58<00:27,  2.40it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [00:58<00:27,  2.40it/s]Running loglikelihood requests:  68%|██████▊   | 136/200 [00:59<00:26,  2.40it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [00:59<00:26,  2.41it/s]Running loglikelihood requests:  69%|██████▉   | 138/200 [01:00<00:26,  2.37it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [01:00<00:26,  2.34it/s]Running loglikelihood requests:  70%|███████   | 140/200 [01:00<00:25,  2.37it/s]Running loglikelihood requests:  70%|███████   | 141/200 [01:01<00:24,  2.39it/s]Running loglikelihood requests:  71%|███████   | 142/200 [01:01<00:24,  2.40it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [01:02<00:23,  2.41it/s]Running loglikelihood requests:  72%|███████▏  | 144/200 [01:02<00:23,  2.43it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [01:02<00:22,  2.43it/s]Running loglikelihood requests:  73%|███████▎  | 146/200 [01:03<00:22,  2.44it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [01:03<00:22,  2.41it/s]Running loglikelihood requests:  74%|███████▍  | 148/200 [01:04<00:21,  2.38it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [01:04<00:21,  2.40it/s]Running loglikelihood requests:  75%|███████▌  | 150/200 [01:05<00:20,  2.41it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [01:05<00:20,  2.43it/s]Running loglikelihood requests:  76%|███████▌  | 152/200 [01:05<00:19,  2.43it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [01:06<00:19,  2.44it/s]Running loglikelihood requests:  77%|███████▋  | 154/200 [01:06<00:18,  2.45it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [01:07<00:18,  2.45it/s]Running loglikelihood requests:  78%|███████▊  | 156/200 [01:07<00:17,  2.46it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [01:07<00:17,  2.47it/s]Running loglikelihood requests:  79%|███████▉  | 158/200 [01:08<00:17,  2.46it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [01:08<00:16,  2.47it/s]Running loglikelihood requests:  80%|████████  | 160/200 [01:09<00:16,  2.48it/s]Running loglikelihood requests:  80%|████████  | 161/200 [01:09<00:15,  2.49it/s]Running loglikelihood requests:  81%|████████  | 162/200 [01:09<00:15,  2.49it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [01:10<00:15,  2.44it/s]Running loglikelihood requests:  82%|████████▏ | 164/200 [01:10<00:14,  2.42it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [01:11<00:14,  2.44it/s]Running loglikelihood requests:  83%|████████▎ | 166/200 [01:11<00:13,  2.46it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [01:11<00:13,  2.48it/s]Running loglikelihood requests:  84%|████████▍ | 168/200 [01:12<00:12,  2.48it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [01:12<00:12,  2.48it/s]Running loglikelihood requests:  85%|████████▌ | 170/200 [01:13<00:12,  2.47it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [01:13<00:11,  2.48it/s]Running loglikelihood requests:  86%|████████▌ | 172/200 [01:13<00:11,  2.48it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [01:14<00:10,  2.50it/s]Running loglikelihood requests:  87%|████████▋ | 174/200 [01:14<00:10,  2.50it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [01:15<00:09,  2.51it/s]Running loglikelihood requests:  88%|████████▊ | 176/200 [01:15<00:09,  2.51it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [01:15<00:09,  2.51it/s]Running loglikelihood requests:  89%|████████▉ | 178/200 [01:16<00:08,  2.52it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [01:16<00:08,  2.52it/s]Running loglikelihood requests:  90%|█████████ | 180/200 [01:17<00:07,  2.52it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [01:17<00:07,  2.51it/s]Running loglikelihood requests:  91%|█████████ | 182/200 [01:17<00:07,  2.51it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [01:18<00:06,  2.54it/s]Running loglikelihood requests:  92%|█████████▏| 184/200 [01:18<00:06,  2.55it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [01:19<00:05,  2.55it/s]Running loglikelihood requests:  93%|█████████▎| 186/200 [01:19<00:05,  2.55it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [01:19<00:05,  2.56it/s]Running loglikelihood requests:  94%|█████████▍| 188/200 [01:20<00:04,  2.55it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [01:20<00:04,  2.56it/s]Running loglikelihood requests:  95%|█████████▌| 190/200 [01:21<00:03,  2.58it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [01:21<00:03,  2.57it/s]Running loglikelihood requests:  96%|█████████▌| 192/200 [01:21<00:03,  2.57it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [01:22<00:02,  2.57it/s]Running loglikelihood requests:  97%|█████████▋| 194/200 [01:22<00:02,  2.57it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:22<00:01,  2.61it/s]Running loglikelihood requests:  98%|█████████▊| 196/200 [01:23<00:01,  2.61it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:23<00:01,  2.63it/s]Running loglikelihood requests:  99%|█████████▉| 198/200 [01:24<00:00,  2.65it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:24<00:00,  2.65it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:24<00:00,  2.67it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:24<00:00,  2.36it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:6'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:6'}
full model:
{'copa': {'alias': 'copa', 'acc,none': 0.82, 'acc_stderr,none': 0.03861229196653691}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.7827148355678417
0.8244609672079803
0.649635438690672
0.6067147398962018
0.806517251330611
0.9304450428937726
0.9492767057467371
0.8146777207922447
0.5943920512469448
0.6904992046065734
0.898578027138337
0.9772061768478973
0.9053772479641496
0.8020143483317842
0.5125553000556808
0.7018400400551881
0.8957865573767195
0.6076519427757794
0.975563476608663
0.9639212062070597
0.9296418237714587
0.9150145595079396
0.9197448761365332
0.7066536936990038
0.6639302750778917
0.912306872752127
0.7698141900267782
0.6230420491138425
0.8289959673107662
Total groups 68 exceeded the threshold, stopping comparison.
The group tensor is
[7, 3, 4, 1, 2, 6, 5, 0]
tensor([7, 3, 4, 1, 2, 6, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 4, 1, 0, 5, 7, 2]
tensor([6, 3, 4, 1, 0, 5, 7, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[7, 4, 3, 2, 0, 5, 6, 1]
tensor([7, 4, 3, 2, 0, 5, 6, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[7, 6, 4, 2, 1, 3, 5, 0]
tensor([7, 6, 4, 2, 1, 3, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 3, 0, 1, 2, 3, 2]
tensor([0, 1, 3, 0, 1, 2, 3, 2], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 3, 1, 0, 2, 3, 2]
tensor([0, 1, 3, 1, 0, 2, 3, 2], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 0, 1.0, 1.0, 1.0, 1]
tensor([0, 1, 1, 0, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1, 1.0, 1.0, 1.0, 0]
tensor([0, 1, 1, 1, 1, 1, 1, 0], dtype=torch.int32)
[0, 1]
Normal merging for layer 1
tensor([4])
tensor(4)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([6])
tensor(6)
done!
Cross-layer merge completed for layers 2 to 3
done!
Normal merging for layer 4
tensor([4])
tensor(4)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 5 to 6
done!
Normal merging for layer 7
tensor([7])
tensor(7)
tensor([4])
tensor(4)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 8 to 15
done!
Normal merging for layer 16
tensor([0, 3])
tensor(0)
tensor([1, 4])
tensor(1)
tensor([5, 7])
tensor(5)
tensor([2, 6])
tensor(2)
done!
Cross-layer merge completed for layers 17 to 21
done!
Normal merging for layer 22
tensor([0, 4])
tensor(0)
tensor([1, 3])
tensor(1)
tensor([5, 7])
tensor(5)
tensor([2, 6])
tensor(2)
done!
Cross-layer merge completed for layers 23 to 27
done!
Normal merging for layer 28
tensor([0, 3])
tensor(0)
tensor([1, 2, 4, 5, 6, 7])
tensor(1)
done!
Cross-layer merge completed for layers 29 to 30
done!
Normal merging for layer 31
tensor([0, 7])
tensor(0)
tensor([1, 2, 3, 4, 5, 6])
tensor(1)
done!
all done!
Model size: 12.1348 GB
94
cuda:6
cola
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:41<00:41, 41.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 24.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 27.25s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: cola] metric mcc is defined, but aggregation is not. using default aggregation=matthews_corrcoef
WARNING:lm_eval.api.task:[Task: cola] metric mcc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cola?recursive=False&expand=False HTTP/1.1" 307 141
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cola?recursive=False&expand=False HTTP/1.1" 200 358
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140236790266336 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_cola_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140236790266336 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_cola_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140236790266336 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_cola_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140236790266336 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_cola_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140237329562128 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140237329562128 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140237329562128 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140237329562128 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of cola from None to 0
INFO:lm_eval.api.task:Building contexts for cola on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 3223.51it/s]
DEBUG:lm_eval.evaluator:Task: cola; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:01<03:21,  1.01s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:01<01:31,  2.15it/s]Running loglikelihood requests:   2%|▎         | 5/200 [00:02<01:09,  2.80it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:02<01:00,  3.17it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:03<00:55,  3.44it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:03<00:52,  3.62it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:04<00:49,  3.76it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:04<00:48,  3.85it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:05<00:46,  3.92it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:05<00:45,  3.98it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:06<00:44,  4.01it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:06<00:43,  4.03it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:07<00:43,  4.05it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:07<00:42,  4.07it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:07<00:41,  4.10it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:08<00:41,  4.12it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:08<00:40,  4.12it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:09<00:39,  4.14it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:09<00:39,  4.15it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:10<00:38,  4.15it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:10<00:38,  4.17it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:11<00:37,  4.17it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:11<00:36,  4.20it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:12<00:36,  4.21it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:12<00:35,  4.21it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:13<00:35,  4.23it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:13<00:34,  4.24it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:14<00:34,  4.25it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:14<00:33,  4.26it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:15<00:33,  4.26it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:15<00:32,  4.28it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:16<00:31,  4.29it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:16<00:31,  4.30it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:16<00:30,  4.30it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:17<00:30,  4.32it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:17<00:29,  4.33it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:18<00:29,  4.34it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:18<00:28,  4.34it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:19<00:28,  4.35it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:19<00:27,  4.35it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:20<00:27,  4.35it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:20<00:26,  4.36it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:21<00:26,  4.38it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:21<00:25,  4.39it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:21<00:25,  4.40it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:22<00:24,  4.40it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:22<00:24,  4.40it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:23<00:23,  4.40it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:23<00:23,  4.40it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:24<00:22,  4.41it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:24<00:22,  4.43it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:25<00:21,  4.44it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:25<00:21,  4.44it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:26<00:20,  4.45it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:26<00:20,  4.45it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:26<00:20,  4.44it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:27<00:19,  4.44it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:27<00:19,  4.44it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:28<00:18,  4.46it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:28<00:18,  4.47it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:29<00:17,  4.48it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:29<00:17,  4.48it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:30<00:16,  4.49it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [00:30<00:16,  4.49it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [00:30<00:15,  4.49it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [00:31<00:15,  4.52it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [00:31<00:14,  4.53it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [00:32<00:14,  4.53it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [00:32<00:13,  4.53it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [00:33<00:13,  4.54it/s]Running loglikelihood requests:  70%|███████   | 141/200 [00:33<00:12,  4.56it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [00:34<00:12,  4.57it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [00:34<00:12,  4.57it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [00:34<00:11,  4.58it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [00:35<00:11,  4.59it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [00:35<00:10,  4.59it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [00:36<00:10,  4.60it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [00:36<00:09,  4.60it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [00:37<00:09,  4.61it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [00:37<00:08,  4.62it/s]Running loglikelihood requests:  80%|████████  | 161/200 [00:37<00:08,  4.63it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [00:38<00:07,  4.64it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [00:38<00:07,  4.64it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [00:39<00:07,  4.65it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [00:39<00:06,  4.65it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [00:40<00:06,  4.67it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [00:40<00:05,  4.69it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [00:40<00:05,  4.70it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [00:41<00:04,  4.71it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [00:41<00:04,  4.71it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [00:42<00:04,  4.71it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [00:42<00:03,  4.71it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [00:43<00:03,  4.71it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [00:43<00:02,  4.72it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [00:43<00:02,  4.74it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [00:44<00:01,  4.76it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [00:44<00:01,  4.78it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [00:45<00:01,  4.79it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [00:45<00:00,  4.80it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [00:45<00:00,  4.82it/s]Running loglikelihood requests: 100%|██████████| 200/200 [00:45<00:00,  4.35it/s]
bootstrapping for stddev (sequential): matthews_corrcoef
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<01:34,  1.05it/s]  2%|▏         | 2/100 [00:01<01:32,  1.06it/s]  3%|▎         | 3/100 [00:02<01:30,  1.07it/s]  4%|▍         | 4/100 [00:03<01:29,  1.08it/s]  5%|▌         | 5/100 [00:04<01:28,  1.08it/s]  6%|▌         | 6/100 [00:05<01:27,  1.08it/s]  7%|▋         | 7/100 [00:06<01:26,  1.08it/s]  8%|▊         | 8/100 [00:07<01:25,  1.08it/s]  9%|▉         | 9/100 [00:08<01:24,  1.08it/s] 10%|█         | 10/100 [00:09<01:23,  1.08it/s] 11%|█         | 11/100 [00:10<01:22,  1.08it/s] 12%|█▏        | 12/100 [00:11<01:21,  1.08it/s] 13%|█▎        | 13/100 [00:12<01:20,  1.08it/s] 14%|█▍        | 14/100 [00:13<01:19,  1.08it/s] 15%|█▌        | 15/100 [00:13<01:18,  1.08it/s] 16%|█▌        | 16/100 [00:14<01:17,  1.08it/s] 17%|█▋        | 17/100 [00:15<01:16,  1.08it/s] 18%|█▊        | 18/100 [00:16<01:16,  1.08it/s] 19%|█▉        | 19/100 [00:17<01:15,  1.08it/s] 20%|██        | 20/100 [00:18<01:14,  1.08it/s] 21%|██        | 21/100 [00:19<01:13,  1.08it/s] 22%|██▏       | 22/100 [00:20<01:12,  1.08it/s] 23%|██▎       | 23/100 [00:21<01:11,  1.08it/s] 24%|██▍       | 24/100 [00:22<01:10,  1.08it/s] 25%|██▌       | 25/100 [00:23<01:09,  1.08it/s] 26%|██▌       | 26/100 [00:24<01:08,  1.08it/s] 27%|██▋       | 27/100 [00:25<01:07,  1.08it/s] 28%|██▊       | 28/100 [00:25<01:06,  1.08it/s] 29%|██▉       | 29/100 [00:26<01:06,  1.07it/s] 30%|███       | 30/100 [00:27<01:05,  1.07it/s] 31%|███       | 31/100 [00:28<01:04,  1.07it/s] 32%|███▏      | 32/100 [00:29<01:03,  1.07it/s] 33%|███▎      | 33/100 [00:30<01:02,  1.07it/s] 34%|███▍      | 34/100 [00:31<01:01,  1.07it/s] 35%|███▌      | 35/100 [00:32<01:00,  1.07it/s] 36%|███▌      | 36/100 [00:33<00:59,  1.07it/s] 37%|███▋      | 37/100 [00:34<00:58,  1.07it/s] 38%|███▊      | 38/100 [00:35<00:57,  1.07it/s] 39%|███▉      | 39/100 [00:36<00:56,  1.07it/s] 40%|████      | 40/100 [00:37<00:56,  1.07it/s] 41%|████      | 41/100 [00:38<00:55,  1.07it/s] 42%|████▏     | 42/100 [00:39<00:54,  1.07it/s] 43%|████▎     | 43/100 [00:40<00:53,  1.07it/s] 44%|████▍     | 44/100 [00:40<00:52,  1.07it/s] 45%|████▌     | 45/100 [00:41<00:51,  1.07it/s] 46%|████▌     | 46/100 [00:42<00:50,  1.07it/s] 47%|████▋     | 47/100 [00:43<00:49,  1.07it/s] 48%|████▊     | 48/100 [00:44<00:48,  1.07it/s] 49%|████▉     | 49/100 [00:45<00:47,  1.07it/s] 50%|█████     | 50/100 [00:46<00:46,  1.07it/s] 51%|█████     | 51/100 [00:47<00:45,  1.07it/s] 52%|█████▏    | 52/100 [00:48<00:44,  1.07it/s] 53%|█████▎    | 53/100 [00:49<00:44,  1.06it/s] 54%|█████▍    | 54/100 [00:50<00:43,  1.07it/s] 55%|█████▌    | 55/100 [00:51<00:42,  1.07it/s] 56%|█████▌    | 56/100 [00:52<00:41,  1.07it/s] 57%|█████▋    | 57/100 [00:53<00:40,  1.07it/s] 58%|█████▊    | 58/100 [00:54<00:39,  1.07it/s] 59%|█████▉    | 59/100 [00:54<00:38,  1.07it/s] 60%|██████    | 60/100 [00:55<00:37,  1.07it/s] 61%|██████    | 61/100 [00:56<00:36,  1.07it/s] 62%|██████▏   | 62/100 [00:57<00:35,  1.07it/s] 63%|██████▎   | 63/100 [00:58<00:34,  1.07it/s] 64%|██████▍   | 64/100 [00:59<00:33,  1.07it/s] 65%|██████▌   | 65/100 [01:00<00:32,  1.07it/s] 66%|██████▌   | 66/100 [01:01<00:31,  1.07it/s] 67%|██████▋   | 67/100 [01:02<00:30,  1.07it/s] 68%|██████▊   | 68/100 [01:03<00:30,  1.06it/s] 69%|██████▉   | 69/100 [01:04<00:29,  1.06it/s] 70%|███████   | 70/100 [01:05<00:28,  1.06it/s] 71%|███████   | 71/100 [01:06<00:27,  1.06it/s] 72%|███████▏  | 72/100 [01:07<00:26,  1.06it/s] 73%|███████▎  | 73/100 [01:08<00:25,  1.06it/s] 74%|███████▍  | 74/100 [01:09<00:24,  1.06it/s] 75%|███████▌  | 75/100 [01:09<00:23,  1.06it/s] 76%|███████▌  | 76/100 [01:10<00:22,  1.06it/s] 77%|███████▋  | 77/100 [01:11<00:21,  1.05it/s] 78%|███████▊  | 78/100 [01:12<00:20,  1.06it/s] 79%|███████▉  | 79/100 [01:13<00:19,  1.06it/s] 80%|████████  | 80/100 [01:14<00:18,  1.06it/s] 81%|████████  | 81/100 [01:15<00:17,  1.06it/s] 82%|████████▏ | 82/100 [01:16<00:17,  1.06it/s] 83%|████████▎ | 83/100 [01:17<00:16,  1.05it/s] 84%|████████▍ | 84/100 [01:18<00:15,  1.06it/s] 85%|████████▌ | 85/100 [01:19<00:14,  1.06it/s] 86%|████████▌ | 86/100 [01:20<00:13,  1.06it/s] 87%|████████▋ | 87/100 [01:21<00:12,  1.06it/s] 88%|████████▊ | 88/100 [01:22<00:11,  1.06it/s] 89%|████████▉ | 89/100 [01:23<00:10,  1.06it/s] 90%|█████████ | 90/100 [01:24<00:09,  1.06it/s] 91%|█████████ | 91/100 [01:25<00:08,  1.06it/s] 92%|█████████▏| 92/100 [01:26<00:07,  1.06it/s] 93%|█████████▎| 93/100 [01:26<00:06,  1.06it/s] 94%|█████████▍| 94/100 [01:27<00:05,  1.06it/s] 95%|█████████▌| 95/100 [01:28<00:04,  1.06it/s] 96%|█████████▌| 96/100 [01:29<00:03,  1.06it/s] 97%|█████████▋| 97/100 [01:30<00:02,  1.06it/s] 98%|█████████▊| 98/100 [01:31<00:01,  1.06it/s] 99%|█████████▉| 99/100 [01:32<00:00,  1.06it/s]100%|██████████| 100/100 [01:33<00:00,  1.06it/s]100%|██████████| 100/100 [01:33<00:00,  1.07it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:7'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:7'}
full model:
{'cola': {'alias': 'cola', 'mcc,none': np.float64(-0.0234083603222329), 'mcc_stderr,none': 0.10027612985654218}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9827615088085355
0.9302188892609604
0.7011961870018854
0.5626926521241726
0.8487059565524276
0.8497526414658526
0.9054485200458864
0.7394951536076
0.6615723249956142
0.3790091735780837
0.7669438266452424
0.6500882643740805
0.6039759750877352
0.8611545876684488
0.9595791152744535
0.7624866897939796
0.8585278638499474
0.9654871578633694
0.8537985077125277
0.9276026122967783
0.938072418626947
0.8815459403167786
0.6241194219560614
0.901256729143793
0.7007049393842223
0.6541093728101413
0.9141945519271818
0.7667764647672246
0.8091089193013563
Total groups 69 exceeded the threshold, stopping comparison.
The group tensor is
[3, 2, 6, 7, 5, 1, 4, 0]
tensor([3, 2, 6, 7, 5, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 3, 6, 7, 5, 1, 4, 0]
tensor([2, 3, 6, 7, 5, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 3, 5, 7, 6, 1, 2, 0]
tensor([4, 3, 5, 7, 6, 1, 2, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[2, 3, 0, 1, 2, 1, 3, 0]
tensor([2, 3, 0, 1, 2, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[1, 0, 1, 2, 3, 2, 3, 0]
tensor([1, 0, 1, 2, 3, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 2, 1, 2, 3, 1, 3, 0]
tensor([0, 2, 1, 2, 3, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[1, 0, 0, 1, 2, 3, 3, 2]
tensor([1, 0, 0, 1, 2, 3, 3, 2], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[3, 1, 0, 1, 2, 2, 3, 0]
tensor([3, 1, 0, 1, 2, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1.0, 1.0, 1, 1.0, 0]
tensor([0, 1, 1, 1, 1, 1, 1, 0], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
done!
Cross-layer merge completed for layers 2 to 5
done!
Normal merging for layer 6
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
tensor([3])
tensor(3)
done!
Cross-layer merge completed for layers 7 to 18
done!
Normal merging for layer 19
tensor([2, 7])
tensor(2)
tensor([3, 5])
tensor(3)
tensor([0, 4])
tensor(0)
tensor([1, 6])
tensor(1)
done!
Normal merging for layer 20
tensor([1, 7])
tensor(1)
tensor([0, 2])
tensor(0)
tensor([3, 5])
tensor(3)
tensor([4, 6])
tensor(4)
done!
Normal merging for layer 21
tensor([0, 7])
tensor(0)
tensor([2, 5])
tensor(2)
tensor([1, 3])
tensor(1)
tensor([4, 6])
tensor(4)
done!
Normal merging for layer 22
tensor([1, 2])
tensor(1)
tensor([0, 3])
tensor(0)
tensor([4, 7])
tensor(4)
tensor([5, 6])
tensor(5)
done!
Normal merging for layer 23
tensor([2, 7])
tensor(2)
tensor([1, 3])
tensor(1)
tensor([4, 5])
tensor(4)
tensor([0, 6])
tensor(0)
done!
Cross-layer merge completed for layers 24 to 27
done!
Normal merging for layer 28
tensor([0, 7])
tensor(0)
tensor([1, 2, 3, 4, 5, 6])
tensor(1)
done!
Cross-layer merge completed for layers 29 to 31
done!
all done!
Model size: 12.1348 GB
40
cuda:7
coqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:41<00:41, 41.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:53<00:00, 24.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:53<00:00, 26.99s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa HTTP/1.1" 200 846
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/EleutherAI/coqa/EleutherAI/coqa.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa HTTP/1.1" 200 857
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/coqa/resolve/82e11af842af6c1396f5e9a5c7de260107c50cf1/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa/tree/82e11af842af6c1396f5e9a5c7de260107c50cf1/data?recursive=False&expand=False HTTP/1.1" 404 79
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/EleutherAI/coqa/tree/82e11af842af6c1396f5e9a5c7de260107c50cf1/data?recursive=False&expand=False HTTP/1.1" 404 79
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/EleutherAI/coqa/resolve/82e11af842af6c1396f5e9a5c7de260107c50cf1/dataset_infos.json HTTP/1.1" 200 0
DEBUG:filelock:Attempting to acquire lock 140218795996464 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___coqa_default_0.0.0_82e11af842af6c1396f5e9a5c7de260107c50cf1.lock
DEBUG:filelock:Lock 140218795996464 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___coqa_default_0.0.0_82e11af842af6c1396f5e9a5c7de260107c50cf1.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1/dataset_info.json
DEBUG:filelock:Attempting to release lock 140218795996464 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___coqa_default_0.0.0_82e11af842af6c1396f5e9a5c7de260107c50cf1.lock
DEBUG:filelock:Lock 140218795996464 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_EleutherAI___coqa_default_0.0.0_82e11af842af6c1396f5e9a5c7de260107c50cf1.lock
DEBUG:filelock:Attempting to acquire lock 140240419063712 on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1_builder.lock
DEBUG:filelock:Lock 140240419063712 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1/dataset_info.json
DEBUG:filelock:Attempting to release lock 140240419063712 on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1_builder.lock
DEBUG:filelock:Lock 140240419063712 released on /public/home/zouyifei001/.cache/huggingface/datasets/EleutherAI___coqa/default/0.0.0/82e11af842af6c1396f5e9a5c7de260107c50cf1_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
DEBUG:lm_eval.api.task:doc_to_target returned a list. Assuming multiple targets.
INFO:lm_eval.evaluator:coqa: Using gen_kwargs: {'until': ['\nQ:']}
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of coqa from None to 0
INFO:lm_eval.api.task:Building contexts for coqa on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 75627.55it/s]
DEBUG:lm_eval.evaluator:Task: coqa; number of requests on this rank: 100
INFO:lm_eval.evaluator:Running generate_until requests
Running generate_until requests:   0%|          | 0/100 [00:00<?, ?it/s]Running generate_until requests:   1%|          | 1/100 [00:05<09:22,  5.68s/it]Running generate_until requests:   2%|▏         | 2/100 [00:10<08:35,  5.26s/it]Running generate_until requests:   3%|▎         | 3/100 [00:16<09:03,  5.60s/it]Running generate_until requests:   4%|▍         | 4/100 [00:21<08:29,  5.31s/it]Running generate_until requests:   5%|▌         | 5/100 [00:26<08:16,  5.22s/it]Running generate_until requests:   6%|▌         | 6/100 [00:31<07:52,  5.03s/it]Running generate_until requests:   7%|▋         | 7/100 [00:36<08:04,  5.21s/it]Running generate_until requests:   8%|▊         | 8/100 [00:41<07:43,  5.03s/it]Running generate_until requests:   9%|▉         | 9/100 [00:46<07:36,  5.01s/it]Running generate_until requests:  10%|█         | 10/100 [00:51<07:43,  5.15s/it]Running generate_until requests:  11%|█         | 11/100 [00:56<07:36,  5.13s/it]Running generate_until requests:  12%|█▏        | 12/100 [01:03<08:00,  5.46s/it]Running generate_until requests:  13%|█▎        | 13/100 [01:07<07:28,  5.15s/it]Running generate_until requests:  14%|█▍        | 14/100 [01:12<07:04,  4.93s/it]Running generate_until requests:  15%|█▌        | 15/100 [01:16<06:52,  4.85s/it]Running generate_until requests:  16%|█▌        | 16/100 [01:21<06:37,  4.73s/it]Running generate_until requests:  17%|█▋        | 17/100 [01:25<06:26,  4.65s/it]Running generate_until requests:  18%|█▊        | 18/100 [01:29<06:10,  4.52s/it]Running generate_until requests:  19%|█▉        | 19/100 [01:34<06:04,  4.50s/it]Running generate_until requests:  20%|██        | 20/100 [01:38<05:55,  4.44s/it]Running generate_until requests:  21%|██        | 21/100 [01:43<05:50,  4.43s/it]Running generate_until requests:  22%|██▏       | 22/100 [01:47<05:42,  4.39s/it]Running generate_until requests:  23%|██▎       | 23/100 [01:52<05:59,  4.67s/it]Running generate_until requests:  24%|██▍       | 24/100 [01:57<06:06,  4.82s/it]Running generate_until requests:  25%|██▌       | 25/100 [02:02<05:48,  4.65s/it]Running generate_until requests:  26%|██▌       | 26/100 [02:06<05:43,  4.65s/it]Running generate_until requests:  27%|██▋       | 27/100 [02:11<05:44,  4.72s/it]Running generate_until requests:  28%|██▊       | 28/100 [02:16<05:41,  4.74s/it]Running generate_until requests:  29%|██▉       | 29/100 [02:20<05:29,  4.64s/it]Running generate_until requests:  30%|███       | 30/100 [02:25<05:22,  4.61s/it]Running generate_until requests:  31%|███       | 31/100 [02:29<05:04,  4.42s/it]Running generate_until requests:  32%|███▏      | 32/100 [02:33<05:04,  4.48s/it]Running generate_until requests:  33%|███▎      | 33/100 [02:38<04:59,  4.48s/it]Running generate_until requests:  34%|███▍      | 34/100 [02:42<04:52,  4.43s/it]Running generate_until requests:  35%|███▌      | 35/100 [02:46<04:38,  4.29s/it]Running generate_until requests:  36%|███▌      | 36/100 [02:52<04:57,  4.64s/it]Running generate_until requests:  37%|███▋      | 37/100 [02:56<04:38,  4.42s/it]Running generate_until requests:  38%|███▊      | 38/100 [02:59<04:24,  4.26s/it]Running generate_until requests:  39%|███▉      | 39/100 [03:04<04:17,  4.22s/it]Running generate_until requests:  40%|████      | 40/100 [03:07<04:06,  4.11s/it]Running generate_until requests:  41%|████      | 41/100 [03:12<04:02,  4.11s/it]Running generate_until requests:  42%|████▏     | 42/100 [03:17<04:18,  4.45s/it]Running generate_until requests:  43%|████▎     | 43/100 [03:21<04:06,  4.33s/it]Running generate_until requests:  44%|████▍     | 44/100 [03:25<04:02,  4.33s/it]Running generate_until requests:  45%|████▌     | 45/100 [03:29<03:55,  4.29s/it]Running generate_until requests:  46%|████▌     | 46/100 [03:33<03:43,  4.14s/it]Running generate_until requests:  47%|████▋     | 47/100 [03:37<03:33,  4.03s/it]Running generate_until requests:  48%|████▊     | 48/100 [03:41<03:34,  4.13s/it]Running generate_until requests:  49%|████▉     | 49/100 [03:46<03:41,  4.34s/it]Running generate_until requests:  50%|█████     | 50/100 [03:50<03:28,  4.16s/it]Running generate_until requests:  51%|█████     | 51/100 [03:55<03:32,  4.34s/it]Running generate_until requests:  52%|█████▏    | 52/100 [03:58<03:19,  4.15s/it]Running generate_until requests:  53%|█████▎    | 53/100 [04:03<03:17,  4.21s/it]Running generate_until requests:  54%|█████▍    | 54/100 [04:06<03:06,  4.05s/it]Running generate_until requests:  55%|█████▌    | 55/100 [04:10<03:02,  4.06s/it]Running generate_until requests:  56%|█████▌    | 56/100 [04:15<03:03,  4.18s/it]Running generate_until requests:  57%|█████▋    | 57/100 [04:19<02:59,  4.18s/it]Running generate_until requests:  58%|█████▊    | 58/100 [04:23<02:49,  4.03s/it]Running generate_until requests:  59%|█████▉    | 59/100 [04:28<02:56,  4.30s/it]Running generate_until requests:  60%|██████    | 60/100 [04:31<02:44,  4.10s/it]Running generate_until requests:  61%|██████    | 61/100 [04:36<02:45,  4.25s/it]Running generate_until requests:  62%|██████▏   | 62/100 [04:41<02:45,  4.36s/it]Running generate_until requests:  63%|██████▎   | 63/100 [04:44<02:32,  4.13s/it]Running generate_until requests:  64%|██████▍   | 64/100 [04:48<02:22,  3.96s/it]Running generate_until requests:  65%|██████▌   | 65/100 [04:51<02:14,  3.83s/it]Running generate_until requests:  66%|██████▌   | 66/100 [04:55<02:07,  3.74s/it]Running generate_until requests:  67%|██████▋   | 67/100 [04:58<02:01,  3.67s/it]Running generate_until requests:  68%|██████▊   | 68/100 [05:02<02:01,  3.80s/it]Running generate_until requests:  69%|██████▉   | 69/100 [05:08<02:14,  4.34s/it]Running generate_until requests:  70%|███████   | 70/100 [05:12<02:08,  4.28s/it]Running generate_until requests:  71%|███████   | 71/100 [05:20<02:39,  5.49s/it]Running generate_until requests:  72%|███████▏  | 72/100 [05:24<02:16,  4.88s/it]Running generate_until requests:  73%|███████▎  | 73/100 [05:27<02:01,  4.49s/it]Running generate_until requests:  74%|███████▍  | 74/100 [05:31<01:52,  4.32s/it]Running generate_until requests:  75%|███████▌  | 75/100 [05:35<01:41,  4.08s/it]Running generate_until requests:  76%|███████▌  | 76/100 [05:38<01:33,  3.90s/it]Running generate_until requests:  77%|███████▋  | 77/100 [05:43<01:33,  4.05s/it]Running generate_until requests:  78%|███████▊  | 78/100 [05:46<01:26,  3.92s/it]Running generate_until requests:  79%|███████▉  | 79/100 [05:50<01:18,  3.73s/it]Running generate_until requests:  80%|████████  | 80/100 [05:53<01:15,  3.75s/it]Running generate_until requests:  81%|████████  | 81/100 [05:59<01:22,  4.32s/it]Running generate_until requests:  82%|████████▏ | 82/100 [06:02<01:12,  4.01s/it]Running generate_until requests:  83%|████████▎ | 83/100 [06:06<01:06,  3.90s/it]Running generate_until requests:  84%|████████▍ | 84/100 [06:09<00:59,  3.69s/it]Running generate_until requests:  85%|████████▌ | 85/100 [06:12<00:53,  3.54s/it]Running generate_until requests:  86%|████████▌ | 86/100 [06:16<00:48,  3.50s/it]Running generate_until requests:  87%|████████▋ | 87/100 [06:20<00:48,  3.75s/it]Running generate_until requests:  88%|████████▊ | 88/100 [06:24<00:44,  3.67s/it]Running generate_until requests:  89%|████████▉ | 89/100 [06:27<00:38,  3.46s/it]Running generate_until requests:  90%|█████████ | 90/100 [06:30<00:32,  3.28s/it]Running generate_until requests:  91%|█████████ | 91/100 [06:32<00:28,  3.12s/it]Running generate_until requests:  92%|█████████▏| 92/100 [06:35<00:24,  3.03s/it]Running generate_until requests:  93%|█████████▎| 93/100 [06:38<00:20,  2.99s/it]Running generate_until requests:  94%|█████████▍| 94/100 [06:41<00:17,  3.00s/it]Running generate_until requests:  95%|█████████▌| 95/100 [06:44<00:15,  3.07s/it]Running generate_until requests:  96%|█████████▌| 96/100 [06:47<00:12,  3.08s/it]Running generate_until requests:  97%|█████████▋| 97/100 [06:50<00:08,  2.91s/it]Running generate_until requests:  98%|█████████▊| 98/100 [06:52<00:05,  2.79s/it]Running generate_until requests:  99%|█████████▉| 99/100 [06:55<00:02,  2.78s/it]Running generate_until requests: 100%|██████████| 100/100 [06:58<00:00,  2.78s/it]Running generate_until requests: 100%|██████████| 100/100 [06:58<00:00,  4.18s/it]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:0'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}
full model:
{'coqa': {'alias': 'coqa', 'em,none': 0.595, 'em_stderr,none': 0.044774970461162564, 'f1,none': 0.7211574141733987, 'f1_stderr,none': 0.037128235455690536}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.6057853926542468
0.4195568875297668
0.5244744113321889
0.5202703028806769
0.6150870974034927
0.5299634576457063
0.9336763524510373
0.23649940737178063
0.388911200696845
0.6478041116722705
0.5517233675449297
0.6723258763091353
0.7175526480521238
0.8411089149883405
0.7404554224148189
0.26376935916880817
0.9373006475493478
0.5360566853939598
0.38729358133282565
0.4541602442018795
0.8623573205888978
0.7318340566806717
0.6643209906079897
0.8122565195147101
0.4707270481319977
0.9785001455445378
0.17075087907531752
0.489625917805058
0.7595051272431785
0.6057853926542468
0.4195568875297668
0.5244744113321889
0.5202703028806769
0.6150870974034927
0.5299634576457063
0.9336763524510373
0.23649940737178063
0.388911200696845
0.6478041116722705
0.5517233675449297
0.6723258763091353
0.7175526480521238
0.8411089149883405
0.7404554224148189
0.26376935916880817
0.9373006475493478
0.5360566853939598
0.38729358133282565
0.4541602442018795
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[5, 4, 3, 2, 0, 1, 7, 6]
tensor([5, 4, 3, 2, 0, 1, 7, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 3, 4, 0, 2, 1, 7, 6]
tensor([5, 3, 4, 0, 2, 1, 7, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 1, 7, 0, 6, 2, 3, 4]
tensor([5, 1, 7, 0, 6, 2, 3, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 3, 6, 0, 5, 2, 4, 1]
tensor([7, 3, 6, 0, 5, 2, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 5, 7, 2, 4, 0, 3, 1]
tensor([6, 5, 7, 2, 4, 0, 3, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 5, 0, 0, 1, 2, 1, 3]
tensor([4, 5, 0, 0, 1, 2, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1, 2, 2, 0, 3, 3]
tensor([0, 1, 1, 2, 2, 0, 3, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([7])
tensor(7)
tensor([6])
tensor(6)
done!
Normal merging for layer 2
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
done!
Normal merging for layer 4
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Cross-layer merge completed for layers 5 to 8
done!
Normal merging for layer 9
tensor([2, 3])
tensor(2)
tensor([4, 6])
tensor(4)
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([1])
tensor(1)
done!
Cross-layer merge completed for layers 10 to 22
done!
Normal merging for layer 23
tensor([0, 5])
tensor(0)
tensor([1, 2])
tensor(1)
tensor([3, 4])
tensor(3)
tensor([6, 7])
tensor(6)
done!
Cross-layer merge completed for layers 24 to 31
done!
all done!
Model size: 12.3238 GB
180
cuda:0
rte
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:42<00:42, 42.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 24.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 27.38s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: rte] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: rte] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 235
DEBUG:filelock:Attempting to acquire lock 140239877532480 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140239877532480 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140239877532480 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140239877532480 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_rte_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140233170200976 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140233170200976 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140233170200976 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140233170200976 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/rte/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of rte from None to 0
INFO:lm_eval.api.task:Building contexts for rte on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 2545.83it/s]
DEBUG:lm_eval.evaluator:Task: rte; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:01<06:36,  1.99s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:03<03:29,  1.07s/it]Running loglikelihood requests:   2%|▎         | 5/200 [00:04<02:47,  1.16it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:06<02:27,  1.31it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:07<02:16,  1.40it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:08<02:08,  1.47it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:09<02:03,  1.51it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:11<01:59,  1.55it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:12<01:55,  1.58it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:13<01:52,  1.61it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:14<01:48,  1.65it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:15<01:45,  1.67it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:16<01:42,  1.70it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:17<01:39,  1.74it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:19<01:36,  1.77it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:20<01:34,  1.79it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:21<01:32,  1.81it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:22<01:30,  1.83it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:23<01:28,  1.84it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:24<01:26,  1.86it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:25<01:23,  1.90it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:26<01:21,  1.93it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:27<01:18,  1.98it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:28<01:16,  2.01it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:29<01:13,  2.06it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:30<01:10,  2.11it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:30<01:07,  2.17it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:31<01:05,  2.23it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:32<01:02,  2.28it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:33<01:00,  2.33it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:34<00:58,  2.37it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:35<00:57,  2.40it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:35<00:55,  2.42it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:36<00:54,  2.44it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:37<00:53,  2.47it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:38<00:51,  2.48it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:39<00:50,  2.50it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:39<00:49,  2.53it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:40<00:48,  2.55it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:41<00:47,  2.57it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:42<00:45,  2.59it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:42<00:44,  2.62it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:43<00:43,  2.64it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:44<00:42,  2.66it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:45<00:41,  2.68it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:45<00:40,  2.70it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:46<00:39,  2.72it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:47<00:38,  2.73it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:47<00:37,  2.75it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:48<00:36,  2.76it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:49<00:35,  2.78it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:50<00:34,  2.79it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:50<00:33,  2.81it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:51<00:32,  2.83it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:52<00:32,  2.84it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:52<00:31,  2.85it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:53<00:30,  2.86it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:54<00:29,  2.87it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:54<00:28,  2.88it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:55<00:28,  2.89it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:56<00:27,  2.90it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:57<00:26,  2.91it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:57<00:25,  2.91it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [00:58<00:25,  2.91it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [00:59<00:24,  2.92it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [00:59<00:23,  2.93it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [01:00<00:22,  2.95it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [01:01<00:21,  2.98it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [01:01<00:21,  2.99it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [01:02<00:20,  3.01it/s]Running loglikelihood requests:  70%|███████   | 141/200 [01:03<00:19,  3.02it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [01:03<00:18,  3.04it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [01:04<00:17,  3.06it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [01:05<00:17,  3.07it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [01:05<00:16,  3.08it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [01:06<00:15,  3.09it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [01:06<00:15,  3.10it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [01:07<00:14,  3.11it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [01:08<00:13,  3.13it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [01:08<00:13,  3.15it/s]Running loglikelihood requests:  80%|████████  | 161/200 [01:09<00:12,  3.17it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [01:10<00:11,  3.19it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [01:10<00:10,  3.19it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [01:11<00:10,  3.22it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [01:11<00:09,  3.23it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [01:12<00:08,  3.26it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [01:13<00:08,  3.28it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [01:13<00:07,  3.29it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [01:14<00:06,  3.31it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [01:14<00:06,  3.32it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [01:15<00:05,  3.33it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [01:16<00:05,  3.35it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [01:16<00:04,  3.35it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [01:17<00:03,  3.37it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [01:17<00:03,  3.38it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [01:18<00:02,  3.39it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [01:19<00:02,  3.41it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:19<00:01,  3.43it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:20<00:00,  3.51it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:20<00:00,  3.58it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:20<00:00,  2.48it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:1'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:1'}
full model:
{'rte': {'alias': 'rte', 'acc,none': 0.5, 'acc_stderr,none': 0.050251890762960605}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.34161229456626735
0.905233410256777
0.5205040718697735
0.4121994254524892
0.7398116665887099
0.6225415196831932
0.7923970242263771
0.7353888240887675
0.6535613357308766
0.7757058271862038
0.734046359122903
0.4471799126982846
0.773619360921301
0.7955347039939479
0.8672068064531693
0.8652880343596522
0.3302235467760883
0.6789268064017625
0.6072221471952108
0.9194446824778495
0.4812004589187253
0.5728915095234594
0.1682455054057436
0.93212414632396
0.9148362604533635
0.8268537756297094
0.7592245907029287
0.7256008379011685
0.7109756105942956
0.34161229456626735
0.905233410256777
0.5205040718697735
0.4121994254524892
0.7398116665887099
0.6225415196831932
0.7923970242263771
0.7353888240887675
0.6535613357308766
0.7757058271862038
0.734046359122903
0.4471799126982846
0.773619360921301
0.7955347039939479
0.8672068064531693
0.8652880343596522
0.3302235467760883
0.6789268064017625
0.6072221471952108
0.9194446824778495
0.4812004589187253
Total groups 73 exceeded the threshold, stopping comparison.
The group tensor is
[5, 2, 7, 1, 6, 4, 3, 0]
tensor([5, 2, 7, 1, 6, 4, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 6, 0, 7, 3, 4, 1]
tensor([5, 2, 6, 0, 7, 3, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 7, 2, 5, 4, 3, 0]
tensor([6, 1, 7, 2, 5, 4, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 7, 2, 4, 1, 5, 0]
tensor([6, 3, 7, 2, 4, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 5, 6, 2, 3, 1, 4, 0]
tensor([7, 5, 6, 2, 3, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 2, 5, 4, 1, 0, 1, 3]
tensor([0, 2, 5, 4, 1, 0, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1.0, 1.0, 0, 1.0, 1]
tensor([0, 1, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
Normal merging for layer 1
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
done!
Normal merging for layer 2
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 4
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 5 to 8
done!
Normal merging for layer 9
tensor([0, 5])
tensor(0)
tensor([4, 6])
tensor(4)
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
done!
Cross-layer merge completed for layers 10 to 30
done!
Normal merging for layer 31
tensor([0, 5])
tensor(0)
tensor([1, 2, 3, 4, 6, 7])
tensor(1)
done!
all done!
Model size: 12.1348 GB
211
cuda:1
mnli
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:40<00:40, 40.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:52<00:00, 23.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:52<00:00, 26.33s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: mnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: mnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/mnli?recursive=False&expand=False HTTP/1.1" 307 141
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/mnli?recursive=False&expand=False HTTP/1.1" 200 512
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140242299328976 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_mnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140242299328976 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_mnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/mnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140242299328976 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_mnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140242299328976 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_mnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140239877337456 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/mnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140239877337456 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/mnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/mnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140239877337456 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/mnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140239877337456 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/mnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mnli from None to 0
INFO:lm_eval.api.task:Building contexts for mnli on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 129095.23it/s]
DEBUG:lm_eval.evaluator:Task: mnli; number of requests on this rank: 300
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/300 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/300 [00:01<08:37,  1.73s/it]Running loglikelihood requests:   1%|          | 2/300 [00:03<07:15,  1.46s/it]Running loglikelihood requests:   1%|▏         | 4/300 [00:03<04:12,  1.17it/s]Running loglikelihood requests:   2%|▏         | 5/300 [00:04<04:23,  1.12it/s]Running loglikelihood requests:   2%|▏         | 7/300 [00:05<03:21,  1.45it/s]Running loglikelihood requests:   3%|▎         | 8/300 [00:06<03:36,  1.35it/s]Running loglikelihood requests:   3%|▎         | 10/300 [00:07<02:59,  1.62it/s]Running loglikelihood requests:   4%|▎         | 11/300 [00:08<03:13,  1.49it/s]Running loglikelihood requests:   4%|▍         | 13/300 [00:09<02:42,  1.77it/s]Running loglikelihood requests:   5%|▍         | 14/300 [00:10<02:57,  1.61it/s]Running loglikelihood requests:   5%|▌         | 16/300 [00:10<02:30,  1.89it/s]Running loglikelihood requests:   6%|▌         | 17/300 [00:11<02:44,  1.72it/s]Running loglikelihood requests:   6%|▌         | 18/300 [00:12<02:55,  1.60it/s]Running loglikelihood requests:   7%|▋         | 20/300 [00:13<02:27,  1.90it/s]Running loglikelihood requests:   7%|▋         | 21/300 [00:13<02:42,  1.72it/s]Running loglikelihood requests:   8%|▊         | 23/300 [00:14<02:18,  2.00it/s]Running loglikelihood requests:   8%|▊         | 25/300 [00:15<02:04,  2.20it/s]Running loglikelihood requests:   9%|▊         | 26/300 [00:16<02:21,  1.94it/s]Running loglikelihood requests:   9%|▉         | 28/300 [00:16<02:05,  2.17it/s]Running loglikelihood requests:  10%|▉         | 29/300 [00:17<02:19,  1.94it/s]Running loglikelihood requests:  10%|█         | 30/300 [00:18<02:32,  1.77it/s]Running loglikelihood requests:  10%|█         | 31/300 [00:19<02:42,  1.66it/s]Running loglikelihood requests:  11%|█         | 32/300 [00:19<02:50,  1.57it/s]Running loglikelihood requests:  11%|█▏        | 34/300 [00:20<02:17,  1.93it/s]Running loglikelihood requests:  12%|█▏        | 36/300 [00:21<02:01,  2.18it/s]Running loglikelihood requests:  13%|█▎        | 38/300 [00:22<01:51,  2.36it/s]Running loglikelihood requests:  13%|█▎        | 40/300 [00:22<01:44,  2.50it/s]Running loglikelihood requests:  14%|█▎        | 41/300 [00:23<01:58,  2.18it/s]Running loglikelihood requests:  14%|█▍        | 42/300 [00:24<02:11,  1.95it/s]Running loglikelihood requests:  14%|█▍        | 43/300 [00:24<02:22,  1.80it/s]Running loglikelihood requests:  15%|█▌        | 45/300 [00:25<02:00,  2.12it/s]Running loglikelihood requests:  16%|█▌        | 47/300 [00:26<01:48,  2.34it/s]Running loglikelihood requests:  16%|█▌        | 48/300 [00:26<02:03,  2.05it/s]Running loglikelihood requests:  17%|█▋        | 50/300 [00:27<01:48,  2.30it/s]Running loglikelihood requests:  17%|█▋        | 52/300 [00:28<01:39,  2.49it/s]Running loglikelihood requests:  18%|█▊        | 53/300 [00:29<01:53,  2.18it/s]Running loglikelihood requests:  18%|█▊        | 54/300 [00:29<02:04,  1.98it/s]Running loglikelihood requests:  18%|█▊        | 55/300 [00:30<02:13,  1.83it/s]Running loglikelihood requests:  19%|█▉        | 57/300 [00:31<01:52,  2.16it/s]Running loglikelihood requests:  20%|█▉        | 59/300 [00:31<01:40,  2.40it/s]Running loglikelihood requests:  20%|██        | 61/300 [00:32<01:33,  2.54it/s]Running loglikelihood requests:  21%|██        | 62/300 [00:33<01:46,  2.23it/s]Running loglikelihood requests:  21%|██▏       | 64/300 [00:33<01:36,  2.44it/s]Running loglikelihood requests:  22%|██▏       | 65/300 [00:34<01:48,  2.16it/s]Running loglikelihood requests:  22%|██▏       | 66/300 [00:35<01:59,  1.96it/s]Running loglikelihood requests:  22%|██▏       | 67/300 [00:35<02:08,  1.82it/s]Running loglikelihood requests:  23%|██▎       | 69/300 [00:36<01:46,  2.17it/s]Running loglikelihood requests:  24%|██▎       | 71/300 [00:37<01:34,  2.41it/s]Running loglikelihood requests:  24%|██▍       | 72/300 [00:37<01:46,  2.14it/s]Running loglikelihood requests:  24%|██▍       | 73/300 [00:38<01:56,  1.95it/s]Running loglikelihood requests:  25%|██▌       | 75/300 [00:39<01:39,  2.27it/s]Running loglikelihood requests:  26%|██▌       | 77/300 [00:39<01:29,  2.49it/s]Running loglikelihood requests:  26%|██▋       | 79/300 [00:40<01:23,  2.65it/s]Running loglikelihood requests:  27%|██▋       | 80/300 [00:41<01:35,  2.31it/s]Running loglikelihood requests:  27%|██▋       | 81/300 [00:41<01:45,  2.08it/s]Running loglikelihood requests:  27%|██▋       | 82/300 [00:42<01:54,  1.91it/s]Running loglikelihood requests:  28%|██▊       | 83/300 [00:43<02:01,  1.79it/s]Running loglikelihood requests:  28%|██▊       | 85/300 [00:43<01:38,  2.17it/s]Running loglikelihood requests:  29%|██▊       | 86/300 [00:44<01:48,  1.98it/s]Running loglikelihood requests:  29%|██▉       | 88/300 [00:45<01:31,  2.31it/s]Running loglikelihood requests:  30%|██▉       | 89/300 [00:45<01:41,  2.07it/s]Running loglikelihood requests:  30%|███       | 91/300 [00:46<01:28,  2.37it/s]Running loglikelihood requests:  31%|███       | 93/300 [00:46<01:20,  2.58it/s]Running loglikelihood requests:  32%|███▏      | 95/300 [00:47<01:15,  2.73it/s]Running loglikelihood requests:  32%|███▏      | 96/300 [00:48<01:25,  2.38it/s]Running loglikelihood requests:  33%|███▎      | 98/300 [00:48<01:17,  2.59it/s]Running loglikelihood requests:  33%|███▎      | 99/300 [00:49<01:28,  2.28it/s]Running loglikelihood requests:  34%|███▎      | 101/300 [00:50<01:18,  2.53it/s]Running loglikelihood requests:  34%|███▍      | 102/300 [00:50<01:28,  2.23it/s]Running loglikelihood requests:  34%|███▍      | 103/300 [00:51<01:37,  2.03it/s]Running loglikelihood requests:  35%|███▍      | 104/300 [00:52<01:43,  1.89it/s]Running loglikelihood requests:  35%|███▌      | 105/300 [00:52<01:48,  1.79it/s]Running loglikelihood requests:  36%|███▌      | 107/300 [00:53<01:28,  2.19it/s]Running loglikelihood requests:  36%|███▌      | 108/300 [00:54<01:35,  2.00it/s]Running loglikelihood requests:  36%|███▋      | 109/300 [00:54<01:42,  1.85it/s]Running loglikelihood requests:  37%|███▋      | 111/300 [00:55<01:24,  2.24it/s]Running loglikelihood requests:  38%|███▊      | 113/300 [00:56<01:14,  2.50it/s]Running loglikelihood requests:  38%|███▊      | 115/300 [00:56<01:09,  2.67it/s]Running loglikelihood requests:  39%|███▉      | 117/300 [00:57<01:05,  2.80it/s]Running loglikelihood requests:  40%|███▉      | 119/300 [00:57<01:02,  2.90it/s]Running loglikelihood requests:  40%|████      | 121/300 [00:58<01:00,  2.96it/s]Running loglikelihood requests:  41%|████      | 122/300 [00:59<01:09,  2.55it/s]Running loglikelihood requests:  41%|████▏     | 124/300 [00:59<01:04,  2.73it/s]Running loglikelihood requests:  42%|████▏     | 125/300 [01:00<01:13,  2.39it/s]Running loglikelihood requests:  42%|████▏     | 126/300 [01:01<01:21,  2.15it/s]Running loglikelihood requests:  42%|████▏     | 127/300 [01:01<01:27,  1.98it/s]Running loglikelihood requests:  43%|████▎     | 129/300 [01:02<01:13,  2.34it/s]Running loglikelihood requests:  44%|████▎     | 131/300 [01:02<01:05,  2.60it/s]Running loglikelihood requests:  44%|████▍     | 133/300 [01:03<00:59,  2.80it/s]Running loglikelihood requests:  45%|████▍     | 134/300 [01:04<01:07,  2.46it/s]Running loglikelihood requests:  45%|████▌     | 135/300 [01:04<01:14,  2.22it/s]Running loglikelihood requests:  45%|████▌     | 136/300 [01:05<01:19,  2.05it/s]Running loglikelihood requests:  46%|████▌     | 137/300 [01:06<01:24,  1.93it/s]Running loglikelihood requests:  46%|████▌     | 138/300 [01:06<01:27,  1.85it/s]Running loglikelihood requests:  47%|████▋     | 140/300 [01:07<01:10,  2.28it/s]Running loglikelihood requests:  47%|████▋     | 142/300 [01:07<01:00,  2.59it/s]Running loglikelihood requests:  48%|████▊     | 143/300 [01:08<01:07,  2.32it/s]Running loglikelihood requests:  48%|████▊     | 145/300 [01:09<00:59,  2.62it/s]Running loglikelihood requests:  49%|████▊     | 146/300 [01:09<01:05,  2.33it/s]Running loglikelihood requests:  49%|████▉     | 147/300 [01:10<01:11,  2.13it/s]Running loglikelihood requests:  49%|████▉     | 148/300 [01:10<01:16,  1.99it/s]Running loglikelihood requests:  50%|█████     | 150/300 [01:11<01:02,  2.39it/s]Running loglikelihood requests:  51%|█████     | 152/300 [01:12<00:55,  2.68it/s]Running loglikelihood requests:  51%|█████▏    | 154/300 [01:12<00:50,  2.88it/s]Running loglikelihood requests:  52%|█████▏    | 155/300 [01:13<00:57,  2.52it/s]Running loglikelihood requests:  52%|█████▏    | 157/300 [01:13<00:51,  2.77it/s]Running loglikelihood requests:  53%|█████▎    | 159/300 [01:14<00:47,  2.95it/s]Running loglikelihood requests:  54%|█████▎    | 161/300 [01:15<00:45,  3.08it/s]Running loglikelihood requests:  54%|█████▍    | 162/300 [01:15<00:51,  2.66it/s]Running loglikelihood requests:  55%|█████▍    | 164/300 [01:16<00:47,  2.88it/s]Running loglikelihood requests:  55%|█████▌    | 165/300 [01:16<00:53,  2.53it/s]Running loglikelihood requests:  56%|█████▌    | 167/300 [01:17<00:47,  2.79it/s]Running loglikelihood requests:  56%|█████▋    | 169/300 [01:17<00:44,  2.98it/s]Running loglikelihood requests:  57%|█████▋    | 170/300 [01:18<00:50,  2.60it/s]Running loglikelihood requests:  57%|█████▋    | 171/300 [01:19<00:55,  2.34it/s]Running loglikelihood requests:  57%|█████▋    | 172/300 [01:19<00:59,  2.15it/s]Running loglikelihood requests:  58%|█████▊    | 173/300 [01:20<01:02,  2.02it/s]Running loglikelihood requests:  58%|█████▊    | 175/300 [01:20<00:51,  2.45it/s]Running loglikelihood requests:  59%|█████▉    | 177/300 [01:21<00:44,  2.75it/s]Running loglikelihood requests:  60%|█████▉    | 179/300 [01:22<00:40,  2.96it/s]Running loglikelihood requests:  60%|██████    | 180/300 [01:22<00:46,  2.59it/s]Running loglikelihood requests:  60%|██████    | 181/300 [01:23<00:51,  2.31it/s]Running loglikelihood requests:  61%|██████    | 183/300 [01:23<00:43,  2.68it/s]Running loglikelihood requests:  62%|██████▏   | 185/300 [01:24<00:39,  2.92it/s]Running loglikelihood requests:  62%|██████▏   | 186/300 [01:24<00:44,  2.57it/s]Running loglikelihood requests:  63%|██████▎   | 188/300 [01:25<00:39,  2.86it/s]Running loglikelihood requests:  63%|██████▎   | 190/300 [01:26<00:35,  3.06it/s]Running loglikelihood requests:  64%|██████▎   | 191/300 [01:26<00:40,  2.68it/s]Running loglikelihood requests:  64%|██████▍   | 192/300 [01:27<00:44,  2.41it/s]Running loglikelihood requests:  65%|██████▍   | 194/300 [01:27<00:38,  2.76it/s]Running loglikelihood requests:  65%|██████▌   | 195/300 [01:28<00:42,  2.47it/s]Running loglikelihood requests:  65%|██████▌   | 196/300 [01:28<00:45,  2.26it/s]Running loglikelihood requests:  66%|██████▌   | 198/300 [01:29<00:38,  2.66it/s]Running loglikelihood requests:  66%|██████▋   | 199/300 [01:29<00:42,  2.40it/s]Running loglikelihood requests:  67%|██████▋   | 200/300 [01:30<00:44,  2.22it/s]Running loglikelihood requests:  67%|██████▋   | 201/300 [01:31<00:47,  2.10it/s]Running loglikelihood requests:  68%|██████▊   | 203/300 [01:31<00:38,  2.55it/s]Running loglikelihood requests:  68%|██████▊   | 205/300 [01:32<00:33,  2.87it/s]Running loglikelihood requests:  69%|██████▊   | 206/300 [01:32<00:36,  2.56it/s]Running loglikelihood requests:  69%|██████▉   | 208/300 [01:33<00:31,  2.88it/s]Running loglikelihood requests:  70%|███████   | 210/300 [01:33<00:29,  3.10it/s]Running loglikelihood requests:  71%|███████   | 212/300 [01:34<00:26,  3.26it/s]Running loglikelihood requests:  71%|███████   | 213/300 [01:34<00:30,  2.84it/s]Running loglikelihood requests:  72%|███████▏  | 215/300 [01:35<00:27,  3.08it/s]Running loglikelihood requests:  72%|███████▏  | 216/300 [01:36<00:31,  2.71it/s]Running loglikelihood requests:  72%|███████▏  | 217/300 [01:36<00:33,  2.45it/s]Running loglikelihood requests:  73%|███████▎  | 219/300 [01:37<00:28,  2.82it/s]Running loglikelihood requests:  74%|███████▎  | 221/300 [01:37<00:25,  3.08it/s]Running loglikelihood requests:  74%|███████▍  | 222/300 [01:38<00:28,  2.71it/s]Running loglikelihood requests:  75%|███████▍  | 224/300 [01:38<00:25,  3.01it/s]Running loglikelihood requests:  75%|███████▌  | 225/300 [01:39<00:28,  2.67it/s]Running loglikelihood requests:  76%|███████▌  | 227/300 [01:39<00:24,  2.99it/s]Running loglikelihood requests:  76%|███████▌  | 228/300 [01:40<00:27,  2.65it/s]Running loglikelihood requests:  76%|███████▋  | 229/300 [01:40<00:29,  2.42it/s]Running loglikelihood requests:  77%|███████▋  | 231/300 [01:41<00:24,  2.82it/s]Running loglikelihood requests:  77%|███████▋  | 232/300 [01:41<00:26,  2.54it/s]Running loglikelihood requests:  78%|███████▊  | 233/300 [01:42<00:28,  2.34it/s]Running loglikelihood requests:  78%|███████▊  | 234/300 [01:42<00:29,  2.21it/s]Running loglikelihood requests:  78%|███████▊  | 235/300 [01:43<00:30,  2.11it/s]Running loglikelihood requests:  79%|███████▊  | 236/300 [01:44<00:31,  2.04it/s]Running loglikelihood requests:  79%|███████▉  | 237/300 [01:44<00:31,  2.00it/s]Running loglikelihood requests:  79%|███████▉  | 238/300 [01:45<00:31,  1.96it/s]Running loglikelihood requests:  80%|████████  | 240/300 [01:45<00:23,  2.51it/s]Running loglikelihood requests:  81%|████████  | 242/300 [01:46<00:20,  2.89it/s]Running loglikelihood requests:  81%|████████▏ | 244/300 [01:46<00:17,  3.16it/s]Running loglikelihood requests:  82%|████████▏ | 246/300 [01:47<00:16,  3.35it/s]Running loglikelihood requests:  83%|████████▎ | 248/300 [01:47<00:14,  3.49it/s]Running loglikelihood requests:  83%|████████▎ | 250/300 [01:48<00:13,  3.58it/s]Running loglikelihood requests:  84%|████████▍ | 252/300 [01:48<00:13,  3.64it/s]Running loglikelihood requests:  85%|████████▍ | 254/300 [01:49<00:12,  3.69it/s]Running loglikelihood requests:  85%|████████▌ | 256/300 [01:49<00:11,  3.73it/s]Running loglikelihood requests:  86%|████████▌ | 257/300 [01:50<00:13,  3.20it/s]Running loglikelihood requests:  86%|████████▌ | 258/300 [01:50<00:14,  2.82it/s]Running loglikelihood requests:  87%|████████▋ | 260/300 [01:51<00:12,  3.14it/s]Running loglikelihood requests:  87%|████████▋ | 261/300 [01:51<00:13,  2.79it/s]Running loglikelihood requests:  88%|████████▊ | 263/300 [01:52<00:11,  3.12it/s]Running loglikelihood requests:  88%|████████▊ | 264/300 [01:52<00:12,  2.78it/s]Running loglikelihood requests:  88%|████████▊ | 265/300 [01:53<00:13,  2.54it/s]Running loglikelihood requests:  89%|████████▊ | 266/300 [01:53<00:14,  2.37it/s]Running loglikelihood requests:  89%|████████▉ | 268/300 [01:54<00:11,  2.84it/s]Running loglikelihood requests:  90%|█████████ | 270/300 [01:54<00:09,  3.17it/s]Running loglikelihood requests:  91%|█████████ | 272/300 [01:55<00:08,  3.41it/s]Running loglikelihood requests:  91%|█████████▏| 274/300 [01:55<00:07,  3.59it/s]Running loglikelihood requests:  92%|█████████▏| 275/300 [01:56<00:07,  3.13it/s]Running loglikelihood requests:  92%|█████████▏| 277/300 [01:56<00:06,  3.40it/s]Running loglikelihood requests:  93%|█████████▎| 278/300 [01:57<00:07,  2.99it/s]Running loglikelihood requests:  93%|█████████▎| 279/300 [01:57<00:07,  2.71it/s]Running loglikelihood requests:  94%|█████████▎| 281/300 [01:58<00:06,  3.12it/s]Running loglikelihood requests:  94%|█████████▍| 282/300 [01:58<00:06,  2.80it/s]Running loglikelihood requests:  94%|█████████▍| 283/300 [01:59<00:06,  2.58it/s]Running loglikelihood requests:  95%|█████████▍| 284/300 [01:59<00:06,  2.38it/s]Running loglikelihood requests:  95%|█████████▌| 286/300 [02:00<00:04,  2.88it/s]Running loglikelihood requests:  96%|█████████▌| 288/300 [02:00<00:03,  3.28it/s]Running loglikelihood requests:  97%|█████████▋| 290/300 [02:01<00:02,  3.52it/s]Running loglikelihood requests:  97%|█████████▋| 292/300 [02:01<00:02,  3.74it/s]Running loglikelihood requests:  98%|█████████▊| 293/300 [02:02<00:02,  3.29it/s]Running loglikelihood requests:  98%|█████████▊| 294/300 [02:02<00:02,  2.96it/s]Running loglikelihood requests:  99%|█████████▊| 296/300 [02:03<00:01,  3.38it/s]Running loglikelihood requests:  99%|█████████▉| 298/300 [02:03<00:00,  3.71it/s]Running loglikelihood requests: 100%|█████████▉| 299/300 [02:04<00:00,  3.29it/s]Running loglikelihood requests: 100%|██████████| 300/300 [02:04<00:00,  2.42it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:2'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:2'}
full model:
{'mnli': {'alias': 'mnli', 'acc,none': 0.4, 'acc_stderr,none': 0.0492365963917331}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8171409999433525
0.8739893758684915
0.8333413990263023
0.8782828649633461
0.7602933913725962
0.7047335470608914
0.9813668198386444
0.7850949920891616
0.748983595161589
0.6557873189175887
0.7043210867322975
0.9420132312730142
0.9548348739467002
0.8459964595909506
0.6932219150662173
0.8804855383939617
0.868566987197908
0.8437399449827557
0.9153450822718411
0.8433082326287293
0.910397090611448
0.7626694638419581
0.752151649412453
0.8346986395359313
0.9530736745854924
0.8635918585764104
0.8647192950921815
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[4, 5, 6, 1, 7, 2, 3, 0]
tensor([4, 5, 6, 1, 7, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 4, 6, 2, 5, 1, 3, 0]
tensor([7, 4, 6, 2, 5, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 2, 7, 3, 5, 1, 4, 0]
tensor([6, 2, 7, 3, 5, 1, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 2, 5, 4, 6, 1, 3, 0]
tensor([7, 2, 5, 4, 6, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 5, 3, 1, 2, 4, 0]
tensor([0, 1, 5, 3, 1, 2, 4, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 1, 1, 2, 2, 3, 0]
tensor([0, 3, 1, 1, 2, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 2, 3, 1, 2, 0, 3, 1]
tensor([0, 2, 3, 1, 2, 0, 3, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 3, 1, 2, 2, 1, 3, 0]
tensor([0, 3, 1, 2, 2, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1.0, 1.0, 0, 1.0, 1]
tensor([0, 1, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
done!
Normal merging for layer 2
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([2])
tensor(2)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 4 to 8
done!
Normal merging for layer 9
tensor([0, 7])
tensor(0)
tensor([1, 4])
tensor(1)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([2])
tensor(2)
done!
Cross-layer merge completed for layers 10 to 20
done!
Normal merging for layer 21
tensor([0, 7])
tensor(0)
tensor([2, 3])
tensor(2)
tensor([4, 5])
tensor(4)
tensor([1, 6])
tensor(1)
done!
Normal merging for layer 22
tensor([0, 5])
tensor(0)
tensor([3, 7])
tensor(3)
tensor([1, 4])
tensor(1)
tensor([2, 6])
tensor(2)
done!
Normal merging for layer 23
tensor([0, 7])
tensor(0)
tensor([2, 5])
tensor(2)
tensor([3, 4])
tensor(3)
tensor([1, 6])
tensor(1)
done!
Cross-layer merge completed for layers 24 to 25
done!
Normal merging for layer 26
tensor([0, 5])
tensor(0)
tensor([1, 2, 3, 4, 6, 7])
tensor(1)
done!
Cross-layer merge completed for layers 27 to 31
done!
all done!
Model size: 12.5127 GB
163
cuda:2
mastermind_35_easy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:41<00:41, 41.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 24.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 27.15s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_35_mcq_random HTTP/1.1" 200 772
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/flair/mastermind_35_mcq_random/flair/mastermind_35_mcq_random.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_35_mcq_random HTTP/1.1" 200 780
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/flair/mastermind_35_mcq_random/resolve/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/flair/mastermind_35_mcq_random/resolve/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:filelock:Attempting to acquire lock 140239877332560 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_35_mcq_random_default_0.0.0_15dd5105771e9c8d2d3ea71c8d44fffda374a7a1.lock
DEBUG:filelock:Lock 140239877332560 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_35_mcq_random_default_0.0.0_15dd5105771e9c8d2d3ea71c8d44fffda374a7a1.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1/dataset_info.json
DEBUG:filelock:Attempting to release lock 140239877332560 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_35_mcq_random_default_0.0.0_15dd5105771e9c8d2d3ea71c8d44fffda374a7a1.lock
DEBUG:filelock:Lock 140239877332560 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_35_mcq_random_default_0.0.0_15dd5105771e9c8d2d3ea71c8d44fffda374a7a1.lock
DEBUG:filelock:Attempting to acquire lock 140240956812048 on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1_builder.lock
DEBUG:filelock:Lock 140240956812048 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1/dataset_info.json
DEBUG:filelock:Attempting to release lock 140240956812048 on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1_builder.lock
DEBUG:filelock:Lock 140240956812048 released on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mastermind_35_easy from None to 0
INFO:lm_eval.api.task:Building contexts for mastermind_35_easy on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1512.04it/s]
DEBUG:lm_eval.evaluator:Task: mastermind_35_easy; number of requests on this rank: 400
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/400 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/400 [00:01<11:31,  1.73s/it]Running loglikelihood requests:   0%|          | 2/400 [00:03<09:40,  1.46s/it]Running loglikelihood requests:   1%|          | 3/400 [00:04<09:02,  1.37s/it]Running loglikelihood requests:   1%|          | 4/400 [00:05<08:44,  1.32s/it]Running loglikelihood requests:   1%|▏         | 5/400 [00:06<08:33,  1.30s/it]Running loglikelihood requests:   2%|▏         | 6/400 [00:08<08:24,  1.28s/it]Running loglikelihood requests:   2%|▏         | 7/400 [00:09<08:19,  1.27s/it]Running loglikelihood requests:   2%|▏         | 8/400 [00:10<08:15,  1.26s/it]Running loglikelihood requests:   2%|▏         | 9/400 [00:11<08:11,  1.26s/it]Running loglikelihood requests:   2%|▎         | 10/400 [00:13<08:08,  1.25s/it]Running loglikelihood requests:   3%|▎         | 11/400 [00:14<08:06,  1.25s/it]Running loglikelihood requests:   3%|▎         | 12/400 [00:15<08:04,  1.25s/it]Running loglikelihood requests:   3%|▎         | 13/400 [00:16<08:01,  1.24s/it]Running loglikelihood requests:   4%|▎         | 14/400 [00:17<07:59,  1.24s/it]Running loglikelihood requests:   4%|▍         | 15/400 [00:19<07:57,  1.24s/it]Running loglikelihood requests:   4%|▍         | 16/400 [00:20<07:56,  1.24s/it]Running loglikelihood requests:   4%|▍         | 17/400 [00:21<07:54,  1.24s/it]Running loglikelihood requests:   4%|▍         | 18/400 [00:22<07:52,  1.24s/it]Running loglikelihood requests:   5%|▍         | 19/400 [00:24<07:50,  1.24s/it]Running loglikelihood requests:   5%|▌         | 20/400 [00:25<07:49,  1.24s/it]Running loglikelihood requests:   5%|▌         | 21/400 [00:26<07:47,  1.23s/it]Running loglikelihood requests:   6%|▌         | 23/400 [00:27<05:57,  1.05it/s]Running loglikelihood requests:   6%|▌         | 24/400 [00:29<06:25,  1.03s/it]Running loglikelihood requests:   6%|▋         | 25/400 [00:30<06:45,  1.08s/it]Running loglikelihood requests:   6%|▋         | 26/400 [00:31<06:59,  1.12s/it]Running loglikelihood requests:   7%|▋         | 27/400 [00:32<07:08,  1.15s/it]Running loglikelihood requests:   7%|▋         | 28/400 [00:34<07:15,  1.17s/it]Running loglikelihood requests:   7%|▋         | 29/400 [00:35<07:19,  1.18s/it]Running loglikelihood requests:   8%|▊         | 30/400 [00:36<07:22,  1.19s/it]Running loglikelihood requests:   8%|▊         | 31/400 [00:37<07:23,  1.20s/it]Running loglikelihood requests:   8%|▊         | 32/400 [00:38<07:23,  1.21s/it]Running loglikelihood requests:   8%|▊         | 33/400 [00:40<07:24,  1.21s/it]Running loglikelihood requests:   8%|▊         | 34/400 [00:41<07:23,  1.21s/it]Running loglikelihood requests:   9%|▉         | 35/400 [00:42<07:23,  1.21s/it]Running loglikelihood requests:   9%|▉         | 36/400 [00:43<07:22,  1.22s/it]Running loglikelihood requests:   9%|▉         | 37/400 [00:44<07:21,  1.22s/it]Running loglikelihood requests:  10%|▉         | 38/400 [00:46<07:20,  1.22s/it]Running loglikelihood requests:  10%|▉         | 39/400 [00:47<07:19,  1.22s/it]Running loglikelihood requests:  10%|█         | 40/400 [00:48<07:17,  1.22s/it]Running loglikelihood requests:  10%|█         | 41/400 [00:49<07:16,  1.22s/it]Running loglikelihood requests:  10%|█         | 42/400 [00:51<07:15,  1.22s/it]Running loglikelihood requests:  11%|█         | 43/400 [00:52<07:14,  1.22s/it]Running loglikelihood requests:  11%|█         | 44/400 [00:53<07:12,  1.22s/it]Running loglikelihood requests:  11%|█▏        | 45/400 [00:54<07:11,  1.22s/it]Running loglikelihood requests:  12%|█▏        | 46/400 [00:55<07:10,  1.22s/it]Running loglikelihood requests:  12%|█▏        | 47/400 [00:57<07:09,  1.22s/it]Running loglikelihood requests:  12%|█▏        | 48/400 [00:58<07:07,  1.22s/it]Running loglikelihood requests:  12%|█▏        | 49/400 [00:59<07:06,  1.22s/it]Running loglikelihood requests:  12%|█▎        | 50/400 [01:00<07:05,  1.22s/it]Running loglikelihood requests:  13%|█▎        | 51/400 [01:01<07:04,  1.22s/it]Running loglikelihood requests:  13%|█▎        | 52/400 [01:03<07:02,  1.21s/it]Running loglikelihood requests:  13%|█▎        | 53/400 [01:04<07:01,  1.21s/it]Running loglikelihood requests:  14%|█▎        | 54/400 [01:05<07:00,  1.21s/it]Running loglikelihood requests:  14%|█▍        | 55/400 [01:06<06:59,  1.22s/it]Running loglikelihood requests:  14%|█▍        | 56/400 [01:08<06:57,  1.22s/it]Running loglikelihood requests:  14%|█▍        | 57/400 [01:09<06:56,  1.21s/it]Running loglikelihood requests:  14%|█▍        | 58/400 [01:10<06:55,  1.21s/it]Running loglikelihood requests:  15%|█▍        | 59/400 [01:11<06:54,  1.22s/it]Running loglikelihood requests:  15%|█▌        | 60/400 [01:12<06:53,  1.21s/it]Running loglikelihood requests:  15%|█▌        | 61/400 [01:14<06:51,  1.22s/it]Running loglikelihood requests:  16%|█▌        | 62/400 [01:15<06:50,  1.21s/it]Running loglikelihood requests:  16%|█▌        | 63/400 [01:16<06:49,  1.21s/it]Running loglikelihood requests:  16%|█▌        | 64/400 [01:17<06:48,  1.21s/it]Running loglikelihood requests:  16%|█▋        | 65/400 [01:19<06:46,  1.21s/it]Running loglikelihood requests:  16%|█▋        | 66/400 [01:20<06:45,  1.21s/it]Running loglikelihood requests:  17%|█▋        | 67/400 [01:21<06:44,  1.21s/it]Running loglikelihood requests:  17%|█▋        | 68/400 [01:22<06:43,  1.21s/it]Running loglikelihood requests:  17%|█▋        | 69/400 [01:23<06:41,  1.21s/it]Running loglikelihood requests:  18%|█▊        | 70/400 [01:25<06:40,  1.21s/it]Running loglikelihood requests:  18%|█▊        | 71/400 [01:26<06:39,  1.21s/it]Running loglikelihood requests:  18%|█▊        | 72/400 [01:27<06:38,  1.21s/it]Running loglikelihood requests:  18%|█▊        | 73/400 [01:28<06:36,  1.21s/it]Running loglikelihood requests:  18%|█▊        | 74/400 [01:29<06:35,  1.21s/it]Running loglikelihood requests:  19%|█▉        | 75/400 [01:31<06:33,  1.21s/it]Running loglikelihood requests:  19%|█▉        | 76/400 [01:32<06:32,  1.21s/it]Running loglikelihood requests:  19%|█▉        | 77/400 [01:33<06:31,  1.21s/it]Running loglikelihood requests:  20%|█▉        | 78/400 [01:34<06:29,  1.21s/it]Running loglikelihood requests:  20%|█▉        | 79/400 [01:35<06:28,  1.21s/it]Running loglikelihood requests:  20%|██        | 80/400 [01:37<06:27,  1.21s/it]Running loglikelihood requests:  20%|██        | 81/400 [01:38<06:25,  1.21s/it]Running loglikelihood requests:  20%|██        | 82/400 [01:39<06:24,  1.21s/it]Running loglikelihood requests:  21%|██        | 83/400 [01:40<06:23,  1.21s/it]Running loglikelihood requests:  21%|██        | 84/400 [01:42<06:22,  1.21s/it]Running loglikelihood requests:  21%|██▏       | 85/400 [01:43<06:20,  1.21s/it]Running loglikelihood requests:  22%|██▏       | 86/400 [01:44<06:19,  1.21s/it]Running loglikelihood requests:  22%|██▏       | 87/400 [01:45<06:18,  1.21s/it]Running loglikelihood requests:  22%|██▏       | 88/400 [01:46<06:17,  1.21s/it]Running loglikelihood requests:  22%|██▏       | 89/400 [01:48<06:16,  1.21s/it]Running loglikelihood requests:  22%|██▎       | 90/400 [01:49<06:15,  1.21s/it]Running loglikelihood requests:  23%|██▎       | 91/400 [01:50<06:15,  1.21s/it]Running loglikelihood requests:  23%|██▎       | 92/400 [01:51<06:13,  1.21s/it]Running loglikelihood requests:  23%|██▎       | 93/400 [01:52<06:11,  1.21s/it]Running loglikelihood requests:  24%|██▎       | 94/400 [01:54<06:11,  1.21s/it]Running loglikelihood requests:  24%|██▍       | 95/400 [01:55<06:10,  1.21s/it]Running loglikelihood requests:  24%|██▍       | 96/400 [01:56<06:08,  1.21s/it]Running loglikelihood requests:  24%|██▍       | 97/400 [01:57<06:07,  1.21s/it]Running loglikelihood requests:  24%|██▍       | 98/400 [01:58<06:05,  1.21s/it]Running loglikelihood requests:  25%|██▍       | 99/400 [02:00<06:04,  1.21s/it]Running loglikelihood requests:  25%|██▌       | 100/400 [02:01<06:03,  1.21s/it]Running loglikelihood requests:  25%|██▌       | 101/400 [02:02<06:01,  1.21s/it]Running loglikelihood requests:  26%|██▌       | 102/400 [02:03<06:00,  1.21s/it]Running loglikelihood requests:  26%|██▌       | 103/400 [02:05<05:58,  1.21s/it]Running loglikelihood requests:  26%|██▌       | 104/400 [02:06<05:57,  1.21s/it]Running loglikelihood requests:  26%|██▋       | 105/400 [02:07<05:56,  1.21s/it]Running loglikelihood requests:  26%|██▋       | 106/400 [02:08<05:54,  1.21s/it]Running loglikelihood requests:  27%|██▋       | 107/400 [02:09<05:53,  1.21s/it]Running loglikelihood requests:  27%|██▋       | 108/400 [02:11<05:52,  1.21s/it]Running loglikelihood requests:  27%|██▋       | 109/400 [02:12<05:50,  1.21s/it]Running loglikelihood requests:  28%|██▊       | 110/400 [02:13<05:49,  1.21s/it]Running loglikelihood requests:  28%|██▊       | 112/400 [02:14<04:27,  1.08it/s]Running loglikelihood requests:  28%|██▊       | 113/400 [02:15<04:46,  1.00it/s]Running loglikelihood requests:  28%|██▊       | 114/400 [02:17<05:00,  1.05s/it]Running loglikelihood requests:  29%|██▉       | 115/400 [02:18<05:11,  1.09s/it]Running loglikelihood requests:  29%|██▉       | 116/400 [02:19<05:19,  1.12s/it]Running loglikelihood requests:  29%|██▉       | 117/400 [02:20<05:24,  1.15s/it]Running loglikelihood requests:  30%|██▉       | 118/400 [02:21<05:28,  1.16s/it]Running loglikelihood requests:  30%|██▉       | 119/400 [02:23<05:30,  1.18s/it]Running loglikelihood requests:  30%|███       | 120/400 [02:24<05:31,  1.19s/it]Running loglikelihood requests:  30%|███       | 121/400 [02:25<05:32,  1.19s/it]Running loglikelihood requests:  30%|███       | 122/400 [02:26<05:32,  1.20s/it]Running loglikelihood requests:  31%|███       | 123/400 [02:27<05:32,  1.20s/it]Running loglikelihood requests:  31%|███       | 124/400 [02:29<05:31,  1.20s/it]Running loglikelihood requests:  31%|███▏      | 125/400 [02:30<05:30,  1.20s/it]Running loglikelihood requests:  32%|███▏      | 126/400 [02:31<05:29,  1.20s/it]Running loglikelihood requests:  32%|███▏      | 127/400 [02:32<05:28,  1.20s/it]Running loglikelihood requests:  32%|███▏      | 128/400 [02:33<05:27,  1.20s/it]Running loglikelihood requests:  32%|███▏      | 129/400 [02:35<05:25,  1.20s/it]Running loglikelihood requests:  32%|███▎      | 130/400 [02:36<05:24,  1.20s/it]Running loglikelihood requests:  33%|███▎      | 131/400 [02:37<05:23,  1.20s/it]Running loglikelihood requests:  33%|███▎      | 132/400 [02:38<05:21,  1.20s/it]Running loglikelihood requests:  33%|███▎      | 133/400 [02:39<05:20,  1.20s/it]Running loglikelihood requests:  34%|███▎      | 134/400 [02:41<05:19,  1.20s/it]Running loglikelihood requests:  34%|███▍      | 135/400 [02:42<05:17,  1.20s/it]Running loglikelihood requests:  34%|███▍      | 136/400 [02:43<05:16,  1.20s/it]Running loglikelihood requests:  34%|███▍      | 137/400 [02:44<05:14,  1.20s/it]Running loglikelihood requests:  34%|███▍      | 138/400 [02:45<05:13,  1.20s/it]Running loglikelihood requests:  35%|███▍      | 139/400 [02:47<05:12,  1.20s/it]Running loglikelihood requests:  35%|███▌      | 140/400 [02:48<05:10,  1.20s/it]Running loglikelihood requests:  35%|███▌      | 141/400 [02:49<05:09,  1.20s/it]Running loglikelihood requests:  36%|███▌      | 142/400 [02:50<05:08,  1.20s/it]Running loglikelihood requests:  36%|███▌      | 143/400 [02:51<05:07,  1.20s/it]Running loglikelihood requests:  36%|███▌      | 144/400 [02:53<05:05,  1.19s/it]Running loglikelihood requests:  36%|███▋      | 145/400 [02:54<05:04,  1.19s/it]Running loglikelihood requests:  36%|███▋      | 146/400 [02:55<05:03,  1.19s/it]Running loglikelihood requests:  37%|███▋      | 147/400 [02:56<05:01,  1.19s/it]Running loglikelihood requests:  37%|███▋      | 148/400 [02:57<05:00,  1.19s/it]Running loglikelihood requests:  37%|███▋      | 149/400 [02:59<04:59,  1.19s/it]Running loglikelihood requests:  38%|███▊      | 150/400 [03:00<04:58,  1.19s/it]Running loglikelihood requests:  38%|███▊      | 151/400 [03:01<04:57,  1.19s/it]Running loglikelihood requests:  38%|███▊      | 152/400 [03:02<04:56,  1.19s/it]Running loglikelihood requests:  38%|███▊      | 153/400 [03:03<04:54,  1.19s/it]Running loglikelihood requests:  38%|███▊      | 154/400 [03:05<04:53,  1.19s/it]Running loglikelihood requests:  39%|███▉      | 155/400 [03:06<04:51,  1.19s/it]Running loglikelihood requests:  39%|███▉      | 156/400 [03:07<04:50,  1.19s/it]Running loglikelihood requests:  39%|███▉      | 157/400 [03:08<04:48,  1.19s/it]Running loglikelihood requests:  40%|███▉      | 158/400 [03:09<04:47,  1.19s/it]Running loglikelihood requests:  40%|███▉      | 159/400 [03:10<04:46,  1.19s/it]Running loglikelihood requests:  40%|████      | 160/400 [03:12<04:44,  1.18s/it]Running loglikelihood requests:  40%|████      | 161/400 [03:13<04:42,  1.18s/it]Running loglikelihood requests:  40%|████      | 162/400 [03:14<04:41,  1.18s/it]Running loglikelihood requests:  41%|████      | 163/400 [03:15<04:40,  1.18s/it]Running loglikelihood requests:  41%|████      | 164/400 [03:16<04:39,  1.18s/it]Running loglikelihood requests:  41%|████▏     | 165/400 [03:18<04:38,  1.18s/it]Running loglikelihood requests:  42%|████▏     | 166/400 [03:19<04:36,  1.18s/it]Running loglikelihood requests:  42%|████▏     | 167/400 [03:20<04:35,  1.18s/it]Running loglikelihood requests:  42%|████▏     | 168/400 [03:21<04:34,  1.18s/it]Running loglikelihood requests:  42%|████▏     | 169/400 [03:22<04:32,  1.18s/it]Running loglikelihood requests:  42%|████▎     | 170/400 [03:23<04:31,  1.18s/it]Running loglikelihood requests:  43%|████▎     | 171/400 [03:25<04:29,  1.18s/it]Running loglikelihood requests:  43%|████▎     | 172/400 [03:26<04:28,  1.18s/it]Running loglikelihood requests:  43%|████▎     | 173/400 [03:27<04:27,  1.18s/it]Running loglikelihood requests:  44%|████▎     | 174/400 [03:28<04:26,  1.18s/it]Running loglikelihood requests:  44%|████▍     | 175/400 [03:29<04:24,  1.18s/it]Running loglikelihood requests:  44%|████▍     | 177/400 [03:31<03:21,  1.11it/s]Running loglikelihood requests:  44%|████▍     | 178/400 [03:32<03:35,  1.03it/s]Running loglikelihood requests:  45%|████▍     | 179/400 [03:33<03:46,  1.03s/it]Running loglikelihood requests:  45%|████▌     | 180/400 [03:34<03:54,  1.07s/it]Running loglikelihood requests:  45%|████▌     | 181/400 [03:35<04:00,  1.10s/it]Running loglikelihood requests:  46%|████▌     | 182/400 [03:36<04:04,  1.12s/it]Running loglikelihood requests:  46%|████▌     | 183/400 [03:38<04:06,  1.14s/it]Running loglikelihood requests:  46%|████▌     | 184/400 [03:39<04:08,  1.15s/it]Running loglikelihood requests:  46%|████▋     | 185/400 [03:40<04:08,  1.16s/it]Running loglikelihood requests:  46%|████▋     | 186/400 [03:41<04:08,  1.16s/it]Running loglikelihood requests:  47%|████▋     | 187/400 [03:42<04:08,  1.17s/it]Running loglikelihood requests:  47%|████▋     | 188/400 [03:43<04:07,  1.17s/it]Running loglikelihood requests:  47%|████▋     | 189/400 [03:45<04:06,  1.17s/it]Running loglikelihood requests:  48%|████▊     | 190/400 [03:46<04:05,  1.17s/it]Running loglikelihood requests:  48%|████▊     | 191/400 [03:47<04:04,  1.17s/it]Running loglikelihood requests:  48%|████▊     | 192/400 [03:48<04:03,  1.17s/it]Running loglikelihood requests:  48%|████▊     | 193/400 [03:49<04:02,  1.17s/it]Running loglikelihood requests:  48%|████▊     | 194/400 [03:50<04:01,  1.17s/it]Running loglikelihood requests:  49%|████▉     | 195/400 [03:52<04:00,  1.17s/it]Running loglikelihood requests:  49%|████▉     | 196/400 [03:53<03:58,  1.17s/it]Running loglikelihood requests:  49%|████▉     | 197/400 [03:54<03:57,  1.17s/it]Running loglikelihood requests:  50%|████▉     | 198/400 [03:55<03:56,  1.17s/it]Running loglikelihood requests:  50%|████▉     | 199/400 [03:56<03:55,  1.17s/it]Running loglikelihood requests:  50%|█████     | 200/400 [03:57<03:53,  1.17s/it]Running loglikelihood requests:  50%|█████     | 201/400 [03:59<03:52,  1.17s/it]Running loglikelihood requests:  50%|█████     | 202/400 [04:00<03:51,  1.17s/it]Running loglikelihood requests:  51%|█████     | 203/400 [04:01<03:50,  1.17s/it]Running loglikelihood requests:  51%|█████▏    | 205/400 [04:02<02:55,  1.11it/s]Running loglikelihood requests:  52%|█████▏    | 206/400 [04:03<03:07,  1.04it/s]Running loglikelihood requests:  52%|█████▏    | 207/400 [04:05<03:16,  1.02s/it]Running loglikelihood requests:  52%|█████▏    | 208/400 [04:06<03:23,  1.06s/it]Running loglikelihood requests:  52%|█████▏    | 209/400 [04:07<03:28,  1.09s/it]Running loglikelihood requests:  52%|█████▎    | 210/400 [04:08<03:31,  1.11s/it]Running loglikelihood requests:  53%|█████▎    | 211/400 [04:09<03:33,  1.13s/it]Running loglikelihood requests:  53%|█████▎    | 212/400 [04:10<03:34,  1.14s/it]Running loglikelihood requests:  53%|█████▎    | 213/400 [04:12<03:35,  1.15s/it]Running loglikelihood requests:  54%|█████▎    | 214/400 [04:13<03:34,  1.15s/it]Running loglikelihood requests:  54%|█████▍    | 215/400 [04:14<03:33,  1.16s/it]Running loglikelihood requests:  54%|█████▍    | 216/400 [04:15<03:33,  1.16s/it]Running loglikelihood requests:  54%|█████▍    | 217/400 [04:16<03:32,  1.16s/it]Running loglikelihood requests:  55%|█████▍    | 218/400 [04:17<03:31,  1.16s/it]Running loglikelihood requests:  55%|█████▍    | 219/400 [04:18<03:30,  1.16s/it]Running loglikelihood requests:  55%|█████▌    | 220/400 [04:20<03:29,  1.16s/it]Running loglikelihood requests:  55%|█████▌    | 221/400 [04:21<03:28,  1.16s/it]Running loglikelihood requests:  56%|█████▌    | 222/400 [04:22<03:26,  1.16s/it]Running loglikelihood requests:  56%|█████▌    | 223/400 [04:23<03:25,  1.16s/it]Running loglikelihood requests:  56%|█████▌    | 224/400 [04:24<03:24,  1.16s/it]Running loglikelihood requests:  56%|█████▋    | 225/400 [04:25<03:23,  1.16s/it]Running loglikelihood requests:  56%|█████▋    | 226/400 [04:27<03:22,  1.16s/it]Running loglikelihood requests:  57%|█████▋    | 227/400 [04:28<03:21,  1.16s/it]Running loglikelihood requests:  57%|█████▋    | 228/400 [04:29<03:19,  1.16s/it]Running loglikelihood requests:  57%|█████▋    | 229/400 [04:30<03:18,  1.16s/it]Running loglikelihood requests:  57%|█████▊    | 230/400 [04:31<03:17,  1.16s/it]Running loglikelihood requests:  58%|█████▊    | 231/400 [04:32<03:15,  1.16s/it]Running loglikelihood requests:  58%|█████▊    | 232/400 [04:34<03:14,  1.16s/it]Running loglikelihood requests:  58%|█████▊    | 233/400 [04:35<03:13,  1.16s/it]Running loglikelihood requests:  58%|█████▊    | 234/400 [04:36<03:12,  1.16s/it]Running loglikelihood requests:  59%|█████▉    | 235/400 [04:37<03:11,  1.16s/it]Running loglikelihood requests:  59%|█████▉    | 236/400 [04:38<03:09,  1.16s/it]Running loglikelihood requests:  59%|█████▉    | 237/400 [04:39<03:08,  1.16s/it]Running loglikelihood requests:  60%|█████▉    | 238/400 [04:41<03:07,  1.16s/it]Running loglikelihood requests:  60%|█████▉    | 239/400 [04:42<03:06,  1.16s/it]Running loglikelihood requests:  60%|██████    | 241/400 [04:43<02:21,  1.12it/s]Running loglikelihood requests:  60%|██████    | 242/400 [04:44<02:31,  1.05it/s]Running loglikelihood requests:  61%|██████    | 243/400 [04:45<02:38,  1.01s/it]Running loglikelihood requests:  61%|██████    | 244/400 [04:46<02:43,  1.05s/it]Running loglikelihood requests:  61%|██████▏   | 245/400 [04:47<02:47,  1.08s/it]Running loglikelihood requests:  62%|██████▏   | 246/400 [04:49<02:49,  1.10s/it]Running loglikelihood requests:  62%|██████▏   | 247/400 [04:50<02:50,  1.12s/it]Running loglikelihood requests:  62%|██████▏   | 248/400 [04:51<02:51,  1.13s/it]Running loglikelihood requests:  62%|██████▏   | 249/400 [04:52<02:51,  1.13s/it]Running loglikelihood requests:  62%|██████▎   | 250/400 [04:53<02:50,  1.14s/it]Running loglikelihood requests:  63%|██████▎   | 251/400 [04:54<02:50,  1.14s/it]Running loglikelihood requests:  63%|██████▎   | 252/400 [04:56<02:49,  1.15s/it]Running loglikelihood requests:  63%|██████▎   | 253/400 [04:57<02:48,  1.15s/it]Running loglikelihood requests:  64%|██████▍   | 255/400 [04:58<02:08,  1.13it/s]Running loglikelihood requests:  64%|██████▍   | 256/400 [04:59<02:16,  1.05it/s]Running loglikelihood requests:  64%|██████▍   | 257/400 [05:00<02:23,  1.00s/it]Running loglikelihood requests:  64%|██████▍   | 258/400 [05:01<02:28,  1.04s/it]Running loglikelihood requests:  65%|██████▍   | 259/400 [05:02<02:31,  1.07s/it]Running loglikelihood requests:  65%|██████▌   | 260/400 [05:04<02:33,  1.10s/it]Running loglikelihood requests:  65%|██████▌   | 261/400 [05:05<02:34,  1.11s/it]Running loglikelihood requests:  66%|██████▌   | 262/400 [05:06<02:34,  1.12s/it]Running loglikelihood requests:  66%|██████▌   | 263/400 [05:07<02:34,  1.13s/it]Running loglikelihood requests:  66%|██████▌   | 264/400 [05:08<02:34,  1.13s/it]Running loglikelihood requests:  66%|██████▋   | 265/400 [05:09<02:33,  1.14s/it]Running loglikelihood requests:  66%|██████▋   | 266/400 [05:10<02:32,  1.14s/it]Running loglikelihood requests:  67%|██████▋   | 267/400 [05:12<02:32,  1.14s/it]Running loglikelihood requests:  67%|██████▋   | 268/400 [05:13<02:31,  1.14s/it]Running loglikelihood requests:  68%|██████▊   | 270/400 [05:14<01:54,  1.14it/s]Running loglikelihood requests:  68%|██████▊   | 271/400 [05:15<02:01,  1.06it/s]Running loglikelihood requests:  68%|██████▊   | 272/400 [05:16<02:07,  1.00it/s]Running loglikelihood requests:  68%|██████▊   | 273/400 [05:17<02:11,  1.04s/it]Running loglikelihood requests:  68%|██████▊   | 274/400 [05:18<02:14,  1.06s/it]Running loglikelihood requests:  69%|██████▉   | 275/400 [05:20<02:15,  1.09s/it]Running loglikelihood requests:  69%|██████▉   | 276/400 [05:21<02:16,  1.10s/it]Running loglikelihood requests:  69%|██████▉   | 277/400 [05:22<02:16,  1.11s/it]Running loglikelihood requests:  70%|██████▉   | 278/400 [05:23<02:16,  1.12s/it]Running loglikelihood requests:  70%|██████▉   | 279/400 [05:24<02:15,  1.12s/it]Running loglikelihood requests:  70%|███████   | 280/400 [05:25<02:15,  1.13s/it]Running loglikelihood requests:  70%|███████   | 281/400 [05:26<02:14,  1.13s/it]Running loglikelihood requests:  70%|███████   | 282/400 [05:28<02:13,  1.13s/it]Running loglikelihood requests:  71%|███████   | 283/400 [05:29<02:12,  1.13s/it]Running loglikelihood requests:  71%|███████   | 284/400 [05:30<02:11,  1.13s/it]Running loglikelihood requests:  71%|███████▏  | 285/400 [05:31<02:10,  1.13s/it]Running loglikelihood requests:  72%|███████▏  | 286/400 [05:32<02:08,  1.13s/it]Running loglikelihood requests:  72%|███████▏  | 287/400 [05:33<02:07,  1.13s/it]Running loglikelihood requests:  72%|███████▏  | 288/400 [05:34<02:06,  1.13s/it]Running loglikelihood requests:  72%|███████▏  | 289/400 [05:36<02:05,  1.13s/it]Running loglikelihood requests:  72%|███████▎  | 290/400 [05:37<02:04,  1.13s/it]Running loglikelihood requests:  73%|███████▎  | 291/400 [05:38<02:03,  1.13s/it]Running loglikelihood requests:  73%|███████▎  | 292/400 [05:39<02:02,  1.13s/it]Running loglikelihood requests:  73%|███████▎  | 293/400 [05:40<02:00,  1.13s/it]Running loglikelihood requests:  74%|███████▎  | 294/400 [05:41<01:59,  1.13s/it]Running loglikelihood requests:  74%|███████▍  | 295/400 [05:42<01:58,  1.13s/it]Running loglikelihood requests:  74%|███████▍  | 296/400 [05:43<01:57,  1.13s/it]Running loglikelihood requests:  74%|███████▍  | 297/400 [05:45<01:56,  1.13s/it]Running loglikelihood requests:  74%|███████▍  | 298/400 [05:46<01:54,  1.13s/it]Running loglikelihood requests:  75%|███████▍  | 299/400 [05:47<01:53,  1.13s/it]Running loglikelihood requests:  75%|███████▌  | 300/400 [05:48<01:52,  1.12s/it]Running loglikelihood requests:  75%|███████▌  | 301/400 [05:49<01:51,  1.12s/it]Running loglikelihood requests:  76%|███████▌  | 302/400 [05:50<01:50,  1.12s/it]Running loglikelihood requests:  76%|███████▌  | 304/400 [05:51<01:22,  1.16it/s]Running loglikelihood requests:  76%|███████▋  | 305/400 [05:52<01:28,  1.08it/s]Running loglikelihood requests:  76%|███████▋  | 306/400 [05:54<01:31,  1.02it/s]Running loglikelihood requests:  77%|███████▋  | 307/400 [05:55<01:34,  1.01s/it]Running loglikelihood requests:  77%|███████▋  | 308/400 [05:56<01:35,  1.04s/it]Running loglikelihood requests:  77%|███████▋  | 309/400 [05:57<01:36,  1.06s/it]Running loglikelihood requests:  78%|███████▊  | 310/400 [05:58<01:36,  1.08s/it]Running loglikelihood requests:  78%|███████▊  | 311/400 [05:59<01:36,  1.09s/it]Running loglikelihood requests:  78%|███████▊  | 312/400 [06:00<01:36,  1.09s/it]Running loglikelihood requests:  78%|███████▊  | 313/400 [06:01<01:35,  1.10s/it]Running loglikelihood requests:  78%|███████▊  | 314/400 [06:02<01:34,  1.10s/it]Running loglikelihood requests:  79%|███████▉  | 315/400 [06:04<01:33,  1.11s/it]Running loglikelihood requests:  79%|███████▉  | 316/400 [06:05<01:33,  1.11s/it]Running loglikelihood requests:  79%|███████▉  | 317/400 [06:06<01:31,  1.11s/it]Running loglikelihood requests:  80%|███████▉  | 318/400 [06:07<01:30,  1.11s/it]Running loglikelihood requests:  80%|███████▉  | 319/400 [06:08<01:29,  1.11s/it]Running loglikelihood requests:  80%|████████  | 320/400 [06:09<01:28,  1.11s/it]Running loglikelihood requests:  80%|████████  | 321/400 [06:10<01:27,  1.11s/it]Running loglikelihood requests:  80%|████████  | 322/400 [06:11<01:26,  1.11s/it]Running loglikelihood requests:  81%|████████  | 323/400 [06:12<01:25,  1.11s/it]Running loglikelihood requests:  81%|████████  | 324/400 [06:13<01:24,  1.11s/it]Running loglikelihood requests:  81%|████████▏ | 325/400 [06:15<01:22,  1.11s/it]Running loglikelihood requests:  82%|████████▏ | 326/400 [06:16<01:21,  1.11s/it]Running loglikelihood requests:  82%|████████▏ | 327/400 [06:17<01:20,  1.11s/it]Running loglikelihood requests:  82%|████████▏ | 328/400 [06:18<01:19,  1.10s/it]Running loglikelihood requests:  82%|████████▎ | 330/400 [06:19<00:59,  1.18it/s]Running loglikelihood requests:  83%|████████▎ | 331/400 [06:20<01:02,  1.10it/s]Running loglikelihood requests:  83%|████████▎ | 332/400 [06:21<01:05,  1.04it/s]Running loglikelihood requests:  83%|████████▎ | 333/400 [06:22<01:06,  1.00it/s]Running loglikelihood requests:  84%|████████▎ | 334/400 [06:23<01:07,  1.03s/it]Running loglikelihood requests:  84%|████████▍ | 335/400 [06:24<01:07,  1.05s/it]Running loglikelihood requests:  84%|████████▍ | 336/400 [06:26<01:07,  1.06s/it]Running loglikelihood requests:  84%|████████▍ | 337/400 [06:27<01:07,  1.07s/it]Running loglikelihood requests:  84%|████████▍ | 338/400 [06:28<01:06,  1.08s/it]Running loglikelihood requests:  85%|████████▍ | 339/400 [06:29<01:06,  1.09s/it]Running loglikelihood requests:  85%|████████▌ | 340/400 [06:30<01:05,  1.09s/it]Running loglikelihood requests:  85%|████████▌ | 341/400 [06:31<01:04,  1.09s/it]Running loglikelihood requests:  86%|████████▌ | 342/400 [06:32<01:03,  1.09s/it]Running loglikelihood requests:  86%|████████▌ | 343/400 [06:33<01:02,  1.09s/it]Running loglikelihood requests:  86%|████████▌ | 344/400 [06:34<01:01,  1.09s/it]Running loglikelihood requests:  86%|████████▋ | 345/400 [06:35<01:00,  1.09s/it]Running loglikelihood requests:  86%|████████▋ | 346/400 [06:37<00:59,  1.09s/it]Running loglikelihood requests:  87%|████████▋ | 347/400 [06:38<00:57,  1.09s/it]Running loglikelihood requests:  87%|████████▋ | 348/400 [06:39<00:56,  1.09s/it]Running loglikelihood requests:  87%|████████▋ | 349/400 [06:40<00:55,  1.09s/it]Running loglikelihood requests:  88%|████████▊ | 350/400 [06:41<00:54,  1.08s/it]Running loglikelihood requests:  88%|████████▊ | 351/400 [06:42<00:52,  1.08s/it]Running loglikelihood requests:  88%|████████▊ | 352/400 [06:43<00:51,  1.08s/it]Running loglikelihood requests:  88%|████████▊ | 353/400 [06:44<00:50,  1.08s/it]Running loglikelihood requests:  88%|████████▊ | 354/400 [06:45<00:49,  1.08s/it]Running loglikelihood requests:  89%|████████▉ | 355/400 [06:46<00:48,  1.08s/it]Running loglikelihood requests:  89%|████████▉ | 356/400 [06:47<00:47,  1.08s/it]Running loglikelihood requests:  89%|████████▉ | 357/400 [06:48<00:46,  1.07s/it]Running loglikelihood requests:  90%|████████▉ | 358/400 [06:49<00:45,  1.07s/it]Running loglikelihood requests:  90%|████████▉ | 359/400 [06:51<00:43,  1.07s/it]Running loglikelihood requests:  90%|█████████ | 360/400 [06:52<00:42,  1.07s/it]Running loglikelihood requests:  90%|█████████ | 361/400 [06:53<00:41,  1.07s/it]Running loglikelihood requests:  90%|█████████ | 362/400 [06:54<00:40,  1.06s/it]Running loglikelihood requests:  91%|█████████ | 363/400 [06:55<00:39,  1.06s/it]Running loglikelihood requests:  91%|█████████ | 364/400 [06:56<00:38,  1.06s/it]Running loglikelihood requests:  91%|█████████▏| 365/400 [06:57<00:37,  1.06s/it]Running loglikelihood requests:  92%|█████████▏| 366/400 [06:58<00:35,  1.06s/it]Running loglikelihood requests:  92%|█████████▏| 367/400 [06:59<00:34,  1.06s/it]Running loglikelihood requests:  92%|█████████▏| 368/400 [07:00<00:33,  1.05s/it]Running loglikelihood requests:  92%|█████████▏| 369/400 [07:01<00:32,  1.05s/it]Running loglikelihood requests:  92%|█████████▎| 370/400 [07:02<00:31,  1.05s/it]Running loglikelihood requests:  93%|█████████▎| 371/400 [07:03<00:30,  1.05s/it]Running loglikelihood requests:  93%|█████████▎| 372/400 [07:04<00:29,  1.05s/it]Running loglikelihood requests:  93%|█████████▎| 373/400 [07:05<00:28,  1.05s/it]Running loglikelihood requests:  94%|█████████▎| 374/400 [07:06<00:27,  1.05s/it]Running loglikelihood requests:  94%|█████████▍| 375/400 [07:07<00:26,  1.05s/it]Running loglikelihood requests:  94%|█████████▍| 376/400 [07:08<00:25,  1.04s/it]Running loglikelihood requests:  94%|█████████▍| 377/400 [07:09<00:23,  1.04s/it]Running loglikelihood requests:  94%|█████████▍| 378/400 [07:10<00:22,  1.04s/it]Running loglikelihood requests:  95%|█████████▍| 379/400 [07:12<00:21,  1.04s/it]Running loglikelihood requests:  95%|█████████▌| 380/400 [07:13<00:20,  1.03s/it]Running loglikelihood requests:  95%|█████████▌| 381/400 [07:14<00:19,  1.03s/it]Running loglikelihood requests:  96%|█████████▌| 382/400 [07:15<00:18,  1.03s/it]Running loglikelihood requests:  96%|█████████▌| 383/400 [07:16<00:17,  1.03s/it]Running loglikelihood requests:  96%|█████████▌| 384/400 [07:17<00:16,  1.03s/it]Running loglikelihood requests:  96%|█████████▋| 385/400 [07:18<00:15,  1.03s/it]Running loglikelihood requests:  96%|█████████▋| 386/400 [07:19<00:14,  1.03s/it]Running loglikelihood requests:  97%|█████████▋| 387/400 [07:20<00:13,  1.03s/it]Running loglikelihood requests:  97%|█████████▋| 388/400 [07:21<00:12,  1.03s/it]Running loglikelihood requests:  97%|█████████▋| 389/400 [07:22<00:11,  1.03s/it]Running loglikelihood requests:  98%|█████████▊| 390/400 [07:23<00:10,  1.03s/it]Running loglikelihood requests:  98%|█████████▊| 391/400 [07:24<00:09,  1.03s/it]Running loglikelihood requests:  98%|█████████▊| 392/400 [07:25<00:08,  1.02s/it]Running loglikelihood requests:  98%|█████████▊| 393/400 [07:26<00:07,  1.02s/it]Running loglikelihood requests:  98%|█████████▊| 394/400 [07:27<00:06,  1.02s/it]Running loglikelihood requests:  99%|█████████▉| 395/400 [07:28<00:05,  1.02s/it]Running loglikelihood requests:  99%|█████████▉| 396/400 [07:29<00:04,  1.02s/it]Running loglikelihood requests:  99%|█████████▉| 397/400 [07:30<00:03,  1.01s/it]Running loglikelihood requests: 100%|█████████▉| 398/400 [07:31<00:02,  1.01s/it]Running loglikelihood requests: 100%|█████████▉| 399/400 [07:32<00:01,  1.00s/it]Running loglikelihood requests: 100%|██████████| 400/400 [07:33<00:00,  1.00it/s]Running loglikelihood requests: 100%|██████████| 400/400 [07:33<00:00,  1.13s/it]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:3'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:3'}
full model:
{'mastermind_35_easy': {'alias': 'mastermind_35_easy', 'acc,none': 0.51, 'acc_stderr,none': 0.05024183937956913}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9685093904417202
0.9837389482734848
0.9887891422859466
0.9728424941793791
0.9273096247071001
0.9956884174036557
0.9936991917224709
0.990637728847171
0.984416562505352
0.9357041463019401
0.957486187236088
0.9794440444506461
0.9854000882321717
0.989321120949945
0.9948124947717892
0.9950699411775289
0.9589145403056732
0.9488498047330014
0.979093344902028
0.9861615563222426
0.9944647439314634
0.9974738465425171
0.9932459641322177
0.9612113452387381
0.9566187588663586
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[5, 1, 0, 3, 7, 6, 2, 4]
tensor([5, 1, 0, 3, 7, 6, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 0, 3, 7, 5, 2, 4]
tensor([6, 1, 0, 3, 7, 5, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 1, 0, 3, 7, 6, 2, 4]
tensor([5, 1, 0, 3, 7, 6, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 0, 3, 7, 5, 2, 4]
tensor([6, 1, 0, 3, 7, 5, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 1, 0, 3, 7, 6, 2, 4]
tensor([5, 1, 0, 3, 7, 6, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 0, 3, 7, 5, 2, 4]
tensor([6, 1, 0, 3, 7, 5, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Normal merging for layer 2
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Normal merging for layer 3
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Normal merging for layer 4
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Normal merging for layer 5
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 6 to 31
done!
all done!
Model size: 12.0718 GB
52
cuda:3
mrpc
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:42<00:42, 42.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 24.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 27.37s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: mrpc] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: mrpc] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
WARNING:lm_eval.api.task:[Task: mrpc] metric f1 is defined, but aggregation is not. using default aggregation=f1
WARNING:lm_eval.api.task:[Task: mrpc] metric f1 is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/mrpc?recursive=False&expand=False HTTP/1.1" 307 141
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/tree/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/mrpc?recursive=False&expand=False HTTP/1.1" 200 356
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140240419491712 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_mrpc_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140240419491712 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_mrpc_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/mrpc/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140240419491712 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_mrpc_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140240419491712 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_mrpc_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140237334027040 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/mrpc/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140237334027040 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/mrpc/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/mrpc/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140237334027040 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/mrpc/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140237334027040 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/mrpc/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mrpc from None to 0
INFO:lm_eval.api.task:Building contexts for mrpc on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 2470.80it/s]
DEBUG:lm_eval.evaluator:Task: mrpc; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:01<04:43,  1.43s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:02<02:20,  1.41it/s]Running loglikelihood requests:   2%|▎         | 5/200 [00:03<01:53,  1.72it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:04<01:41,  1.90it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:05<01:34,  2.01it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:05<01:30,  2.09it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:06<01:27,  2.14it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:07<01:24,  2.18it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:08<01:22,  2.21it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:09<01:21,  2.23it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:10<01:19,  2.25it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:11<01:18,  2.26it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:12<01:16,  2.28it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:12<01:15,  2.29it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:13<01:14,  2.30it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:14<01:12,  2.32it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:15<01:11,  2.33it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:16<01:10,  2.34it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:17<01:09,  2.35it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:18<01:08,  2.36it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:18<01:07,  2.37it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:19<01:06,  2.38it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:20<01:05,  2.38it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:21<01:03,  2.39it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:22<01:02,  2.41it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:23<01:01,  2.42it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:23<01:00,  2.43it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:24<00:59,  2.44it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:25<00:58,  2.44it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:26<00:57,  2.45it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:27<00:56,  2.46it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:27<00:55,  2.47it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:28<00:54,  2.47it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:29<00:53,  2.48it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:30<00:52,  2.48it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:31<00:51,  2.50it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:31<00:50,  2.51it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:32<00:49,  2.52it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:33<00:48,  2.53it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:34<00:47,  2.54it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:34<00:46,  2.55it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:35<00:45,  2.55it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:36<00:44,  2.56it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:37<00:44,  2.56it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:38<00:43,  2.58it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:38<00:42,  2.58it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:39<00:41,  2.60it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:40<00:40,  2.61it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:41<00:39,  2.61it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:41<00:38,  2.62it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:42<00:37,  2.63it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:43<00:36,  2.63it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:44<00:35,  2.64it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:44<00:35,  2.64it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:45<00:34,  2.65it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:46<00:33,  2.65it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:47<00:32,  2.66it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:47<00:31,  2.66it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:48<00:31,  2.66it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:49<00:30,  2.67it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:50<00:29,  2.67it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:50<00:28,  2.68it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:51<00:27,  2.68it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [00:52<00:27,  2.69it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [00:53<00:26,  2.70it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [00:53<00:25,  2.70it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [00:54<00:24,  2.71it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [00:55<00:23,  2.72it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [00:56<00:23,  2.72it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [00:56<00:22,  2.72it/s]Running loglikelihood requests:  70%|███████   | 141/200 [00:57<00:21,  2.73it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [00:58<00:20,  2.74it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [00:58<00:19,  2.76it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [00:59<00:19,  2.77it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [01:00<00:18,  2.77it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [01:01<00:17,  2.78it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [01:01<00:16,  2.78it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [01:02<00:16,  2.78it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [01:03<00:15,  2.79it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [01:03<00:14,  2.80it/s]Running loglikelihood requests:  80%|████████  | 161/200 [01:04<00:13,  2.81it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [01:05<00:13,  2.82it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [01:06<00:12,  2.84it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [01:06<00:11,  2.86it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [01:07<00:10,  2.88it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [01:08<00:10,  2.90it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [01:08<00:09,  2.92it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [01:09<00:08,  2.93it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [01:10<00:07,  2.95it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [01:10<00:07,  2.98it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [01:11<00:06,  3.00it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [01:12<00:05,  3.03it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [01:12<00:04,  3.04it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [01:13<00:04,  3.07it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [01:14<00:03,  3.09it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [01:14<00:02,  3.10it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [01:15<00:02,  3.12it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:15<00:01,  3.14it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:16<00:00,  3.16it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:17<00:00,  3.21it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:17<00:00,  2.59it/s]
bootstrapping for stddev (sequential): f1_score
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:01<01:58,  1.20s/it]  2%|▏         | 2/100 [00:02<01:57,  1.20s/it]  3%|▎         | 3/100 [00:03<01:56,  1.20s/it]  4%|▍         | 4/100 [00:04<01:54,  1.20s/it]  5%|▌         | 5/100 [00:05<01:53,  1.20s/it]  6%|▌         | 6/100 [00:07<01:52,  1.20s/it]  7%|▋         | 7/100 [00:08<01:51,  1.20s/it]  8%|▊         | 8/100 [00:09<01:50,  1.20s/it]  9%|▉         | 9/100 [00:10<01:48,  1.20s/it] 10%|█         | 10/100 [00:11<01:47,  1.20s/it] 11%|█         | 11/100 [00:13<01:46,  1.20s/it] 12%|█▏        | 12/100 [00:14<01:45,  1.20s/it] 13%|█▎        | 13/100 [00:15<01:44,  1.20s/it] 14%|█▍        | 14/100 [00:16<01:42,  1.20s/it] 15%|█▌        | 15/100 [00:17<01:41,  1.20s/it] 16%|█▌        | 16/100 [00:19<01:40,  1.20s/it] 17%|█▋        | 17/100 [00:20<01:39,  1.20s/it] 18%|█▊        | 18/100 [00:21<01:38,  1.20s/it] 19%|█▉        | 19/100 [00:22<01:36,  1.20s/it] 20%|██        | 20/100 [00:23<01:35,  1.20s/it] 21%|██        | 21/100 [00:25<01:34,  1.20s/it] 22%|██▏       | 22/100 [00:26<01:33,  1.20s/it] 23%|██▎       | 23/100 [00:27<01:32,  1.20s/it] 24%|██▍       | 24/100 [00:28<01:30,  1.20s/it] 25%|██▌       | 25/100 [00:29<01:29,  1.20s/it] 26%|██▌       | 26/100 [00:31<01:28,  1.20s/it] 27%|██▋       | 27/100 [00:32<01:27,  1.20s/it] 28%|██▊       | 28/100 [00:33<01:26,  1.20s/it] 29%|██▉       | 29/100 [00:34<01:24,  1.20s/it] 30%|███       | 30/100 [00:35<01:23,  1.20s/it] 31%|███       | 31/100 [00:37<01:22,  1.20s/it] 32%|███▏      | 32/100 [00:38<01:21,  1.20s/it] 33%|███▎      | 33/100 [00:39<01:20,  1.20s/it] 34%|███▍      | 34/100 [00:40<01:18,  1.20s/it] 35%|███▌      | 35/100 [00:41<01:17,  1.20s/it] 36%|███▌      | 36/100 [00:43<01:16,  1.20s/it] 37%|███▋      | 37/100 [00:44<01:15,  1.20s/it] 38%|███▊      | 38/100 [00:45<01:14,  1.20s/it] 39%|███▉      | 39/100 [00:46<01:12,  1.20s/it] 40%|████      | 40/100 [00:47<01:11,  1.20s/it] 41%|████      | 41/100 [00:49<01:10,  1.20s/it] 42%|████▏     | 42/100 [00:50<01:09,  1.20s/it] 43%|████▎     | 43/100 [00:51<01:08,  1.20s/it] 44%|████▍     | 44/100 [00:52<01:07,  1.20s/it] 45%|████▌     | 45/100 [00:53<01:05,  1.20s/it] 46%|████▌     | 46/100 [00:55<01:04,  1.20s/it] 47%|████▋     | 47/100 [00:56<01:03,  1.20s/it] 48%|████▊     | 48/100 [00:57<01:02,  1.20s/it] 49%|████▉     | 49/100 [00:58<01:01,  1.20s/it] 50%|█████     | 50/100 [00:59<00:59,  1.20s/it] 51%|█████     | 51/100 [01:01<00:58,  1.20s/it] 52%|█████▏    | 52/100 [01:02<00:57,  1.20s/it] 53%|█████▎    | 53/100 [01:03<00:56,  1.20s/it] 54%|█████▍    | 54/100 [01:04<00:55,  1.20s/it] 55%|█████▌    | 55/100 [01:05<00:53,  1.20s/it] 56%|█████▌    | 56/100 [01:07<00:52,  1.20s/it] 57%|█████▋    | 57/100 [01:08<00:51,  1.20s/it] 58%|█████▊    | 58/100 [01:09<00:50,  1.20s/it] 59%|█████▉    | 59/100 [01:10<00:49,  1.20s/it] 60%|██████    | 60/100 [01:11<00:47,  1.20s/it] 61%|██████    | 61/100 [01:13<00:46,  1.20s/it] 62%|██████▏   | 62/100 [01:14<00:45,  1.20s/it] 63%|██████▎   | 63/100 [01:15<00:44,  1.20s/it] 64%|██████▍   | 64/100 [01:16<00:43,  1.20s/it] 65%|██████▌   | 65/100 [01:17<00:41,  1.20s/it] 66%|██████▌   | 66/100 [01:19<00:40,  1.20s/it] 67%|██████▋   | 67/100 [01:20<00:39,  1.20s/it] 68%|██████▊   | 68/100 [01:21<00:38,  1.20s/it] 69%|██████▉   | 69/100 [01:22<00:37,  1.20s/it] 70%|███████   | 70/100 [01:23<00:36,  1.20s/it] 71%|███████   | 71/100 [01:25<00:34,  1.20s/it] 72%|███████▏  | 72/100 [01:26<00:33,  1.20s/it] 73%|███████▎  | 73/100 [01:27<00:32,  1.20s/it] 74%|███████▍  | 74/100 [01:28<00:31,  1.20s/it] 75%|███████▌  | 75/100 [01:29<00:29,  1.20s/it] 76%|███████▌  | 76/100 [01:31<00:28,  1.20s/it] 77%|███████▋  | 77/100 [01:32<00:27,  1.20s/it] 78%|███████▊  | 78/100 [01:33<00:26,  1.20s/it] 79%|███████▉  | 79/100 [01:34<00:25,  1.20s/it] 80%|████████  | 80/100 [01:35<00:23,  1.20s/it] 81%|████████  | 81/100 [01:36<00:22,  1.20s/it] 82%|████████▏ | 82/100 [01:38<00:21,  1.20s/it] 83%|████████▎ | 83/100 [01:39<00:20,  1.20s/it] 84%|████████▍ | 84/100 [01:40<00:19,  1.20s/it] 85%|████████▌ | 85/100 [01:41<00:17,  1.20s/it] 86%|████████▌ | 86/100 [01:42<00:16,  1.20s/it] 87%|████████▋ | 87/100 [01:44<00:15,  1.20s/it] 88%|████████▊ | 88/100 [01:45<00:14,  1.20s/it] 89%|████████▉ | 89/100 [01:46<00:13,  1.20s/it] 90%|█████████ | 90/100 [01:47<00:12,  1.20s/it] 91%|█████████ | 91/100 [01:48<00:10,  1.20s/it] 92%|█████████▏| 92/100 [01:50<00:09,  1.20s/it] 93%|█████████▎| 93/100 [01:51<00:08,  1.20s/it] 94%|█████████▍| 94/100 [01:52<00:07,  1.20s/it] 95%|█████████▌| 95/100 [01:53<00:05,  1.20s/it] 96%|█████████▌| 96/100 [01:54<00:04,  1.20s/it] 97%|█████████▋| 97/100 [01:56<00:03,  1.20s/it] 98%|█████████▊| 98/100 [01:57<00:02,  1.20s/it] 99%|█████████▉| 99/100 [01:58<00:01,  1.20s/it]100%|██████████| 100/100 [01:59<00:00,  1.20s/it]100%|██████████| 100/100 [01:59<00:00,  1.20s/it]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:4'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:4'}
full model:
{'mrpc': {'alias': 'mrpc', 'acc,none': 0.7, 'acc_stderr,none': 0.04605661864718383, 'f1,none': np.float64(0.8214285714285714), 'f1_stderr,none': 0.0323693653386572}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.32375514242269293
0.9664141198776434
0.4263233992087649
0.29258192731768157
0.3497718342079178
0.5968480671674146
0.7870107004084098
0.7068508532201193
0.7836897379939763
0.2579819071737284
0.5774144903645764
0.7819348699339372
0.7404680063618143
0.651835611327285
0.6832243011482585
0.34680079188801705
0.6033476505145444
0.6299526106979766
0.6468468631829007
0.8458578364778718
0.39447753640727073
0.5291234791393744
0.944540808938638
0.8460909093145242
0.4915397062049404
0.5314721523201049
0.8670806018560002
0.6451914961665037
0.7380077491787214
0.32375514242269293
0.9664141198776434
0.4263233992087649
0.29258192731768157
0.3497718342079178
0.5968480671674146
0.7870107004084098
0.7068508532201193
0.7836897379939763
0.2579819071737284
0.5774144903645764
0.7819348699339372
0.7404680063618143
0.651835611327285
0.6832243011482585
0.34680079188801705
0.6033476505145444
0.6299526106979766
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[4, 5, 7, 1, 6, 2, 3, 0]
tensor([4, 5, 7, 1, 6, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 7, 4, 5, 0, 1, 2]
tensor([6, 3, 7, 4, 5, 0, 1, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 1, 7, 2, 6, 0, 3, 5]
tensor([4, 1, 7, 2, 6, 0, 3, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 5, 2, 7, 0, 4, 1]
tensor([6, 3, 5, 2, 7, 0, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 5, 6, 7, 3, 1, 0, 2]
tensor([4, 5, 6, 7, 3, 1, 0, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 1, 2, 4, 1, 0, 5]
tensor([0, 3, 1, 2, 4, 1, 0, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1.0, 1.0, 0, 1, 1.0]
tensor([0, 1, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1, 1.0, 1.0, 1.0, 0]
tensor([0, 1, 1, 1, 1, 1, 1, 0], dtype=torch.int32)
[0, 1]
Normal merging for layer 1
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([7])
tensor(7)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
done!
Normal merging for layer 2
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([7])
tensor(7)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([2])
tensor(2)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 4 to 5
done!
Normal merging for layer 6
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
done!
Cross-layer merge completed for layers 7 to 9
done!
Normal merging for layer 10
tensor([0, 6])
tensor(0)
tensor([2, 5])
tensor(2)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([4])
tensor(4)
tensor([7])
tensor(7)
done!
Cross-layer merge completed for layers 11 to 26
done!
Normal merging for layer 27
tensor([0, 5])
tensor(0)
tensor([1, 2, 3, 4, 6, 7])
tensor(1)
done!
Cross-layer merge completed for layers 28 to 30
done!
Normal merging for layer 31
tensor([0, 7])
tensor(0)
tensor([1, 2, 3, 4, 5, 6])
tensor(1)
done!
all done!
Model size: 12.3867 GB
140
cuda:4
mastermind_24_easy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:42<00:42, 42.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 24.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 27.29s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_24_mcq_random HTTP/1.1" 200 772
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/flair/mastermind_24_mcq_random/flair/mastermind_24_mcq_random.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_24_mcq_random HTTP/1.1" 200 779
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/flair/mastermind_24_mcq_random/resolve/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_24_mcq_random/revision/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 779
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_24_mcq_random/tree/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5?recursive=False&expand=False HTTP/1.1" 200 290
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_24_mcq_random/tree/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5/data?recursive=False&expand=False HTTP/1.1" 200 358
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_24_mcq_random/revision/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 779
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/flair/mastermind_24_mcq_random/resolve/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_24_mcq_random/paths-info/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5 HTTP/1.1" 200 218
DEBUG:filelock:Attempting to acquire lock 140237329981200 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_24_mcq_random_default_0.0.0_cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5.lock
DEBUG:filelock:Lock 140237329981200 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_24_mcq_random_default_0.0.0_cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_24_mcq_random/default/0.0.0/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5/dataset_info.json
DEBUG:filelock:Attempting to release lock 140237329981200 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_24_mcq_random_default_0.0.0_cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5.lock
DEBUG:filelock:Lock 140237329981200 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_24_mcq_random_default_0.0.0_cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5.lock
DEBUG:filelock:Attempting to acquire lock 140237329981584 on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_24_mcq_random/default/0.0.0/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5_builder.lock
DEBUG:filelock:Lock 140237329981584 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_24_mcq_random/default/0.0.0/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_24_mcq_random/default/0.0.0/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5/dataset_info.json
DEBUG:filelock:Attempting to release lock 140237329981584 on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_24_mcq_random/default/0.0.0/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5_builder.lock
DEBUG:filelock:Lock 140237329981584 released on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_24_mcq_random/default/0.0.0/cdc1332d34ece1ecdd2453e227ebdc3837b4a0c5_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mastermind_24_easy from None to 0
INFO:lm_eval.api.task:Building contexts for mastermind_24_easy on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1508.37it/s]
DEBUG:lm_eval.evaluator:Task: mastermind_24_easy; number of requests on this rank: 400
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/400 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/400 [00:01<09:49,  1.48s/it]Running loglikelihood requests:   0%|          | 2/400 [00:02<08:07,  1.22s/it]Running loglikelihood requests:   1%|          | 3/400 [00:03<07:33,  1.14s/it]Running loglikelihood requests:   1%|          | 4/400 [00:04<07:17,  1.10s/it]Running loglikelihood requests:   1%|▏         | 5/400 [00:05<07:06,  1.08s/it]Running loglikelihood requests:   2%|▏         | 6/400 [00:06<06:59,  1.06s/it]Running loglikelihood requests:   2%|▏         | 7/400 [00:07<06:53,  1.05s/it]Running loglikelihood requests:   2%|▏         | 8/400 [00:08<06:49,  1.05s/it]Running loglikelihood requests:   2%|▏         | 9/400 [00:09<06:47,  1.04s/it]Running loglikelihood requests:   2%|▎         | 10/400 [00:10<06:45,  1.04s/it]Running loglikelihood requests:   3%|▎         | 12/400 [00:11<05:07,  1.26it/s]Running loglikelihood requests:   3%|▎         | 13/400 [00:12<05:29,  1.17it/s]Running loglikelihood requests:   4%|▎         | 14/400 [00:13<05:47,  1.11it/s]Running loglikelihood requests:   4%|▍         | 16/400 [00:14<04:42,  1.36it/s]Running loglikelihood requests:   4%|▍         | 17/400 [00:15<05:07,  1.25it/s]Running loglikelihood requests:   4%|▍         | 18/400 [00:16<05:27,  1.17it/s]Running loglikelihood requests:   5%|▍         | 19/400 [00:18<05:43,  1.11it/s]Running loglikelihood requests:   5%|▌         | 20/400 [00:19<05:56,  1.07it/s]Running loglikelihood requests:   5%|▌         | 21/400 [00:20<06:04,  1.04it/s]Running loglikelihood requests:   6%|▌         | 22/400 [00:21<06:11,  1.02it/s]Running loglikelihood requests:   6%|▌         | 23/400 [00:22<06:15,  1.00it/s]Running loglikelihood requests:   6%|▋         | 25/400 [00:23<04:50,  1.29it/s]Running loglikelihood requests:   6%|▋         | 26/400 [00:24<05:12,  1.20it/s]Running loglikelihood requests:   7%|▋         | 27/400 [00:25<05:29,  1.13it/s]Running loglikelihood requests:   7%|▋         | 29/400 [00:26<04:29,  1.38it/s]Running loglikelihood requests:   8%|▊         | 30/400 [00:27<04:53,  1.26it/s]Running loglikelihood requests:   8%|▊         | 31/400 [00:28<05:13,  1.18it/s]Running loglikelihood requests:   8%|▊         | 32/400 [00:29<05:29,  1.12it/s]Running loglikelihood requests:   8%|▊         | 34/400 [00:30<04:27,  1.37it/s]Running loglikelihood requests:   9%|▉         | 35/400 [00:31<04:51,  1.25it/s]Running loglikelihood requests:  10%|▉         | 38/400 [00:32<03:25,  1.76it/s]Running loglikelihood requests:  10%|▉         | 39/400 [00:33<03:56,  1.53it/s]Running loglikelihood requests:  10%|█         | 40/400 [00:34<04:23,  1.37it/s]Running loglikelihood requests:  10%|█         | 41/400 [00:35<04:46,  1.25it/s]Running loglikelihood requests:  10%|█         | 42/400 [00:36<05:05,  1.17it/s]Running loglikelihood requests:  11%|█         | 43/400 [00:37<05:19,  1.12it/s]Running loglikelihood requests:  11%|█         | 44/400 [00:38<05:30,  1.08it/s]Running loglikelihood requests:  11%|█▏        | 45/400 [00:39<05:37,  1.05it/s]Running loglikelihood requests:  12%|█▏        | 47/400 [00:40<04:25,  1.33it/s]Running loglikelihood requests:  12%|█▏        | 48/400 [00:41<04:46,  1.23it/s]Running loglikelihood requests:  12%|█▏        | 49/400 [00:42<05:03,  1.16it/s]Running loglikelihood requests:  12%|█▎        | 50/400 [00:43<05:16,  1.11it/s]Running loglikelihood requests:  13%|█▎        | 52/400 [00:44<04:14,  1.37it/s]Running loglikelihood requests:  13%|█▎        | 53/400 [00:45<04:36,  1.26it/s]Running loglikelihood requests:  14%|█▎        | 54/400 [00:46<04:53,  1.18it/s]Running loglikelihood requests:  14%|█▍        | 56/400 [00:47<04:02,  1.42it/s]Running loglikelihood requests:  14%|█▍        | 57/400 [00:48<04:25,  1.29it/s]Running loglikelihood requests:  14%|█▍        | 58/400 [00:49<04:43,  1.21it/s]Running loglikelihood requests:  15%|█▍        | 59/400 [00:50<05:02,  1.13it/s]Running loglikelihood requests:  15%|█▌        | 60/400 [00:51<05:13,  1.08it/s]Running loglikelihood requests:  15%|█▌        | 61/400 [00:52<05:21,  1.05it/s]Running loglikelihood requests:  16%|█▌        | 62/400 [00:53<05:27,  1.03it/s]Running loglikelihood requests:  16%|█▌        | 63/400 [00:54<05:31,  1.02it/s]Running loglikelihood requests:  16%|█▌        | 64/400 [00:55<05:33,  1.01it/s]Running loglikelihood requests:  16%|█▋        | 65/400 [00:56<05:35,  1.00s/it]Running loglikelihood requests:  16%|█▋        | 66/400 [00:57<05:35,  1.00s/it]Running loglikelihood requests:  17%|█▋        | 67/400 [00:58<05:35,  1.01s/it]Running loglikelihood requests:  17%|█▋        | 68/400 [00:59<05:35,  1.01s/it]Running loglikelihood requests:  17%|█▋        | 69/400 [01:00<05:35,  1.01s/it]Running loglikelihood requests:  18%|█▊        | 70/400 [01:01<05:34,  1.01s/it]Running loglikelihood requests:  18%|█▊        | 71/400 [01:02<05:33,  1.01s/it]Running loglikelihood requests:  18%|█▊        | 72/400 [01:03<05:32,  1.01s/it]Running loglikelihood requests:  18%|█▊        | 73/400 [01:04<05:31,  1.01s/it]Running loglikelihood requests:  18%|█▊        | 74/400 [01:05<05:30,  1.01s/it]Running loglikelihood requests:  19%|█▉        | 76/400 [01:06<04:12,  1.28it/s]Running loglikelihood requests:  19%|█▉        | 77/400 [01:07<04:30,  1.20it/s]Running loglikelihood requests:  20%|█▉        | 78/400 [01:08<04:44,  1.13it/s]Running loglikelihood requests:  20%|█▉        | 79/400 [01:09<04:54,  1.09it/s]Running loglikelihood requests:  20%|██        | 80/400 [01:10<05:02,  1.06it/s]Running loglikelihood requests:  20%|██        | 81/400 [01:11<05:07,  1.04it/s]Running loglikelihood requests:  20%|██        | 82/400 [01:12<05:10,  1.03it/s]Running loglikelihood requests:  21%|██        | 83/400 [01:13<05:12,  1.02it/s]Running loglikelihood requests:  21%|██        | 84/400 [01:14<05:13,  1.01it/s]Running loglikelihood requests:  21%|██▏       | 85/400 [01:15<05:13,  1.00it/s]Running loglikelihood requests:  22%|██▏       | 87/400 [01:16<04:01,  1.30it/s]Running loglikelihood requests:  22%|██▏       | 88/400 [01:17<04:18,  1.21it/s]Running loglikelihood requests:  22%|██▏       | 89/400 [01:18<04:31,  1.14it/s]Running loglikelihood requests:  22%|██▎       | 90/400 [01:19<04:41,  1.10it/s]Running loglikelihood requests:  23%|██▎       | 91/400 [01:20<04:48,  1.07it/s]Running loglikelihood requests:  23%|██▎       | 92/400 [01:21<04:53,  1.05it/s]Running loglikelihood requests:  24%|██▎       | 94/400 [01:22<03:49,  1.33it/s]Running loglikelihood requests:  24%|██▍       | 95/400 [01:23<04:07,  1.23it/s]Running loglikelihood requests:  24%|██▍       | 96/400 [01:24<04:21,  1.16it/s]Running loglikelihood requests:  24%|██▍       | 98/400 [01:25<03:34,  1.41it/s]Running loglikelihood requests:  25%|██▌       | 100/400 [01:26<03:09,  1.59it/s]Running loglikelihood requests:  26%|██▌       | 102/400 [01:27<02:54,  1.71it/s]Running loglikelihood requests:  26%|██▌       | 103/400 [01:28<03:18,  1.50it/s]Running loglikelihood requests:  26%|██▌       | 104/400 [01:29<03:39,  1.35it/s]Running loglikelihood requests:  27%|██▋       | 107/400 [01:30<02:39,  1.84it/s]Running loglikelihood requests:  27%|██▋       | 108/400 [01:31<03:03,  1.59it/s]Running loglikelihood requests:  27%|██▋       | 109/400 [01:32<03:25,  1.41it/s]Running loglikelihood requests:  28%|██▊       | 110/400 [01:33<03:44,  1.29it/s]Running loglikelihood requests:  28%|██▊       | 111/400 [01:34<04:00,  1.20it/s]Running loglikelihood requests:  28%|██▊       | 112/400 [01:35<04:11,  1.14it/s]Running loglikelihood requests:  28%|██▊       | 113/400 [01:36<04:20,  1.10it/s]Running loglikelihood requests:  28%|██▊       | 114/400 [01:37<04:26,  1.07it/s]Running loglikelihood requests:  29%|██▉       | 116/400 [01:38<03:29,  1.35it/s]Running loglikelihood requests:  29%|██▉       | 117/400 [01:39<03:46,  1.25it/s]Running loglikelihood requests:  30%|██▉       | 118/400 [01:40<03:59,  1.18it/s]Running loglikelihood requests:  30%|███       | 121/400 [01:41<02:41,  1.73it/s]Running loglikelihood requests:  30%|███       | 122/400 [01:42<03:03,  1.51it/s]Running loglikelihood requests:  31%|███       | 123/400 [01:43<03:23,  1.36it/s]Running loglikelihood requests:  31%|███       | 124/400 [01:44<03:39,  1.26it/s]Running loglikelihood requests:  31%|███▏      | 125/400 [01:45<03:50,  1.19it/s]Running loglikelihood requests:  32%|███▏      | 126/400 [01:46<03:59,  1.14it/s]Running loglikelihood requests:  32%|███▏      | 127/400 [01:47<04:05,  1.11it/s]Running loglikelihood requests:  32%|███▏      | 128/400 [01:48<04:09,  1.09it/s]Running loglikelihood requests:  32%|███▎      | 130/400 [01:49<03:15,  1.38it/s]Running loglikelihood requests:  33%|███▎      | 132/400 [01:50<02:48,  1.59it/s]Running loglikelihood requests:  33%|███▎      | 133/400 [01:51<03:07,  1.42it/s]Running loglikelihood requests:  34%|███▎      | 134/400 [01:52<03:23,  1.31it/s]Running loglikelihood requests:  34%|███▍      | 135/400 [01:53<03:35,  1.23it/s]Running loglikelihood requests:  34%|███▍      | 136/400 [01:54<03:44,  1.17it/s]Running loglikelihood requests:  34%|███▍      | 137/400 [01:55<03:51,  1.13it/s]Running loglikelihood requests:  34%|███▍      | 138/400 [01:56<03:56,  1.11it/s]Running loglikelihood requests:  35%|███▍      | 139/400 [01:57<03:59,  1.09it/s]Running loglikelihood requests:  35%|███▌      | 140/400 [01:58<04:01,  1.08it/s]Running loglikelihood requests:  35%|███▌      | 141/400 [01:59<04:02,  1.07it/s]Running loglikelihood requests:  36%|███▌      | 142/400 [02:00<04:02,  1.06it/s]Running loglikelihood requests:  36%|███▌      | 143/400 [02:01<04:03,  1.06it/s]Running loglikelihood requests:  36%|███▋      | 145/400 [02:02<03:06,  1.37it/s]Running loglikelihood requests:  36%|███▋      | 146/400 [02:03<03:19,  1.27it/s]Running loglikelihood requests:  37%|███▋      | 147/400 [02:04<03:29,  1.21it/s]Running loglikelihood requests:  37%|███▋      | 148/400 [02:05<03:37,  1.16it/s]Running loglikelihood requests:  37%|███▋      | 149/400 [02:05<03:43,  1.12it/s]Running loglikelihood requests:  38%|███▊      | 150/400 [02:06<03:46,  1.10it/s]Running loglikelihood requests:  38%|███▊      | 152/400 [02:07<02:57,  1.40it/s]Running loglikelihood requests:  38%|███▊      | 153/400 [02:08<03:10,  1.29it/s]Running loglikelihood requests:  38%|███▊      | 154/400 [02:09<03:21,  1.22it/s]Running loglikelihood requests:  39%|███▉      | 155/400 [02:10<03:29,  1.17it/s]Running loglikelihood requests:  39%|███▉      | 157/400 [02:11<02:47,  1.45it/s]Running loglikelihood requests:  40%|███▉      | 158/400 [02:12<03:02,  1.33it/s]Running loglikelihood requests:  40%|████      | 160/400 [02:13<02:36,  1.53it/s]Running loglikelihood requests:  40%|████      | 161/400 [02:14<02:52,  1.39it/s]Running loglikelihood requests:  40%|████      | 162/400 [02:15<03:04,  1.29it/s]Running loglikelihood requests:  41%|████      | 163/400 [02:16<03:14,  1.22it/s]Running loglikelihood requests:  41%|████▏     | 165/400 [02:17<02:38,  1.48it/s]Running loglikelihood requests:  42%|████▏     | 166/400 [02:18<02:52,  1.36it/s]Running loglikelihood requests:  42%|████▏     | 167/400 [02:19<03:04,  1.27it/s]Running loglikelihood requests:  42%|████▏     | 168/400 [02:20<03:12,  1.20it/s]Running loglikelihood requests:  42%|████▎     | 170/400 [02:21<02:36,  1.47it/s]Running loglikelihood requests:  43%|████▎     | 171/400 [02:22<02:49,  1.35it/s]Running loglikelihood requests:  43%|████▎     | 172/400 [02:23<03:01,  1.26it/s]Running loglikelihood requests:  43%|████▎     | 173/400 [02:24<03:09,  1.20it/s]Running loglikelihood requests:  44%|████▎     | 174/400 [02:25<03:15,  1.15it/s]Running loglikelihood requests:  44%|████▍     | 175/400 [02:25<03:20,  1.12it/s]Running loglikelihood requests:  44%|████▍     | 176/400 [02:26<03:22,  1.10it/s]Running loglikelihood requests:  44%|████▍     | 178/400 [02:27<02:38,  1.40it/s]Running loglikelihood requests:  45%|████▍     | 179/400 [02:28<02:50,  1.30it/s]Running loglikelihood requests:  45%|████▌     | 180/400 [02:29<02:59,  1.23it/s]Running loglikelihood requests:  45%|████▌     | 181/400 [02:30<03:06,  1.17it/s]Running loglikelihood requests:  46%|████▌     | 183/400 [02:31<02:29,  1.45it/s]Running loglikelihood requests:  46%|████▌     | 184/400 [02:32<02:41,  1.33it/s]Running loglikelihood requests:  47%|████▋     | 187/400 [02:33<01:53,  1.88it/s]Running loglikelihood requests:  47%|████▋     | 188/400 [02:34<02:09,  1.63it/s]Running loglikelihood requests:  47%|████▋     | 189/400 [02:35<02:24,  1.46it/s]Running loglikelihood requests:  48%|████▊     | 190/400 [02:36<02:36,  1.34it/s]Running loglikelihood requests:  48%|████▊     | 191/400 [02:37<02:46,  1.26it/s]Running loglikelihood requests:  48%|████▊     | 192/400 [02:38<02:53,  1.20it/s]Running loglikelihood requests:  48%|████▊     | 193/400 [02:39<02:59,  1.16it/s]Running loglikelihood requests:  48%|████▊     | 194/400 [02:40<03:02,  1.13it/s]Running loglikelihood requests:  49%|████▉     | 196/400 [02:41<02:23,  1.42it/s]Running loglikelihood requests:  49%|████▉     | 197/400 [02:42<02:34,  1.31it/s]Running loglikelihood requests:  50%|████▉     | 198/400 [02:43<02:43,  1.24it/s]Running loglikelihood requests:  50%|████▉     | 199/400 [02:43<02:50,  1.18it/s]Running loglikelihood requests:  50%|█████     | 200/400 [02:44<02:54,  1.14it/s]Running loglikelihood requests:  50%|█████     | 202/400 [02:45<02:17,  1.44it/s]Running loglikelihood requests:  51%|█████     | 203/400 [02:46<02:28,  1.32it/s]Running loglikelihood requests:  51%|█████     | 204/400 [02:47<02:37,  1.24it/s]Running loglikelihood requests:  51%|█████▏    | 205/400 [02:48<02:43,  1.19it/s]Running loglikelihood requests:  52%|█████▏    | 206/400 [02:49<02:48,  1.15it/s]Running loglikelihood requests:  52%|█████▏    | 207/400 [02:50<02:51,  1.12it/s]Running loglikelihood requests:  52%|█████▎    | 210/400 [02:51<01:49,  1.74it/s]Running loglikelihood requests:  53%|█████▎    | 212/400 [02:52<01:41,  1.85it/s]Running loglikelihood requests:  53%|█████▎    | 213/400 [02:53<01:55,  1.61it/s]Running loglikelihood requests:  54%|█████▍    | 215/400 [02:54<01:44,  1.76it/s]Running loglikelihood requests:  54%|█████▍    | 216/400 [02:55<01:58,  1.55it/s]Running loglikelihood requests:  54%|█████▍    | 217/400 [02:56<02:10,  1.40it/s]Running loglikelihood requests:  55%|█████▍    | 219/400 [02:57<01:51,  1.62it/s]Running loglikelihood requests:  55%|█████▌    | 220/400 [02:58<02:04,  1.45it/s]Running loglikelihood requests:  55%|█████▌    | 221/400 [02:59<02:14,  1.33it/s]Running loglikelihood requests:  56%|█████▌    | 222/400 [03:00<02:22,  1.25it/s]Running loglikelihood requests:  56%|█████▌    | 223/400 [03:01<02:28,  1.19it/s]Running loglikelihood requests:  56%|█████▌    | 224/400 [03:01<02:32,  1.15it/s]Running loglikelihood requests:  56%|█████▋    | 225/400 [03:02<02:35,  1.13it/s]Running loglikelihood requests:  56%|█████▋    | 226/400 [03:03<02:37,  1.11it/s]Running loglikelihood requests:  57%|█████▋    | 227/400 [03:04<02:38,  1.09it/s]Running loglikelihood requests:  57%|█████▋    | 228/400 [03:05<02:38,  1.08it/s]Running loglikelihood requests:  57%|█████▋    | 229/400 [03:06<02:38,  1.08it/s]Running loglikelihood requests:  57%|█████▊    | 230/400 [03:07<02:38,  1.07it/s]Running loglikelihood requests:  58%|█████▊    | 231/400 [03:08<02:37,  1.07it/s]Running loglikelihood requests:  58%|█████▊    | 232/400 [03:09<02:37,  1.07it/s]Running loglikelihood requests:  58%|█████▊    | 233/400 [03:10<02:36,  1.07it/s]Running loglikelihood requests:  59%|█████▉    | 235/400 [03:11<01:59,  1.39it/s]Running loglikelihood requests:  59%|█████▉    | 236/400 [03:12<02:07,  1.29it/s]Running loglikelihood requests:  59%|█████▉    | 237/400 [03:13<02:13,  1.22it/s]Running loglikelihood requests:  60%|█████▉    | 238/400 [03:14<02:18,  1.17it/s]Running loglikelihood requests:  60%|█████▉    | 239/400 [03:15<02:21,  1.14it/s]Running loglikelihood requests:  60%|██████    | 240/400 [03:16<02:22,  1.12it/s]Running loglikelihood requests:  60%|██████    | 242/400 [03:16<01:50,  1.43it/s]Running loglikelihood requests:  61%|██████    | 243/400 [03:17<01:58,  1.33it/s]Running loglikelihood requests:  61%|██████    | 244/400 [03:18<02:04,  1.26it/s]Running loglikelihood requests:  61%|██████▏   | 245/400 [03:19<02:08,  1.21it/s]Running loglikelihood requests:  62%|██████▏   | 246/400 [03:20<02:11,  1.17it/s]Running loglikelihood requests:  62%|██████▏   | 247/400 [03:21<02:13,  1.15it/s]Running loglikelihood requests:  62%|██████▏   | 249/400 [03:22<01:43,  1.46it/s]Running loglikelihood requests:  62%|██████▎   | 250/400 [03:23<01:51,  1.35it/s]Running loglikelihood requests:  63%|██████▎   | 251/400 [03:24<01:57,  1.27it/s]Running loglikelihood requests:  63%|██████▎   | 252/400 [03:25<02:01,  1.22it/s]Running loglikelihood requests:  63%|██████▎   | 253/400 [03:26<02:04,  1.18it/s]Running loglikelihood requests:  64%|██████▎   | 254/400 [03:27<02:06,  1.15it/s]Running loglikelihood requests:  64%|██████▍   | 255/400 [03:27<02:07,  1.13it/s]Running loglikelihood requests:  64%|██████▍   | 256/400 [03:28<02:08,  1.12it/s]Running loglikelihood requests:  64%|██████▍   | 257/400 [03:29<02:08,  1.11it/s]Running loglikelihood requests:  64%|██████▍   | 258/400 [03:30<02:08,  1.11it/s]Running loglikelihood requests:  65%|██████▌   | 260/400 [03:31<01:37,  1.43it/s]Running loglikelihood requests:  65%|██████▌   | 261/400 [03:32<01:44,  1.33it/s]Running loglikelihood requests:  66%|██████▌   | 264/400 [03:33<01:11,  1.91it/s]Running loglikelihood requests:  66%|██████▋   | 265/400 [03:34<01:21,  1.66it/s]Running loglikelihood requests:  66%|██████▋   | 266/400 [03:35<01:29,  1.49it/s]Running loglikelihood requests:  67%|██████▋   | 267/400 [03:36<01:36,  1.37it/s]Running loglikelihood requests:  67%|██████▋   | 268/400 [03:37<01:42,  1.29it/s]Running loglikelihood requests:  67%|██████▋   | 269/400 [03:38<01:46,  1.23it/s]Running loglikelihood requests:  68%|██████▊   | 270/400 [03:38<01:49,  1.19it/s]Running loglikelihood requests:  68%|██████▊   | 271/400 [03:39<01:50,  1.16it/s]Running loglikelihood requests:  68%|██████▊   | 272/400 [03:40<01:52,  1.14it/s]Running loglikelihood requests:  68%|██████▊   | 273/400 [03:41<01:52,  1.13it/s]Running loglikelihood requests:  68%|██████▊   | 274/400 [03:42<01:52,  1.12it/s]Running loglikelihood requests:  69%|██████▉   | 277/400 [03:43<01:09,  1.77it/s]Running loglikelihood requests:  70%|██████▉   | 279/400 [03:44<01:03,  1.90it/s]Running loglikelihood requests:  70%|███████   | 281/400 [03:45<00:59,  1.99it/s]Running loglikelihood requests:  71%|███████   | 284/400 [03:46<00:48,  2.38it/s]Running loglikelihood requests:  71%|███████▏  | 285/400 [03:47<00:57,  2.00it/s]Running loglikelihood requests:  72%|███████▏  | 286/400 [03:48<01:05,  1.73it/s]Running loglikelihood requests:  72%|███████▏  | 287/400 [03:48<01:13,  1.54it/s]Running loglikelihood requests:  72%|███████▏  | 288/400 [03:49<01:19,  1.41it/s]Running loglikelihood requests:  72%|███████▏  | 289/400 [03:50<01:24,  1.32it/s]Running loglikelihood requests:  72%|███████▎  | 290/400 [03:51<01:27,  1.26it/s]Running loglikelihood requests:  73%|███████▎  | 291/400 [03:52<01:29,  1.21it/s]Running loglikelihood requests:  73%|███████▎  | 293/400 [03:53<01:10,  1.51it/s]Running loglikelihood requests:  74%|███████▎  | 294/400 [03:54<01:16,  1.39it/s]Running loglikelihood requests:  74%|███████▍  | 295/400 [03:55<01:20,  1.30it/s]Running loglikelihood requests:  74%|███████▍  | 296/400 [03:56<01:23,  1.24it/s]Running loglikelihood requests:  74%|███████▍  | 297/400 [03:57<01:25,  1.20it/s]Running loglikelihood requests:  75%|███████▍  | 299/400 [03:58<01:07,  1.50it/s]Running loglikelihood requests:  75%|███████▌  | 300/400 [03:58<01:12,  1.38it/s]Running loglikelihood requests:  75%|███████▌  | 301/400 [03:59<01:16,  1.30it/s]Running loglikelihood requests:  76%|███████▌  | 302/400 [04:00<01:18,  1.24it/s]Running loglikelihood requests:  76%|███████▌  | 304/400 [04:01<01:02,  1.53it/s]Running loglikelihood requests:  76%|███████▋  | 305/400 [04:02<01:07,  1.41it/s]Running loglikelihood requests:  77%|███████▋  | 307/400 [04:03<00:56,  1.65it/s]Running loglikelihood requests:  77%|███████▋  | 309/400 [04:04<00:49,  1.82it/s]Running loglikelihood requests:  78%|███████▊  | 310/400 [04:05<00:55,  1.61it/s]Running loglikelihood requests:  78%|███████▊  | 311/400 [04:06<01:00,  1.46it/s]Running loglikelihood requests:  78%|███████▊  | 312/400 [04:07<01:04,  1.36it/s]Running loglikelihood requests:  78%|███████▊  | 313/400 [04:07<01:07,  1.28it/s]Running loglikelihood requests:  79%|███████▉  | 315/400 [04:08<00:54,  1.57it/s]Running loglikelihood requests:  79%|███████▉  | 317/400 [04:09<00:47,  1.76it/s]Running loglikelihood requests:  80%|███████▉  | 318/400 [04:10<00:52,  1.57it/s]Running loglikelihood requests:  80%|███████▉  | 319/400 [04:11<00:56,  1.43it/s]Running loglikelihood requests:  80%|████████  | 321/400 [04:12<00:47,  1.67it/s]Running loglikelihood requests:  81%|████████  | 323/400 [04:13<00:41,  1.84it/s]Running loglikelihood requests:  82%|████████▏ | 326/400 [04:14<00:32,  2.29it/s]Running loglikelihood requests:  82%|████████▏ | 327/400 [04:15<00:37,  1.93it/s]Running loglikelihood requests:  82%|████████▏ | 328/400 [04:16<00:42,  1.68it/s]Running loglikelihood requests:  82%|████████▏ | 329/400 [04:16<00:47,  1.51it/s]Running loglikelihood requests:  82%|████████▎ | 330/400 [04:17<00:50,  1.39it/s]Running loglikelihood requests:  83%|████████▎ | 332/400 [04:18<00:41,  1.64it/s]Running loglikelihood requests:  83%|████████▎ | 333/400 [04:19<00:45,  1.48it/s]Running loglikelihood requests:  84%|████████▎ | 334/400 [04:20<00:48,  1.37it/s]Running loglikelihood requests:  84%|████████▍ | 335/400 [04:21<00:50,  1.30it/s]Running loglikelihood requests:  84%|████████▍ | 336/400 [04:22<00:51,  1.24it/s]Running loglikelihood requests:  84%|████████▍ | 337/400 [04:23<00:52,  1.20it/s]Running loglikelihood requests:  84%|████████▍ | 338/400 [04:24<00:52,  1.18it/s]Running loglikelihood requests:  85%|████████▍ | 339/400 [04:25<00:52,  1.16it/s]Running loglikelihood requests:  85%|████████▌ | 340/400 [04:25<00:52,  1.15it/s]Running loglikelihood requests:  85%|████████▌ | 341/400 [04:26<00:50,  1.17it/s]Running loglikelihood requests:  86%|████████▌ | 342/400 [04:27<00:49,  1.18it/s]Running loglikelihood requests:  86%|████████▌ | 343/400 [04:28<00:47,  1.20it/s]Running loglikelihood requests:  86%|████████▋ | 346/400 [04:29<00:28,  1.92it/s]Running loglikelihood requests:  87%|████████▋ | 348/400 [04:29<00:24,  2.08it/s]Running loglikelihood requests:  87%|████████▋ | 349/400 [04:30<00:27,  1.83it/s]Running loglikelihood requests:  88%|████████▊ | 350/400 [04:31<00:30,  1.65it/s]Running loglikelihood requests:  88%|████████▊ | 351/400 [04:32<00:32,  1.52it/s]Running loglikelihood requests:  88%|████████▊ | 352/400 [04:33<00:33,  1.44it/s]Running loglikelihood requests:  88%|████████▊ | 353/400 [04:34<00:34,  1.37it/s]Running loglikelihood requests:  88%|████████▊ | 354/400 [04:34<00:34,  1.33it/s]Running loglikelihood requests:  89%|████████▉ | 355/400 [04:35<00:34,  1.30it/s]Running loglikelihood requests:  89%|████████▉ | 356/400 [04:36<00:34,  1.28it/s]Running loglikelihood requests:  90%|████████▉ | 358/400 [04:37<00:25,  1.64it/s]Running loglikelihood requests:  90%|████████▉ | 359/400 [04:38<00:27,  1.52it/s]Running loglikelihood requests:  90%|█████████ | 360/400 [04:38<00:27,  1.43it/s]Running loglikelihood requests:  90%|█████████ | 361/400 [04:39<00:28,  1.37it/s]Running loglikelihood requests:  90%|█████████ | 362/400 [04:40<00:28,  1.33it/s]Running loglikelihood requests:  91%|█████████ | 364/400 [04:41<00:21,  1.67it/s]Running loglikelihood requests:  91%|█████████▏| 365/400 [04:42<00:22,  1.54it/s]Running loglikelihood requests:  92%|█████████▏| 367/400 [04:42<00:18,  1.82it/s]Running loglikelihood requests:  92%|█████████▏| 368/400 [04:43<00:19,  1.64it/s]Running loglikelihood requests:  92%|█████████▏| 369/400 [04:44<00:20,  1.52it/s]Running loglikelihood requests:  92%|█████████▎| 370/400 [04:45<00:20,  1.43it/s]Running loglikelihood requests:  93%|█████████▎| 371/400 [04:46<00:21,  1.37it/s]Running loglikelihood requests:  93%|█████████▎| 373/400 [04:47<00:15,  1.70it/s]Running loglikelihood requests:  94%|█████████▍| 375/400 [04:47<00:12,  1.93it/s]Running loglikelihood requests:  94%|█████████▍| 376/400 [04:48<00:13,  1.72it/s]Running loglikelihood requests:  95%|█████████▍| 379/400 [04:49<00:09,  2.32it/s]Running loglikelihood requests:  95%|█████████▌| 381/400 [04:50<00:08,  2.37it/s]Running loglikelihood requests:  96%|█████████▌| 382/400 [04:51<00:08,  2.03it/s]Running loglikelihood requests:  96%|█████████▌| 384/400 [04:51<00:07,  2.16it/s]Running loglikelihood requests:  96%|█████████▋| 386/400 [04:52<00:06,  2.26it/s]Running loglikelihood requests:  97%|█████████▋| 387/400 [04:53<00:06,  1.96it/s]Running loglikelihood requests:  97%|█████████▋| 389/400 [04:54<00:05,  2.11it/s]Running loglikelihood requests:  98%|█████████▊| 391/400 [04:55<00:04,  2.22it/s]Running loglikelihood requests:  98%|█████████▊| 393/400 [04:55<00:03,  2.30it/s]Running loglikelihood requests:  99%|█████████▉| 395/400 [04:56<00:02,  2.36it/s]Running loglikelihood requests:  99%|█████████▉| 397/400 [04:57<00:01,  2.40it/s]Running loglikelihood requests: 100%|█████████▉| 398/400 [04:58<00:00,  2.05it/s]Running loglikelihood requests: 100%|██████████| 400/400 [04:59<00:00,  2.19it/s]Running loglikelihood requests: 100%|██████████| 400/400 [04:59<00:00,  1.34it/s]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:5'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:5'}
full model:
{'mastermind_24_easy': {'alias': 'mastermind_24_easy', 'acc,none': 0.33, 'acc_stderr,none': 0.04725815626252609}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9705388716727775
0.9880227828623074
0.982119607496995
0.9941469535767887
0.984917378949356
0.9883609317461776
0.9752442385272352
0.9858149677985593
0.9966001900863091
0.9954965780195978
0.9982374916142641
0.987839947084121
0.9740425263242771
0.9802324544963317
0.9965978314947238
0.9890806289155061
0.971808392501808
0.9767123038440666
0.9820534501654181
0.9672299205809463
0.9753579231968917
0.9973837437819523
0.9951994747100236
0.9465102818948206
0.9757933184251313
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[7, 0, 1, 3, 6, 5, 4, 2]
tensor([7, 0, 1, 3, 6, 5, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 0, 1, 3, 7, 5, 4, 2]
tensor([6, 0, 1, 3, 7, 5, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 0, 1, 3, 6, 5, 4, 2]
tensor([7, 0, 1, 3, 6, 5, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 0, 1, 3, 7, 5, 4, 2]
tensor([6, 0, 1, 3, 7, 5, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 0, 1, 3, 6, 5, 4, 2]
tensor([7, 0, 1, 3, 6, 5, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 0, 2, 3, 6, 5, 4, 1]
tensor([7, 0, 2, 3, 6, 5, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Normal merging for layer 2
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
done!
Normal merging for layer 3
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Normal merging for layer 4
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
done!
Normal merging for layer 5
tensor([1])
tensor(1)
tensor([7])
tensor(7)
tensor([2])
tensor(2)
tensor([3])
tensor(3)
tensor([6])
tensor(6)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 6 to 31
done!
all done!
Model size: 12.0718 GB
219
cuda:5
boolq
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:41<00:41, 41.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:53<00:00, 24.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:53<00:00, 26.72s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: boolq] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: boolq] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/super_glue/super_glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 237
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 237
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 237
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 237
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 237
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 237
DEBUG:filelock:Attempting to acquire lock 140218667589152 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_boolq_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 140218667589152 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_boolq_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/boolq/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 140218667589152 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_boolq_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 140218667589152 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_boolq_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Attempting to acquire lock 140239479667696 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/boolq/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 140239479667696 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/boolq/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/boolq/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 140239479667696 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/boolq/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 140239479667696 released on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/boolq/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of boolq from None to 0
INFO:lm_eval.api.task:Building contexts for boolq on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 2588.85it/s]
DEBUG:lm_eval.evaluator:Task: boolq; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:04<13:40,  4.12s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:05<05:45,  1.75s/it]Running loglikelihood requests:   2%|▎         | 5/200 [00:07<04:15,  1.31s/it]Running loglikelihood requests:   4%|▎         | 7/200 [00:09<03:36,  1.12s/it]Running loglikelihood requests:   4%|▍         | 9/200 [00:11<03:12,  1.01s/it]Running loglikelihood requests:   6%|▌         | 11/200 [00:12<02:56,  1.07it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:14<02:45,  1.13it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:15<02:36,  1.18it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:17<02:29,  1.22it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:18<02:23,  1.26it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:20<02:18,  1.29it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:21<02:14,  1.32it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:23<02:10,  1.34it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:24<02:07,  1.36it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:25<02:04,  1.37it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:27<02:01,  1.39it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:28<01:59,  1.40it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:30<01:56,  1.41it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:31<01:54,  1.43it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:32<01:52,  1.44it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:34<01:50,  1.45it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:35<01:48,  1.45it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:36<01:45,  1.47it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:38<01:43,  1.48it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:39<01:40,  1.50it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:40<01:38,  1.52it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:42<01:36,  1.53it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:43<01:34,  1.54it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:44<01:31,  1.55it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:45<01:29,  1.57it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:47<01:27,  1.59it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:48<01:25,  1.60it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:49<01:24,  1.61it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:50<01:22,  1.62it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:52<01:20,  1.63it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:53<01:17,  1.66it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:54<01:15,  1.68it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:55<01:13,  1.70it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:56<01:11,  1.72it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:57<01:09,  1.74it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:58<01:07,  1.75it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:59<01:06,  1.76it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [01:01<01:04,  1.77it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [01:02<01:03,  1.78it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [01:03<01:01,  1.79it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [01:04<01:00,  1.79it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [01:05<00:59,  1.80it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [01:06<00:57,  1.81it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [01:07<00:56,  1.82it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [01:08<00:55,  1.83it/s]Running loglikelihood requests:  50%|█████     | 101/200 [01:09<00:53,  1.85it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [01:10<00:52,  1.86it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [01:11<00:50,  1.87it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [01:12<00:49,  1.88it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [01:14<00:48,  1.89it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [01:15<00:46,  1.90it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [01:16<00:45,  1.90it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [01:17<00:44,  1.91it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [01:18<00:43,  1.92it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [01:19<00:41,  1.94it/s]Running loglikelihood requests:  60%|██████    | 121/200 [01:20<00:40,  1.96it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [01:21<00:38,  1.98it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [01:22<00:37,  2.01it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [01:23<00:35,  2.03it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [01:24<00:34,  2.06it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [01:24<00:32,  2.09it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [01:25<00:31,  2.12it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [01:26<00:30,  2.14it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [01:27<00:29,  2.16it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [01:28<00:28,  2.17it/s]Running loglikelihood requests:  70%|███████   | 141/200 [01:29<00:26,  2.19it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [01:30<00:25,  2.22it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [01:31<00:24,  2.25it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [01:32<00:23,  2.27it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [01:32<00:22,  2.29it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [01:33<00:21,  2.31it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [01:34<00:20,  2.31it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [01:35<00:19,  2.33it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [01:36<00:18,  2.36it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [01:37<00:17,  2.39it/s]Running loglikelihood requests:  80%|████████  | 161/200 [01:37<00:16,  2.40it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [01:38<00:15,  2.43it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [01:39<00:14,  2.45it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [01:40<00:13,  2.47it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [01:41<00:12,  2.49it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [01:41<00:11,  2.53it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [01:42<00:10,  2.57it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [01:43<00:09,  2.61it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [01:44<00:08,  2.64it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [01:44<00:07,  2.67it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [01:45<00:07,  2.69it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [01:46<00:06,  2.71it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [01:47<00:05,  2.75it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [01:47<00:04,  2.80it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [01:48<00:03,  2.84it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [01:49<00:03,  2.87it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [01:49<00:02,  2.89it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:50<00:01,  2.95it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:50<00:00,  3.07it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:51<00:00,  3.23it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:51<00:00,  1.79it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:6'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:6'}
full model:
{'boolq': {'alias': 'boolq', 'acc,none': 0.67, 'acc_stderr,none': 0.04725815626252609}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9782993007407264
0.4824830207482711
0.6583529368570694
0.8822475410601947
0.3059812833421515
0.7645942683746021
0.5411564675926485
0.6399758236302138
0.752913626333875
0.9170504110771489
0.8755679311709376
0.9130694495301263
0.6399088029710222
0.5907791688883935
0.8704540476128766
0.484807489124531
0.7579322019225017
0.8465026175931075
0.8104840653949666
0.671147278193032
0.7709951349967222
0.532915988335396
0.6066099270395096
0.5511989097245372
0.4671998655475952
0.6078287002452507
0.3992240879306912
0.5299030614769079
0.5709371890677749
0.9782993007407264
0.4824830207482711
0.6583529368570694
0.8822475410601947
0.3059812833421515
0.7645942683746021
0.5411564675926485
0.6399758236302138
0.752913626333875
0.9170504110771489
0.8755679311709376
0.9130694495301263
0.6399088029710222
0.5907791688883935
0.8704540476128766
0.484807489124531
0.7579322019225017
0.8465026175931075
0.8104840653949666
0.671147278193032
0.7709951349967222
0.532915988335396
0.6066099270395096
0.5511989097245372
0.4671998655475952
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[6, 2, 7, 0, 5, 3, 4, 1]
tensor([6, 2, 7, 0, 5, 3, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 2, 3, 0, 6, 1, 4, 5]
tensor([7, 2, 3, 0, 6, 1, 4, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 1, 7, 0, 6, 4, 2, 3]
tensor([5, 1, 7, 0, 6, 4, 2, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 3, 5, 1, 7, 2, 6, 0]
tensor([4, 3, 5, 1, 7, 2, 6, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[1, 6, 7, 3, 4, 5, 0, 2]
tensor([1, 6, 7, 3, 4, 5, 0, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 4, 1, 7, 2, 5, 0]
tensor([6, 3, 4, 1, 7, 2, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([7])
tensor(7)
tensor([4])
tensor(4)
tensor([0])
tensor(0)
done!
Normal merging for layer 2
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
tensor([2])
tensor(2)
done!
Normal merging for layer 3
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
done!
Normal merging for layer 4
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
done!
Normal merging for layer 5
tensor([7])
tensor(7)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([1])
tensor(1)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 6 to 31
done!
all done!
Model size: 12.0718 GB
151
cuda:6
wic
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:41<00:41, 41.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:53<00:00, 24.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:53<00:00, 26.94s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wic] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wic] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/super_glue/super_glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/super_glue HTTP/1.1" 307 63
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/aps/super_glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 234
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/aps/super_glue/resolve/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 235
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 307 115
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/aps/super_glue/paths-info/3de24cf8022e94f4ee4b9d55a6f539891524d646 HTTP/1.1" 200 235
DEBUG:filelock:Attempting to acquire lock 140243031275664 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_wic_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 140243031275664 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_wic_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wic/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 140243031275664 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_wic_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Lock 140243031275664 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_super_glue_wic_0.0.0_3de24cf8022e94f4ee4b9d55a6f539891524d646.lock
DEBUG:filelock:Attempting to acquire lock 140237333793056 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wic/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 140237333793056 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wic/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wic/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646/dataset_info.json
DEBUG:filelock:Attempting to release lock 140237333793056 on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wic/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:filelock:Lock 140237333793056 released on /public/home/zouyifei001/.cache/huggingface/datasets/super_glue/wic/0.0.0/3de24cf8022e94f4ee4b9d55a6f539891524d646_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wic from None to 0
INFO:lm_eval.api.task:Building contexts for wic on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1576.32it/s]
DEBUG:lm_eval.evaluator:Task: wic; number of requests on this rank: 200
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/200 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/200 [00:01<03:46,  1.14s/it]Running loglikelihood requests:   2%|▏         | 3/200 [00:01<01:48,  1.82it/s]Running loglikelihood requests:   2%|▎         | 5/200 [00:02<01:26,  2.26it/s]Running loglikelihood requests:   4%|▎         | 7/200 [00:03<01:17,  2.51it/s]Running loglikelihood requests:   4%|▍         | 9/200 [00:03<01:11,  2.67it/s]Running loglikelihood requests:   6%|▌         | 11/200 [00:04<01:08,  2.77it/s]Running loglikelihood requests:   6%|▋         | 13/200 [00:05<01:05,  2.86it/s]Running loglikelihood requests:   8%|▊         | 15/200 [00:05<01:03,  2.92it/s]Running loglikelihood requests:   8%|▊         | 17/200 [00:06<01:01,  2.97it/s]Running loglikelihood requests:  10%|▉         | 19/200 [00:07<01:00,  3.00it/s]Running loglikelihood requests:  10%|█         | 21/200 [00:07<00:59,  3.03it/s]Running loglikelihood requests:  12%|█▏        | 23/200 [00:08<00:58,  3.05it/s]Running loglikelihood requests:  12%|█▎        | 25/200 [00:09<00:57,  3.06it/s]Running loglikelihood requests:  14%|█▎        | 27/200 [00:09<00:56,  3.07it/s]Running loglikelihood requests:  14%|█▍        | 29/200 [00:10<00:55,  3.09it/s]Running loglikelihood requests:  16%|█▌        | 31/200 [00:11<00:54,  3.09it/s]Running loglikelihood requests:  16%|█▋        | 33/200 [00:11<00:53,  3.11it/s]Running loglikelihood requests:  18%|█▊        | 35/200 [00:12<00:52,  3.13it/s]Running loglikelihood requests:  18%|█▊        | 37/200 [00:12<00:51,  3.14it/s]Running loglikelihood requests:  20%|█▉        | 39/200 [00:13<00:51,  3.16it/s]Running loglikelihood requests:  20%|██        | 41/200 [00:14<00:50,  3.17it/s]Running loglikelihood requests:  22%|██▏       | 43/200 [00:14<00:49,  3.18it/s]Running loglikelihood requests:  22%|██▎       | 45/200 [00:15<00:48,  3.18it/s]Running loglikelihood requests:  24%|██▎       | 47/200 [00:16<00:48,  3.18it/s]Running loglikelihood requests:  24%|██▍       | 49/200 [00:16<00:47,  3.19it/s]Running loglikelihood requests:  26%|██▌       | 51/200 [00:17<00:46,  3.19it/s]Running loglikelihood requests:  26%|██▋       | 53/200 [00:17<00:45,  3.20it/s]Running loglikelihood requests:  28%|██▊       | 55/200 [00:18<00:45,  3.20it/s]Running loglikelihood requests:  28%|██▊       | 57/200 [00:19<00:44,  3.21it/s]Running loglikelihood requests:  30%|██▉       | 59/200 [00:19<00:43,  3.21it/s]Running loglikelihood requests:  30%|███       | 61/200 [00:20<00:43,  3.21it/s]Running loglikelihood requests:  32%|███▏      | 63/200 [00:21<00:42,  3.21it/s]Running loglikelihood requests:  32%|███▎      | 65/200 [00:21<00:42,  3.21it/s]Running loglikelihood requests:  34%|███▎      | 67/200 [00:22<00:41,  3.22it/s]Running loglikelihood requests:  34%|███▍      | 69/200 [00:22<00:40,  3.22it/s]Running loglikelihood requests:  36%|███▌      | 71/200 [00:23<00:39,  3.23it/s]Running loglikelihood requests:  36%|███▋      | 73/200 [00:24<00:39,  3.24it/s]Running loglikelihood requests:  38%|███▊      | 75/200 [00:24<00:38,  3.25it/s]Running loglikelihood requests:  38%|███▊      | 77/200 [00:25<00:37,  3.25it/s]Running loglikelihood requests:  40%|███▉      | 79/200 [00:25<00:37,  3.26it/s]Running loglikelihood requests:  40%|████      | 81/200 [00:26<00:36,  3.27it/s]Running loglikelihood requests:  42%|████▏     | 83/200 [00:27<00:35,  3.27it/s]Running loglikelihood requests:  42%|████▎     | 85/200 [00:27<00:35,  3.28it/s]Running loglikelihood requests:  44%|████▎     | 87/200 [00:28<00:34,  3.28it/s]Running loglikelihood requests:  44%|████▍     | 89/200 [00:28<00:33,  3.29it/s]Running loglikelihood requests:  46%|████▌     | 91/200 [00:29<00:33,  3.28it/s]Running loglikelihood requests:  46%|████▋     | 93/200 [00:30<00:32,  3.29it/s]Running loglikelihood requests:  48%|████▊     | 95/200 [00:30<00:31,  3.29it/s]Running loglikelihood requests:  48%|████▊     | 97/200 [00:31<00:31,  3.29it/s]Running loglikelihood requests:  50%|████▉     | 99/200 [00:32<00:30,  3.29it/s]Running loglikelihood requests:  50%|█████     | 101/200 [00:32<00:30,  3.29it/s]Running loglikelihood requests:  52%|█████▏    | 103/200 [00:33<00:29,  3.29it/s]Running loglikelihood requests:  52%|█████▎    | 105/200 [00:33<00:28,  3.30it/s]Running loglikelihood requests:  54%|█████▎    | 107/200 [00:34<00:28,  3.30it/s]Running loglikelihood requests:  55%|█████▍    | 109/200 [00:35<00:27,  3.31it/s]Running loglikelihood requests:  56%|█████▌    | 111/200 [00:35<00:26,  3.31it/s]Running loglikelihood requests:  56%|█████▋    | 113/200 [00:36<00:26,  3.31it/s]Running loglikelihood requests:  57%|█████▊    | 115/200 [00:36<00:25,  3.32it/s]Running loglikelihood requests:  58%|█████▊    | 117/200 [00:37<00:25,  3.32it/s]Running loglikelihood requests:  60%|█████▉    | 119/200 [00:38<00:24,  3.32it/s]Running loglikelihood requests:  60%|██████    | 121/200 [00:38<00:23,  3.32it/s]Running loglikelihood requests:  62%|██████▏   | 123/200 [00:39<00:23,  3.32it/s]Running loglikelihood requests:  62%|██████▎   | 125/200 [00:39<00:22,  3.32it/s]Running loglikelihood requests:  64%|██████▎   | 127/200 [00:40<00:21,  3.32it/s]Running loglikelihood requests:  64%|██████▍   | 129/200 [00:41<00:21,  3.32it/s]Running loglikelihood requests:  66%|██████▌   | 131/200 [00:41<00:20,  3.33it/s]Running loglikelihood requests:  66%|██████▋   | 133/200 [00:42<00:20,  3.33it/s]Running loglikelihood requests:  68%|██████▊   | 135/200 [00:42<00:19,  3.34it/s]Running loglikelihood requests:  68%|██████▊   | 137/200 [00:43<00:18,  3.34it/s]Running loglikelihood requests:  70%|██████▉   | 139/200 [00:44<00:18,  3.35it/s]Running loglikelihood requests:  70%|███████   | 141/200 [00:44<00:17,  3.35it/s]Running loglikelihood requests:  72%|███████▏  | 143/200 [00:45<00:16,  3.36it/s]Running loglikelihood requests:  72%|███████▎  | 145/200 [00:45<00:16,  3.37it/s]Running loglikelihood requests:  74%|███████▎  | 147/200 [00:46<00:15,  3.38it/s]Running loglikelihood requests:  74%|███████▍  | 149/200 [00:47<00:15,  3.38it/s]Running loglikelihood requests:  76%|███████▌  | 151/200 [00:47<00:14,  3.39it/s]Running loglikelihood requests:  76%|███████▋  | 153/200 [00:48<00:13,  3.39it/s]Running loglikelihood requests:  78%|███████▊  | 155/200 [00:48<00:13,  3.39it/s]Running loglikelihood requests:  78%|███████▊  | 157/200 [00:49<00:12,  3.40it/s]Running loglikelihood requests:  80%|███████▉  | 159/200 [00:49<00:12,  3.41it/s]Running loglikelihood requests:  80%|████████  | 161/200 [00:50<00:11,  3.41it/s]Running loglikelihood requests:  82%|████████▏ | 163/200 [00:51<00:10,  3.41it/s]Running loglikelihood requests:  82%|████████▎ | 165/200 [00:51<00:10,  3.42it/s]Running loglikelihood requests:  84%|████████▎ | 167/200 [00:52<00:09,  3.42it/s]Running loglikelihood requests:  84%|████████▍ | 169/200 [00:52<00:09,  3.43it/s]Running loglikelihood requests:  86%|████████▌ | 171/200 [00:53<00:08,  3.44it/s]Running loglikelihood requests:  86%|████████▋ | 173/200 [00:54<00:07,  3.45it/s]Running loglikelihood requests:  88%|████████▊ | 175/200 [00:54<00:07,  3.46it/s]Running loglikelihood requests:  88%|████████▊ | 177/200 [00:55<00:06,  3.47it/s]Running loglikelihood requests:  90%|████████▉ | 179/200 [00:55<00:06,  3.47it/s]Running loglikelihood requests:  90%|█████████ | 181/200 [00:56<00:05,  3.48it/s]Running loglikelihood requests:  92%|█████████▏| 183/200 [00:56<00:04,  3.48it/s]Running loglikelihood requests:  92%|█████████▎| 185/200 [00:57<00:04,  3.49it/s]Running loglikelihood requests:  94%|█████████▎| 187/200 [00:58<00:03,  3.49it/s]Running loglikelihood requests:  94%|█████████▍| 189/200 [00:58<00:03,  3.50it/s]Running loglikelihood requests:  96%|█████████▌| 191/200 [00:59<00:02,  3.52it/s]Running loglikelihood requests:  96%|█████████▋| 193/200 [00:59<00:01,  3.53it/s]Running loglikelihood requests:  98%|█████████▊| 195/200 [01:00<00:01,  3.55it/s]Running loglikelihood requests:  98%|█████████▊| 197/200 [01:00<00:00,  3.56it/s]Running loglikelihood requests: 100%|█████████▉| 199/200 [01:01<00:00,  3.57it/s]Running loglikelihood requests: 100%|██████████| 200/200 [01:01<00:00,  3.26it/s]
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
DEBUG:lm_eval.tasks:File _evalita-mp_ner_adg.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_fic.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
DEBUG:lm_eval.tasks:File _evalita-mp_ner_wn.yaml in /public/home/zouyifei001/project/mo-e_-merge_and_-update_-mec/lm_eval/tasks/evalita_llm could not be loaded
WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:7'
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:7'}
full model:
{'wic': {'alias': 'wic', 'acc,none': 0.47, 'acc_stderr,none': 0.05016135580465919}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.7015569150227223
0.5302361010977743
0.6131123609930033
0.8131827739550247
0.5456264918897312
0.5653128506125247
0.9024119585362896
0.8122852497904204
0.9072724946141106
0.866764102055741
0.8260299199157425
0.7472915500213457
0.8874866998217976
0.7441602305581367
0.22948143665096393
0.6763976434023368
0.5909756859477309
0.6775915070630182
0.8311737665735953
0.5882947608660276
0.7888779075700829
0.9530393862783458
0.7563942945196994
0.7021129984434293
0.9133573687405422
0.8864659884483975
0.43949477197814607
0.49530015739760547
0.9835705252160515
0.7015569150227223
0.5302361010977743
0.6131123609930033
0.8131827739550247
0.5456264918897312
0.5653128506125247
0.9024119585362896
0.8122852497904204
0.9072724946141106
0.866764102055741
0.8260299199157425
0.7472915500213457
0.8874866998217976
0.7441602305581367
Total groups 76 exceeded the threshold, stopping comparison.
The group tensor is
[6, 5, 2, 3, 7, 0, 4, 1]
tensor([6, 5, 2, 3, 7, 0, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 6, 1, 5, 4, 2, 3, 0]
tensor([7, 6, 1, 5, 4, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[7, 6, 2, 4, 5, 0, 3, 1]
tensor([7, 6, 2, 4, 5, 0, 3, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 0, 0, 5, 1, 1, 3, 2]
tensor([4, 0, 0, 5, 1, 1, 3, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 0, 2, 5, 3, 4, 1]
tensor([0, 1, 0, 2, 5, 3, 4, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 0, 1, 4, 1, 2, 3, 0]
tensor([5, 0, 1, 4, 1, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 1, 1, 3, 4, 2, 5, 0]
tensor([0, 1, 1, 3, 4, 2, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 1, 0, 2, 3, 1, 2, 3]
tensor([0, 1, 0, 2, 3, 1, 2, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([7])
tensor(7)
tensor([2])
tensor(2)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
tensor([3])
tensor(3)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 2 to 3
done!
Normal merging for layer 4
tensor([5])
tensor(5)
tensor([7])
tensor(7)
tensor([2])
tensor(2)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([1])
tensor(1)
tensor([0])
tensor(0)
done!
Cross-layer merge completed for layers 5 to 7
done!
Normal merging for layer 8
tensor([1, 2])
tensor(1)
tensor([4, 5])
tensor(4)
tensor([7])
tensor(7)
tensor([6])
tensor(6)
tensor([0])
tensor(0)
tensor([3])
tensor(3)
done!
Cross-layer merge completed for layers 9 to 10
done!
Normal merging for layer 11
tensor([0, 2])
tensor(0)
tensor([1, 7])
tensor(1)
tensor([3])
tensor(3)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 12 to 13
done!
Normal merging for layer 14
tensor([1, 7])
tensor(1)
tensor([2, 4])
tensor(2)
tensor([5])
tensor(5)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([0])
tensor(0)
done!
Normal merging for layer 15
tensor([0, 7])
tensor(0)
tensor([1, 2])
tensor(1)
tensor([5])
tensor(5)
tensor([3])
tensor(3)
tensor([4])
tensor(4)
tensor([6])
tensor(6)
done!
Normal merging for layer 16
tensor([0, 2])
tensor(0)
tensor([1, 5])
tensor(1)
tensor([3, 6])
tensor(3)
tensor([4, 7])
tensor(4)
done!
Cross-layer merge completed for layers 17 to 31
done!
all done!
Model size: 12.5757 GB
112
cuda:7
mastermind_35_easy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:41<00:41, 41.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:53<00:00, 24.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:53<00:00, 26.77s/it]
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_35_mcq_random HTTP/1.1" 200 780
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/flair/mastermind_35_mcq_random/flair/mastermind_35_mcq_random.py HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/flair/mastermind_35_mcq_random HTTP/1.1" 200 780
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/flair/mastermind_35_mcq_random/resolve/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/flair/mastermind_35_mcq_random/resolve/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/flair/mastermind_35_mcq_random/paths-info/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1 HTTP/1.1" 200 218
DEBUG:filelock:Attempting to acquire lock 140239880233968 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_35_mcq_random_default_0.0.0_15dd5105771e9c8d2d3ea71c8d44fffda374a7a1.lock
DEBUG:filelock:Lock 140239880233968 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_35_mcq_random_default_0.0.0_15dd5105771e9c8d2d3ea71c8d44fffda374a7a1.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1/dataset_info.json
DEBUG:filelock:Attempting to release lock 140239880233968 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_35_mcq_random_default_0.0.0_15dd5105771e9c8d2d3ea71c8d44fffda374a7a1.lock
DEBUG:filelock:Lock 140239880233968 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_flair___mastermind_35_mcq_random_default_0.0.0_15dd5105771e9c8d2d3ea71c8d44fffda374a7a1.lock
DEBUG:filelock:Attempting to acquire lock 140240017480336 on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1_builder.lock
DEBUG:filelock:Lock 140240017480336 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1/dataset_info.json
DEBUG:filelock:Attempting to release lock 140240017480336 on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1_builder.lock
DEBUG:filelock:Lock 140240017480336 released on /public/home/zouyifei001/.cache/huggingface/datasets/flair___mastermind_35_mcq_random/default/0.0.0/15dd5105771e9c8d2d3ea71c8d44fffda374a7a1_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of mastermind_35_easy from None to 0
INFO:lm_eval.api.task:Building contexts for mastermind_35_easy on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s]100%|██████████| 100/100 [00:00<00:00, 1530.52it/s]
DEBUG:lm_eval.evaluator:Task: mastermind_35_easy; number of requests on this rank: 400
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/400 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/400 [00:01<11:15,  1.69s/it]Running loglikelihood requests:   0%|          | 2/400 [00:02<09:22,  1.41s/it]Running loglikelihood requests:   1%|          | 3/400 [00:04<08:43,  1.32s/it]Running loglikelihood requests:   1%|          | 4/400 [00:05<08:24,  1.27s/it]Running loglikelihood requests:   1%|▏         | 5/400 [00:06<08:13,  1.25s/it]Running loglikelihood requests:   2%|▏         | 6/400 [00:07<08:05,  1.23s/it]Running loglikelihood requests:   2%|▏         | 7/400 [00:08<07:59,  1.22s/it]Running loglikelihood requests:   2%|▏         | 8/400 [00:10<07:55,  1.21s/it]Running loglikelihood requests:   2%|▏         | 9/400 [00:11<07:52,  1.21s/it]Running loglikelihood requests:   2%|▎         | 10/400 [00:12<07:49,  1.20s/it]Running loglikelihood requests:   3%|▎         | 11/400 [00:13<07:47,  1.20s/it]Running loglikelihood requests:   3%|▎         | 12/400 [00:14<07:44,  1.20s/it]Running loglikelihood requests:   3%|▎         | 13/400 [00:16<07:42,  1.19s/it]Running loglikelihood requests:   4%|▎         | 14/400 [00:17<07:39,  1.19s/it]Running loglikelihood requests:   4%|▍         | 15/400 [00:18<07:37,  1.19s/it]Running loglikelihood requests:   4%|▍         | 16/400 [00:19<07:36,  1.19s/it]Running loglikelihood requests:   4%|▍         | 17/400 [00:20<07:34,  1.19s/it]Running loglikelihood requests:   4%|▍         | 18/400 [00:21<07:32,  1.18s/it]Running loglikelihood requests:   5%|▍         | 19/400 [00:23<07:30,  1.18s/it]Running loglikelihood requests:   5%|▌         | 20/400 [00:24<07:28,  1.18s/it]Running loglikelihood requests:   5%|▌         | 21/400 [00:25<07:27,  1.18s/it]Running loglikelihood requests:   6%|▌         | 23/400 [00:26<05:41,  1.10it/s]Running loglikelihood requests:   6%|▌         | 24/400 [00:27<06:05,  1.03it/s]Running loglikelihood requests:   6%|▋         | 25/400 [00:29<06:24,  1.02s/it]Running loglikelihood requests:   6%|▋         | 26/400 [00:30<06:37,  1.06s/it]Running loglikelihood requests:   7%|▋         | 27/400 [00:31<06:47,  1.09s/it]Running loglikelihood requests:   7%|▋         | 28/400 [00:32<06:54,  1.11s/it]Running loglikelihood requests:   7%|▋         | 29/400 [00:33<06:59,  1.13s/it]Running loglikelihood requests:   8%|▊         | 30/400 [00:34<07:02,  1.14s/it]Running loglikelihood requests:   8%|▊         | 31/400 [00:36<07:04,  1.15s/it]Running loglikelihood requests:   8%|▊         | 32/400 [00:37<07:05,  1.16s/it]Running loglikelihood requests:   8%|▊         | 33/400 [00:38<07:05,  1.16s/it]Running loglikelihood requests:   8%|▊         | 34/400 [00:39<07:05,  1.16s/it]Running loglikelihood requests:   9%|▉         | 35/400 [00:40<07:04,  1.16s/it]Running loglikelihood requests:   9%|▉         | 36/400 [00:41<07:03,  1.16s/it]Running loglikelihood requests:   9%|▉         | 37/400 [00:43<07:03,  1.17s/it]Running loglikelihood requests:  10%|▉         | 38/400 [00:44<07:01,  1.17s/it]Running loglikelihood requests:  10%|▉         | 39/400 [00:45<07:00,  1.17s/it]Running loglikelihood requests:  10%|█         | 40/400 [00:46<06:59,  1.17s/it]Running loglikelihood requests:  10%|█         | 41/400 [00:47<06:57,  1.16s/it]Running loglikelihood requests:  10%|█         | 42/400 [00:48<06:56,  1.16s/it]Running loglikelihood requests:  11%|█         | 43/400 [00:50<06:55,  1.16s/it]Running loglikelihood requests:  11%|█         | 44/400 [00:51<06:54,  1.16s/it]Running loglikelihood requests:  11%|█▏        | 45/400 [00:52<06:53,  1.16s/it]Running loglikelihood requests:  12%|█▏        | 46/400 [00:53<06:52,  1.16s/it]Running loglikelihood requests:  12%|█▏        | 47/400 [00:54<06:51,  1.16s/it]Running loglikelihood requests:  12%|█▏        | 48/400 [00:55<06:50,  1.17s/it]Running loglikelihood requests:  12%|█▏        | 49/400 [00:57<06:48,  1.16s/it]Running loglikelihood requests:  12%|█▎        | 50/400 [00:58<06:47,  1.16s/it]Running loglikelihood requests:  13%|█▎        | 51/400 [00:59<06:46,  1.16s/it]Running loglikelihood requests:  13%|█▎        | 52/400 [01:00<06:44,  1.16s/it]Running loglikelihood requests:  13%|█▎        | 53/400 [01:01<06:43,  1.16s/it]Running loglikelihood requests:  14%|█▎        | 54/400 [01:02<06:42,  1.16s/it]Running loglikelihood requests:  14%|█▍        | 55/400 [01:04<06:40,  1.16s/it]Running loglikelihood requests:  14%|█▍        | 56/400 [01:05<06:39,  1.16s/it]Running loglikelihood requests:  14%|█▍        | 57/400 [01:06<06:38,  1.16s/it]Running loglikelihood requests:  14%|█▍        | 58/400 [01:07<06:37,  1.16s/it]Running loglikelihood requests:  15%|█▍        | 59/400 [01:08<06:36,  1.16s/it]Running loglikelihood requests:  15%|█▌        | 60/400 [01:09<06:35,  1.16s/it]Running loglikelihood requests:  15%|█▌        | 61/400 [01:10<06:34,  1.16s/it]Running loglikelihood requests:  16%|█▌        | 62/400 [01:12<06:32,  1.16s/it]Running loglikelihood requests:  16%|█▌        | 63/400 [01:13<06:31,  1.16s/it]Running loglikelihood requests:  16%|█▌        | 64/400 [01:14<06:30,  1.16s/it]Running loglikelihood requests:  16%|█▋        | 65/400 [01:15<06:29,  1.16s/it]Running loglikelihood requests:  16%|█▋        | 66/400 [01:16<06:27,  1.16s/it]Running loglikelihood requests:  17%|█▋        | 67/400 [01:17<06:26,  1.16s/it]Running loglikelihood requests:  17%|█▋        | 68/400 [01:19<06:24,  1.16s/it]Running loglikelihood requests:  17%|█▋        | 69/400 [01:20<06:23,  1.16s/it]Running loglikelihood requests:  18%|█▊        | 70/400 [01:21<06:22,  1.16s/it]Running loglikelihood requests:  18%|█▊        | 71/400 [01:22<06:21,  1.16s/it]Running loglikelihood requests:  18%|█▊        | 72/400 [01:23<06:20,  1.16s/it]Running loglikelihood requests:  18%|█▊        | 73/400 [01:24<06:18,  1.16s/it]Running loglikelihood requests:  18%|█▊        | 74/400 [01:26<06:17,  1.16s/it]Running loglikelihood requests:  19%|█▉        | 75/400 [01:27<06:15,  1.16s/it]Running loglikelihood requests:  19%|█▉        | 76/400 [01:28<06:14,  1.16s/it]Running loglikelihood requests:  19%|█▉        | 77/400 [01:29<06:13,  1.16s/it]Running loglikelihood requests:  20%|█▉        | 78/400 [01:30<06:12,  1.16s/it]Running loglikelihood requests:  20%|█▉        | 79/400 [01:31<06:10,  1.15s/it]Running loglikelihood requests:  20%|██        | 80/400 [01:32<06:09,  1.15s/it]Running loglikelihood requests:  20%|██        | 81/400 [01:34<06:08,  1.16s/it]Running loglikelihood requests:  20%|██        | 82/400 [01:35<06:07,  1.16s/it]Running loglikelihood requests:  21%|██        | 83/400 [01:36<06:06,  1.16s/it]Running loglikelihood requests:  21%|██        | 84/400 [01:37<06:04,  1.15s/it]Running loglikelihood requests:  21%|██▏       | 85/400 [01:38<06:03,  1.15s/it]Running loglikelihood requests:  22%|██▏       | 86/400 [01:39<06:02,  1.15s/it]Running loglikelihood requests:  22%|██▏       | 87/400 [01:41<06:01,  1.16s/it]Running loglikelihood requests:  22%|██▏       | 88/400 [01:42<06:00,  1.16s/it]Running loglikelihood requests:  22%|██▏       | 89/400 [01:43<05:59,  1.16s/it]Running loglikelihood requests:  22%|██▎       | 90/400 [01:44<05:57,  1.15s/it]Running loglikelihood requests:  23%|██▎       | 91/400 [01:45<05:56,  1.15s/it]Running loglikelihood requests:  23%|██▎       | 92/400 [01:46<05:55,  1.15s/it]Running loglikelihood requests:  23%|██▎       | 93/400 [01:47<05:54,  1.15s/it]Running loglikelihood requests:  24%|██▎       | 94/400 [01:49<05:53,  1.15s/it]Running loglikelihood requests:  24%|██▍       | 95/400 [01:50<05:51,  1.15s/it]Running loglikelihood requests:  24%|██▍       | 96/400 [01:51<05:51,  1.15s/it]Running loglikelihood requests:  24%|██▍       | 97/400 [01:52<05:49,  1.15s/it]Running loglikelihood requests:  24%|██▍       | 98/400 [01:53<05:48,  1.15s/it]Running loglikelihood requests:  25%|██▍       | 99/400 [01:54<05:47,  1.15s/it]Running loglikelihood requests:  25%|██▌       | 100/400 [01:56<05:46,  1.15s/it]Running loglikelihood requests:  25%|██▌       | 101/400 [01:57<05:44,  1.15s/it]Running loglikelihood requests:  26%|██▌       | 102/400 [01:58<05:43,  1.15s/it]Running loglikelihood requests:  26%|██▌       | 103/400 [01:59<05:42,  1.15s/it]Running loglikelihood requests:  26%|██▌       | 104/400 [02:00<05:40,  1.15s/it]Running loglikelihood requests:  26%|██▋       | 105/400 [02:01<05:39,  1.15s/it]Running loglikelihood requests:  26%|██▋       | 106/400 [02:02<05:38,  1.15s/it]Running loglikelihood requests:  27%|██▋       | 107/400 [02:04<05:37,  1.15s/it]Running loglikelihood requests:  27%|██▋       | 108/400 [02:05<05:35,  1.15s/it]Running loglikelihood requests:  27%|██▋       | 109/400 [02:06<05:34,  1.15s/it]Running loglikelihood requests:  28%|██▊       | 110/400 [02:07<05:33,  1.15s/it]Running loglikelihood requests:  28%|██▊       | 112/400 [02:08<04:15,  1.13it/s]Running loglikelihood requests:  28%|██▊       | 113/400 [02:09<04:32,  1.05it/s]Running loglikelihood requests:  28%|██▊       | 114/400 [02:11<04:46,  1.00s/it]Running loglikelihood requests:  29%|██▉       | 115/400 [02:12<04:56,  1.04s/it]Running loglikelihood requests:  29%|██▉       | 116/400 [02:13<05:04,  1.07s/it]Running loglikelihood requests:  29%|██▉       | 117/400 [02:14<05:09,  1.09s/it]Running loglikelihood requests:  30%|██▉       | 118/400 [02:15<05:13,  1.11s/it]Running loglikelihood requests:  30%|██▉       | 119/400 [02:16<05:15,  1.12s/it]Running loglikelihood requests:  30%|███       | 120/400 [02:17<05:16,  1.13s/it]Running loglikelihood requests:  30%|███       | 121/400 [02:19<05:16,  1.13s/it]Running loglikelihood requests:  30%|███       | 122/400 [02:20<05:16,  1.14s/it]Running loglikelihood requests:  31%|███       | 123/400 [02:21<05:16,  1.14s/it]Running loglikelihood requests:  31%|███       | 124/400 [02:22<05:15,  1.14s/it]Running loglikelihood requests:  31%|███▏      | 125/400 [02:23<05:14,  1.15s/it]Running loglikelihood requests:  32%|███▏      | 126/400 [02:24<05:14,  1.15s/it]Running loglikelihood requests:  32%|███▏      | 127/400 [02:25<05:12,  1.15s/it]Running loglikelihood requests:  32%|███▏      | 128/400 [02:27<05:11,  1.14s/it]Running loglikelihood requests:  32%|███▏      | 129/400 [02:28<05:10,  1.14s/it]Running loglikelihood requests:  32%|███▎      | 130/400 [02:29<05:09,  1.14s/it]Running loglikelihood requests:  33%|███▎      | 131/400 [02:30<05:07,  1.14s/it]Running loglikelihood requests:  33%|███▎      | 132/400 [02:31<05:06,  1.14s/it]Running loglikelihood requests:  33%|███▎      | 133/400 [02:32<05:05,  1.14s/it]Running loglikelihood requests:  34%|███▎      | 134/400 [02:33<05:04,  1.14s/it]Running loglikelihood requests:  34%|███▍      | 135/400 [02:35<05:02,  1.14s/it]Running loglikelihood requests:  34%|███▍      | 136/400 [02:36<05:01,  1.14s/it]Running loglikelihood requests:  34%|███▍      | 137/400 [02:37<05:00,  1.14s/it]Running loglikelihood requests:  34%|███▍      | 138/400 [02:38<04:58,  1.14s/it]Running loglikelihood requests:  35%|███▍      | 139/400 [02:39<04:58,  1.14s/it]Running loglikelihood requests:  35%|███▌      | 140/400 [02:40<04:57,  1.14s/it]Running loglikelihood requests:  35%|███▌      | 141/400 [02:41<04:55,  1.14s/it]Running loglikelihood requests:  36%|███▌      | 142/400 [02:43<04:54,  1.14s/it]Running loglikelihood requests:  36%|███▌      | 143/400 [02:44<04:53,  1.14s/it]Running loglikelihood requests:  36%|███▌      | 144/400 [02:45<04:52,  1.14s/it]Running loglikelihood requests:  36%|███▋      | 145/400 [02:46<04:50,  1.14s/it]Running loglikelihood requests:  36%|███▋      | 146/400 [02:47<04:49,  1.14s/it]Running loglikelihood requests:  37%|███▋      | 147/400 [02:48<04:47,  1.14s/it]Running loglikelihood requests:  37%|███▋      | 148/400 [02:49<04:46,  1.14s/it]Running loglikelihood requests:  37%|███▋      | 149/400 [02:51<04:45,  1.14s/it]Running loglikelihood requests:  38%|███▊      | 150/400 [02:52<04:44,  1.14s/it]Running loglikelihood requests:  38%|███▊      | 151/400 [02:53<04:42,  1.14s/it]Running loglikelihood requests:  38%|███▊      | 152/400 [02:54<04:42,  1.14s/it]Running loglikelihood requests:  38%|███▊      | 153/400 [02:55<04:40,  1.14s/it]Running loglikelihood requests:  38%|███▊      | 154/400 [02:56<04:39,  1.14s/it]Running loglikelihood requests:  39%|███▉      | 155/400 [02:57<04:38,  1.14s/it]Running loglikelihood requests:  39%|███▉      | 156/400 [02:58<04:36,  1.13s/it]Running loglikelihood requests:  39%|███▉      | 157/400 [03:00<04:35,  1.13s/it]Running loglikelihood requests:  40%|███▉      | 158/400 [03:01<04:34,  1.13s/it]Running loglikelihood requests:  40%|███▉      | 159/400 [03:02<04:33,  1.13s/it]Running loglikelihood requests:  40%|████      | 160/400 [03:03<04:31,  1.13s/it]Running loglikelihood requests:  40%|████      | 161/400 [03:04<04:30,  1.13s/it]Running loglikelihood requests:  40%|████      | 162/400 [03:05<04:28,  1.13s/it]Running loglikelihood requests:  41%|████      | 163/400 [03:06<04:27,  1.13s/it]Running loglikelihood requests:  41%|████      | 164/400 [03:08<04:26,  1.13s/it]Running loglikelihood requests:  41%|████▏     | 165/400 [03:09<04:24,  1.13s/it]Running loglikelihood requests:  42%|████▏     | 166/400 [03:10<04:23,  1.13s/it]Running loglikelihood requests:  42%|████▏     | 167/400 [03:11<04:22,  1.13s/it]Running loglikelihood requests:  42%|████▏     | 168/400 [03:12<04:21,  1.13s/it]Running loglikelihood requests:  42%|████▏     | 169/400 [03:13<04:19,  1.12s/it]Running loglikelihood requests:  42%|████▎     | 170/400 [03:14<04:18,  1.12s/it]Running loglikelihood requests:  43%|████▎     | 171/400 [03:15<04:17,  1.12s/it]Running loglikelihood requests:  43%|████▎     | 172/400 [03:17<04:16,  1.12s/it]Running loglikelihood requests:  43%|████▎     | 173/400 [03:18<04:15,  1.12s/it]Running loglikelihood requests:  44%|████▎     | 174/400 [03:19<04:13,  1.12s/it]Running loglikelihood requests:  44%|████▍     | 175/400 [03:20<04:12,  1.12s/it]Running loglikelihood requests:  44%|████▍     | 177/400 [03:21<03:12,  1.16it/s]Running loglikelihood requests:  44%|████▍     | 178/400 [03:22<03:26,  1.08it/s]Running loglikelihood requests:  45%|████▍     | 179/400 [03:23<03:36,  1.02it/s]Running loglikelihood requests:  45%|████▌     | 180/400 [03:24<03:44,  1.02s/it]Running loglikelihood requests:  45%|████▌     | 181/400 [03:26<03:49,  1.05s/it]Running loglikelihood requests:  46%|████▌     | 182/400 [03:27<03:53,  1.07s/it]Running loglikelihood requests:  46%|████▌     | 183/400 [03:28<03:55,  1.08s/it]Running loglikelihood requests:  46%|████▌     | 184/400 [03:29<03:56,  1.10s/it]Running loglikelihood requests:  46%|████▋     | 185/400 [03:30<03:57,  1.10s/it]Running loglikelihood requests:  46%|████▋     | 186/400 [03:31<03:57,  1.11s/it]Running loglikelihood requests:  47%|████▋     | 187/400 [03:32<03:56,  1.11s/it]Running loglikelihood requests:  47%|████▋     | 188/400 [03:33<03:56,  1.11s/it]Running loglikelihood requests:  47%|████▋     | 189/400 [03:34<03:55,  1.12s/it]Running loglikelihood requests:  48%|████▊     | 190/400 [03:36<03:54,  1.12s/it]Running loglikelihood requests:  48%|████▊     | 191/400 [03:37<03:53,  1.12s/it]Running loglikelihood requests:  48%|████▊     | 192/400 [03:38<03:52,  1.12s/it]Running loglikelihood requests:  48%|████▊     | 193/400 [03:39<03:51,  1.12s/it]Running loglikelihood requests:  48%|████▊     | 194/400 [03:40<03:50,  1.12s/it]Running loglikelihood requests:  49%|████▉     | 195/400 [03:41<03:49,  1.12s/it]Running loglikelihood requests:  49%|████▉     | 196/400 [03:42<03:48,  1.12s/it]Running loglikelihood requests:  49%|████▉     | 197/400 [03:43<03:47,  1.12s/it]Running loglikelihood requests:  50%|████▉     | 198/400 [03:45<03:45,  1.12s/it]Running loglikelihood requests:  50%|████▉     | 199/400 [03:46<03:44,  1.12s/it]Running loglikelihood requests:  50%|█████     | 200/400 [03:47<03:43,  1.12s/it]Running loglikelihood requests:  50%|█████     | 201/400 [03:48<03:41,  1.11s/it]Running loglikelihood requests:  50%|█████     | 202/400 [03:49<03:40,  1.11s/it]Running loglikelihood requests:  51%|█████     | 203/400 [03:50<03:39,  1.12s/it]Running loglikelihood requests:  51%|█████▏    | 205/400 [03:51<02:47,  1.17it/s]Running loglikelihood requests:  52%|█████▏    | 206/400 [03:52<02:58,  1.08it/s]Running loglikelihood requests:  52%|█████▏    | 207/400 [03:53<03:07,  1.03it/s]Running loglikelihood requests:  52%|█████▏    | 208/400 [03:55<03:13,  1.01s/it]Running loglikelihood requests:  52%|█████▏    | 209/400 [03:56<03:18,  1.04s/it]Running loglikelihood requests:  52%|█████▎    | 210/400 [03:57<03:21,  1.06s/it]Running loglikelihood requests:  53%|█████▎    | 211/400 [03:58<03:23,  1.08s/it]Running loglikelihood requests:  53%|█████▎    | 212/400 [03:59<03:24,  1.09s/it]Running loglikelihood requests:  53%|█████▎    | 213/400 [04:00<03:24,  1.09s/it]Running loglikelihood requests:  54%|█████▎    | 214/400 [04:01<03:24,  1.10s/it]Running loglikelihood requests:  54%|█████▍    | 215/400 [04:02<03:24,  1.10s/it]Running loglikelihood requests:  54%|█████▍    | 216/400 [04:03<03:23,  1.11s/it]Running loglikelihood requests:  54%|█████▍    | 217/400 [04:05<03:22,  1.11s/it]Running loglikelihood requests:  55%|█████▍    | 218/400 [04:06<03:22,  1.11s/it]Running loglikelihood requests:  55%|█████▍    | 219/400 [04:07<03:20,  1.11s/it]Running loglikelihood requests:  55%|█████▌    | 220/400 [04:08<03:19,  1.11s/it]Running loglikelihood requests:  55%|█████▌    | 221/400 [04:09<03:18,  1.11s/it]Running loglikelihood requests:  56%|█████▌    | 222/400 [04:10<03:18,  1.11s/it]Running loglikelihood requests:  56%|█████▌    | 223/400 [04:11<03:16,  1.11s/it]Running loglikelihood requests:  56%|█████▌    | 224/400 [04:12<03:15,  1.11s/it]Running loglikelihood requests:  56%|█████▋    | 225/400 [04:13<03:14,  1.11s/it]Running loglikelihood requests:  56%|█████▋    | 226/400 [04:15<03:13,  1.11s/it]Running loglikelihood requests:  57%|█████▋    | 227/400 [04:16<03:12,  1.11s/it]Running loglikelihood requests:  57%|█████▋    | 228/400 [04:17<03:11,  1.11s/it]Running loglikelihood requests:  57%|█████▋    | 229/400 [04:18<03:09,  1.11s/it]Running loglikelihood requests:  57%|█████▊    | 230/400 [04:19<03:08,  1.11s/it]Running loglikelihood requests:  58%|█████▊    | 231/400 [04:20<03:07,  1.11s/it]Running loglikelihood requests:  58%|█████▊    | 232/400 [04:21<03:06,  1.11s/it]Running loglikelihood requests:  58%|█████▊    | 233/400 [04:22<03:04,  1.11s/it]Running loglikelihood requests:  58%|█████▊    | 234/400 [04:23<03:03,  1.11s/it]Running loglikelihood requests:  59%|█████▉    | 235/400 [04:25<03:02,  1.11s/it]Running loglikelihood requests:  59%|█████▉    | 236/400 [04:26<03:01,  1.11s/it]Running loglikelihood requests:  59%|█████▉    | 237/400 [04:27<03:00,  1.11s/it]Running loglikelihood requests:  60%|█████▉    | 238/400 [04:28<02:59,  1.11s/it]Running loglikelihood requests:  60%|█████▉    | 239/400 [04:29<02:58,  1.11s/it]Running loglikelihood requests:  60%|██████    | 241/400 [04:30<02:15,  1.17it/s]Running loglikelihood requests:  60%|██████    | 242/400 [04:31<02:24,  1.09it/s]Running loglikelihood requests:  61%|██████    | 243/400 [04:32<02:31,  1.04it/s]Running loglikelihood requests:  61%|██████    | 244/400 [04:33<02:36,  1.00s/it]Running loglikelihood requests:  61%|██████▏   | 245/400 [04:35<02:39,  1.03s/it]Running loglikelihood requests:  62%|██████▏   | 246/400 [04:36<02:41,  1.05s/it]Running loglikelihood requests:  62%|██████▏   | 247/400 [04:37<02:42,  1.06s/it]Running loglikelihood requests:  62%|██████▏   | 248/400 [04:38<02:43,  1.08s/it]Running loglikelihood requests:  62%|██████▏   | 249/400 [04:39<02:43,  1.08s/it]Running loglikelihood requests:  62%|██████▎   | 250/400 [04:40<02:43,  1.09s/it]Running loglikelihood requests:  63%|██████▎   | 251/400 [04:41<02:42,  1.09s/it]Running loglikelihood requests:  63%|██████▎   | 252/400 [04:42<02:42,  1.10s/it]Running loglikelihood requests:  63%|██████▎   | 253/400 [04:43<02:41,  1.10s/it]Running loglikelihood requests:  64%|██████▍   | 255/400 [04:44<02:02,  1.18it/s]Running loglikelihood requests:  64%|██████▍   | 256/400 [04:46<02:11,  1.10it/s]Running loglikelihood requests:  64%|██████▍   | 257/400 [04:47<02:17,  1.04it/s]Running loglikelihood requests:  64%|██████▍   | 258/400 [04:48<02:21,  1.00it/s]Running loglikelihood requests:  65%|██████▍   | 259/400 [04:49<02:24,  1.03s/it]Running loglikelihood requests:  65%|██████▌   | 260/400 [04:50<02:26,  1.05s/it]Running loglikelihood requests:  65%|██████▌   | 261/400 [04:51<02:27,  1.06s/it]Running loglikelihood requests:  66%|██████▌   | 262/400 [04:52<02:27,  1.07s/it]Running loglikelihood requests:  66%|██████▌   | 263/400 [04:53<02:27,  1.08s/it]Running loglikelihood requests:  66%|██████▌   | 264/400 [04:54<02:27,  1.08s/it]Running loglikelihood requests:  66%|██████▋   | 265/400 [04:55<02:26,  1.09s/it]Running loglikelihood requests:  66%|██████▋   | 266/400 [04:57<02:26,  1.09s/it]Running loglikelihood requests:  67%|██████▋   | 267/400 [04:58<02:25,  1.09s/it]Running loglikelihood requests:  67%|██████▋   | 268/400 [04:59<02:24,  1.09s/it]Running loglikelihood requests:  68%|██████▊   | 270/400 [05:00<01:49,  1.19it/s]Running loglikelihood requests:  68%|██████▊   | 271/400 [05:01<01:56,  1.11it/s]Running loglikelihood requests:  68%|██████▊   | 272/400 [05:02<02:02,  1.05it/s]Running loglikelihood requests:  68%|██████▊   | 273/400 [05:03<02:05,  1.01it/s]Running loglikelihood requests:  68%|██████▊   | 274/400 [05:04<02:08,  1.02s/it]Running loglikelihood requests:  69%|██████▉   | 275/400 [05:05<02:09,  1.04s/it]Running loglikelihood requests:  69%|██████▉   | 276/400 [05:06<02:10,  1.05s/it]Running loglikelihood requests:  69%|██████▉   | 277/400 [05:07<02:10,  1.06s/it]Running loglikelihood requests:  70%|██████▉   | 278/400 [05:09<02:10,  1.07s/it]Running loglikelihood requests:  70%|██████▉   | 279/400 [05:10<02:09,  1.07s/it]Running loglikelihood requests:  70%|███████   | 280/400 [05:11<02:09,  1.08s/it]Running loglikelihood requests:  70%|███████   | 281/400 [05:12<02:08,  1.08s/it]Running loglikelihood requests:  70%|███████   | 282/400 [05:13<02:07,  1.08s/it]Running loglikelihood requests:  71%|███████   | 283/400 [05:14<02:06,  1.08s/it]Running loglikelihood requests:  71%|███████   | 284/400 [05:15<02:05,  1.08s/it]Running loglikelihood requests:  71%|███████▏  | 285/400 [05:16<02:04,  1.08s/it]Running loglikelihood requests:  72%|███████▏  | 286/400 [05:17<02:03,  1.08s/it]Running loglikelihood requests:  72%|███████▏  | 287/400 [05:18<02:01,  1.08s/it]Running loglikelihood requests:  72%|███████▏  | 288/400 [05:19<02:00,  1.08s/it]Running loglikelihood requests:  72%|███████▏  | 289/400 [05:20<01:59,  1.08s/it]Running loglikelihood requests:  72%|███████▎  | 290/400 [05:21<01:58,  1.08s/it]Running loglikelihood requests:  73%|███████▎  | 291/400 [05:23<01:57,  1.08s/it]Running loglikelihood requests:  73%|███████▎  | 292/400 [05:24<01:56,  1.08s/it]Running loglikelihood requests:  73%|███████▎  | 293/400 [05:25<01:55,  1.08s/it]Running loglikelihood requests:  74%|███████▎  | 294/400 [05:26<01:54,  1.08s/it]Running loglikelihood requests:  74%|███████▍  | 295/400 [05:27<01:53,  1.08s/it]Running loglikelihood requests:  74%|███████▍  | 296/400 [05:28<01:52,  1.08s/it]Running loglikelihood requests:  74%|███████▍  | 297/400 [05:29<01:51,  1.08s/it]Running loglikelihood requests:  74%|███████▍  | 298/400 [05:30<01:49,  1.08s/it]Running loglikelihood requests:  75%|███████▍  | 299/400 [05:31<01:48,  1.08s/it]Running loglikelihood requests:  75%|███████▌  | 300/400 [05:32<01:47,  1.07s/it]Running loglikelihood requests:  75%|███████▌  | 301/400 [05:33<01:46,  1.07s/it]Running loglikelihood requests:  76%|███████▌  | 302/400 [05:34<01:45,  1.07s/it]Running loglikelihood requests:  76%|███████▌  | 304/400 [05:35<01:19,  1.21it/s]Running loglikelihood requests:  76%|███████▋  | 305/400 [05:37<01:24,  1.13it/s]Running loglikelihood requests:  76%|███████▋  | 306/400 [05:38<01:27,  1.07it/s]Running loglikelihood requests:  77%|███████▋  | 307/400 [05:39<01:30,  1.03it/s]Running loglikelihood requests:  77%|███████▋  | 308/400 [05:40<01:31,  1.00it/s]Running loglikelihood requests:  77%|███████▋  | 309/400 [05:41<01:32,  1.02s/it]Running loglikelihood requests:  78%|███████▊  | 310/400 [05:42<01:32,  1.03s/it]Running loglikelihood requests:  78%|███████▊  | 311/400 [05:43<01:32,  1.04s/it]Running loglikelihood requests:  78%|███████▊  | 312/400 [05:44<01:32,  1.05s/it]Running loglikelihood requests:  78%|███████▊  | 313/400 [05:45<01:31,  1.05s/it]Running loglikelihood requests:  78%|███████▊  | 314/400 [05:46<01:30,  1.06s/it]Running loglikelihood requests:  79%|███████▉  | 315/400 [05:47<01:29,  1.06s/it]Running loglikelihood requests:  79%|███████▉  | 316/400 [05:48<01:28,  1.06s/it]Running loglikelihood requests:  79%|███████▉  | 317/400 [05:49<01:27,  1.06s/it]Running loglikelihood requests:  80%|███████▉  | 318/400 [05:50<01:26,  1.06s/it]Running loglikelihood requests:  80%|███████▉  | 319/400 [05:51<01:25,  1.06s/it]Running loglikelihood requests:  80%|████████  | 320/400 [05:52<01:24,  1.06s/it]Running loglikelihood requests:  80%|████████  | 321/400 [05:54<01:23,  1.06s/it]Running loglikelihood requests:  80%|████████  | 322/400 [05:55<01:22,  1.06s/it]Running loglikelihood requests:  81%|████████  | 323/400 [05:56<01:21,  1.06s/it]Running loglikelihood requests:  81%|████████  | 324/400 [05:57<01:20,  1.06s/it]Running loglikelihood requests:  81%|████████▏ | 325/400 [05:58<01:19,  1.06s/it]Running loglikelihood requests:  82%|████████▏ | 326/400 [05:59<01:18,  1.06s/it]Running loglikelihood requests:  82%|████████▏ | 327/400 [06:00<01:17,  1.06s/it]Running loglikelihood requests:  82%|████████▏ | 328/400 [06:01<01:16,  1.06s/it]Running loglikelihood requests:  82%|████████▎ | 330/400 [06:02<00:56,  1.23it/s]Running loglikelihood requests:  83%|████████▎ | 331/400 [06:03<01:00,  1.15it/s]Running loglikelihood requests:  83%|████████▎ | 332/400 [06:04<01:02,  1.09it/s]Running loglikelihood requests:  83%|████████▎ | 333/400 [06:05<01:03,  1.05it/s]Running loglikelihood requests:  84%|████████▎ | 334/400 [06:06<01:04,  1.02it/s]Running loglikelihood requests:  84%|████████▍ | 335/400 [06:07<01:04,  1.00it/s]Running loglikelihood requests:  84%|████████▍ | 336/400 [06:08<01:04,  1.01s/it]Running loglikelihood requests:  84%|████████▍ | 337/400 [06:09<01:04,  1.02s/it]Running loglikelihood requests:  84%|████████▍ | 338/400 [06:10<01:03,  1.03s/it]Running loglikelihood requests:  85%|████████▍ | 339/400 [06:11<01:03,  1.04s/it]Running loglikelihood requests:  85%|████████▌ | 340/400 [06:12<01:02,  1.04s/it]Running loglikelihood requests:  85%|████████▌ | 341/400 [06:14<01:01,  1.04s/it]Running loglikelihood requests:  86%|████████▌ | 342/400 [06:15<01:00,  1.04s/it]Running loglikelihood requests:  86%|████████▌ | 343/400 [06:16<00:59,  1.04s/it]Running loglikelihood requests:  86%|████████▌ | 344/400 [06:17<00:58,  1.04s/it]Running loglikelihood requests:  86%|████████▋ | 345/400 [06:18<00:57,  1.04s/it]Running loglikelihood requests:  86%|████████▋ | 346/400 [06:19<00:56,  1.04s/it]Running loglikelihood requests:  87%|████████▋ | 347/400 [06:20<00:55,  1.04s/it]Running loglikelihood requests:  87%|████████▋ | 348/400 [06:21<00:54,  1.04s/it]Running loglikelihood requests:  87%|████████▋ | 349/400 [06:22<00:52,  1.04s/it]Running loglikelihood requests:  88%|████████▊ | 350/400 [06:23<00:51,  1.03s/it]Running loglikelihood requests:  88%|████████▊ | 351/400 [06:24<00:50,  1.03s/it]Running loglikelihood requests:  88%|████████▊ | 352/400 [06:25<00:49,  1.03s/it]Running loglikelihood requests:  88%|████████▊ | 353/400 [06:26<00:48,  1.03s/it]Running loglikelihood requests:  88%|████████▊ | 354/400 [06:27<00:47,  1.03s/it]Running loglikelihood requests:  89%|████████▉ | 355/400 [06:28<00:46,  1.03s/it]Running loglikelihood requests:  89%|████████▉ | 356/400 [06:29<00:45,  1.03s/it]Running loglikelihood requests:  89%|████████▉ | 357/400 [06:30<00:44,  1.03s/it]Running loglikelihood requests:  90%|████████▉ | 358/400 [06:31<00:43,  1.02s/it]Running loglikelihood requests:  90%|████████▉ | 359/400 [06:32<00:41,  1.02s/it]Running loglikelihood requests:  90%|█████████ | 360/400 [06:33<00:40,  1.02s/it]Running loglikelihood requests:  90%|█████████ | 361/400 [06:34<00:39,  1.02s/it]Running loglikelihood requests:  90%|█████████ | 362/400 [06:35<00:38,  1.02s/it]Running loglikelihood requests:  91%|█████████ | 363/400 [06:36<00:37,  1.01s/it]Running loglikelihood requests:  91%|█████████ | 364/400 [06:37<00:36,  1.01s/it]Running loglikelihood requests:  91%|█████████▏| 365/400 [06:38<00:35,  1.01s/it]Running loglikelihood requests:  92%|█████████▏| 366/400 [06:39<00:34,  1.01s/it]Running loglikelihood requests:  92%|█████████▏| 367/400 [06:40<00:33,  1.01s/it]Running loglikelihood requests:  92%|█████████▏| 368/400 [06:41<00:32,  1.01s/it]Running loglikelihood requests:  92%|█████████▏| 369/400 [06:42<00:31,  1.01s/it]Running loglikelihood requests:  92%|█████████▎| 370/400 [06:43<00:30,  1.01s/it]Running loglikelihood requests:  93%|█████████▎| 371/400 [06:44<00:29,  1.01s/it]Running loglikelihood requests:  93%|█████████▎| 372/400 [06:45<00:28,  1.01s/it]Running loglikelihood requests:  93%|█████████▎| 373/400 [06:46<00:27,  1.00s/it]Running loglikelihood requests:  94%|█████████▎| 374/400 [06:47<00:26,  1.00s/it]Running loglikelihood requests:  94%|█████████▍| 375/400 [06:48<00:25,  1.00s/it]Running loglikelihood requests:  94%|█████████▍| 376/400 [06:49<00:23,  1.00it/s]Running loglikelihood requests:  94%|█████████▍| 377/400 [06:50<00:22,  1.00it/s]Running loglikelihood requests:  94%|█████████▍| 378/400 [06:51<00:21,  1.01it/s]Running loglikelihood requests:  95%|█████████▍| 379/400 [06:52<00:20,  1.01it/s]Running loglikelihood requests:  95%|█████████▌| 380/400 [06:53<00:19,  1.01it/s]Running loglikelihood requests:  95%|█████████▌| 381/400 [06:54<00:18,  1.01it/s]Running loglikelihood requests:  96%|█████████▌| 382/400 [06:55<00:17,  1.01it/s]Running loglikelihood requests:  96%|█████████▌| 383/400 [06:56<00:16,  1.01it/s]Running loglikelihood requests:  96%|█████████▌| 384/400 [06:57<00:15,  1.01it/s]Running loglikelihood requests:  96%|█████████▋| 385/400 [06:58<00:14,  1.01it/s]Running loglikelihood requests:  96%|█████████▋| 386/400 [06:59<00:13,  1.01it/s]Running loglikelihood requests:  97%|█████████▋| 387/400 [07:00<00:12,  1.01it/s]Running loglikelihood requests:  97%|█████████▋| 388/400 [07:01<00:11,  1.01it/s]Running loglikelihood requests:  97%|█████████▋| 389/400 [07:02<00:10,  1.01it/s]Running loglikelihood requests:  98%|█████████▊| 390/400 [07:03<00:09,  1.02it/s]Running loglikelihood requests:  98%|█████████▊| 391/400 [07:04<00:08,  1.02it/s]Running loglikelihood requests:  98%|█████████▊| 392/400 [07:05<00:07,  1.02it/s]Running loglikelihood requests:  98%|█████████▊| 393/400 [07:06<00:06,  1.02it/s]Running loglikelihood requests:  98%|█████████▊| 394/400 [07:07<00:05,  1.02it/s]Running loglikelihood requests:  99%|█████████▉| 395/400 [07:08<00:04,  1.02it/s]Running loglikelihood requests:  99%|█████████▉| 396/400 [07:09<00:03,  1.02it/s]Running loglikelihood requests:  99%|█████████▉| 397/400 [07:10<00:02,  1.03it/s]Running loglikelihood requests: 100%|█████████▉| 398/400 [07:11<00:01,  1.04it/s]Running loglikelihood requests: 100%|█████████▉| 399/400 [07:12<00:00,  1.04it/s]Running loglikelihood requests: 100%|██████████| 400/400 [07:13<00:00,  1.04it/s]Running loglikelihood requests: 100%|██████████| 400/400 [07:13<00:00,  1.08s/it]
DEBUG:urllib3.connectionpool:Resetting dropped connection: hf-mirror.com
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/models/llama-moe/LLaMA-MoE-v1-3_5B-2_8/revision/main HTTP/1.1" 200 927
WARNING:lm_eval.models.huggingface:`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
INFO:lm_eval.models.huggingface:Model type cannot be determined. Using default model type 'causal'
WARNING:lm_eval.models.huggingface:Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
full model:
{'mastermind_35_easy': {'alias': 'mastermind_35_easy', 'acc,none': 0.51, 'acc_stderr,none': 0.05024183937956913}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9685093904417202
0.9837389482734848
0.9887891422859466
0.9728424941793791
0.9273096247071001
0.9956884174036557
0.9936991917224709
0.990637728847171
0.984416562505352
0.9357041463019401
0.957486187236088
0.9794440444506461
0.9854000882321717
0.989321120949945
0.9948124947717892
0.9950699411775289
0.9589145403056732
0.9488498047330014
0.979093344902028
0.9861615563222426
0.9944647439314634
0.9974738465425171
0.9932459641322177
0.9612113452387381
0.9566187588663586
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[5, 1, 0, 3, 7, 6, 2, 4]
tensor([5, 1, 0, 3, 7, 6, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 0, 3, 7, 5, 2, 4]
tensor([6, 1, 0, 3, 7, 5, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 1, 0, 3, 7, 6, 2, 4]
tensor([5, 1, 0, 3, 7, 6, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 0, 3, 7, 5, 2, 4]
tensor([6, 1, 0, 3, 7, 5, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 1, 0, 3, 7, 6, 2, 4]
tensor([5, 1, 0, 3, 7, 6, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 0, 3, 7, 5, 2, 4]
tensor([6, 1, 0, 3, 7, 5, 2, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Normal merging for layer 1
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Normal merging for layer 2
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Normal merging for layer 3
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Normal merging for layer 4
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([0])
tensor(0)
tensor([5])
tensor(5)
tensor([4])
tensor(4)
done!
Normal merging for layer 5
tensor([2])
tensor(2)
tensor([1])
tensor(1)
tensor([6])
tensor(6)
tensor([3])
tensor(3)
tensor([7])
tensor(7)
tensor([5])
tensor(5)
tensor([0])
tensor(0)
tensor([4])
tensor(4)
done!
Cross-layer merge completed for layers 6 to 31
done!
all done!
Model size: 12.0718 GB
Node 39 Flask server is running on port 5039...
Node 123 Flask server is running on port 5123...
Node 174 Flask server is running on port 5174...
Node 75 Flask server is running on port 5075...
Node 239 Flask server is running on port 5239...
Node 172 Flask server is running on port 5172...
Node 55 Flask server is running on port 5055...
Node 9 Flask server is running on port 5009...
Node 99 Flask server is running on port 5099...
Node 98 Flask server is running on port 5098...
Node 160 Flask server is running on port 5160...
Node 12 Flask server is running on port 5012...
Node 173 Flask server is running on port 5173...
Node 247 Flask server is running on port 5247...
Node 63 Flask server is running on port 5063...
Node 161 Flask server is running on port 5161...
Node 34 Flask server is running on port 5034...
Node 87 Flask server is running on port 5087...
Node 164 Flask server is running on port 5164...
Node 117 Flask server is running on port 5117...
 * Serving Flask app 'Node_llama_test'
Node 157 Flask server is running on port 5157...
Node 127 Flask server is running on port 5127...
 * Debug mode: off
Node 94 Flask server is running on port 5094...
Node 40 Flask server is running on port 5040...
Node 180 Flask server is running on port 5180...
Node 211 Flask server is running on port 5211...
Node 163 Flask server is running on port 5163...
Node 52 Flask server is running on port 5052...
Node 140 Flask server is running on port 5140...
Node 219 Flask server is running on port 5219...
Node 151 Flask server is running on port 5151...
Node 112 Flask server is running on port 5112...
[39] Inference Step Starting
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5039
 * Running on http://173.0.64.7:5039
INFO:werkzeug:[33mPress CTRL+C to quit[0m
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5174
 * Running on http://173.0.64.7:5174
 * Debug mode: off
INFO:werkzeug:[33mPress CTRL+C to quit[0m
 * Serving Flask app 'Node_llama_test'
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5161
 * Running on http://173.0.64.7:5161
 * Debug mode: off
INFO:werkzeug:[33mPress CTRL+C to quit[0m
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5055
 * Running on http://173.0.64.7:5055
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5098
 * Running on http://173.0.64.7:5098
INFO:werkzeug:[33mPress CTRL+C to quit[0m
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5164
 * Running on http://173.0.64.7:5164
 * Serving Flask app 'Node_llama_test'
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5239
 * Running on http://173.0.64.7:5239
 * Serving Flask app 'Node_llama_test'
INFO:werkzeug:[33mPress CTRL+C to quit[0m
 * Debug mode: off
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5075
 * Running on http://173.0.64.7:5075
 * Debug mode: off
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5151
 * Running on http://173.0.64.7:5151
INFO:werkzeug:[33mPress CTRL+C to quit[0m
 * Serving Flask app 'Node_llama_test'
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5173
 * Running on http://173.0.64.7:5173
 * Debug mode: off
INFO:werkzeug:[33mPress CTRL+C to quit[0m
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5012
 * Running on http://173.0.64.7:5012
INFO:werkzeug:[33mPress CTRL+C to quit[0m
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5127
 * Running on http://173.0.64.7:5127
INFO:werkzeug:[33mPress CTRL+C to quit[0m
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5211
 * Running on http://173.0.64.7:5211
INFO:werkzeug:[33mPress CTRL+C to quit[0m
 * Debug mode: off
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5140
 * Running on http://173.0.64.7:5140
 * Serving Flask app 'Node_llama_test'
INFO:werkzeug:[33mPress CTRL+C to quit[0m
 * Debug mode: off
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5247
 * Running on http://173.0.64.7:5247
INFO:werkzeug:[33mPress CTRL+C to quit[0m
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5040
 * Running on http://173.0.64.7:5040
INFO:werkzeug:[33mPress CTRL+C to quit[0m
 * Serving Flask app 'Node_llama_test'
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5219
 * Running on http://173.0.64.7:5219
INFO:werkzeug:[33mPress CTRL+C to quit[0m
 * Debug mode: off
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5099
 * Running on http://173.0.64.7:5099
 * Serving Flask app 'Node_llama_test'
INFO:werkzeug:[33mPress CTRL+C to quit[0m
 * Debug mode: off
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5094
 * Running on http://173.0.64.7:5094
 * Serving Flask app 'Node_llama_test'
INFO:werkzeug:[33mPress CTRL+C to quit[0m
 * Debug mode: off
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5052
 * Running on http://173.0.64.7:5052
INFO:werkzeug:[33mPress CTRL+C to quit[0m
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5112
 * Running on http://173.0.64.7:5112
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5087
 * Running on http://173.0.64.7:5087
 * Serving Flask app 'Node_llama_test'
INFO:werkzeug:[33mPress CTRL+C to quit[0m
 * Debug mode: off
INFO:werkzeug:[33mPress CTRL+C to quit[0m
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5157
 * Running on http://173.0.64.7:5157
INFO:werkzeug:[33mPress CTRL+C to quit[0m
 * Serving Flask app 'Node_llama_test'
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5009
 * Running on http://173.0.64.7:5009
 * Debug mode: off
INFO:werkzeug:[33mPress CTRL+C to quit[0m
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5034
 * Running on http://173.0.64.7:5034
INFO:werkzeug:[33mPress CTRL+C to quit[0m
 * Debug mode: off
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5160
 * Running on http://173.0.64.7:5160
 * Serving Flask app 'Node_llama_test'
INFO:werkzeug:[33mPress CTRL+C to quit[0m
 * Debug mode: off
 * Serving Flask app 'Node_llama_test'
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5163
 * Running on http://173.0.64.7:5163
 * Debug mode: off
INFO:werkzeug:[33mPress CTRL+C to quit[0m
 * Serving Flask app 'Node_llama_test'
 * Debug mode: off
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5180
 * Running on http://173.0.64.7:5180
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5117
 * Running on http://173.0.64.7:5117
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5172
 * Running on http://173.0.64.7:5172
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5123
 * Running on http://173.0.64.7:5123
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5063
 * Running on http://173.0.64.7:5063
INFO:werkzeug:[33mPress CTRL+C to quit[0m
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue/revision/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 111
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue/revision/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140218738157680 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140218738157680 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140218738157680 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140218738157680 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140237333804336 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140237333804336 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140237333804336 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140237333804336 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2604.25it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:15,  2.67s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:18,  1.43s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:42,  1.19s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:27,  1.09s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:21,  1.06s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:13<02:36,  1.19s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:15<02:22,  1.10s/it]Running loglikelihood requests:  11%|█         | 15/142 [00:17<02:20,  1.10s/it]Running loglikelihood requests:  12%|█▏        | 17/142 [00:19<02:07,  1.02s/it]Running loglikelihood requests:  13%|█▎        | 19/142 [00:21<02:06,  1.03s/it]Running loglikelihood requests:  15%|█▍        | 21/142 [00:22<01:55,  1.05it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:24<01:46,  1.11it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:25<01:39,  1.17it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:27<01:34,  1.22it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:28<01:29,  1.26it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:31<01:50,  1.01it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:33<01:40,  1.09it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:34<01:32,  1.16it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:36<01:26,  1.21it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:37<01:22,  1.25it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:39<01:18,  1.29it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:42<01:37,  1.01it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:43<01:27,  1.11it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:44<01:19,  1.19it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:46<01:13,  1.27it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:47<01:08,  1.33it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:48<01:04,  1.38it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:50<01:01,  1.42it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:51<01:02,  1.37it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:52<00:58,  1.42it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:54<00:55,  1.45it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:55<00:53,  1.48it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:56<00:51,  1.50it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:58<00:49,  1.52it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:59<00:47,  1.54it/s]Running loglikelihood requests:  50%|█████     | 71/142 [01:02<01:04,  1.11it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [01:03<00:57,  1.21it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [01:04<00:51,  1.30it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:06<00:47,  1.38it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:07<00:43,  1.44it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:08<00:41,  1.48it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:09<00:38,  1.52it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:13<00:58,  1.03s/it]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:15<00:49,  1.10it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:16<00:43,  1.22it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:17<00:38,  1.32it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:18<00:35,  1.40it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:19<00:32,  1.46it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:22<00:37,  1.20it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:23<00:32,  1.31it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:24<00:29,  1.39it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:25<00:26,  1.46it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:27<00:24,  1.51it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:28<00:22,  1.55it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:29<00:20,  1.58it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:30<00:19,  1.61it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:32<00:18,  1.54it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:33<00:17,  1.59it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:34<00:15,  1.62it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:35<00:13,  1.66it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:36<00:12,  1.67it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:37<00:11,  1.69it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:39<00:09,  1.71it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:40<00:08,  1.72it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:41<00:08,  1.60it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:43<00:07,  1.53it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:44<00:05,  1.60it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:45<00:04,  1.66it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:46<00:02,  1.70it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:47<00:01,  1.74it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:48<00:00,  1.78it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:48<00:00,  1.31it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-8): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10-22): 13 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (23): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24-31): 8 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-8): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10-22): 13 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (23): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24-31): 8 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/39.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:13:49] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5009
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:13:49] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5009 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 9
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5247
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:13:49] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5247 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 247
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5180
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:13:49] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5180 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 180
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:13:49] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5098
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:13:49] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5098 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 98
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:13:49] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5211
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:13:49] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5211 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 211
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5164
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:13:49] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5164 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 164
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:13:49] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5052
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:13:49] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5052 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 52
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5172
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:13:49] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5172 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 172
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5063
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:13:49] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5063 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 63
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:13:49] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5157
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:13:49] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5157 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 157
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5012
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:13:49] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5012 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 12
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:13:49] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5173
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:13:49] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5173 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 173
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:13:49] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5140
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:13:49] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5140 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 140
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5160
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:13:49] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5160 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 160
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:13:49] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5112
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:13:49] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5112 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 112
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5174
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:13:49] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5174 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 174
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:13:49] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5040
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:13:49] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5040 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 40
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5151
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:13:49] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5151 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 151
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5099
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:13:49] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5099 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 99
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5034
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:13:49] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5034 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 34
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5219
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:13:49] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5219 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 219
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5075
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:13:49] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5075 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 75
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140218738157680 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140218738157680 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140218738157680 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140218738157680 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140240955306352 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140240955306352 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140240955306352 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140240955306352 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[39] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4647887323943662, 'acc_stderr,none': 0.05961305784972239}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8670569790937798
0.5488271932172035
0.673013746499191
0.7739554714966184
0.626122351153327
0.7480239804573661
0.8404062667282521
0.585845593784257
0.5486089643527782
0.295628094796439
0.8187255304150794
0.4183228390778105
0.5130578032019412
0.8769017151034573
0.9364820135353734
0.9916222006713932
0.9862354083632185
0.9582978800582982
0.8980649992917061
0.8669816466709701
0.9008509099634621
0.9321426254796342
0.8646919425811247
0.6505326186022521
0.6612551300691957
0.8835733690017037
0.7234157945938043
0.7342253877992871
0.5683390151095499
0.8670569790937798
0.5488271932172035
0.673013746499191
0.7739554714966184
0.626122351153327
0.7480239804573661
0.8404062667282521
0.585845593784257
0.5486089643527782
0.295628094796439
0.8187255304150794
0.4183228390778105
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[5, 3, 6, 2, 4, 0, 7, 1]
tensor([5, 3, 6, 2, 4, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 4, 6, 7, 2, 0, 5, 1]
tensor([3, 4, 6, 7, 2, 0, 5, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 6, 2, 1, 3, 0, 7, 5]
tensor([4, 6, 2, 1, 3, 0, 7, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 4, 6, 0, 1, 2, 7, 3]
tensor([5, 4, 6, 0, 1, 2, 7, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 2, 6, 5, 4, 0, 7, 1]
tensor([3, 2, 6, 5, 4, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 2, 5, 6, 3, 0, 7, 1]
tensor([4, 2, 5, 6, 3, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/39.pt
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[RECEIVE] Queued message from 39
[QUEUE] Processing info from 39
[QUEUE] Stored info from 39
[123] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2555.46it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:03,  2.58s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:05<03:40,  1.58s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:07<02:59,  1.31s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:09<02:36,  1.16s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:23,  1.08s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:13<02:20,  1.08s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:11,  1.02s/it]Running loglikelihood requests:  11%|█         | 15/142 [00:17<02:16,  1.08s/it]Running loglikelihood requests:  12%|█▏        | 17/142 [00:18<02:05,  1.00s/it]Running loglikelihood requests:  13%|█▎        | 19/142 [00:20<01:55,  1.07it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:22<01:52,  1.07it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:23<01:44,  1.14it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:25<01:38,  1.19it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:27<01:48,  1.06it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:29<01:40,  1.13it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:30<01:34,  1.18it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:32<01:29,  1.22it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:33<01:25,  1.25it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:35<01:22,  1.27it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:37<01:23,  1.23it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:38<01:20,  1.26it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:40<01:16,  1.29it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:41<01:12,  1.33it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:42<01:09,  1.37it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:44<01:06,  1.40it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:45<01:03,  1.44it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:47<01:03,  1.39it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:48<01:00,  1.43it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:49<00:58,  1.45it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:50<00:56,  1.48it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:52<00:54,  1.50it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:53<00:52,  1.52it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:54<00:50,  1.53it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:56<00:48,  1.55it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:57<00:49,  1.49it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:58<00:46,  1.52it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [01:00<00:44,  1.54it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [01:01<00:43,  1.56it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:02<00:41,  1.58it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:03<00:39,  1.59it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:04<00:38,  1.60it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:06<00:36,  1.60it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:07<00:36,  1.55it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:08<00:34,  1.57it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:10<00:33,  1.59it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:11<00:31,  1.61it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:12<00:30,  1.62it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:13<00:28,  1.64it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:14<00:27,  1.65it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:16<00:26,  1.65it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:17<00:24,  1.66it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:18<00:24,  1.60it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:19<00:22,  1.63it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:20<00:21,  1.66it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:22<00:19,  1.68it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:23<00:18,  1.69it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:24<00:17,  1.70it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:25<00:15,  1.71it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:26<00:14,  1.72it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:28<00:13,  1.67it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:29<00:12,  1.68it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:30<00:11,  1.71it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:31<00:09,  1.73it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:32<00:08,  1.75it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:33<00:07,  1.76it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:34<00:06,  1.77it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:35<00:05,  1.79it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:36<00:03,  1.80it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:39<00:03,  1.41it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:40<00:01,  1.52it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:41<00:00,  1.62it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:41<00:00,  1.40it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-4): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-9): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (11-12): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (13): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14-19): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (20-21): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (22-23): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (25-31): 7 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-4): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-9): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (11-12): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (13): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14-19): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (20-21): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (22-23): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (25-31): 7 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/123.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5034
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:15:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5034 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 34
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5164
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:15:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5164 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 164
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5157
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:15:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5157 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 157
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5160
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:15:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5160 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 160
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:15:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5112
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:15:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5112 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 112
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5040
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:15:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5040 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 40
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5180
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:15:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5180 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 180
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5140
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:15:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5140 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 140
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:15:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5174
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:15:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5174 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 174
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5173
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:15:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5173 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 173
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5063
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:15:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5063 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 63
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:15:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5075
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:15:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5075 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 75
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5052
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:15:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5052 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 52
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5009
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:15:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5009 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 9
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5151
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:15:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5151 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 151
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:15:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:15:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:15:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5211
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:15:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5211 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 211
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5172
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:15:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5172 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 172
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:15:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5219
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:15:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5219 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 219
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:15:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5098
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:15:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5098 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 98
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5247
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:15:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5247 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 247
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:15:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5099
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:15:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5099 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 99
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5012
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:15:48] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5012 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 12
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140243031323424 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140243031323424 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140243031323424 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140243031323424 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140237864781344 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140237864781344 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140237864781344 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140237864781344 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[123] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.43661971830985913, 'acc_stderr,none': 0.05927935558412972}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8840011732877091
0.9530187867791682
0.922962504956303
0.7839472459406365
0.8981387177104178
0.9267264969548299
0.5821108615798573
0.2837945650872556
0.6077879555368297
0.40197237439213185
0.8904940347912964
0.7509530386402397
0.901875691813653
0.9122390055224058
0.7316046462179062
0.7968435583929763
0.548007144578676
0.5393492220671232
0.9101317167988644
0.5489553505889563
0.4310648048222707
0.3687557715800523
0.8114931082909914
0.5012706843250611
0.2095243909347347
0.3518983916697559
0.9676050865236582
0.8840253404453832
0.6389046419601837
0.8840011732877091
0.9530187867791682
0.922962504956303
0.7839472459406365
0.8981387177104178
0.9267264969548299
0.5821108615798573
0.2837945650872556
0.6077879555368297
0.40197237439213185
0.8904940347912964
0.7509530386402397
0.901875691813653
0.9122390055224058
0.7316046462179062
0.7968435583929763
0.548007144578676
0.5393492220671232
0.9101317167988644
0.5489553505889563
Total groups 72 exceeded the threshold, stopping comparison.
The group tensor is
[1, 2, 7, 4, 3, 0, 6, 5]
tensor([1, 2, 7, 4, 3, 0, 6, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 5, 4, 1, 0, 7, 2]
tensor([6, 3, 5, 4, 1, 0, 7, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[1, 3, 6, 4, 2, 0, 7, 5]
tensor([1, 3, 6, 4, 2, 0, 7, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 3, 6, 4, 0, 1, 7, 2]
tensor([5, 3, 6, 4, 0, 1, 7, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 4, 6, 5, 3, 0, 7, 1]
tensor([2, 4, 6, 5, 3, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 5, 2, 4, 0, 1, 3]
tensor([0, 1, 5, 2, 4, 0, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/123.pt
[RECEIVE] Queued message from 123
[QUEUE] Processing info from 123
[QUEUE] Stored info from 123
[RECEIVE] Queued message from 123
[QUEUE] Processing info from 123
[QUEUE] Stored info from 123
[RECEIVE] Queued message from 123
[QUEUE] Processing info from 123
[QUEUE] Stored info from 123
[RECEIVE] Queued message from 123
[QUEUE] Processing info from 123
[QUEUE] Stored info from 123
[RECEIVE] Queued message from 123
[QUEUE] Processing info from 123
[QUEUE] Stored info from 123
[RECEIVE] Queued message from 123
[QUEUE] Processing info from 123
[QUEUE] Stored info from 123
[RECEIVE] Queued message from 123
[QUEUE] Processing info from 123
[QUEUE] Stored info from 123
[RECEIVE] Queued message from 123
[QUEUE] Processing info from 123
[QUEUE] Stored info from 123
[RECEIVE] Queued message from 123
[QUEUE] Processing info from 123
[QUEUE] Stored info from 123
[RECEIVE] Queued message from 123
[QUEUE] Processing info from 123
[QUEUE] Stored info from 123
[RECEIVE] Queued message from 123
[QUEUE] Processing info from 123
[QUEUE] Stored info from 123
[RECEIVE] Queued message from 123
[QUEUE] Processing info from 123
[QUEUE] Stored info from 123
[RECEIVE] Queued message from 123
[QUEUE] Processing info from 123
[QUEUE] Stored info from 123
[RECEIVE] Queued message from 123
[QUEUE] Processing info from 123
[QUEUE] Stored info from 123
[RECEIVE] Queued message from 123
[QUEUE] Processing info from 123
[QUEUE] Stored info from 123
[RECEIVE] Queued message from 123
[QUEUE] Processing info from 123
[QUEUE] Stored info from 123
[RECEIVE] Queued message from 123
[QUEUE] Processing info from 123
[QUEUE] Stored info from 123
[RECEIVE] Queued message from 123
[QUEUE] Processing info from 123
[QUEUE] Stored info from 123
[RECEIVE] Queued message from 123
[QUEUE] Processing info from 123
[QUEUE] Stored info from 123
[RECEIVE] Queued message from 123
[QUEUE] Processing info from 123
[QUEUE] Stored info from 123
[RECEIVE] Queued message from 123
[QUEUE] Processing info from 123
[QUEUE] Stored info from 123
[RECEIVE] Queued message from 123
[QUEUE] Processing info from 123
[QUEUE] Stored info from 123
[RECEIVE] Queued message from 123
[QUEUE] Processing info from 123
[QUEUE] Stored info from 123
[RECEIVE] Queued message from 123
[QUEUE] Processing info from 123
[QUEUE] Stored info from 123
[RECEIVE] Queued message from 123
[QUEUE] Processing info from 123
[QUEUE] Stored info from 123
[RECEIVE] Queued message from 123
[QUEUE] Processing info from 123
[QUEUE] Stored info from 123
[RECEIVE] Queued message from 123
[QUEUE] Processing info from 123
[QUEUE] Stored info from 123
[RECEIVE] Queued message from 123
[QUEUE] Processing info from 123
[QUEUE] Stored info from 123
[RECEIVE] Queued message from 123
[QUEUE] Processing info from 123
[QUEUE] Stored info from 123
[RECEIVE] Queued message from 123
[QUEUE] Processing info from 123
[QUEUE] Stored info from 123
[RECEIVE] Queued message from 123
[QUEUE] Processing info from 123
[QUEUE] Stored info from 123
[174] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2617.78it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:03<08:43,  3.71s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:05<03:52,  1.67s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:07<02:57,  1.29s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:09<02:38,  1.18s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:11<02:38,  1.19s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:13<02:25,  1.11s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:15<02:14,  1.04s/it]Running loglikelihood requests:  11%|█         | 15/142 [00:17<02:04,  1.02it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:19<01:56,  1.08it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:20<01:48,  1.13it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:22<01:47,  1.13it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:23<01:40,  1.18it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:25<01:34,  1.23it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:26<01:32,  1.25it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:28<01:27,  1.28it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:29<01:24,  1.32it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:31<01:26,  1.26it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:32<01:22,  1.30it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:34<01:19,  1.33it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:35<01:16,  1.35it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:37<01:14,  1.36it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:38<01:12,  1.37it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:40<01:09,  1.40it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:41<01:08,  1.38it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:42<01:05,  1.42it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:44<01:02,  1.45it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:45<01:00,  1.47it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:46<00:57,  1.50it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:48<00:55,  1.52it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:49<00:54,  1.53it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:50<00:52,  1.54it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:52<00:52,  1.49it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:53<00:50,  1.52it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:54<00:48,  1.54it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:55<00:46,  1.56it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:57<00:45,  1.57it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:58<00:45,  1.53it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [00:59<00:43,  1.55it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:00<00:41,  1.58it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:02<00:45,  1.38it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:03<00:42,  1.45it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:05<00:39,  1.51it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:06<00:36,  1.55it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:07<00:34,  1.58it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:08<00:33,  1.60it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:09<00:31,  1.62it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:11<00:29,  1.64it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:12<00:31,  1.52it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:13<00:28,  1.56it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:15<00:26,  1.60it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:16<00:25,  1.63it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:17<00:23,  1.65it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:18<00:22,  1.67it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:19<00:20,  1.68it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:20<00:19,  1.69it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:22<00:18,  1.71it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:23<00:18,  1.58it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:24<00:16,  1.62it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:25<00:15,  1.64it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:27<00:13,  1.68it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:28<00:12,  1.70it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:29<00:11,  1.72it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:30<00:09,  1.73it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:31<00:08,  1.75it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:32<00:07,  1.67it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:33<00:06,  1.71it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:35<00:05,  1.75it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:36<00:03,  1.78it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:37<00:03,  1.55it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:38<00:01,  1.63it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:39<00:00,  1.71it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:39<00:00,  1.42it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-31): 26 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-31): 26 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/174.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:17:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5040
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:17:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5040 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 40
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5157
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:17:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5157 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 157
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5151
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:17:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5151 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 151
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5034
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:17:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5034 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 34
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5172
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:17:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5172 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 172
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:17:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5009
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:17:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5009 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 9
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:17:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5012
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:17:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5012 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 12
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5219
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:17:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5219 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 219
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:17:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:17:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:17:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:17:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:17:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5164
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:17:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5164 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 164
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5098
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:17:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5098 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 98
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5099
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:17:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5099 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 99
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:17:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5075
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:17:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5075 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 75
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5211
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:17:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5211 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 211
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5112
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:17:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5112 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 112
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5140
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:17:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5140 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 140
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:17:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5160
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:17:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5160 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 160
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5247
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:17:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5247 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 247
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5052
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:17:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5052 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 52
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5173
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:17:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5173 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 173
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5180
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:17:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5180 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 180
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5063
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:17:45] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5063 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 63
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140234416451232 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140234416451232 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140234416451232 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140234416451232 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140240012156160 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140240012156160 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140240012156160 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140240012156160 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[174] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4084507042253521, 'acc_stderr,none': 0.058751136942575236}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8470147925890528
0.7476864669376683
0.7057458194715966
0.9259961826035564
0.9063486644110201
0.24963708122926456
0.19827660218091203
0.8342224461031358
0.674768686362321
0.8317740713616216
0.8052770539851904
0.87411142785436
0.9423251627051763
0.6325449231299249
0.5709019604280002
0.492272078021527
0.5470094105753499
0.8106788106419917
0.8007286389438932
0.8514363351777328
0.5678533410855942
0.6964663000476322
0.43791892189616227
0.24333097709743945
0.6773756911035087
0.7468917488225975
0.9536421875896308
0.6970547096788922
0.8446279043078407
0.8470147925890528
0.7476864669376683
0.7057458194715966
0.9259961826035564
0.9063486644110201
0.24963708122926456
0.19827660218091203
0.8342224461031358
0.674768686362321
0.8317740713616216
0.8052770539851904
0.87411142785436
0.9423251627051763
0.6325449231299249
0.5709019604280002
0.492272078021527
Total groups 76 exceeded the threshold, stopping comparison.
The group tensor is
[3, 4, 6, 5, 2, 0, 7, 1]
tensor([3, 4, 6, 5, 2, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 4, 6, 5, 3, 0, 7, 1]
tensor([2, 4, 6, 5, 3, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[6, 3, 4, 5, 2, 0, 7, 1]
tensor([6, 3, 4, 5, 2, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[1, 4, 7, 2, 5, 0, 6, 3]
tensor([1, 4, 7, 2, 5, 0, 6, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[0, 3, 5, 2, 0, 1, 1, 4]
tensor([0, 3, 5, 2, 0, 1, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[4, 3, 0, 5, 2, 0, 1, 1]
tensor([4, 3, 0, 5, 2, 0, 1, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 3, 5, 1, 4, 0, 1, 2]
tensor([0, 3, 5, 1, 4, 0, 1, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1, 0, 1.0, 1.0, 1.0]
tensor([0, 1, 1, 1, 0, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/174.pt
[RECEIVE] Queued message from 174
[QUEUE] Processing info from 174
[QUEUE] Stored info from 174
[RECEIVE] Queued message from 174
[QUEUE] Processing info from 174
[QUEUE] Stored info from 174
[RECEIVE] Queued message from 174
[QUEUE] Processing info from 174
[QUEUE] Stored info from 174
[RECEIVE] Queued message from 174
[QUEUE] Processing info from 174
[QUEUE] Stored info from 174
[RECEIVE] Queued message from 174
[QUEUE] Processing info from 174
[QUEUE] Stored info from 174
[RECEIVE] Queued message from 174
[QUEUE] Processing info from 174
[QUEUE] Stored info from 174
[RECEIVE] Queued message from 174
[QUEUE] Processing info from 174
[QUEUE] Stored info from 174
[RECEIVE] Queued message from 174
[QUEUE] Processing info from 174
[QUEUE] Stored info from 174
[RECEIVE] Queued message from 174
[QUEUE] Processing info from 174
[QUEUE] Stored info from 174
[RECEIVE] Queued message from 174
[QUEUE] Processing info from 174
[QUEUE] Stored info from 174
[RECEIVE] Queued message from 174
[QUEUE] Processing info from 174
[QUEUE] Stored info from 174
[RECEIVE] Queued message from 174
[QUEUE] Processing info from 174
[QUEUE] Stored info from 174
[RECEIVE] Queued message from 174
[QUEUE] Processing info from 174
[QUEUE] Stored info from 174
[RECEIVE] Queued message from 174
[QUEUE] Processing info from 174
[QUEUE] Stored info from 174
[RECEIVE] Queued message from 174
[QUEUE] Processing info from 174
[QUEUE] Stored info from 174
[RECEIVE] Queued message from 174
[QUEUE] Processing info from 174
[QUEUE] Stored info from 174
[RECEIVE] Queued message from 174
[QUEUE] Processing info from 174
[QUEUE] Stored info from 174
[RECEIVE] Queued message from 174
[QUEUE] Processing info from 174
[QUEUE] Stored info from 174
[RECEIVE] Queued message from 174
[QUEUE] Processing info from 174
[QUEUE] Stored info from 174
[RECEIVE] Queued message from 174
[QUEUE] Processing info from 174
[QUEUE] Stored info from 174
[RECEIVE] Queued message from 174
[QUEUE] Processing info from 174
[QUEUE] Stored info from 174
[RECEIVE] Queued message from 174
[QUEUE] Processing info from 174
[QUEUE] Stored info from 174
[RECEIVE] Queued message from 174
[QUEUE] Processing info from 174
[QUEUE] Stored info from 174
[RECEIVE] Queued message from 174
[QUEUE] Processing info from 174
[QUEUE] Stored info from 174
[RECEIVE] Queued message from 174
[QUEUE] Processing info from 174
[QUEUE] Stored info from 174
[RECEIVE] Queued message from 174
[QUEUE] Processing info from 174
[QUEUE] Stored info from 174
[RECEIVE] Queued message from 174
[QUEUE] Processing info from 174
[QUEUE] Stored info from 174
[RECEIVE] Queued message from 174
[QUEUE] Processing info from 174
[QUEUE] Stored info from 174
[RECEIVE] Queued message from 174
[QUEUE] Processing info from 174
[QUEUE] Stored info from 174
[RECEIVE] Queued message from 174
[QUEUE] Processing info from 174
[QUEUE] Stored info from 174
[RECEIVE] Queued message from 174
[QUEUE] Processing info from 174
[QUEUE] Stored info from 174
[75] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2585.12it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:01,  2.57s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:08,  1.36s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:41,  1.18s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:25,  1.08s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:14,  1.01s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:11<02:06,  1.03it/s]Running loglikelihood requests:   9%|▉         | 13/142 [00:13<01:59,  1.08it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:15<02:01,  1.05it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:17<01:52,  1.11it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:18<01:45,  1.17it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:20<01:39,  1.21it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:22<01:45,  1.13it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:23<01:37,  1.20it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:26<01:50,  1.04it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:27<01:39,  1.13it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:29<01:32,  1.21it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:30<01:26,  1.26it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:31<01:22,  1.30it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:33<01:19,  1.33it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:34<01:16,  1.35it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:36<01:23,  1.20it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:38<01:18,  1.27it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:39<01:12,  1.33it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:40<01:08,  1.39it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:42<01:04,  1.44it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:43<01:01,  1.48it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:44<00:58,  1.51it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:46<01:02,  1.40it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:47<00:58,  1.46it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:48<00:55,  1.50it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:49<00:52,  1.54it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:51<00:50,  1.56it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:52<00:48,  1.58it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:53<00:46,  1.60it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:54<00:45,  1.62it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:56<00:48,  1.48it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:57<00:45,  1.53it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [00:58<00:42,  1.56it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:00<00:40,  1.59it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:01<00:38,  1.62it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:02<00:37,  1.64it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:03<00:35,  1.66it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:04<00:34,  1.66it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:06<00:32,  1.67it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:08<00:38,  1.37it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:09<00:35,  1.46it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:10<00:32,  1.53it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:11<00:29,  1.59it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:12<00:27,  1.64it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:13<00:25,  1.67it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:15<00:24,  1.69it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:16<00:22,  1.72it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:17<00:22,  1.63it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:18<00:20,  1.67it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:19<00:19,  1.70it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:20<00:18,  1.72it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:22<00:16,  1.74it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:23<00:15,  1.74it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:24<00:14,  1.75it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:25<00:13,  1.77it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:26<00:11,  1.78it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:27<00:11,  1.71it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:28<00:09,  1.74it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:29<00:08,  1.78it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:31<00:07,  1.80it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:32<00:06,  1.82it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:33<00:04,  1.84it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:34<00:03,  1.86it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:35<00:02,  1.88it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:36<00:01,  1.90it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:37<00:00,  1.82it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:37<00:00,  1.46it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-31): 26 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-31): 26 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/75.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:19:41] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5052
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:19:41] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5052 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 52
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5063
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:19:41] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5063 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 63
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5098
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:19:41] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5098 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 98
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5034
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:19:41] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5034 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 34
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5151
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:19:41] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5151 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 151
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:19:41] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5174
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:19:41] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5174 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 174
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:19:41] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5040
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:19:41] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5040 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 40
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:19:41] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5157
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:19:41] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5157 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 157
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:19:41] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5172
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:19:41] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5172 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 172
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5247
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:19:41] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5247 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 247
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5219
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:19:41] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5219 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 219
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5009
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:19:41] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5009 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 9
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5173
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:19:41] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5173 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 173
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5160
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:19:41] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5160 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 160
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5140
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:19:41] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5140 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 140
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:19:41] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:19:41] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5164
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:19:41] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5164 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 164
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:19:41] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:19:41] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:19:41] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5012
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:19:42] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5012 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 12
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5112
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:19:42] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5112 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 112
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5180
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:19:42] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5180 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 180
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5099
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:19:42] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5099 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 99
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5211
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:19:42] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5211 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 211
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140233170190800 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140233170190800 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140233170190800 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140233170190800 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140239883411888 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140239883411888 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140239883411888 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140239883411888 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[75] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4084507042253521, 'acc_stderr,none': 0.058751136942575236}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8470147925890528
0.7476864669376683
0.7057458194715966
0.9259961826035564
0.9063486644110201
0.24963708122926456
0.19827660218091203
0.8342224461031358
0.674768686362321
0.8317740713616216
0.8052770539851904
0.87411142785436
0.9423251627051763
0.6325449231299249
0.5709019604280002
0.492272078021527
0.5470094105753499
0.8106788106419917
0.8007286389438932
0.8514363351777328
0.5678533410855942
0.6964663000476322
0.43791892189616227
0.24333097709743945
0.6773756911035087
0.7468917488225975
0.9536421875896308
0.6970547096788922
0.8446279043078407
0.8470147925890528
0.7476864669376683
0.7057458194715966
0.9259961826035564
0.9063486644110201
0.24963708122926456
0.19827660218091203
0.8342224461031358
0.674768686362321
0.8317740713616216
0.8052770539851904
0.87411142785436
0.9423251627051763
0.6325449231299249
0.5709019604280002
0.492272078021527
Total groups 76 exceeded the threshold, stopping comparison.
The group tensor is
[3, 4, 6, 5, 2, 0, 7, 1]
tensor([3, 4, 6, 5, 2, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 4, 6, 5, 3, 0, 7, 1]
tensor([2, 4, 6, 5, 3, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[6, 3, 4, 5, 2, 0, 7, 1]
tensor([6, 3, 4, 5, 2, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[1, 4, 7, 2, 5, 0, 6, 3]
tensor([1, 4, 7, 2, 5, 0, 6, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[0, 3, 5, 2, 0, 1, 1, 4]
tensor([0, 3, 5, 2, 0, 1, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[4, 3, 0, 5, 2, 0, 1, 1]
tensor([4, 3, 0, 5, 2, 0, 1, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 3, 5, 1, 4, 0, 1, 2]
tensor([0, 3, 5, 1, 4, 0, 1, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1, 0, 1.0, 1.0, 1.0]
tensor([0, 1, 1, 1, 0, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/75.pt
[RECEIVE] Queued message from 75
[QUEUE] Processing info from 75
[QUEUE] Stored info from 75
[RECEIVE] Queued message from 75
[QUEUE] Processing info from 75
[QUEUE] Stored info from 75
[RECEIVE] Queued message from 75
[QUEUE] Processing info from 75
[QUEUE] Stored info from 75
[RECEIVE] Queued message from 75
[QUEUE] Processing info from 75
[QUEUE] Stored info from 75
[RECEIVE] Queued message from 75
[QUEUE] Processing info from 75
[QUEUE] Stored info from 75
[RECEIVE] Queued message from 75
[QUEUE] Processing info from 75
[QUEUE] Stored info from 75
[RECEIVE] Queued message from 75
[QUEUE] Processing info from 75
[QUEUE] Stored info from 75
[RECEIVE] Queued message from 75
[QUEUE] Processing info from 75
[QUEUE] Stored info from 75
[RECEIVE] Queued message from 75
[QUEUE] Processing info from 75
[QUEUE] Stored info from 75
[RECEIVE] Queued message from 75
[QUEUE] Processing info from 75
[QUEUE] Stored info from 75
[RECEIVE] Queued message from 75
[QUEUE] Processing info from 75
[QUEUE] Stored info from 75
[RECEIVE] Queued message from 75
[QUEUE] Processing info from 75
[QUEUE] Stored info from 75
[RECEIVE] Queued message from 75
[QUEUE] Processing info from 75
[QUEUE] Stored info from 75
[RECEIVE] Queued message from 75
[QUEUE] Processing info from 75
[QUEUE] Stored info from 75
[RECEIVE] Queued message from 75
[QUEUE] Processing info from 75
[QUEUE] Stored info from 75
[RECEIVE] Queued message from 75
[QUEUE] Processing info from 75
[QUEUE] Stored info from 75
[RECEIVE] Queued message from 75
[QUEUE] Processing info from 75
[QUEUE] Stored info from 75
[RECEIVE] Queued message from 75
[QUEUE] Processing info from 75
[QUEUE] Stored info from 75
[RECEIVE] Queued message from 75
[QUEUE] Processing info from 75
[QUEUE] Stored info from 75
[RECEIVE] Queued message from 75
[QUEUE] Processing info from 75
[QUEUE] Stored info from 75
[RECEIVE] Queued message from 75
[QUEUE] Processing info from 75
[QUEUE] Stored info from 75
[RECEIVE] Queued message from 75
[QUEUE] Processing info from 75
[QUEUE] Stored info from 75
[RECEIVE] Queued message from 75
[QUEUE] Processing info from 75
[QUEUE] Stored info from 75
[RECEIVE] Queued message from 75
[QUEUE] Processing info from 75
[QUEUE] Stored info from 75
[RECEIVE] Queued message from 75
[QUEUE] Processing info from 75
[QUEUE] Stored info from 75
[RECEIVE] Queued message from 75
[QUEUE] Processing info from 75
[QUEUE] Stored info from 75
[RECEIVE] Queued message from 75
[QUEUE] Processing info from 75
[QUEUE] Stored info from 75
[RECEIVE] Queued message from 75
[QUEUE] Processing info from 75
[QUEUE] Stored info from 75
[RECEIVE] Queued message from 75
[QUEUE] Processing info from 75
[QUEUE] Stored info from 75
[RECEIVE] Queued message from 75
[QUEUE] Processing info from 75
[QUEUE] Stored info from 75
[RECEIVE] Queued message from 75
[QUEUE] Processing info from 75
[QUEUE] Stored info from 75
[239] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2584.74it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:03<08:46,  3.73s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:05<03:54,  1.68s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:07<02:59,  1.31s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:09<02:35,  1.15s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:11<02:21,  1.06s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:13<02:16,  1.04s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:15<02:06,  1.02it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:16<01:58,  1.07it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:18<01:52,  1.11it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:20<01:51,  1.11it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:21<01:44,  1.16it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:23<01:40,  1.18it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:24<01:35,  1.23it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:26<01:31,  1.26it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:27<01:27,  1.29it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:29<01:24,  1.32it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:30<01:21,  1.34it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:32<01:18,  1.35it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:33<01:19,  1.33it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:35<01:17,  1.34it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:36<01:15,  1.35it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:38<01:22,  1.20it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:40<01:16,  1.27it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:41<01:11,  1.33it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:42<01:10,  1.33it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:46<01:30,  1.00it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:47<01:19,  1.12it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:48<01:13,  1.19it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:50<01:06,  1.28it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:51<01:01,  1.36it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:52<00:56,  1.42it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:54<01:01,  1.28it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:55<00:56,  1.36it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:56<00:52,  1.43it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:58<00:49,  1.48it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:59<00:46,  1.51it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [01:00<00:44,  1.54it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [01:01<00:42,  1.57it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:03<00:40,  1.59it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:04<00:41,  1.53it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:05<00:38,  1.57it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:06<00:37,  1.59it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:08<00:35,  1.61it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:09<00:33,  1.63it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:10<00:32,  1.64it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:11<00:30,  1.65it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:12<00:29,  1.66it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:15<00:38,  1.21it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:16<00:34,  1.32it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:18<00:30,  1.42it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:19<00:27,  1.50it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:20<00:24,  1.56it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:21<00:23,  1.61it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:22<00:21,  1.65it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:24<00:22,  1.48it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:25<00:19,  1.55it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:26<00:18,  1.61it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:27<00:16,  1.65it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:28<00:14,  1.67it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:29<00:13,  1.71it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:31<00:12,  1.73it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:32<00:10,  1.74it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:33<00:09,  1.76it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:35<00:09,  1.51it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:36<00:08,  1.60it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:37<00:06,  1.66it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:38<00:05,  1.72it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:39<00:03,  1.77it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:40<00:02,  1.80it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:41<00:01,  1.83it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:42<00:00,  1.87it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:42<00:00,  1.38it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-6): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (7): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (8-12): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (13): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (15-18): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (19): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (20-23): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (25-31): 7 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-6): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (7): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (8-12): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (13): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (15-18): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (19): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (20-23): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (25-31): 7 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/239.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:21:41] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:21:41] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5151
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:21:41] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5151 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 151
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5009
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:21:41] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5009 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 9
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:21:41] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5099
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:21:42] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5099 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 99
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:21:42] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5034
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:21:42] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5034 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 34
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5075
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:21:42] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5075 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 75
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5172
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:21:42] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5172 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 172
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5112
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:21:42] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5112 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 112
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5211
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:21:42] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5211 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 211
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:21:42] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5098
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:21:42] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5098 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 98
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:21:42] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5180
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:21:42] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5180 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 180
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5157
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:21:42] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5157 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 157
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:21:42] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5012
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:21:42] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5012 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 12
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5219
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:21:42] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5219 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 219
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5160
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:21:42] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5160 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 160
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5040
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:21:42] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5040 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 40
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:21:42] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5164
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:21:42] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5164 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 164
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5063
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:21:42] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5063 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 63
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5174
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:21:42] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5174 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 174
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:21:42] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5052
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:21:42] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5052 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 52
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5140
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:21:42] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5140 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 140
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5173
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:21:42] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5173 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 173
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5247
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:21:42] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5247 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 247
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140218740642144 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140218740642144 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140218740642144 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140218740642144 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140240012151408 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140240012151408 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140240012151408 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140240012151408 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[239] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.43661971830985913, 'acc_stderr,none': 0.05927935558412972}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.45379462613562144
0.5121987218538359
0.3805605062852953
0.9250105662738365
0.5393046917775384
0.6260326331104198
0.8626372247282749
0.4859614961709456
0.13108090074681872
0.540361134548941
0.3691796883542366
0.8419863957417434
0.3738225663436576
0.7939340566193666
0.6916928670672426
0.661840354699148
0.5510051512470766
0.5066100211995253
0.5208949147180995
0.7283079951082674
0.8857784175671931
0.553624027417834
0.6922319498836209
0.6063680148478464
0.9220941595054846
0.9172099247528117
0.5762720309944068
0.05484791873187908
0.6210078066443784
0.45379462613562144
0.5121987218538359
0.3805605062852953
0.9250105662738365
0.5393046917775384
0.6260326331104198
0.8626372247282749
0.4859614961709456
0.13108090074681872
0.540361134548941
0.3691796883542366
0.8419863957417434
0.3738225663436576
0.7939340566193666
0.6916928670672426
0.661840354699148
0.5510051512470766
0.5066100211995253
0.5208949147180995
0.7283079951082674
0.8857784175671931
0.553624027417834
Total groups 72 exceeded the threshold, stopping comparison.
The group tensor is
[1, 2, 6, 3, 5, 0, 7, 4]
tensor([1, 2, 6, 3, 5, 0, 7, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 4, 3, 2, 0, 6, 7, 1]
tensor([5, 4, 3, 2, 0, 6, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 4, 6, 2, 5, 0, 7, 1]
tensor([3, 4, 6, 2, 5, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 2, 4, 6, 1, 0, 3, 5]
tensor([7, 2, 4, 6, 1, 0, 3, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 0, 7, 4, 3, 5, 6, 1]
tensor([2, 0, 7, 4, 3, 5, 6, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[3, 0, 5, 4, 1, 0, 1, 2]
tensor([3, 0, 5, 4, 1, 0, 1, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/239.pt
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[RECEIVE] Queued message from 239
[QUEUE] Processing info from 239
[QUEUE] Stored info from 239
[172] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2614.65it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:03<08:21,  3.56s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:05<03:45,  1.62s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:07<02:53,  1.26s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:09<02:32,  1.13s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:18,  1.04s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:13<02:16,  1.04s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:06,  1.02it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:16<01:58,  1.07it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:18<01:51,  1.12it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:19<01:44,  1.17it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:21<01:39,  1.22it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:22<01:34,  1.26it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:24<01:35,  1.23it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:25<01:30,  1.27it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:27<01:27,  1.29it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:28<01:23,  1.33it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:30<01:20,  1.35it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:31<01:18,  1.37it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:32<01:16,  1.38it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:34<01:16,  1.35it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:35<01:13,  1.37it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:37<01:13,  1.34it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:38<01:10,  1.38it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:40<01:07,  1.42it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:41<01:05,  1.43it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:42<01:04,  1.42it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:44<01:12,  1.23it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:46<01:06,  1.31it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:48<01:07,  1.25it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:49<01:01,  1.34it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:50<00:57,  1.41it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:51<00:53,  1.46it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:53<00:51,  1.51it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:54<00:50,  1.48it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:55<00:47,  1.52it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:56<00:45,  1.55it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:58<00:43,  1.58it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [00:59<00:41,  1.60it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:00<00:40,  1.61it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:01<00:38,  1.63it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:02<00:37,  1.64it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:04<00:37,  1.58it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:05<00:35,  1.60it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:06<00:33,  1.62it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:07<00:32,  1.64it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:09<00:30,  1.65it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:10<00:29,  1.66it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:11<00:28,  1.67it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:12<00:26,  1.68it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:13<00:25,  1.69it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:15<00:26,  1.54it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:16<00:24,  1.59it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:17<00:22,  1.63it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:18<00:21,  1.66it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:19<00:19,  1.68it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:21<00:18,  1.70it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:22<00:16,  1.72it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:23<00:15,  1.73it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:24<00:16,  1.56it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:26<00:14,  1.62it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:27<00:12,  1.66it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:28<00:11,  1.70it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:29<00:09,  1.73it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:30<00:08,  1.76it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:31<00:07,  1.78it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:32<00:06,  1.80it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:33<00:04,  1.82it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:35<00:03,  1.76it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:36<00:02,  1.80it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:37<00:01,  1.83it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:38<00:00,  1.87it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:38<00:00,  1.45it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-31): 26 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-31): 26 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/172.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5040
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:23:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5040 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 40
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5052
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:23:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5052 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 52
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5247
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:23:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5247 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 247
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5034
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:23:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5034 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 34
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5112
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:23:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5112 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 112
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:23:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:23:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5211
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:23:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5211 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 211
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5063
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:23:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5063 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 63
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5098
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:23:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5098 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 98
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5219
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:23:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5219 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 219
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5173
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:23:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5173 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 173
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:23:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:23:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5157
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:23:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5157 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 157
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5075
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:23:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5075 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 75
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:23:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5140
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:23:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5140 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 140
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5160
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:23:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5160 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 160
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5164
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:23:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5164 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 164
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:23:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:23:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5012
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:23:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5012 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 12
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:23:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5009
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:23:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5009 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 9
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5180
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:23:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5180 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 180
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:23:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5099
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:23:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5099 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 99
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5174
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:23:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5174 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 174
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:23:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5151
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:23:40] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5151 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 151
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140240419488496 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140240419488496 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140240419488496 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140240419488496 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140218790400400 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140218790400400 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140218790400400 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140218790400400 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[172] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4225352112676056, 'acc_stderr,none': 0.059039842056825796}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8301327615319641
0.7817720914227475
0.8113678911982368
0.2257173763133808
0.2927105469616105
0.5177793359335131
0.8145737190612207
0.7363478990038121
0.20758834533702153
0.2533018140549718
0.30764875086796684
0.29044714199656413
0.9350374080783923
0.6277994360424477
0.603553220567354
0.78279661631625
0.6718149226457006
0.5353760149732133
0.6848376228333551
0.9446001512801305
0.7972906165117697
0.5043025319455414
0.5939887608746786
0.6455402209569181
0.2505215486241291
0.321550947803521
0.8361163063826382
0.7208169010376037
0.9633188772100769
0.8301327615319641
0.7817720914227475
0.8113678911982368
0.2257173763133808
0.2927105469616105
0.5177793359335131
0.8145737190612207
0.7363478990038121
0.20758834533702153
0.2533018140549718
0.30764875086796684
0.29044714199656413
0.9350374080783923
0.6277994360424477
0.603553220567354
0.78279661631625
0.6718149226457006
0.5353760149732133
0.6848376228333551
0.9446001512801305
0.7972906165117697
0.5043025319455414
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[6, 5, 4, 1, 3, 0, 7, 2]
tensor([6, 5, 4, 1, 3, 0, 7, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 7, 5, 1, 0, 4, 2]
tensor([6, 3, 7, 5, 1, 0, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[6, 4, 7, 0, 3, 1, 5, 2]
tensor([6, 4, 7, 0, 3, 1, 5, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 5, 3, 4, 1, 0, 7, 6]
tensor([2, 5, 3, 4, 1, 0, 7, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 5, 0, 2, 4, 0, 1, 1]
tensor([3, 5, 0, 2, 4, 0, 1, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 1, 0, 2, 1, 2, 3]
tensor([0, 3, 1, 0, 2, 1, 2, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 3, 1, 2, 2, 1, 3, 0]
tensor([0, 3, 1, 2, 2, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 1, 2, 0, 3, 3, 2, 1]
tensor([0, 1, 2, 0, 3, 3, 2, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1, 0, 1.0, 1.0, 1.0, 1.0]
tensor([0, 1, 1, 0, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/172.pt
[RECEIVE] Queued message from 172
[QUEUE] Processing info from 172
[QUEUE] Stored info from 172
[RECEIVE] Queued message from 172
[QUEUE] Processing info from 172
[QUEUE] Stored info from 172
[RECEIVE] Queued message from 172
[QUEUE] Processing info from 172
[QUEUE] Stored info from 172
[RECEIVE] Queued message from 172
[QUEUE] Processing info from 172
[QUEUE] Stored info from 172
[RECEIVE] Queued message from 172
[QUEUE] Processing info from 172
[QUEUE] Stored info from 172
[RECEIVE] Queued message from 172
[QUEUE] Processing info from 172
[QUEUE] Stored info from 172
[RECEIVE] Queued message from 172
[QUEUE] Processing info from 172
[QUEUE] Stored info from 172
[RECEIVE] Queued message from 172
[QUEUE] Processing info from 172
[QUEUE] Stored info from 172
[RECEIVE] Queued message from 172
[QUEUE] Processing info from 172
[QUEUE] Stored info from 172
[RECEIVE] Queued message from 172
[QUEUE] Processing info from 172
[QUEUE] Stored info from 172
[RECEIVE] Queued message from 172
[QUEUE] Processing info from 172
[QUEUE] Stored info from 172
[RECEIVE] Queued message from 172
[QUEUE] Processing info from 172
[QUEUE] Stored info from 172
[RECEIVE] Queued message from 172
[QUEUE] Processing info from 172
[QUEUE] Stored info from 172
[RECEIVE] Queued message from 172
[QUEUE] Processing info from 172
[QUEUE] Stored info from 172
[RECEIVE] Queued message from 172
[QUEUE] Processing info from 172
[QUEUE] Stored info from 172
[RECEIVE] Queued message from 172
[QUEUE] Processing info from 172
[QUEUE] Stored info from 172
[RECEIVE] Queued message from 172
[QUEUE] Processing info from 172
[QUEUE] Stored info from 172
[RECEIVE] Queued message from 172
[QUEUE] Processing info from 172
[QUEUE] Stored info from 172
[RECEIVE] Queued message from 172
[QUEUE] Processing info from 172
[QUEUE] Stored info from 172
[RECEIVE] Queued message from 172
[QUEUE] Processing info from 172
[QUEUE] Stored info from 172
[RECEIVE] Queued message from 172
[QUEUE] Processing info from 172
[QUEUE] Stored info from 172
[RECEIVE] Queued message from 172
[QUEUE] Processing info from 172
[QUEUE] Stored info from 172
[RECEIVE] Queued message from 172
[QUEUE] Processing info from 172
[QUEUE] Stored info from 172
[RECEIVE] Queued message from 172
[QUEUE] Processing info from 172
[QUEUE] Stored info from 172
[RECEIVE] Queued message from 172
[QUEUE] Processing info from 172
[QUEUE] Stored info from 172
[RECEIVE] Queued message from 172
[QUEUE] Processing info from 172
[QUEUE] Stored info from 172
[RECEIVE] Queued message from 172
[QUEUE] Processing info from 172
[QUEUE] Stored info from 172
[RECEIVE] Queued message from 172
[QUEUE] Processing info from 172
[QUEUE] Stored info from 172
[RECEIVE] Queued message from 172
[QUEUE] Processing info from 172
[QUEUE] Stored info from 172
[RECEIVE] Queued message from 172
[QUEUE] Processing info from 172
[QUEUE] Stored info from 172
[RECEIVE] Queued message from 172
[QUEUE] Processing info from 172
[QUEUE] Stored info from 172
[55] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2604.04it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:03<07:44,  3.29s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:05<03:38,  1.57s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:07<02:51,  1.25s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:09<02:31,  1.13s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:11<02:23,  1.08s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:13,  1.02s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:05,  1.03it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:16<01:58,  1.07it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:18<01:53,  1.11it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:19<01:49,  1.12it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:21<01:43,  1.17it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:22<01:38,  1.21it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:24<01:33,  1.25it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:25<01:29,  1.29it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:27<01:26,  1.31it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:28<01:23,  1.33it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:30<01:24,  1.30it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:31<01:21,  1.31it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:33<01:19,  1.33it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:34<01:17,  1.33it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:36<01:14,  1.35it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:37<01:12,  1.36it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:38<01:10,  1.39it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:40<01:10,  1.35it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:41<01:06,  1.39it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:43<01:03,  1.43it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:44<01:01,  1.46it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:45<00:58,  1.48it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:47<00:56,  1.50it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:48<00:55,  1.51it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:49<00:53,  1.51it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:51<00:55,  1.43it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:52<00:52,  1.46it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:53<00:50,  1.47it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:55<00:48,  1.49it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:56<00:46,  1.51it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:57<00:44,  1.54it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [00:59<00:43,  1.56it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:00<00:41,  1.57it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:01<00:40,  1.54it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:02<00:39,  1.56it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:04<00:37,  1.58it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:05<00:35,  1.60it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:06<00:34,  1.61it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:07<00:32,  1.62it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:08<00:31,  1.63it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:10<00:29,  1.64it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:12<00:33,  1.42it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:13<00:30,  1.48it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:14<00:28,  1.53it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:15<00:26,  1.57it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:16<00:24,  1.60it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:17<00:22,  1.63it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:19<00:21,  1.64it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:20<00:20,  1.62it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:21<00:19,  1.55it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:23<00:18,  1.60it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:24<00:16,  1.64it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:25<00:15,  1.66it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:26<00:13,  1.69it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:27<00:12,  1.70it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:28<00:11,  1.72it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:29<00:09,  1.73it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:31<00:08,  1.69it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:32<00:07,  1.70it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:33<00:06,  1.73it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:34<00:05,  1.76it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:35<00:03,  1.78it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:36<00:02,  1.81it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:37<00:01,  1.83it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:38<00:00,  1.85it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:38<00:00,  1.44it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-8): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10-22): 13 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (23): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24-31): 8 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-8): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10-22): 13 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (23): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24-31): 8 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/55.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5075
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:25:36] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5075 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 75
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5211
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:25:36] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5211 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 211
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5157
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:25:36] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5157 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 157
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5160
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:25:36] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5160 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 160
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5172
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:25:36] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5172 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 172
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:25:36] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5012
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:25:36] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5012 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 12
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:25:36] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:25:36] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5009
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:25:36] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5009 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 9
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5173
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:25:36] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5173 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 173
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:25:36] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5040
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:25:36] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5040 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 40
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5112
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:25:36] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5112 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 112
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5219
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:25:36] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5219 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 219
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5034
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:25:36] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5034 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 34
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:25:36] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5180
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:25:36] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5180 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 180
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:25:37] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5063
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:25:37] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5063 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 63
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5151
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:25:37] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5151 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 151
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5099
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:25:37] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5099 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 99
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:25:37] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5140
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:25:37] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5140 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 140
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:25:37] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5052
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:25:37] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5052 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 52
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5247
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:25:37] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5247 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 247
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5174
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:25:37] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5174 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 174
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:25:37] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5164
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:25:37] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5164 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 164
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5098
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:25:37] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5098 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 98
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140240017044400 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140240017044400 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140240017044400 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140240017044400 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140218637337040 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140218637337040 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140218637337040 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140218637337040 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[55] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4647887323943662, 'acc_stderr,none': 0.05961305784972239}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8670569790937798
0.5488271932172035
0.673013746499191
0.7739554714966184
0.626122351153327
0.7480239804573661
0.8404062667282521
0.585845593784257
0.5486089643527782
0.295628094796439
0.8187255304150794
0.4183228390778105
0.5130578032019412
0.8769017151034573
0.9364820135353734
0.9916222006713932
0.9862354083632185
0.9582978800582982
0.8980649992917061
0.8669816466709701
0.9008509099634621
0.9321426254796342
0.8646919425811247
0.6505326186022521
0.6612551300691957
0.8835733690017037
0.7234157945938043
0.7342253877992871
0.5683390151095499
0.8670569790937798
0.5488271932172035
0.673013746499191
0.7739554714966184
0.626122351153327
0.7480239804573661
0.8404062667282521
0.585845593784257
0.5486089643527782
0.295628094796439
0.8187255304150794
0.4183228390778105
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[5, 3, 6, 2, 4, 0, 7, 1]
tensor([5, 3, 6, 2, 4, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 4, 6, 7, 2, 0, 5, 1]
tensor([3, 4, 6, 7, 2, 0, 5, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 6, 2, 1, 3, 0, 7, 5]
tensor([4, 6, 2, 1, 3, 0, 7, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 4, 6, 0, 1, 2, 7, 3]
tensor([5, 4, 6, 0, 1, 2, 7, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 2, 6, 5, 4, 0, 7, 1]
tensor([3, 2, 6, 5, 4, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 2, 5, 6, 3, 0, 7, 1]
tensor([4, 2, 5, 6, 3, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/55.pt
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[RECEIVE] Queued message from 55
[QUEUE] Processing info from 55
[QUEUE] Stored info from 55
[9] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2602.54it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:03<07:18,  3.11s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:05<03:29,  1.51s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:07<02:51,  1.25s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:30,  1.12s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:18,  1.04s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:09,  1.01it/s]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:15,  1.05s/it]Running loglikelihood requests:  11%|█         | 15/142 [00:16<02:07,  1.01s/it]Running loglikelihood requests:  12%|█▏        | 17/142 [00:18<02:00,  1.04it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:19<01:51,  1.10it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:21<01:44,  1.16it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:22<01:38,  1.21it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:24<01:33,  1.26it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:25<01:28,  1.30it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:27<01:28,  1.28it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:28<01:24,  1.32it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:30<01:21,  1.34it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:31<01:18,  1.36it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:33<01:16,  1.38it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:34<01:14,  1.38it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:36<01:12,  1.39it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:38<01:19,  1.24it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:39<01:14,  1.31it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:40<01:10,  1.36it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:42<01:07,  1.38it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:43<01:03,  1.43it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:44<01:01,  1.46it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:45<00:58,  1.49it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:47<00:59,  1.42it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:48<00:56,  1.46it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:50<00:53,  1.50it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:51<00:51,  1.52it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:52<00:49,  1.54it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:53<00:48,  1.55it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:55<00:46,  1.56it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:56<00:45,  1.57it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:57<00:45,  1.51it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [00:59<00:43,  1.54it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:00<00:41,  1.56it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:01<00:39,  1.60it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:02<00:37,  1.62it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:03<00:36,  1.64it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:05<00:34,  1.65it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:06<00:33,  1.66it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:07<00:33,  1.57it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:08<00:31,  1.60it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:10<00:30,  1.62it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:11<00:28,  1.64it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:12<00:27,  1.66it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:13<00:25,  1.67it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:14<00:24,  1.65it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:16<00:23,  1.67it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:17<00:22,  1.68it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:18<00:22,  1.56it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:19<00:20,  1.60it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:20<00:18,  1.64it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:22<00:17,  1.67it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:23<00:15,  1.70it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:24<00:14,  1.71it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:25<00:13,  1.73it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:26<00:12,  1.62it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:28<00:11,  1.60it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:29<00:10,  1.65it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:30<00:08,  1.69it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:31<00:07,  1.68it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:32<00:06,  1.71it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:33<00:05,  1.75it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:34<00:03,  1.78it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:36<00:02,  1.81it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:37<00:01,  1.84it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:38<00:00,  1.80it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:38<00:00,  1.45it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-8): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10-30): 21 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (31): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-8): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10-30): 21 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (31): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/9.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:27:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5034
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:27:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5034 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 34
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:27:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5219
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:27:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5219 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 219
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5164
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:27:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5164 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 164
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5012
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:27:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5012 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 12
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:27:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5172
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:27:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5172 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 172
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5099
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:27:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5099 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 99
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5174
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:27:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5174 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 174
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:27:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5247
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:27:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5247 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 247
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:27:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5151
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:27:32] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5151 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 151
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:27:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5098
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:27:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5098 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 98
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5180
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:27:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5180 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 180
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:27:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:27:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5211
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:27:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5211 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 211
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5112
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:27:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5112 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 112
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5140
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:27:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5140 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 140
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:27:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:27:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5052
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:27:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5052 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 52
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5075
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:27:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5075 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 75
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5063
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:27:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5063 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 63
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5157
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:27:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5157 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 157
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5160
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:27:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5160 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 160
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5040
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:27:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5040 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 40
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5173
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:27:33] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5173 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 173
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140218774364736 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140218774364736 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140218774364736 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140218774364736 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140237327955056 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140237327955056 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140237327955056 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140237327955056 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[9] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4507042253521127, 'acc_stderr,none': 0.05947027187738001}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.891975958338049
0.3982001908036579
0.26652204443251004
0.14111026067874816
0.11763525057572936
0.8635004180455561
0.8741394655456793
0.5304527321557103
0.44617634270319845
0.7007455592903002
0.6799150362476898
0.3511365594568724
0.47145939463701925
0.4744673317050211
0.905435493752087
0.903612941640167
0.8893763849001028
0.6821933807976941
0.6796182015499347
0.7774502436639344
0.8164788896198145
0.9011095591650676
0.8564639597370403
0.9528866120532432
0.4784452972921274
0.48852492817861076
0.8397355586186119
0.7433051149723976
0.5457687574271932
0.891975958338049
0.3982001908036579
0.26652204443251004
0.14111026067874816
0.11763525057572936
0.8635004180455561
0.8741394655456793
0.5304527321557103
0.44617634270319845
0.7007455592903002
0.6799150362476898
0.3511365594568724
0.47145939463701925
0.4744673317050211
0.905435493752087
0.903612941640167
0.8893763849001028
0.6821933807976941
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[6, 5, 4, 3, 2, 1, 7, 0]
tensor([6, 5, 4, 3, 2, 1, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 7, 4, 1, 0, 6, 3]
tensor([5, 2, 7, 4, 1, 0, 6, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 6, 5, 2, 4, 0, 7, 1]
tensor([3, 6, 5, 2, 4, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 4, 6, 0, 2, 1, 7, 3]
tensor([5, 4, 6, 0, 2, 1, 7, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 0, 7, 3, 5, 1, 6, 2]
tensor([4, 0, 7, 3, 5, 1, 6, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 5, 1, 3, 2, 0, 1, 4]
tensor([0, 5, 1, 3, 2, 0, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[1, 0, 0, 1, 1.0, 1.0, 1.0, 1.0]
tensor([1, 0, 0, 1, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[1, 0, 1, 1.0, 1.0, 0, 1.0, 1.0]
tensor([1, 0, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[0, 1, 1.0, 1.0, 0, 1, 1.0, 1.0]
tensor([0, 1, 1, 1, 0, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/9.pt
[RECEIVE] Queued message from 9
[QUEUE] Processing info from 9
[QUEUE] Stored info from 9
[RECEIVE] Queued message from 9
[QUEUE] Processing info from 9
[QUEUE] Stored info from 9
[RECEIVE] Queued message from 9
[QUEUE] Processing info from 9
[QUEUE] Stored info from 9
[RECEIVE] Queued message from 9
[QUEUE] Processing info from 9
[QUEUE] Stored info from 9
[RECEIVE] Queued message from 9
[QUEUE] Processing info from 9
[QUEUE] Stored info from 9
[RECEIVE] Queued message from 9
[QUEUE] Processing info from 9
[QUEUE] Stored info from 9
[RECEIVE] Queued message from 9
[QUEUE] Processing info from 9
[QUEUE] Stored info from 9
[RECEIVE] Queued message from 9
[QUEUE] Processing info from 9
[QUEUE] Stored info from 9
[RECEIVE] Queued message from 9
[QUEUE] Processing info from 9
[QUEUE] Stored info from 9
[RECEIVE] Queued message from 9
[QUEUE] Processing info from 9
[QUEUE] Stored info from 9
[RECEIVE] Queued message from 9
[QUEUE] Processing info from 9
[QUEUE] Stored info from 9
[RECEIVE] Queued message from 9
[QUEUE] Processing info from 9
[QUEUE] Stored info from 9
[RECEIVE] Queued message from 9
[QUEUE] Processing info from 9
[QUEUE] Stored info from 9
[RECEIVE] Queued message from 9
[QUEUE] Processing info from 9
[QUEUE] Stored info from 9
[RECEIVE] Queued message from 9
[QUEUE] Processing info from 9
[QUEUE] Stored info from 9
[RECEIVE] Queued message from 9
[QUEUE] Processing info from 9
[QUEUE] Stored info from 9
[RECEIVE] Queued message from 9
[QUEUE] Processing info from 9
[QUEUE] Stored info from 9
[RECEIVE] Queued message from 9
[QUEUE] Processing info from 9
[QUEUE] Stored info from 9
[RECEIVE] Queued message from 9
[QUEUE] Processing info from 9
[QUEUE] Stored info from 9
[RECEIVE] Queued message from 9
[QUEUE] Processing info from 9
[QUEUE] Stored info from 9
[RECEIVE] Queued message from 9
[QUEUE] Processing info from 9
[QUEUE] Stored info from 9
[RECEIVE] Queued message from 9
[QUEUE] Processing info from 9
[QUEUE] Stored info from 9
[RECEIVE] Queued message from 9
[QUEUE] Processing info from 9
[QUEUE] Stored info from 9
[RECEIVE] Queued message from 9
[QUEUE] Processing info from 9
[QUEUE] Stored info from 9
[RECEIVE] Queued message from 9
[QUEUE] Processing info from 9
[QUEUE] Stored info from 9
[RECEIVE] Queued message from 9
[QUEUE] Processing info from 9
[QUEUE] Stored info from 9
[RECEIVE] Queued message from 9
[QUEUE] Processing info from 9
[QUEUE] Stored info from 9
[RECEIVE] Queued message from 9
[QUEUE] Processing info from 9
[QUEUE] Stored info from 9
[RECEIVE] Queued message from 9
[QUEUE] Processing info from 9
[QUEUE] Stored info from 9
[RECEIVE] Queued message from 9
[QUEUE] Processing info from 9
[QUEUE] Stored info from 9
[RECEIVE] Queued message from 9
[QUEUE] Processing info from 9
[QUEUE] Stored info from 9
[99] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2607.46it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:15,  2.67s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:19,  1.44s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:40,  1.17s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:24,  1.07s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:13,  1.01s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:11<02:06,  1.04it/s]Running loglikelihood requests:   9%|▉         | 13/142 [00:13<02:03,  1.05it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:15<01:56,  1.09it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:17<01:49,  1.14it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:18<01:43,  1.19it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:20<01:38,  1.23it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:21<01:33,  1.27it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:22<01:29,  1.31it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:24<01:28,  1.30it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:25<01:24,  1.34it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:27<01:21,  1.36it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:28<01:18,  1.38it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:30<01:16,  1.40it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:31<01:14,  1.40it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:32<01:12,  1.41it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:34<01:13,  1.37it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:35<01:11,  1.39it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:37<01:08,  1.42it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:38<01:05,  1.45it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:39<01:02,  1.48it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:41<01:01,  1.47it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:42<00:59,  1.50it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:43<00:56,  1.53it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:45<01:00,  1.42it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:46<00:56,  1.46it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:47<00:54,  1.49it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:49<00:51,  1.52it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:50<00:49,  1.54it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:51<00:48,  1.56it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:52<00:46,  1.58it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:54<00:44,  1.59it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:55<00:44,  1.55it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [00:56<00:42,  1.57it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [00:57<00:40,  1.59it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [00:59<00:39,  1.61it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:00<00:37,  1.61it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:01<00:36,  1.62it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:02<00:35,  1.63it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:04<00:33,  1.64it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:05<00:33,  1.57it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:06<00:31,  1.60it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:07<00:30,  1.62it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:09<00:28,  1.65it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:10<00:27,  1.66it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:11<00:25,  1.67it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:12<00:24,  1.68it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:13<00:22,  1.70it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:14<00:21,  1.69it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:16<00:21,  1.60it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:17<00:20,  1.64it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:18<00:18,  1.67it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:19<00:17,  1.69it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:20<00:15,  1.71it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:22<00:15,  1.63it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:23<00:13,  1.67it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:24<00:12,  1.70it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:25<00:11,  1.61it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:27<00:10,  1.66it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:28<00:08,  1.70it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:29<00:07,  1.73it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:30<00:06,  1.76it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:31<00:05,  1.78it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:32<00:03,  1.80it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:33<00:02,  1.83it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:34<00:01,  1.84it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:35<00:00,  1.80it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:35<00:00,  1.48it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-31): 26 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-31): 26 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/99.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5211
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:29:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5211 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 211
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5098
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:29:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5098 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 98
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:29:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5140
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:29:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5140 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 140
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5012
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:29:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5012 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 12
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:29:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5009
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:29:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5009 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 9
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5219
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:29:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5219 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 219
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:29:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5160
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:29:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5160 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 160
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:29:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5052
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:29:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5052 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 52
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5157
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:29:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5157 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 157
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5112
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:29:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5112 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 112
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5063
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:29:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5063 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 63
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5034
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:29:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5034 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 34
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:29:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5040
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:29:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5040 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 40
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5180
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:29:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5180 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 180
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:29:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5164
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:29:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5164 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 164
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5247
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:29:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5247 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 247
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5172
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:29:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5172 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 172
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:29:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:29:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:29:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5173
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:29:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5173 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 173
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5174
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:29:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5174 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 174
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:29:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5151
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:29:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5151 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 151
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5075
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:29:25] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5075 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 75
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140218659818624 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140218659818624 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140218659818624 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140218659818624 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140218745976208 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140218745976208 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140218745976208 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140218745976208 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[99] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4225352112676056, 'acc_stderr,none': 0.059039842056825796}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9416968404415913
0.7938815868474761
0.8191819727516524
0.8917669687772857
0.90570342985793
0.3043907333176312
0.4952220736758006
0.29899990072660143
0.7758711420345523
0.838301482150715
0.8086122742620726
0.9126741954079025
0.6304407611776705
0.6595297618724628
0.176689009460142
0.4424440684940646
0.43152501031897406
0.48316840881543294
0.43857258209632005
0.7021905687600761
0.2402003641072479
0.27348823957209967
0.6649171314730306
0.25117416182112623
0.9114030338716436
0.9328254651349717
0.9096786197852272
0.9107213191843687
0.8764776988845487
0.9416968404415913
0.7938815868474761
0.8191819727516524
0.8917669687772857
0.90570342985793
0.3043907333176312
0.4952220736758006
0.29899990072660143
0.7758711420345523
0.838301482150715
0.8086122742620726
0.9126741954079025
0.6304407611776705
0.6595297618724628
0.176689009460142
0.4424440684940646
0.43152501031897406
Total groups 76 exceeded the threshold, stopping comparison.
The group tensor is
[4, 3, 7, 2, 5, 1, 6, 0]
tensor([4, 3, 7, 2, 5, 1, 6, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 5, 7, 4, 3, 0, 6, 1]
tensor([2, 5, 7, 4, 3, 0, 6, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 5, 4, 0, 1, 1, 2]
tensor([0, 3, 5, 4, 0, 1, 1, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[4, 3, 0, 2, 5, 0, 1, 1]
tensor([4, 3, 0, 2, 5, 0, 1, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 0, 5, 1, 4, 2, 1, 3]
tensor([0, 0, 5, 1, 4, 2, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[3, 4, 0, 1, 2, 0, 5, 1]
tensor([3, 4, 0, 1, 2, 0, 5, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[5, 0, 4, 3, 2, 0, 1, 1]
tensor([5, 0, 4, 3, 2, 0, 1, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 3, 4, 0, 1, 2, 1, 5]
tensor([0, 3, 4, 0, 1, 2, 1, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/99.pt
[RECEIVE] Queued message from 99
[QUEUE] Processing info from 99
[QUEUE] Stored info from 99
[RECEIVE] Queued message from 99
[QUEUE] Processing info from 99
[QUEUE] Stored info from 99
[RECEIVE] Queued message from 99
[QUEUE] Processing info from 99
[QUEUE] Stored info from 99
[RECEIVE] Queued message from 99
[QUEUE] Processing info from 99
[QUEUE] Stored info from 99
[RECEIVE] Queued message from 99
[QUEUE] Processing info from 99
[QUEUE] Stored info from 99
[RECEIVE] Queued message from 99
[QUEUE] Processing info from 99
[QUEUE] Stored info from 99
[RECEIVE] Queued message from 99
[QUEUE] Processing info from 99
[QUEUE] Stored info from 99
[RECEIVE] Queued message from 99
[QUEUE] Processing info from 99
[QUEUE] Stored info from 99
[RECEIVE] Queued message from 99
[QUEUE] Processing info from 99
[QUEUE] Stored info from 99
[RECEIVE] Queued message from 99
[QUEUE] Processing info from 99
[QUEUE] Stored info from 99
[RECEIVE] Queued message from 99
[QUEUE] Processing info from 99
[QUEUE] Stored info from 99
[RECEIVE] Queued message from 99
[QUEUE] Processing info from 99
[QUEUE] Stored info from 99
[RECEIVE] Queued message from 99
[QUEUE] Processing info from 99
[QUEUE] Stored info from 99
[RECEIVE] Queued message from 99
[QUEUE] Processing info from 99
[QUEUE] Stored info from 99
[RECEIVE] Queued message from 99
[QUEUE] Processing info from 99
[QUEUE] Stored info from 99
[RECEIVE] Queued message from 99
[QUEUE] Processing info from 99
[QUEUE] Stored info from 99
[RECEIVE] Queued message from 99
[QUEUE] Processing info from 99
[QUEUE] Stored info from 99
[RECEIVE] Queued message from 99
[QUEUE] Processing info from 99
[QUEUE] Stored info from 99
[RECEIVE] Queued message from 99
[QUEUE] Processing info from 99
[QUEUE] Stored info from 99
[RECEIVE] Queued message from 99
[QUEUE] Processing info from 99
[QUEUE] Stored info from 99
[RECEIVE] Queued message from 99
[QUEUE] Processing info from 99
[QUEUE] Stored info from 99
[RECEIVE] Queued message from 99
[QUEUE] Processing info from 99
[QUEUE] Stored info from 99
[RECEIVE] Queued message from 99
[QUEUE] Processing info from 99
[QUEUE] Stored info from 99
[RECEIVE] Queued message from 99
[QUEUE] Processing info from 99
[QUEUE] Stored info from 99
[RECEIVE] Queued message from 99
[QUEUE] Processing info from 99
[QUEUE] Stored info from 99
[RECEIVE] Queued message from 99
[QUEUE] Processing info from 99
[QUEUE] Stored info from 99
[RECEIVE] Queued message from 99
[QUEUE] Processing info from 99
[QUEUE] Stored info from 99
[RECEIVE] Queued message from 99
[QUEUE] Processing info from 99
[QUEUE] Stored info from 99
[RECEIVE] Queued message from 99
[QUEUE] Processing info from 99
[QUEUE] Stored info from 99
[RECEIVE] Queued message from 99
[QUEUE] Processing info from 99
[QUEUE] Stored info from 99
[RECEIVE] Queued message from 99
[QUEUE] Processing info from 99
[QUEUE] Stored info from 99
[98] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2569.97it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:03<07:28,  3.18s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:05<03:31,  1.52s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:46,  1.21s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:26,  1.09s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:15,  1.02s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:10,  1.00it/s]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:02,  1.06it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:15<01:55,  1.10it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:17<01:49,  1.14it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:18<01:43,  1.19it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:20<01:38,  1.23it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:21<01:33,  1.27it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:23<01:34,  1.23it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:25<01:29,  1.29it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:26<01:25,  1.32it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:27<01:22,  1.35it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:29<01:19,  1.37it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:30<01:17,  1.39it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:32<01:15,  1.40it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:33<01:18,  1.30it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:35<01:15,  1.34it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:36<01:12,  1.37it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:37<01:09,  1.41it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:39<01:06,  1.44it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:40<01:03,  1.47it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:41<01:00,  1.50it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:43<01:01,  1.46it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:44<00:58,  1.48it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:45<00:56,  1.52it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:47<00:53,  1.55it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:48<00:51,  1.56it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:49<00:49,  1.58it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:50<00:48,  1.60it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:52<00:46,  1.61it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:53<00:48,  1.51it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:54<00:45,  1.55it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:55<00:43,  1.58it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [00:57<00:42,  1.59it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [00:58<00:40,  1.61it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [00:59<00:38,  1.63it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:00<00:37,  1.64it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:01<00:35,  1.65it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:03<00:36,  1.57it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:04<00:34,  1.60it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:05<00:32,  1.62it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:06<00:31,  1.63it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:08<00:29,  1.65it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:09<00:28,  1.68it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:10<00:26,  1.69it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:11<00:25,  1.70it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:12<00:24,  1.70it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:14<00:25,  1.51it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:15<00:23,  1.58it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:16<00:21,  1.63it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:17<00:19,  1.67it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:18<00:18,  1.70it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:20<00:16,  1.72it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:21<00:15,  1.74it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:22<00:14,  1.76it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:23<00:12,  1.78it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:24<00:12,  1.65it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:25<00:11,  1.69it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:27<00:09,  1.73it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:28<00:08,  1.76it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:29<00:07,  1.79it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:30<00:06,  1.80it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:31<00:04,  1.82it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:32<00:03,  1.85it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:33<00:02,  1.88it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:37<00:02,  1.01it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:38<00:00,  1.19it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:38<00:00,  1.44it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-16): 12 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (17-18): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (19): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (20-31): 12 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-16): 12 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (17-18): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (19): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (20-31): 12 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/98.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5112
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:31:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5112 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 112
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5172
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:31:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5172 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 172
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5173
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:31:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5173 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 173
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5075
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:31:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5075 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 75
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:31:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5009
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:31:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5009 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 9
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5052
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:31:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5052 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 52
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5012
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:31:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5012 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 12
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5160
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:31:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5160 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 160
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5211
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:31:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5211 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 211
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:31:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5219
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:31:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5219 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 219
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:31:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5164
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:31:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5164 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 164
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5174
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:31:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5174 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 174
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:31:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:31:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5157
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:31:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5157 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 157
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5063
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:31:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5063 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 63
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5151
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:31:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5151 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 151
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:31:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5247
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:31:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5247 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 247
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5034
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:31:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5034 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 34
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5140
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:31:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5140 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 140
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5099
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:31:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5099 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 99
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5040
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:31:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5040 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 40
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:31:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:31:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:31:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:31:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5180
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:31:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5180 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 180
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140218774359408 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140218774359408 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140218774359408 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140218774359408 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140218785862416 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140218785862416 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140218785862416 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140218785862416 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[98] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4507042253521127, 'acc_stderr,none': 0.05947027187738001}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.5492204626454702
0.13502488496756465
0.9275303495607449
0.7165821511880784
0.7594126839120312
0.8664668964215797
0.7349473681509868
0.7930425076096883
0.8162917298680349
0.8517270618457119
0.5861829129308435
0.5835405684895388
0.588879417394676
0.5205548377189629
0.7140538082286251
0.531207880500868
0.8809821166189434
0.6995488915401884
0.4683250920235365
0.5868402787291006
0.7967272991738612
0.8359030243014328
0.776130470073111
0.7836617242516619
0.8225513545207798
0.7161038509602672
0.7843138704646394
0.6004827793986917
0.8596931332130378
0.5492204626454702
0.13502488496756465
0.9275303495607449
0.7165821511880784
0.7594126839120312
0.8664668964215797
0.7349473681509868
0.7930425076096883
0.8162917298680349
0.8517270618457119
0.5861829129308435
0.5835405684895388
0.588879417394676
0.5205548377189629
0.7140538082286251
0.531207880500868
0.8809821166189434
0.6995488915401884
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[2, 4, 6, 3, 5, 0, 7, 1]
tensor([2, 4, 6, 3, 5, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 2, 0, 5, 3, 1, 6, 7]
tensor([4, 2, 0, 5, 3, 1, 6, 7], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 3, 6, 2, 4, 0, 7, 1]
tensor([5, 3, 6, 2, 4, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[7, 1, 6, 4, 2, 0, 5, 3]
tensor([7, 1, 6, 4, 2, 0, 5, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 5, 1, 2, 3, 0, 1, 4]
tensor([0, 5, 1, 2, 3, 0, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[3, 0, 2, 5, 4, 1, 1, 0]
tensor([3, 0, 2, 5, 4, 1, 1, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 1, 4, 5, 2, 0, 1, 3]
tensor([0, 1, 4, 5, 2, 0, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/98.pt
[RECEIVE] Queued message from 98
[QUEUE] Processing info from 98
[QUEUE] Stored info from 98
[RECEIVE] Queued message from 98
[QUEUE] Processing info from 98
[QUEUE] Stored info from 98
[RECEIVE] Queued message from 98
[QUEUE] Processing info from 98
[QUEUE] Stored info from 98
[RECEIVE] Queued message from 98
[QUEUE] Processing info from 98
[QUEUE] Stored info from 98
[RECEIVE] Queued message from 98
[QUEUE] Processing info from 98
[QUEUE] Stored info from 98
[RECEIVE] Queued message from 98
[QUEUE] Processing info from 98
[QUEUE] Stored info from 98
[RECEIVE] Queued message from 98
[QUEUE] Processing info from 98
[QUEUE] Stored info from 98
[RECEIVE] Queued message from 98
[QUEUE] Processing info from 98
[QUEUE] Stored info from 98
[RECEIVE] Queued message from 98
[QUEUE] Processing info from 98
[QUEUE] Stored info from 98
[RECEIVE] Queued message from 98
[QUEUE] Processing info from 98
[QUEUE] Stored info from 98
[RECEIVE] Queued message from 98
[QUEUE] Processing info from 98
[QUEUE] Stored info from 98
[RECEIVE] Queued message from 98
[QUEUE] Processing info from 98
[QUEUE] Stored info from 98
[RECEIVE] Queued message from 98
[QUEUE] Processing info from 98
[QUEUE] Stored info from 98
[RECEIVE] Queued message from 98
[QUEUE] Processing info from 98
[QUEUE] Stored info from 98
[RECEIVE] Queued message from 98
[QUEUE] Processing info from 98
[QUEUE] Stored info from 98
[RECEIVE] Queued message from 98
[QUEUE] Processing info from 98
[QUEUE] Stored info from 98
[RECEIVE] Queued message from 98
[QUEUE] Processing info from 98
[QUEUE] Stored info from 98
[RECEIVE] Queued message from 98
[QUEUE] Processing info from 98
[QUEUE] Stored info from 98
[RECEIVE] Queued message from 98
[QUEUE] Processing info from 98
[QUEUE] Stored info from 98
[RECEIVE] Queued message from 98
[QUEUE] Processing info from 98
[QUEUE] Stored info from 98
[RECEIVE] Queued message from 98
[QUEUE] Processing info from 98
[QUEUE] Stored info from 98
[RECEIVE] Queued message from 98
[QUEUE] Processing info from 98
[QUEUE] Stored info from 98
[RECEIVE] Queued message from 98
[QUEUE] Processing info from 98
[QUEUE] Stored info from 98
[RECEIVE] Queued message from 98
[QUEUE] Processing info from 98
[QUEUE] Stored info from 98
[RECEIVE] Queued message from 98
[QUEUE] Processing info from 98
[QUEUE] Stored info from 98
[RECEIVE] Queued message from 98
[QUEUE] Processing info from 98
[QUEUE] Stored info from 98
[RECEIVE] Queued message from 98
[QUEUE] Processing info from 98
[QUEUE] Stored info from 98
[RECEIVE] Queued message from 98
[QUEUE] Processing info from 98
[QUEUE] Stored info from 98
[RECEIVE] Queued message from 98
[QUEUE] Processing info from 98
[QUEUE] Stored info from 98
[RECEIVE] Queued message from 98
[QUEUE] Processing info from 98
[QUEUE] Stored info from 98
[RECEIVE] Queued message from 98
[QUEUE] Processing info from 98
[QUEUE] Stored info from 98
[160] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2587.32it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:21,  2.70s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:17,  1.42s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:42,  1.19s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:41,  1.20s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:25,  1.10s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:15,  1.03s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:06,  1.02it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:16<02:00,  1.06it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:19<02:24,  1.16s/it]Running loglikelihood requests:  13%|█▎        | 19/142 [00:20<02:08,  1.04s/it]Running loglikelihood requests:  15%|█▍        | 21/142 [00:22<01:56,  1.04it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:24<01:46,  1.12it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:25<01:39,  1.18it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:27<01:33,  1.22it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:28<01:32,  1.22it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:30<01:27,  1.26it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:31<01:24,  1.29it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:33<01:21,  1.32it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:34<01:19,  1.32it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:35<01:16,  1.34it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:37<01:14,  1.35it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:39<01:16,  1.30it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:40<01:12,  1.34it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:41<01:09,  1.37it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:43<01:06,  1.40it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:44<01:03,  1.44it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:45<01:00,  1.47it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:47<00:58,  1.48it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:48<01:00,  1.41it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:50<00:57,  1.45it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:51<00:54,  1.48it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:52<00:52,  1.50it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:53<00:50,  1.53it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:55<00:48,  1.54it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:56<00:46,  1.56it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:57<00:45,  1.56it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:59<00:45,  1.52it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [01:00<00:43,  1.54it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:01<00:41,  1.56it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:02<00:40,  1.57it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:04<00:38,  1.58it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:05<00:36,  1.59it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:06<00:35,  1.60it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:07<00:34,  1.62it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:09<00:35,  1.48it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:10<00:33,  1.51it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:11<00:31,  1.53it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:13<00:30,  1.55it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:14<00:31,  1.44it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:15<00:28,  1.50it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:17<00:26,  1.53it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:18<00:24,  1.57it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:19<00:23,  1.54it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:20<00:22,  1.58it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:22<00:20,  1.62it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:23<00:18,  1.65it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:24<00:17,  1.67it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:25<00:16,  1.68it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:26<00:14,  1.69it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:27<00:13,  1.71it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:29<00:12,  1.70it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:30<00:11,  1.65it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:31<00:10,  1.68it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:32<00:08,  1.70it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:35<00:10,  1.20it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:36<00:08,  1.33it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:37<00:06,  1.44it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:38<00:04,  1.53it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:40<00:03,  1.51it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:41<00:01,  1.60it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:42<00:00,  1.68it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:42<00:00,  1.39it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-3): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (4): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-7): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (8): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9-10): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (11): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (12-13): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (15): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (16): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (17-31): 15 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-3): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (4): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-7): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (8): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9-10): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (11): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (12-13): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (15): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (16): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (17-31): 15 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/160.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5247
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:33:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5247 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 247
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5180
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:33:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5180 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 180
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:33:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5151
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:33:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5151 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 151
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5040
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:33:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5040 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 40
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5174
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:33:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5174 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 174
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5112
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:33:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5112 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 112
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5211
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:33:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5211 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 211
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5075
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:33:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5075 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 75
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5099
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:33:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5099 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 99
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5219
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:33:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5219 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 219
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5157
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:33:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5157 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 157
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:33:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5034
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:33:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5034 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 34
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5172
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:33:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5172 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 172
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:33:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:33:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5173
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:33:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5173 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 173
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:33:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:33:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5009
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:33:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5009 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 9
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5012
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:33:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5012 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 12
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5052
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:33:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5052 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 52
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:33:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5098
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:33:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5098 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 98
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5063
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:33:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5063 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 63
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:33:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:33:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:33:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5140
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:33:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5140 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 140
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5164
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:33:23] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5164 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 164
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140218653329168 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140218653329168 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140218653329168 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140218653329168 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140218653487088 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140218653487088 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140218653487088 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140218653487088 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[160] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.43661971830985913, 'acc_stderr,none': 0.05927935558412972}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.6384788962207051
0.4946572039289874
0.7062468225311351
0.5924118081316296
0.8055799477986278
0.4290834385090486
0.5207152243980063
0.40307410421369466
0.575849756312845
0.37833122092903004
0.559402975459772
0.9202435099718248
0.7328649512638977
0.4656521136449837
0.6226167455222542
0.6500475926241498
0.14933051029764177
0.852848973497393
0.7020336348742873
0.8036038458930006
0.25840240277743587
0.45348406473870356
0.7291236246725161
0.5999541971262276
0.7071125031923391
0.6523270915574834
0.5982105985982268
0.6520903105513685
0.39933491227192136
0.6384788962207051
0.4946572039289874
0.7062468225311351
0.5924118081316296
0.8055799477986278
0.4290834385090486
0.5207152243980063
0.40307410421369466
0.575849756312845
0.37833122092903004
0.559402975459772
0.9202435099718248
0.7328649512638977
0.4656521136449837
0.6226167455222542
0.6500475926241498
0.14933051029764177
0.852848973497393
0.7020336348742873
0.8036038458930006
0.25840240277743587
0.45348406473870356
0.7291236246725161
0.5999541971262276
0.7071125031923391
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[6, 3, 2, 1, 5, 0, 7, 4]
tensor([6, 3, 2, 1, 5, 0, 7, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 5, 4, 2, 6, 0, 7, 1]
tensor([3, 5, 4, 2, 6, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 7, 6, 3, 4, 1, 5, 0]
tensor([2, 7, 6, 3, 4, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 2, 5, 4, 6, 0, 7, 1]
tensor([3, 2, 5, 4, 6, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 5, 7, 0, 3, 2, 6, 1]
tensor([4, 5, 7, 0, 3, 2, 6, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 6, 3, 4, 2, 1, 7, 0]
tensor([5, 6, 3, 4, 2, 1, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/160.pt
[RECEIVE] Queued message from 160
[QUEUE] Processing info from 160
[QUEUE] Stored info from 160
[RECEIVE] Queued message from 160
[QUEUE] Processing info from 160
[QUEUE] Stored info from 160
[RECEIVE] Queued message from 160
[QUEUE] Processing info from 160
[QUEUE] Stored info from 160
[RECEIVE] Queued message from 160
[QUEUE] Processing info from 160
[QUEUE] Stored info from 160
[RECEIVE] Queued message from 160
[QUEUE] Processing info from 160
[QUEUE] Stored info from 160
[RECEIVE] Queued message from 160
[QUEUE] Processing info from 160
[QUEUE] Stored info from 160
[RECEIVE] Queued message from 160
[QUEUE] Processing info from 160
[QUEUE] Stored info from 160
[RECEIVE] Queued message from 160
[QUEUE] Processing info from 160
[QUEUE] Stored info from 160
[RECEIVE] Queued message from 160
[QUEUE] Processing info from 160
[QUEUE] Stored info from 160
[RECEIVE] Queued message from 160
[QUEUE] Processing info from 160
[QUEUE] Stored info from 160
[RECEIVE] Queued message from 160
[QUEUE] Processing info from 160
[QUEUE] Stored info from 160
[RECEIVE] Queued message from 160
[QUEUE] Processing info from 160
[QUEUE] Stored info from 160
[RECEIVE] Queued message from 160
[QUEUE] Processing info from 160
[QUEUE] Stored info from 160
[RECEIVE] Queued message from 160
[QUEUE] Processing info from 160
[QUEUE] Stored info from 160
[RECEIVE] Queued message from 160
[QUEUE] Processing info from 160
[QUEUE] Stored info from 160
[RECEIVE] Queued message from 160
[QUEUE] Processing info from 160
[QUEUE] Stored info from 160
[RECEIVE] Queued message from 160
[QUEUE] Processing info from 160
[QUEUE] Stored info from 160
[RECEIVE] Queued message from 160
[QUEUE] Processing info from 160
[QUEUE] Stored info from 160
[RECEIVE] Queued message from 160
[QUEUE] Processing info from 160
[QUEUE] Stored info from 160
[RECEIVE] Queued message from 160
[QUEUE] Processing info from 160
[QUEUE] Stored info from 160
[RECEIVE] Queued message from 160
[QUEUE] Processing info from 160
[QUEUE] Stored info from 160
[RECEIVE] Queued message from 160
[QUEUE] Processing info from 160
[QUEUE] Stored info from 160
[RECEIVE] Queued message from 160
[QUEUE] Processing info from 160
[QUEUE] Stored info from 160
[RECEIVE] Queued message from 160
[QUEUE] Processing info from 160
[QUEUE] Stored info from 160
[RECEIVE] Queued message from 160
[QUEUE] Processing info from 160
[QUEUE] Stored info from 160
[RECEIVE] Queued message from 160
[QUEUE] Processing info from 160
[QUEUE] Stored info from 160
[RECEIVE] Queued message from 160
[QUEUE] Processing info from 160
[QUEUE] Stored info from 160
[RECEIVE] Queued message from 160
[QUEUE] Processing info from 160
[QUEUE] Stored info from 160
[RECEIVE] Queued message from 160
[QUEUE] Processing info from 160
[QUEUE] Stored info from 160
[RECEIVE] Queued message from 160
[QUEUE] Processing info from 160
[QUEUE] Stored info from 160
[RECEIVE] Queued message from 160
[QUEUE] Processing info from 160
[QUEUE] Stored info from 160
[12] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2585.86it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:03<07:17,  3.10s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:24,  1.47s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:07<02:55,  1.28s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:31,  1.12s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:16,  1.03s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:07,  1.03it/s]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<01:58,  1.08it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:15<01:51,  1.13it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:17<01:49,  1.15it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:18<01:41,  1.21it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:20<01:36,  1.25it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:21<01:31,  1.30it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:23<01:27,  1.34it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:24<01:23,  1.37it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:25<01:20,  1.40it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:27<01:22,  1.34it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:28<01:19,  1.38it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:30<01:16,  1.41it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:31<01:13,  1.43it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:32<01:11,  1.45it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:34<01:09,  1.46it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:35<01:07,  1.47it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:36<01:04,  1.50it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:38<01:05,  1.45it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:39<01:02,  1.49it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:40<00:59,  1.53it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:41<00:56,  1.56it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:43<00:54,  1.59it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:44<00:52,  1.62it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:45<00:53,  1.55it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:47<00:52,  1.55it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:48<00:55,  1.43it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:49<00:51,  1.49it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:51<00:48,  1.54it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:52<00:46,  1.58it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:53<00:45,  1.57it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:54<00:42,  1.61it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [00:55<00:40,  1.64it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [00:57<00:40,  1.62it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [00:58<00:40,  1.54it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [00:59<00:38,  1.59it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:00<00:36,  1.63it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:02<00:34,  1.66it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:03<00:32,  1.69it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:04<00:31,  1.71it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:05<00:29,  1.72it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:06<00:28,  1.74it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:07<00:27,  1.72it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:09<00:32,  1.38it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:11<00:28,  1.48it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:12<00:26,  1.56it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:13<00:23,  1.63it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:14<00:22,  1.66it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:15<00:20,  1.71it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:16<00:19,  1.74it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:17<00:17,  1.75it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:19<00:16,  1.71it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:20<00:15,  1.74it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:21<00:14,  1.76it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:22<00:12,  1.79it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:23<00:11,  1.81it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:24<00:10,  1.84it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:25<00:09,  1.86it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:26<00:07,  1.88it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:27<00:06,  1.90it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:29<00:06,  1.68it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:30<00:05,  1.76it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:31<00:03,  1.83it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:32<00:02,  1.88it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:33<00:01,  1.92it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:33<00:00,  1.98it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:33<00:00,  1.51it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-31): 26 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-31): 26 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/12.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5247
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:35:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5247 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 247
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5172
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:35:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5172 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 172
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5157
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:35:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5157 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 157
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:35:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5160
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:35:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5160 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 160
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:35:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5140
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:35:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5140 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 140
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:35:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5219
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:35:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5219 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 219
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:35:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5063
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:35:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5063 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 63
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5040
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:35:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5040 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 40
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:35:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:35:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:35:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5099
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:35:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5099 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 99
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5180
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:35:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5180 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 180
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:35:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5052
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:35:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5052 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 52
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5034
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:35:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5034 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 34
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5151
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:35:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5151 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 151
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5164
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:35:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5164 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 164
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5009
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:35:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5009 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 9
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5173
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:35:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5173 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 173
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5174
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:35:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5174 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 174
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5075
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:35:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5075 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 75
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5098
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:35:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5098 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 98
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:35:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5211
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:35:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5211 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 211
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:35:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5112
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:35:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5112 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 112
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140218785360080 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140218785360080 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140218785360080 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140218785360080 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140218783048448 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140218783048448 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140218783048448 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140218783048448 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[12] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4225352112676056, 'acc_stderr,none': 0.059039842056825796}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.9416968404415913
0.7938815868474761
0.8191819727516524
0.8917669687772857
0.90570342985793
0.3043907333176312
0.4952220736758006
0.29899990072660143
0.7758711420345523
0.838301482150715
0.8086122742620726
0.9126741954079025
0.6304407611776705
0.6595297618724628
0.176689009460142
0.4424440684940646
0.43152501031897406
0.48316840881543294
0.43857258209632005
0.7021905687600761
0.2402003641072479
0.27348823957209967
0.6649171314730306
0.25117416182112623
0.9114030338716436
0.9328254651349717
0.9096786197852272
0.9107213191843687
0.8764776988845487
0.9416968404415913
0.7938815868474761
0.8191819727516524
0.8917669687772857
0.90570342985793
0.3043907333176312
0.4952220736758006
0.29899990072660143
0.7758711420345523
0.838301482150715
0.8086122742620726
0.9126741954079025
0.6304407611776705
0.6595297618724628
0.176689009460142
0.4424440684940646
0.43152501031897406
Total groups 76 exceeded the threshold, stopping comparison.
The group tensor is
[4, 3, 7, 2, 5, 1, 6, 0]
tensor([4, 3, 7, 2, 5, 1, 6, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 5, 7, 4, 3, 0, 6, 1]
tensor([2, 5, 7, 4, 3, 0, 6, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 5, 4, 0, 1, 1, 2]
tensor([0, 3, 5, 4, 0, 1, 1, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[4, 3, 0, 2, 5, 0, 1, 1]
tensor([4, 3, 0, 2, 5, 0, 1, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 0, 5, 1, 4, 2, 1, 3]
tensor([0, 0, 5, 1, 4, 2, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[3, 4, 0, 1, 2, 0, 5, 1]
tensor([3, 4, 0, 1, 2, 0, 5, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[5, 0, 4, 3, 2, 0, 1, 1]
tensor([5, 0, 4, 3, 2, 0, 1, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 3, 4, 0, 1, 2, 1, 5]
tensor([0, 3, 4, 0, 1, 2, 1, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/12.pt
[RECEIVE] Queued message from 12
[QUEUE] Processing info from 12
[QUEUE] Stored info from 12
[RECEIVE] Queued message from 12
[QUEUE] Processing info from 12
[QUEUE] Stored info from 12
[RECEIVE] Queued message from 12
[QUEUE] Processing info from 12
[QUEUE] Stored info from 12
[RECEIVE] Queued message from 12
[QUEUE] Processing info from 12
[QUEUE] Stored info from 12
[RECEIVE] Queued message from 12
[QUEUE] Processing info from 12
[QUEUE] Stored info from 12
[RECEIVE] Queued message from 12
[QUEUE] Processing info from 12
[QUEUE] Stored info from 12
[RECEIVE] Queued message from 12
[QUEUE] Processing info from 12
[QUEUE] Stored info from 12
[RECEIVE] Queued message from 12
[QUEUE] Processing info from 12
[QUEUE] Stored info from 12
[RECEIVE] Queued message from 12
[QUEUE] Processing info from 12
[QUEUE] Stored info from 12
[RECEIVE] Queued message from 12
[QUEUE] Processing info from 12
[QUEUE] Stored info from 12
[RECEIVE] Queued message from 12
[QUEUE] Processing info from 12
[QUEUE] Stored info from 12
[RECEIVE] Queued message from 12
[QUEUE] Processing info from 12
[QUEUE] Stored info from 12
[RECEIVE] Queued message from 12
[QUEUE] Processing info from 12
[QUEUE] Stored info from 12
[RECEIVE] Queued message from 12
[QUEUE] Processing info from 12
[QUEUE] Stored info from 12
[RECEIVE] Queued message from 12
[QUEUE] Processing info from 12
[QUEUE] Stored info from 12
[RECEIVE] Queued message from 12
[QUEUE] Processing info from 12
[QUEUE] Stored info from 12
[RECEIVE] Queued message from 12
[QUEUE] Processing info from 12
[QUEUE] Stored info from 12
[RECEIVE] Queued message from 12
[QUEUE] Processing info from 12
[QUEUE] Stored info from 12
[RECEIVE] Queued message from 12
[QUEUE] Processing info from 12
[QUEUE] Stored info from 12
[RECEIVE] Queued message from 12
[QUEUE] Processing info from 12
[QUEUE] Stored info from 12
[RECEIVE] Queued message from 12
[QUEUE] Processing info from 12
[QUEUE] Stored info from 12
[RECEIVE] Queued message from 12
[QUEUE] Processing info from 12
[QUEUE] Stored info from 12
[RECEIVE] Queued message from 12
[QUEUE] Processing info from 12
[QUEUE] Stored info from 12
[RECEIVE] Queued message from 12
[QUEUE] Processing info from 12
[QUEUE] Stored info from 12
[RECEIVE] Queued message from 12
[QUEUE] Processing info from 12
[QUEUE] Stored info from 12
[RECEIVE] Queued message from 12
[QUEUE] Processing info from 12
[QUEUE] Stored info from 12
[RECEIVE] Queued message from 12
[QUEUE] Processing info from 12
[QUEUE] Stored info from 12
[RECEIVE] Queued message from 12
[QUEUE] Processing info from 12
[QUEUE] Stored info from 12
[RECEIVE] Queued message from 12
[QUEUE] Processing info from 12
[QUEUE] Stored info from 12
[RECEIVE] Queued message from 12
[QUEUE] Processing info from 12
[QUEUE] Stored info from 12
[RECEIVE] Queued message from 12
[QUEUE] Processing info from 12
[QUEUE] Stored info from 12
[173] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2545.85it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:45,  2.87s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:21,  1.45s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:07<03:11,  1.40s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:09<02:42,  1.20s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:11<02:25,  1.09s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:14,  1.03s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:05,  1.02it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:17<02:14,  1.06s/it]Running loglikelihood requests:  12%|█▏        | 17/142 [00:18<02:03,  1.02it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:20<01:53,  1.09it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:21<01:45,  1.14it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:23<01:39,  1.20it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:24<01:34,  1.24it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:26<01:33,  1.24it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:27<01:28,  1.27it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:29<01:24,  1.31it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:30<01:22,  1.33it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:32<01:20,  1.33it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:33<01:17,  1.35it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:35<01:15,  1.36it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:38<01:47,  1.06s/it]Running loglikelihood requests:  30%|███       | 43/142 [00:40<01:35,  1.04it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:41<01:25,  1.14it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:43<01:21,  1.17it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:44<01:14,  1.25it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:46<01:08,  1.32it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:47<01:07,  1.32it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:49<01:12,  1.20it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:50<01:05,  1.29it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:52<01:03,  1.30it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:53<00:59,  1.36it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:54<00:55,  1.41it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:56<00:52,  1.46it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:57<00:54,  1.38it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:59<00:51,  1.43it/s]Running loglikelihood requests:  50%|█████     | 71/142 [01:00<00:48,  1.47it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [01:01<00:45,  1.50it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [01:02<00:43,  1.52it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:04<00:42,  1.55it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:05<00:40,  1.57it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:06<00:38,  1.58it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:08<00:38,  1.51it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:09<00:36,  1.54it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:10<00:34,  1.57it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:11<00:33,  1.60it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:12<00:31,  1.61it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:14<00:30,  1.62it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:15<00:28,  1.63it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:16<00:27,  1.64it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:17<00:27,  1.59it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:19<00:25,  1.60it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:20<00:23,  1.63it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:21<00:22,  1.64it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:22<00:21,  1.66it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:23<00:19,  1.67it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:25<00:19,  1.60it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:26<00:17,  1.63it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:27<00:16,  1.59it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:28<00:15,  1.63it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:30<00:13,  1.66it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:31<00:13,  1.60it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:32<00:11,  1.63it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:33<00:10,  1.66it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:34<00:08,  1.69it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:35<00:07,  1.73it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:37<00:06,  1.76it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:38<00:05,  1.65it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:39<00:04,  1.71it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:40<00:02,  1.76it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:41<00:01,  1.80it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:42<00:00,  1.84it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:42<00:00,  1.38it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-8): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10-22): 13 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (23): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24-31): 8 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-8): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10-22): 13 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (23): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24-31): 8 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/173.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5112
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:37:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5112 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 112
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:37:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5140
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:37:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5140 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 140
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5075
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:37:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5075 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 75
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5063
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:37:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5063 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 63
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5009
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:37:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5009 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 9
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5180
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:37:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5180 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 180
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5012
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:37:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5012 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 12
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5034
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:37:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5034 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 34
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:37:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:37:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5040
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:37:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5040 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 40
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5157
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:37:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5157 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 157
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:37:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5160
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:37:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5160 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 160
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5151
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:37:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5151 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 151
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:37:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5172
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:37:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5172 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 172
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5211
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:37:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5211 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 211
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:37:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:37:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5247
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:37:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5247 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 247
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5098
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:37:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5098 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 98
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5219
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:37:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5219 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 219
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5099
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:37:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5099 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 99
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5052
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:37:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5052 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 52
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:37:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:37:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:37:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5174
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:37:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5174 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 174
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5164
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:37:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5164 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 164
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140218646751104 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140218646751104 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140218646751104 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140218646751104 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140218606994256 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140218606994256 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140218606994256 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140218606994256 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[173] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4647887323943662, 'acc_stderr,none': 0.05961305784972239}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8670569790937798
0.5488271932172035
0.673013746499191
0.7739554714966184
0.626122351153327
0.7480239804573661
0.8404062667282521
0.585845593784257
0.5486089643527782
0.295628094796439
0.8187255304150794
0.4183228390778105
0.5130578032019412
0.8769017151034573
0.9364820135353734
0.9916222006713932
0.9862354083632185
0.9582978800582982
0.8980649992917061
0.8669816466709701
0.9008509099634621
0.9321426254796342
0.8646919425811247
0.6505326186022521
0.6612551300691957
0.8835733690017037
0.7234157945938043
0.7342253877992871
0.5683390151095499
0.8670569790937798
0.5488271932172035
0.673013746499191
0.7739554714966184
0.626122351153327
0.7480239804573661
0.8404062667282521
0.585845593784257
0.5486089643527782
0.295628094796439
0.8187255304150794
0.4183228390778105
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[5, 3, 6, 2, 4, 0, 7, 1]
tensor([5, 3, 6, 2, 4, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 4, 6, 7, 2, 0, 5, 1]
tensor([3, 4, 6, 7, 2, 0, 5, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 6, 2, 1, 3, 0, 7, 5]
tensor([4, 6, 2, 1, 3, 0, 7, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 4, 6, 0, 1, 2, 7, 3]
tensor([5, 4, 6, 0, 1, 2, 7, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 2, 6, 5, 4, 0, 7, 1]
tensor([3, 2, 6, 5, 4, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 2, 5, 6, 3, 0, 7, 1]
tensor([4, 2, 5, 6, 3, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/173.pt
[RECEIVE] Queued message from 173
[QUEUE] Processing info from 173
[QUEUE] Stored info from 173
[RECEIVE] Queued message from 173
[QUEUE] Processing info from 173
[QUEUE] Stored info from 173
[RECEIVE] Queued message from 173
[QUEUE] Processing info from 173
[QUEUE] Stored info from 173
[RECEIVE] Queued message from 173
[QUEUE] Processing info from 173
[QUEUE] Stored info from 173
[RECEIVE] Queued message from 173
[QUEUE] Processing info from 173
[QUEUE] Stored info from 173
[RECEIVE] Queued message from 173
[QUEUE] Processing info from 173
[QUEUE] Stored info from 173
[RECEIVE] Queued message from 173
[QUEUE] Processing info from 173
[QUEUE] Stored info from 173
[RECEIVE] Queued message from 173
[QUEUE] Processing info from 173
[QUEUE] Stored info from 173
[RECEIVE] Queued message from 173
[QUEUE] Processing info from 173
[QUEUE] Stored info from 173
[RECEIVE] Queued message from 173
[QUEUE] Processing info from 173
[QUEUE] Stored info from 173
[RECEIVE] Queued message from 173
[QUEUE] Processing info from 173
[QUEUE] Stored info from 173
[RECEIVE] Queued message from 173
[QUEUE] Processing info from 173
[QUEUE] Stored info from 173
[RECEIVE] Queued message from 173
[QUEUE] Processing info from 173
[QUEUE] Stored info from 173
[RECEIVE] Queued message from 173
[QUEUE] Processing info from 173
[QUEUE] Stored info from 173
[RECEIVE] Queued message from 173
[QUEUE] Processing info from 173
[QUEUE] Stored info from 173
[RECEIVE] Queued message from 173
[QUEUE] Processing info from 173
[QUEUE] Stored info from 173
[RECEIVE] Queued message from 173
[QUEUE] Processing info from 173
[QUEUE] Stored info from 173
[RECEIVE] Queued message from 173
[QUEUE] Processing info from 173
[QUEUE] Stored info from 173
[RECEIVE] Queued message from 173
[QUEUE] Processing info from 173
[QUEUE] Stored info from 173
[RECEIVE] Queued message from 173
[QUEUE] Processing info from 173
[QUEUE] Stored info from 173
[RECEIVE] Queued message from 173
[QUEUE] Processing info from 173
[QUEUE] Stored info from 173
[RECEIVE] Queued message from 173
[QUEUE] Processing info from 173
[QUEUE] Stored info from 173
[RECEIVE] Queued message from 173
[QUEUE] Processing info from 173
[QUEUE] Stored info from 173
[RECEIVE] Queued message from 173
[QUEUE] Processing info from 173
[QUEUE] Stored info from 173
[RECEIVE] Queued message from 173
[QUEUE] Processing info from 173
[QUEUE] Stored info from 173
[RECEIVE] Queued message from 173
[QUEUE] Processing info from 173
[QUEUE] Stored info from 173
[RECEIVE] Queued message from 173
[QUEUE] Processing info from 173
[QUEUE] Stored info from 173
[RECEIVE] Queued message from 173
[QUEUE] Processing info from 173
[QUEUE] Stored info from 173
[RECEIVE] Queued message from 173
[QUEUE] Processing info from 173
[QUEUE] Stored info from 173
[RECEIVE] Queued message from 173
[QUEUE] Processing info from 173
[QUEUE] Stored info from 173
[RECEIVE] Queued message from 173
[QUEUE] Processing info from 173
[QUEUE] Stored info from 173
[247] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2534.54it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:03<07:26,  3.17s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:05<03:35,  1.55s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:07<03:06,  1.36s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:09<02:40,  1.19s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:11<02:25,  1.09s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:13<02:14,  1.03s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:15<02:11,  1.02s/it]Running loglikelihood requests:  11%|█         | 15/142 [00:16<02:02,  1.04it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:18<01:58,  1.05it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:20<01:51,  1.10it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:21<01:45,  1.15it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:23<01:38,  1.20it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:24<01:34,  1.24it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:26<01:29,  1.28it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:27<01:30,  1.25it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:29<01:26,  1.29it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:30<01:23,  1.31it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:32<01:20,  1.32it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:33<01:18,  1.33it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:35<01:16,  1.35it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:36<01:14,  1.35it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:38<01:15,  1.31it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:39<01:12,  1.34it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:41<01:09,  1.37it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:42<01:06,  1.41it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:43<01:03,  1.44it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:45<01:00,  1.47it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:46<00:58,  1.49it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:47<00:59,  1.44it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:49<00:56,  1.47it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:50<00:58,  1.39it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:52<00:55,  1.43it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:53<00:52,  1.46it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:54<00:50,  1.49it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:55<00:48,  1.51it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:57<00:46,  1.53it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:58<00:47,  1.45it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [01:00<00:45,  1.48it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:01<00:42,  1.51it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:02<00:40,  1.54it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:03<00:39,  1.55it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:05<00:37,  1.56it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:06<00:36,  1.57it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:07<00:34,  1.58it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:08<00:34,  1.54it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:10<00:32,  1.56it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:11<00:30,  1.59it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:12<00:29,  1.60it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:13<00:27,  1.61it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:15<00:26,  1.63it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:16<00:25,  1.63it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:17<00:23,  1.64it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:18<00:23,  1.59it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:19<00:21,  1.62it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:21<00:20,  1.64it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:22<00:18,  1.65it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:23<00:17,  1.67it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:24<00:16,  1.68it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:25<00:14,  1.68it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:27<00:13,  1.69it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:28<00:12,  1.69it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:29<00:11,  1.62it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:30<00:10,  1.65it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:31<00:08,  1.67it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:33<00:07,  1.68it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:34<00:06,  1.68it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:35<00:05,  1.69it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:36<00:04,  1.71it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:37<00:02,  1.75it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:39<00:02,  1.44it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:40<00:00,  1.56it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:40<00:00,  1.41it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-2): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (3-4): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-7): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (8-25): 18 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (26): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (27-31): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-2): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (3-4): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-7): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (8-25): 18 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (26): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (27-31): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/247.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:39:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5099
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:39:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5099 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 99
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:39:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5052
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:39:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5052 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 52
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5009
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:39:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5009 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 9
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:39:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5151
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:39:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5151 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 151
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:39:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5160
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:39:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5160 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 160
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5112
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:39:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5112 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 112
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5180
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:39:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5180 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 180
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5040
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:39:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5040 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 40
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5173
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:39:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5173 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 173
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5172
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:39:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5172 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 172
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5140
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:39:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5140 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 140
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5012
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:39:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5012 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 12
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5164
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:39:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5164 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 164
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:39:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5075
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:39:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5075 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 75
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5219
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:39:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5219 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 219
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5174
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:39:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5174 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 174
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5063
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:39:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5063 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 63
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5034
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:39:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5034 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 34
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:39:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5098
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:39:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5098 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 98
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5157
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:39:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5157 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 157
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:39:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:39:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5211
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:39:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5211 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 211
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:39:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:39:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140218654392096 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140218654392096 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140218654392096 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140218654392096 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140218653436352 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140218653436352 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140218653436352 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140218653436352 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[247] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4507042253521127, 'acc_stderr,none': 0.05947027187738001}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.4211049002945932
0.6717558353282359
0.7474911564899941
0.6826176878179091
0.7797142635267413
0.8231499933202435
0.9112841579744179
0.9329117857417774
0.3884156651377716
0.7116719161574963
0.3163186199985964
0.7579641143181478
0.7487852880300513
0.644901206148365
0.6252899485594469
0.8300709483875389
0.9686405093585702
0.4827230969630938
0.4401250454367978
0.846541236433719
0.9874080634814415
0.6954384705363965
0.33457229698994645
0.3090774332022817
0.9161115178604439
0.6466213503285708
0.719815146262638
0.8765685188625579
0.30061586460742784
0.4211049002945932
0.6717558353282359
0.7474911564899941
0.6826176878179091
0.7797142635267413
0.8231499933202435
0.9112841579744179
0.9329117857417774
0.3884156651377716
0.7116719161574963
0.3163186199985964
0.7579641143181478
0.7487852880300513
0.644901206148365
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[2, 5, 6, 1, 4, 0, 7, 3]
tensor([2, 5, 6, 1, 4, 0, 7, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 4, 6, 1, 5, 0, 7, 3]
tensor([2, 4, 6, 1, 5, 0, 7, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 2, 7, 0, 1, 3, 6, 5]
tensor([4, 2, 7, 0, 1, 3, 6, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[6, 3, 7, 1, 2, 0, 5, 4]
tensor([6, 3, 7, 1, 2, 0, 5, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 5, 0, 0, 2, 3, 1, 1]
tensor([4, 5, 0, 0, 2, 3, 1, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 4, 1, 2, 1, 0, 3, 5]
tensor([0, 4, 1, 2, 1, 0, 3, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 5, 0, 2, 1, 1, 4]
tensor([0, 3, 5, 0, 2, 1, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/247.pt
[RECEIVE] Queued message from 247
[QUEUE] Processing info from 247
[QUEUE] Stored info from 247
[RECEIVE] Queued message from 247
[QUEUE] Processing info from 247
[QUEUE] Stored info from 247
[RECEIVE] Queued message from 247
[QUEUE] Processing info from 247
[QUEUE] Stored info from 247
[RECEIVE] Queued message from 247
[QUEUE] Processing info from 247
[QUEUE] Stored info from 247
[RECEIVE] Queued message from 247
[QUEUE] Processing info from 247
[QUEUE] Stored info from 247
[RECEIVE] Queued message from 247
[QUEUE] Processing info from 247
[QUEUE] Stored info from 247
[RECEIVE] Queued message from 247
[QUEUE] Processing info from 247
[QUEUE] Stored info from 247
[RECEIVE] Queued message from 247
[QUEUE] Processing info from 247
[QUEUE] Stored info from 247
[RECEIVE] Queued message from 247
[QUEUE] Processing info from 247
[QUEUE] Stored info from 247
[RECEIVE] Queued message from 247
[QUEUE] Processing info from 247
[QUEUE] Stored info from 247
[RECEIVE] Queued message from 247
[QUEUE] Processing info from 247
[QUEUE] Stored info from 247
[RECEIVE] Queued message from 247
[QUEUE] Processing info from 247
[QUEUE] Stored info from 247
[RECEIVE] Queued message from 247
[QUEUE] Processing info from 247
[QUEUE] Stored info from 247
[RECEIVE] Queued message from 247
[QUEUE] Processing info from 247
[QUEUE] Stored info from 247
[RECEIVE] Queued message from 247
[QUEUE] Processing info from 247
[QUEUE] Stored info from 247
[RECEIVE] Queued message from 247
[QUEUE] Processing info from 247
[QUEUE] Stored info from 247
[RECEIVE] Queued message from 247
[QUEUE] Processing info from 247
[QUEUE] Stored info from 247
[RECEIVE] Queued message from 247
[QUEUE] Processing info from 247
[QUEUE] Stored info from 247
[RECEIVE] Queued message from 247
[QUEUE] Processing info from 247
[QUEUE] Stored info from 247
[RECEIVE] Queued message from 247
[QUEUE] Processing info from 247
[QUEUE] Stored info from 247
[RECEIVE] Queued message from 247
[QUEUE] Processing info from 247
[QUEUE] Stored info from 247
[RECEIVE] Queued message from 247
[QUEUE] Processing info from 247
[QUEUE] Stored info from 247
[RECEIVE] Queued message from 247
[QUEUE] Processing info from 247
[QUEUE] Stored info from 247
[RECEIVE] Queued message from 247
[QUEUE] Processing info from 247
[QUEUE] Stored info from 247
[RECEIVE] Queued message from 247
[QUEUE] Processing info from 247
[QUEUE] Stored info from 247
[RECEIVE] Queued message from 247
[QUEUE] Processing info from 247
[QUEUE] Stored info from 247
[RECEIVE] Queued message from 247
[QUEUE] Processing info from 247
[QUEUE] Stored info from 247
[RECEIVE] Queued message from 247
[QUEUE] Processing info from 247
[QUEUE] Stored info from 247
[RECEIVE] Queued message from 247
[QUEUE] Processing info from 247
[QUEUE] Stored info from 247
[RECEIVE] Queued message from 247
[QUEUE] Processing info from 247
[QUEUE] Stored info from 247
[RECEIVE] Queued message from 247
[QUEUE] Processing info from 247
[QUEUE] Stored info from 247
[63] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2598.50it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<07:00,  2.98s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:23,  1.47s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:42,  1.19s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:24,  1.07s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:13,  1.01s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:06,  1.04it/s]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:17,  1.06s/it]Running loglikelihood requests:  11%|█         | 15/142 [00:16<02:05,  1.01it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:17<01:56,  1.07it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:19<01:48,  1.14it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:20<01:41,  1.19it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:22<01:36,  1.24it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:24<01:34,  1.24it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:25<01:29,  1.29it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:26<01:25,  1.31it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:28<01:22,  1.34it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:29<01:20,  1.36it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:31<01:17,  1.38it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:32<01:15,  1.39it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:35<01:32,  1.11it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:36<01:25,  1.19it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:37<01:18,  1.25it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:39<01:13,  1.32it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:40<01:09,  1.37it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:41<01:05,  1.42it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:43<01:09,  1.31it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:44<01:04,  1.38it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:46<01:00,  1.43it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:47<00:57,  1.48it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:48<00:54,  1.51it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:50<00:52,  1.54it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:51<00:50,  1.55it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:52<00:48,  1.57it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:53<00:49,  1.51it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:55<00:47,  1.54it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:56<00:45,  1.55it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:57<00:43,  1.57it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [00:58<00:42,  1.59it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:00<00:40,  1.60it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:01<00:38,  1.62it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:02<00:37,  1.64it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:03<00:37,  1.56it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:05<00:35,  1.59it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:06<00:33,  1.62it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:07<00:32,  1.64it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:08<00:30,  1.66it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:09<00:29,  1.67it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:11<00:28,  1.63it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:12<00:27,  1.66it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:13<00:25,  1.68it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:15<00:27,  1.50it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:16<00:24,  1.56it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:17<00:22,  1.61it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:18<00:21,  1.65it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:19<00:19,  1.68it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:20<00:18,  1.70it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:22<00:16,  1.72it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:23<00:15,  1.74it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:24<00:14,  1.67it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:25<00:13,  1.71it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:26<00:12,  1.73it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:27<00:10,  1.76it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:28<00:09,  1.78it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:29<00:08,  1.79it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:31<00:07,  1.81it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:32<00:06,  1.82it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:33<00:04,  1.83it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:34<00:03,  1.76it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:35<00:02,  1.80it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:36<00:01,  1.69it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:37<00:00,  1.74it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:37<00:00,  1.45it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-4): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-9): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (11-12): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (13): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14-19): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (20-21): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (22-23): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (25-31): 7 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-4): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-9): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (11-12): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (13): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14-19): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (20-21): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (22-23): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (25-31): 7 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/63.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:41:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5247
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:41:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5247 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 247
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5075
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:41:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5075 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 75
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:41:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5040
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:41:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5040 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 40
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5211
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:41:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5211 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 211
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5098
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:41:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5098 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 98
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:41:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5180
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:41:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5180 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 180
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5140
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:41:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5140 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 140
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5012
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:41:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5012 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 12
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:41:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:41:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5034
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:41:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5034 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 34
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:41:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5151
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:41:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5151 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 151
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5172
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:41:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5172 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 172
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5173
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:41:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5173 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 173
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:41:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5160
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:41:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5160 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 160
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5219
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:41:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5219 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 219
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5099
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:41:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5099 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 99
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5164
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:41:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5164 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 164
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5052
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:41:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5052 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 52
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5009
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:41:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5009 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 9
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:41:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5157
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:41:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5157 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 157
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5112
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:41:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5112 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 112
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:41:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5174
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:41:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5174 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 174
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:41:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140218654390560 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140218654390560 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140218654390560 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140218654390560 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140218743966032 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140218743966032 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140218743966032 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140218743966032 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[63] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.43661971830985913, 'acc_stderr,none': 0.05927935558412972}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8840011732877091
0.9530187867791682
0.922962504956303
0.7839472459406365
0.8981387177104178
0.9267264969548299
0.5821108615798573
0.2837945650872556
0.6077879555368297
0.40197237439213185
0.8904940347912964
0.7509530386402397
0.901875691813653
0.9122390055224058
0.7316046462179062
0.7968435583929763
0.548007144578676
0.5393492220671232
0.9101317167988644
0.5489553505889563
0.4310648048222707
0.3687557715800523
0.8114931082909914
0.5012706843250611
0.2095243909347347
0.3518983916697559
0.9676050865236582
0.8840253404453832
0.6389046419601837
0.8840011732877091
0.9530187867791682
0.922962504956303
0.7839472459406365
0.8981387177104178
0.9267264969548299
0.5821108615798573
0.2837945650872556
0.6077879555368297
0.40197237439213185
0.8904940347912964
0.7509530386402397
0.901875691813653
0.9122390055224058
0.7316046462179062
0.7968435583929763
0.548007144578676
0.5393492220671232
0.9101317167988644
0.5489553505889563
Total groups 72 exceeded the threshold, stopping comparison.
The group tensor is
[1, 2, 7, 4, 3, 0, 6, 5]
tensor([1, 2, 7, 4, 3, 0, 6, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 5, 4, 1, 0, 7, 2]
tensor([6, 3, 5, 4, 1, 0, 7, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[1, 3, 6, 4, 2, 0, 7, 5]
tensor([1, 3, 6, 4, 2, 0, 7, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[5, 3, 6, 4, 0, 1, 7, 2]
tensor([5, 3, 6, 4, 0, 1, 7, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 4, 6, 5, 3, 0, 7, 1]
tensor([2, 4, 6, 5, 3, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 5, 2, 4, 0, 1, 3]
tensor([0, 1, 5, 2, 4, 0, 1, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/63.pt
[RECEIVE] Queued message from 63
[QUEUE] Processing info from 63
[QUEUE] Stored info from 63
[RECEIVE] Queued message from 63
[QUEUE] Processing info from 63
[QUEUE] Stored info from 63
[RECEIVE] Queued message from 63
[QUEUE] Processing info from 63
[QUEUE] Stored info from 63
[RECEIVE] Queued message from 63
[QUEUE] Processing info from 63
[QUEUE] Stored info from 63
[RECEIVE] Queued message from 63
[QUEUE] Processing info from 63
[QUEUE] Stored info from 63
[RECEIVE] Queued message from 63
[QUEUE] Processing info from 63
[QUEUE] Stored info from 63
[RECEIVE] Queued message from 63
[QUEUE] Processing info from 63
[QUEUE] Stored info from 63
[RECEIVE] Queued message from 63
[QUEUE] Processing info from 63
[QUEUE] Stored info from 63
[RECEIVE] Queued message from 63
[QUEUE] Processing info from 63
[QUEUE] Stored info from 63
[RECEIVE] Queued message from 63
[QUEUE] Processing info from 63
[QUEUE] Stored info from 63
[RECEIVE] Queued message from 63
[QUEUE] Processing info from 63
[QUEUE] Stored info from 63
[RECEIVE] Queued message from 63
[QUEUE] Processing info from 63
[QUEUE] Stored info from 63
[RECEIVE] Queued message from 63
[QUEUE] Processing info from 63
[QUEUE] Stored info from 63
[RECEIVE] Queued message from 63
[QUEUE] Processing info from 63
[QUEUE] Stored info from 63
[RECEIVE] Queued message from 63
[QUEUE] Processing info from 63
[QUEUE] Stored info from 63
[RECEIVE] Queued message from 63
[QUEUE] Processing info from 63
[QUEUE] Stored info from 63
[RECEIVE] Queued message from 63
[QUEUE] Processing info from 63
[QUEUE] Stored info from 63
[RECEIVE] Queued message from 63
[QUEUE] Processing info from 63
[QUEUE] Stored info from 63
[RECEIVE] Queued message from 63
[QUEUE] Processing info from 63
[QUEUE] Stored info from 63
[RECEIVE] Queued message from 63
[QUEUE] Processing info from 63
[QUEUE] Stored info from 63
[RECEIVE] Queued message from 63
[QUEUE] Processing info from 63
[QUEUE] Stored info from 63
[RECEIVE] Queued message from 63
[QUEUE] Processing info from 63
[QUEUE] Stored info from 63
[RECEIVE] Queued message from 63
[QUEUE] Processing info from 63
[QUEUE] Stored info from 63
[RECEIVE] Queued message from 63
[QUEUE] Processing info from 63
[QUEUE] Stored info from 63
[RECEIVE] Queued message from 63
[QUEUE] Processing info from 63
[QUEUE] Stored info from 63
[RECEIVE] Queued message from 63
[QUEUE] Processing info from 63
[QUEUE] Stored info from 63
[RECEIVE] Queued message from 63
[QUEUE] Processing info from 63
[QUEUE] Stored info from 63
[RECEIVE] Queued message from 63
[QUEUE] Processing info from 63
[QUEUE] Stored info from 63
[RECEIVE] Queued message from 63
[QUEUE] Processing info from 63
[QUEUE] Stored info from 63
[RECEIVE] Queued message from 63
[QUEUE] Processing info from 63
[QUEUE] Stored info from 63
[RECEIVE] Queued message from 63
[QUEUE] Processing info from 63
[QUEUE] Stored info from 63
[161] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2617.29it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:28,  2.75s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:15,  1.41s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:39,  1.16s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:22,  1.05s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:12,  1.01it/s]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:10,  1.00it/s]Running loglikelihood requests:   9%|▉         | 13/142 [00:13<02:03,  1.05it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:15<01:56,  1.09it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:17<01:50,  1.13it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:18<01:43,  1.18it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:20<01:38,  1.22it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:22<01:44,  1.14it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:23<01:36,  1.21it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:25<01:30,  1.27it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:26<01:26,  1.31it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:27<01:22,  1.34it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:29<01:19,  1.37it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:31<01:27,  1.22it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:32<01:22,  1.27it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:34<01:17,  1.32it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:35<01:14,  1.35it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:36<01:11,  1.38it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:38<01:09,  1.39it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:39<01:06,  1.42it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:41<01:07,  1.38it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:42<01:03,  1.44it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:43<01:00,  1.48it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:44<00:57,  1.51it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:46<00:55,  1.52it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:47<00:53,  1.55it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:48<00:51,  1.57it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:49<00:49,  1.59it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:51<00:50,  1.53it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:52<00:48,  1.56it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:53<00:45,  1.59it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:54<00:44,  1.61it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:56<00:42,  1.63it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [00:57<00:40,  1.65it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [00:58<00:39,  1.66it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [00:59<00:37,  1.68it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:00<00:36,  1.68it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:02<00:41,  1.41it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:04<00:38,  1.47it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:05<00:35,  1.53it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:06<00:33,  1.58it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:07<00:31,  1.61it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:08<00:29,  1.64it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:09<00:28,  1.66it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:11<00:26,  1.67it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:12<00:26,  1.59it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:13<00:25,  1.64it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:14<00:23,  1.68it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:15<00:21,  1.70it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:16<00:20,  1.73it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:18<00:18,  1.74it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:19<00:17,  1.76it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:20<00:16,  1.77it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:21<00:15,  1.78it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:22<00:14,  1.69it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:23<00:13,  1.73it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:24<00:11,  1.76it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:26<00:10,  1.79it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:27<00:10,  1.64it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:28<00:08,  1.70it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:29<00:07,  1.71it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:30<00:06,  1.75it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:32<00:05,  1.69it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:33<00:03,  1.75it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:34<00:02,  1.80it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:35<00:01,  1.84it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:36<00:00,  1.89it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:36<00:00,  1.48it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-8): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10-30): 21 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (31): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-8): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10-30): 21 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (31): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/161.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5140
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:43:06] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5140 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 140
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5211
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:43:06] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5211 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 211
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5174
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:43:06] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5174 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 174
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:43:06] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:43:06] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5219
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:43:06] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5219 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 219
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:43:06] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5075
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:43:06] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5075 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 75
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5112
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:43:06] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5112 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 112
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5040
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:43:06] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5040 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 40
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5157
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:43:06] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5157 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 157
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5151
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:43:06] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5151 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 151
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5009
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:43:06] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5009 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 9
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5052
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:43:06] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5052 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 52
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5098
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:43:06] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5098 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 98
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:43:06] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:43:06] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5247
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:43:06] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5247 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 247
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:43:06] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5012
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:43:06] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5012 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 12
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:43:06] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5172
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:43:06] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5172 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 172
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5034
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:43:06] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5034 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 34
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5160
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:43:06] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5160 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 160
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5063
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:43:06] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5063 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 63
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5099
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:43:06] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5099 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 99
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5164
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:43:06] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5164 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 164
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:43:06] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5173
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:43:06] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5173 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 173
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5180
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:43:06] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5180 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 180
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:43:06] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140218668336144 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140218668336144 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140218668336144 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140218668336144 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140218646381344 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140218646381344 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140218646381344 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140218646381344 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[161] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4507042253521127, 'acc_stderr,none': 0.05947027187738001}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.891975958338049
0.3982001908036579
0.26652204443251004
0.14111026067874816
0.11763525057572936
0.8635004180455561
0.8741394655456793
0.5304527321557103
0.44617634270319845
0.7007455592903002
0.6799150362476898
0.3511365594568724
0.47145939463701925
0.4744673317050211
0.905435493752087
0.903612941640167
0.8893763849001028
0.6821933807976941
0.6796182015499347
0.7774502436639344
0.8164788896198145
0.9011095591650676
0.8564639597370403
0.9528866120532432
0.4784452972921274
0.48852492817861076
0.8397355586186119
0.7433051149723976
0.5457687574271932
0.891975958338049
0.3982001908036579
0.26652204443251004
0.14111026067874816
0.11763525057572936
0.8635004180455561
0.8741394655456793
0.5304527321557103
0.44617634270319845
0.7007455592903002
0.6799150362476898
0.3511365594568724
0.47145939463701925
0.4744673317050211
0.905435493752087
0.903612941640167
0.8893763849001028
0.6821933807976941
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[6, 5, 4, 3, 2, 1, 7, 0]
tensor([6, 5, 4, 3, 2, 1, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 7, 4, 1, 0, 6, 3]
tensor([5, 2, 7, 4, 1, 0, 6, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 6, 5, 2, 4, 0, 7, 1]
tensor([3, 6, 5, 2, 4, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 4, 6, 0, 2, 1, 7, 3]
tensor([5, 4, 6, 0, 2, 1, 7, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 0, 7, 3, 5, 1, 6, 2]
tensor([4, 0, 7, 3, 5, 1, 6, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 5, 1, 3, 2, 0, 1, 4]
tensor([0, 5, 1, 3, 2, 0, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[1, 0, 0, 1, 1.0, 1.0, 1.0, 1.0]
tensor([1, 0, 0, 1, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[1, 0, 1, 1.0, 1.0, 0, 1.0, 1.0]
tensor([1, 0, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[0, 1, 1.0, 1.0, 0, 1, 1.0, 1.0]
tensor([0, 1, 1, 1, 0, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/161.pt
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[RECEIVE] Queued message from 161
[QUEUE] Processing info from 161
[QUEUE] Stored info from 161
[34] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2619.69it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:39,  2.83s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:22,  1.46s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:45,  1.21s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:34,  1.14s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:23,  1.08s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:18,  1.06s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:09,  1.00s/it]Running loglikelihood requests:  11%|█         | 15/142 [00:16<02:01,  1.04it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:18<01:59,  1.04it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:19<01:51,  1.10it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:21<01:45,  1.15it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:22<01:39,  1.19it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:24<01:35,  1.23it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:25<01:31,  1.26it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:28<01:38,  1.15it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:29<01:32,  1.20it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:31<01:27,  1.24it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:32<01:24,  1.27it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:34<01:21,  1.29it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:35<01:18,  1.32it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:39<01:47,  1.07s/it]Running loglikelihood requests:  30%|███       | 43/142 [00:40<01:35,  1.04it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:41<01:25,  1.13it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:44<01:30,  1.06it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:45<01:20,  1.15it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:46<01:13,  1.24it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:48<01:13,  1.21it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:49<01:07,  1.29it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:51<01:02,  1.36it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:52<00:58,  1.41it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:53<00:55,  1.45it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:55<00:53,  1.47it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:56<00:51,  1.50it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:57<00:49,  1.52it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:59<00:52,  1.38it/s]Running loglikelihood requests:  50%|█████     | 71/142 [01:00<00:49,  1.43it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [01:01<00:46,  1.48it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [01:04<00:55,  1.21it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:05<00:49,  1.30it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:06<00:45,  1.38it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:07<00:42,  1.44it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:10<00:47,  1.25it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:11<00:42,  1.34it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:12<00:38,  1.42it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:13<00:35,  1.48it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:14<00:33,  1.52it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:16<00:31,  1.56it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:17<00:29,  1.59it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:19<00:35,  1.25it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:20<00:31,  1.35it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:22<00:28,  1.42it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:23<00:26,  1.49it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:24<00:24,  1.54it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:25<00:22,  1.57it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:26<00:20,  1.60it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:28<00:19,  1.63it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:29<00:18,  1.59it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:30<00:16,  1.63it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:31<00:15,  1.64it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:33<00:13,  1.67it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:34<00:12,  1.68it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:35<00:11,  1.70it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:36<00:09,  1.71it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:37<00:08,  1.72it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:38<00:07,  1.73it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:40<00:06,  1.68it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:41<00:05,  1.71it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:42<00:04,  1.73it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:43<00:03,  1.51it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:45<00:01,  1.59it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:46<00:00,  1.66it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:46<00:00,  1.34it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-3): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (4): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-7): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (8): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9-10): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (11): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (12-13): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (15): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (16): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (17-31): 15 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-3): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (4): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-7): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (8): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9-10): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (11): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (12-13): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (15): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (16): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (17-31): 15 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/34.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:45:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5098
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:45:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5098 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 98
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5160
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:45:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5160 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 160
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5052
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:45:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5052 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 52
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:45:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:45:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5173
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:45:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5173 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 173
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5180
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:45:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5180 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 180
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5075
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:45:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5075 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 75
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5211
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:45:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5211 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 211
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:45:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5099
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:45:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5099 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 99
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5157
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:45:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5157 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 157
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5164
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:45:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5164 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 164
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:45:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5151
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:45:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5151 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 151
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:45:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5172
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:45:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5172 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 172
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:45:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5219
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:45:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5219 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 219
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5063
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:45:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5063 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 63
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5140
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:45:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5140 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 140
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5247
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:45:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5247 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 247
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5112
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:45:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5112 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 112
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:45:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5174
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:45:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5174 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 174
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:45:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5040
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:45:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5040 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 40
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5012
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:45:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5012 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 12
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5009
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:45:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5009 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 9
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:45:13] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140215976440656 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140215976440656 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140215976440656 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140215976440656 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140218640583424 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140218640583424 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140218640583424 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140218640583424 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[34] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.43661971830985913, 'acc_stderr,none': 0.05927935558412972}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.6384788962207051
0.4946572039289874
0.7062468225311351
0.5924118081316296
0.8055799477986278
0.4290834385090486
0.5207152243980063
0.40307410421369466
0.575849756312845
0.37833122092903004
0.559402975459772
0.9202435099718248
0.7328649512638977
0.4656521136449837
0.6226167455222542
0.6500475926241498
0.14933051029764177
0.852848973497393
0.7020336348742873
0.8036038458930006
0.25840240277743587
0.45348406473870356
0.7291236246725161
0.5999541971262276
0.7071125031923391
0.6523270915574834
0.5982105985982268
0.6520903105513685
0.39933491227192136
0.6384788962207051
0.4946572039289874
0.7062468225311351
0.5924118081316296
0.8055799477986278
0.4290834385090486
0.5207152243980063
0.40307410421369466
0.575849756312845
0.37833122092903004
0.559402975459772
0.9202435099718248
0.7328649512638977
0.4656521136449837
0.6226167455222542
0.6500475926241498
0.14933051029764177
0.852848973497393
0.7020336348742873
0.8036038458930006
0.25840240277743587
0.45348406473870356
0.7291236246725161
0.5999541971262276
0.7071125031923391
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[6, 3, 2, 1, 5, 0, 7, 4]
tensor([6, 3, 2, 1, 5, 0, 7, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 5, 4, 2, 6, 0, 7, 1]
tensor([3, 5, 4, 2, 6, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 7, 6, 3, 4, 1, 5, 0]
tensor([2, 7, 6, 3, 4, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 2, 5, 4, 6, 0, 7, 1]
tensor([3, 2, 5, 4, 6, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 5, 7, 0, 3, 2, 6, 1]
tensor([4, 5, 7, 0, 3, 2, 6, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 6, 3, 4, 2, 1, 7, 0]
tensor([5, 6, 3, 4, 2, 1, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/34.pt
[RECEIVE] Queued message from 34
[QUEUE] Processing info from 34
[QUEUE] Stored info from 34
[RECEIVE] Queued message from 34
[QUEUE] Processing info from 34
[QUEUE] Stored info from 34
[RECEIVE] Queued message from 34
[QUEUE] Processing info from 34
[QUEUE] Stored info from 34
[RECEIVE] Queued message from 34
[QUEUE] Processing info from 34
[QUEUE] Stored info from 34
[RECEIVE] Queued message from 34
[QUEUE] Processing info from 34
[QUEUE] Stored info from 34
[RECEIVE] Queued message from 34
[QUEUE] Processing info from 34
[QUEUE] Stored info from 34
[RECEIVE] Queued message from 34
[QUEUE] Processing info from 34
[QUEUE] Stored info from 34
[RECEIVE] Queued message from 34
[QUEUE] Processing info from 34
[QUEUE] Stored info from 34
[RECEIVE] Queued message from 34
[QUEUE] Processing info from 34
[QUEUE] Stored info from 34
[RECEIVE] Queued message from 34
[QUEUE] Processing info from 34
[QUEUE] Stored info from 34
[RECEIVE] Queued message from 34
[QUEUE] Processing info from 34
[QUEUE] Stored info from 34
[RECEIVE] Queued message from 34
[QUEUE] Processing info from 34
[QUEUE] Stored info from 34
[RECEIVE] Queued message from 34
[QUEUE] Processing info from 34
[QUEUE] Stored info from 34
[RECEIVE] Queued message from 34
[QUEUE] Processing info from 34
[QUEUE] Stored info from 34
[RECEIVE] Queued message from 34
[QUEUE] Processing info from 34
[QUEUE] Stored info from 34
[RECEIVE] Queued message from 34
[QUEUE] Processing info from 34
[QUEUE] Stored info from 34
[RECEIVE] Queued message from 34
[QUEUE] Processing info from 34
[QUEUE] Stored info from 34
[RECEIVE] Queued message from 34
[QUEUE] Processing info from 34
[QUEUE] Stored info from 34
[RECEIVE] Queued message from 34
[QUEUE] Processing info from 34
[QUEUE] Stored info from 34
[RECEIVE] Queued message from 34
[QUEUE] Processing info from 34
[QUEUE] Stored info from 34
[RECEIVE] Queued message from 34
[QUEUE] Processing info from 34
[QUEUE] Stored info from 34
[RECEIVE] Queued message from 34
[QUEUE] Processing info from 34
[QUEUE] Stored info from 34
[RECEIVE] Queued message from 34
[QUEUE] Processing info from 34
[QUEUE] Stored info from 34
[RECEIVE] Queued message from 34
[QUEUE] Processing info from 34
[QUEUE] Stored info from 34
[RECEIVE] Queued message from 34
[QUEUE] Processing info from 34
[QUEUE] Stored info from 34
[RECEIVE] Queued message from 34
[QUEUE] Processing info from 34
[QUEUE] Stored info from 34
[RECEIVE] Queued message from 34
[QUEUE] Processing info from 34
[QUEUE] Stored info from 34
[RECEIVE] Queued message from 34
[QUEUE] Processing info from 34
[QUEUE] Stored info from 34
[RECEIVE] Queued message from 34
[QUEUE] Processing info from 34
[QUEUE] Stored info from 34
[RECEIVE] Queued message from 34
[QUEUE] Processing info from 34
[QUEUE] Stored info from 34
[RECEIVE] Queued message from 34
[QUEUE] Processing info from 34
[QUEUE] Stored info from 34
[87] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2605.68it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:03<07:13,  3.08s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:05<04:21,  1.88s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:08<03:25,  1.50s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:10<02:50,  1.27s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:12<02:31,  1.14s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:13<02:18,  1.06s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:15<02:08,  1.00it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:17<02:06,  1.01it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:19<01:58,  1.06it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:20<01:50,  1.11it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:22<01:44,  1.15it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:23<01:39,  1.20it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:25<01:34,  1.24it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:27<01:34,  1.22it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:28<01:29,  1.26it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:30<01:26,  1.29it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:31<01:23,  1.30it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:33<01:20,  1.32it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:34<01:18,  1.33it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:35<01:16,  1.35it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:37<01:22,  1.23it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:39<01:17,  1.28it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:40<01:13,  1.32it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:42<01:10,  1.36it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:43<01:06,  1.40it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:44<01:03,  1.43it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:46<01:01,  1.46it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:47<01:04,  1.35it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:49<01:00,  1.40it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:50<00:57,  1.44it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:51<00:55,  1.47it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:53<00:55,  1.43it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:54<00:52,  1.47it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:55<00:50,  1.50it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:57<00:47,  1.53it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:58<00:51,  1.39it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [01:00<00:47,  1.44it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [01:01<00:47,  1.42it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:02<00:44,  1.46it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:03<00:41,  1.51it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:05<00:40,  1.52it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:06<00:38,  1.54it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:09<00:47,  1.20it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:10<00:42,  1.30it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:11<00:38,  1.39it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:12<00:34,  1.46it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:13<00:32,  1.51it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:15<00:30,  1.55it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:16<00:28,  1.58it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:17<00:26,  1.61it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:18<00:26,  1.56it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:20<00:24,  1.59it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:21<00:22,  1.61it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:22<00:21,  1.63it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:23<00:20,  1.65it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:24<00:18,  1.66it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:26<00:17,  1.67it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:27<00:16,  1.68it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:28<00:15,  1.62it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:29<00:13,  1.66it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:30<00:12,  1.68it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:31<00:11,  1.70it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:33<00:09,  1.72it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:34<00:08,  1.73it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:35<00:07,  1.74it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:36<00:06,  1.75it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:37<00:05,  1.77it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:38<00:04,  1.70it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:39<00:02,  1.74it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:41<00:01,  1.76it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:42<00:00,  1.79it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:42<00:00,  1.39it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-3): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (4): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-7): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (8): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9-10): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (11): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (12-13): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (15): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (16): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (17-31): 15 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-3): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (4): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-7): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (8): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9-10): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (11): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (12-13): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (15): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (16): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (17-31): 15 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/87.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5211
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:47:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5211 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 211
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5174
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:47:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5174 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 174
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:47:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5075
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:47:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5075 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 75
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5098
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:47:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5098 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 98
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5219
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:47:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5219 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 219
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:47:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5180
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:47:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5180 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 180
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5140
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:47:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5140 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 140
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5112
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:47:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5112 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 112
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5164
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:47:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5164 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 164
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5099
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:47:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5099 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 99
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5157
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:47:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5157 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 157
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:47:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5173
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:47:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5173 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 173
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5160
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:47:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5160 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 160
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5172
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:47:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5172 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 172
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:47:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:47:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5151
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:47:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5151 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 151
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5247
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:47:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5247 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 247
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:47:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5034
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:47:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5034 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 34
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:47:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5009
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:47:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5009 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 9
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5052
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:47:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5052 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 52
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5063
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:47:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5063 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 63
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5040
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:47:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5040 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 40
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:47:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5012
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:47:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5012 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 12
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:47:12] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140218646384320 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140218646384320 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140218646384320 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140218646384320 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140218646384320 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140218646384320 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140218646384320 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140218646384320 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[87] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.43661971830985913, 'acc_stderr,none': 0.05927935558412972}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.6384788962207051
0.4946572039289874
0.7062468225311351
0.5924118081316296
0.8055799477986278
0.4290834385090486
0.5207152243980063
0.40307410421369466
0.575849756312845
0.37833122092903004
0.559402975459772
0.9202435099718248
0.7328649512638977
0.4656521136449837
0.6226167455222542
0.6500475926241498
0.14933051029764177
0.852848973497393
0.7020336348742873
0.8036038458930006
0.25840240277743587
0.45348406473870356
0.7291236246725161
0.5999541971262276
0.7071125031923391
0.6523270915574834
0.5982105985982268
0.6520903105513685
0.39933491227192136
0.6384788962207051
0.4946572039289874
0.7062468225311351
0.5924118081316296
0.8055799477986278
0.4290834385090486
0.5207152243980063
0.40307410421369466
0.575849756312845
0.37833122092903004
0.559402975459772
0.9202435099718248
0.7328649512638977
0.4656521136449837
0.6226167455222542
0.6500475926241498
0.14933051029764177
0.852848973497393
0.7020336348742873
0.8036038458930006
0.25840240277743587
0.45348406473870356
0.7291236246725161
0.5999541971262276
0.7071125031923391
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[6, 3, 2, 1, 5, 0, 7, 4]
tensor([6, 3, 2, 1, 5, 0, 7, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 5, 4, 2, 6, 0, 7, 1]
tensor([3, 5, 4, 2, 6, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 7, 6, 3, 4, 1, 5, 0]
tensor([2, 7, 6, 3, 4, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 2, 5, 4, 6, 0, 7, 1]
tensor([3, 2, 5, 4, 6, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 5, 7, 0, 3, 2, 6, 1]
tensor([4, 5, 7, 0, 3, 2, 6, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 6, 3, 4, 2, 1, 7, 0]
tensor([5, 6, 3, 4, 2, 1, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/87.pt
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[RECEIVE] Queued message from 87
[QUEUE] Processing info from 87
[QUEUE] Stored info from 87
[164] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2639.00it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:13,  2.65s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:13,  1.39s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:39,  1.16s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:11<04:01,  1.79s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:13<03:12,  1.45s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:15<02:43,  1.25s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:16<02:24,  1.12s/it]Running loglikelihood requests:  11%|█         | 15/142 [00:18<02:09,  1.02s/it]Running loglikelihood requests:  12%|█▏        | 17/142 [00:20<02:01,  1.03it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:21<01:51,  1.11it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:23<01:43,  1.17it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:24<01:37,  1.22it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:26<01:31,  1.28it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:27<01:27,  1.32it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:28<01:23,  1.35it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:30<01:22,  1.34it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:31<01:19,  1.37it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:33<01:16,  1.39it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:34<01:14,  1.41it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:36<01:12,  1.43it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:37<01:10,  1.44it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:38<01:08,  1.45it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:40<01:06,  1.47it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:41<01:06,  1.43it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:42<01:04,  1.45it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:44<01:01,  1.49it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:45<00:58,  1.52it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:46<00:56,  1.54it/s]Running loglikelihood requests:  40%|████      | 57/142 [01:35<11:05,  7.83s/it]Running loglikelihood requests:  42%|████▏     | 59/142 [02:43<21:38, 15.64s/it]Running loglikelihood requests:  43%|████▎     | 61/142 [02:44<15:02, 11.14s/it]Running loglikelihood requests:  44%|████▍     | 63/142 [02:46<10:30,  7.99s/it]Running loglikelihood requests:  46%|████▌     | 65/142 [02:47<07:27,  5.81s/it]Running loglikelihood requests:  47%|████▋     | 67/142 [02:48<05:18,  4.25s/it]Running loglikelihood requests:  49%|████▊     | 69/142 [02:50<03:55,  3.23s/it]Running loglikelihood requests:  50%|█████     | 71/142 [02:51<02:53,  2.44s/it]Running loglikelihood requests:  51%|█████▏    | 73/142 [02:52<02:09,  1.88s/it]Running loglikelihood requests:  53%|█████▎    | 75/142 [02:55<01:53,  1.69s/it]Running loglikelihood requests:  54%|█████▍    | 77/142 [02:56<01:28,  1.36s/it]Running loglikelihood requests:  56%|█████▌    | 79/142 [02:57<01:10,  1.12s/it]Running loglikelihood requests:  57%|█████▋    | 81/142 [02:58<00:58,  1.04it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [02:59<00:49,  1.18it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [03:01<00:43,  1.31it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [03:02<00:38,  1.41it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [03:03<00:35,  1.50it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [03:04<00:35,  1.44it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [03:06<00:32,  1.50it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [03:07<00:30,  1.56it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [03:08<00:28,  1.60it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [03:09<00:26,  1.64it/s]Running loglikelihood requests:  71%|███████   | 101/142 [03:11<00:31,  1.31it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [03:12<00:27,  1.41it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [03:17<00:43,  1.18s/it]Running loglikelihood requests:  75%|███████▌  | 107/142 [03:18<00:34,  1.01it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [03:19<00:28,  1.16it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [03:20<00:23,  1.31it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [03:21<00:20,  1.43it/s]Running loglikelihood requests:  81%|████████  | 115/142 [03:22<00:17,  1.53it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [03:24<00:16,  1.53it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [03:25<00:14,  1.61it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [03:26<00:12,  1.68it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [03:27<00:10,  1.73it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [03:28<00:09,  1.78it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [03:29<00:08,  1.81it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [03:30<00:07,  1.84it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [03:31<00:05,  1.87it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [03:34<00:06,  1.31it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [03:35<00:04,  1.44it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [03:36<00:03,  1.58it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [03:37<00:01,  1.68it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [03:38<00:00,  1.78it/s]Running loglikelihood requests: 100%|██████████| 142/142 [03:38<00:00,  1.54s/it]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-8): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10-30): 21 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (31): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-8): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10-30): 21 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (31): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/164.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:51:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:51:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:51:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5211
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:51:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5211 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 211
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:51:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5063
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:51:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5063 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 63
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5034
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:51:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5034 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 34
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5174
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:51:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5174 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 174
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:51:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:51:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5219
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:51:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5219 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 219
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5075
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:51:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5075 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 75
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5140
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:51:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5140 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 140
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:51:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5052
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:51:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5052 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 52
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5112
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:51:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5112 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 112
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5151
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:51:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5151 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 151
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5009
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:51:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5009 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 9
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5172
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:51:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5172 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 172
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:51:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5157
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:51:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5157 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 157
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5098
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:51:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5098 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 98
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5247
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:51:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5247 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 247
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5180
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:51:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5180 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 180
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5099
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:51:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5099 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 99
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5040
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:51:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5040 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 40
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:51:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:51:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5173
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:51:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5173 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 173
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5160
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:51:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5160 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 160
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5012
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:51:08] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5012 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 12
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140240017047328 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140240017047328 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140240017047328 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140240017047328 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140216457159088 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140216457159088 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140216457159088 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140216457159088 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[164] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4507042253521127, 'acc_stderr,none': 0.05947027187738001}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.891975958338049
0.3982001908036579
0.26652204443251004
0.14111026067874816
0.11763525057572936
0.8635004180455561
0.8741394655456793
0.5304527321557103
0.44617634270319845
0.7007455592903002
0.6799150362476898
0.3511365594568724
0.47145939463701925
0.4744673317050211
0.905435493752087
0.903612941640167
0.8893763849001028
0.6821933807976941
0.6796182015499347
0.7774502436639344
0.8164788896198145
0.9011095591650676
0.8564639597370403
0.9528866120532432
0.4784452972921274
0.48852492817861076
0.8397355586186119
0.7433051149723976
0.5457687574271932
0.891975958338049
0.3982001908036579
0.26652204443251004
0.14111026067874816
0.11763525057572936
0.8635004180455561
0.8741394655456793
0.5304527321557103
0.44617634270319845
0.7007455592903002
0.6799150362476898
0.3511365594568724
0.47145939463701925
0.4744673317050211
0.905435493752087
0.903612941640167
0.8893763849001028
0.6821933807976941
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[6, 5, 4, 3, 2, 1, 7, 0]
tensor([6, 5, 4, 3, 2, 1, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 7, 4, 1, 0, 6, 3]
tensor([5, 2, 7, 4, 1, 0, 6, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 6, 5, 2, 4, 0, 7, 1]
tensor([3, 6, 5, 2, 4, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 4, 6, 0, 2, 1, 7, 3]
tensor([5, 4, 6, 0, 2, 1, 7, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 0, 7, 3, 5, 1, 6, 2]
tensor([4, 0, 7, 3, 5, 1, 6, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 5, 1, 3, 2, 0, 1, 4]
tensor([0, 5, 1, 3, 2, 0, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[1, 0, 0, 1, 1.0, 1.0, 1.0, 1.0]
tensor([1, 0, 0, 1, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[1, 0, 1, 1.0, 1.0, 0, 1.0, 1.0]
tensor([1, 0, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[0, 1, 1.0, 1.0, 0, 1, 1.0, 1.0]
tensor([0, 1, 1, 1, 0, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/164.pt
[RECEIVE] Queued message from 164
[QUEUE] Processing info from 164
[QUEUE] Stored info from 164
[RECEIVE] Queued message from 164
[QUEUE] Processing info from 164
[QUEUE] Stored info from 164
[RECEIVE] Queued message from 164
[QUEUE] Processing info from 164
[QUEUE] Stored info from 164
[RECEIVE] Queued message from 164
[QUEUE] Processing info from 164
[QUEUE] Stored info from 164
[RECEIVE] Queued message from 164
[QUEUE] Processing info from 164
[QUEUE] Stored info from 164
[RECEIVE] Queued message from 164
[QUEUE] Processing info from 164
[QUEUE] Stored info from 164
[RECEIVE] Queued message from 164
[QUEUE] Processing info from 164
[QUEUE] Stored info from 164
[RECEIVE] Queued message from 164
[QUEUE] Processing info from 164
[QUEUE] Stored info from 164
[RECEIVE] Queued message from 164
[QUEUE] Processing info from 164
[QUEUE] Stored info from 164
[RECEIVE] Queued message from 164
[QUEUE] Processing info from 164
[QUEUE] Stored info from 164
[RECEIVE] Queued message from 164
[QUEUE] Processing info from 164
[QUEUE] Stored info from 164
[RECEIVE] Queued message from 164
[QUEUE] Processing info from 164
[QUEUE] Stored info from 164
[RECEIVE] Queued message from 164
[QUEUE] Processing info from 164
[QUEUE] Stored info from 164
[RECEIVE] Queued message from 164
[QUEUE] Processing info from 164
[QUEUE] Stored info from 164
[RECEIVE] Queued message from 164
[QUEUE] Processing info from 164
[QUEUE] Stored info from 164
[RECEIVE] Queued message from 164
[QUEUE] Processing info from 164
[QUEUE] Stored info from 164
[RECEIVE] Queued message from 164
[QUEUE] Processing info from 164
[QUEUE] Stored info from 164
[RECEIVE] Queued message from 164
[QUEUE] Processing info from 164
[QUEUE] Stored info from 164
[RECEIVE] Queued message from 164
[QUEUE] Processing info from 164
[QUEUE] Stored info from 164
[RECEIVE] Queued message from 164
[QUEUE] Processing info from 164
[QUEUE] Stored info from 164
[RECEIVE] Queued message from 164
[QUEUE] Processing info from 164
[QUEUE] Stored info from 164
[RECEIVE] Queued message from 164
[QUEUE] Processing info from 164
[QUEUE] Stored info from 164
[RECEIVE] Queued message from 164
[QUEUE] Processing info from 164
[QUEUE] Stored info from 164
[RECEIVE] Queued message from 164
[QUEUE] Processing info from 164
[QUEUE] Stored info from 164
[RECEIVE] Queued message from 164
[QUEUE] Processing info from 164
[QUEUE] Stored info from 164
[RECEIVE] Queued message from 164
[QUEUE] Processing info from 164
[QUEUE] Stored info from 164
[RECEIVE] Queued message from 164
[QUEUE] Processing info from 164
[QUEUE] Stored info from 164
[RECEIVE] Queued message from 164
[QUEUE] Processing info from 164
[QUEUE] Stored info from 164
[RECEIVE] Queued message from 164
[QUEUE] Processing info from 164
[QUEUE] Stored info from 164
[RECEIVE] Queued message from 164
[QUEUE] Processing info from 164
[QUEUE] Stored info from 164
[RECEIVE] Queued message from 164
[QUEUE] Processing info from 164
[QUEUE] Stored info from 164
[117] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2620.08it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:29,  2.76s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:18,  1.43s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:40,  1.18s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:30,  1.11s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:17,  1.03s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:08,  1.02it/s]Running loglikelihood requests:   9%|▉         | 13/142 [00:13<02:01,  1.06it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:15<01:55,  1.10it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:17<01:49,  1.14it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:18<01:46,  1.16it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:20<01:40,  1.20it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:21<01:35,  1.25it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:23<01:31,  1.29it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:24<01:27,  1.32it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:26<01:24,  1.34it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:27<01:22,  1.35it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:29<01:33,  1.16it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:31<01:27,  1.22it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:32<01:22,  1.27it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:34<01:18,  1.31it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:35<01:15,  1.34it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:36<01:12,  1.37it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:38<01:13,  1.33it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:39<01:09,  1.37it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:41<01:05,  1.42it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:42<01:02,  1.47it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:43<00:59,  1.49it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:45<00:57,  1.52it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:46<00:55,  1.54it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:47<00:53,  1.56it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:49<01:03,  1.28it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:51<00:58,  1.36it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:52<00:58,  1.32it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:53<00:53,  1.39it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:55<00:50,  1.45it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:56<00:47,  1.50it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:57<00:44,  1.53it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [00:59<00:44,  1.50it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:00<00:42,  1.52it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:01<00:41,  1.52it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:02<00:39,  1.55it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:04<00:37,  1.58it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:05<00:35,  1.59it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:06<00:34,  1.61it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:07<00:32,  1.64it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:08<00:30,  1.65it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:10<00:31,  1.55it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:11<00:29,  1.60it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:12<00:27,  1.63it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:13<00:25,  1.66it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:14<00:24,  1.68it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:16<00:23,  1.70it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:17<00:21,  1.69it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:18<00:20,  1.71it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:19<00:20,  1.60it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:21<00:18,  1.64it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:22<00:17,  1.69it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:23<00:15,  1.69it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:24<00:14,  1.71it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:25<00:13,  1.72it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:26<00:12,  1.73it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:27<00:10,  1.75it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:28<00:09,  1.76it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:30<00:08,  1.70it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:31<00:07,  1.74it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:32<00:06,  1.77it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:33<00:04,  1.80it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:34<00:03,  1.83it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:35<00:02,  1.86it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:36<00:01,  1.88it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:37<00:00,  1.91it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:37<00:00,  1.45it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-3): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (4): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-6): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (7): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (8-15): 8 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (16): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (17-21): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (22): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (23-27): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (28): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (29-30): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (31): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-3): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (4): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-6): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (7): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (8-15): 8 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (16): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (17-21): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (22): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (23-27): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (28): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (29-30): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (31): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/117.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:53:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:53:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5075
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:53:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5075 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 75
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5112
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:53:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5112 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 112
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5151
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:53:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5151 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 151
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5098
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:53:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5098 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 98
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:53:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5160
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:53:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5160 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 160
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5247
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:53:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5247 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 247
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5040
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:53:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5040 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 40
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5172
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:53:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5172 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 172
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:53:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5034
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:53:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5034 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 34
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:53:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5211
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:53:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5211 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 211
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5063
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:53:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5063 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 63
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:53:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5052
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:53:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5052 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 52
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:53:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5174
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:53:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5174 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 174
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5164
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:53:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5164 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 164
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5012
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:53:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5012 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 12
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5219
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:53:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5219 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 219
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5173
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:53:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5173 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 173
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5140
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:53:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5140 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 140
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5099
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:53:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5099 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 99
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5009
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:53:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5009 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 9
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:53:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:53:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5157
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:53:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5157 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 157
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5180
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:53:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5180 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 180
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140218743968624 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140218743968624 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140218743968624 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140218743968624 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140215972886816 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140215972886816 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140215972886816 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140215972886816 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[117] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.43661971830985913, 'acc_stderr,none': 0.05927935558412972}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.7988766190696382
0.433785810695937
0.6525315214782026
0.871250377966373
0.7790022985921221
0.6581533546839238
0.6948782189696622
0.4773368074709654
0.7967725763717977
0.6899017375628973
0.8876656342513365
0.741048035098914
0.7711231987685904
0.658722026565161
0.8415498496492992
0.7230018765402745
0.5047290951856622
0.7541475774993723
0.5858483604351846
0.9316615143976832
0.7753381144708663
0.5505312367470351
0.97693166402346
0.9600861235134092
0.9818242386505116
0.9256028941559552
0.44553043946224297
0.3299453067275913
0.5544144775455869
0.7988766190696382
0.433785810695937
0.6525315214782026
0.871250377966373
0.7790022985921221
0.6581533546839238
0.6948782189696622
0.4773368074709654
0.7967725763717977
0.6899017375628973
0.8876656342513365
0.741048035098914
0.7711231987685904
0.658722026565161
0.8415498496492992
0.7230018765402745
0.5047290951856622
0.7541475774993723
Total groups 72 exceeded the threshold, stopping comparison.
The group tensor is
[5, 3, 7, 1, 2, 0, 6, 4]
tensor([5, 3, 7, 1, 2, 0, 6, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 4, 5, 2, 0, 7, 1]
tensor([6, 3, 4, 5, 2, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 4, 7, 2, 5, 1, 6, 0]
tensor([3, 4, 7, 2, 5, 1, 6, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 4, 7, 1, 3, 0, 5, 2]
tensor([6, 4, 7, 1, 3, 0, 5, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 3, 6, 2, 0, 1, 7, 4]
tensor([5, 3, 6, 2, 0, 1, 7, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[3, 5, 0, 2, 4, 0, 1, 1]
tensor([3, 5, 0, 2, 4, 0, 1, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/117.pt
[RECEIVE] Queued message from 117
[QUEUE] Processing info from 117
[QUEUE] Stored info from 117
[RECEIVE] Queued message from 117
[QUEUE] Processing info from 117
[QUEUE] Stored info from 117
[RECEIVE] Queued message from 117
[QUEUE] Processing info from 117
[QUEUE] Stored info from 117
[RECEIVE] Queued message from 117
[QUEUE] Processing info from 117
[QUEUE] Stored info from 117
[RECEIVE] Queued message from 117
[QUEUE] Processing info from 117
[QUEUE] Stored info from 117
[RECEIVE] Queued message from 117
[QUEUE] Processing info from 117
[QUEUE] Stored info from 117
[RECEIVE] Queued message from 117
[QUEUE] Processing info from 117
[QUEUE] Stored info from 117
[RECEIVE] Queued message from 117
[QUEUE] Processing info from 117
[QUEUE] Stored info from 117
[RECEIVE] Queued message from 117
[QUEUE] Processing info from 117
[QUEUE] Stored info from 117
[RECEIVE] Queued message from 117
[QUEUE] Processing info from 117
[QUEUE] Stored info from 117
[RECEIVE] Queued message from 117
[QUEUE] Processing info from 117
[QUEUE] Stored info from 117
[RECEIVE] Queued message from 117
[QUEUE] Processing info from 117
[QUEUE] Stored info from 117
[RECEIVE] Queued message from 117
[QUEUE] Processing info from 117
[QUEUE] Stored info from 117
[RECEIVE] Queued message from 117
[QUEUE] Processing info from 117
[QUEUE] Stored info from 117
[RECEIVE] Queued message from 117
[QUEUE] Processing info from 117
[QUEUE] Stored info from 117
[RECEIVE] Queued message from 117
[QUEUE] Processing info from 117
[QUEUE] Stored info from 117
[RECEIVE] Queued message from 117
[QUEUE] Processing info from 117
[QUEUE] Stored info from 117
[RECEIVE] Queued message from 117
[QUEUE] Processing info from 117
[QUEUE] Stored info from 117
[RECEIVE] Queued message from 117
[QUEUE] Processing info from 117
[QUEUE] Stored info from 117
[RECEIVE] Queued message from 117
[QUEUE] Processing info from 117
[QUEUE] Stored info from 117
[RECEIVE] Queued message from 117
[QUEUE] Processing info from 117
[QUEUE] Stored info from 117
[RECEIVE] Queued message from 117
[QUEUE] Processing info from 117
[QUEUE] Stored info from 117
[RECEIVE] Queued message from 117
[QUEUE] Processing info from 117
[QUEUE] Stored info from 117
[RECEIVE] Queued message from 117
[QUEUE] Processing info from 117
[QUEUE] Stored info from 117
[RECEIVE] Queued message from 117
[QUEUE] Processing info from 117
[QUEUE] Stored info from 117
[RECEIVE] Queued message from 117
[QUEUE] Processing info from 117
[QUEUE] Stored info from 117
[RECEIVE] Queued message from 117
[QUEUE] Processing info from 117
[QUEUE] Stored info from 117
[RECEIVE] Queued message from 117
[QUEUE] Processing info from 117
[QUEUE] Stored info from 117
[RECEIVE] Queued message from 117
[QUEUE] Processing info from 117
[QUEUE] Stored info from 117
[RECEIVE] Queued message from 117
[QUEUE] Processing info from 117
[QUEUE] Stored info from 117
[RECEIVE] Queued message from 117
[QUEUE] Processing info from 117
[QUEUE] Stored info from 117
[157] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2564.42it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:28,  2.76s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:18,  1.43s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:54,  1.27s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:32,  1.13s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:20,  1.05s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:11,  1.00s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:03,  1.05it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:16<02:00,  1.05it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:17<01:54,  1.09it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:19<01:47,  1.15it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:20<01:41,  1.19it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:23<01:59,  1.01s/it]Running loglikelihood requests:  18%|█▊        | 25/142 [00:25<01:48,  1.08it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:26<01:44,  1.11it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:28<01:36,  1.17it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:29<01:30,  1.23it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:31<01:26,  1.26it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:32<01:22,  1.30it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:34<01:19,  1.32it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:35<01:16,  1.34it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:37<01:18,  1.29it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:38<01:14,  1.32it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:40<01:11,  1.36it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:41<01:08,  1.39it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:42<01:05,  1.42it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:44<01:02,  1.45it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:45<01:00,  1.47it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:46<01:02,  1.40it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:48<00:59,  1.44it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:49<00:56,  1.47it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:50<00:54,  1.49it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:52<00:52,  1.51it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:53<00:50,  1.53it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:54<00:48,  1.54it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:55<00:47,  1.55it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:57<00:47,  1.49it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:58<00:45,  1.52it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [00:59<00:43,  1.54it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:01<00:41,  1.56it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:02<00:40,  1.57it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:03<00:38,  1.58it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:04<00:37,  1.58it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:06<00:36,  1.57it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:07<00:37,  1.47it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:09<00:35,  1.48it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:10<00:33,  1.51it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:11<00:31,  1.54it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:12<00:30,  1.57it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:14<00:28,  1.59it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:15<00:26,  1.61it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:16<00:25,  1.62it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:17<00:24,  1.56it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:19<00:23,  1.59it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:20<00:21,  1.62it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:21<00:21,  1.52it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:22<00:19,  1.57it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:24<00:18,  1.60it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:25<00:16,  1.63it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:26<00:15,  1.64it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:27<00:14,  1.61it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:28<00:12,  1.64it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:30<00:11,  1.66it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:31<00:10,  1.68it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:32<00:08,  1.70it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:33<00:07,  1.71it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:34<00:06,  1.72it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:35<00:05,  1.74it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:36<00:03,  1.76it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:38<00:03,  1.50it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:39<00:01,  1.59it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:40<00:00,  1.67it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:40<00:00,  1.41it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-15): 11 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (16): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (17): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (18-30): 13 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (31): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-15): 11 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (16): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (17): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (18-30): 13 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (31): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/157.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5034
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:55:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5034 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 34
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5219
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:55:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5219 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 219
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5247
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:55:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5247 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 247
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5098
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:55:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5098 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 98
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5164
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:55:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5164 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 164
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5112
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:55:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5112 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 112
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5160
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:55:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5160 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 160
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:55:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5151
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:55:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5151 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 151
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:55:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5052
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:55:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5052 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 52
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5012
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:55:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5012 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 12
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5180
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:55:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5180 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 180
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:55:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5211
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:55:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5211 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 211
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:55:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5140
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:55:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5140 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 140
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5099
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:55:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5099 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 99
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5174
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:55:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5174 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 174
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5063
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:55:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5063 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 63
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5040
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:55:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5040 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 40
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:55:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5173
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:55:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5173 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 173
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:55:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:55:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5172
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:55:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5172 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 172
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:55:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5009
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:55:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5009 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 9
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:55:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:55:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5075
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:55:01] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5075 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 75
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140215976485680 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140215976485680 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140215976485680 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140215976485680 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140215973529600 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140215973529600 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140215973529600 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140215973529600 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[157] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4225352112676056, 'acc_stderr,none': 0.059039842056825796}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8980271762152415
0.2639787465429745
0.5625332696290335
0.793649776762635
0.3255906663223904
0.0484338095439226
0.14923347971103265
0.5710137578745996
0.4024845012023718
0.40192324238029414
0.7421347168699821
0.33528288680973795
0.3799695309319889
0.38260979896102654
0.8288488026343434
0.5741428622514854
0.32292256805357755
0.2608862087917634
0.5815302784189874
0.6526878745506514
0.23164180573632143
0.7209107763819704
0.641400211099821
0.36378810546943974
0.5869502091248732
0.1447672816588167
0.22624580082754567
0.43042437260655503
0.5802248606876254
0.8980271762152415
0.2639787465429745
0.5625332696290335
0.793649776762635
0.3255906663223904
0.0484338095439226
0.14923347971103265
0.5710137578745996
0.4024845012023718
0.40192324238029414
0.7421347168699821
0.33528288680973795
0.3799695309319889
0.38260979896102654
0.8288488026343434
0.5741428622514854
0.32292256805357755
0.2608862087917634
0.5815302784189874
0.6526878745506514
0.23164180573632143
0.7209107763819704
0.641400211099821
0.36378810546943974
0.5869502091248732
0.1447672816588167
0.22624580082754567
0.43042437260655503
Total groups 73 exceeded the threshold, stopping comparison.
The group tensor is
[5, 3, 7, 4, 1, 0, 6, 2]
tensor([5, 3, 7, 4, 1, 0, 6, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 5, 1, 2, 4, 0, 7, 3]
tensor([6, 5, 1, 2, 4, 0, 7, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 4, 3, 1, 5, 0, 7, 2]
tensor([6, 4, 3, 1, 5, 0, 7, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[7, 3, 6, 0, 4, 2, 5, 1]
tensor([7, 3, 6, 0, 4, 2, 5, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 4, 1, 2, 0, 3, 5, 1]
tensor([0, 4, 1, 2, 0, 3, 5, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[2, 0, 1, 3, 1, 0, 2, 3]
tensor([2, 0, 1, 3, 1, 0, 2, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 1, 1, 3, 0, 2, 3, 2]
tensor([0, 1, 1, 3, 0, 2, 3, 2], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1, 1.0, 1.0, 1.0, 0]
tensor([0, 1, 1, 1, 1, 1, 1, 0], dtype=torch.int32)
[0, 1]
The group tensor is
[1, 0, 1, 1.0, 1.0, 0, 1.0, 1.0]
tensor([1, 0, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/157.pt
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[RECEIVE] Queued message from 157
[QUEUE] Processing info from 157
[QUEUE] Stored info from 157
[127] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2583.69it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:30,  2.77s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:21,  1.45s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:07<03:07,  1.37s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:09<02:57,  1.32s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:11<02:35,  1.17s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:13<02:21,  1.08s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:15<02:11,  1.02s/it]Running loglikelihood requests:  11%|█         | 15/142 [00:16<02:02,  1.04it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:18<01:58,  1.06it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:20<01:50,  1.11it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:21<01:44,  1.16it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:23<01:38,  1.20it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:24<01:34,  1.24it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:26<01:30,  1.27it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:27<01:27,  1.29it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:29<01:27,  1.27it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:31<01:24,  1.29it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:32<01:21,  1.31it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:34<01:19,  1.33it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:35<01:16,  1.34it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:36<01:14,  1.35it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:38<01:15,  1.31it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:39<01:12,  1.34it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:41<01:08,  1.38it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:42<01:05,  1.41it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:43<01:03,  1.44it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:45<01:00,  1.46it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:46<00:58,  1.48it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:47<00:56,  1.50it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:49<00:56,  1.46it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:50<00:54,  1.48it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:51<00:52,  1.50it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:53<00:50,  1.52it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:54<00:49,  1.53it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:55<00:47,  1.54it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:57<00:45,  1.55it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:58<00:44,  1.56it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [00:59<00:44,  1.51it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:01<00:49,  1.31it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:02<00:45,  1.38it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:04<00:42,  1.44it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:05<00:39,  1.48it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:06<00:37,  1.51it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:08<00:36,  1.53it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:09<00:35,  1.49it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:10<00:33,  1.51it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:11<00:31,  1.54it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:13<00:30,  1.56it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:14<00:30,  1.47it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:16<00:31,  1.37it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:17<00:28,  1.44it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:18<00:26,  1.49it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:20<00:25,  1.43it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:21<00:23,  1.50it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:22<00:21,  1.55it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:24<00:19,  1.58it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:25<00:17,  1.61it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:26<00:16,  1.63it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:27<00:15,  1.65it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:28<00:13,  1.67it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:30<00:13,  1.59it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:31<00:11,  1.62it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:32<00:10,  1.65it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:33<00:08,  1.67it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:34<00:07,  1.69it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:35<00:06,  1.71it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:37<00:05,  1.73it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:38<00:04,  1.74it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:39<00:02,  1.76it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:41<00:02,  1.31it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:42<00:00,  1.45it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:42<00:00,  1.38it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-3): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (4): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-6): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (7): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (8-15): 8 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (16): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (17-21): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (22): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (23-27): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (28): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (29-30): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (31): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-3): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (4): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-6): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (7): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (8-15): 8 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (16): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (17-21): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (22): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (23-27): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (28): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (29-30): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (31): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/127.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5098
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:57:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5098 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 98
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5172
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:57:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5172 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 172
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:57:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5112
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:57:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5112 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 112
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:57:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:57:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5151
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:57:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5151 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 151
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5040
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:57:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5040 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 40
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5009
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:57:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5009 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 9
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5052
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:57:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5052 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 52
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5034
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:57:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5034 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 34
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:57:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5180
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:57:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5180 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 180
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5157
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:57:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5157 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 157
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5211
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:57:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5211 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 211
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5063
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:57:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5063 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 63
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5140
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:57:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5140 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 140
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:57:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5164
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:57:03] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5164 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 164
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5247
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:57:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5247 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 247
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5160
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:57:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5160 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 160
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5219
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:57:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5219 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 219
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:57:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:57:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5012
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:57:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5012 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 12
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5099
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:57:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5099 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 99
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5174
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:57:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5174 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 174
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:57:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5075
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:57:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5075 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 75
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:57:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5173
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:57:04] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5173 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 173
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140215449816816 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140215449816816 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140215449816816 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140215449816816 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140215922102576 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140215922102576 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140215922102576 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140215922102576 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[127] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.43661971830985913, 'acc_stderr,none': 0.05927935558412972}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.7988766190696382
0.433785810695937
0.6525315214782026
0.871250377966373
0.7790022985921221
0.6581533546839238
0.6948782189696622
0.4773368074709654
0.7967725763717977
0.6899017375628973
0.8876656342513365
0.741048035098914
0.7711231987685904
0.658722026565161
0.8415498496492992
0.7230018765402745
0.5047290951856622
0.7541475774993723
0.5858483604351846
0.9316615143976832
0.7753381144708663
0.5505312367470351
0.97693166402346
0.9600861235134092
0.9818242386505116
0.9256028941559552
0.44553043946224297
0.3299453067275913
0.5544144775455869
0.7988766190696382
0.433785810695937
0.6525315214782026
0.871250377966373
0.7790022985921221
0.6581533546839238
0.6948782189696622
0.4773368074709654
0.7967725763717977
0.6899017375628973
0.8876656342513365
0.741048035098914
0.7711231987685904
0.658722026565161
0.8415498496492992
0.7230018765402745
0.5047290951856622
0.7541475774993723
Total groups 72 exceeded the threshold, stopping comparison.
The group tensor is
[5, 3, 7, 1, 2, 0, 6, 4]
tensor([5, 3, 7, 1, 2, 0, 6, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 4, 5, 2, 0, 7, 1]
tensor([6, 3, 4, 5, 2, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 4, 7, 2, 5, 1, 6, 0]
tensor([3, 4, 7, 2, 5, 1, 6, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 4, 7, 1, 3, 0, 5, 2]
tensor([6, 4, 7, 1, 3, 0, 5, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 3, 6, 2, 0, 1, 7, 4]
tensor([5, 3, 6, 2, 0, 1, 7, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[3, 5, 0, 2, 4, 0, 1, 1]
tensor([3, 5, 0, 2, 4, 0, 1, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/127.pt
[RECEIVE] Queued message from 127
[QUEUE] Processing info from 127
[QUEUE] Stored info from 127
[RECEIVE] Queued message from 127
[QUEUE] Processing info from 127
[QUEUE] Stored info from 127
[RECEIVE] Queued message from 127
[QUEUE] Processing info from 127
[QUEUE] Stored info from 127
[RECEIVE] Queued message from 127
[QUEUE] Processing info from 127
[QUEUE] Stored info from 127
[RECEIVE] Queued message from 127
[QUEUE] Processing info from 127
[QUEUE] Stored info from 127
[RECEIVE] Queued message from 127
[QUEUE] Processing info from 127
[QUEUE] Stored info from 127
[RECEIVE] Queued message from 127
[QUEUE] Processing info from 127
[QUEUE] Stored info from 127
[RECEIVE] Queued message from 127
[QUEUE] Processing info from 127
[QUEUE] Stored info from 127
[RECEIVE] Queued message from 127
[QUEUE] Processing info from 127
[QUEUE] Stored info from 127
[RECEIVE] Queued message from 127
[QUEUE] Processing info from 127
[QUEUE] Stored info from 127
[RECEIVE] Queued message from 127
[QUEUE] Processing info from 127
[QUEUE] Stored info from 127
[RECEIVE] Queued message from 127
[QUEUE] Processing info from 127
[QUEUE] Stored info from 127
[RECEIVE] Queued message from 127
[QUEUE] Processing info from 127
[QUEUE] Stored info from 127
[RECEIVE] Queued message from 127
[QUEUE] Processing info from 127
[QUEUE] Stored info from 127
[RECEIVE] Queued message from 127
[QUEUE] Processing info from 127
[QUEUE] Stored info from 127
[RECEIVE] Queued message from 127
[QUEUE] Processing info from 127
[QUEUE] Stored info from 127
[RECEIVE] Queued message from 127
[QUEUE] Processing info from 127
[QUEUE] Stored info from 127
[RECEIVE] Queued message from 127
[QUEUE] Processing info from 127
[QUEUE] Stored info from 127
[RECEIVE] Queued message from 127
[QUEUE] Processing info from 127
[QUEUE] Stored info from 127
[RECEIVE] Queued message from 127
[QUEUE] Processing info from 127
[QUEUE] Stored info from 127
[RECEIVE] Queued message from 127
[QUEUE] Processing info from 127
[QUEUE] Stored info from 127
[RECEIVE] Queued message from 127
[QUEUE] Processing info from 127
[QUEUE] Stored info from 127
[RECEIVE] Queued message from 127
[QUEUE] Processing info from 127
[QUEUE] Stored info from 127
[RECEIVE] Queued message from 127
[QUEUE] Processing info from 127
[QUEUE] Stored info from 127
[RECEIVE] Queued message from 127
[QUEUE] Processing info from 127
[QUEUE] Stored info from 127
[RECEIVE] Queued message from 127
[QUEUE] Processing info from 127
[QUEUE] Stored info from 127
[RECEIVE] Queued message from 127
[QUEUE] Processing info from 127
[QUEUE] Stored info from 127
[RECEIVE] Queued message from 127
[QUEUE] Processing info from 127
[QUEUE] Stored info from 127
[RECEIVE] Queued message from 127
[QUEUE] Processing info from 127
[QUEUE] Stored info from 127
[RECEIVE] Queued message from 127
[QUEUE] Processing info from 127
[QUEUE] Stored info from 127
[RECEIVE] Queued message from 127
[QUEUE] Processing info from 127
[QUEUE] Stored info from 127
[94] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2532.38it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:54,  2.94s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:24,  1.47s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:44,  1.20s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:27,  1.09s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:27,  1.11s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:16,  1.04s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:08,  1.00it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:16<02:00,  1.05it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:17<01:54,  1.09it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:19<01:47,  1.14it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:21<01:47,  1.12it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:22<01:41,  1.17it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:24<01:36,  1.21it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:25<01:32,  1.25it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:27<01:28,  1.27it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:28<01:25,  1.30it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:30<01:25,  1.27it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:32<01:22,  1.29it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:33<01:20,  1.31it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:34<01:17,  1.33it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:37<01:30,  1.11it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:38<01:23,  1.18it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:40<01:21,  1.20it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:41<01:15,  1.26it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:43<01:11,  1.31it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:44<01:07,  1.36it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:45<01:03,  1.39it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:47<01:01,  1.42it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:48<01:00,  1.39it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:50<00:58,  1.42it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:51<00:58,  1.40it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:52<00:55,  1.43it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:54<00:52,  1.46it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:55<00:50,  1.48it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:56<00:48,  1.50it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:58<00:46,  1.51it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:59<00:45,  1.53it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [01:00<00:45,  1.48it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:02<00:43,  1.51it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:03<00:41,  1.52it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:04<00:39,  1.53it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:05<00:38,  1.55it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:07<00:36,  1.56it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:08<00:35,  1.57it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:09<00:33,  1.57it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:13<00:49,  1.04it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:14<00:42,  1.14it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:15<00:37,  1.24it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:17<00:33,  1.33it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:18<00:30,  1.41it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:19<00:27,  1.47it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:21<00:32,  1.21it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:23<00:28,  1.32it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:24<00:24,  1.40it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:25<00:22,  1.47it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:26<00:20,  1.52it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:27<00:18,  1.56it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:29<00:16,  1.59it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:30<00:15,  1.61it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:31<00:14,  1.56it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:32<00:13,  1.59it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:34<00:11,  1.62it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:35<00:10,  1.64it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:36<00:09,  1.66it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:37<00:07,  1.66it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:38<00:06,  1.67it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:39<00:05,  1.70it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:41<00:04,  1.73it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:42<00:03,  1.54it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:43<00:01,  1.60it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:44<00:00,  1.66it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:44<00:00,  1.35it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-5): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (7-18): 12 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (19): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (20): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (21): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (22): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (23): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24-27): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (28): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (29-31): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-5): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (7-18): 12 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (19): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (20): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (21): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (22): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (23): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24-27): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (28): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (29-31): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/94.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:59:07] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5172
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:59:07] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5172 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 172
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5173
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:59:07] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5173 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 173
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5174
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:59:07] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5174 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 174
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5034
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:59:07] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5034 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 34
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5075
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:59:07] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5075 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 75
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:59:07] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5164
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:59:07] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5164 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 164
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5063
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:59:07] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5063 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 63
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:59:07] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:59:07] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:59:07] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5219
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:59:07] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5219 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 219
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5040
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:59:07] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5040 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 40
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5012
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:59:07] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5012 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 12
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5180
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:59:07] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5180 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 180
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5211
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:59:07] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5211 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 211
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:59:07] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5247
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:59:07] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5247 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 247
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5052
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:59:07] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5052 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 52
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5009
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:59:07] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5009 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 9
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5160
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:59:07] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5160 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 160
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:59:07] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5098
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:59:07] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5098 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 98
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5112
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:59:07] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5112 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 112
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:59:07] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5157
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:59:07] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5157 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 157
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5140
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:59:07] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5140 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 140
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5151
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:59:07] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5151 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 151
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5099
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:59:07] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5099 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 99
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [18/May/2025 09:59:07] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140215976040624 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140215976040624 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140215976040624 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140215976040624 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140210780187264 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140210780187264 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140210780187264 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140210780187264 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[94] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.43661971830985913, 'acc_stderr,none': 0.05927935558412972}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8579940969956122
0.9172414698319051
0.5383905049167778
0.7154451748054276
0.547671504517951
0.8833126318549385
0.815742382492854
0.6517871119418787
0.320270438500039
0.20847052823122236
0.9142272844016534
0.8979022224289909
0.8081306275049516
0.5991072724268783
0.8920856671099552
0.8548931916511182
0.9545918502043321
0.9270787839270334
0.4466502436196787
0.892147307459623
0.7319083135729072
0.8321772812735796
0.9605666801588856
0.3242808765028886
0.884060616512067
0.5116280105615226
0.22259676802614164
0.8272877996431262
Total groups 68 exceeded the threshold, stopping comparison.
The group tensor is
[3, 2, 7, 4, 5, 0, 6, 1]
tensor([3, 2, 7, 4, 5, 0, 6, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[1, 6, 5, 4, 2, 0, 7, 3]
tensor([1, 6, 5, 4, 2, 0, 7, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 3, 5, 6, 1, 2, 7, 0]
tensor([4, 3, 5, 6, 1, 2, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[2, 5, 3, 7, 0, 1, 6, 4]
tensor([2, 5, 3, 7, 0, 1, 6, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 2, 1, 1, 3, 2, 3]
tensor([0, 0, 2, 1, 1, 3, 2, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[3, 0, 2, 1, 1, 0, 2, 3]
tensor([3, 0, 2, 1, 1, 0, 2, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 0, 1, 1.0, 1, 1.0, 1.0, 1.0]
tensor([0, 0, 1, 1, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[1, 0, 1, 1.0, 1.0, 0, 1.0, 1.0]
tensor([1, 0, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/94.pt
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[RECEIVE] Queued message from 94
[QUEUE] Processing info from 94
[QUEUE] Stored info from 94
[40] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2585.64it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:03<07:03,  3.01s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:29,  1.51s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:07<02:52,  1.26s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:31,  1.12s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:18,  1.04s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:09,  1.01it/s]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:16,  1.06s/it]Running loglikelihood requests:  11%|█         | 15/142 [00:17<02:15,  1.06s/it]Running loglikelihood requests:  12%|█▏        | 17/142 [00:18<02:03,  1.01it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:20<01:52,  1.09it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:21<01:45,  1.15it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:23<01:38,  1.20it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:24<01:33,  1.25it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:26<01:32,  1.25it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:27<01:27,  1.29it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:29<01:24,  1.32it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:30<01:21,  1.34it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:32<01:18,  1.36it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:33<01:16,  1.38it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:34<01:14,  1.39it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:36<01:15,  1.34it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:38<01:16,  1.29it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:40<01:31,  1.06it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:42<01:21,  1.16it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:43<01:14,  1.25it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:44<01:08,  1.34it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:45<01:03,  1.40it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:47<01:04,  1.34it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:48<01:00,  1.41it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:50<00:56,  1.46it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:51<00:54,  1.50it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:52<00:51,  1.53it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:53<00:49,  1.55it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:55<00:47,  1.57it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:56<00:45,  1.59it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:57<00:46,  1.54it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:58<00:43,  1.57it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [01:00<00:41,  1.60it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:01<00:40,  1.62it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:02<00:38,  1.64it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:03<00:37,  1.64it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:04<00:35,  1.65it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:06<00:34,  1.65it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:07<00:35,  1.57it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:08<00:33,  1.59it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:11<00:42,  1.19it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:12<00:37,  1.30it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:13<00:33,  1.40it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:15<00:30,  1.48it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:16<00:27,  1.54it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:17<00:27,  1.51it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:18<00:24,  1.57it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:19<00:22,  1.61it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:21<00:21,  1.65it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:22<00:19,  1.67it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:23<00:18,  1.70it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:24<00:16,  1.71it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:25<00:15,  1.73it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:26<00:14,  1.73it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:28<00:13,  1.66it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:29<00:12,  1.69it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:30<00:11,  1.71it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:31<00:09,  1.73it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:32<00:08,  1.75it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:33<00:07,  1.77it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:34<00:06,  1.78it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:35<00:05,  1.80it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:36<00:03,  1.82it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:39<00:03,  1.31it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:40<00:02,  1.44it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:41<00:00,  1.57it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:41<00:00,  1.40it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-8): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10-22): 13 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (23): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24-31): 8 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-8): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10-22): 13 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (23): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24-31): 8 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/40.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:01:10] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:01:10] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:01:10] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5151
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:01:10] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5151 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 151
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5063
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:01:10] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5063 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 63
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5164
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:01:10] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5164 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 164
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5034
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:01:10] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5034 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 34
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5160
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:01:10] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5160 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 160
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5157
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:01:10] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5157 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 157
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5012
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:01:10] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5012 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 12
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5247
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:01:10] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5247 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 247
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5112
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:01:10] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5112 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 112
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5174
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:01:10] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5174 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 174
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5140
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:01:10] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5140 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 140
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5173
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:01:10] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5173 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 173
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5172
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:01:10] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5172 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 172
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5075
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:01:10] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5075 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 75
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5009
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:01:10] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5009 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 9
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5211
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:01:10] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5211 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 211
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:01:10] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:01:10] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5099
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:01:10] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5099 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 99
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:01:10] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5052
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:01:10] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5052 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 52
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:01:10] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:01:10] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:01:10] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5180
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:01:10] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5180 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 180
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5098
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:01:10] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5098 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 98
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:01:10] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5219
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:01:10] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5219 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 219
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140215451522192 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140215451522192 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140215451522192 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140215451522192 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140210827870128 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140210827870128 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140210827870128 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140210827870128 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[40] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4647887323943662, 'acc_stderr,none': 0.05961305784972239}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8670569790937798
0.5488271932172035
0.673013746499191
0.7739554714966184
0.626122351153327
0.7480239804573661
0.8404062667282521
0.585845593784257
0.5486089643527782
0.295628094796439
0.8187255304150794
0.4183228390778105
0.5130578032019412
0.8769017151034573
0.9364820135353734
0.9916222006713932
0.9862354083632185
0.9582978800582982
0.8980649992917061
0.8669816466709701
0.9008509099634621
0.9321426254796342
0.8646919425811247
0.6505326186022521
0.6612551300691957
0.8835733690017037
0.7234157945938043
0.7342253877992871
0.5683390151095499
0.8670569790937798
0.5488271932172035
0.673013746499191
0.7739554714966184
0.626122351153327
0.7480239804573661
0.8404062667282521
0.585845593784257
0.5486089643527782
0.295628094796439
0.8187255304150794
0.4183228390778105
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[5, 3, 6, 2, 4, 0, 7, 1]
tensor([5, 3, 6, 2, 4, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 4, 6, 7, 2, 0, 5, 1]
tensor([3, 4, 6, 7, 2, 0, 5, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 6, 2, 1, 3, 0, 7, 5]
tensor([4, 6, 2, 1, 3, 0, 7, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 4, 6, 0, 1, 2, 7, 3]
tensor([5, 4, 6, 0, 1, 2, 7, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 2, 6, 5, 4, 0, 7, 1]
tensor([3, 2, 6, 5, 4, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 2, 5, 6, 3, 0, 7, 1]
tensor([4, 2, 5, 6, 3, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/40.pt
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[RECEIVE] Queued message from 40
[QUEUE] Processing info from 40
[QUEUE] Stored info from 40
[180] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2565.19it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:08,  2.61s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:13,  1.39s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:39,  1.17s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:09<02:45,  1.23s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:28,  1.11s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:16,  1.04s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:08,  1.01it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:16<02:00,  1.05it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:18<01:59,  1.04it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:19<01:51,  1.10it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:21<01:45,  1.15it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:22<01:39,  1.19it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:24<01:34,  1.23it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:25<01:30,  1.26it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:27<01:27,  1.29it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:28<01:27,  1.28it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:30<01:23,  1.30it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:31<01:21,  1.32it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:33<01:18,  1.33it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:34<01:16,  1.35it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:36<01:14,  1.36it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:37<01:12,  1.36it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:39<01:13,  1.32it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:40<01:10,  1.35it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:42<01:07,  1.38it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:43<01:04,  1.41it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:44<01:02,  1.44it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:46<00:59,  1.46it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:47<00:57,  1.47it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:49<00:58,  1.41it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:50<00:55,  1.45it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:51<00:53,  1.48it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:52<00:51,  1.50it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:54<00:49,  1.52it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:55<00:47,  1.54it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:56<00:45,  1.54it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:57<00:44,  1.56it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [00:59<00:49,  1.36it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:01<00:45,  1.42it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:02<00:42,  1.47it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:03<00:40,  1.50it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:04<00:38,  1.53it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:06<00:36,  1.54it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:07<00:35,  1.56it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:08<00:34,  1.52it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:10<00:33,  1.54it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:11<00:31,  1.54it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:12<00:30,  1.56it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:13<00:28,  1.57it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:15<00:27,  1.59it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:16<00:25,  1.61it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:17<00:23,  1.63it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:18<00:22,  1.63it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:20<00:22,  1.57it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:21<00:20,  1.59it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:22<00:19,  1.62it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:23<00:17,  1.64it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:24<00:16,  1.66it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:26<00:15,  1.67it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:27<00:13,  1.68it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:28<00:12,  1.68it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:29<00:12,  1.54it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:31<00:10,  1.58it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:32<00:09,  1.62it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:33<00:07,  1.65it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:34<00:06,  1.68it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:35<00:05,  1.70it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:37<00:04,  1.62it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:38<00:03,  1.66it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:40<00:02,  1.30it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:41<00:00,  1.41it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:41<00:00,  1.40it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-8): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10-30): 21 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (31): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-4): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-8): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10-30): 21 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (31): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:0)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/180.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5009
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:03:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5009 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 9
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5174
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:03:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5174 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 174
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5075
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:03:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5075 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 75
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5211
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:03:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5211 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 211
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5151
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:03:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5151 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 151
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:03:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5098
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:03:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5098 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 98
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5099
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:03:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5099 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 99
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:03:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5040
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:03:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5040 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 40
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5112
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:03:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5112 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 112
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5052
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:03:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5052 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 52
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5034
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:03:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5034 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 34
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:03:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5160
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:03:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5160 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 160
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:03:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5172
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:03:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5172 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 172
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5164
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:03:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5164 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 164
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5012
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:03:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5012 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 12
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:03:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5140
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:03:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5140 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 140
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5219
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:03:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5219 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 219
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5063
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:03:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5063 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 63
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5247
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:03:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5247 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 247
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5173
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:03:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5173 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 173
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:03:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5157
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:03:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5157 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 157
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:03:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:03:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:03:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:03:11] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140210780183904 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140210780183904 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140210780183904 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140210780183904 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140215942449248 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140215942449248 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140215942449248 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140215942449248 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[180] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4507042253521127, 'acc_stderr,none': 0.05947027187738001}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.891975958338049
0.3982001908036579
0.26652204443251004
0.14111026067874816
0.11763525057572936
0.8635004180455561
0.8741394655456793
0.5304527321557103
0.44617634270319845
0.7007455592903002
0.6799150362476898
0.3511365594568724
0.47145939463701925
0.4744673317050211
0.905435493752087
0.903612941640167
0.8893763849001028
0.6821933807976941
0.6796182015499347
0.7774502436639344
0.8164788896198145
0.9011095591650676
0.8564639597370403
0.9528866120532432
0.4784452972921274
0.48852492817861076
0.8397355586186119
0.7433051149723976
0.5457687574271932
0.891975958338049
0.3982001908036579
0.26652204443251004
0.14111026067874816
0.11763525057572936
0.8635004180455561
0.8741394655456793
0.5304527321557103
0.44617634270319845
0.7007455592903002
0.6799150362476898
0.3511365594568724
0.47145939463701925
0.4744673317050211
0.905435493752087
0.903612941640167
0.8893763849001028
0.6821933807976941
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[6, 5, 4, 3, 2, 1, 7, 0]
tensor([6, 5, 4, 3, 2, 1, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 2, 7, 4, 1, 0, 6, 3]
tensor([5, 2, 7, 4, 1, 0, 6, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 6, 5, 2, 4, 0, 7, 1]
tensor([3, 6, 5, 2, 4, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 4, 6, 0, 2, 1, 7, 3]
tensor([5, 4, 6, 0, 2, 1, 7, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[4, 0, 7, 3, 5, 1, 6, 2]
tensor([4, 0, 7, 3, 5, 1, 6, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 5, 1, 3, 2, 0, 1, 4]
tensor([0, 5, 1, 3, 2, 0, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[1, 0, 0, 1, 1.0, 1.0, 1.0, 1.0]
tensor([1, 0, 0, 1, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[1, 0, 1, 1.0, 1.0, 0, 1.0, 1.0]
tensor([1, 0, 1, 1, 1, 0, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[0, 1, 1.0, 1.0, 0, 1, 1.0, 1.0]
tensor([0, 1, 1, 1, 0, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/180.pt
[RECEIVE] Queued message from 180
[QUEUE] Processing info from 180
[QUEUE] Stored info from 180
[RECEIVE] Queued message from 180
[QUEUE] Processing info from 180
[QUEUE] Stored info from 180
[RECEIVE] Queued message from 180
[QUEUE] Processing info from 180
[QUEUE] Stored info from 180
[RECEIVE] Queued message from 180
[QUEUE] Processing info from 180
[QUEUE] Stored info from 180
[RECEIVE] Queued message from 180
[QUEUE] Processing info from 180
[QUEUE] Stored info from 180
[RECEIVE] Queued message from 180
[QUEUE] Processing info from 180
[QUEUE] Stored info from 180
[RECEIVE] Queued message from 180
[QUEUE] Processing info from 180
[QUEUE] Stored info from 180
[RECEIVE] Queued message from 180
[QUEUE] Processing info from 180
[QUEUE] Stored info from 180
[RECEIVE] Queued message from 180
[QUEUE] Processing info from 180
[QUEUE] Stored info from 180
[RECEIVE] Queued message from 180
[QUEUE] Processing info from 180
[QUEUE] Stored info from 180
[RECEIVE] Queued message from 180
[QUEUE] Processing info from 180
[QUEUE] Stored info from 180
[RECEIVE] Queued message from 180
[QUEUE] Processing info from 180
[QUEUE] Stored info from 180
[RECEIVE] Queued message from 180
[QUEUE] Processing info from 180
[QUEUE] Stored info from 180
[RECEIVE] Queued message from 180
[QUEUE] Processing info from 180
[QUEUE] Stored info from 180
[RECEIVE] Queued message from 180
[QUEUE] Processing info from 180
[QUEUE] Stored info from 180
[RECEIVE] Queued message from 180
[QUEUE] Processing info from 180
[QUEUE] Stored info from 180
[RECEIVE] Queued message from 180
[QUEUE] Processing info from 180
[QUEUE] Stored info from 180
[RECEIVE] Queued message from 180
[QUEUE] Processing info from 180
[QUEUE] Stored info from 180
[RECEIVE] Queued message from 180
[QUEUE] Processing info from 180
[QUEUE] Stored info from 180
[RECEIVE] Queued message from 180
[QUEUE] Processing info from 180
[QUEUE] Stored info from 180
[RECEIVE] Queued message from 180
[QUEUE] Processing info from 180
[QUEUE] Stored info from 180
[RECEIVE] Queued message from 180
[QUEUE] Processing info from 180
[QUEUE] Stored info from 180
[RECEIVE] Queued message from 180
[QUEUE] Processing info from 180
[QUEUE] Stored info from 180
[RECEIVE] Queued message from 180
[QUEUE] Processing info from 180
[QUEUE] Stored info from 180
[RECEIVE] Queued message from 180
[QUEUE] Processing info from 180
[QUEUE] Stored info from 180
[RECEIVE] Queued message from 180
[QUEUE] Processing info from 180
[QUEUE] Stored info from 180
[RECEIVE] Queued message from 180
[QUEUE] Processing info from 180
[QUEUE] Stored info from 180
[RECEIVE] Queued message from 180
[QUEUE] Processing info from 180
[QUEUE] Stored info from 180
[RECEIVE] Queued message from 180
[QUEUE] Processing info from 180
[QUEUE] Stored info from 180
[RECEIVE] Queued message from 180
[QUEUE] Processing info from 180
[QUEUE] Stored info from 180
[RECEIVE] Queued message from 180
[QUEUE] Processing info from 180
[QUEUE] Stored info from 180
[211] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 1324.30it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:51,  2.92s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:25,  1.48s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:46,  1.22s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:29,  1.11s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:25,  1.10s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:15,  1.04s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:08,  1.00it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:16<02:01,  1.04it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:18<01:55,  1.08it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:19<01:49,  1.12it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:21<01:48,  1.12it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:23<01:42,  1.16it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:24<01:37,  1.20it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:26<01:32,  1.24it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:27<01:29,  1.26it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:29<01:26,  1.28it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:30<01:27,  1.25it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:32<01:24,  1.27it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:33<01:22,  1.28it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:35<01:19,  1.30it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:36<01:17,  1.30it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:38<01:15,  1.31it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:39<01:12,  1.33it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:41<01:14,  1.28it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:42<01:10,  1.32it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:44<01:06,  1.36it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:45<01:04,  1.38it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:47<01:01,  1.41it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:48<00:59,  1.43it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:49<00:57,  1.45it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:51<00:57,  1.41it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:52<00:55,  1.43it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:53<00:53,  1.45it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:55<00:51,  1.46it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:56<00:49,  1.48it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:57<00:47,  1.49it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:59<00:45,  1.50it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [01:00<00:44,  1.50it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:03<01:00,  1.08it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:04<00:53,  1.18it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:06<00:47,  1.27it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:07<00:43,  1.34it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:08<00:41,  1.38it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:10<00:38,  1.43it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:11<00:39,  1.35it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:13<00:41,  1.22it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:15<00:41,  1.19it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:16<00:36,  1.28it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:18<00:33,  1.35it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:19<00:30,  1.41it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:20<00:28,  1.45it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:22<00:28,  1.39it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:23<00:25,  1.45it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:24<00:23,  1.49it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:26<00:21,  1.52it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:27<00:20,  1.55it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:28<00:18,  1.56it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:29<00:17,  1.58it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:31<00:15,  1.59it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:33<00:17,  1.30it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:34<00:15,  1.33it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:35<00:13,  1.40it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:37<00:11,  1.46it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:38<00:09,  1.51it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:39<00:09,  1.42it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:41<00:07,  1.48it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:42<00:06,  1.45it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:43<00:04,  1.51it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:44<00:03,  1.57it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:46<00:01,  1.62it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:47<00:00,  1.66it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:47<00:00,  1.32it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-3): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (4-8): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10-20): 11 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (21): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (22-23): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24-25): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (26): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (27-31): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-3): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (4-8): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10-20): 11 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (21): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (22-23): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (24-25): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (26): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (27-31): 5 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:1)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/211.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:05:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:05:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5160
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:05:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5160 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 160
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5173
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:05:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5173 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 173
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5012
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:05:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5012 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 12
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:05:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:05:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5034
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:05:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5034 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 34
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5040
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:05:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5040 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 40
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:05:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5098
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:05:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5098 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 98
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5052
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:05:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5052 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 52
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5174
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:05:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5174 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 174
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5164
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:05:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5164 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 164
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5151
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:05:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5151 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 151
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5157
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:05:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5157 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 157
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5063
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:05:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5063 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 63
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5247
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:05:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5247 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 247
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5219
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:05:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5219 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 219
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:05:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5075
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:05:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5075 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 75
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5112
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:05:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5112 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 112
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5180
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:05:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5180 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 180
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:05:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5099
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:05:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5099 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 99
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:05:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5009
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:05:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5009 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 9
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5140
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:05:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5140 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 140
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5172
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:05:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5172 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 172
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:05:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:05:17] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140208453954272 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140208453954272 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140208453954272 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140208453954272 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140208458643216 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140208458643216 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140208458643216 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140208458643216 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[211] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.43661971830985913, 'acc_stderr,none': 0.05927935558412972}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8745617680355892
0.4870053329545456
0.7039635907698274
0.13683136283338845
0.45491781836309914
0.7394007339170455
0.7100810563328822
0.5089938007827006
0.6148932447522303
0.6097500975530942
0.2557945445996536
0.6585024343395449
0.3077968033302773
0.5696663704302732
0.4357302352587323
0.8508165638532892
0.2937402676601578
0.5546720889398816
0.456887590217546
0.8515148368106646
0.6351128178266827
0.587082322906938
0.4014945886309545
0.6816643170727646
0.7647343638504926
0.15578350583970074
0.7065213224778255
0.687952127174302
0.881700230921547
0.8745617680355892
0.4870053329545456
0.7039635907698274
0.13683136283338845
0.45491781836309914
0.7394007339170455
0.7100810563328822
0.5089938007827006
0.6148932447522303
0.6097500975530942
0.2557945445996536
0.6585024343395449
0.3077968033302773
0.5696663704302732
0.4357302352587323
0.8508165638532892
0.2937402676601578
0.5546720889398816
0.456887590217546
0.8515148368106646
0.6351128178266827
0.587082322906938
0.4014945886309545
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[5, 3, 7, 6, 1, 0, 4, 2]
tensor([5, 3, 7, 6, 1, 0, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 7, 1, 5, 6, 0, 4, 2]
tensor([3, 7, 1, 5, 6, 0, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[6, 3, 2, 4, 5, 1, 7, 0]
tensor([6, 3, 2, 4, 5, 1, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 4, 7, 5, 1, 3, 6, 0]
tensor([2, 4, 7, 5, 1, 3, 6, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[0, 2, 4, 6, 5, 1, 7, 3]
tensor([0, 2, 4, 6, 5, 1, 7, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 2, 5, 3, 6, 0, 7, 1]
tensor([4, 2, 5, 3, 6, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/211.pt
[RECEIVE] Queued message from 211
[QUEUE] Processing info from 211
[QUEUE] Stored info from 211
[RECEIVE] Queued message from 211
[QUEUE] Processing info from 211
[QUEUE] Stored info from 211
[RECEIVE] Queued message from 211
[QUEUE] Processing info from 211
[QUEUE] Stored info from 211
[RECEIVE] Queued message from 211
[QUEUE] Processing info from 211
[QUEUE] Stored info from 211
[RECEIVE] Queued message from 211
[QUEUE] Processing info from 211
[QUEUE] Stored info from 211
[RECEIVE] Queued message from 211
[QUEUE] Processing info from 211
[QUEUE] Stored info from 211
[RECEIVE] Queued message from 211
[QUEUE] Processing info from 211
[QUEUE] Stored info from 211
[RECEIVE] Queued message from 211
[QUEUE] Processing info from 211
[QUEUE] Stored info from 211
[RECEIVE] Queued message from 211
[QUEUE] Processing info from 211
[QUEUE] Stored info from 211
[RECEIVE] Queued message from 211
[QUEUE] Processing info from 211
[QUEUE] Stored info from 211
[RECEIVE] Queued message from 211
[QUEUE] Processing info from 211
[QUEUE] Stored info from 211
[RECEIVE] Queued message from 211
[QUEUE] Processing info from 211
[QUEUE] Stored info from 211
[RECEIVE] Queued message from 211
[QUEUE] Processing info from 211
[QUEUE] Stored info from 211
[RECEIVE] Queued message from 211
[QUEUE] Processing info from 211
[QUEUE] Stored info from 211
[RECEIVE] Queued message from 211
[QUEUE] Processing info from 211
[QUEUE] Stored info from 211
[RECEIVE] Queued message from 211
[QUEUE] Processing info from 211
[QUEUE] Stored info from 211
[RECEIVE] Queued message from 211
[QUEUE] Processing info from 211
[QUEUE] Stored info from 211
[RECEIVE] Queued message from 211
[QUEUE] Processing info from 211
[QUEUE] Stored info from 211
[RECEIVE] Queued message from 211
[QUEUE] Processing info from 211
[QUEUE] Stored info from 211
[RECEIVE] Queued message from 211
[QUEUE] Processing info from 211
[QUEUE] Stored info from 211
[RECEIVE] Queued message from 211
[QUEUE] Processing info from 211
[QUEUE] Stored info from 211
[RECEIVE] Queued message from 211
[QUEUE] Processing info from 211
[QUEUE] Stored info from 211
[RECEIVE] Queued message from 211
[QUEUE] Processing info from 211
[QUEUE] Stored info from 211
[RECEIVE] Queued message from 211
[QUEUE] Processing info from 211
[QUEUE] Stored info from 211
[RECEIVE] Queued message from 211
[QUEUE] Processing info from 211
[QUEUE] Stored info from 211
[RECEIVE] Queued message from 211
[QUEUE] Processing info from 211
[QUEUE] Stored info from 211
[RECEIVE] Queued message from 211
[QUEUE] Processing info from 211
[QUEUE] Stored info from 211
[RECEIVE] Queued message from 211
[QUEUE] Processing info from 211
[QUEUE] Stored info from 211
[RECEIVE] Queued message from 211
[QUEUE] Processing info from 211
[QUEUE] Stored info from 211
[RECEIVE] Queued message from 211
[QUEUE] Processing info from 211
[QUEUE] Stored info from 211
[RECEIVE] Queued message from 211
[QUEUE] Processing info from 211
[QUEUE] Stored info from 211
[163] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2580.84it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:17,  2.67s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:13,  1.39s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:41,  1.18s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:39,  1.18s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:24,  1.09s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:14,  1.03s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:06,  1.02it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:16<01:59,  1.06it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:18<02:09,  1.03s/it]Running loglikelihood requests:  13%|█▎        | 19/142 [00:20<01:58,  1.04it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:21<01:49,  1.10it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:23<01:42,  1.16it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:24<01:37,  1.20it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:26<01:32,  1.24it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:27<01:31,  1.23it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:29<01:27,  1.27it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:30<01:24,  1.29it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:32<01:22,  1.30it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:33<01:20,  1.31it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:35<01:18,  1.32it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:36<01:15,  1.33it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:38<01:16,  1.30it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:39<01:12,  1.33it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:41<01:09,  1.36it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:42<01:07,  1.39it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:43<01:04,  1.41it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:45<01:02,  1.43it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:46<01:00,  1.45it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:48<01:00,  1.41it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:49<00:58,  1.43it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:50<00:55,  1.45it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:52<00:53,  1.46it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:53<00:52,  1.48it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:54<00:50,  1.49it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:56<00:48,  1.50it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:57<00:47,  1.50it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:59<00:47,  1.45it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [01:00<00:46,  1.45it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:01<00:43,  1.48it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:02<00:41,  1.51it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:04<00:40,  1.52it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:05<00:38,  1.52it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:06<00:37,  1.52it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:08<00:35,  1.54it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:09<00:35,  1.49it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:10<00:33,  1.51it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:12<00:31,  1.53it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:13<00:30,  1.55it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:14<00:28,  1.56it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:15<00:27,  1.57it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:17<00:25,  1.58it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:18<00:24,  1.59it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:20<00:25,  1.44it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:21<00:23,  1.49it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:22<00:21,  1.53it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:23<00:19,  1.55it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:24<00:18,  1.58it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:26<00:16,  1.60it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:27<00:16,  1.51it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:29<00:16,  1.42it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:30<00:14,  1.50it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:31<00:12,  1.56it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:32<00:10,  1.61it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:33<00:09,  1.64it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:35<00:07,  1.67it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:36<00:06,  1.68it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:37<00:05,  1.69it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:38<00:04,  1.70it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:39<00:03,  1.67it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:40<00:01,  1.70it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:42<00:00,  1.73it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:42<00:00,  1.39it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-31): 26 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-31): 26 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:2)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/163.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5172
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:07:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5172 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 172
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5009
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:07:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5009 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 9
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5140
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:07:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5140 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 140
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5180
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:07:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5180 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 180
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5211
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:07:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5211 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 211
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5157
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:07:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5157 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 157
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:07:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:07:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5063
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:07:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5063 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 63
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5012
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:07:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5012 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 12
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5099
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:07:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5099 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 99
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5219
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:07:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5219 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 219
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5112
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:07:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5112 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 112
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5052
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:07:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5052 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 52
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5164
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:07:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5164 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 164
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5098
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:07:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5098 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 98
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5160
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:07:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5160 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 160
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:07:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:07:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5173
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:07:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5173 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 173
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:07:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:07:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5034
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:07:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5034 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 34
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:07:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5075
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:07:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5075 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 75
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:07:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5040
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:07:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5040 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 40
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:07:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5174
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:07:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5174 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 174
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5247
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:07:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5247 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 247
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5151
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:07:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5151 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 151
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140210782947328 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140210782947328 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140210782947328 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140210782947328 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140209476775824 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140209476775824 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140209476775824 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140209476775824 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[163] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4225352112676056, 'acc_stderr,none': 0.059039842056825796}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8301327615319641
0.7817720914227475
0.8113678911982368
0.2257173763133808
0.2927105469616105
0.5177793359335131
0.8145737190612207
0.7363478990038121
0.20758834533702153
0.2533018140549718
0.30764875086796684
0.29044714199656413
0.9350374080783923
0.6277994360424477
0.603553220567354
0.78279661631625
0.6718149226457006
0.5353760149732133
0.6848376228333551
0.9446001512801305
0.7972906165117697
0.5043025319455414
0.5939887608746786
0.6455402209569181
0.2505215486241291
0.321550947803521
0.8361163063826382
0.7208169010376037
0.9633188772100769
0.8301327615319641
0.7817720914227475
0.8113678911982368
0.2257173763133808
0.2927105469616105
0.5177793359335131
0.8145737190612207
0.7363478990038121
0.20758834533702153
0.2533018140549718
0.30764875086796684
0.29044714199656413
0.9350374080783923
0.6277994360424477
0.603553220567354
0.78279661631625
0.6718149226457006
0.5353760149732133
0.6848376228333551
0.9446001512801305
0.7972906165117697
0.5043025319455414
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[6, 5, 4, 1, 3, 0, 7, 2]
tensor([6, 5, 4, 1, 3, 0, 7, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 3, 7, 5, 1, 0, 4, 2]
tensor([6, 3, 7, 5, 1, 0, 4, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[6, 4, 7, 0, 3, 1, 5, 2]
tensor([6, 4, 7, 0, 3, 1, 5, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 5, 3, 4, 1, 0, 7, 6]
tensor([2, 5, 3, 4, 1, 0, 7, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 5, 0, 2, 4, 0, 1, 1]
tensor([3, 5, 0, 2, 4, 0, 1, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 3, 1, 0, 2, 1, 2, 3]
tensor([0, 3, 1, 0, 2, 1, 2, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 3, 1, 2, 2, 1, 3, 0]
tensor([0, 3, 1, 2, 2, 1, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 1, 2, 0, 3, 3, 2, 1]
tensor([0, 1, 2, 0, 3, 3, 2, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1, 0, 1.0, 1.0, 1.0, 1.0]
tensor([0, 1, 1, 0, 1, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/163.pt
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[RECEIVE] Queued message from 163
[QUEUE] Processing info from 163
[QUEUE] Stored info from 163
[52] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2545.72it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:57,  2.96s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:29,  1.51s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:07<02:54,  1.27s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:33,  1.14s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:21,  1.06s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:12,  1.01s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:05,  1.03it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:16<01:59,  1.06it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:18<01:56,  1.07it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:19<01:49,  1.12it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:21<01:44,  1.16it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:22<01:38,  1.20it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:24<01:34,  1.24it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:25<01:30,  1.27it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:27<01:30,  1.25it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:28<01:26,  1.28it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:30<01:24,  1.29it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:31<01:21,  1.31it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:33<01:19,  1.32it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:34<01:17,  1.33it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:36<01:15,  1.34it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:37<01:16,  1.30it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:39<01:12,  1.33it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:40<01:09,  1.37it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:42<01:06,  1.41it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:43<01:03,  1.43it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:44<01:02,  1.42it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:46<01:00,  1.44it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:48<01:04,  1.32it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:49<01:00,  1.36it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:50<00:57,  1.40it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:51<00:55,  1.43it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:53<00:52,  1.46it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:54<00:50,  1.47it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:56<00:52,  1.40it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:57<00:49,  1.44it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:59<00:49,  1.40it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [01:00<00:46,  1.45it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:01<00:44,  1.47it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:02<00:41,  1.50it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:04<00:40,  1.52it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:05<00:38,  1.53it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:06<00:37,  1.54it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:08<00:42,  1.30it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:10<00:39,  1.36it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:11<00:36,  1.40it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:12<00:33,  1.45it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:14<00:31,  1.49it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:15<00:29,  1.52it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:16<00:27,  1.55it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:17<00:26,  1.57it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:19<00:25,  1.52it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:20<00:25,  1.46it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:21<00:23,  1.51it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:23<00:21,  1.55it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:24<00:19,  1.59it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:25<00:17,  1.61it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:26<00:16,  1.63it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:27<00:15,  1.63it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:29<00:14,  1.58it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:31<00:14,  1.41it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:32<00:12,  1.49it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:33<00:10,  1.56it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:34<00:09,  1.60it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:35<00:07,  1.63it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:36<00:06,  1.61it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:38<00:05,  1.60it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:39<00:04,  1.58it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:40<00:03,  1.63it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:41<00:01,  1.68it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:42<00:00,  1.72it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:42<00:00,  1.38it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-3): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (4-5): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (7-9): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (11-26): 16 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (27): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (28-30): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (31): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-3): 4 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (4-5): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (7-9): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (10): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (11-26): 16 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (27): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (28-30): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (31): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:3)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/52.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5063
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:09:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5063 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 63
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5160
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:09:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5160 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 160
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5164
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:09:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5164 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 164
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5247
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:09:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5247 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 247
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:09:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5211
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:09:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5211 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 211
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5034
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:09:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5034 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 34
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5099
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:09:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5099 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 99
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5157
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:09:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5157 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 157
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5012
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:09:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5012 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 12
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:09:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5098
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:09:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5098 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 98
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5173
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:09:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5173 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 173
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5180
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:09:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5180 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 180
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5140
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:09:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5140 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 140
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:09:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:09:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:09:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:09:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5112
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:09:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5112 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 112
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:09:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5174
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:09:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5174 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 174
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:09:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5040
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:09:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5040 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 40
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5172
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:09:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5172 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 172
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:09:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5075
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:09:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5075 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 75
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5009
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:09:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5009 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 9
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:09:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5151
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:09:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5151 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 151
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5219
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:09:22] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5219 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 219
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140208455213488 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140208455213488 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140208455213488 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140208455213488 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140215976506912 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140215976506912 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140215976506912 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140215976506912 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[52] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4225352112676056, 'acc_stderr,none': 0.059039842056825796}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.7169249479288816
0.6183111372245332
0.46095560668163316
0.45412629074361927
0.5961385422474115
0.8890533054728373
0.9122749865545955
0.7722412965326397
0.28598717020359266
0.16135518374824295
0.6405733513488978
0.34881239744915987
0.02163114281968652
0.8586809120820075
0.5280864903169471
0.5549214872848108
0.8809884720847853
0.8184475126773784
0.7411818478320343
0.9204128494945557
0.8828541622108917
0.8520796846320295
0.9938665155729866
0.8532228506983649
0.8363754351071634
0.7452449391867536
0.8461045724576085
0.3693743162395131
0.3582309316878524
0.7169249479288816
0.6183111372245332
0.46095560668163316
0.45412629074361927
0.5961385422474115
0.8890533054728373
0.9122749865545955
0.7722412965326397
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[5, 4, 6, 3, 2, 0, 7, 1]
tensor([5, 4, 6, 3, 2, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[6, 1, 7, 2, 4, 0, 5, 3]
tensor([6, 1, 7, 2, 4, 0, 5, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 4, 6, 3, 1, 0, 7, 5]
tensor([2, 4, 6, 3, 1, 0, 7, 5], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 0, 6, 4, 3, 1, 5, 7]
tensor([2, 0, 6, 4, 3, 1, 5, 7], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[3, 1, 0, 1, 2, 0, 2, 3]
tensor([3, 1, 0, 1, 2, 0, 2, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 2, 1, 0, 2, 3, 3]
tensor([0, 1, 2, 1, 0, 2, 3, 3], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[3, 1, 0, 1, 2, 0, 3, 2]
tensor([3, 1, 0, 1, 2, 0, 3, 2], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[0, 1, 2, 2, 3, 0, 3, 1]
tensor([0, 1, 2, 2, 3, 0, 3, 1], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[3, 0, 1, 2, 1, 2, 3, 0]
tensor([3, 0, 1, 2, 1, 2, 3, 0], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/52.pt
[RECEIVE] Queued message from 52
[QUEUE] Processing info from 52
[QUEUE] Stored info from 52
[RECEIVE] Queued message from 52
[QUEUE] Processing info from 52
[QUEUE] Stored info from 52
[RECEIVE] Queued message from 52
[QUEUE] Processing info from 52
[QUEUE] Stored info from 52
[RECEIVE] Queued message from 52
[QUEUE] Processing info from 52
[QUEUE] Stored info from 52
[RECEIVE] Queued message from 52
[QUEUE] Processing info from 52
[QUEUE] Stored info from 52
[RECEIVE] Queued message from 52
[QUEUE] Processing info from 52
[QUEUE] Stored info from 52
[RECEIVE] Queued message from 52
[QUEUE] Processing info from 52
[QUEUE] Stored info from 52
[RECEIVE] Queued message from 52
[QUEUE] Processing info from 52
[QUEUE] Stored info from 52
[RECEIVE] Queued message from 52
[QUEUE] Processing info from 52
[QUEUE] Stored info from 52
[RECEIVE] Queued message from 52
[QUEUE] Processing info from 52
[QUEUE] Stored info from 52
[RECEIVE] Queued message from 52
[QUEUE] Processing info from 52
[QUEUE] Stored info from 52
[RECEIVE] Queued message from 52
[QUEUE] Processing info from 52
[QUEUE] Stored info from 52
[RECEIVE] Queued message from 52
[QUEUE] Processing info from 52
[QUEUE] Stored info from 52
[RECEIVE] Queued message from 52
[QUEUE] Processing info from 52
[QUEUE] Stored info from 52
[RECEIVE] Queued message from 52
[QUEUE] Processing info from 52
[QUEUE] Stored info from 52
[RECEIVE] Queued message from 52
[QUEUE] Processing info from 52
[QUEUE] Stored info from 52
[RECEIVE] Queued message from 52
[QUEUE] Processing info from 52
[QUEUE] Stored info from 52
[RECEIVE] Queued message from 52
[QUEUE] Processing info from 52
[QUEUE] Stored info from 52
[RECEIVE] Queued message from 52
[QUEUE] Processing info from 52
[QUEUE] Stored info from 52
[RECEIVE] Queued message from 52
[QUEUE] Processing info from 52
[QUEUE] Stored info from 52
[RECEIVE] Queued message from 52
[QUEUE] Processing info from 52
[QUEUE] Stored info from 52
[RECEIVE] Queued message from 52
[QUEUE] Processing info from 52
[QUEUE] Stored info from 52
[RECEIVE] Queued message from 52
[QUEUE] Processing info from 52
[QUEUE] Stored info from 52
[RECEIVE] Queued message from 52
[QUEUE] Processing info from 52
[QUEUE] Stored info from 52
[RECEIVE] Queued message from 52
[QUEUE] Processing info from 52
[QUEUE] Stored info from 52
[RECEIVE] Queued message from 52
[QUEUE] Processing info from 52
[QUEUE] Stored info from 52
[RECEIVE] Queued message from 52
[QUEUE] Processing info from 52
[QUEUE] Stored info from 52
[RECEIVE] Queued message from 52
[QUEUE] Processing info from 52
[QUEUE] Stored info from 52
[RECEIVE] Queued message from 52
[QUEUE] Processing info from 52
[QUEUE] Stored info from 52
[RECEIVE] Queued message from 52
[QUEUE] Processing info from 52
[QUEUE] Stored info from 52
[RECEIVE] Queued message from 52
[QUEUE] Processing info from 52
[QUEUE] Stored info from 52
[140] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2477.19it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:03<07:43,  3.29s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:05<03:37,  1.56s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:07<02:50,  1.25s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:09<02:51,  1.27s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:11<02:31,  1.14s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:13<02:18,  1.06s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:15<02:08,  1.00it/s]Running loglikelihood requests:  11%|█         | 15/142 [00:16<02:02,  1.04it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:18<01:54,  1.09it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:20<01:50,  1.12it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:21<01:43,  1.17it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:23<01:37,  1.22it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:24<01:32,  1.26it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:26<01:28,  1.30it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:27<01:25,  1.32it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:29<01:36,  1.15it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:31<01:29,  1.21it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:32<01:24,  1.26it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:34<01:21,  1.29it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:35<01:17,  1.32it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:37<01:15,  1.34it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:38<01:12,  1.36it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:40<01:12,  1.33it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:41<01:09,  1.37it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:42<01:05,  1.41it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:44<01:02,  1.45it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:45<01:00,  1.47it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:46<00:58,  1.49it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:47<00:56,  1.51it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:49<00:54,  1.52it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:50<00:55,  1.47it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:51<00:52,  1.50it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:53<00:50,  1.53it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:54<00:48,  1.54it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:55<00:46,  1.56it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:56<00:45,  1.57it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:58<00:43,  1.59it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [00:59<00:41,  1.60it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:00<00:42,  1.54it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:02<00:40,  1.57it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:03<00:38,  1.59it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:04<00:36,  1.60it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:05<00:35,  1.61it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:06<00:34,  1.62it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:08<00:32,  1.62it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:09<00:31,  1.61it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:10<00:31,  1.54it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:12<00:33,  1.41it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:13<00:31,  1.41it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:15<00:29,  1.48it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:16<00:26,  1.54it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:17<00:24,  1.59it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:18<00:22,  1.62it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:19<00:21,  1.65it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:21<00:20,  1.59it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:22<00:18,  1.63it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:23<00:17,  1.67it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:25<00:18,  1.45it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:26<00:16,  1.51it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:27<00:14,  1.57it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:28<00:12,  1.62it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:29<00:11,  1.66it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:31<00:10,  1.63it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:32<00:08,  1.68it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:33<00:07,  1.71it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:34<00:06,  1.71it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:35<00:05,  1.74it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:36<00:03,  1.77it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:37<00:02,  1.80it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:38<00:01,  1.82it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:39<00:00,  1.86it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:39<00:00,  1.42it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-31): 26 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-31): 26 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:4)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/140.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5112
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:11:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5112 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 112
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5151
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:11:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5151 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 151
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5012
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:11:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5012 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 12
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:11:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5211
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:11:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5211 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 211
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5173
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:11:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5173 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 173
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5157
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:11:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5157 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 157
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:11:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:11:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5164
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:11:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5164 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 164
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5099
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:11:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5099 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 99
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:11:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5180
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:11:19] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5180 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 180
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:11:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:11:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5040
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:11:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5040 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 40
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:11:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:11:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:11:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5172
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:11:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5172 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 172
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5174
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:11:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5174 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 174
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5009
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:11:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5009 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 9
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5063
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:11:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5063 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 63
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5075
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:11:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5075 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 75
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5098
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:11:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5098 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 98
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5052
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:11:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5052 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 52
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5219
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:11:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5219 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 219
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5247
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:11:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5247 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 247
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5034
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:11:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5034 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 34
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5160
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:11:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5160 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 160
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:11:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140218668336384 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140218668336384 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140218668336384 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140218668336384 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140240957481152 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140240957481152 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140240957481152 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140240957481152 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[140] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4225352112676056, 'acc_stderr,none': 0.059039842056825796}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.4249710358556562
0.875077076525312
0.8377657430496294
0.7631146361001728
0.8061134194824199
0.597293936853132
0.8993038548124084
0.40672319990150296
0.4427306135620195
0.6697754068966065
0.560869697816391
0.6365238158372074
0.7977251509942833
0.5774168099619936
0.7636367981130562
0.45204149170439595
0.2621700055892588
0.8796773875905071
0.8519712476811715
0.8067705781994788
0.5994711637356425
0.8334667984344581
0.8573465838873401
0.8381586594258955
0.8329727759300379
0.8464402476627775
0.7864641899632313
0.6699089018877085
0.7340555031678195
0.4249710358556562
0.875077076525312
0.8377657430496294
0.7631146361001728
0.8061134194824199
0.597293936853132
0.8993038548124084
0.40672319990150296
0.4427306135620195
0.6697754068966065
0.560869697816391
0.6365238158372074
0.7977251509942833
0.5774168099619936
Total groups 75 exceeded the threshold, stopping comparison.
The group tensor is
[2, 1, 7, 5, 6, 0, 4, 3]
tensor([2, 1, 7, 5, 6, 0, 4, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 6, 7, 1, 3, 0, 5, 4]
tensor([2, 6, 7, 1, 3, 0, 5, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 1, 7, 4, 3, 0, 5, 6]
tensor([2, 1, 7, 4, 3, 0, 5, 6], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 3, 7, 1, 4, 0, 6, 2]
tensor([5, 3, 7, 1, 4, 0, 6, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 4, 6, 1, 3, 0, 7, 2]
tensor([5, 4, 6, 1, 3, 0, 7, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[2, 5, 0, 4, 1, 3, 1, 0]
tensor([2, 5, 0, 4, 1, 3, 1, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 3, 1, 1, 2, 0, 3, 2]
tensor([0, 3, 1, 1, 2, 0, 3, 2], dtype=torch.int32)
[0, 1, 2, 3]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/140.pt
[RECEIVE] Queued message from 140
[QUEUE] Processing info from 140
[QUEUE] Stored info from 140
[RECEIVE] Queued message from 140
[QUEUE] Processing info from 140
[QUEUE] Stored info from 140
[RECEIVE] Queued message from 140
[QUEUE] Processing info from 140
[QUEUE] Stored info from 140
[RECEIVE] Queued message from 140
[QUEUE] Processing info from 140
[QUEUE] Stored info from 140
[RECEIVE] Queued message from 140
[QUEUE] Processing info from 140
[QUEUE] Stored info from 140
[RECEIVE] Queued message from 140
[QUEUE] Processing info from 140
[QUEUE] Stored info from 140
[RECEIVE] Queued message from 140
[QUEUE] Processing info from 140
[QUEUE] Stored info from 140
[RECEIVE] Queued message from 140
[QUEUE] Processing info from 140
[QUEUE] Stored info from 140
[RECEIVE] Queued message from 140
[QUEUE] Processing info from 140
[QUEUE] Stored info from 140
[RECEIVE] Queued message from 140
[QUEUE] Processing info from 140
[QUEUE] Stored info from 140
[RECEIVE] Queued message from 140
[QUEUE] Processing info from 140
[QUEUE] Stored info from 140
[RECEIVE] Queued message from 140
[QUEUE] Processing info from 140
[QUEUE] Stored info from 140
[RECEIVE] Queued message from 140
[QUEUE] Processing info from 140
[QUEUE] Stored info from 140
[RECEIVE] Queued message from 140
[QUEUE] Processing info from 140
[QUEUE] Stored info from 140
[RECEIVE] Queued message from 140
[QUEUE] Processing info from 140
[QUEUE] Stored info from 140
[RECEIVE] Queued message from 140
[QUEUE] Processing info from 140
[QUEUE] Stored info from 140
[RECEIVE] Queued message from 140
[QUEUE] Processing info from 140
[QUEUE] Stored info from 140
[RECEIVE] Queued message from 140
[QUEUE] Processing info from 140
[QUEUE] Stored info from 140
[RECEIVE] Queued message from 140
[QUEUE] Processing info from 140
[QUEUE] Stored info from 140
[RECEIVE] Queued message from 140
[QUEUE] Processing info from 140
[QUEUE] Stored info from 140
[RECEIVE] Queued message from 140
[QUEUE] Processing info from 140
[QUEUE] Stored info from 140
[RECEIVE] Queued message from 140
[QUEUE] Processing info from 140
[QUEUE] Stored info from 140
[RECEIVE] Queued message from 140
[QUEUE] Processing info from 140
[QUEUE] Stored info from 140
[RECEIVE] Queued message from 140
[QUEUE] Processing info from 140
[QUEUE] Stored info from 140
[RECEIVE] Queued message from 140
[QUEUE] Processing info from 140
[QUEUE] Stored info from 140
[RECEIVE] Queued message from 140
[QUEUE] Processing info from 140
[QUEUE] Stored info from 140
[RECEIVE] Queued message from 140
[QUEUE] Processing info from 140
[QUEUE] Stored info from 140
[RECEIVE] Queued message from 140
[QUEUE] Processing info from 140
[QUEUE] Stored info from 140
[RECEIVE] Queued message from 140
[QUEUE] Processing info from 140
[QUEUE] Stored info from 140
[RECEIVE] Queued message from 140
[QUEUE] Processing info from 140
[QUEUE] Stored info from 140
[RECEIVE] Queued message from 140
[QUEUE] Processing info from 140
[QUEUE] Stored info from 140
[219] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2559.94it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:02<06:09,  2.62s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:04<03:22,  1.45s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:06<02:44,  1.20s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:08<02:28,  1.10s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:10<02:23,  1.08s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:12<02:14,  1.03s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:14<02:09,  1.00s/it]Running loglikelihood requests:  11%|█         | 15/142 [00:16<02:04,  1.02it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:17<01:56,  1.07it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:19<01:49,  1.12it/s]Running loglikelihood requests:  15%|█▍        | 21/142 [00:21<01:43,  1.17it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:22<01:38,  1.21it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:24<01:33,  1.25it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:25<01:33,  1.23it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:27<01:29,  1.26it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:28<01:25,  1.29it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:30<01:23,  1.31it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:31<01:20,  1.33it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:33<01:18,  1.33it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:34<01:19,  1.29it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:36<01:16,  1.32it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:37<01:14,  1.33it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:39<01:11,  1.35it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:40<01:08,  1.38it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:41<01:06,  1.41it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:43<01:03,  1.43it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:44<01:01,  1.45it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:46<01:01,  1.42it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:47<00:58,  1.46it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:48<00:55,  1.49it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:49<00:53,  1.51it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:51<00:51,  1.52it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:52<00:50,  1.54it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:53<00:48,  1.55it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:55<00:49,  1.48it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:56<00:49,  1.42it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [00:57<00:46,  1.48it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [00:59<00:44,  1.52it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:00<00:42,  1.55it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:01<00:39,  1.58it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:02<00:38,  1.59it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:04<00:36,  1.60it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:05<00:36,  1.55it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:06<00:35,  1.56it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:07<00:33,  1.58it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:09<00:32,  1.59it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:10<00:30,  1.60it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:11<00:29,  1.61it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:12<00:28,  1.59it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:14<00:26,  1.60it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:15<00:28,  1.45it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:17<00:25,  1.50it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:18<00:24,  1.54it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:19<00:22,  1.57it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:20<00:20,  1.60it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:21<00:19,  1.62it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:23<00:17,  1.64it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:24<00:16,  1.65it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:25<00:16,  1.51it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:27<00:14,  1.57it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:28<00:13,  1.61it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:29<00:11,  1.65it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:30<00:10,  1.67it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:31<00:08,  1.70it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:32<00:07,  1.71it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:33<00:06,  1.72it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:35<00:05,  1.73it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:36<00:04,  1.70it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:37<00:02,  1.74it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:38<00:01,  1.76it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:39<00:00,  1.80it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:39<00:00,  1.43it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-31): 26 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-31): 26 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:5)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/219.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5112
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:13:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5112 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 112
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5174
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:13:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5174 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 174
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5151
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:13:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5151 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 151
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:13:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:13:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5099
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:13:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5099 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 99
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:13:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5012
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:13:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5012 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 12
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5164
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:13:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5164 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 164
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5009
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:13:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5009 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 9
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5075
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:13:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5075 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 75
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:13:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:13:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:13:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5172
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:13:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5172 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 172
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5040
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:13:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5040 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 40
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:13:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5180
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:13:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5180 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 180
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5173
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:13:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5173 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 173
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5063
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:13:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5063 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 63
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5052
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:13:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5052 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 52
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5211
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:13:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5211 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 211
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:13:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5098
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:13:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5098 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 98
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5140
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:13:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5140 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 140
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5034
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:13:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5034 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 34
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5160
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:13:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5160 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 160
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:13:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5157
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:13:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5157 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 157
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5247
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:13:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5247 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 247
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:13:16] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140209478063776 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140209478063776 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140209478063776 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140209478063776 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140209476715584 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140209476715584 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140209476715584 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140209476715584 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[219] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.4084507042253521, 'acc_stderr,none': 0.058751136942575236}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.8470147925890528
0.7476864669376683
0.7057458194715966
0.9259961826035564
0.9063486644110201
0.24963708122926456
0.19827660218091203
0.8342224461031358
0.674768686362321
0.8317740713616216
0.8052770539851904
0.87411142785436
0.9423251627051763
0.6325449231299249
0.5709019604280002
0.492272078021527
0.5470094105753499
0.8106788106419917
0.8007286389438932
0.8514363351777328
0.5678533410855942
0.6964663000476322
0.43791892189616227
0.24333097709743945
0.6773756911035087
0.7468917488225975
0.9536421875896308
0.6970547096788922
0.8446279043078407
0.8470147925890528
0.7476864669376683
0.7057458194715966
0.9259961826035564
0.9063486644110201
0.24963708122926456
0.19827660218091203
0.8342224461031358
0.674768686362321
0.8317740713616216
0.8052770539851904
0.87411142785436
0.9423251627051763
0.6325449231299249
0.5709019604280002
0.492272078021527
Total groups 76 exceeded the threshold, stopping comparison.
The group tensor is
[3, 4, 6, 5, 2, 0, 7, 1]
tensor([3, 4, 6, 5, 2, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 4, 6, 5, 3, 0, 7, 1]
tensor([2, 4, 6, 5, 3, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[6, 3, 4, 5, 2, 0, 7, 1]
tensor([6, 3, 4, 5, 2, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[1, 4, 7, 2, 5, 0, 6, 3]
tensor([1, 4, 7, 2, 5, 0, 6, 3], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[0, 3, 5, 2, 0, 1, 1, 4]
tensor([0, 3, 5, 2, 0, 1, 1, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[4, 3, 0, 5, 2, 0, 1, 1]
tensor([4, 3, 0, 5, 2, 0, 1, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[0, 3, 5, 1, 4, 0, 1, 2]
tensor([0, 3, 5, 1, 4, 0, 1, 2], dtype=torch.int32)
[0, 1, 2, 3, 4, 5]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
The group tensor is
[0, 1, 1.0, 1, 0, 1.0, 1.0, 1.0]
tensor([0, 1, 1, 1, 0, 1, 1, 1], dtype=torch.int32)
[0, 1]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/219.pt
[RECEIVE] Queued message from 219
[QUEUE] Processing info from 219
[QUEUE] Stored info from 219
[RECEIVE] Queued message from 219
[QUEUE] Processing info from 219
[QUEUE] Stored info from 219
[RECEIVE] Queued message from 219
[QUEUE] Processing info from 219
[QUEUE] Stored info from 219
[RECEIVE] Queued message from 219
[QUEUE] Processing info from 219
[QUEUE] Stored info from 219
[RECEIVE] Queued message from 219
[QUEUE] Processing info from 219
[QUEUE] Stored info from 219
[RECEIVE] Queued message from 219
[QUEUE] Processing info from 219
[QUEUE] Stored info from 219
[RECEIVE] Queued message from 219
[QUEUE] Processing info from 219
[QUEUE] Stored info from 219
[RECEIVE] Queued message from 219
[QUEUE] Processing info from 219
[QUEUE] Stored info from 219
[RECEIVE] Queued message from 219
[QUEUE] Processing info from 219
[QUEUE] Stored info from 219
[RECEIVE] Queued message from 219
[QUEUE] Processing info from 219
[QUEUE] Stored info from 219
[RECEIVE] Queued message from 219
[QUEUE] Processing info from 219
[QUEUE] Stored info from 219
[RECEIVE] Queued message from 219
[QUEUE] Processing info from 219
[QUEUE] Stored info from 219
[RECEIVE] Queued message from 219
[QUEUE] Processing info from 219
[QUEUE] Stored info from 219
[RECEIVE] Queued message from 219
[QUEUE] Processing info from 219
[QUEUE] Stored info from 219
[RECEIVE] Queued message from 219
[QUEUE] Processing info from 219
[QUEUE] Stored info from 219
[RECEIVE] Queued message from 219
[QUEUE] Processing info from 219
[QUEUE] Stored info from 219
[RECEIVE] Queued message from 219
[QUEUE] Processing info from 219
[QUEUE] Stored info from 219
[RECEIVE] Queued message from 219
[QUEUE] Processing info from 219
[QUEUE] Stored info from 219
[RECEIVE] Queued message from 219
[QUEUE] Processing info from 219
[QUEUE] Stored info from 219
[RECEIVE] Queued message from 219
[QUEUE] Processing info from 219
[QUEUE] Stored info from 219
[RECEIVE] Queued message from 219
[QUEUE] Processing info from 219
[QUEUE] Stored info from 219
[RECEIVE] Queued message from 219
[QUEUE] Processing info from 219
[QUEUE] Stored info from 219
[RECEIVE] Queued message from 219
[QUEUE] Processing info from 219
[QUEUE] Stored info from 219
[RECEIVE] Queued message from 219
[QUEUE] Processing info from 219
[QUEUE] Stored info from 219
[RECEIVE] Queued message from 219
[QUEUE] Processing info from 219
[QUEUE] Stored info from 219
[RECEIVE] Queued message from 219
[QUEUE] Processing info from 219
[QUEUE] Stored info from 219
[RECEIVE] Queued message from 219
[QUEUE] Processing info from 219
[QUEUE] Stored info from 219
[RECEIVE] Queued message from 219
[QUEUE] Processing info from 219
[QUEUE] Stored info from 219
[RECEIVE] Queued message from 219
[QUEUE] Processing info from 219
[QUEUE] Stored info from 219
[RECEIVE] Queued message from 219
[QUEUE] Processing info from 219
[QUEUE] Stored info from 219
[RECEIVE] Queued message from 219
[QUEUE] Processing info from 219
[QUEUE] Stored info from 219
[151] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2569.88it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:03<08:46,  3.73s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:05<04:00,  1.73s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:07<03:06,  1.36s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:09<02:43,  1.21s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:11<02:32,  1.15s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:13<02:22,  1.09s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:15<02:13,  1.03s/it]Running loglikelihood requests:  11%|█         | 15/142 [00:17<02:06,  1.00it/s]Running loglikelihood requests:  12%|█▏        | 17/142 [00:19<02:00,  1.04it/s]Running loglikelihood requests:  13%|█▎        | 19/142 [00:21<02:03,  1.00s/it]Running loglikelihood requests:  15%|█▍        | 21/142 [00:23<01:54,  1.06it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:24<01:46,  1.11it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:26<01:40,  1.16it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:27<01:35,  1.20it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:29<01:31,  1.23it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:31<01:35,  1.17it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:32<01:30,  1.20it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:34<01:26,  1.24it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:35<01:23,  1.25it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:37<01:20,  1.28it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:38<01:18,  1.28it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:40<01:16,  1.30it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:42<01:17,  1.25it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:43<01:13,  1.29it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:44<01:09,  1.34it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:46<01:05,  1.38it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:47<01:03,  1.41it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:48<01:00,  1.43it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:50<00:58,  1.45it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:51<01:00,  1.38it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:53<00:57,  1.41it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:54<00:54,  1.44it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:55<00:52,  1.46it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:57<00:50,  1.48it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [00:58<00:48,  1.50it/s]Running loglikelihood requests:  50%|█████     | 71/142 [00:59<00:47,  1.50it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [01:01<00:45,  1.51it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [01:02<00:45,  1.46it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:03<00:43,  1.49it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:05<00:41,  1.51it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:06<00:39,  1.53it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:07<00:38,  1.54it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:09<00:36,  1.55it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:10<00:35,  1.56it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:11<00:37,  1.42it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:13<00:37,  1.36it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:14<00:34,  1.40it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:16<00:32,  1.44it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:17<00:30,  1.48it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:18<00:28,  1.50it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:20<00:26,  1.52it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:21<00:25,  1.54it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:22<00:24,  1.51it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:23<00:22,  1.54it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:25<00:21,  1.57it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:26<00:19,  1.59it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:27<00:18,  1.61it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:28<00:16,  1.62it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:30<00:15,  1.63it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:31<00:13,  1.64it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:32<00:13,  1.59it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:33<00:11,  1.62it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:34<00:10,  1.65it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:36<00:09,  1.66it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:37<00:07,  1.68it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:38<00:06,  1.69it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:39<00:05,  1.71it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:40<00:04,  1.73it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:41<00:02,  1.75it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:43<00:01,  1.51it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:44<00:00,  1.59it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:44<00:00,  1.36it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-3): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (4): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-7): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (8): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9-10): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (11): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (12-13): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (15): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (16): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (17-31): 15 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-1): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (2-3): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (4): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (5-7): 3 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (8): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (9-10): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (11): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (12-13): 2 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (14): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (15): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (16): LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (17-31): 15 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:6)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/151.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5173
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:15:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5173 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 173
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:15:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5052
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:15:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5052 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 52
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5012
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:15:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5012 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 12
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5160
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:15:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5160 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 160
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5063
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:15:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5063 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 63
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:15:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5140
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:15:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5140 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 140
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5075
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:15:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5075 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 75
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5034
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:15:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5034 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 34
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:15:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5098
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:15:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5098 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 98
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5180
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:15:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5180 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 180
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5164
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:15:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5164 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 164
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:15:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5174
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:15:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5174 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 174
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5040
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:15:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5040 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 40
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:15:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5247
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:15:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5247 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 247
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5219
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:15:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5219 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 219
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5112
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:15:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5112 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 112
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:15:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5172
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:15:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5172 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 172
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:15:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:15:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:15:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5211
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:15:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5211 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 211
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5009
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:15:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5009 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 9
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5099
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:15:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5099 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 99
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5157
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:15:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5157 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 157
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:15:18] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
INFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Using pre-initialized model
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but aggregation is not. using default aggregation=mean
WARNING:lm_eval.api.task:[Task: wnli] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /datasets.huggingface.co/datasets/datasets/glue/glue.py HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/glue HTTP/1.1" 307 61
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "GET /api/datasets/nyu-mll/glue HTTP/1.1" 200 None
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/README.md HTTP/1.1" 200 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 233
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): hf-mirror.com:443
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 307 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "HEAD /datasets/nyu-mll/glue/resolve/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_infos.json HTTP/1.1" 404 0
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 307 113
DEBUG:urllib3.connectionpool:https://hf-mirror.com:443 "POST /api/datasets/nyu-mll/glue/paths-info/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c HTTP/1.1" 200 236
DEBUG:filelock:Attempting to acquire lock 140216457163504 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140216457163504 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140216457163504 on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Lock 140216457163504 released on /public/home/zouyifei001/.cache/huggingface/datasets/_public_home_zouyifei001_.cache_huggingface_datasets_glue_wnli_0.0.0_bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c.lock
DEBUG:filelock:Attempting to acquire lock 140218643528304 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140218643528304 acquired on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:fsspec.local:open file: /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/dataset_info.json
DEBUG:filelock:Attempting to release lock 140218643528304 on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:filelock:Lock 140218643528304 released on /public/home/zouyifei001/.cache/huggingface/datasets/glue/wnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c_builder.lock
DEBUG:lm_eval.api.task:No custom filters defined. Using default 'take_first' filter for handling repeats.
WARNING:lm_eval.evaluator:Overwriting default num_fewshot of wnli from None to 0
INFO:lm_eval.api.task:Building contexts for wnli on rank 0...
[151] Inference Results (Before Update): {'wnli': {'alias': 'wnli', 'acc,none': 0.43661971830985913, 'acc_stderr,none': 0.05927935558412972}}
length of layer 0 is :8
length of layer 1 is :8
length of layer 2 is :8
length of layer 3 is :8
length of layer 4 is :8
length of layer 5 is :8
length of layer 6 is :8
length of layer 7 is :8
length of layer 8 is :8
length of layer 9 is :8
length of layer 10 is :8
length of layer 11 is :8
length of layer 12 is :8
length of layer 13 is :8
length of layer 14 is :8
length of layer 15 is :8
length of layer 16 is :8
length of layer 17 is :8
length of layer 18 is :8
length of layer 19 is :8
length of layer 20 is :8
length of layer 21 is :8
length of layer 22 is :8
length of layer 23 is :8
length of layer 24 is :8
length of layer 25 is :8
length of layer 26 is :8
length of layer 27 is :8
length of layer 28 is :8
length of layer 29 is :8
length of layer 30 is :8
length of layer 31 is :8
0.6384788962207051
0.4946572039289874
0.7062468225311351
0.5924118081316296
0.8055799477986278
0.4290834385090486
0.5207152243980063
0.40307410421369466
0.575849756312845
0.37833122092903004
0.559402975459772
0.9202435099718248
0.7328649512638977
0.4656521136449837
0.6226167455222542
0.6500475926241498
0.14933051029764177
0.852848973497393
0.7020336348742873
0.8036038458930006
0.25840240277743587
0.45348406473870356
0.7291236246725161
0.5999541971262276
0.7071125031923391
0.6523270915574834
0.5982105985982268
0.6520903105513685
0.39933491227192136
0.6384788962207051
0.4946572039289874
0.7062468225311351
0.5924118081316296
0.8055799477986278
0.4290834385090486
0.5207152243980063
0.40307410421369466
0.575849756312845
0.37833122092903004
0.559402975459772
0.9202435099718248
0.7328649512638977
0.4656521136449837
0.6226167455222542
0.6500475926241498
0.14933051029764177
0.852848973497393
0.7020336348742873
0.8036038458930006
0.25840240277743587
0.45348406473870356
0.7291236246725161
0.5999541971262276
0.7071125031923391
Total groups 74 exceeded the threshold, stopping comparison.
The group tensor is
[6, 3, 2, 1, 5, 0, 7, 4]
tensor([6, 3, 2, 1, 5, 0, 7, 4], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 5, 4, 2, 6, 0, 7, 1]
tensor([3, 5, 4, 2, 6, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[2, 7, 6, 3, 4, 1, 5, 0]
tensor([2, 7, 6, 3, 4, 1, 5, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[3, 2, 5, 4, 6, 0, 7, 1]
tensor([3, 2, 5, 4, 6, 0, 7, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[4, 5, 7, 0, 3, 2, 6, 1]
tensor([4, 5, 7, 0, 3, 2, 6, 1], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[5, 6, 3, 4, 2, 1, 7, 0]
tensor([5, 6, 3, 4, 2, 1, 7, 0], dtype=torch.int32)
[0, 1, 2, 3, 4, 5, 6, 7]
The group tensor is
[-2, -2, -2, -2, -2, -2, -2, -2]
tensor([-2, -2, -2, -2, -2, -2, -2, -2], dtype=torch.int32)
[-2]
Model saved locally at saved_models/151.pt
[RECEIVE] Queued message from 151
[QUEUE] Processing info from 151
[QUEUE] Stored info from 151
[RECEIVE] Queued message from 151
[QUEUE] Processing info from 151
[QUEUE] Stored info from 151
[RECEIVE] Queued message from 151
[QUEUE] Processing info from 151
[QUEUE] Stored info from 151
[RECEIVE] Queued message from 151
[QUEUE] Processing info from 151
[QUEUE] Stored info from 151
[RECEIVE] Queued message from 151
[QUEUE] Processing info from 151
[QUEUE] Stored info from 151
[RECEIVE] Queued message from 151
[QUEUE] Processing info from 151
[QUEUE] Stored info from 151
[RECEIVE] Queued message from 151
[QUEUE] Processing info from 151
[QUEUE] Stored info from 151
[RECEIVE] Queued message from 151
[QUEUE] Processing info from 151
[QUEUE] Stored info from 151
[RECEIVE] Queued message from 151
[QUEUE] Processing info from 151
[QUEUE] Stored info from 151
[RECEIVE] Queued message from 151
[QUEUE] Processing info from 151
[QUEUE] Stored info from 151
[RECEIVE] Queued message from 151
[QUEUE] Processing info from 151
[QUEUE] Stored info from 151
[RECEIVE] Queued message from 151
[QUEUE] Processing info from 151
[QUEUE] Stored info from 151
[RECEIVE] Queued message from 151
[QUEUE] Processing info from 151
[QUEUE] Stored info from 151
[RECEIVE] Queued message from 151
[QUEUE] Processing info from 151
[QUEUE] Stored info from 151
[RECEIVE] Queued message from 151
[QUEUE] Processing info from 151
[QUEUE] Stored info from 151
[RECEIVE] Queued message from 151
[QUEUE] Processing info from 151
[QUEUE] Stored info from 151
[RECEIVE] Queued message from 151
[QUEUE] Processing info from 151
[QUEUE] Stored info from 151
[RECEIVE] Queued message from 151
[QUEUE] Processing info from 151
[QUEUE] Stored info from 151
[RECEIVE] Queued message from 151
[QUEUE] Processing info from 151
[QUEUE] Stored info from 151
[RECEIVE] Queued message from 151
[QUEUE] Processing info from 151
[QUEUE] Stored info from 151
[RECEIVE] Queued message from 151
[QUEUE] Processing info from 151
[QUEUE] Stored info from 151
[RECEIVE] Queued message from 151
[QUEUE] Processing info from 151
[QUEUE] Stored info from 151
[RECEIVE] Queued message from 151
[QUEUE] Processing info from 151
[QUEUE] Stored info from 151
[RECEIVE] Queued message from 151
[QUEUE] Processing info from 151
[QUEUE] Stored info from 151
[RECEIVE] Queued message from 151
[QUEUE] Processing info from 151
[QUEUE] Stored info from 151
[RECEIVE] Queued message from 151
[QUEUE] Processing info from 151
[QUEUE] Stored info from 151
[RECEIVE] Queued message from 151
[QUEUE] Processing info from 151
[QUEUE] Stored info from 151
[RECEIVE] Queued message from 151
[QUEUE] Processing info from 151
[QUEUE] Stored info from 151
[RECEIVE] Queued message from 151
[QUEUE] Processing info from 151
[QUEUE] Stored info from 151
[RECEIVE] Queued message from 151
[QUEUE] Processing info from 151
[QUEUE] Stored info from 151
[RECEIVE] Queued message from 151
[QUEUE] Processing info from 151
[QUEUE] Stored info from 151
[112] Inference Step Starting
  0%|          | 0/71 [00:00<?, ?it/s]100%|██████████| 71/71 [00:00<00:00, 2555.35it/s]
DEBUG:lm_eval.evaluator:Task: wnli; number of requests on this rank: 142
INFO:lm_eval.evaluator:Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/142 [00:00<?, ?it/s]Running loglikelihood requests:   1%|          | 1/142 [00:03<08:15,  3.51s/it]Running loglikelihood requests:   2%|▏         | 3/142 [00:05<03:45,  1.62s/it]Running loglikelihood requests:   4%|▎         | 5/142 [00:07<02:54,  1.27s/it]Running loglikelihood requests:   5%|▍         | 7/142 [00:09<02:34,  1.14s/it]Running loglikelihood requests:   6%|▋         | 9/142 [00:14<03:57,  1.79s/it]Running loglikelihood requests:   8%|▊         | 11/142 [00:16<03:14,  1.48s/it]Running loglikelihood requests:   9%|▉         | 13/142 [00:18<02:45,  1.28s/it]Running loglikelihood requests:  11%|█         | 15/142 [00:20<02:25,  1.14s/it]Running loglikelihood requests:  12%|█▏        | 17/142 [00:22<02:21,  1.13s/it]Running loglikelihood requests:  13%|█▎        | 19/142 [00:24<02:06,  1.03s/it]Running loglikelihood requests:  15%|█▍        | 21/142 [00:25<01:55,  1.05it/s]Running loglikelihood requests:  16%|█▌        | 23/142 [00:27<01:46,  1.12it/s]Running loglikelihood requests:  18%|█▊        | 25/142 [00:28<01:39,  1.18it/s]Running loglikelihood requests:  19%|█▉        | 27/142 [00:30<01:33,  1.23it/s]Running loglikelihood requests:  20%|██        | 29/142 [00:31<01:34,  1.19it/s]Running loglikelihood requests:  22%|██▏       | 31/142 [00:33<01:29,  1.24it/s]Running loglikelihood requests:  23%|██▎       | 33/142 [00:35<01:40,  1.08it/s]Running loglikelihood requests:  25%|██▍       | 35/142 [00:37<01:32,  1.15it/s]Running loglikelihood requests:  26%|██▌       | 37/142 [00:38<01:26,  1.21it/s]Running loglikelihood requests:  27%|██▋       | 39/142 [00:40<01:21,  1.26it/s]Running loglikelihood requests:  29%|██▉       | 41/142 [00:41<01:18,  1.29it/s]Running loglikelihood requests:  30%|███       | 43/142 [00:43<01:21,  1.22it/s]Running loglikelihood requests:  32%|███▏      | 45/142 [00:44<01:15,  1.28it/s]Running loglikelihood requests:  33%|███▎      | 47/142 [00:46<01:11,  1.33it/s]Running loglikelihood requests:  35%|███▍      | 49/142 [00:47<01:07,  1.38it/s]Running loglikelihood requests:  36%|███▌      | 51/142 [00:48<01:04,  1.42it/s]Running loglikelihood requests:  37%|███▋      | 53/142 [00:50<01:01,  1.45it/s]Running loglikelihood requests:  39%|███▊      | 55/142 [00:51<00:59,  1.47it/s]Running loglikelihood requests:  40%|████      | 57/142 [00:52<00:58,  1.45it/s]Running loglikelihood requests:  42%|████▏     | 59/142 [00:54<00:56,  1.47it/s]Running loglikelihood requests:  43%|████▎     | 61/142 [00:55<00:54,  1.49it/s]Running loglikelihood requests:  44%|████▍     | 63/142 [00:56<00:52,  1.51it/s]Running loglikelihood requests:  46%|████▌     | 65/142 [00:58<00:50,  1.53it/s]Running loglikelihood requests:  47%|████▋     | 67/142 [00:59<00:48,  1.54it/s]Running loglikelihood requests:  49%|████▊     | 69/142 [01:00<00:47,  1.55it/s]Running loglikelihood requests:  50%|█████     | 71/142 [01:01<00:45,  1.55it/s]Running loglikelihood requests:  51%|█████▏    | 73/142 [01:03<00:45,  1.51it/s]Running loglikelihood requests:  53%|█████▎    | 75/142 [01:04<00:43,  1.53it/s]Running loglikelihood requests:  54%|█████▍    | 77/142 [01:05<00:41,  1.55it/s]Running loglikelihood requests:  56%|█████▌    | 79/142 [01:07<00:40,  1.57it/s]Running loglikelihood requests:  57%|█████▋    | 81/142 [01:08<00:42,  1.42it/s]Running loglikelihood requests:  58%|█████▊    | 83/142 [01:09<00:39,  1.48it/s]Running loglikelihood requests:  60%|█████▉    | 85/142 [01:11<00:37,  1.51it/s]Running loglikelihood requests:  61%|██████▏   | 87/142 [01:12<00:38,  1.41it/s]Running loglikelihood requests:  63%|██████▎   | 89/142 [01:14<00:36,  1.47it/s]Running loglikelihood requests:  64%|██████▍   | 91/142 [01:15<00:33,  1.50it/s]Running loglikelihood requests:  65%|██████▌   | 93/142 [01:16<00:31,  1.54it/s]Running loglikelihood requests:  67%|██████▋   | 95/142 [01:17<00:30,  1.56it/s]Running loglikelihood requests:  68%|██████▊   | 97/142 [01:19<00:28,  1.58it/s]Running loglikelihood requests:  70%|██████▉   | 99/142 [01:20<00:26,  1.60it/s]Running loglikelihood requests:  71%|███████   | 101/142 [01:21<00:25,  1.62it/s]Running loglikelihood requests:  73%|███████▎  | 103/142 [01:23<00:26,  1.45it/s]Running loglikelihood requests:  74%|███████▍  | 105/142 [01:24<00:24,  1.51it/s]Running loglikelihood requests:  75%|███████▌  | 107/142 [01:25<00:22,  1.56it/s]Running loglikelihood requests:  77%|███████▋  | 109/142 [01:26<00:20,  1.60it/s]Running loglikelihood requests:  78%|███████▊  | 111/142 [01:28<00:20,  1.53it/s]Running loglikelihood requests:  80%|███████▉  | 113/142 [01:29<00:18,  1.58it/s]Running loglikelihood requests:  81%|████████  | 115/142 [01:30<00:16,  1.62it/s]Running loglikelihood requests:  82%|████████▏ | 117/142 [01:31<00:15,  1.65it/s]Running loglikelihood requests:  84%|████████▍ | 119/142 [01:33<00:15,  1.52it/s]Running loglikelihood requests:  85%|████████▌ | 121/142 [01:34<00:13,  1.58it/s]Running loglikelihood requests:  87%|████████▋ | 123/142 [01:35<00:11,  1.64it/s]Running loglikelihood requests:  88%|████████▊ | 125/142 [01:36<00:10,  1.68it/s]Running loglikelihood requests:  89%|████████▉ | 127/142 [01:37<00:08,  1.70it/s]Running loglikelihood requests:  91%|█████████ | 129/142 [01:38<00:07,  1.73it/s]Running loglikelihood requests:  92%|█████████▏| 131/142 [01:39<00:06,  1.75it/s]Running loglikelihood requests:  94%|█████████▎| 133/142 [01:41<00:05,  1.77it/s]Running loglikelihood requests:  95%|█████████▌| 135/142 [01:42<00:03,  1.79it/s]Running loglikelihood requests:  96%|█████████▋| 137/142 [01:43<00:03,  1.66it/s]Running loglikelihood requests:  98%|█████████▊| 139/142 [01:44<00:01,  1.71it/s]Running loglikelihood requests:  99%|█████████▉| 141/142 [01:45<00:00,  1.76it/s]Running loglikelihood requests: 100%|██████████| 142/142 [01:45<00:00,  1.34it/s]
DEBUG:lm_eval.models.huggingface:Failed to get model SHA for LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-31): 26 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) at revision main. Error: Repo id must be a string, not <class 'transformers_modules.LLaMA-MoE-v1-3_5B-2_8.modeling_llama_moe_hf.LlamaMoEForCausalLM'>: 'LlamaMoEForCausalLM(
  (model): LlamaMoEModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-5): 6 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1376x4096]
                  (2): Parameter containing: [torch.float32 of size 1376x4096]
                  (3): Parameter containing: [torch.float32 of size 1376x4096]
                  (4): Parameter containing: [torch.float32 of size 1376x4096]
                  (5): Parameter containing: [torch.float32 of size 1376x4096]
                  (6): Parameter containing: [torch.float32 of size 1376x4096]
                  (7): Parameter containing: [torch.float32 of size 1376x4096]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 4096x1376]
                  (2): Parameter containing: [torch.float32 of size 4096x1376]
                  (3): Parameter containing: [torch.float32 of size 4096x1376]
                  (4): Parameter containing: [torch.float32 of size 4096x1376]
                  (5): Parameter containing: [torch.float32 of size 4096x1376]
                  (6): Parameter containing: [torch.float32 of size 4096x1376]
                  (7): Parameter containing: [torch.float32 of size 4096x1376]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
      (6-31): 26 x LlamaMoEDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LinearGLUMoELayer(
          (gate): TopKBalancedNoisyGate(
            (gate_network): Sequential(
              (0): Linear(in_features=4096, out_features=8, bias=False)
              (1): Tanh()
              (2): Linear(in_features=8, out_features=8, bias=False)
            )
            (softmax): Softmax(dim=1)
            (weight_noise): Linear(in_features=4096, out_features=8, bias=False)
            (softplus): Softplus(beta=1.0, threshold=20.0)
          )
          (calculator): UniversalCalculator(
            (experts): LinearGLUExperts(
              in_features=4096, hidden_features=11008, out_features=4096, hidden_act=silu, num_experts=8, size_experts=[1376, 1376, 1376, 1376, 1376, 1376, 1376, 1376], bias=False
              (act_fn): SiLU()
              (weight_gate): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_up): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 1376x4096]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
              (weight_down): ParameterList(
                  (0): Parameter containing: [torch.float32 of size 4096x1376]
                  (1): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (2): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (3): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (4): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (5): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (6): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
                  (7): Parameter containing: [torch.float32 of size 1x1 (cuda:7)]
              )
            )
          )
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
)'.
WARNING:save_model:Expert index -2 is negative, resetting to 0.
INFO:save_model:Model saved successfully at saved_models/112.pt
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5012
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:17:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5012 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 12
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5161
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:17:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5161 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 161
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5247
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:17:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5247 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 247
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5173
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:17:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5173 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 173
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5174
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:17:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5174 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 174
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5157
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:17:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5157 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 157
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5239
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:17:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5239 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 239
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5140
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:17:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5140 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 140
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5151
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:17:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5151 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 151
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5127
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:17:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5127 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 127
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5164
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:17:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5164 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 164
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5099
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:17:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5099 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 99
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5163
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:17:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5163 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 163
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5055
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:17:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5055 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5063
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:17:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5063 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 63
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5087
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:17:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5087 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 87
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5034
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:17:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5034 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 34
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5039
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:17:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5039 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 39
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5211
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:17:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5211 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 211
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5172
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:17:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5172 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 172
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5052
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:17:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5052 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 52
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5098
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:17:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5098 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 98
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5117
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:17:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5117 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 117
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5009
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:17:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5009 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 9
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5160
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:17:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5160 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 160
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5040
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:17:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5040 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 40
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5075
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:17:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5075 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 75
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5094
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:17:20] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5094 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 94
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5219
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:17:21] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5219 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 219
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5180
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:17:21] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5180 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 180
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:5123
INFO:werkzeug:127.0.0.1 - - [18/May/2025 10:17:21] "POST /receive_info HTTP/1.1" 200 -
DEBUG:urllib3.connectionpool:http://127.0.0.1:5123 "POST /receive_info HTTP/1.1" 200 42
INFO:save_model:Node info successfully sent to 123
